Extracting:   0%|          | 0/31 [00:00<?, ?it/s]Extracting:   3%|▎         | 1/31 [00:15<07:39, 15.33s/it]Extracting:   6%|▋         | 2/31 [00:15<03:07,  6.46s/it]Extracting:  10%|▉         | 3/31 [00:15<01:41,  3.63s/it]Extracting:  13%|█▎        | 4/31 [00:18<01:32,  3.44s/it]Extracting:  16%|█▌        | 5/31 [00:21<01:23,  3.19s/it]Extracting:  19%|█▉        | 6/31 [00:22<00:54,  2.20s/it]Extracting:  23%|██▎       | 7/31 [00:22<00:37,  1.56s/it]Extracting:  26%|██▌       | 8/31 [00:28<01:12,  3.16s/it]Extracting:  29%|██▉       | 9/31 [00:31<01:06,  3.03s/it]Extracting:  32%|███▏      | 10/31 [00:31<00:45,  2.18s/it]Extracting:  35%|███▌      | 11/31 [00:32<00:31,  1.59s/it]Extracting:  39%|███▊      | 12/31 [00:36<00:48,  2.54s/it]Extracting:  42%|████▏     | 13/31 [00:41<00:56,  3.12s/it]Extracting:  45%|████▌     | 14/31 [00:41<00:38,  2.26s/it]Extracting:  48%|████▊     | 15/31 [00:41<00:26,  1.66s/it]Extracting:  52%|█████▏    | 16/31 [00:48<00:46,  3.09s/it]Extracting:  55%|█████▍    | 17/31 [00:52<00:49,  3.52s/it]Extracting:  58%|█████▊    | 18/31 [00:53<00:33,  2.54s/it]Extracting:  61%|██████▏   | 19/31 [00:53<00:22,  1.86s/it]Extracting:  65%|██████▍   | 20/31 [00:58<00:33,  3.01s/it]Extracting:  68%|██████▊   | 21/31 [01:03<00:33,  3.39s/it]Extracting:  71%|███████   | 22/31 [01:03<00:22,  2.45s/it]Extracting:  74%|███████▍  | 23/31 [01:03<00:14,  1.80s/it]Extracting:  77%|███████▋  | 24/31 [01:12<00:27,  3.93s/it]Extracting:  81%|████████  | 25/31 [01:14<00:20,  3.41s/it]Extracting:  84%|████████▍ | 26/31 [01:15<00:12,  2.46s/it]Extracting:  87%|████████▋ | 27/31 [01:15<00:07,  1.80s/it]Extracting:  90%|█████████ | 28/31 [01:21<00:09,  3.20s/it]Extracting:  94%|█████████▎| 29/31 [01:27<00:08,  4.07s/it]Extracting:  97%|█████████▋| 30/31 [01:28<00:02,  2.92s/it]Extracting: 100%|██████████| 31/31 [01:28<00:00,  2.85s/it]
Training epoch 0:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 0:   3%|▎         | 1/31 [00:29<14:30, 29.01s/it]Training epoch 0:   3%|▎         | 1/31 [00:29<14:30, 29.01s/it, loss=10.9728, batch_acc=0.0000, running_acc=0.0000, grad=33.2910]Training epoch 0:   6%|▋         | 2/31 [00:30<06:13, 12.88s/it, loss=10.9728, batch_acc=0.0000, running_acc=0.0000, grad=33.2910]Training epoch 0:   6%|▋         | 2/31 [00:30<06:13, 12.88s/it, loss=10.4011, batch_acc=0.0000, running_acc=0.0000, grad=21.0478]Training epoch 0:  10%|▉         | 3/31 [00:32<03:35,  7.68s/it, loss=10.4011, batch_acc=0.0000, running_acc=0.0000, grad=21.0478]Training epoch 0:  10%|▉         | 3/31 [00:32<03:35,  7.68s/it, loss=9.9112, batch_acc=0.0000, running_acc=0.0000, grad=26.0500] Training epoch 0:  13%|█▎        | 4/31 [00:33<02:21,  5.25s/it, loss=9.9112, batch_acc=0.0000, running_acc=0.0000, grad=26.0500]Training epoch 0:  13%|█▎        | 4/31 [00:33<02:21,  5.25s/it, loss=10.5213, batch_acc=0.0000, running_acc=0.0000, grad=23.6819]Training epoch 0:  16%|█▌        | 5/31 [00:35<01:41,  3.90s/it, loss=10.5213, batch_acc=0.0000, running_acc=0.0000, grad=23.6819]Training epoch 0:  16%|█▌        | 5/31 [00:35<01:41,  3.90s/it, loss=9.2566, batch_acc=0.0000, running_acc=0.0000, grad=36.1837] Training epoch 0:  19%|█▉        | 6/31 [00:36<01:17,  3.08s/it, loss=9.2566, batch_acc=0.0000, running_acc=0.0000, grad=36.1837]Training epoch 0:  19%|█▉        | 6/31 [00:36<01:17,  3.08s/it, loss=9.9510, batch_acc=0.0000, running_acc=0.0000, grad=22.2725]Training epoch 0:  23%|██▎       | 7/31 [00:38<01:01,  2.57s/it, loss=9.9510, batch_acc=0.0000, running_acc=0.0000, grad=22.2725]Training epoch 0:  23%|██▎       | 7/31 [00:38<01:01,  2.57s/it, loss=9.6648, batch_acc=0.0000, running_acc=0.0000, grad=18.1418]Training epoch 0:  26%|██▌       | 8/31 [00:39<00:51,  2.24s/it, loss=9.6648, batch_acc=0.0000, running_acc=0.0000, grad=18.1418]Training epoch 0:  26%|██▌       | 8/31 [00:39<00:51,  2.24s/it, loss=9.8912, batch_acc=0.0000, running_acc=0.0000, grad=25.5825]Training epoch 0:  29%|██▉       | 9/31 [00:41<00:44,  2.01s/it, loss=9.8912, batch_acc=0.0000, running_acc=0.0000, grad=25.5825]Training epoch 0:  29%|██▉       | 9/31 [00:41<00:44,  2.01s/it, loss=9.1914, batch_acc=0.0000, running_acc=0.0000, grad=22.9807]Training epoch 0:  32%|███▏      | 10/31 [00:42<00:38,  1.85s/it, loss=9.1914, batch_acc=0.0000, running_acc=0.0000, grad=22.9807]Training epoch 0:  32%|███▏      | 10/31 [00:42<00:38,  1.85s/it, loss=9.2131, batch_acc=0.0000, running_acc=0.0000, grad=24.8856]Training epoch 0:  35%|███▌      | 11/31 [00:44<00:34,  1.75s/it, loss=9.2131, batch_acc=0.0000, running_acc=0.0000, grad=24.8856]Training epoch 0:  35%|███▌      | 11/31 [00:44<00:34,  1.75s/it, loss=9.8802, batch_acc=0.0000, running_acc=0.0000, grad=24.5417]Training epoch 0:  39%|███▊      | 12/31 [00:45<00:31,  1.68s/it, loss=9.8802, batch_acc=0.0000, running_acc=0.0000, grad=24.5417]Training epoch 0:  39%|███▊      | 12/31 [00:45<00:31,  1.68s/it, loss=9.6098, batch_acc=0.0000, running_acc=0.0000, grad=19.4059]Training epoch 0:  42%|████▏     | 13/31 [00:47<00:29,  1.63s/it, loss=9.6098, batch_acc=0.0000, running_acc=0.0000, grad=19.4059]Training epoch 0:  42%|████▏     | 13/31 [00:47<00:29,  1.63s/it, loss=9.4622, batch_acc=0.0000, running_acc=0.0000, grad=24.1365]Training epoch 0:  45%|████▌     | 14/31 [00:48<00:27,  1.59s/it, loss=9.4622, batch_acc=0.0000, running_acc=0.0000, grad=24.1365]Training epoch 0:  45%|████▌     | 14/31 [00:48<00:27,  1.59s/it, loss=9.2772, batch_acc=0.0000, running_acc=0.0000, grad=29.7140]Training epoch 0:  48%|████▊     | 15/31 [00:50<00:25,  1.57s/it, loss=9.2772, batch_acc=0.0000, running_acc=0.0000, grad=29.7140]Training epoch 0:  48%|████▊     | 15/31 [00:50<00:25,  1.57s/it, loss=9.4842, batch_acc=0.0000, running_acc=0.0000, grad=23.7691]Training epoch 0:  52%|█████▏    | 16/31 [00:51<00:23,  1.55s/it, loss=9.4842, batch_acc=0.0000, running_acc=0.0000, grad=23.7691]Training epoch 0:  52%|█████▏    | 16/31 [00:51<00:23,  1.55s/it, loss=9.2686, batch_acc=0.0000, running_acc=0.0000, grad=34.5261]Training epoch 0:  55%|█████▍    | 17/31 [00:53<00:21,  1.54s/it, loss=9.2686, batch_acc=0.0000, running_acc=0.0000, grad=34.5261]Training epoch 0:  55%|█████▍    | 17/31 [00:53<00:21,  1.54s/it, loss=9.4272, batch_acc=0.0000, running_acc=0.0000, grad=57.9561]Training epoch 0:  58%|█████▊    | 18/31 [00:58<00:35,  2.75s/it, loss=9.4272, batch_acc=0.0000, running_acc=0.0000, grad=57.9561]Training epoch 0:  58%|█████▊    | 18/31 [00:58<00:35,  2.75s/it, loss=9.1899, batch_acc=0.0000, running_acc=0.0000, grad=14.7985]Training epoch 0:  61%|██████▏   | 19/31 [01:00<00:28,  2.38s/it, loss=9.1899, batch_acc=0.0000, running_acc=0.0000, grad=14.7985]Training epoch 0:  61%|██████▏   | 19/31 [01:00<00:28,  2.38s/it, loss=9.9725, batch_acc=0.0000, running_acc=0.0000, grad=23.3705]Training epoch 0:  65%|██████▍   | 20/31 [01:01<00:23,  2.12s/it, loss=9.9725, batch_acc=0.0000, running_acc=0.0000, grad=23.3705]Training epoch 0:  65%|██████▍   | 20/31 [01:01<00:23,  2.12s/it, loss=9.0388, batch_acc=0.0000, running_acc=0.0000, grad=23.6411]Training epoch 0:  68%|██████▊   | 21/31 [01:03<00:19,  1.94s/it, loss=9.0388, batch_acc=0.0000, running_acc=0.0000, grad=23.6411]Training epoch 0:  68%|██████▊   | 21/31 [01:03<00:19,  1.94s/it, loss=8.9772, batch_acc=0.0000, running_acc=0.0000, grad=20.1852]Training epoch 0:  71%|███████   | 22/31 [01:08<00:25,  2.85s/it, loss=8.9772, batch_acc=0.0000, running_acc=0.0000, grad=20.1852]Training epoch 0:  71%|███████   | 22/31 [01:08<00:25,  2.85s/it, loss=9.7285, batch_acc=0.0000, running_acc=0.0000, grad=18.8099]Training epoch 0:  74%|███████▍  | 23/31 [01:10<00:20,  2.53s/it, loss=9.7285, batch_acc=0.0000, running_acc=0.0000, grad=18.8099]Training epoch 0:  74%|███████▍  | 23/31 [01:10<00:20,  2.53s/it, loss=9.2542, batch_acc=0.0000, running_acc=0.0000, grad=32.2990]Training epoch 0:  77%|███████▋  | 24/31 [01:12<00:16,  2.41s/it, loss=9.2542, batch_acc=0.0000, running_acc=0.0000, grad=32.2990]Training epoch 0:  77%|███████▋  | 24/31 [01:12<00:16,  2.41s/it, loss=8.0389, batch_acc=0.0000, running_acc=0.0000, grad=62.5447]Training epoch 0:  81%|████████  | 25/31 [01:13<00:12,  2.14s/it, loss=8.0389, batch_acc=0.0000, running_acc=0.0000, grad=62.5447]Training epoch 0:  81%|████████  | 25/31 [01:13<00:12,  2.14s/it, loss=8.5505, batch_acc=0.0000, running_acc=0.0000, grad=28.6069]Training epoch 0:  84%|████████▍ | 26/31 [01:18<00:14,  2.90s/it, loss=8.5505, batch_acc=0.0000, running_acc=0.0000, grad=28.6069]Training epoch 0:  84%|████████▍ | 26/31 [01:18<00:14,  2.90s/it, loss=8.7820, batch_acc=0.0000, running_acc=0.0000, grad=71.5163]Training epoch 0:  87%|████████▋ | 27/31 [01:26<00:17,  4.44s/it, loss=8.7820, batch_acc=0.0000, running_acc=0.0000, grad=71.5163]Training epoch 0:  87%|████████▋ | 27/31 [01:26<00:17,  4.44s/it, loss=8.7182, batch_acc=0.0000, running_acc=0.0000, grad=19.2803]Training epoch 0:  90%|█████████ | 28/31 [01:27<00:10,  3.56s/it, loss=8.7182, batch_acc=0.0000, running_acc=0.0000, grad=19.2803]Training epoch 0:  90%|█████████ | 28/31 [01:27<00:10,  3.56s/it, loss=8.3879, batch_acc=0.0000, running_acc=0.0000, grad=14.2666]Training epoch 0:  94%|█████████▎| 29/31 [01:29<00:05,  2.94s/it, loss=8.3879, batch_acc=0.0000, running_acc=0.0000, grad=14.2666]Training epoch 0:  94%|█████████▎| 29/31 [01:29<00:05,  2.94s/it, loss=8.4712, batch_acc=0.0000, running_acc=0.0000, grad=31.3496]Training epoch 0:  97%|█████████▋| 30/31 [01:30<00:02,  2.51s/it, loss=8.4712, batch_acc=0.0000, running_acc=0.0000, grad=31.3496]Training epoch 0:  97%|█████████▋| 30/31 [01:30<00:02,  2.51s/it, loss=7.8577, batch_acc=0.0000, running_acc=0.0000, grad=24.1298]Training epoch 0: 100%|██████████| 31/31 [01:33<00:00,  2.61s/it, loss=7.8577, batch_acc=0.0000, running_acc=0.0000, grad=24.1298]Training epoch 0: 100%|██████████| 31/31 [01:33<00:00,  2.61s/it, loss=8.6440, batch_acc=0.0000, running_acc=0.0000, grad=40.4576]Training epoch 0: 100%|██████████| 31/31 [01:33<00:00,  3.03s/it, loss=8.6440, batch_acc=0.0000, running_acc=0.0000, grad=40.4576]
Evaluation epoch 0:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 0:  20%|██        | 1/5 [00:11<00:46, 11.51s/it]Evaluation epoch 0:  20%|██        | 1/5 [00:11<00:46, 11.51s/it, loss=7.8356, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0:  40%|████      | 2/5 [00:12<00:15,  5.18s/it, loss=7.8356, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0:  40%|████      | 2/5 [00:12<00:15,  5.18s/it, loss=8.1793, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0:  60%|██████    | 3/5 [00:13<00:06,  3.16s/it, loss=8.1793, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0:  60%|██████    | 3/5 [00:13<00:06,  3.16s/it, loss=7.7991, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0:  80%|████████  | 4/5 [00:20<00:04,  4.79s/it, loss=7.7991, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0:  80%|████████  | 4/5 [00:20<00:04,  4.79s/it, loss=7.7815, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0: 100%|██████████| 5/5 [00:21<00:00,  3.35s/it, loss=7.7815, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0: 100%|██████████| 5/5 [00:21<00:00,  3.35s/it, loss=8.5817, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 0: 100%|██████████| 5/5 [00:21<00:00,  4.22s/it, loss=8.5817, batch_acc=0.0000, running_acc=0.0000]
Training epoch 1:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 1:   3%|▎         | 1/31 [00:08<04:00,  8.01s/it]Training epoch 1:   3%|▎         | 1/31 [00:08<04:00,  8.01s/it, loss=7.2025, batch_acc=0.0000, running_acc=0.0000, grad=36.6471]Training epoch 1:   6%|▋         | 2/31 [00:10<02:15,  4.68s/it, loss=7.2025, batch_acc=0.0000, running_acc=0.0000, grad=36.6471]Training epoch 1:   6%|▋         | 2/31 [00:10<02:15,  4.68s/it, loss=7.6201, batch_acc=0.0000, running_acc=0.0000, grad=23.3128]Training epoch 1:  10%|▉         | 3/31 [00:11<01:30,  3.23s/it, loss=7.6201, batch_acc=0.0000, running_acc=0.0000, grad=23.3128]Training epoch 1:  10%|▉         | 3/31 [00:11<01:30,  3.23s/it, loss=7.6935, batch_acc=0.0000, running_acc=0.0000, grad=19.5060]Training epoch 1:  13%|█▎        | 4/31 [00:13<01:09,  2.58s/it, loss=7.6935, batch_acc=0.0000, running_acc=0.0000, grad=19.5060]Training epoch 1:  13%|█▎        | 4/31 [00:13<01:09,  2.58s/it, loss=7.8330, batch_acc=0.0000, running_acc=0.0000, grad=61.8467]Training epoch 1:  16%|█▌        | 5/31 [00:14<00:57,  2.20s/it, loss=7.8330, batch_acc=0.0000, running_acc=0.0000, grad=61.8467]Training epoch 1:  16%|█▌        | 5/31 [00:14<00:57,  2.20s/it, loss=7.9919, batch_acc=0.0000, running_acc=0.0000, grad=17.6724]Training epoch 1:  19%|█▉        | 6/31 [00:17<00:56,  2.26s/it, loss=7.9919, batch_acc=0.0000, running_acc=0.0000, grad=17.6724]Training epoch 1:  19%|█▉        | 6/31 [00:17<00:56,  2.26s/it, loss=7.8476, batch_acc=0.0000, running_acc=0.0000, grad=50.7094]Training epoch 1:  23%|██▎       | 7/31 [00:18<00:48,  2.01s/it, loss=7.8476, batch_acc=0.0000, running_acc=0.0000, grad=50.7094]Training epoch 1:  23%|██▎       | 7/31 [00:18<00:48,  2.01s/it, loss=7.1649, batch_acc=0.0000, running_acc=0.0000, grad=23.5944]Training epoch 1:  26%|██▌       | 8/31 [00:20<00:42,  1.85s/it, loss=7.1649, batch_acc=0.0000, running_acc=0.0000, grad=23.5944]Training epoch 1:  26%|██▌       | 8/31 [00:20<00:42,  1.85s/it, loss=7.3163, batch_acc=0.0000, running_acc=0.0000, grad=15.8979]Training epoch 1:  29%|██▉       | 9/31 [00:21<00:38,  1.75s/it, loss=7.3163, batch_acc=0.0000, running_acc=0.0000, grad=15.8979]Training epoch 1:  29%|██▉       | 9/31 [00:21<00:38,  1.75s/it, loss=7.7856, batch_acc=0.0000, running_acc=0.0000, grad=24.0221]Training epoch 1:  32%|███▏      | 10/31 [00:26<00:54,  2.58s/it, loss=7.7856, batch_acc=0.0000, running_acc=0.0000, grad=24.0221]Training epoch 1:  32%|███▏      | 10/31 [00:26<00:54,  2.58s/it, loss=7.8571, batch_acc=0.0000, running_acc=0.0000, grad=15.2348]Training epoch 1:  35%|███▌      | 11/31 [00:27<00:45,  2.25s/it, loss=7.8571, batch_acc=0.0000, running_acc=0.0000, grad=15.2348]Training epoch 1:  35%|███▌      | 11/31 [00:27<00:45,  2.25s/it, loss=7.3076, batch_acc=0.0000, running_acc=0.0000, grad=16.4601]Training epoch 1:  39%|███▊      | 12/31 [00:29<00:39,  2.07s/it, loss=7.3076, batch_acc=0.0000, running_acc=0.0000, grad=16.4601]Training epoch 1:  39%|███▊      | 12/31 [00:29<00:39,  2.07s/it, loss=7.3006, batch_acc=0.0000, running_acc=0.0000, grad=31.6457]Training epoch 1:  42%|████▏     | 13/31 [00:30<00:34,  1.90s/it, loss=7.3006, batch_acc=0.0000, running_acc=0.0000, grad=31.6457]Training epoch 1:  42%|████▏     | 13/31 [00:30<00:34,  1.90s/it, loss=6.7885, batch_acc=0.0000, running_acc=0.0000, grad=21.8139]Training epoch 1:  45%|████▌     | 14/31 [00:34<00:42,  2.51s/it, loss=6.7885, batch_acc=0.0000, running_acc=0.0000, grad=21.8139]Training epoch 1:  45%|████▌     | 14/31 [00:34<00:42,  2.51s/it, loss=6.8209, batch_acc=0.0000, running_acc=0.0000, grad=17.4957]Training epoch 1:  48%|████▊     | 15/31 [00:36<00:35,  2.21s/it, loss=6.8209, batch_acc=0.0000, running_acc=0.0000, grad=17.4957]Training epoch 1:  48%|████▊     | 15/31 [00:36<00:35,  2.21s/it, loss=6.4976, batch_acc=0.0000, running_acc=0.0000, grad=23.1567]Training epoch 1:  52%|█████▏    | 16/31 [00:37<00:29,  2.00s/it, loss=6.4976, batch_acc=0.0000, running_acc=0.0000, grad=23.1567]Training epoch 1:  52%|█████▏    | 16/31 [00:37<00:29,  2.00s/it, loss=7.1703, batch_acc=0.0000, running_acc=0.0000, grad=21.4859]Training epoch 1:  55%|█████▍    | 17/31 [00:39<00:25,  1.85s/it, loss=7.1703, batch_acc=0.0000, running_acc=0.0000, grad=21.4859]Training epoch 1:  55%|█████▍    | 17/31 [00:39<00:25,  1.85s/it, loss=6.4901, batch_acc=0.0000, running_acc=0.0000, grad=36.1167]Training epoch 1:  58%|█████▊    | 18/31 [00:49<00:57,  4.39s/it, loss=6.4901, batch_acc=0.0000, running_acc=0.0000, grad=36.1167]Training epoch 1:  58%|█████▊    | 18/31 [00:49<00:57,  4.39s/it, loss=6.6198, batch_acc=0.0000, running_acc=0.0000, grad=21.6739]Training epoch 1:  61%|██████▏   | 19/31 [00:51<00:42,  3.53s/it, loss=6.6198, batch_acc=0.0000, running_acc=0.0000, grad=21.6739]Training epoch 1:  61%|██████▏   | 19/31 [00:51<00:42,  3.53s/it, loss=6.8774, batch_acc=0.0000, running_acc=0.0000, grad=15.6999]Training epoch 1:  65%|██████▍   | 20/31 [00:52<00:32,  2.92s/it, loss=6.8774, batch_acc=0.0000, running_acc=0.0000, grad=15.6999]Training epoch 1:  65%|██████▍   | 20/31 [00:52<00:32,  2.92s/it, loss=6.2187, batch_acc=0.0000, running_acc=0.0000, grad=19.2276]Training epoch 1:  68%|██████▊   | 21/31 [00:54<00:24,  2.50s/it, loss=6.2187, batch_acc=0.0000, running_acc=0.0000, grad=19.2276]Training epoch 1:  68%|██████▊   | 21/31 [00:54<00:24,  2.50s/it, loss=5.9259, batch_acc=0.0000, running_acc=0.0000, grad=15.2145]Training epoch 1:  71%|███████   | 22/31 [01:03<00:41,  4.57s/it, loss=5.9259, batch_acc=0.0000, running_acc=0.0000, grad=15.2145]Training epoch 1:  71%|███████   | 22/31 [01:03<00:41,  4.57s/it, loss=5.9204, batch_acc=0.0000, running_acc=0.0000, grad=16.0495]Training epoch 1:  74%|███████▍  | 23/31 [01:05<00:29,  3.65s/it, loss=5.9204, batch_acc=0.0000, running_acc=0.0000, grad=16.0495]Training epoch 1:  74%|███████▍  | 23/31 [01:05<00:29,  3.65s/it, loss=6.6475, batch_acc=0.0000, running_acc=0.0000, grad=29.4487]Training epoch 1:  77%|███████▋  | 24/31 [01:06<00:21,  3.01s/it, loss=6.6475, batch_acc=0.0000, running_acc=0.0000, grad=29.4487]Training epoch 1:  77%|███████▋  | 24/31 [01:06<00:21,  3.01s/it, loss=5.8825, batch_acc=0.0000, running_acc=0.0000, grad=24.1684]Training epoch 1:  81%|████████  | 25/31 [01:08<00:15,  2.56s/it, loss=5.8825, batch_acc=0.0000, running_acc=0.0000, grad=24.1684]Training epoch 1:  81%|████████  | 25/31 [01:08<00:15,  2.56s/it, loss=5.9181, batch_acc=0.0000, running_acc=0.0000, grad=15.1411]Training epoch 1:  84%|████████▍ | 26/31 [01:11<00:14,  2.91s/it, loss=5.9181, batch_acc=0.0000, running_acc=0.0000, grad=15.1411]Training epoch 1:  84%|████████▍ | 26/31 [01:11<00:14,  2.91s/it, loss=6.1942, batch_acc=0.0000, running_acc=0.0000, grad=28.2968]Training epoch 1:  87%|████████▋ | 27/31 [01:13<00:09,  2.49s/it, loss=6.1942, batch_acc=0.0000, running_acc=0.0000, grad=28.2968]Training epoch 1:  87%|████████▋ | 27/31 [01:13<00:09,  2.49s/it, loss=5.6889, batch_acc=0.0000, running_acc=0.0000, grad=146.0070]Training epoch 1:  90%|█████████ | 28/31 [01:14<00:06,  2.19s/it, loss=5.6889, batch_acc=0.0000, running_acc=0.0000, grad=146.0070]Training epoch 1:  90%|█████████ | 28/31 [01:14<00:06,  2.19s/it, loss=5.9077, batch_acc=0.0000, running_acc=0.0000, grad=18.6855] Training epoch 1:  94%|█████████▎| 29/31 [01:16<00:03,  1.99s/it, loss=5.9077, batch_acc=0.0000, running_acc=0.0000, grad=18.6855]Training epoch 1:  94%|█████████▎| 29/31 [01:16<00:03,  1.99s/it, loss=5.1765, batch_acc=0.0000, running_acc=0.0000, grad=22.1234]Training epoch 1:  97%|█████████▋| 30/31 [01:17<00:01,  1.84s/it, loss=5.1765, batch_acc=0.0000, running_acc=0.0000, grad=22.1234]Training epoch 1:  97%|█████████▋| 30/31 [01:17<00:01,  1.84s/it, loss=5.5281, batch_acc=0.0000, running_acc=0.0000, grad=13.0960]Training epoch 1: 100%|██████████| 31/31 [01:18<00:00,  1.35s/it, loss=5.5281, batch_acc=0.0000, running_acc=0.0000, grad=13.0960]Training epoch 1: 100%|██████████| 31/31 [01:18<00:00,  1.35s/it, loss=6.1256, batch_acc=0.0000, running_acc=0.0000, grad=124.4988]Training epoch 1: 100%|██████████| 31/31 [01:18<00:00,  2.52s/it, loss=6.1256, batch_acc=0.0000, running_acc=0.0000, grad=124.4988]
Evaluation epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 1:  20%|██        | 1/5 [00:13<00:54, 13.50s/it]Evaluation epoch 1:  20%|██        | 1/5 [00:13<00:54, 13.50s/it, loss=4.5871, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1:  40%|████      | 2/5 [00:14<00:17,  6.00s/it, loss=4.5871, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1:  40%|████      | 2/5 [00:14<00:17,  6.00s/it, loss=5.4720, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1:  60%|██████    | 3/5 [00:14<00:07,  3.60s/it, loss=5.4720, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1:  60%|██████    | 3/5 [00:14<00:07,  3.60s/it, loss=5.0074, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1:  80%|████████  | 4/5 [00:20<00:04,  4.41s/it, loss=5.0074, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1:  80%|████████  | 4/5 [00:20<00:04,  4.41s/it, loss=5.2078, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1: 100%|██████████| 5/5 [00:21<00:00,  3.10s/it, loss=5.2078, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1: 100%|██████████| 5/5 [00:21<00:00,  3.10s/it, loss=5.8473, batch_acc=0.0000, running_acc=0.0000]Evaluation epoch 1: 100%|██████████| 5/5 [00:21<00:00,  4.29s/it, loss=5.8473, batch_acc=0.0000, running_acc=0.0000]
Training epoch 2:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 2:   3%|▎         | 1/31 [00:06<03:01,  6.06s/it]Training epoch 2:   3%|▎         | 1/31 [00:06<03:01,  6.06s/it, loss=5.5955, batch_acc=0.0000, running_acc=0.0000, grad=11.9479]Training epoch 2:   6%|▋         | 2/31 [00:07<01:38,  3.39s/it, loss=5.5955, batch_acc=0.0000, running_acc=0.0000, grad=11.9479]Training epoch 2:   6%|▋         | 2/31 [00:07<01:38,  3.39s/it, loss=4.9939, batch_acc=0.0000, running_acc=0.0000, grad=13.8350]Training epoch 2:  10%|▉         | 3/31 [00:09<01:10,  2.53s/it, loss=4.9939, batch_acc=0.0000, running_acc=0.0000, grad=13.8350]Training epoch 2:  10%|▉         | 3/31 [00:09<01:10,  2.53s/it, loss=4.6953, batch_acc=0.0000, running_acc=0.0000, grad=16.2690]Training epoch 2:  13%|█▎        | 4/31 [00:11<01:11,  2.64s/it, loss=4.6953, batch_acc=0.0000, running_acc=0.0000, grad=16.2690]Training epoch 2:  13%|█▎        | 4/31 [00:11<01:11,  2.64s/it, loss=4.8005, batch_acc=0.0000, running_acc=0.0000, grad=28.1530]Training epoch 2:  16%|█▌        | 5/31 [00:14<01:04,  2.49s/it, loss=4.8005, batch_acc=0.0000, running_acc=0.0000, grad=28.1530]Training epoch 2:  16%|█▌        | 5/31 [00:14<01:04,  2.49s/it, loss=4.4073, batch_acc=0.0000, running_acc=0.0000, grad=33.2373]Training epoch 2:  19%|█▉        | 6/31 [00:15<00:53,  2.16s/it, loss=4.4073, batch_acc=0.0000, running_acc=0.0000, grad=33.2373]Training epoch 2:  19%|█▉        | 6/31 [00:15<00:53,  2.16s/it, loss=4.8064, batch_acc=0.0000, running_acc=0.0000, grad=12.9911]Training epoch 2:  23%|██▎       | 7/31 [00:17<00:46,  1.95s/it, loss=4.8064, batch_acc=0.0000, running_acc=0.0000, grad=12.9911]Training epoch 2:  23%|██▎       | 7/31 [00:17<00:46,  1.95s/it, loss=4.7125, batch_acc=0.0000, running_acc=0.0000, grad=14.8595]Training epoch 2:  26%|██▌       | 8/31 [00:18<00:41,  1.81s/it, loss=4.7125, batch_acc=0.0000, running_acc=0.0000, grad=14.8595]Training epoch 2:  26%|██▌       | 8/31 [00:18<00:41,  1.81s/it, loss=4.9524, batch_acc=0.0000, running_acc=0.0000, grad=20.4033]Training epoch 2:  29%|██▉       | 9/31 [00:20<00:42,  1.93s/it, loss=4.9524, batch_acc=0.0000, running_acc=0.0000, grad=20.4033]Training epoch 2:  29%|██▉       | 9/31 [00:20<00:42,  1.93s/it, loss=4.4357, batch_acc=0.0000, running_acc=0.0000, grad=26.3418]Training epoch 2:  32%|███▏      | 10/31 [00:22<00:37,  1.80s/it, loss=4.4357, batch_acc=0.0000, running_acc=0.0000, grad=26.3418]Training epoch 2:  32%|███▏      | 10/31 [00:22<00:37,  1.80s/it, loss=4.4305, batch_acc=0.0000, running_acc=0.0000, grad=80.7225]Training epoch 2:  35%|███▌      | 11/31 [00:23<00:34,  1.71s/it, loss=4.4305, batch_acc=0.0000, running_acc=0.0000, grad=80.7225]Training epoch 2:  35%|███▌      | 11/31 [00:23<00:34,  1.71s/it, loss=4.7005, batch_acc=0.0000, running_acc=0.0000, grad=125.6811]Training epoch 2:  39%|███▊      | 12/31 [00:25<00:31,  1.65s/it, loss=4.7005, batch_acc=0.0000, running_acc=0.0000, grad=125.6811]Training epoch 2:  39%|███▊      | 12/31 [00:25<00:31,  1.65s/it, loss=4.8615, batch_acc=0.0000, running_acc=0.0000, grad=19.0519] Training epoch 2:  42%|████▏     | 13/31 [00:26<00:29,  1.61s/it, loss=4.8615, batch_acc=0.0000, running_acc=0.0000, grad=19.0519]Training epoch 2:  42%|████▏     | 13/31 [00:26<00:29,  1.61s/it, loss=4.3734, batch_acc=0.0312, running_acc=0.0024, grad=13.9099]Training epoch 2:  45%|████▌     | 14/31 [00:28<00:26,  1.58s/it, loss=4.3734, batch_acc=0.0312, running_acc=0.0024, grad=13.9099]Training epoch 2:  45%|████▌     | 14/31 [00:28<00:26,  1.58s/it, loss=4.1364, batch_acc=0.0000, running_acc=0.0022, grad=24.8009]Training epoch 2:  48%|████▊     | 15/31 [00:29<00:24,  1.56s/it, loss=4.1364, batch_acc=0.0000, running_acc=0.0022, grad=24.8009]Training epoch 2:  48%|████▊     | 15/31 [00:29<00:24,  1.56s/it, loss=4.1313, batch_acc=0.0000, running_acc=0.0021, grad=15.5939]Training epoch 2:  52%|█████▏    | 16/31 [00:31<00:23,  1.55s/it, loss=4.1313, batch_acc=0.0000, running_acc=0.0021, grad=15.5939]Training epoch 2:  52%|█████▏    | 16/31 [00:31<00:23,  1.55s/it, loss=3.9294, batch_acc=0.0312, running_acc=0.0039, grad=13.8883]Training epoch 2:  55%|█████▍    | 17/31 [00:32<00:21,  1.54s/it, loss=3.9294, batch_acc=0.0312, running_acc=0.0039, grad=13.8883]Training epoch 2:  55%|█████▍    | 17/31 [00:32<00:21,  1.54s/it, loss=4.0348, batch_acc=0.0312, running_acc=0.0055, grad=34.8028]Training epoch 2:  58%|█████▊    | 18/31 [00:34<00:19,  1.53s/it, loss=4.0348, batch_acc=0.0312, running_acc=0.0055, grad=34.8028]Training epoch 2:  58%|█████▊    | 18/31 [00:34<00:19,  1.53s/it, loss=3.9292, batch_acc=0.0625, running_acc=0.0087, grad=18.6621]Training epoch 2:  61%|██████▏   | 19/31 [00:37<00:23,  1.99s/it, loss=3.9292, batch_acc=0.0625, running_acc=0.0087, grad=18.6621]Training epoch 2:  61%|██████▏   | 19/31 [00:37<00:23,  1.99s/it, loss=3.8294, batch_acc=0.0000, running_acc=0.0082, grad=18.4888]Training epoch 2:  65%|██████▍   | 20/31 [00:40<00:23,  2.17s/it, loss=3.8294, batch_acc=0.0000, running_acc=0.0082, grad=18.4888]Training epoch 2:  65%|██████▍   | 20/31 [00:40<00:23,  2.17s/it, loss=3.9353, batch_acc=0.0000, running_acc=0.0078, grad=13.1827]Training epoch 2:  68%|██████▊   | 21/31 [00:44<00:28,  2.85s/it, loss=3.9353, batch_acc=0.0000, running_acc=0.0078, grad=13.1827]Training epoch 2:  68%|██████▊   | 21/31 [00:44<00:28,  2.85s/it, loss=3.5434, batch_acc=0.0000, running_acc=0.0074, grad=21.0195]Training epoch 2:  71%|███████   | 22/31 [00:46<00:22,  2.45s/it, loss=3.5434, batch_acc=0.0000, running_acc=0.0074, grad=21.0195]Training epoch 2:  71%|███████   | 22/31 [00:46<00:22,  2.45s/it, loss=3.7444, batch_acc=0.0000, running_acc=0.0071, grad=16.2233]Training epoch 2:  74%|███████▍  | 23/31 [00:47<00:17,  2.17s/it, loss=3.7444, batch_acc=0.0000, running_acc=0.0071, grad=16.2233]Training epoch 2:  74%|███████▍  | 23/31 [00:47<00:17,  2.17s/it, loss=3.5023, batch_acc=0.0625, running_acc=0.0095, grad=12.0851]Training epoch 2:  77%|███████▋  | 24/31 [00:55<00:28,  4.01s/it, loss=3.5023, batch_acc=0.0625, running_acc=0.0095, grad=12.0851]Training epoch 2:  77%|███████▋  | 24/31 [00:55<00:28,  4.01s/it, loss=3.4759, batch_acc=0.0625, running_acc=0.0117, grad=20.1395]Training epoch 2:  81%|████████  | 25/31 [00:57<00:19,  3.26s/it, loss=3.4759, batch_acc=0.0625, running_acc=0.0117, grad=20.1395]Training epoch 2:  81%|████████  | 25/31 [00:57<00:19,  3.26s/it, loss=3.7073, batch_acc=0.0938, running_acc=0.0150, grad=19.8185]Training epoch 2:  84%|████████▍ | 26/31 [00:58<00:13,  2.73s/it, loss=3.7073, batch_acc=0.0938, running_acc=0.0150, grad=19.8185]Training epoch 2:  84%|████████▍ | 26/31 [00:58<00:13,  2.73s/it, loss=3.5144, batch_acc=0.1562, running_acc=0.0204, grad=16.5504]Training epoch 2:  87%|████████▋ | 27/31 [01:00<00:09,  2.37s/it, loss=3.5144, batch_acc=0.1562, running_acc=0.0204, grad=16.5504]Training epoch 2:  87%|████████▋ | 27/31 [01:00<00:09,  2.37s/it, loss=3.6024, batch_acc=0.0312, running_acc=0.0208, grad=56.7977]Training epoch 2:  90%|█████████ | 28/31 [01:01<00:06,  2.11s/it, loss=3.6024, batch_acc=0.0312, running_acc=0.0208, grad=56.7977]Training epoch 2:  90%|█████████ | 28/31 [01:01<00:06,  2.11s/it, loss=3.6031, batch_acc=0.0938, running_acc=0.0234, grad=14.4272]Training epoch 2:  94%|█████████▎| 29/31 [01:03<00:03,  1.93s/it, loss=3.6031, batch_acc=0.0938, running_acc=0.0234, grad=14.4272]Training epoch 2:  94%|█████████▎| 29/31 [01:03<00:03,  1.93s/it, loss=3.3827, batch_acc=0.0625, running_acc=0.0248, grad=22.5860]Training epoch 2:  97%|█████████▋| 30/31 [01:04<00:01,  1.80s/it, loss=3.3827, batch_acc=0.0625, running_acc=0.0248, grad=22.5860]Training epoch 2:  97%|█████████▋| 30/31 [01:04<00:01,  1.80s/it, loss=3.3401, batch_acc=0.1250, running_acc=0.0281, grad=15.6070]Training epoch 2: 100%|██████████| 31/31 [01:05<00:00,  1.32s/it, loss=3.3401, batch_acc=0.1250, running_acc=0.0281, grad=15.6070]Training epoch 2: 100%|██████████| 31/31 [01:05<00:00,  1.32s/it, loss=2.9504, batch_acc=0.0000, running_acc=0.0281, grad=25.7292]Training epoch 2: 100%|██████████| 31/31 [01:05<00:00,  2.10s/it, loss=2.9504, batch_acc=0.0000, running_acc=0.0281, grad=25.7292]
Evaluation epoch 2:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 2:  20%|██        | 1/5 [00:04<00:19,  4.77s/it]Evaluation epoch 2:  20%|██        | 1/5 [00:04<00:19,  4.77s/it, loss=2.6656, batch_acc=0.4062, running_acc=0.4062]Evaluation epoch 2:  40%|████      | 2/5 [00:05<00:07,  2.40s/it, loss=2.6656, batch_acc=0.4062, running_acc=0.4062]Evaluation epoch 2:  40%|████      | 2/5 [00:05<00:07,  2.40s/it, loss=3.1496, batch_acc=0.0938, running_acc=0.2500]Evaluation epoch 2:  60%|██████    | 3/5 [00:06<00:03,  1.64s/it, loss=3.1496, batch_acc=0.0938, running_acc=0.2500]Evaluation epoch 2:  60%|██████    | 3/5 [00:06<00:03,  1.64s/it, loss=3.4812, batch_acc=0.0625, running_acc=0.1875]Evaluation epoch 2:  80%|████████  | 4/5 [00:07<00:01,  1.51s/it, loss=3.4812, batch_acc=0.0625, running_acc=0.1875]Evaluation epoch 2:  80%|████████  | 4/5 [00:07<00:01,  1.51s/it, loss=3.4952, batch_acc=0.0000, running_acc=0.1406]Evaluation epoch 2: 100%|██████████| 5/5 [00:08<00:00,  1.25s/it, loss=3.4952, batch_acc=0.0000, running_acc=0.1406]Evaluation epoch 2: 100%|██████████| 5/5 [00:08<00:00,  1.25s/it, loss=3.8696, batch_acc=0.0000, running_acc=0.1125]Evaluation epoch 2: 100%|██████████| 5/5 [00:08<00:00,  1.67s/it, loss=3.8696, batch_acc=0.0000, running_acc=0.1125]
Training epoch 3:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 3:   3%|▎         | 1/31 [00:08<04:26,  8.89s/it]Training epoch 3:   3%|▎         | 1/31 [00:08<04:26,  8.89s/it, loss=3.4918, batch_acc=0.0312, running_acc=0.0312, grad=10.5975]Training epoch 3:   6%|▋         | 2/31 [00:10<02:11,  4.55s/it, loss=3.4918, batch_acc=0.0312, running_acc=0.0312, grad=10.5975]Training epoch 3:   6%|▋         | 2/31 [00:10<02:11,  4.55s/it, loss=3.2244, batch_acc=0.0625, running_acc=0.0469, grad=20.0138]Training epoch 3:  10%|▉         | 3/31 [00:11<01:28,  3.16s/it, loss=3.2244, batch_acc=0.0625, running_acc=0.0469, grad=20.0138]Training epoch 3:  10%|▉         | 3/31 [00:11<01:28,  3.16s/it, loss=3.4158, batch_acc=0.0625, running_acc=0.0521, grad=11.8976]Training epoch 3:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=3.4158, batch_acc=0.0625, running_acc=0.0521, grad=11.8976]Training epoch 3:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=3.0495, batch_acc=0.0938, running_acc=0.0625, grad=15.3228]Training epoch 3:  16%|█▌        | 5/31 [00:14<00:55,  2.15s/it, loss=3.0495, batch_acc=0.0938, running_acc=0.0625, grad=15.3228]Training epoch 3:  16%|█▌        | 5/31 [00:14<00:55,  2.15s/it, loss=3.1508, batch_acc=0.1250, running_acc=0.0750, grad=26.5455]Training epoch 3:  19%|█▉        | 6/31 [00:16<00:48,  1.93s/it, loss=3.1508, batch_acc=0.1250, running_acc=0.0750, grad=26.5455]Training epoch 3:  19%|█▉        | 6/31 [00:16<00:48,  1.93s/it, loss=3.0596, batch_acc=0.2500, running_acc=0.1042, grad=883.7668]Training epoch 3:  23%|██▎       | 7/31 [00:17<00:43,  1.80s/it, loss=3.0596, batch_acc=0.2500, running_acc=0.1042, grad=883.7668]Training epoch 3:  23%|██▎       | 7/31 [00:17<00:43,  1.80s/it, loss=3.2668, batch_acc=0.1250, running_acc=0.1071, grad=19.6725] Training epoch 3:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=3.2668, batch_acc=0.1250, running_acc=0.1071, grad=19.6725]Training epoch 3:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=3.0037, batch_acc=0.3438, running_acc=0.1367, grad=30.8101]Training epoch 3:  29%|██▉       | 9/31 [00:20<00:36,  1.64s/it, loss=3.0037, batch_acc=0.3438, running_acc=0.1367, grad=30.8101]Training epoch 3:  29%|██▉       | 9/31 [00:20<00:36,  1.64s/it, loss=3.2817, batch_acc=0.2500, running_acc=0.1493, grad=15.0944]Training epoch 3:  32%|███▏      | 10/31 [00:22<00:33,  1.60s/it, loss=3.2817, batch_acc=0.2500, running_acc=0.1493, grad=15.0944]Training epoch 3:  32%|███▏      | 10/31 [00:22<00:33,  1.60s/it, loss=2.8959, batch_acc=0.2812, running_acc=0.1625, grad=31.4683]Training epoch 3:  35%|███▌      | 11/31 [00:26<00:45,  2.27s/it, loss=2.8959, batch_acc=0.2812, running_acc=0.1625, grad=31.4683]Training epoch 3:  35%|███▌      | 11/31 [00:26<00:45,  2.27s/it, loss=3.0400, batch_acc=0.1562, running_acc=0.1619, grad=22.3513]Training epoch 3:  39%|███▊      | 12/31 [00:27<00:38,  2.04s/it, loss=3.0400, batch_acc=0.1562, running_acc=0.1619, grad=22.3513]Training epoch 3:  39%|███▊      | 12/31 [00:27<00:38,  2.04s/it, loss=3.1006, batch_acc=0.1250, running_acc=0.1589, grad=30.9521]Training epoch 3:  42%|████▏     | 13/31 [00:29<00:33,  1.88s/it, loss=3.1006, batch_acc=0.1250, running_acc=0.1589, grad=30.9521]Training epoch 3:  42%|████▏     | 13/31 [00:29<00:33,  1.88s/it, loss=3.0840, batch_acc=0.1250, running_acc=0.1562, grad=13.5913]Training epoch 3:  45%|████▌     | 14/31 [00:30<00:30,  1.77s/it, loss=3.0840, batch_acc=0.1250, running_acc=0.1562, grad=13.5913]Training epoch 3:  45%|████▌     | 14/31 [00:30<00:30,  1.77s/it, loss=2.8398, batch_acc=0.1875, running_acc=0.1585, grad=10.6026]Training epoch 3:  48%|████▊     | 15/31 [00:32<00:27,  1.69s/it, loss=2.8398, batch_acc=0.1875, running_acc=0.1585, grad=10.6026]Training epoch 3:  48%|████▊     | 15/31 [00:32<00:27,  1.69s/it, loss=2.9485, batch_acc=0.0938, running_acc=0.1542, grad=12.6140]Training epoch 3:  52%|█████▏    | 16/31 [00:33<00:24,  1.64s/it, loss=2.9485, batch_acc=0.0938, running_acc=0.1542, grad=12.6140]Training epoch 3:  52%|█████▏    | 16/31 [00:33<00:24,  1.64s/it, loss=2.8776, batch_acc=0.2812, running_acc=0.1621, grad=11.2789]Training epoch 3:  55%|█████▍    | 17/31 [00:35<00:22,  1.60s/it, loss=2.8776, batch_acc=0.2812, running_acc=0.1621, grad=11.2789]Training epoch 3:  55%|█████▍    | 17/31 [00:35<00:22,  1.60s/it, loss=2.8534, batch_acc=0.3125, running_acc=0.1710, grad=13.9540]Training epoch 3:  58%|█████▊    | 18/31 [00:36<00:20,  1.57s/it, loss=2.8534, batch_acc=0.3125, running_acc=0.1710, grad=13.9540]Training epoch 3:  58%|█████▊    | 18/31 [00:36<00:20,  1.57s/it, loss=2.9134, batch_acc=0.3125, running_acc=0.1788, grad=21.4219]Training epoch 3:  61%|██████▏   | 19/31 [00:39<00:21,  1.81s/it, loss=2.9134, batch_acc=0.3125, running_acc=0.1788, grad=21.4219]Training epoch 3:  61%|██████▏   | 19/31 [00:39<00:21,  1.81s/it, loss=2.7921, batch_acc=0.2188, running_acc=0.1809, grad=12.6719]Training epoch 3:  65%|██████▍   | 20/31 [00:40<00:18,  1.72s/it, loss=2.7921, batch_acc=0.2188, running_acc=0.1809, grad=12.6719]Training epoch 3:  65%|██████▍   | 20/31 [00:40<00:18,  1.72s/it, loss=2.8934, batch_acc=0.2812, running_acc=0.1859, grad=13.4266]Training epoch 3:  68%|██████▊   | 21/31 [00:43<00:20,  2.01s/it, loss=2.8934, batch_acc=0.2812, running_acc=0.1859, grad=13.4266]Training epoch 3:  68%|██████▊   | 21/31 [00:43<00:20,  2.01s/it, loss=2.8354, batch_acc=0.1875, running_acc=0.1860, grad=13.0743]Training epoch 3:  71%|███████   | 22/31 [00:45<00:17,  1.98s/it, loss=2.8354, batch_acc=0.1875, running_acc=0.1860, grad=13.0743]Training epoch 3:  71%|███████   | 22/31 [00:45<00:17,  1.98s/it, loss=2.8607, batch_acc=0.2188, running_acc=0.1875, grad=12.2649]Training epoch 3:  74%|███████▍  | 23/31 [00:47<00:17,  2.19s/it, loss=2.8607, batch_acc=0.2188, running_acc=0.1875, grad=12.2649]Training epoch 3:  74%|███████▍  | 23/31 [00:47<00:17,  2.19s/it, loss=2.6998, batch_acc=0.3125, running_acc=0.1929, grad=13.7142]Training epoch 3:  77%|███████▋  | 24/31 [00:49<00:13,  1.98s/it, loss=2.6998, batch_acc=0.3125, running_acc=0.1929, grad=13.7142]Training epoch 3:  77%|███████▋  | 24/31 [00:49<00:13,  1.98s/it, loss=2.6285, batch_acc=0.4062, running_acc=0.2018, grad=13.1412]Training epoch 3:  81%|████████  | 25/31 [00:51<00:11,  1.84s/it, loss=2.6285, batch_acc=0.4062, running_acc=0.2018, grad=13.1412]Training epoch 3:  81%|████████  | 25/31 [00:51<00:11,  1.84s/it, loss=2.7672, batch_acc=0.3438, running_acc=0.2075, grad=23.0972]Training epoch 3:  84%|████████▍ | 26/31 [00:52<00:08,  1.74s/it, loss=2.7672, batch_acc=0.3438, running_acc=0.2075, grad=23.0972]Training epoch 3:  84%|████████▍ | 26/31 [00:52<00:08,  1.74s/it, loss=2.9723, batch_acc=0.2188, running_acc=0.2079, grad=9.9397] Training epoch 3:  87%|████████▋ | 27/31 [00:54<00:06,  1.67s/it, loss=2.9723, batch_acc=0.2188, running_acc=0.2079, grad=9.9397]Training epoch 3:  87%|████████▋ | 27/31 [00:54<00:06,  1.67s/it, loss=2.7336, batch_acc=0.3125, running_acc=0.2118, grad=19.2944]Training epoch 3:  90%|█████████ | 28/31 [00:55<00:04,  1.62s/it, loss=2.7336, batch_acc=0.3125, running_acc=0.2118, grad=19.2944]Training epoch 3:  90%|█████████ | 28/31 [00:55<00:04,  1.62s/it, loss=2.8239, batch_acc=0.2812, running_acc=0.2143, grad=11.6485]Training epoch 3:  94%|█████████▎| 29/31 [00:57<00:03,  1.59s/it, loss=2.8239, batch_acc=0.2812, running_acc=0.2143, grad=11.6485]Training epoch 3:  94%|█████████▎| 29/31 [00:57<00:03,  1.59s/it, loss=2.6832, batch_acc=0.3750, running_acc=0.2198, grad=10.5506]Training epoch 3:  97%|█████████▋| 30/31 [00:58<00:01,  1.56s/it, loss=2.6832, batch_acc=0.3750, running_acc=0.2198, grad=10.5506]Training epoch 3:  97%|█████████▋| 30/31 [00:58<00:01,  1.56s/it, loss=2.7020, batch_acc=0.2500, running_acc=0.2208, grad=11.1715]Training epoch 3: 100%|██████████| 31/31 [00:58<00:00,  1.15s/it, loss=2.7020, batch_acc=0.2500, running_acc=0.2208, grad=11.1715]Training epoch 3: 100%|██████████| 31/31 [00:58<00:00,  1.15s/it, loss=2.9733, batch_acc=0.0000, running_acc=0.2204, grad=25.0679]Training epoch 3: 100%|██████████| 31/31 [00:58<00:00,  1.89s/it, loss=2.9733, batch_acc=0.0000, running_acc=0.2204, grad=25.0679]
Evaluation epoch 3:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 3:  20%|██        | 1/5 [00:04<00:19,  4.96s/it]Evaluation epoch 3:  20%|██        | 1/5 [00:04<00:19,  4.96s/it, loss=2.4699, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 3:  40%|████      | 2/5 [00:05<00:07,  2.48s/it, loss=2.4699, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 3:  40%|████      | 2/5 [00:05<00:07,  2.48s/it, loss=2.3520, batch_acc=0.6250, running_acc=0.5781]Evaluation epoch 3:  60%|██████    | 3/5 [00:06<00:03,  1.68s/it, loss=2.3520, batch_acc=0.6250, running_acc=0.5781]Evaluation epoch 3:  60%|██████    | 3/5 [00:06<00:03,  1.68s/it, loss=2.7912, batch_acc=0.2812, running_acc=0.4792]Evaluation epoch 3:  80%|████████  | 4/5 [00:07<00:01,  1.42s/it, loss=2.7912, batch_acc=0.2812, running_acc=0.4792]Evaluation epoch 3:  80%|████████  | 4/5 [00:07<00:01,  1.42s/it, loss=2.8971, batch_acc=0.0938, running_acc=0.3828]Evaluation epoch 3: 100%|██████████| 5/5 [00:08<00:00,  1.19s/it, loss=2.8971, batch_acc=0.0938, running_acc=0.3828]Evaluation epoch 3: 100%|██████████| 5/5 [00:08<00:00,  1.19s/it, loss=2.8800, batch_acc=0.2500, running_acc=0.3563]Evaluation epoch 3: 100%|██████████| 5/5 [00:08<00:00,  1.65s/it, loss=2.8800, batch_acc=0.2500, running_acc=0.3563]
Training epoch 4:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 4:   3%|▎         | 1/31 [00:07<03:31,  7.05s/it]Training epoch 4:   3%|▎         | 1/31 [00:07<03:31,  7.05s/it, loss=2.6465, batch_acc=0.2500, running_acc=0.2500, grad=9.1357]Training epoch 4:   6%|▋         | 2/31 [00:08<01:49,  3.79s/it, loss=2.6465, batch_acc=0.2500, running_acc=0.2500, grad=9.1357]Training epoch 4:   6%|▋         | 2/31 [00:08<01:49,  3.79s/it, loss=2.6241, batch_acc=0.4375, running_acc=0.3438, grad=22.7057]Training epoch 4:  10%|▉         | 3/31 [00:10<01:16,  2.75s/it, loss=2.6241, batch_acc=0.4375, running_acc=0.3438, grad=22.7057]Training epoch 4:  10%|▉         | 3/31 [00:10<01:16,  2.75s/it, loss=2.5854, batch_acc=0.3750, running_acc=0.3542, grad=12.4524]Training epoch 4:  13%|█▎        | 4/31 [00:11<01:01,  2.26s/it, loss=2.5854, batch_acc=0.3750, running_acc=0.3542, grad=12.4524]Training epoch 4:  13%|█▎        | 4/31 [00:11<01:01,  2.26s/it, loss=2.7294, batch_acc=0.4375, running_acc=0.3750, grad=27.7310]Training epoch 4:  16%|█▌        | 5/31 [00:13<00:51,  1.99s/it, loss=2.7294, batch_acc=0.4375, running_acc=0.3750, grad=27.7310]Training epoch 4:  16%|█▌        | 5/31 [00:13<00:51,  1.99s/it, loss=2.5951, batch_acc=0.2812, running_acc=0.3563, grad=37.4602]Training epoch 4:  19%|█▉        | 6/31 [00:14<00:45,  1.83s/it, loss=2.5951, batch_acc=0.2812, running_acc=0.3563, grad=37.4602]Training epoch 4:  19%|█▉        | 6/31 [00:14<00:45,  1.83s/it, loss=2.4677, batch_acc=0.4688, running_acc=0.3750, grad=26.2885]Training epoch 4:  23%|██▎       | 7/31 [00:16<00:41,  1.72s/it, loss=2.4677, batch_acc=0.4688, running_acc=0.3750, grad=26.2885]Training epoch 4:  23%|██▎       | 7/31 [00:16<00:41,  1.72s/it, loss=2.8799, batch_acc=0.1875, running_acc=0.3482, grad=10.5875]Training epoch 4:  26%|██▌       | 8/31 [00:17<00:38,  1.66s/it, loss=2.8799, batch_acc=0.1875, running_acc=0.3482, grad=10.5875]Training epoch 4:  26%|██▌       | 8/31 [00:17<00:38,  1.66s/it, loss=2.7041, batch_acc=0.2812, running_acc=0.3398, grad=30.7010]Training epoch 4:  29%|██▉       | 9/31 [00:19<00:35,  1.61s/it, loss=2.7041, batch_acc=0.2812, running_acc=0.3398, grad=30.7010]Training epoch 4:  29%|██▉       | 9/31 [00:19<00:35,  1.61s/it, loss=2.7812, batch_acc=0.3125, running_acc=0.3368, grad=31.9332]Training epoch 4:  32%|███▏      | 10/31 [00:20<00:33,  1.58s/it, loss=2.7812, batch_acc=0.3125, running_acc=0.3368, grad=31.9332]Training epoch 4:  32%|███▏      | 10/31 [00:20<00:33,  1.58s/it, loss=2.7820, batch_acc=0.2500, running_acc=0.3281, grad=21.5060]Training epoch 4:  35%|███▌      | 11/31 [00:22<00:31,  1.56s/it, loss=2.7820, batch_acc=0.2500, running_acc=0.3281, grad=21.5060]Training epoch 4:  35%|███▌      | 11/31 [00:22<00:31,  1.56s/it, loss=2.6685, batch_acc=0.2812, running_acc=0.3239, grad=34.8655]Training epoch 4:  39%|███▊      | 12/31 [00:23<00:29,  1.54s/it, loss=2.6685, batch_acc=0.2812, running_acc=0.3239, grad=34.8655]Training epoch 4:  39%|███▊      | 12/31 [00:23<00:29,  1.54s/it, loss=2.6595, batch_acc=0.3125, running_acc=0.3229, grad=15.4684]Training epoch 4:  42%|████▏     | 13/31 [00:25<00:27,  1.53s/it, loss=2.6595, batch_acc=0.3125, running_acc=0.3229, grad=15.4684]Training epoch 4:  42%|████▏     | 13/31 [00:25<00:27,  1.53s/it, loss=2.6200, batch_acc=0.3125, running_acc=0.3221, grad=7.7736] Training epoch 4:  45%|████▌     | 14/31 [00:26<00:25,  1.52s/it, loss=2.6200, batch_acc=0.3125, running_acc=0.3221, grad=7.7736]Training epoch 4:  45%|████▌     | 14/31 [00:26<00:25,  1.52s/it, loss=2.7888, batch_acc=0.2500, running_acc=0.3170, grad=13.9413]Training epoch 4:  48%|████▊     | 15/31 [00:28<00:24,  1.52s/it, loss=2.7888, batch_acc=0.2500, running_acc=0.3170, grad=13.9413]Training epoch 4:  48%|████▊     | 15/31 [00:28<00:24,  1.52s/it, loss=2.6471, batch_acc=0.3750, running_acc=0.3208, grad=14.9252]Training epoch 4:  52%|█████▏    | 16/31 [00:29<00:22,  1.51s/it, loss=2.6471, batch_acc=0.3750, running_acc=0.3208, grad=14.9252]Training epoch 4:  52%|█████▏    | 16/31 [00:29<00:22,  1.51s/it, loss=2.7084, batch_acc=0.3438, running_acc=0.3223, grad=11.1073]Training epoch 4:  55%|█████▍    | 17/31 [00:31<00:21,  1.51s/it, loss=2.7084, batch_acc=0.3438, running_acc=0.3223, grad=11.1073]Training epoch 4:  55%|█████▍    | 17/31 [00:31<00:21,  1.51s/it, loss=2.6310, batch_acc=0.4375, running_acc=0.3290, grad=14.1204]Training epoch 4:  58%|█████▊    | 18/31 [00:32<00:19,  1.51s/it, loss=2.6310, batch_acc=0.4375, running_acc=0.3290, grad=14.1204]Training epoch 4:  58%|█████▊    | 18/31 [00:32<00:19,  1.51s/it, loss=2.4627, batch_acc=0.3438, running_acc=0.3299, grad=25.6428]Training epoch 4:  61%|██████▏   | 19/31 [00:34<00:18,  1.51s/it, loss=2.4627, batch_acc=0.3438, running_acc=0.3299, grad=25.6428]Training epoch 4:  61%|██████▏   | 19/31 [00:34<00:18,  1.51s/it, loss=2.5694, batch_acc=0.4062, running_acc=0.3339, grad=25.7923]Training epoch 4:  65%|██████▍   | 20/31 [00:35<00:16,  1.51s/it, loss=2.5694, batch_acc=0.4062, running_acc=0.3339, grad=25.7923]Training epoch 4:  65%|██████▍   | 20/31 [00:35<00:16,  1.51s/it, loss=2.6479, batch_acc=0.3438, running_acc=0.3344, grad=16.5487]Training epoch 4:  68%|██████▊   | 21/31 [00:37<00:15,  1.52s/it, loss=2.6479, batch_acc=0.3438, running_acc=0.3344, grad=16.5487]Training epoch 4:  68%|██████▊   | 21/31 [00:37<00:15,  1.52s/it, loss=2.5879, batch_acc=0.3438, running_acc=0.3348, grad=81.5612]Training epoch 4:  71%|███████   | 22/31 [00:38<00:13,  1.52s/it, loss=2.5879, batch_acc=0.3438, running_acc=0.3348, grad=81.5612]Training epoch 4:  71%|███████   | 22/31 [00:38<00:13,  1.52s/it, loss=2.6008, batch_acc=0.2812, running_acc=0.3324, grad=10.8163]Training epoch 4:  74%|███████▍  | 23/31 [00:40<00:12,  1.51s/it, loss=2.6008, batch_acc=0.2812, running_acc=0.3324, grad=10.8163]Training epoch 4:  74%|███████▍  | 23/31 [00:40<00:12,  1.51s/it, loss=2.7055, batch_acc=0.3125, running_acc=0.3315, grad=7.9214] Training epoch 4:  77%|███████▋  | 24/31 [00:41<00:10,  1.51s/it, loss=2.7055, batch_acc=0.3125, running_acc=0.3315, grad=7.9214]Training epoch 4:  77%|███████▋  | 24/31 [00:41<00:10,  1.51s/it, loss=2.5233, batch_acc=0.4062, running_acc=0.3346, grad=15.6338]Training epoch 4:  81%|████████  | 25/31 [00:43<00:09,  1.51s/it, loss=2.5233, batch_acc=0.4062, running_acc=0.3346, grad=15.6338]Training epoch 4:  81%|████████  | 25/31 [00:43<00:09,  1.51s/it, loss=2.6319, batch_acc=0.2812, running_acc=0.3325, grad=8.5809] Training epoch 4:  84%|████████▍ | 26/31 [00:44<00:07,  1.51s/it, loss=2.6319, batch_acc=0.2812, running_acc=0.3325, grad=8.5809]Training epoch 4:  84%|████████▍ | 26/31 [00:44<00:07,  1.51s/it, loss=2.5630, batch_acc=0.3750, running_acc=0.3341, grad=13.1569]Training epoch 4:  87%|████████▋ | 27/31 [00:46<00:06,  1.51s/it, loss=2.5630, batch_acc=0.3750, running_acc=0.3341, grad=13.1569]Training epoch 4:  87%|████████▋ | 27/31 [00:46<00:06,  1.51s/it, loss=2.7197, batch_acc=0.3125, running_acc=0.3333, grad=16.6145]Training epoch 4:  90%|█████████ | 28/31 [00:47<00:04,  1.51s/it, loss=2.7197, batch_acc=0.3125, running_acc=0.3333, grad=16.6145]Training epoch 4:  90%|█████████ | 28/31 [00:47<00:04,  1.51s/it, loss=2.5414, batch_acc=0.4062, running_acc=0.3359, grad=22.8665]Training epoch 4:  94%|█████████▎| 29/31 [00:49<00:03,  1.50s/it, loss=2.5414, batch_acc=0.4062, running_acc=0.3359, grad=22.8665]Training epoch 4:  94%|█████████▎| 29/31 [00:49<00:03,  1.50s/it, loss=2.4957, batch_acc=0.3125, running_acc=0.3351, grad=11.7018]Training epoch 4:  97%|█████████▋| 30/31 [00:50<00:01,  1.50s/it, loss=2.4957, batch_acc=0.3125, running_acc=0.3351, grad=11.7018]Training epoch 4:  97%|█████████▋| 30/31 [00:50<00:01,  1.50s/it, loss=2.4942, batch_acc=0.2812, running_acc=0.3333, grad=67.5889]Training epoch 4: 100%|██████████| 31/31 [00:50<00:00,  1.11s/it, loss=2.4942, batch_acc=0.2812, running_acc=0.3333, grad=67.5889]Training epoch 4: 100%|██████████| 31/31 [00:50<00:00,  1.11s/it, loss=2.8929, batch_acc=0.0000, running_acc=0.3326, grad=29.8781]Training epoch 4: 100%|██████████| 31/31 [00:50<00:00,  1.65s/it, loss=2.8929, batch_acc=0.0000, running_acc=0.3326, grad=29.8781]
Evaluation epoch 4:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 4:  20%|██        | 1/5 [00:10<00:43, 10.96s/it]Evaluation epoch 4:  20%|██        | 1/5 [00:10<00:43, 10.96s/it, loss=2.4621, batch_acc=0.3125, running_acc=0.3125]Evaluation epoch 4:  40%|████      | 2/5 [00:11<00:14,  4.95s/it, loss=2.4621, batch_acc=0.3125, running_acc=0.3125]Evaluation epoch 4:  40%|████      | 2/5 [00:11<00:14,  4.95s/it, loss=2.2413, batch_acc=0.6562, running_acc=0.4844]Evaluation epoch 4:  60%|██████    | 3/5 [00:18<00:11,  5.82s/it, loss=2.2413, batch_acc=0.6562, running_acc=0.4844]Evaluation epoch 4:  60%|██████    | 3/5 [00:18<00:11,  5.82s/it, loss=2.6109, batch_acc=0.3750, running_acc=0.4479]Evaluation epoch 4:  80%|████████  | 4/5 [00:29<00:08,  8.00s/it, loss=2.6109, batch_acc=0.3750, running_acc=0.4479]Evaluation epoch 4:  80%|████████  | 4/5 [00:29<00:08,  8.00s/it, loss=2.8080, batch_acc=0.2188, running_acc=0.3906]Evaluation epoch 4: 100%|██████████| 5/5 [00:30<00:00,  5.40s/it, loss=2.8080, batch_acc=0.2188, running_acc=0.3906]Evaluation epoch 4: 100%|██████████| 5/5 [00:30<00:00,  5.40s/it, loss=2.7171, batch_acc=0.2500, running_acc=0.3625]Evaluation epoch 4: 100%|██████████| 5/5 [00:30<00:00,  6.14s/it, loss=2.7171, batch_acc=0.2500, running_acc=0.3625]
Training epoch 5:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 5:   3%|▎         | 1/31 [00:10<05:10, 10.36s/it]Training epoch 5:   3%|▎         | 1/31 [00:10<05:10, 10.36s/it, loss=2.7346, batch_acc=0.3750, running_acc=0.3750, grad=21.6066]Training epoch 5:   6%|▋         | 2/31 [00:11<02:29,  5.15s/it, loss=2.7346, batch_acc=0.3750, running_acc=0.3750, grad=21.6066]Training epoch 5:   6%|▋         | 2/31 [00:11<02:29,  5.15s/it, loss=2.5967, batch_acc=0.3125, running_acc=0.3438, grad=39.1409]Training epoch 5:  10%|▉         | 3/31 [00:13<01:37,  3.49s/it, loss=2.5967, batch_acc=0.3125, running_acc=0.3438, grad=39.1409]Training epoch 5:  10%|▉         | 3/31 [00:13<01:37,  3.49s/it, loss=2.5754, batch_acc=0.2812, running_acc=0.3229, grad=14.5655]Training epoch 5:  13%|█▎        | 4/31 [00:15<01:20,  2.97s/it, loss=2.5754, batch_acc=0.2812, running_acc=0.3229, grad=14.5655]Training epoch 5:  13%|█▎        | 4/31 [00:15<01:20,  2.97s/it, loss=2.5329, batch_acc=0.3750, running_acc=0.3359, grad=9.1405] Training epoch 5:  16%|█▌        | 5/31 [00:17<01:03,  2.44s/it, loss=2.5329, batch_acc=0.3750, running_acc=0.3359, grad=9.1405]Training epoch 5:  16%|█▌        | 5/31 [00:17<01:03,  2.44s/it, loss=2.6468, batch_acc=0.2188, running_acc=0.3125, grad=22.0153]Training epoch 5:  19%|█▉        | 6/31 [00:18<00:53,  2.13s/it, loss=2.6468, batch_acc=0.2188, running_acc=0.3125, grad=22.0153]Training epoch 5:  19%|█▉        | 6/31 [00:18<00:53,  2.13s/it, loss=2.5586, batch_acc=0.2812, running_acc=0.3073, grad=14.6343]Training epoch 5:  23%|██▎       | 7/31 [00:20<00:46,  1.93s/it, loss=2.5586, batch_acc=0.2812, running_acc=0.3073, grad=14.6343]Training epoch 5:  23%|██▎       | 7/31 [00:20<00:46,  1.93s/it, loss=2.5550, batch_acc=0.3125, running_acc=0.3080, grad=10.0548]Training epoch 5:  26%|██▌       | 8/31 [00:21<00:41,  1.80s/it, loss=2.5550, batch_acc=0.3125, running_acc=0.3080, grad=10.0548]Training epoch 5:  26%|██▌       | 8/31 [00:21<00:41,  1.80s/it, loss=2.6435, batch_acc=0.2500, running_acc=0.3008, grad=30.6054]Training epoch 5:  29%|██▉       | 9/31 [00:23<00:37,  1.71s/it, loss=2.6435, batch_acc=0.2500, running_acc=0.3008, grad=30.6054]Training epoch 5:  29%|██▉       | 9/31 [00:23<00:37,  1.71s/it, loss=2.6237, batch_acc=0.3750, running_acc=0.3090, grad=10.0171]Training epoch 5:  32%|███▏      | 10/31 [00:24<00:34,  1.64s/it, loss=2.6237, batch_acc=0.3750, running_acc=0.3090, grad=10.0171]Training epoch 5:  32%|███▏      | 10/31 [00:24<00:34,  1.64s/it, loss=2.4057, batch_acc=0.3750, running_acc=0.3156, grad=13.6923]Training epoch 5:  35%|███▌      | 11/31 [00:26<00:32,  1.60s/it, loss=2.4057, batch_acc=0.3750, running_acc=0.3156, grad=13.6923]Training epoch 5:  35%|███▌      | 11/31 [00:26<00:32,  1.60s/it, loss=2.4015, batch_acc=0.3125, running_acc=0.3153, grad=15.6278]Training epoch 5:  39%|███▊      | 12/31 [00:28<00:36,  1.90s/it, loss=2.4015, batch_acc=0.3125, running_acc=0.3153, grad=15.6278]Training epoch 5:  39%|███▊      | 12/31 [00:28<00:36,  1.90s/it, loss=2.4062, batch_acc=0.3438, running_acc=0.3177, grad=11.8268]Training epoch 5:  42%|████▏     | 13/31 [00:30<00:32,  1.78s/it, loss=2.4062, batch_acc=0.3438, running_acc=0.3177, grad=11.8268]Training epoch 5:  42%|████▏     | 13/31 [00:30<00:32,  1.78s/it, loss=2.5978, batch_acc=0.2188, running_acc=0.3101, grad=19.1227]Training epoch 5:  45%|████▌     | 14/31 [00:31<00:28,  1.70s/it, loss=2.5978, batch_acc=0.2188, running_acc=0.3101, grad=19.1227]Training epoch 5:  45%|████▌     | 14/31 [00:31<00:28,  1.70s/it, loss=2.4519, batch_acc=0.3125, running_acc=0.3103, grad=19.6726]Training epoch 5:  48%|████▊     | 15/31 [00:33<00:26,  1.64s/it, loss=2.4519, batch_acc=0.3125, running_acc=0.3103, grad=19.6726]Training epoch 5:  48%|████▊     | 15/31 [00:33<00:26,  1.64s/it, loss=2.5280, batch_acc=0.3438, running_acc=0.3125, grad=28.6363]Training epoch 5:  52%|█████▏    | 16/31 [00:37<00:35,  2.37s/it, loss=2.5280, batch_acc=0.3438, running_acc=0.3125, grad=28.6363]Training epoch 5:  52%|█████▏    | 16/31 [00:37<00:35,  2.37s/it, loss=2.3942, batch_acc=0.3438, running_acc=0.3145, grad=16.0650]Training epoch 5:  55%|█████▍    | 17/31 [00:38<00:29,  2.11s/it, loss=2.3942, batch_acc=0.3438, running_acc=0.3145, grad=16.0650]Training epoch 5:  55%|█████▍    | 17/31 [00:38<00:29,  2.11s/it, loss=2.5735, batch_acc=0.3438, running_acc=0.3162, grad=12.0991]Training epoch 5:  58%|█████▊    | 18/31 [00:40<00:25,  1.93s/it, loss=2.5735, batch_acc=0.3438, running_acc=0.3162, grad=12.0991]Training epoch 5:  58%|█████▊    | 18/31 [00:40<00:25,  1.93s/it, loss=2.6124, batch_acc=0.2188, running_acc=0.3108, grad=12.6519]Training epoch 5:  61%|██████▏   | 19/31 [00:41<00:21,  1.80s/it, loss=2.6124, batch_acc=0.2188, running_acc=0.3108, grad=12.6519]Training epoch 5:  61%|██████▏   | 19/31 [00:41<00:21,  1.80s/it, loss=2.4568, batch_acc=0.4688, running_acc=0.3191, grad=12.9988]Training epoch 5:  65%|██████▍   | 20/31 [00:44<00:23,  2.17s/it, loss=2.4568, batch_acc=0.4688, running_acc=0.3191, grad=12.9988]Training epoch 5:  65%|██████▍   | 20/31 [00:44<00:23,  2.17s/it, loss=2.6764, batch_acc=0.2500, running_acc=0.3156, grad=20.0452]Training epoch 5:  68%|██████▊   | 21/31 [00:46<00:19,  1.97s/it, loss=2.6764, batch_acc=0.2500, running_acc=0.3156, grad=20.0452]Training epoch 5:  68%|██████▊   | 21/31 [00:46<00:19,  1.97s/it, loss=2.5311, batch_acc=0.3125, running_acc=0.3155, grad=8.4268] Training epoch 5:  71%|███████   | 22/31 [00:47<00:16,  1.83s/it, loss=2.5311, batch_acc=0.3125, running_acc=0.3155, grad=8.4268]Training epoch 5:  71%|███████   | 22/31 [00:47<00:16,  1.83s/it, loss=2.3784, batch_acc=0.3750, running_acc=0.3182, grad=13.4796]Training epoch 5:  74%|███████▍  | 23/31 [00:49<00:13,  1.73s/it, loss=2.3784, batch_acc=0.3750, running_acc=0.3182, grad=13.4796]Training epoch 5:  74%|███████▍  | 23/31 [00:49<00:13,  1.73s/it, loss=2.5382, batch_acc=0.3125, running_acc=0.3179, grad=10.9174]Training epoch 5:  77%|███████▋  | 24/31 [00:55<00:22,  3.20s/it, loss=2.5382, batch_acc=0.3125, running_acc=0.3179, grad=10.9174]Training epoch 5:  77%|███████▋  | 24/31 [00:55<00:22,  3.20s/it, loss=2.4100, batch_acc=0.5000, running_acc=0.3255, grad=33.2360]Training epoch 5:  81%|████████  | 25/31 [00:57<00:16,  2.69s/it, loss=2.4100, batch_acc=0.5000, running_acc=0.3255, grad=33.2360]Training epoch 5:  81%|████████  | 25/31 [00:57<00:16,  2.69s/it, loss=2.3760, batch_acc=0.4688, running_acc=0.3312, grad=17.2885]Training epoch 5:  84%|████████▍ | 26/31 [00:59<00:11,  2.34s/it, loss=2.3760, batch_acc=0.4688, running_acc=0.3312, grad=17.2885]Training epoch 5:  84%|████████▍ | 26/31 [00:59<00:11,  2.34s/it, loss=2.4687, batch_acc=0.3750, running_acc=0.3329, grad=13.1383]Training epoch 5:  87%|████████▋ | 27/31 [01:00<00:08,  2.09s/it, loss=2.4687, batch_acc=0.3750, running_acc=0.3329, grad=13.1383]Training epoch 5:  87%|████████▋ | 27/31 [01:00<00:08,  2.09s/it, loss=2.5704, batch_acc=0.2500, running_acc=0.3299, grad=9.3032] Training epoch 5:  90%|█████████ | 28/31 [01:05<00:09,  3.09s/it, loss=2.5704, batch_acc=0.2500, running_acc=0.3299, grad=9.3032]Training epoch 5:  90%|█████████ | 28/31 [01:05<00:09,  3.09s/it, loss=2.8493, batch_acc=0.2812, running_acc=0.3281, grad=65.6953]Training epoch 5:  94%|█████████▎| 29/31 [01:07<00:05,  2.62s/it, loss=2.8493, batch_acc=0.2812, running_acc=0.3281, grad=65.6953]Training epoch 5:  94%|█████████▎| 29/31 [01:07<00:05,  2.62s/it, loss=2.5245, batch_acc=0.4062, running_acc=0.3308, grad=27.2484]Training epoch 5:  97%|█████████▋| 30/31 [01:08<00:02,  2.28s/it, loss=2.5245, batch_acc=0.4062, running_acc=0.3308, grad=27.2484]Training epoch 5:  97%|█████████▋| 30/31 [01:08<00:02,  2.28s/it, loss=2.3770, batch_acc=0.4688, running_acc=0.3354, grad=13.5873]Training epoch 5: 100%|██████████| 31/31 [01:09<00:00,  1.66s/it, loss=2.3770, batch_acc=0.4688, running_acc=0.3354, grad=13.5873]Training epoch 5: 100%|██████████| 31/31 [01:09<00:00,  1.66s/it, loss=2.1153, batch_acc=0.5000, running_acc=0.3358, grad=42.3867]Training epoch 5: 100%|██████████| 31/31 [01:09<00:00,  2.23s/it, loss=2.1153, batch_acc=0.5000, running_acc=0.3358, grad=42.3867]
Evaluation epoch 5:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 5:  20%|██        | 1/5 [00:04<00:19,  4.76s/it]Evaluation epoch 5:  20%|██        | 1/5 [00:04<00:19,  4.76s/it, loss=2.3832, batch_acc=0.4688, running_acc=0.4688]Evaluation epoch 5:  40%|████      | 2/5 [00:05<00:07,  2.40s/it, loss=2.3832, batch_acc=0.4688, running_acc=0.4688]Evaluation epoch 5:  40%|████      | 2/5 [00:05<00:07,  2.40s/it, loss=2.2775, batch_acc=0.5625, running_acc=0.5156]Evaluation epoch 5:  60%|██████    | 3/5 [00:06<00:03,  1.64s/it, loss=2.2775, batch_acc=0.5625, running_acc=0.5156]Evaluation epoch 5:  60%|██████    | 3/5 [00:06<00:03,  1.64s/it, loss=2.5470, batch_acc=0.3125, running_acc=0.4479]Evaluation epoch 5:  80%|████████  | 4/5 [00:07<00:01,  1.59s/it, loss=2.5470, batch_acc=0.3125, running_acc=0.4479]Evaluation epoch 5:  80%|████████  | 4/5 [00:07<00:01,  1.59s/it, loss=2.5848, batch_acc=0.2812, running_acc=0.4062]Evaluation epoch 5: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=2.5848, batch_acc=0.2812, running_acc=0.4062]Evaluation epoch 5: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=2.6303, batch_acc=0.3125, running_acc=0.3875]Evaluation epoch 5: 100%|██████████| 5/5 [00:08<00:00,  1.71s/it, loss=2.6303, batch_acc=0.3125, running_acc=0.3875]
Training epoch 6:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 6:   3%|▎         | 1/31 [00:09<04:42,  9.42s/it]Training epoch 6:   3%|▎         | 1/31 [00:09<04:42,  9.42s/it, loss=2.4319, batch_acc=0.4062, running_acc=0.4062, grad=14.4425]Training epoch 6:   6%|▋         | 2/31 [00:10<02:18,  4.77s/it, loss=2.4319, batch_acc=0.4062, running_acc=0.4062, grad=14.4425]Training epoch 6:   6%|▋         | 2/31 [00:10<02:18,  4.77s/it, loss=2.4850, batch_acc=0.4062, running_acc=0.4062, grad=12.4179]Training epoch 6:  10%|▉         | 3/31 [00:12<01:31,  3.28s/it, loss=2.4850, batch_acc=0.4062, running_acc=0.4062, grad=12.4179]Training epoch 6:  10%|▉         | 3/31 [00:12<01:31,  3.28s/it, loss=2.5415, batch_acc=0.2812, running_acc=0.3646, grad=16.0435]Training epoch 6:  13%|█▎        | 4/31 [00:16<01:36,  3.57s/it, loss=2.5415, batch_acc=0.2812, running_acc=0.3646, grad=16.0435]Training epoch 6:  13%|█▎        | 4/31 [00:16<01:36,  3.57s/it, loss=2.4835, batch_acc=0.3750, running_acc=0.3672, grad=17.9651]Training epoch 6:  16%|█▌        | 5/31 [00:17<01:13,  2.83s/it, loss=2.4835, batch_acc=0.3750, running_acc=0.3672, grad=17.9651]Training epoch 6:  16%|█▌        | 5/31 [00:17<01:13,  2.83s/it, loss=2.5452, batch_acc=0.2812, running_acc=0.3500, grad=16.5314]Training epoch 6:  19%|█▉        | 6/31 [00:19<00:59,  2.38s/it, loss=2.5452, batch_acc=0.2812, running_acc=0.3500, grad=16.5314]Training epoch 6:  19%|█▉        | 6/31 [00:19<00:59,  2.38s/it, loss=2.4846, batch_acc=0.4062, running_acc=0.3594, grad=9.9940] Training epoch 6:  23%|██▎       | 7/31 [00:20<00:50,  2.10s/it, loss=2.4846, batch_acc=0.4062, running_acc=0.3594, grad=9.9940]Training epoch 6:  23%|██▎       | 7/31 [00:20<00:50,  2.10s/it, loss=2.6923, batch_acc=0.2188, running_acc=0.3393, grad=21.5671]Training epoch 6:  26%|██▌       | 8/31 [00:31<01:48,  4.71s/it, loss=2.6923, batch_acc=0.2188, running_acc=0.3393, grad=21.5671]Training epoch 6:  26%|██▌       | 8/31 [00:31<01:48,  4.71s/it, loss=2.6221, batch_acc=0.2188, running_acc=0.3242, grad=18.0521]Training epoch 6:  29%|██▉       | 9/31 [00:32<01:21,  3.71s/it, loss=2.6221, batch_acc=0.2188, running_acc=0.3242, grad=18.0521]Training epoch 6:  29%|██▉       | 9/31 [00:32<01:21,  3.71s/it, loss=2.2324, batch_acc=0.5938, running_acc=0.3542, grad=9.8954] Training epoch 6:  32%|███▏      | 10/31 [00:34<01:03,  3.03s/it, loss=2.2324, batch_acc=0.5938, running_acc=0.3542, grad=9.8954]Training epoch 6:  32%|███▏      | 10/31 [00:34<01:03,  3.03s/it, loss=2.2318, batch_acc=0.5938, running_acc=0.3781, grad=6.3269]Training epoch 6:  35%|███▌      | 11/31 [00:35<00:51,  2.57s/it, loss=2.2318, batch_acc=0.5938, running_acc=0.3781, grad=6.3269]Training epoch 6:  35%|███▌      | 11/31 [00:35<00:51,  2.57s/it, loss=2.3240, batch_acc=0.4375, running_acc=0.3835, grad=18.4173]Training epoch 6:  39%|███▊      | 12/31 [00:51<02:06,  6.66s/it, loss=2.3240, batch_acc=0.4375, running_acc=0.3835, grad=18.4173]Training epoch 6:  39%|███▊      | 12/31 [00:51<02:06,  6.66s/it, loss=2.2258, batch_acc=0.5000, running_acc=0.3932, grad=14.7090]Training epoch 6:  42%|████▏     | 13/31 [00:53<01:31,  5.10s/it, loss=2.2258, batch_acc=0.5000, running_acc=0.3932, grad=14.7090]Training epoch 6:  42%|████▏     | 13/31 [00:53<01:31,  5.10s/it, loss=2.4043, batch_acc=0.3438, running_acc=0.3894, grad=8.7367] Training epoch 6:  45%|████▌     | 14/31 [00:54<01:08,  4.01s/it, loss=2.4043, batch_acc=0.3438, running_acc=0.3894, grad=8.7367]Training epoch 6:  45%|████▌     | 14/31 [00:54<01:08,  4.01s/it, loss=2.5372, batch_acc=0.3125, running_acc=0.3839, grad=18.7643]Training epoch 6:  48%|████▊     | 15/31 [00:56<00:52,  3.26s/it, loss=2.5372, batch_acc=0.3125, running_acc=0.3839, grad=18.7643]Training epoch 6:  48%|████▊     | 15/31 [00:56<00:52,  3.26s/it, loss=2.4828, batch_acc=0.4062, running_acc=0.3854, grad=18.0175]Training epoch 6:  52%|█████▏    | 16/31 [01:15<02:01,  8.10s/it, loss=2.4828, batch_acc=0.4062, running_acc=0.3854, grad=18.0175]Training epoch 6:  52%|█████▏    | 16/31 [01:15<02:01,  8.10s/it, loss=2.4321, batch_acc=0.3750, running_acc=0.3848, grad=14.9327]Training epoch 6:  55%|█████▍    | 17/31 [01:17<01:25,  6.12s/it, loss=2.4321, batch_acc=0.3750, running_acc=0.3848, grad=14.9327]Training epoch 6:  55%|█████▍    | 17/31 [01:17<01:25,  6.12s/it, loss=2.5803, batch_acc=0.3750, running_acc=0.3842, grad=90.1139]Training epoch 6:  58%|█████▊    | 18/31 [01:18<01:01,  4.73s/it, loss=2.5803, batch_acc=0.3750, running_acc=0.3842, grad=90.1139]Training epoch 6:  58%|█████▊    | 18/31 [01:18<01:01,  4.73s/it, loss=2.5311, batch_acc=0.2812, running_acc=0.3785, grad=8.8975] Training epoch 6:  61%|██████▏   | 19/31 [01:20<00:45,  3.76s/it, loss=2.5311, batch_acc=0.2812, running_acc=0.3785, grad=8.8975]Training epoch 6:  61%|██████▏   | 19/31 [01:20<00:45,  3.76s/it, loss=2.5880, batch_acc=0.3438, running_acc=0.3766, grad=11.0840]Training epoch 6:  65%|██████▍   | 20/31 [01:21<00:33,  3.09s/it, loss=2.5880, batch_acc=0.3438, running_acc=0.3766, grad=11.0840]Training epoch 6:  65%|██████▍   | 20/31 [01:21<00:33,  3.09s/it, loss=2.6283, batch_acc=0.4375, running_acc=0.3797, grad=31.2148]Training epoch 6:  68%|██████▊   | 21/31 [01:23<00:26,  2.61s/it, loss=2.6283, batch_acc=0.4375, running_acc=0.3797, grad=31.2148]Training epoch 6:  68%|██████▊   | 21/31 [01:23<00:26,  2.61s/it, loss=2.4954, batch_acc=0.5312, running_acc=0.3869, grad=8.8708] Training epoch 6:  71%|███████   | 22/31 [01:24<00:20,  2.28s/it, loss=2.4954, batch_acc=0.5312, running_acc=0.3869, grad=8.8708]Training epoch 6:  71%|███████   | 22/31 [01:24<00:20,  2.28s/it, loss=2.4262, batch_acc=0.4375, running_acc=0.3892, grad=15.7736]Training epoch 6:  74%|███████▍  | 23/31 [01:26<00:16,  2.05s/it, loss=2.4262, batch_acc=0.4375, running_acc=0.3892, grad=15.7736]Training epoch 6:  74%|███████▍  | 23/31 [01:26<00:16,  2.05s/it, loss=2.3106, batch_acc=0.5000, running_acc=0.3940, grad=13.4801]Training epoch 6:  77%|███████▋  | 24/31 [01:29<00:17,  2.51s/it, loss=2.3106, batch_acc=0.5000, running_acc=0.3940, grad=13.4801]Training epoch 6:  77%|███████▋  | 24/31 [01:29<00:17,  2.51s/it, loss=2.6559, batch_acc=0.1875, running_acc=0.3854, grad=8.9821] Training epoch 6:  81%|████████  | 25/31 [01:31<00:13,  2.21s/it, loss=2.6559, batch_acc=0.1875, running_acc=0.3854, grad=8.9821]Training epoch 6:  81%|████████  | 25/31 [01:31<00:13,  2.21s/it, loss=2.7208, batch_acc=0.2188, running_acc=0.3787, grad=15.0276]Training epoch 6:  84%|████████▍ | 26/31 [01:32<00:09,  2.00s/it, loss=2.7208, batch_acc=0.2188, running_acc=0.3787, grad=15.0276]Training epoch 6:  84%|████████▍ | 26/31 [01:32<00:09,  2.00s/it, loss=2.2633, batch_acc=0.5000, running_acc=0.3834, grad=10.8831]Training epoch 6:  87%|████████▋ | 27/31 [01:34<00:07,  1.85s/it, loss=2.2633, batch_acc=0.5000, running_acc=0.3834, grad=10.8831]Training epoch 6:  87%|████████▋ | 27/31 [01:34<00:07,  1.85s/it, loss=2.3285, batch_acc=0.4375, running_acc=0.3854, grad=11.6687]Training epoch 6:  90%|█████████ | 28/31 [01:35<00:05,  1.75s/it, loss=2.3285, batch_acc=0.4375, running_acc=0.3854, grad=11.6687]Training epoch 6:  90%|█████████ | 28/31 [01:35<00:05,  1.75s/it, loss=2.4719, batch_acc=0.4062, running_acc=0.3862, grad=12.5306]Training epoch 6:  94%|█████████▎| 29/31 [01:37<00:03,  1.67s/it, loss=2.4719, batch_acc=0.4062, running_acc=0.3862, grad=12.5306]Training epoch 6:  94%|█████████▎| 29/31 [01:37<00:03,  1.67s/it, loss=2.3530, batch_acc=0.5000, running_acc=0.3901, grad=14.2143]Training epoch 6:  97%|█████████▋| 30/31 [01:38<00:01,  1.62s/it, loss=2.3530, batch_acc=0.5000, running_acc=0.3901, grad=14.2143]Training epoch 6:  97%|█████████▋| 30/31 [01:38<00:01,  1.62s/it, loss=2.4849, batch_acc=0.3750, running_acc=0.3896, grad=12.7706]Training epoch 6: 100%|██████████| 31/31 [01:39<00:00,  1.20s/it, loss=2.4849, batch_acc=0.3750, running_acc=0.3896, grad=12.7706]Training epoch 6: 100%|██████████| 31/31 [01:39<00:00,  1.20s/it, loss=2.6773, batch_acc=0.5000, running_acc=0.3898, grad=58.9873]Training epoch 6: 100%|██████████| 31/31 [01:39<00:00,  3.20s/it, loss=2.6773, batch_acc=0.5000, running_acc=0.3898, grad=58.9873]
Evaluation epoch 6:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 6:  20%|██        | 1/5 [00:06<00:26,  6.69s/it]Evaluation epoch 6:  20%|██        | 1/5 [00:06<00:26,  6.69s/it, loss=2.1642, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 6:  40%|████      | 2/5 [00:07<00:09,  3.19s/it, loss=2.1642, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 6:  40%|████      | 2/5 [00:07<00:09,  3.19s/it, loss=2.0839, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 6:  60%|██████    | 3/5 [00:08<00:04,  2.08s/it, loss=2.0839, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 6:  60%|██████    | 3/5 [00:08<00:04,  2.08s/it, loss=2.5157, batch_acc=0.2500, running_acc=0.4375]Evaluation epoch 6:  80%|████████  | 4/5 [00:08<00:01,  1.55s/it, loss=2.5157, batch_acc=0.2500, running_acc=0.4375]Evaluation epoch 6:  80%|████████  | 4/5 [00:08<00:01,  1.55s/it, loss=2.5649, batch_acc=0.3125, running_acc=0.4062]Evaluation epoch 6: 100%|██████████| 5/5 [00:09<00:00,  1.27s/it, loss=2.5649, batch_acc=0.3125, running_acc=0.4062]Evaluation epoch 6: 100%|██████████| 5/5 [00:09<00:00,  1.27s/it, loss=2.6112, batch_acc=0.3125, running_acc=0.3875]Evaluation epoch 6: 100%|██████████| 5/5 [00:09<00:00,  1.94s/it, loss=2.6112, batch_acc=0.3125, running_acc=0.3875]
Training epoch 7:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 7:   3%|▎         | 1/31 [00:08<04:24,  8.83s/it]Training epoch 7:   3%|▎         | 1/31 [00:08<04:24,  8.83s/it, loss=2.3405, batch_acc=0.3125, running_acc=0.3125, grad=11.2954]Training epoch 7:   6%|▋         | 2/31 [00:10<02:11,  4.52s/it, loss=2.3405, batch_acc=0.3125, running_acc=0.3125, grad=11.2954]Training epoch 7:   6%|▋         | 2/31 [00:10<02:11,  4.52s/it, loss=2.3382, batch_acc=0.4375, running_acc=0.3750, grad=12.0437]Training epoch 7:  10%|▉         | 3/31 [00:11<01:28,  3.15s/it, loss=2.3382, batch_acc=0.4375, running_acc=0.3750, grad=12.0437]Training epoch 7:  10%|▉         | 3/31 [00:11<01:28,  3.15s/it, loss=2.4012, batch_acc=0.3750, running_acc=0.3750, grad=11.5725]Training epoch 7:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=2.4012, batch_acc=0.3750, running_acc=0.3750, grad=11.5725]Training epoch 7:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=2.3108, batch_acc=0.4375, running_acc=0.3906, grad=31.1846]Training epoch 7:  16%|█▌        | 5/31 [00:14<00:55,  2.15s/it, loss=2.3108, batch_acc=0.4375, running_acc=0.3906, grad=31.1846]Training epoch 7:  16%|█▌        | 5/31 [00:14<00:55,  2.15s/it, loss=2.2354, batch_acc=0.4688, running_acc=0.4062, grad=9.3115] Training epoch 7:  19%|█▉        | 6/31 [00:16<00:48,  1.93s/it, loss=2.2354, batch_acc=0.4688, running_acc=0.4062, grad=9.3115]Training epoch 7:  19%|█▉        | 6/31 [00:16<00:48,  1.93s/it, loss=2.3560, batch_acc=0.4375, running_acc=0.4115, grad=31.9387]Training epoch 7:  23%|██▎       | 7/31 [00:17<00:42,  1.79s/it, loss=2.3560, batch_acc=0.4375, running_acc=0.4115, grad=31.9387]Training epoch 7:  23%|██▎       | 7/31 [00:17<00:42,  1.79s/it, loss=2.1834, batch_acc=0.5000, running_acc=0.4241, grad=8.5556] Training epoch 7:  26%|██▌       | 8/31 [00:19<00:39,  1.70s/it, loss=2.1834, batch_acc=0.5000, running_acc=0.4241, grad=8.5556]Training epoch 7:  26%|██▌       | 8/31 [00:19<00:39,  1.70s/it, loss=2.4634, batch_acc=0.4062, running_acc=0.4219, grad=27.8348]Training epoch 7:  29%|██▉       | 9/31 [00:20<00:36,  1.64s/it, loss=2.4634, batch_acc=0.4062, running_acc=0.4219, grad=27.8348]Training epoch 7:  29%|██▉       | 9/31 [00:20<00:36,  1.64s/it, loss=2.2166, batch_acc=0.4062, running_acc=0.4201, grad=10.5026]Training epoch 7:  32%|███▏      | 10/31 [00:22<00:33,  1.60s/it, loss=2.2166, batch_acc=0.4062, running_acc=0.4201, grad=10.5026]Training epoch 7:  32%|███▏      | 10/31 [00:22<00:33,  1.60s/it, loss=2.1763, batch_acc=0.5312, running_acc=0.4313, grad=15.4060]Training epoch 7:  35%|███▌      | 11/31 [00:23<00:31,  1.58s/it, loss=2.1763, batch_acc=0.5312, running_acc=0.4313, grad=15.4060]Training epoch 7:  35%|███▌      | 11/31 [00:23<00:31,  1.58s/it, loss=2.2974, batch_acc=0.4062, running_acc=0.4290, grad=8.8071] Training epoch 7:  39%|███▊      | 12/31 [00:25<00:29,  1.56s/it, loss=2.2974, batch_acc=0.4062, running_acc=0.4290, grad=8.8071]Training epoch 7:  39%|███▊      | 12/31 [00:25<00:29,  1.56s/it, loss=2.4865, batch_acc=0.2500, running_acc=0.4141, grad=21.0490]Training epoch 7:  42%|████▏     | 13/31 [00:26<00:27,  1.55s/it, loss=2.4865, batch_acc=0.2500, running_acc=0.4141, grad=21.0490]Training epoch 7:  42%|████▏     | 13/31 [00:26<00:27,  1.55s/it, loss=2.4870, batch_acc=0.2812, running_acc=0.4038, grad=10.9560]Training epoch 7:  45%|████▌     | 14/31 [00:28<00:26,  1.54s/it, loss=2.4870, batch_acc=0.2812, running_acc=0.4038, grad=10.9560]Training epoch 7:  45%|████▌     | 14/31 [00:28<00:26,  1.54s/it, loss=2.5132, batch_acc=0.4688, running_acc=0.4085, grad=16.5478]Training epoch 7:  48%|████▊     | 15/31 [00:30<00:24,  1.53s/it, loss=2.5132, batch_acc=0.4688, running_acc=0.4085, grad=16.5478]Training epoch 7:  48%|████▊     | 15/31 [00:30<00:24,  1.53s/it, loss=2.1751, batch_acc=0.5938, running_acc=0.4208, grad=15.9586]Training epoch 7:  52%|█████▏    | 16/31 [00:31<00:23,  1.55s/it, loss=2.1751, batch_acc=0.5938, running_acc=0.4208, grad=15.9586]Training epoch 7:  52%|█████▏    | 16/31 [00:31<00:23,  1.55s/it, loss=2.2979, batch_acc=0.4375, running_acc=0.4219, grad=9.9095] Training epoch 7:  55%|█████▍    | 17/31 [00:33<00:21,  1.54s/it, loss=2.2979, batch_acc=0.4375, running_acc=0.4219, grad=9.9095]Training epoch 7:  55%|█████▍    | 17/31 [00:33<00:21,  1.54s/it, loss=2.1877, batch_acc=0.5312, running_acc=0.4283, grad=9.7123]Training epoch 7:  58%|█████▊    | 18/31 [00:34<00:19,  1.53s/it, loss=2.1877, batch_acc=0.5312, running_acc=0.4283, grad=9.7123]Training epoch 7:  58%|█████▊    | 18/31 [00:34<00:19,  1.53s/it, loss=2.5117, batch_acc=0.3750, running_acc=0.4253, grad=21.5606]Training epoch 7:  61%|██████▏   | 19/31 [00:36<00:18,  1.54s/it, loss=2.5117, batch_acc=0.3750, running_acc=0.4253, grad=21.5606]Training epoch 7:  61%|██████▏   | 19/31 [00:36<00:18,  1.54s/it, loss=2.3021, batch_acc=0.3438, running_acc=0.4211, grad=18.4259]Training epoch 7:  65%|██████▍   | 20/31 [00:37<00:16,  1.53s/it, loss=2.3021, batch_acc=0.3438, running_acc=0.4211, grad=18.4259]Training epoch 7:  65%|██████▍   | 20/31 [00:37<00:16,  1.53s/it, loss=2.4035, batch_acc=0.3438, running_acc=0.4172, grad=10.8003]Training epoch 7:  68%|██████▊   | 21/31 [00:39<00:15,  1.52s/it, loss=2.4035, batch_acc=0.3438, running_acc=0.4172, grad=10.8003]Training epoch 7:  68%|██████▊   | 21/31 [00:39<00:15,  1.52s/it, loss=2.3559, batch_acc=0.3438, running_acc=0.4137, grad=10.3205]Training epoch 7:  71%|███████   | 22/31 [00:40<00:13,  1.52s/it, loss=2.3559, batch_acc=0.3438, running_acc=0.4137, grad=10.3205]Training epoch 7:  71%|███████   | 22/31 [00:40<00:13,  1.52s/it, loss=2.3135, batch_acc=0.4062, running_acc=0.4134, grad=23.4481]Training epoch 7:  74%|███████▍  | 23/31 [00:42<00:12,  1.52s/it, loss=2.3135, batch_acc=0.4062, running_acc=0.4134, grad=23.4481]Training epoch 7:  74%|███████▍  | 23/31 [00:42<00:12,  1.52s/it, loss=2.4078, batch_acc=0.3125, running_acc=0.4090, grad=18.3819]Training epoch 7:  77%|███████▋  | 24/31 [00:43<00:10,  1.51s/it, loss=2.4078, batch_acc=0.3125, running_acc=0.4090, grad=18.3819]Training epoch 7:  77%|███████▋  | 24/31 [00:43<00:10,  1.51s/it, loss=2.1993, batch_acc=0.4062, running_acc=0.4089, grad=8.5045] Training epoch 7:  81%|████████  | 25/31 [00:45<00:09,  1.63s/it, loss=2.1993, batch_acc=0.4062, running_acc=0.4089, grad=8.5045]Training epoch 7:  81%|████████  | 25/31 [00:45<00:09,  1.63s/it, loss=2.1639, batch_acc=0.5625, running_acc=0.4150, grad=14.6341]Training epoch 7:  84%|████████▍ | 26/31 [00:47<00:07,  1.60s/it, loss=2.1639, batch_acc=0.5625, running_acc=0.4150, grad=14.6341]Training epoch 7:  84%|████████▍ | 26/31 [00:47<00:07,  1.60s/it, loss=2.2605, batch_acc=0.3750, running_acc=0.4135, grad=9.9623] Training epoch 7:  87%|████████▋ | 27/31 [00:48<00:06,  1.58s/it, loss=2.2605, batch_acc=0.3750, running_acc=0.4135, grad=9.9623]Training epoch 7:  87%|████████▋ | 27/31 [00:48<00:06,  1.58s/it, loss=2.2746, batch_acc=0.4688, running_acc=0.4155, grad=10.9315]Training epoch 7:  90%|█████████ | 28/31 [00:50<00:05,  1.72s/it, loss=2.2746, batch_acc=0.4688, running_acc=0.4155, grad=10.9315]Training epoch 7:  90%|█████████ | 28/31 [00:50<00:05,  1.72s/it, loss=2.3078, batch_acc=0.5000, running_acc=0.4185, grad=9.2078] Training epoch 7:  94%|█████████▎| 29/31 [00:52<00:03,  1.65s/it, loss=2.3078, batch_acc=0.5000, running_acc=0.4185, grad=9.2078]Training epoch 7:  94%|█████████▎| 29/31 [00:52<00:03,  1.65s/it, loss=2.0567, batch_acc=0.5000, running_acc=0.4213, grad=11.0106]Training epoch 7:  97%|█████████▋| 30/31 [00:53<00:01,  1.61s/it, loss=2.0567, batch_acc=0.5000, running_acc=0.4213, grad=11.0106]Training epoch 7:  97%|█████████▋| 30/31 [00:53<00:01,  1.61s/it, loss=2.2725, batch_acc=0.4375, running_acc=0.4219, grad=7.6478] Training epoch 7: 100%|██████████| 31/31 [00:53<00:00,  1.19s/it, loss=2.2725, batch_acc=0.4375, running_acc=0.4219, grad=7.6478]Training epoch 7: 100%|██████████| 31/31 [00:53<00:00,  1.19s/it, loss=1.7847, batch_acc=1.0000, running_acc=0.4231, grad=24.0819]Training epoch 7: 100%|██████████| 31/31 [00:53<00:00,  1.74s/it, loss=1.7847, batch_acc=1.0000, running_acc=0.4231, grad=24.0819]
Evaluation epoch 7:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 7:  20%|██        | 1/5 [00:15<01:03, 15.86s/it]Evaluation epoch 7:  20%|██        | 1/5 [00:15<01:03, 15.86s/it, loss=1.9702, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 7:  40%|████      | 2/5 [00:16<00:20,  6.97s/it, loss=1.9702, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 7:  40%|████      | 2/5 [00:16<00:20,  6.97s/it, loss=2.0670, batch_acc=0.5625, running_acc=0.6094]Evaluation epoch 7:  60%|██████    | 3/5 [00:17<00:08,  4.13s/it, loss=2.0670, batch_acc=0.5625, running_acc=0.6094]Evaluation epoch 7:  60%|██████    | 3/5 [00:17<00:08,  4.13s/it, loss=2.2439, batch_acc=0.2812, running_acc=0.5000]Evaluation epoch 7:  80%|████████  | 4/5 [00:18<00:03,  3.08s/it, loss=2.2439, batch_acc=0.2812, running_acc=0.5000]Evaluation epoch 7:  80%|████████  | 4/5 [00:18<00:03,  3.08s/it, loss=2.3994, batch_acc=0.4375, running_acc=0.4844]Evaluation epoch 7: 100%|██████████| 5/5 [00:19<00:00,  2.25s/it, loss=2.3994, batch_acc=0.4375, running_acc=0.4844]Evaluation epoch 7: 100%|██████████| 5/5 [00:19<00:00,  2.25s/it, loss=2.6111, batch_acc=0.2812, running_acc=0.4437]Evaluation epoch 7: 100%|██████████| 5/5 [00:19<00:00,  3.92s/it, loss=2.6111, batch_acc=0.2812, running_acc=0.4437]
Training epoch 8:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 8:   3%|▎         | 1/31 [00:07<03:51,  7.72s/it]Training epoch 8:   3%|▎         | 1/31 [00:07<03:51,  7.72s/it, loss=2.1454, batch_acc=0.4375, running_acc=0.4375, grad=9.9148]Training epoch 8:   6%|▋         | 2/31 [00:09<01:57,  4.06s/it, loss=2.1454, batch_acc=0.4375, running_acc=0.4375, grad=9.9148]Training epoch 8:   6%|▋         | 2/31 [00:09<01:57,  4.06s/it, loss=2.1450, batch_acc=0.4688, running_acc=0.4531, grad=15.5251]Training epoch 8:  10%|▉         | 3/31 [00:10<01:21,  2.90s/it, loss=2.1450, batch_acc=0.4688, running_acc=0.4531, grad=15.5251]Training epoch 8:  10%|▉         | 3/31 [00:10<01:21,  2.90s/it, loss=2.5192, batch_acc=0.4375, running_acc=0.4479, grad=20.0724]Training epoch 8:  13%|█▎        | 4/31 [00:12<01:03,  2.35s/it, loss=2.5192, batch_acc=0.4375, running_acc=0.4479, grad=20.0724]Training epoch 8:  13%|█▎        | 4/31 [00:12<01:03,  2.35s/it, loss=2.4185, batch_acc=0.4375, running_acc=0.4453, grad=18.8817]Training epoch 8:  16%|█▌        | 5/31 [00:14<00:57,  2.20s/it, loss=2.4185, batch_acc=0.4375, running_acc=0.4453, grad=18.8817]Training epoch 8:  16%|█▌        | 5/31 [00:14<00:57,  2.20s/it, loss=2.1900, batch_acc=0.5938, running_acc=0.4750, grad=17.6164]Training epoch 8:  19%|█▉        | 6/31 [00:15<00:49,  1.97s/it, loss=2.1900, batch_acc=0.5938, running_acc=0.4750, grad=17.6164]Training epoch 8:  19%|█▉        | 6/31 [00:15<00:49,  1.97s/it, loss=2.2331, batch_acc=0.3750, running_acc=0.4583, grad=20.5582]Training epoch 8:  23%|██▎       | 7/31 [00:17<00:43,  1.82s/it, loss=2.2331, batch_acc=0.3750, running_acc=0.4583, grad=20.5582]Training epoch 8:  23%|██▎       | 7/31 [00:17<00:43,  1.82s/it, loss=2.3513, batch_acc=0.4688, running_acc=0.4598, grad=18.0148]Training epoch 8:  26%|██▌       | 8/31 [00:18<00:39,  1.72s/it, loss=2.3513, batch_acc=0.4688, running_acc=0.4598, grad=18.0148]Training epoch 8:  26%|██▌       | 8/31 [00:18<00:39,  1.72s/it, loss=2.1719, batch_acc=0.5625, running_acc=0.4727, grad=18.0761]Training epoch 8:  29%|██▉       | 9/31 [00:20<00:36,  1.66s/it, loss=2.1719, batch_acc=0.5625, running_acc=0.4727, grad=18.0761]Training epoch 8:  29%|██▉       | 9/31 [00:20<00:36,  1.66s/it, loss=2.2574, batch_acc=0.4375, running_acc=0.4688, grad=12.3564]Training epoch 8:  32%|███▏      | 10/31 [00:21<00:33,  1.61s/it, loss=2.2574, batch_acc=0.4375, running_acc=0.4688, grad=12.3564]Training epoch 8:  32%|███▏      | 10/31 [00:21<00:33,  1.61s/it, loss=2.3662, batch_acc=0.3750, running_acc=0.4594, grad=12.3068]Training epoch 8:  35%|███▌      | 11/31 [00:23<00:31,  1.58s/it, loss=2.3662, batch_acc=0.3750, running_acc=0.4594, grad=12.3068]Training epoch 8:  35%|███▌      | 11/31 [00:23<00:31,  1.58s/it, loss=2.2127, batch_acc=0.5625, running_acc=0.4688, grad=13.9598]Training epoch 8:  39%|███▊      | 12/31 [00:24<00:29,  1.56s/it, loss=2.2127, batch_acc=0.5625, running_acc=0.4688, grad=13.9598]Training epoch 8:  39%|███▊      | 12/31 [00:24<00:29,  1.56s/it, loss=2.3766, batch_acc=0.3438, running_acc=0.4583, grad=15.1049]Training epoch 8:  42%|████▏     | 13/31 [00:26<00:27,  1.55s/it, loss=2.3766, batch_acc=0.3438, running_acc=0.4583, grad=15.1049]Training epoch 8:  42%|████▏     | 13/31 [00:26<00:27,  1.55s/it, loss=2.1342, batch_acc=0.5312, running_acc=0.4639, grad=21.0092]Training epoch 8:  45%|████▌     | 14/31 [00:27<00:26,  1.54s/it, loss=2.1342, batch_acc=0.5312, running_acc=0.4639, grad=21.0092]Training epoch 8:  45%|████▌     | 14/31 [00:27<00:26,  1.54s/it, loss=2.3115, batch_acc=0.4062, running_acc=0.4598, grad=16.7506]Training epoch 8:  48%|████▊     | 15/31 [00:29<00:24,  1.53s/it, loss=2.3115, batch_acc=0.4062, running_acc=0.4598, grad=16.7506]Training epoch 8:  48%|████▊     | 15/31 [00:29<00:24,  1.53s/it, loss=2.4027, batch_acc=0.3750, running_acc=0.4542, grad=39.9936]Training epoch 8:  52%|█████▏    | 16/31 [00:30<00:22,  1.53s/it, loss=2.4027, batch_acc=0.3750, running_acc=0.4542, grad=39.9936]Training epoch 8:  52%|█████▏    | 16/31 [00:30<00:22,  1.53s/it, loss=2.2344, batch_acc=0.4688, running_acc=0.4551, grad=12.9637]Training epoch 8:  55%|█████▍    | 17/31 [00:32<00:21,  1.52s/it, loss=2.2344, batch_acc=0.4688, running_acc=0.4551, grad=12.9637]Training epoch 8:  55%|█████▍    | 17/31 [00:32<00:21,  1.52s/it, loss=2.1125, batch_acc=0.6875, running_acc=0.4688, grad=13.5205]Training epoch 8:  58%|█████▊    | 18/31 [00:33<00:19,  1.52s/it, loss=2.1125, batch_acc=0.6875, running_acc=0.4688, grad=13.5205]Training epoch 8:  58%|█████▊    | 18/31 [00:33<00:19,  1.52s/it, loss=2.2796, batch_acc=0.5312, running_acc=0.4722, grad=9.9539] Training epoch 8:  61%|██████▏   | 19/31 [00:35<00:18,  1.52s/it, loss=2.2796, batch_acc=0.5312, running_acc=0.4722, grad=9.9539]Training epoch 8:  61%|██████▏   | 19/31 [00:35<00:18,  1.52s/it, loss=2.1187, batch_acc=0.4688, running_acc=0.4720, grad=13.0077]Training epoch 8:  65%|██████▍   | 20/31 [00:36<00:16,  1.52s/it, loss=2.1187, batch_acc=0.4688, running_acc=0.4720, grad=13.0077]Training epoch 8:  65%|██████▍   | 20/31 [00:36<00:16,  1.52s/it, loss=2.0020, batch_acc=0.6562, running_acc=0.4813, grad=23.4965]Training epoch 8:  68%|██████▊   | 21/31 [00:38<00:15,  1.51s/it, loss=2.0020, batch_acc=0.6562, running_acc=0.4813, grad=23.4965]Training epoch 8:  68%|██████▊   | 21/31 [00:38<00:15,  1.51s/it, loss=2.3188, batch_acc=0.4688, running_acc=0.4807, grad=7.4785] Training epoch 8:  71%|███████   | 22/31 [00:39<00:13,  1.51s/it, loss=2.3188, batch_acc=0.4688, running_acc=0.4807, grad=7.4785]Training epoch 8:  71%|███████   | 22/31 [00:39<00:13,  1.51s/it, loss=2.3039, batch_acc=0.4062, running_acc=0.4773, grad=12.2006]Training epoch 8:  74%|███████▍  | 23/31 [00:41<00:12,  1.51s/it, loss=2.3039, batch_acc=0.4062, running_acc=0.4773, grad=12.2006]Training epoch 8:  74%|███████▍  | 23/31 [00:41<00:12,  1.51s/it, loss=2.3384, batch_acc=0.3438, running_acc=0.4715, grad=8.2543] Training epoch 8:  77%|███████▋  | 24/31 [00:43<00:10,  1.53s/it, loss=2.3384, batch_acc=0.3438, running_acc=0.4715, grad=8.2543]Training epoch 8:  77%|███████▋  | 24/31 [00:43<00:10,  1.53s/it, loss=2.2181, batch_acc=0.4062, running_acc=0.4688, grad=18.6972]Training epoch 8:  81%|████████  | 25/31 [00:44<00:09,  1.53s/it, loss=2.2181, batch_acc=0.4062, running_acc=0.4688, grad=18.6972]Training epoch 8:  81%|████████  | 25/31 [00:44<00:09,  1.53s/it, loss=2.2715, batch_acc=0.5000, running_acc=0.4700, grad=38.0902]Training epoch 8:  84%|████████▍ | 26/31 [00:46<00:07,  1.52s/it, loss=2.2715, batch_acc=0.5000, running_acc=0.4700, grad=38.0902]Training epoch 8:  84%|████████▍ | 26/31 [00:46<00:07,  1.52s/it, loss=2.2514, batch_acc=0.4062, running_acc=0.4675, grad=10.0654]Training epoch 8:  87%|████████▋ | 27/31 [00:47<00:06,  1.52s/it, loss=2.2514, batch_acc=0.4062, running_acc=0.4675, grad=10.0654]Training epoch 8:  87%|████████▋ | 27/31 [00:47<00:06,  1.52s/it, loss=2.1319, batch_acc=0.5938, running_acc=0.4722, grad=15.6168]Training epoch 8:  90%|█████████ | 28/31 [00:49<00:04,  1.52s/it, loss=2.1319, batch_acc=0.5938, running_acc=0.4722, grad=15.6168]Training epoch 8:  90%|█████████ | 28/31 [00:49<00:04,  1.52s/it, loss=2.2391, batch_acc=0.4688, running_acc=0.4721, grad=35.2314]Training epoch 8:  94%|█████████▎| 29/31 [00:50<00:03,  1.51s/it, loss=2.2391, batch_acc=0.4688, running_acc=0.4721, grad=35.2314]Training epoch 8:  94%|█████████▎| 29/31 [00:50<00:03,  1.51s/it, loss=2.3949, batch_acc=0.4688, running_acc=0.4720, grad=12.8503]Training epoch 8:  97%|█████████▋| 30/31 [00:52<00:01,  1.51s/it, loss=2.3949, batch_acc=0.4688, running_acc=0.4720, grad=12.8503]Training epoch 8:  97%|█████████▋| 30/31 [00:52<00:01,  1.51s/it, loss=2.0615, batch_acc=0.6250, running_acc=0.4771, grad=8.2089] Training epoch 8: 100%|██████████| 31/31 [00:52<00:00,  1.12s/it, loss=2.0615, batch_acc=0.6250, running_acc=0.4771, grad=8.2089]Training epoch 8: 100%|██████████| 31/31 [00:52<00:00,  1.12s/it, loss=2.4860, batch_acc=0.5000, running_acc=0.4771, grad=84.3773]Training epoch 8: 100%|██████████| 31/31 [00:52<00:00,  1.69s/it, loss=2.4860, batch_acc=0.5000, running_acc=0.4771, grad=84.3773]
Evaluation epoch 8:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 8:  20%|██        | 1/5 [00:04<00:19,  4.84s/it]Evaluation epoch 8:  20%|██        | 1/5 [00:04<00:19,  4.84s/it, loss=1.8937, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 8:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.8937, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 8:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.7693, batch_acc=0.5000, running_acc=0.5156]Evaluation epoch 8:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.7693, batch_acc=0.5000, running_acc=0.5156]Evaluation epoch 8:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=2.6103, batch_acc=0.2500, running_acc=0.4271]Evaluation epoch 8:  80%|████████  | 4/5 [00:10<00:02,  2.50s/it, loss=2.6103, batch_acc=0.2500, running_acc=0.4271]Evaluation epoch 8:  80%|████████  | 4/5 [00:10<00:02,  2.50s/it, loss=2.5148, batch_acc=0.2500, running_acc=0.3828]Evaluation epoch 8: 100%|██████████| 5/5 [00:10<00:00,  1.88s/it, loss=2.5148, batch_acc=0.2500, running_acc=0.3828]Evaluation epoch 8: 100%|██████████| 5/5 [00:10<00:00,  1.88s/it, loss=2.3143, batch_acc=0.4375, running_acc=0.3937]Evaluation epoch 8: 100%|██████████| 5/5 [00:10<00:00,  2.19s/it, loss=2.3143, batch_acc=0.4375, running_acc=0.3937]
Training epoch 9:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 9:   3%|▎         | 1/31 [00:09<04:47,  9.57s/it]Training epoch 9:   3%|▎         | 1/31 [00:09<04:47,  9.57s/it, loss=2.1716, batch_acc=0.5000, running_acc=0.5000, grad=12.9195]Training epoch 9:   6%|▋         | 2/31 [00:11<02:20,  4.83s/it, loss=2.1716, batch_acc=0.5000, running_acc=0.5000, grad=12.9195]Training epoch 9:   6%|▋         | 2/31 [00:11<02:20,  4.83s/it, loss=2.1635, batch_acc=0.5312, running_acc=0.5156, grad=14.7563]Training epoch 9:  10%|▉         | 3/31 [00:12<01:32,  3.31s/it, loss=2.1635, batch_acc=0.5312, running_acc=0.5156, grad=14.7563]Training epoch 9:  10%|▉         | 3/31 [00:12<01:32,  3.31s/it, loss=2.1628, batch_acc=0.5625, running_acc=0.5312, grad=22.6019]Training epoch 9:  13%|█▎        | 4/31 [00:14<01:10,  2.60s/it, loss=2.1628, batch_acc=0.5625, running_acc=0.5312, grad=22.6019]Training epoch 9:  13%|█▎        | 4/31 [00:14<01:10,  2.60s/it, loss=2.0346, batch_acc=0.6875, running_acc=0.5703, grad=6.0507] Training epoch 9:  16%|█▌        | 5/31 [00:15<00:57,  2.21s/it, loss=2.0346, batch_acc=0.6875, running_acc=0.5703, grad=6.0507]Training epoch 9:  16%|█▌        | 5/31 [00:15<00:57,  2.21s/it, loss=2.3564, batch_acc=0.4062, running_acc=0.5375, grad=10.8657]Training epoch 9:  19%|█▉        | 6/31 [00:17<00:49,  1.97s/it, loss=2.3564, batch_acc=0.4062, running_acc=0.5375, grad=10.8657]Training epoch 9:  19%|█▉        | 6/31 [00:17<00:49,  1.97s/it, loss=2.0014, batch_acc=0.6250, running_acc=0.5521, grad=12.3306]Training epoch 9:  23%|██▎       | 7/31 [00:18<00:43,  1.82s/it, loss=2.0014, batch_acc=0.6250, running_acc=0.5521, grad=12.3306]Training epoch 9:  23%|██▎       | 7/31 [00:18<00:43,  1.82s/it, loss=2.1653, batch_acc=0.4375, running_acc=0.5357, grad=12.5873]Training epoch 9:  26%|██▌       | 8/31 [00:20<00:39,  1.72s/it, loss=2.1653, batch_acc=0.4375, running_acc=0.5357, grad=12.5873]Training epoch 9:  26%|██▌       | 8/31 [00:20<00:39,  1.72s/it, loss=2.2518, batch_acc=0.4688, running_acc=0.5273, grad=15.1790]Training epoch 9:  29%|██▉       | 9/31 [00:21<00:36,  1.65s/it, loss=2.2518, batch_acc=0.4688, running_acc=0.5273, grad=15.1790]Training epoch 9:  29%|██▉       | 9/31 [00:21<00:36,  1.65s/it, loss=2.0193, batch_acc=0.5938, running_acc=0.5347, grad=10.8437]Training epoch 9:  32%|███▏      | 10/31 [00:23<00:33,  1.61s/it, loss=2.0193, batch_acc=0.5938, running_acc=0.5347, grad=10.8437]Training epoch 9:  32%|███▏      | 10/31 [00:23<00:33,  1.61s/it, loss=2.1492, batch_acc=0.4375, running_acc=0.5250, grad=10.4811]Training epoch 9:  35%|███▌      | 11/31 [00:24<00:31,  1.58s/it, loss=2.1492, batch_acc=0.4375, running_acc=0.5250, grad=10.4811]Training epoch 9:  35%|███▌      | 11/31 [00:24<00:31,  1.58s/it, loss=2.0180, batch_acc=0.6250, running_acc=0.5341, grad=15.3533]Training epoch 9:  39%|███▊      | 12/31 [00:26<00:29,  1.56s/it, loss=2.0180, batch_acc=0.6250, running_acc=0.5341, grad=15.3533]Training epoch 9:  39%|███▊      | 12/31 [00:26<00:29,  1.56s/it, loss=2.2816, batch_acc=0.4688, running_acc=0.5286, grad=24.2810]Training epoch 9:  42%|████▏     | 13/31 [00:27<00:27,  1.55s/it, loss=2.2816, batch_acc=0.4688, running_acc=0.5286, grad=24.2810]Training epoch 9:  42%|████▏     | 13/31 [00:27<00:27,  1.55s/it, loss=2.3063, batch_acc=0.4062, running_acc=0.5192, grad=15.3330]Training epoch 9:  45%|████▌     | 14/31 [00:29<00:26,  1.53s/it, loss=2.3063, batch_acc=0.4062, running_acc=0.5192, grad=15.3330]Training epoch 9:  45%|████▌     | 14/31 [00:29<00:26,  1.53s/it, loss=2.3197, batch_acc=0.4375, running_acc=0.5134, grad=18.6937]Training epoch 9:  48%|████▊     | 15/31 [00:30<00:24,  1.53s/it, loss=2.3197, batch_acc=0.4375, running_acc=0.5134, grad=18.6937]Training epoch 9:  48%|████▊     | 15/31 [00:30<00:24,  1.53s/it, loss=2.1427, batch_acc=0.5625, running_acc=0.5167, grad=7.9566] Training epoch 9:  52%|█████▏    | 16/31 [00:32<00:22,  1.52s/it, loss=2.1427, batch_acc=0.5625, running_acc=0.5167, grad=7.9566]Training epoch 9:  52%|█████▏    | 16/31 [00:32<00:22,  1.52s/it, loss=1.9154, batch_acc=0.5625, running_acc=0.5195, grad=11.9069]Training epoch 9:  55%|█████▍    | 17/31 [00:33<00:21,  1.52s/it, loss=1.9154, batch_acc=0.5625, running_acc=0.5195, grad=11.9069]Training epoch 9:  55%|█████▍    | 17/31 [00:33<00:21,  1.52s/it, loss=2.3826, batch_acc=0.3438, running_acc=0.5092, grad=24.2670]Training epoch 9:  58%|█████▊    | 18/31 [00:35<00:19,  1.52s/it, loss=2.3826, batch_acc=0.3438, running_acc=0.5092, grad=24.2670]Training epoch 9:  58%|█████▊    | 18/31 [00:35<00:19,  1.52s/it, loss=2.3017, batch_acc=0.6250, running_acc=0.5156, grad=26.6486]Training epoch 9:  61%|██████▏   | 19/31 [00:36<00:18,  1.51s/it, loss=2.3017, batch_acc=0.6250, running_acc=0.5156, grad=26.6486]Training epoch 9:  61%|██████▏   | 19/31 [00:36<00:18,  1.51s/it, loss=2.1082, batch_acc=0.5625, running_acc=0.5181, grad=12.2408]Training epoch 9:  65%|██████▍   | 20/31 [00:38<00:16,  1.51s/it, loss=2.1082, batch_acc=0.5625, running_acc=0.5181, grad=12.2408]Training epoch 9:  65%|██████▍   | 20/31 [00:38<00:16,  1.51s/it, loss=2.1581, batch_acc=0.5312, running_acc=0.5188, grad=12.8847]Training epoch 9:  68%|██████▊   | 21/31 [00:39<00:15,  1.51s/it, loss=2.1581, batch_acc=0.5312, running_acc=0.5188, grad=12.8847]Training epoch 9:  68%|██████▊   | 21/31 [00:39<00:15,  1.51s/it, loss=2.1991, batch_acc=0.4375, running_acc=0.5149, grad=15.6810]Training epoch 9:  71%|███████   | 22/31 [00:41<00:13,  1.51s/it, loss=2.1991, batch_acc=0.4375, running_acc=0.5149, grad=15.6810]Training epoch 9:  71%|███████   | 22/31 [00:41<00:13,  1.51s/it, loss=1.9690, batch_acc=0.5938, running_acc=0.5185, grad=14.0594]Training epoch 9:  74%|███████▍  | 23/31 [00:42<00:12,  1.54s/it, loss=1.9690, batch_acc=0.5938, running_acc=0.5185, grad=14.0594]Training epoch 9:  74%|███████▍  | 23/31 [00:42<00:12,  1.54s/it, loss=1.9424, batch_acc=0.6250, running_acc=0.5231, grad=10.6811]Training epoch 9:  77%|███████▋  | 24/31 [00:44<00:10,  1.53s/it, loss=1.9424, batch_acc=0.6250, running_acc=0.5231, grad=10.6811]Training epoch 9:  77%|███████▋  | 24/31 [00:44<00:10,  1.53s/it, loss=2.1904, batch_acc=0.4375, running_acc=0.5195, grad=33.2522]Training epoch 9:  81%|████████  | 25/31 [00:45<00:09,  1.52s/it, loss=2.1904, batch_acc=0.4375, running_acc=0.5195, grad=33.2522]Training epoch 9:  81%|████████  | 25/31 [00:45<00:09,  1.52s/it, loss=2.1344, batch_acc=0.3750, running_acc=0.5138, grad=18.2975]Training epoch 9:  84%|████████▍ | 26/31 [00:47<00:07,  1.52s/it, loss=2.1344, batch_acc=0.3750, running_acc=0.5138, grad=18.2975]Training epoch 9:  84%|████████▍ | 26/31 [00:47<00:07,  1.52s/it, loss=2.0956, batch_acc=0.5000, running_acc=0.5132, grad=17.4685]Training epoch 9:  87%|████████▋ | 27/31 [00:48<00:06,  1.51s/it, loss=2.0956, batch_acc=0.5000, running_acc=0.5132, grad=17.4685]Training epoch 9:  87%|████████▋ | 27/31 [00:48<00:06,  1.51s/it, loss=2.1189, batch_acc=0.4375, running_acc=0.5104, grad=20.2800]Training epoch 9:  90%|█████████ | 28/31 [00:50<00:04,  1.51s/it, loss=2.1189, batch_acc=0.4375, running_acc=0.5104, grad=20.2800]Training epoch 9:  90%|█████████ | 28/31 [00:50<00:04,  1.51s/it, loss=2.1276, batch_acc=0.4688, running_acc=0.5089, grad=13.1075]Training epoch 9:  94%|█████████▎| 29/31 [00:51<00:03,  1.51s/it, loss=2.1276, batch_acc=0.4688, running_acc=0.5089, grad=13.1075]Training epoch 9:  94%|█████████▎| 29/31 [00:51<00:03,  1.51s/it, loss=2.3124, batch_acc=0.3750, running_acc=0.5043, grad=13.6413]Training epoch 9:  97%|█████████▋| 30/31 [00:53<00:01,  1.51s/it, loss=2.3124, batch_acc=0.3750, running_acc=0.5043, grad=13.6413]Training epoch 9:  97%|█████████▋| 30/31 [00:53<00:01,  1.51s/it, loss=2.0865, batch_acc=0.5312, running_acc=0.5052, grad=13.4682]Training epoch 9: 100%|██████████| 31/31 [00:53<00:00,  1.12s/it, loss=2.0865, batch_acc=0.5312, running_acc=0.5052, grad=13.4682]Training epoch 9: 100%|██████████| 31/31 [00:53<00:00,  1.12s/it, loss=3.5272, batch_acc=0.0000, running_acc=0.5042, grad=70.3916]Training epoch 9: 100%|██████████| 31/31 [00:53<00:00,  1.73s/it, loss=3.5272, batch_acc=0.0000, running_acc=0.5042, grad=70.3916]
Evaluation epoch 9:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 9:  20%|██        | 1/5 [00:06<00:26,  6.66s/it]Evaluation epoch 9:  20%|██        | 1/5 [00:06<00:26,  6.66s/it, loss=2.0196, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 9:  40%|████      | 2/5 [00:07<00:09,  3.18s/it, loss=2.0196, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 9:  40%|████      | 2/5 [00:07<00:09,  3.18s/it, loss=1.9614, batch_acc=0.5625, running_acc=0.5781]Evaluation epoch 9:  60%|██████    | 3/5 [00:08<00:04,  2.07s/it, loss=1.9614, batch_acc=0.5625, running_acc=0.5781]Evaluation epoch 9:  60%|██████    | 3/5 [00:08<00:04,  2.07s/it, loss=2.2589, batch_acc=0.4062, running_acc=0.5208]Evaluation epoch 9:  80%|████████  | 4/5 [00:09<00:01,  1.91s/it, loss=2.2589, batch_acc=0.4062, running_acc=0.5208]Evaluation epoch 9:  80%|████████  | 4/5 [00:09<00:01,  1.91s/it, loss=2.2824, batch_acc=0.4375, running_acc=0.5000]Evaluation epoch 9: 100%|██████████| 5/5 [00:10<00:00,  1.50s/it, loss=2.2824, batch_acc=0.4375, running_acc=0.5000]Evaluation epoch 9: 100%|██████████| 5/5 [00:10<00:00,  1.50s/it, loss=2.2947, batch_acc=0.4375, running_acc=0.4875]Evaluation epoch 9: 100%|██████████| 5/5 [00:10<00:00,  2.12s/it, loss=2.2947, batch_acc=0.4375, running_acc=0.4875]
Training epoch 10:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 10:   3%|▎         | 1/31 [00:09<04:49,  9.64s/it]Training epoch 10:   3%|▎         | 1/31 [00:09<04:49,  9.64s/it, loss=2.0414, batch_acc=0.5625, running_acc=0.5625, grad=22.4248]Training epoch 10:   6%|▋         | 2/31 [00:11<02:21,  4.87s/it, loss=2.0414, batch_acc=0.5625, running_acc=0.5625, grad=22.4248]Training epoch 10:   6%|▋         | 2/31 [00:11<02:21,  4.87s/it, loss=2.2341, batch_acc=0.4688, running_acc=0.5156, grad=18.1767]Training epoch 10:  10%|▉         | 3/31 [00:12<01:33,  3.34s/it, loss=2.2341, batch_acc=0.4688, running_acc=0.5156, grad=18.1767]Training epoch 10:  10%|▉         | 3/31 [00:12<01:33,  3.34s/it, loss=2.1916, batch_acc=0.5312, running_acc=0.5208, grad=11.6594]Training epoch 10:  13%|█▎        | 4/31 [00:14<01:11,  2.64s/it, loss=2.1916, batch_acc=0.5312, running_acc=0.5208, grad=11.6594]Training epoch 10:  13%|█▎        | 4/31 [00:14<01:11,  2.64s/it, loss=1.9304, batch_acc=0.6562, running_acc=0.5547, grad=59.0876]Training epoch 10:  16%|█▌        | 5/31 [00:15<00:58,  2.24s/it, loss=1.9304, batch_acc=0.6562, running_acc=0.5547, grad=59.0876]Training epoch 10:  16%|█▌        | 5/31 [00:15<00:58,  2.24s/it, loss=2.0276, batch_acc=0.5000, running_acc=0.5437, grad=13.9481]Training epoch 10:  19%|█▉        | 6/31 [00:17<00:49,  1.99s/it, loss=2.0276, batch_acc=0.5000, running_acc=0.5437, grad=13.9481]Training epoch 10:  19%|█▉        | 6/31 [00:17<00:49,  1.99s/it, loss=2.1506, batch_acc=0.5000, running_acc=0.5365, grad=8.9520] Training epoch 10:  23%|██▎       | 7/31 [00:18<00:43,  1.83s/it, loss=2.1506, batch_acc=0.5000, running_acc=0.5365, grad=8.9520]Training epoch 10:  23%|██▎       | 7/31 [00:18<00:43,  1.83s/it, loss=2.1125, batch_acc=0.5938, running_acc=0.5446, grad=18.8413]Training epoch 10:  26%|██▌       | 8/31 [00:20<00:40,  1.76s/it, loss=2.1125, batch_acc=0.5938, running_acc=0.5446, grad=18.8413]Training epoch 10:  26%|██▌       | 8/31 [00:20<00:40,  1.76s/it, loss=2.2255, batch_acc=0.4062, running_acc=0.5273, grad=13.6127]Training epoch 10:  29%|██▉       | 9/31 [00:21<00:37,  1.68s/it, loss=2.2255, batch_acc=0.4062, running_acc=0.5273, grad=13.6127]Training epoch 10:  29%|██▉       | 9/31 [00:21<00:37,  1.68s/it, loss=2.1671, batch_acc=0.4062, running_acc=0.5139, grad=98.0931]Training epoch 10:  32%|███▏      | 10/31 [00:23<00:34,  1.63s/it, loss=2.1671, batch_acc=0.4062, running_acc=0.5139, grad=98.0931]Training epoch 10:  32%|███▏      | 10/31 [00:23<00:34,  1.63s/it, loss=2.0252, batch_acc=0.5625, running_acc=0.5188, grad=10.9304]Training epoch 10:  35%|███▌      | 11/31 [00:24<00:31,  1.59s/it, loss=2.0252, batch_acc=0.5625, running_acc=0.5188, grad=10.9304]Training epoch 10:  35%|███▌      | 11/31 [00:24<00:31,  1.59s/it, loss=2.1562, batch_acc=0.5000, running_acc=0.5170, grad=22.3432]Training epoch 10:  39%|███▊      | 12/31 [00:30<00:51,  2.71s/it, loss=2.1562, batch_acc=0.5000, running_acc=0.5170, grad=22.3432]Training epoch 10:  39%|███▊      | 12/31 [00:30<00:51,  2.71s/it, loss=2.1418, batch_acc=0.4688, running_acc=0.5130, grad=16.5642]Training epoch 10:  42%|████▏     | 13/31 [00:31<00:42,  2.35s/it, loss=2.1418, batch_acc=0.4688, running_acc=0.5130, grad=16.5642]Training epoch 10:  42%|████▏     | 13/31 [00:31<00:42,  2.35s/it, loss=2.1833, batch_acc=0.4375, running_acc=0.5072, grad=9.2584] Training epoch 10:  45%|████▌     | 14/31 [00:33<00:35,  2.10s/it, loss=2.1833, batch_acc=0.4375, running_acc=0.5072, grad=9.2584]Training epoch 10:  45%|████▌     | 14/31 [00:33<00:35,  2.10s/it, loss=2.2656, batch_acc=0.3750, running_acc=0.4978, grad=17.2283]Training epoch 10:  48%|████▊     | 15/31 [00:34<00:30,  1.92s/it, loss=2.2656, batch_acc=0.3750, running_acc=0.4978, grad=17.2283]Training epoch 10:  48%|████▊     | 15/31 [00:34<00:30,  1.92s/it, loss=2.5085, batch_acc=0.3438, running_acc=0.4875, grad=12.1937]Training epoch 10:  52%|█████▏    | 16/31 [00:36<00:26,  1.80s/it, loss=2.5085, batch_acc=0.3438, running_acc=0.4875, grad=12.1937]Training epoch 10:  52%|█████▏    | 16/31 [00:36<00:26,  1.80s/it, loss=2.1364, batch_acc=0.4688, running_acc=0.4863, grad=11.8400]Training epoch 10:  55%|█████▍    | 17/31 [00:39<00:30,  2.16s/it, loss=2.1364, batch_acc=0.4688, running_acc=0.4863, grad=11.8400]Training epoch 10:  55%|█████▍    | 17/31 [00:39<00:30,  2.16s/it, loss=2.0072, batch_acc=0.5625, running_acc=0.4908, grad=17.0369]Training epoch 10:  58%|█████▊    | 18/31 [00:40<00:25,  1.97s/it, loss=2.0072, batch_acc=0.5625, running_acc=0.4908, grad=17.0369]Training epoch 10:  58%|█████▊    | 18/31 [00:40<00:25,  1.97s/it, loss=2.2644, batch_acc=0.3750, running_acc=0.4844, grad=27.9352]Training epoch 10:  61%|██████▏   | 19/31 [00:42<00:21,  1.83s/it, loss=2.2644, batch_acc=0.3750, running_acc=0.4844, grad=27.9352]Training epoch 10:  61%|██████▏   | 19/31 [00:42<00:21,  1.83s/it, loss=2.0200, batch_acc=0.5938, running_acc=0.4901, grad=19.5504]Training epoch 10:  65%|██████▍   | 20/31 [00:43<00:19,  1.73s/it, loss=2.0200, batch_acc=0.5938, running_acc=0.4901, grad=19.5504]Training epoch 10:  65%|██████▍   | 20/31 [00:43<00:19,  1.73s/it, loss=2.3652, batch_acc=0.3438, running_acc=0.4828, grad=14.4878]Training epoch 10:  68%|██████▊   | 21/31 [00:46<00:19,  1.95s/it, loss=2.3652, batch_acc=0.3438, running_acc=0.4828, grad=14.4878]Training epoch 10:  68%|██████▊   | 21/31 [00:46<00:19,  1.95s/it, loss=2.1585, batch_acc=0.4688, running_acc=0.4821, grad=14.9320]Training epoch 10:  71%|███████   | 22/31 [00:47<00:16,  1.82s/it, loss=2.1585, batch_acc=0.4688, running_acc=0.4821, grad=14.9320]Training epoch 10:  71%|███████   | 22/31 [00:47<00:16,  1.82s/it, loss=2.0776, batch_acc=0.5000, running_acc=0.4830, grad=9.5969] Training epoch 10:  74%|███████▍  | 23/31 [00:49<00:13,  1.72s/it, loss=2.0776, batch_acc=0.5000, running_acc=0.4830, grad=9.5969]Training epoch 10:  74%|███████▍  | 23/31 [00:49<00:13,  1.72s/it, loss=2.2299, batch_acc=0.4688, running_acc=0.4823, grad=19.4829]Training epoch 10:  77%|███████▋  | 24/31 [00:50<00:11,  1.66s/it, loss=2.2299, batch_acc=0.4688, running_acc=0.4823, grad=19.4829]Training epoch 10:  77%|███████▋  | 24/31 [00:50<00:11,  1.66s/it, loss=2.3966, batch_acc=0.3750, running_acc=0.4779, grad=10.8479]Training epoch 10:  81%|████████  | 25/31 [00:52<00:09,  1.61s/it, loss=2.3966, batch_acc=0.3750, running_acc=0.4779, grad=10.8479]Training epoch 10:  81%|████████  | 25/31 [00:52<00:09,  1.61s/it, loss=2.1207, batch_acc=0.6562, running_acc=0.4850, grad=65.7539]Training epoch 10:  84%|████████▍ | 26/31 [00:53<00:07,  1.58s/it, loss=2.1207, batch_acc=0.6562, running_acc=0.4850, grad=65.7539]Training epoch 10:  84%|████████▍ | 26/31 [00:53<00:07,  1.58s/it, loss=2.2280, batch_acc=0.4062, running_acc=0.4820, grad=7.1057] Training epoch 10:  87%|████████▋ | 27/31 [00:55<00:06,  1.56s/it, loss=2.2280, batch_acc=0.4062, running_acc=0.4820, grad=7.1057]Training epoch 10:  87%|████████▋ | 27/31 [00:55<00:06,  1.56s/it, loss=2.3132, batch_acc=0.4375, running_acc=0.4803, grad=13.9692]Training epoch 10:  90%|█████████ | 28/31 [00:56<00:04,  1.55s/it, loss=2.3132, batch_acc=0.4375, running_acc=0.4803, grad=13.9692]Training epoch 10:  90%|█████████ | 28/31 [00:56<00:04,  1.55s/it, loss=2.1209, batch_acc=0.4688, running_acc=0.4799, grad=14.9160]Training epoch 10:  94%|█████████▎| 29/31 [00:58<00:03,  1.53s/it, loss=2.1209, batch_acc=0.4688, running_acc=0.4799, grad=14.9160]Training epoch 10:  94%|█████████▎| 29/31 [00:58<00:03,  1.53s/it, loss=2.4016, batch_acc=0.4688, running_acc=0.4795, grad=14.9865]Training epoch 10:  97%|█████████▋| 30/31 [00:59<00:01,  1.52s/it, loss=2.4016, batch_acc=0.4688, running_acc=0.4795, grad=14.9865]Training epoch 10:  97%|█████████▋| 30/31 [00:59<00:01,  1.52s/it, loss=2.0326, batch_acc=0.6250, running_acc=0.4844, grad=10.3312]Training epoch 10: 100%|██████████| 31/31 [01:00<00:00,  1.13s/it, loss=2.0326, batch_acc=0.6250, running_acc=0.4844, grad=10.3312]Training epoch 10: 100%|██████████| 31/31 [01:00<00:00,  1.13s/it, loss=2.7509, batch_acc=0.0000, running_acc=0.4834, grad=20.3542]Training epoch 10: 100%|██████████| 31/31 [01:00<00:00,  1.94s/it, loss=2.7509, batch_acc=0.0000, running_acc=0.4834, grad=20.3542]
Evaluation epoch 10:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 10:  20%|██        | 1/5 [00:10<00:42, 10.72s/it]Evaluation epoch 10:  20%|██        | 1/5 [00:10<00:42, 10.72s/it, loss=1.9724, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 10:  40%|████      | 2/5 [00:11<00:14,  4.85s/it, loss=1.9724, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 10:  40%|████      | 2/5 [00:11<00:14,  4.85s/it, loss=1.7774, batch_acc=0.7188, running_acc=0.6719]Evaluation epoch 10:  60%|██████    | 3/5 [00:12<00:05,  2.98s/it, loss=1.7774, batch_acc=0.7188, running_acc=0.6719]Evaluation epoch 10:  60%|██████    | 3/5 [00:12<00:05,  2.98s/it, loss=2.3354, batch_acc=0.2812, running_acc=0.5417]Evaluation epoch 10:  80%|████████  | 4/5 [00:15<00:03,  3.21s/it, loss=2.3354, batch_acc=0.2812, running_acc=0.5417]Evaluation epoch 10:  80%|████████  | 4/5 [00:15<00:03,  3.21s/it, loss=2.4474, batch_acc=0.3125, running_acc=0.4844]Evaluation epoch 10: 100%|██████████| 5/5 [00:16<00:00,  2.33s/it, loss=2.4474, batch_acc=0.3125, running_acc=0.4844]Evaluation epoch 10: 100%|██████████| 5/5 [00:16<00:00,  2.33s/it, loss=2.2913, batch_acc=0.4062, running_acc=0.4688]Evaluation epoch 10: 100%|██████████| 5/5 [00:16<00:00,  3.31s/it, loss=2.2913, batch_acc=0.4062, running_acc=0.4688]
Training epoch 11:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 11:   3%|▎         | 1/31 [00:07<03:30,  7.03s/it]Training epoch 11:   3%|▎         | 1/31 [00:07<03:30,  7.03s/it, loss=2.2710, batch_acc=0.4688, running_acc=0.4688, grad=11.3266]Training epoch 11:   6%|▋         | 2/31 [00:08<01:49,  3.78s/it, loss=2.2710, batch_acc=0.4688, running_acc=0.4688, grad=11.3266]Training epoch 11:   6%|▋         | 2/31 [00:08<01:49,  3.78s/it, loss=2.3901, batch_acc=0.3750, running_acc=0.4219, grad=7.1146] Training epoch 11:  10%|▉         | 3/31 [00:10<01:16,  2.74s/it, loss=2.3901, batch_acc=0.3750, running_acc=0.4219, grad=7.1146]Training epoch 11:  10%|▉         | 3/31 [00:10<01:16,  2.74s/it, loss=2.1996, batch_acc=0.4688, running_acc=0.4375, grad=20.5911]Training epoch 11:  13%|█▎        | 4/31 [00:13<01:23,  3.08s/it, loss=2.1996, batch_acc=0.4688, running_acc=0.4375, grad=20.5911]Training epoch 11:  13%|█▎        | 4/31 [00:13<01:23,  3.08s/it, loss=2.0946, batch_acc=0.4375, running_acc=0.4375, grad=24.3243]Training epoch 11:  16%|█▌        | 5/31 [00:15<01:05,  2.51s/it, loss=2.0946, batch_acc=0.4375, running_acc=0.4375, grad=24.3243]Training epoch 11:  16%|█▌        | 5/31 [00:15<01:05,  2.51s/it, loss=2.0451, batch_acc=0.6562, running_acc=0.4813, grad=26.9058]Training epoch 11:  19%|█▉        | 6/31 [00:16<00:54,  2.17s/it, loss=2.0451, batch_acc=0.6562, running_acc=0.4813, grad=26.9058]Training epoch 11:  19%|█▉        | 6/31 [00:16<00:54,  2.17s/it, loss=2.3541, batch_acc=0.4375, running_acc=0.4740, grad=15.2729]Training epoch 11:  23%|██▎       | 7/31 [00:18<00:46,  1.95s/it, loss=2.3541, batch_acc=0.4375, running_acc=0.4740, grad=15.2729]Training epoch 11:  23%|██▎       | 7/31 [00:18<00:46,  1.95s/it, loss=2.1309, batch_acc=0.5312, running_acc=0.4821, grad=14.7148]Training epoch 11:  26%|██▌       | 8/31 [00:20<00:47,  2.08s/it, loss=2.1309, batch_acc=0.5312, running_acc=0.4821, grad=14.7148]Training epoch 11:  26%|██▌       | 8/31 [00:20<00:47,  2.08s/it, loss=2.1437, batch_acc=0.5938, running_acc=0.4961, grad=15.8861]Training epoch 11:  29%|██▉       | 9/31 [00:22<00:41,  1.90s/it, loss=2.1437, batch_acc=0.5938, running_acc=0.4961, grad=15.8861]Training epoch 11:  29%|██▉       | 9/31 [00:22<00:41,  1.90s/it, loss=2.0969, batch_acc=0.4375, running_acc=0.4896, grad=22.6630]Training epoch 11:  32%|███▏      | 10/31 [00:23<00:37,  1.78s/it, loss=2.0969, batch_acc=0.4375, running_acc=0.4896, grad=22.6630]Training epoch 11:  32%|███▏      | 10/31 [00:23<00:37,  1.78s/it, loss=1.9227, batch_acc=0.6562, running_acc=0.5062, grad=17.0873]Training epoch 11:  35%|███▌      | 11/31 [00:25<00:33,  1.70s/it, loss=1.9227, batch_acc=0.6562, running_acc=0.5062, grad=17.0873]Training epoch 11:  35%|███▌      | 11/31 [00:25<00:33,  1.70s/it, loss=2.2523, batch_acc=0.5000, running_acc=0.5057, grad=11.4891]Training epoch 11:  39%|███▊      | 12/31 [00:26<00:31,  1.64s/it, loss=2.2523, batch_acc=0.5000, running_acc=0.5057, grad=11.4891]Training epoch 11:  39%|███▊      | 12/31 [00:26<00:31,  1.64s/it, loss=2.1431, batch_acc=0.3750, running_acc=0.4948, grad=11.9340]Training epoch 11:  42%|████▏     | 13/31 [00:28<00:28,  1.60s/it, loss=2.1431, batch_acc=0.3750, running_acc=0.4948, grad=11.9340]Training epoch 11:  42%|████▏     | 13/31 [00:28<00:28,  1.60s/it, loss=2.0807, batch_acc=0.5625, running_acc=0.5000, grad=20.4190]Training epoch 11:  45%|████▌     | 14/31 [00:29<00:26,  1.57s/it, loss=2.0807, batch_acc=0.5625, running_acc=0.5000, grad=20.4190]Training epoch 11:  45%|████▌     | 14/31 [00:29<00:26,  1.57s/it, loss=2.0824, batch_acc=0.4688, running_acc=0.4978, grad=19.1688]Training epoch 11:  48%|████▊     | 15/31 [00:31<00:24,  1.55s/it, loss=2.0824, batch_acc=0.4688, running_acc=0.4978, grad=19.1688]Training epoch 11:  48%|████▊     | 15/31 [00:31<00:24,  1.55s/it, loss=2.0175, batch_acc=0.6250, running_acc=0.5062, grad=10.6587]Training epoch 11:  52%|█████▏    | 16/31 [00:32<00:24,  1.61s/it, loss=2.0175, batch_acc=0.6250, running_acc=0.5062, grad=10.6587]Training epoch 11:  52%|█████▏    | 16/31 [00:32<00:24,  1.61s/it, loss=1.7975, batch_acc=0.6875, running_acc=0.5176, grad=17.8454]Training epoch 11:  55%|█████▍    | 17/31 [00:34<00:22,  1.58s/it, loss=1.7975, batch_acc=0.6875, running_acc=0.5176, grad=17.8454]Training epoch 11:  55%|█████▍    | 17/31 [00:34<00:22,  1.58s/it, loss=2.0112, batch_acc=0.4688, running_acc=0.5147, grad=18.2481]Training epoch 11:  58%|█████▊    | 18/31 [00:35<00:20,  1.56s/it, loss=2.0112, batch_acc=0.4688, running_acc=0.5147, grad=18.2481]Training epoch 11:  58%|█████▊    | 18/31 [00:35<00:20,  1.56s/it, loss=2.1572, batch_acc=0.4062, running_acc=0.5087, grad=34.8034]Training epoch 11:  61%|██████▏   | 19/31 [00:37<00:18,  1.54s/it, loss=2.1572, batch_acc=0.4062, running_acc=0.5087, grad=34.8034]Training epoch 11:  61%|██████▏   | 19/31 [00:37<00:18,  1.54s/it, loss=1.9115, batch_acc=0.6250, running_acc=0.5148, grad=8.3926] Training epoch 11:  65%|██████▍   | 20/31 [00:39<00:17,  1.63s/it, loss=1.9115, batch_acc=0.6250, running_acc=0.5148, grad=8.3926]Training epoch 11:  65%|██████▍   | 20/31 [00:39<00:17,  1.63s/it, loss=2.1461, batch_acc=0.4375, running_acc=0.5109, grad=10.0259]Training epoch 11:  68%|██████▊   | 21/31 [00:40<00:15,  1.59s/it, loss=2.1461, batch_acc=0.4375, running_acc=0.5109, grad=10.0259]Training epoch 11:  68%|██████▊   | 21/31 [00:40<00:15,  1.59s/it, loss=2.2159, batch_acc=0.4688, running_acc=0.5089, grad=9.4433] Training epoch 11:  71%|███████   | 22/31 [00:42<00:14,  1.57s/it, loss=2.2159, batch_acc=0.4688, running_acc=0.5089, grad=9.4433]Training epoch 11:  71%|███████   | 22/31 [00:42<00:14,  1.57s/it, loss=1.9047, batch_acc=0.6250, running_acc=0.5142, grad=10.5566]Training epoch 11:  74%|███████▍  | 23/31 [00:43<00:12,  1.55s/it, loss=1.9047, batch_acc=0.6250, running_acc=0.5142, grad=10.5566]Training epoch 11:  74%|███████▍  | 23/31 [00:43<00:12,  1.55s/it, loss=1.9434, batch_acc=0.6250, running_acc=0.5190, grad=9.7919] Training epoch 11:  77%|███████▋  | 24/31 [00:45<00:10,  1.54s/it, loss=1.9434, batch_acc=0.6250, running_acc=0.5190, grad=9.7919]Training epoch 11:  77%|███████▋  | 24/31 [00:45<00:10,  1.54s/it, loss=2.2742, batch_acc=0.4062, running_acc=0.5143, grad=9.6377]Training epoch 11:  81%|████████  | 25/31 [00:46<00:09,  1.53s/it, loss=2.2742, batch_acc=0.4062, running_acc=0.5143, grad=9.6377]Training epoch 11:  81%|████████  | 25/31 [00:46<00:09,  1.53s/it, loss=2.1270, batch_acc=0.4062, running_acc=0.5100, grad=29.4214]Training epoch 11:  84%|████████▍ | 26/31 [00:48<00:07,  1.52s/it, loss=2.1270, batch_acc=0.4062, running_acc=0.5100, grad=29.4214]Training epoch 11:  84%|████████▍ | 26/31 [00:48<00:07,  1.52s/it, loss=2.3421, batch_acc=0.3125, running_acc=0.5024, grad=7.6699] Training epoch 11:  87%|████████▋ | 27/31 [00:49<00:06,  1.52s/it, loss=2.3421, batch_acc=0.3125, running_acc=0.5024, grad=7.6699]Training epoch 11:  87%|████████▋ | 27/31 [00:49<00:06,  1.52s/it, loss=2.1939, batch_acc=0.3750, running_acc=0.4977, grad=8.8163]Training epoch 11:  90%|█████████ | 28/31 [00:56<00:08,  2.98s/it, loss=2.1939, batch_acc=0.3750, running_acc=0.4977, grad=8.8163]Training epoch 11:  90%|█████████ | 28/31 [00:56<00:08,  2.98s/it, loss=2.0100, batch_acc=0.5938, running_acc=0.5011, grad=18.4600]Training epoch 11:  94%|█████████▎| 29/31 [00:57<00:05,  2.54s/it, loss=2.0100, batch_acc=0.5938, running_acc=0.5011, grad=18.4600]Training epoch 11:  94%|█████████▎| 29/31 [00:57<00:05,  2.54s/it, loss=2.4253, batch_acc=0.4062, running_acc=0.4978, grad=14.2918]Training epoch 11:  97%|█████████▋| 30/31 [00:59<00:02,  2.23s/it, loss=2.4253, batch_acc=0.4062, running_acc=0.4978, grad=14.2918]Training epoch 11:  97%|█████████▋| 30/31 [00:59<00:02,  2.23s/it, loss=2.2970, batch_acc=0.4062, running_acc=0.4948, grad=9.7954] Training epoch 11: 100%|██████████| 31/31 [00:59<00:00,  1.62s/it, loss=2.2970, batch_acc=0.4062, running_acc=0.4948, grad=9.7954]Training epoch 11: 100%|██████████| 31/31 [00:59<00:00,  1.62s/it, loss=1.3564, batch_acc=1.0000, running_acc=0.4958, grad=17.5045]Training epoch 11: 100%|██████████| 31/31 [00:59<00:00,  1.91s/it, loss=1.3564, batch_acc=1.0000, running_acc=0.4958, grad=17.5045]
Evaluation epoch 11:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 11:  20%|██        | 1/5 [00:04<00:19,  4.98s/it]Evaluation epoch 11:  20%|██        | 1/5 [00:04<00:19,  4.98s/it, loss=1.9193, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 11:  40%|████      | 2/5 [00:05<00:07,  2.49s/it, loss=1.9193, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 11:  40%|████      | 2/5 [00:05<00:07,  2.49s/it, loss=1.6663, batch_acc=0.7188, running_acc=0.6250]Evaluation epoch 11:  60%|██████    | 3/5 [00:06<00:03,  1.69s/it, loss=1.6663, batch_acc=0.7188, running_acc=0.6250]Evaluation epoch 11:  60%|██████    | 3/5 [00:06<00:03,  1.69s/it, loss=2.6217, batch_acc=0.2500, running_acc=0.5000]Evaluation epoch 11:  80%|████████  | 4/5 [00:12<00:03,  3.51s/it, loss=2.6217, batch_acc=0.2500, running_acc=0.5000]Evaluation epoch 11:  80%|████████  | 4/5 [00:12<00:03,  3.51s/it, loss=2.4596, batch_acc=0.3125, running_acc=0.4531]Evaluation epoch 11: 100%|██████████| 5/5 [00:13<00:00,  2.53s/it, loss=2.4596, batch_acc=0.3125, running_acc=0.4531]Evaluation epoch 11: 100%|██████████| 5/5 [00:13<00:00,  2.53s/it, loss=2.2669, batch_acc=0.3125, running_acc=0.4250]Evaluation epoch 11: 100%|██████████| 5/5 [00:13<00:00,  2.71s/it, loss=2.2669, batch_acc=0.3125, running_acc=0.4250]
Training epoch 12:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 12:   3%|▎         | 1/31 [00:05<02:53,  5.78s/it]Training epoch 12:   3%|▎         | 1/31 [00:05<02:53,  5.78s/it, loss=2.3385, batch_acc=0.5000, running_acc=0.5000, grad=16.0006]Training epoch 12:   6%|▋         | 2/31 [00:07<01:36,  3.32s/it, loss=2.3385, batch_acc=0.5000, running_acc=0.5000, grad=16.0006]Training epoch 12:   6%|▋         | 2/31 [00:07<01:36,  3.32s/it, loss=2.0024, batch_acc=0.5625, running_acc=0.5312, grad=10.8131]Training epoch 12:  10%|▉         | 3/31 [00:08<01:09,  2.49s/it, loss=2.0024, batch_acc=0.5625, running_acc=0.5312, grad=10.8131]Training epoch 12:  10%|▉         | 3/31 [00:08<01:09,  2.49s/it, loss=2.4120, batch_acc=0.3750, running_acc=0.4792, grad=19.4135]Training epoch 12:  13%|█▎        | 4/31 [00:10<00:56,  2.10s/it, loss=2.4120, batch_acc=0.3750, running_acc=0.4792, grad=19.4135]Training epoch 12:  13%|█▎        | 4/31 [00:10<00:56,  2.10s/it, loss=2.2643, batch_acc=0.5000, running_acc=0.4844, grad=17.5809]Training epoch 12:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=2.2643, batch_acc=0.5000, running_acc=0.4844, grad=17.5809]Training epoch 12:  16%|█▌        | 5/31 [00:12<00:49,  1.89s/it, loss=2.2687, batch_acc=0.5000, running_acc=0.4875, grad=34.0835]Training epoch 12:  19%|█▉        | 6/31 [00:13<00:46,  1.84s/it, loss=2.2687, batch_acc=0.5000, running_acc=0.4875, grad=34.0835]Training epoch 12:  19%|█▉        | 6/31 [00:13<00:46,  1.84s/it, loss=2.4034, batch_acc=0.5625, running_acc=0.5000, grad=23.9718]Training epoch 12:  23%|██▎       | 7/31 [00:15<00:41,  1.73s/it, loss=2.4034, batch_acc=0.5625, running_acc=0.5000, grad=23.9718]Training epoch 12:  23%|██▎       | 7/31 [00:15<00:41,  1.73s/it, loss=2.1542, batch_acc=0.4688, running_acc=0.4955, grad=64.0076]Training epoch 12:  26%|██▌       | 8/31 [00:16<00:38,  1.67s/it, loss=2.1542, batch_acc=0.4688, running_acc=0.4955, grad=64.0076]Training epoch 12:  26%|██▌       | 8/31 [00:16<00:38,  1.67s/it, loss=2.1029, batch_acc=0.5625, running_acc=0.5039, grad=7.4021] Training epoch 12:  29%|██▉       | 9/31 [00:18<00:35,  1.62s/it, loss=2.1029, batch_acc=0.5625, running_acc=0.5039, grad=7.4021]Training epoch 12:  29%|██▉       | 9/31 [00:18<00:35,  1.62s/it, loss=1.9120, batch_acc=0.5938, running_acc=0.5139, grad=11.4815]Training epoch 12:  32%|███▏      | 10/31 [00:19<00:33,  1.58s/it, loss=1.9120, batch_acc=0.5938, running_acc=0.5139, grad=11.4815]Training epoch 12:  32%|███▏      | 10/31 [00:19<00:33,  1.58s/it, loss=2.0116, batch_acc=0.4375, running_acc=0.5062, grad=54.9430]Training epoch 12:  35%|███▌      | 11/31 [00:21<00:31,  1.56s/it, loss=2.0116, batch_acc=0.4375, running_acc=0.5062, grad=54.9430]Training epoch 12:  35%|███▌      | 11/31 [00:21<00:31,  1.56s/it, loss=1.8793, batch_acc=0.6562, running_acc=0.5199, grad=14.1558]Training epoch 12:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.8793, batch_acc=0.6562, running_acc=0.5199, grad=14.1558]Training epoch 12:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=2.1565, batch_acc=0.3750, running_acc=0.5078, grad=10.9165]Training epoch 12:  42%|████▏     | 13/31 [00:24<00:27,  1.53s/it, loss=2.1565, batch_acc=0.3750, running_acc=0.5078, grad=10.9165]Training epoch 12:  42%|████▏     | 13/31 [00:24<00:27,  1.53s/it, loss=1.9097, batch_acc=0.6562, running_acc=0.5192, grad=20.4274]Training epoch 12:  45%|████▌     | 14/31 [00:25<00:25,  1.53s/it, loss=1.9097, batch_acc=0.6562, running_acc=0.5192, grad=20.4274]Training epoch 12:  45%|████▌     | 14/31 [00:25<00:25,  1.53s/it, loss=2.2017, batch_acc=0.3750, running_acc=0.5089, grad=11.0495]Training epoch 12:  48%|████▊     | 15/31 [00:27<00:24,  1.52s/it, loss=2.2017, batch_acc=0.3750, running_acc=0.5089, grad=11.0495]Training epoch 12:  48%|████▊     | 15/31 [00:27<00:24,  1.52s/it, loss=2.1488, batch_acc=0.3438, running_acc=0.4979, grad=13.8439]Training epoch 12:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=2.1488, batch_acc=0.3438, running_acc=0.4979, grad=13.8439]Training epoch 12:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=2.1382, batch_acc=0.5000, running_acc=0.4980, grad=13.4657]Training epoch 12:  55%|█████▍    | 17/31 [00:30<00:21,  1.52s/it, loss=2.1382, batch_acc=0.5000, running_acc=0.4980, grad=13.4657]Training epoch 12:  55%|█████▍    | 17/31 [00:30<00:21,  1.52s/it, loss=2.1829, batch_acc=0.5000, running_acc=0.4982, grad=13.5059]Training epoch 12:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=2.1829, batch_acc=0.5000, running_acc=0.4982, grad=13.5059]Training epoch 12:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=2.0686, batch_acc=0.5938, running_acc=0.5035, grad=10.0443]Training epoch 12:  61%|██████▏   | 19/31 [00:33<00:18,  1.52s/it, loss=2.0686, batch_acc=0.5938, running_acc=0.5035, grad=10.0443]Training epoch 12:  61%|██████▏   | 19/31 [00:33<00:18,  1.52s/it, loss=2.0754, batch_acc=0.5312, running_acc=0.5049, grad=22.2076]Training epoch 12:  65%|██████▍   | 20/31 [00:34<00:16,  1.52s/it, loss=2.0754, batch_acc=0.5312, running_acc=0.5049, grad=22.2076]Training epoch 12:  65%|██████▍   | 20/31 [00:34<00:16,  1.52s/it, loss=2.2263, batch_acc=0.4375, running_acc=0.5016, grad=21.4547]Training epoch 12:  68%|██████▊   | 21/31 [00:36<00:15,  1.52s/it, loss=2.2263, batch_acc=0.4375, running_acc=0.5016, grad=21.4547]Training epoch 12:  68%|██████▊   | 21/31 [00:36<00:15,  1.52s/it, loss=2.1330, batch_acc=0.5938, running_acc=0.5060, grad=8.5322] Training epoch 12:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=2.1330, batch_acc=0.5938, running_acc=0.5060, grad=8.5322]Training epoch 12:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=2.1995, batch_acc=0.4062, running_acc=0.5014, grad=10.3495]Training epoch 12:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=2.1995, batch_acc=0.4062, running_acc=0.5014, grad=10.3495]Training epoch 12:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.9372, batch_acc=0.6875, running_acc=0.5095, grad=17.3496]Training epoch 12:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.9372, batch_acc=0.6875, running_acc=0.5095, grad=17.3496]Training epoch 12:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=2.2470, batch_acc=0.4375, running_acc=0.5065, grad=36.7692]Training epoch 12:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=2.2470, batch_acc=0.4375, running_acc=0.5065, grad=36.7692]Training epoch 12:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=2.1674, batch_acc=0.5312, running_acc=0.5075, grad=10.9980]Training epoch 12:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=2.1674, batch_acc=0.5312, running_acc=0.5075, grad=10.9980]Training epoch 12:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=2.0981, batch_acc=0.5938, running_acc=0.5108, grad=13.7869]Training epoch 12:  87%|████████▋ | 27/31 [00:45<00:06,  1.51s/it, loss=2.0981, batch_acc=0.5938, running_acc=0.5108, grad=13.7869]Training epoch 12:  87%|████████▋ | 27/31 [00:45<00:06,  1.51s/it, loss=2.2306, batch_acc=0.4375, running_acc=0.5081, grad=19.4379]Training epoch 12:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=2.2306, batch_acc=0.4375, running_acc=0.5081, grad=19.4379]Training epoch 12:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=2.0702, batch_acc=0.5000, running_acc=0.5078, grad=10.0055]Training epoch 12:  94%|█████████▎| 29/31 [00:48<00:03,  1.51s/it, loss=2.0702, batch_acc=0.5000, running_acc=0.5078, grad=10.0055]Training epoch 12:  94%|█████████▎| 29/31 [00:48<00:03,  1.51s/it, loss=2.0329, batch_acc=0.6562, running_acc=0.5129, grad=8.8232] Training epoch 12:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=2.0329, batch_acc=0.6562, running_acc=0.5129, grad=8.8232]Training epoch 12:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=2.0228, batch_acc=0.5938, running_acc=0.5156, grad=7.0828]Training epoch 12: 100%|██████████| 31/31 [00:50<00:00,  1.12s/it, loss=2.0228, batch_acc=0.5938, running_acc=0.5156, grad=7.0828]Training epoch 12: 100%|██████████| 31/31 [00:50<00:00,  1.12s/it, loss=2.8146, batch_acc=0.5000, running_acc=0.5156, grad=26.6969]Training epoch 12: 100%|██████████| 31/31 [00:50<00:00,  1.62s/it, loss=2.8146, batch_acc=0.5000, running_acc=0.5156, grad=26.6969]
Evaluation epoch 12:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 12:  20%|██        | 1/5 [00:04<00:19,  4.82s/it]Evaluation epoch 12:  20%|██        | 1/5 [00:04<00:19,  4.82s/it, loss=1.9497, batch_acc=0.5000, running_acc=0.5000]Evaluation epoch 12:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.9497, batch_acc=0.5000, running_acc=0.5000]Evaluation epoch 12:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.5221, batch_acc=0.8125, running_acc=0.6562]Evaluation epoch 12:  60%|██████    | 3/5 [00:06<00:03,  1.65s/it, loss=1.5221, batch_acc=0.8125, running_acc=0.6562]Evaluation epoch 12:  60%|██████    | 3/5 [00:06<00:03,  1.65s/it, loss=2.3620, batch_acc=0.2500, running_acc=0.5208]Evaluation epoch 12:  80%|████████  | 4/5 [00:07<00:01,  1.49s/it, loss=2.3620, batch_acc=0.2500, running_acc=0.5208]Evaluation epoch 12:  80%|████████  | 4/5 [00:07<00:01,  1.49s/it, loss=2.3581, batch_acc=0.3438, running_acc=0.4766]Evaluation epoch 12: 100%|██████████| 5/5 [00:08<00:00,  1.23s/it, loss=2.3581, batch_acc=0.3438, running_acc=0.4766]Evaluation epoch 12: 100%|██████████| 5/5 [00:08<00:00,  1.23s/it, loss=2.1227, batch_acc=0.4688, running_acc=0.4750]Evaluation epoch 12: 100%|██████████| 5/5 [00:08<00:00,  1.66s/it, loss=2.1227, batch_acc=0.4688, running_acc=0.4750]
Training epoch 13:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 13:   3%|▎         | 1/31 [00:17<08:43, 17.46s/it]Training epoch 13:   3%|▎         | 1/31 [00:17<08:43, 17.46s/it, loss=2.0118, batch_acc=0.5000, running_acc=0.5000, grad=8.9106]Training epoch 13:   6%|▋         | 2/31 [00:18<03:54,  8.08s/it, loss=2.0118, batch_acc=0.5000, running_acc=0.5000, grad=8.9106]Training epoch 13:   6%|▋         | 2/31 [00:18<03:54,  8.08s/it, loss=2.2197, batch_acc=0.4688, running_acc=0.4844, grad=10.5952]Training epoch 13:  10%|▉         | 3/31 [00:20<02:22,  5.08s/it, loss=2.2197, batch_acc=0.4688, running_acc=0.4844, grad=10.5952]Training epoch 13:  10%|▉         | 3/31 [00:20<02:22,  5.08s/it, loss=1.9601, batch_acc=0.6250, running_acc=0.5312, grad=9.5373] Training epoch 13:  13%|█▎        | 4/31 [00:23<01:59,  4.43s/it, loss=1.9601, batch_acc=0.6250, running_acc=0.5312, grad=9.5373]Training epoch 13:  13%|█▎        | 4/31 [00:23<01:59,  4.43s/it, loss=2.2279, batch_acc=0.5000, running_acc=0.5234, grad=26.9091]Training epoch 13:  16%|█▌        | 5/31 [00:25<01:27,  3.38s/it, loss=2.2279, batch_acc=0.5000, running_acc=0.5234, grad=26.9091]Training epoch 13:  16%|█▌        | 5/31 [00:25<01:27,  3.38s/it, loss=2.1307, batch_acc=0.5938, running_acc=0.5375, grad=12.8595]Training epoch 13:  19%|█▉        | 6/31 [00:26<01:08,  2.74s/it, loss=2.1307, batch_acc=0.5938, running_acc=0.5375, grad=12.8595]Training epoch 13:  19%|█▉        | 6/31 [00:26<01:08,  2.74s/it, loss=1.9980, batch_acc=0.6562, running_acc=0.5573, grad=15.8669]Training epoch 13:  23%|██▎       | 7/31 [00:28<00:56,  2.34s/it, loss=1.9980, batch_acc=0.6562, running_acc=0.5573, grad=15.8669]Training epoch 13:  23%|██▎       | 7/31 [00:28<00:56,  2.34s/it, loss=2.3361, batch_acc=0.4688, running_acc=0.5446, grad=9.6691] Training epoch 13:  26%|██▌       | 8/31 [00:31<00:59,  2.60s/it, loss=2.3361, batch_acc=0.4688, running_acc=0.5446, grad=9.6691]Training epoch 13:  26%|██▌       | 8/31 [00:31<00:59,  2.60s/it, loss=2.1101, batch_acc=0.5938, running_acc=0.5508, grad=18.1112]Training epoch 13:  29%|██▉       | 9/31 [00:33<00:49,  2.27s/it, loss=2.1101, batch_acc=0.5938, running_acc=0.5508, grad=18.1112]Training epoch 13:  29%|██▉       | 9/31 [00:33<00:49,  2.27s/it, loss=1.9619, batch_acc=0.5938, running_acc=0.5556, grad=13.9654]Training epoch 13:  32%|███▏      | 10/31 [00:34<00:42,  2.04s/it, loss=1.9619, batch_acc=0.5938, running_acc=0.5556, grad=13.9654]Training epoch 13:  32%|███▏      | 10/31 [00:34<00:42,  2.04s/it, loss=2.3125, batch_acc=0.5312, running_acc=0.5531, grad=17.2637]Training epoch 13:  35%|███▌      | 11/31 [00:36<00:37,  1.87s/it, loss=2.3125, batch_acc=0.5312, running_acc=0.5531, grad=17.2637]Training epoch 13:  35%|███▌      | 11/31 [00:36<00:37,  1.87s/it, loss=1.9801, batch_acc=0.6250, running_acc=0.5597, grad=8.9466] Training epoch 13:  39%|███▊      | 12/31 [00:37<00:34,  1.80s/it, loss=1.9801, batch_acc=0.6250, running_acc=0.5597, grad=8.9466]Training epoch 13:  39%|███▊      | 12/31 [00:37<00:34,  1.80s/it, loss=2.0614, batch_acc=0.6250, running_acc=0.5651, grad=59.8459]Training epoch 13:  42%|████▏     | 13/31 [00:39<00:30,  1.71s/it, loss=2.0614, batch_acc=0.6250, running_acc=0.5651, grad=59.8459]Training epoch 13:  42%|████▏     | 13/31 [00:39<00:30,  1.71s/it, loss=2.1868, batch_acc=0.4688, running_acc=0.5577, grad=10.0213]Training epoch 13:  45%|████▌     | 14/31 [00:40<00:28,  1.65s/it, loss=2.1868, batch_acc=0.4688, running_acc=0.5577, grad=10.0213]Training epoch 13:  45%|████▌     | 14/31 [00:40<00:28,  1.65s/it, loss=2.1910, batch_acc=0.4688, running_acc=0.5513, grad=13.1066]Training epoch 13:  48%|████▊     | 15/31 [00:42<00:25,  1.61s/it, loss=2.1910, batch_acc=0.4688, running_acc=0.5513, grad=13.1066]Training epoch 13:  48%|████▊     | 15/31 [00:42<00:25,  1.61s/it, loss=2.2779, batch_acc=0.4375, running_acc=0.5437, grad=12.5461]Training epoch 13:  52%|█████▏    | 16/31 [00:44<00:26,  1.74s/it, loss=2.2779, batch_acc=0.4375, running_acc=0.5437, grad=12.5461]Training epoch 13:  52%|█████▏    | 16/31 [00:44<00:26,  1.74s/it, loss=2.0523, batch_acc=0.5625, running_acc=0.5449, grad=13.0054]Training epoch 13:  55%|█████▍    | 17/31 [00:45<00:23,  1.67s/it, loss=2.0523, batch_acc=0.5625, running_acc=0.5449, grad=13.0054]Training epoch 13:  55%|█████▍    | 17/31 [00:45<00:23,  1.67s/it, loss=1.8624, batch_acc=0.5625, running_acc=0.5460, grad=14.8083]Training epoch 13:  58%|█████▊    | 18/31 [00:47<00:21,  1.62s/it, loss=1.8624, batch_acc=0.5625, running_acc=0.5460, grad=14.8083]Training epoch 13:  58%|█████▊    | 18/31 [00:47<00:21,  1.62s/it, loss=1.9692, batch_acc=0.5312, running_acc=0.5451, grad=13.2434]Training epoch 13:  61%|██████▏   | 19/31 [00:48<00:19,  1.59s/it, loss=1.9692, batch_acc=0.5312, running_acc=0.5451, grad=13.2434]Training epoch 13:  61%|██████▏   | 19/31 [00:48<00:19,  1.59s/it, loss=1.9075, batch_acc=0.5938, running_acc=0.5477, grad=16.3776]Training epoch 13:  65%|██████▍   | 20/31 [01:01<00:52,  4.81s/it, loss=1.9075, batch_acc=0.5938, running_acc=0.5477, grad=16.3776]Training epoch 13:  65%|██████▍   | 20/31 [01:01<00:52,  4.81s/it, loss=1.9957, batch_acc=0.5625, running_acc=0.5484, grad=13.9808]Training epoch 13:  68%|██████▊   | 21/31 [01:02<00:38,  3.82s/it, loss=1.9957, batch_acc=0.5625, running_acc=0.5484, grad=13.9808]Training epoch 13:  68%|██████▊   | 21/31 [01:02<00:38,  3.82s/it, loss=2.1495, batch_acc=0.4375, running_acc=0.5432, grad=22.0650]Training epoch 13:  71%|███████   | 22/31 [01:04<00:28,  3.12s/it, loss=2.1495, batch_acc=0.4375, running_acc=0.5432, grad=22.0650]Training epoch 13:  71%|███████   | 22/31 [01:04<00:28,  3.12s/it, loss=2.0469, batch_acc=0.5000, running_acc=0.5412, grad=12.2079]Training epoch 13:  74%|███████▍  | 23/31 [01:05<00:21,  2.66s/it, loss=2.0469, batch_acc=0.5000, running_acc=0.5412, grad=12.2079]Training epoch 13:  74%|███████▍  | 23/31 [01:05<00:21,  2.66s/it, loss=1.9768, batch_acc=0.5938, running_acc=0.5435, grad=18.6247]Training epoch 13:  77%|███████▋  | 24/31 [01:07<00:16,  2.35s/it, loss=1.9768, batch_acc=0.5938, running_acc=0.5435, grad=18.6247]Training epoch 13:  77%|███████▋  | 24/31 [01:07<00:16,  2.35s/it, loss=1.7817, batch_acc=0.5625, running_acc=0.5443, grad=11.0654]Training epoch 13:  81%|████████  | 25/31 [01:08<00:12,  2.09s/it, loss=1.7817, batch_acc=0.5625, running_acc=0.5443, grad=11.0654]Training epoch 13:  81%|████████  | 25/31 [01:08<00:12,  2.09s/it, loss=1.8262, batch_acc=0.6562, running_acc=0.5487, grad=14.2580]Training epoch 13:  84%|████████▍ | 26/31 [01:10<00:09,  1.92s/it, loss=1.8262, batch_acc=0.6562, running_acc=0.5487, grad=14.2580]Training epoch 13:  84%|████████▍ | 26/31 [01:10<00:09,  1.92s/it, loss=1.9417, batch_acc=0.5625, running_acc=0.5493, grad=18.0655]Training epoch 13:  87%|████████▋ | 27/31 [01:11<00:07,  1.79s/it, loss=1.9417, batch_acc=0.5625, running_acc=0.5493, grad=18.0655]Training epoch 13:  87%|████████▋ | 27/31 [01:11<00:07,  1.79s/it, loss=1.9282, batch_acc=0.6250, running_acc=0.5521, grad=15.5632]Training epoch 13:  90%|█████████ | 28/31 [01:15<00:07,  2.33s/it, loss=1.9282, batch_acc=0.6250, running_acc=0.5521, grad=15.5632]Training epoch 13:  90%|█████████ | 28/31 [01:15<00:07,  2.33s/it, loss=1.8085, batch_acc=0.6250, running_acc=0.5547, grad=16.1419]Training epoch 13:  94%|█████████▎| 29/31 [01:17<00:04,  2.08s/it, loss=1.8085, batch_acc=0.6250, running_acc=0.5547, grad=16.1419]Training epoch 13:  94%|█████████▎| 29/31 [01:17<00:04,  2.08s/it, loss=1.8428, batch_acc=0.5938, running_acc=0.5560, grad=20.7776]Training epoch 13:  97%|█████████▋| 30/31 [01:18<00:01,  1.91s/it, loss=1.8428, batch_acc=0.5938, running_acc=0.5560, grad=20.7776]Training epoch 13:  97%|█████████▋| 30/31 [01:18<00:01,  1.91s/it, loss=2.0471, batch_acc=0.5312, running_acc=0.5552, grad=23.9206]Training epoch 13: 100%|██████████| 31/31 [01:18<00:00,  1.40s/it, loss=2.0471, batch_acc=0.5312, running_acc=0.5552, grad=23.9206]Training epoch 13: 100%|██████████| 31/31 [01:18<00:00,  1.40s/it, loss=2.0216, batch_acc=0.5000, running_acc=0.5551, grad=35.2687]Training epoch 13: 100%|██████████| 31/31 [01:18<00:00,  2.54s/it, loss=2.0216, batch_acc=0.5000, running_acc=0.5551, grad=35.2687]
Evaluation epoch 13:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 13:  20%|██        | 1/5 [00:11<00:46, 11.56s/it]Evaluation epoch 13:  20%|██        | 1/5 [00:11<00:46, 11.56s/it, loss=1.8548, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 13:  40%|████      | 2/5 [00:12<00:15,  5.20s/it, loss=1.8548, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 13:  40%|████      | 2/5 [00:12<00:15,  5.20s/it, loss=1.5883, batch_acc=0.7188, running_acc=0.6562]Evaluation epoch 13:  60%|██████    | 3/5 [00:13<00:06,  3.16s/it, loss=1.5883, batch_acc=0.7188, running_acc=0.6562]Evaluation epoch 13:  60%|██████    | 3/5 [00:13<00:06,  3.16s/it, loss=2.3327, batch_acc=0.2812, running_acc=0.5312]Evaluation epoch 13:  80%|████████  | 4/5 [00:14<00:02,  2.45s/it, loss=2.3327, batch_acc=0.2812, running_acc=0.5312]Evaluation epoch 13:  80%|████████  | 4/5 [00:14<00:02,  2.45s/it, loss=2.3067, batch_acc=0.3125, running_acc=0.4766]Evaluation epoch 13: 100%|██████████| 5/5 [00:15<00:00,  1.84s/it, loss=2.3067, batch_acc=0.3125, running_acc=0.4766]Evaluation epoch 13: 100%|██████████| 5/5 [00:15<00:00,  1.84s/it, loss=2.2063, batch_acc=0.4688, running_acc=0.4750]Evaluation epoch 13: 100%|██████████| 5/5 [00:15<00:00,  3.04s/it, loss=2.2063, batch_acc=0.4688, running_acc=0.4750]
Training epoch 14:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 14:   3%|▎         | 1/31 [00:13<06:52, 13.75s/it]Training epoch 14:   3%|▎         | 1/31 [00:13<06:52, 13.75s/it, loss=2.2238, batch_acc=0.5312, running_acc=0.5312, grad=15.7063]Training epoch 14:   6%|▋         | 2/31 [00:15<03:09,  6.55s/it, loss=2.2238, batch_acc=0.5312, running_acc=0.5312, grad=15.7063]Training epoch 14:   6%|▋         | 2/31 [00:15<03:09,  6.55s/it, loss=2.0943, batch_acc=0.5000, running_acc=0.5156, grad=9.5322] Training epoch 14:  10%|▉         | 3/31 [00:16<01:58,  4.24s/it, loss=2.0943, batch_acc=0.5000, running_acc=0.5156, grad=9.5322]Training epoch 14:  10%|▉         | 3/31 [00:16<01:58,  4.24s/it, loss=2.2618, batch_acc=0.3750, running_acc=0.4688, grad=11.6810]Training epoch 14:  13%|█▎        | 4/31 [00:21<01:57,  4.35s/it, loss=2.2618, batch_acc=0.3750, running_acc=0.4688, grad=11.6810]Training epoch 14:  13%|█▎        | 4/31 [00:21<01:57,  4.35s/it, loss=1.9900, batch_acc=0.5625, running_acc=0.4922, grad=52.7082]Training epoch 14:  16%|█▌        | 5/31 [00:22<01:26,  3.32s/it, loss=1.9900, batch_acc=0.5625, running_acc=0.4922, grad=52.7082]Training epoch 14:  16%|█▌        | 5/31 [00:22<01:26,  3.32s/it, loss=2.0810, batch_acc=0.5312, running_acc=0.5000, grad=9.1358] Training epoch 14:  19%|█▉        | 6/31 [00:24<01:07,  2.71s/it, loss=2.0810, batch_acc=0.5312, running_acc=0.5000, grad=9.1358]Training epoch 14:  19%|█▉        | 6/31 [00:24<01:07,  2.71s/it, loss=1.9998, batch_acc=0.6250, running_acc=0.5208, grad=16.1045]Training epoch 14:  23%|██▎       | 7/31 [00:25<00:55,  2.31s/it, loss=1.9998, batch_acc=0.6250, running_acc=0.5208, grad=16.1045]Training epoch 14:  23%|██▎       | 7/31 [00:25<00:55,  2.31s/it, loss=2.2369, batch_acc=0.3750, running_acc=0.5000, grad=24.7235]Training epoch 14:  26%|██▌       | 8/31 [00:28<00:58,  2.56s/it, loss=2.2369, batch_acc=0.3750, running_acc=0.5000, grad=24.7235]Training epoch 14:  26%|██▌       | 8/31 [00:28<00:58,  2.56s/it, loss=2.0256, batch_acc=0.4688, running_acc=0.4961, grad=10.5442]Training epoch 14:  29%|██▉       | 9/31 [00:30<00:49,  2.23s/it, loss=2.0256, batch_acc=0.4688, running_acc=0.4961, grad=10.5442]Training epoch 14:  29%|██▉       | 9/31 [00:30<00:49,  2.23s/it, loss=1.9166, batch_acc=0.6562, running_acc=0.5139, grad=53.9001]Training epoch 14:  32%|███▏      | 10/31 [00:31<00:42,  2.01s/it, loss=1.9166, batch_acc=0.6562, running_acc=0.5139, grad=53.9001]Training epoch 14:  32%|███▏      | 10/31 [00:31<00:42,  2.01s/it, loss=1.9423, batch_acc=0.5312, running_acc=0.5156, grad=14.0029]Training epoch 14:  35%|███▌      | 11/31 [00:33<00:37,  1.85s/it, loss=1.9423, batch_acc=0.5312, running_acc=0.5156, grad=14.0029]Training epoch 14:  35%|███▌      | 11/31 [00:33<00:37,  1.85s/it, loss=1.9844, batch_acc=0.5312, running_acc=0.5170, grad=14.2947]Training epoch 14:  39%|███▊      | 12/31 [00:35<00:37,  1.97s/it, loss=1.9844, batch_acc=0.5312, running_acc=0.5170, grad=14.2947]Training epoch 14:  39%|███▊      | 12/31 [00:35<00:37,  1.97s/it, loss=2.0542, batch_acc=0.5000, running_acc=0.5156, grad=12.9715]Training epoch 14:  42%|████▏     | 13/31 [00:37<00:32,  1.83s/it, loss=2.0542, batch_acc=0.5000, running_acc=0.5156, grad=12.9715]Training epoch 14:  42%|████▏     | 13/31 [00:37<00:32,  1.83s/it, loss=1.7076, batch_acc=0.6875, running_acc=0.5288, grad=11.8403]Training epoch 14:  45%|████▌     | 14/31 [00:38<00:29,  1.73s/it, loss=1.7076, batch_acc=0.6875, running_acc=0.5288, grad=11.8403]Training epoch 14:  45%|████▌     | 14/31 [00:38<00:29,  1.73s/it, loss=2.0731, batch_acc=0.5312, running_acc=0.5290, grad=77.5471]Training epoch 14:  48%|████▊     | 15/31 [00:40<00:26,  1.66s/it, loss=2.0731, batch_acc=0.5312, running_acc=0.5290, grad=77.5471]Training epoch 14:  48%|████▊     | 15/31 [00:40<00:26,  1.66s/it, loss=2.0127, batch_acc=0.5000, running_acc=0.5271, grad=19.3997]Training epoch 14:  52%|█████▏    | 16/31 [00:47<00:52,  3.48s/it, loss=2.0127, batch_acc=0.5000, running_acc=0.5271, grad=19.3997]Training epoch 14:  52%|█████▏    | 16/31 [00:47<00:52,  3.48s/it, loss=2.1362, batch_acc=0.5938, running_acc=0.5312, grad=13.6171]Training epoch 14:  55%|█████▍    | 17/31 [00:49<00:40,  2.89s/it, loss=2.1362, batch_acc=0.5938, running_acc=0.5312, grad=13.6171]Training epoch 14:  55%|█████▍    | 17/31 [00:49<00:40,  2.89s/it, loss=1.8174, batch_acc=0.5000, running_acc=0.5294, grad=7.8727] Training epoch 14:  58%|█████▊    | 18/31 [00:50<00:32,  2.48s/it, loss=1.8174, batch_acc=0.5000, running_acc=0.5294, grad=7.8727]Training epoch 14:  58%|█████▊    | 18/31 [00:50<00:32,  2.48s/it, loss=2.2183, batch_acc=0.3750, running_acc=0.5208, grad=14.2771]Training epoch 14:  61%|██████▏   | 19/31 [00:52<00:26,  2.19s/it, loss=2.2183, batch_acc=0.3750, running_acc=0.5208, grad=14.2771]Training epoch 14:  61%|██████▏   | 19/31 [00:52<00:26,  2.19s/it, loss=1.8882, batch_acc=0.5000, running_acc=0.5197, grad=12.5390]Training epoch 14:  65%|██████▍   | 20/31 [00:54<00:24,  2.18s/it, loss=1.8882, batch_acc=0.5000, running_acc=0.5197, grad=12.5390]Training epoch 14:  65%|██████▍   | 20/31 [00:54<00:24,  2.18s/it, loss=2.1573, batch_acc=0.3750, running_acc=0.5125, grad=16.0256]Training epoch 14:  68%|██████▊   | 21/31 [00:56<00:19,  1.98s/it, loss=2.1573, batch_acc=0.3750, running_acc=0.5125, grad=16.0256]Training epoch 14:  68%|██████▊   | 21/31 [00:56<00:19,  1.98s/it, loss=2.0716, batch_acc=0.4375, running_acc=0.5089, grad=9.9727] Training epoch 14:  71%|███████   | 22/31 [00:57<00:16,  1.84s/it, loss=2.0716, batch_acc=0.4375, running_acc=0.5089, grad=9.9727]Training epoch 14:  71%|███████   | 22/31 [00:57<00:16,  1.84s/it, loss=1.8148, batch_acc=0.6250, running_acc=0.5142, grad=17.8825]Training epoch 14:  74%|███████▍  | 23/31 [00:59<00:13,  1.74s/it, loss=1.8148, batch_acc=0.6250, running_acc=0.5142, grad=17.8825]Training epoch 14:  74%|███████▍  | 23/31 [00:59<00:13,  1.74s/it, loss=2.2248, batch_acc=0.3438, running_acc=0.5068, grad=24.0860]Training epoch 14:  77%|███████▋  | 24/31 [01:00<00:11,  1.67s/it, loss=2.2248, batch_acc=0.3438, running_acc=0.5068, grad=24.0860]Training epoch 14:  77%|███████▋  | 24/31 [01:00<00:11,  1.67s/it, loss=1.8496, batch_acc=0.5625, running_acc=0.5091, grad=11.6192]Training epoch 14:  81%|████████  | 25/31 [01:02<00:09,  1.62s/it, loss=1.8496, batch_acc=0.5625, running_acc=0.5091, grad=11.6192]Training epoch 14:  81%|████████  | 25/31 [01:02<00:09,  1.62s/it, loss=1.7210, batch_acc=0.6562, running_acc=0.5150, grad=7.5615] Training epoch 14:  84%|████████▍ | 26/31 [01:04<00:08,  1.73s/it, loss=1.7210, batch_acc=0.6562, running_acc=0.5150, grad=7.5615]Training epoch 14:  84%|████████▍ | 26/31 [01:04<00:08,  1.73s/it, loss=2.2695, batch_acc=0.4062, running_acc=0.5108, grad=40.5097]Training epoch 14:  87%|████████▋ | 27/31 [01:05<00:06,  1.66s/it, loss=2.2695, batch_acc=0.4062, running_acc=0.5108, grad=40.5097]Training epoch 14:  87%|████████▋ | 27/31 [01:05<00:06,  1.66s/it, loss=2.4075, batch_acc=0.3125, running_acc=0.5035, grad=33.3660]Training epoch 14:  90%|█████████ | 28/31 [01:10<00:08,  2.77s/it, loss=2.4075, batch_acc=0.3125, running_acc=0.5035, grad=33.3660]Training epoch 14:  90%|█████████ | 28/31 [01:10<00:08,  2.77s/it, loss=2.1760, batch_acc=0.4062, running_acc=0.5000, grad=13.7006]Training epoch 14:  94%|█████████▎| 29/31 [01:12<00:04,  2.39s/it, loss=2.1760, batch_acc=0.4062, running_acc=0.5000, grad=13.7006]Training epoch 14:  94%|█████████▎| 29/31 [01:12<00:04,  2.39s/it, loss=2.1646, batch_acc=0.5000, running_acc=0.5000, grad=10.7206]Training epoch 14:  97%|█████████▋| 30/31 [01:13<00:02,  2.13s/it, loss=2.1646, batch_acc=0.5000, running_acc=0.5000, grad=10.7206]Training epoch 14:  97%|█████████▋| 30/31 [01:13<00:02,  2.13s/it, loss=2.0998, batch_acc=0.4062, running_acc=0.4969, grad=29.4147]Training epoch 14: 100%|██████████| 31/31 [01:14<00:00,  1.55s/it, loss=2.0998, batch_acc=0.4062, running_acc=0.4969, grad=29.4147]Training epoch 14: 100%|██████████| 31/31 [01:14<00:00,  1.55s/it, loss=2.2863, batch_acc=0.5000, running_acc=0.4969, grad=21.9978]Training epoch 14: 100%|██████████| 31/31 [01:14<00:00,  2.39s/it, loss=2.2863, batch_acc=0.5000, running_acc=0.4969, grad=21.9978]
Evaluation epoch 14:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 14:  20%|██        | 1/5 [00:08<00:35,  8.80s/it]Evaluation epoch 14:  20%|██        | 1/5 [00:08<00:35,  8.80s/it, loss=1.6784, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 14:  40%|████      | 2/5 [00:09<00:12,  4.06s/it, loss=1.6784, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 14:  40%|████      | 2/5 [00:09<00:12,  4.06s/it, loss=1.5564, batch_acc=0.6250, running_acc=0.6406]Evaluation epoch 14:  60%|██████    | 3/5 [00:10<00:05,  2.54s/it, loss=1.5564, batch_acc=0.6250, running_acc=0.6406]Evaluation epoch 14:  60%|██████    | 3/5 [00:10<00:05,  2.54s/it, loss=2.6153, batch_acc=0.2188, running_acc=0.5000]Evaluation epoch 14:  80%|████████  | 4/5 [00:13<00:02,  2.67s/it, loss=2.6153, batch_acc=0.2188, running_acc=0.5000]Evaluation epoch 14:  80%|████████  | 4/5 [00:13<00:02,  2.67s/it, loss=2.3053, batch_acc=0.3125, running_acc=0.4531]Evaluation epoch 14: 100%|██████████| 5/5 [00:13<00:00,  1.99s/it, loss=2.3053, batch_acc=0.3125, running_acc=0.4531]Evaluation epoch 14: 100%|██████████| 5/5 [00:13<00:00,  1.99s/it, loss=2.2164, batch_acc=0.5000, running_acc=0.4625]Evaluation epoch 14: 100%|██████████| 5/5 [00:13<00:00,  2.79s/it, loss=2.2164, batch_acc=0.5000, running_acc=0.4625]
Training epoch 15:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 15:   3%|▎         | 1/31 [00:05<02:46,  5.54s/it]Training epoch 15:   3%|▎         | 1/31 [00:05<02:46,  5.54s/it, loss=1.8777, batch_acc=0.6250, running_acc=0.6250, grad=12.1799]Training epoch 15:   6%|▋         | 2/31 [00:07<01:31,  3.17s/it, loss=1.8777, batch_acc=0.6250, running_acc=0.6250, grad=12.1799]Training epoch 15:   6%|▋         | 2/31 [00:07<01:31,  3.17s/it, loss=2.0047, batch_acc=0.4688, running_acc=0.5469, grad=8.8303] Training epoch 15:  10%|▉         | 3/31 [00:08<01:07,  2.41s/it, loss=2.0047, batch_acc=0.4688, running_acc=0.5469, grad=8.8303]Training epoch 15:  10%|▉         | 3/31 [00:08<01:07,  2.41s/it, loss=2.3764, batch_acc=0.3125, running_acc=0.4688, grad=13.4768]Training epoch 15:  13%|█▎        | 4/31 [00:10<00:55,  2.06s/it, loss=2.3764, batch_acc=0.3125, running_acc=0.4688, grad=13.4768]Training epoch 15:  13%|█▎        | 4/31 [00:10<00:55,  2.06s/it, loss=1.7584, batch_acc=0.6250, running_acc=0.5078, grad=12.2500]Training epoch 15:  16%|█▌        | 5/31 [00:11<00:48,  1.86s/it, loss=1.7584, batch_acc=0.6250, running_acc=0.5078, grad=12.2500]Training epoch 15:  16%|█▌        | 5/31 [00:11<00:48,  1.86s/it, loss=1.8938, batch_acc=0.6562, running_acc=0.5375, grad=9.0040] Training epoch 15:  19%|█▉        | 6/31 [00:13<00:43,  1.74s/it, loss=1.8938, batch_acc=0.6562, running_acc=0.5375, grad=9.0040]Training epoch 15:  19%|█▉        | 6/31 [00:13<00:43,  1.74s/it, loss=1.9947, batch_acc=0.5938, running_acc=0.5469, grad=30.7328]Training epoch 15:  23%|██▎       | 7/31 [00:14<00:40,  1.67s/it, loss=1.9947, batch_acc=0.5938, running_acc=0.5469, grad=30.7328]Training epoch 15:  23%|██▎       | 7/31 [00:14<00:40,  1.67s/it, loss=1.9586, batch_acc=0.5312, running_acc=0.5446, grad=7.3505] Training epoch 15:  26%|██▌       | 8/31 [00:16<00:37,  1.62s/it, loss=1.9586, batch_acc=0.5312, running_acc=0.5446, grad=7.3505]Training epoch 15:  26%|██▌       | 8/31 [00:16<00:37,  1.62s/it, loss=2.2897, batch_acc=0.4062, running_acc=0.5273, grad=17.6032]Training epoch 15:  29%|██▉       | 9/31 [00:17<00:34,  1.59s/it, loss=2.2897, batch_acc=0.4062, running_acc=0.5273, grad=17.6032]Training epoch 15:  29%|██▉       | 9/31 [00:17<00:34,  1.59s/it, loss=2.0471, batch_acc=0.5000, running_acc=0.5243, grad=8.4115] Training epoch 15:  32%|███▏      | 10/31 [00:19<00:32,  1.56s/it, loss=2.0471, batch_acc=0.5000, running_acc=0.5243, grad=8.4115]Training epoch 15:  32%|███▏      | 10/31 [00:19<00:32,  1.56s/it, loss=2.0227, batch_acc=0.5312, running_acc=0.5250, grad=14.6498]Training epoch 15:  35%|███▌      | 11/31 [00:20<00:30,  1.54s/it, loss=2.0227, batch_acc=0.5312, running_acc=0.5250, grad=14.6498]Training epoch 15:  35%|███▌      | 11/31 [00:20<00:30,  1.54s/it, loss=1.9368, batch_acc=0.5625, running_acc=0.5284, grad=12.3895]Training epoch 15:  39%|███▊      | 12/31 [00:22<00:29,  1.53s/it, loss=1.9368, batch_acc=0.5625, running_acc=0.5284, grad=12.3895]Training epoch 15:  39%|███▊      | 12/31 [00:22<00:29,  1.53s/it, loss=2.0837, batch_acc=0.5312, running_acc=0.5286, grad=22.4900]Training epoch 15:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=2.0837, batch_acc=0.5312, running_acc=0.5286, grad=22.4900]Training epoch 15:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=2.1673, batch_acc=0.4688, running_acc=0.5240, grad=12.7479]Training epoch 15:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=2.1673, batch_acc=0.4688, running_acc=0.5240, grad=12.7479]Training epoch 15:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.8565, batch_acc=0.5625, running_acc=0.5268, grad=50.8491]Training epoch 15:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.8565, batch_acc=0.5625, running_acc=0.5268, grad=50.8491]Training epoch 15:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.8570, batch_acc=0.5625, running_acc=0.5292, grad=8.5541] Training epoch 15:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.8570, batch_acc=0.5625, running_acc=0.5292, grad=8.5541]Training epoch 15:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.8812, batch_acc=0.6875, running_acc=0.5391, grad=12.0978]Training epoch 15:  55%|█████▍    | 17/31 [00:29<00:21,  1.51s/it, loss=1.8812, batch_acc=0.6875, running_acc=0.5391, grad=12.0978]Training epoch 15:  55%|█████▍    | 17/31 [00:29<00:21,  1.51s/it, loss=1.8702, batch_acc=0.5000, running_acc=0.5368, grad=14.1224]Training epoch 15:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.8702, batch_acc=0.5000, running_acc=0.5368, grad=14.1224]Training epoch 15:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=2.3015, batch_acc=0.4062, running_acc=0.5295, grad=8.0076] Training epoch 15:  61%|██████▏   | 19/31 [00:32<00:18,  1.51s/it, loss=2.3015, batch_acc=0.4062, running_acc=0.5295, grad=8.0076]Training epoch 15:  61%|██████▏   | 19/31 [00:32<00:18,  1.51s/it, loss=2.0803, batch_acc=0.5625, running_acc=0.5312, grad=12.2003]Training epoch 15:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=2.0803, batch_acc=0.5625, running_acc=0.5312, grad=12.2003]Training epoch 15:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=2.0519, batch_acc=0.5312, running_acc=0.5312, grad=6.1449] Training epoch 15:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=2.0519, batch_acc=0.5312, running_acc=0.5312, grad=6.1449]Training epoch 15:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.9407, batch_acc=0.5312, running_acc=0.5312, grad=8.9332]Training epoch 15:  71%|███████   | 22/31 [00:37<00:13,  1.52s/it, loss=1.9407, batch_acc=0.5312, running_acc=0.5312, grad=8.9332]Training epoch 15:  71%|███████   | 22/31 [00:37<00:13,  1.52s/it, loss=1.9144, batch_acc=0.6875, running_acc=0.5384, grad=14.8625]Training epoch 15:  74%|███████▍  | 23/31 [00:38<00:12,  1.52s/it, loss=1.9144, batch_acc=0.6875, running_acc=0.5384, grad=14.8625]Training epoch 15:  74%|███████▍  | 23/31 [00:38<00:12,  1.52s/it, loss=2.1425, batch_acc=0.5312, running_acc=0.5380, grad=12.7630]Training epoch 15:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=2.1425, batch_acc=0.5312, running_acc=0.5380, grad=12.7630]Training epoch 15:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.6855, batch_acc=0.8125, running_acc=0.5495, grad=10.8377]Training epoch 15:  81%|████████  | 25/31 [00:41<00:09,  1.51s/it, loss=1.6855, batch_acc=0.8125, running_acc=0.5495, grad=10.8377]Training epoch 15:  81%|████████  | 25/31 [00:41<00:09,  1.51s/it, loss=1.9412, batch_acc=0.6562, running_acc=0.5537, grad=13.2453]Training epoch 15:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.9412, batch_acc=0.6562, running_acc=0.5537, grad=13.2453]Training epoch 15:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=2.0244, batch_acc=0.5312, running_acc=0.5529, grad=13.9457]Training epoch 15:  87%|████████▋ | 27/31 [00:44<00:06,  1.51s/it, loss=2.0244, batch_acc=0.5312, running_acc=0.5529, grad=13.9457]Training epoch 15:  87%|████████▋ | 27/31 [00:44<00:06,  1.51s/it, loss=2.0515, batch_acc=0.4688, running_acc=0.5498, grad=9.0055] Training epoch 15:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=2.0515, batch_acc=0.4688, running_acc=0.5498, grad=9.0055]Training epoch 15:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=1.8970, batch_acc=0.6875, running_acc=0.5547, grad=8.9525]Training epoch 15:  94%|█████████▎| 29/31 [00:47<00:03,  1.51s/it, loss=1.8970, batch_acc=0.6875, running_acc=0.5547, grad=8.9525]Training epoch 15:  94%|█████████▎| 29/31 [00:47<00:03,  1.51s/it, loss=1.7505, batch_acc=0.5938, running_acc=0.5560, grad=26.9524]Training epoch 15:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.7505, batch_acc=0.5938, running_acc=0.5560, grad=26.9524]Training epoch 15:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.6864, batch_acc=0.5625, running_acc=0.5563, grad=26.5972]Training epoch 15: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.6864, batch_acc=0.5625, running_acc=0.5563, grad=26.5972]Training epoch 15: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.8796, batch_acc=0.5000, running_acc=0.5561, grad=29.2174]Training epoch 15: 100%|██████████| 31/31 [00:49<00:00,  1.60s/it, loss=1.8796, batch_acc=0.5000, running_acc=0.5561, grad=29.2174]
Evaluation epoch 15:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 15:  20%|██        | 1/5 [00:04<00:19,  4.83s/it]Evaluation epoch 15:  20%|██        | 1/5 [00:04<00:19,  4.83s/it, loss=1.6674, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 15:  40%|████      | 2/5 [00:05<00:07,  2.43s/it, loss=1.6674, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 15:  40%|████      | 2/5 [00:05<00:07,  2.43s/it, loss=1.6041, batch_acc=0.6562, running_acc=0.6875]Evaluation epoch 15:  60%|██████    | 3/5 [00:06<00:03,  1.66s/it, loss=1.6041, batch_acc=0.6562, running_acc=0.6875]Evaluation epoch 15:  60%|██████    | 3/5 [00:06<00:03,  1.66s/it, loss=2.2218, batch_acc=0.5000, running_acc=0.6250]Evaluation epoch 15:  80%|████████  | 4/5 [00:07<00:01,  1.48s/it, loss=2.2218, batch_acc=0.5000, running_acc=0.6250]Evaluation epoch 15:  80%|████████  | 4/5 [00:07<00:01,  1.48s/it, loss=2.3484, batch_acc=0.3438, running_acc=0.5547]Evaluation epoch 15: 100%|██████████| 5/5 [00:08<00:00,  1.23s/it, loss=2.3484, batch_acc=0.3438, running_acc=0.5547]Evaluation epoch 15: 100%|██████████| 5/5 [00:08<00:00,  1.23s/it, loss=1.9961, batch_acc=0.6562, running_acc=0.5750]Evaluation epoch 15: 100%|██████████| 5/5 [00:08<00:00,  1.66s/it, loss=1.9961, batch_acc=0.6562, running_acc=0.5750]
Training epoch 16:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 16:   3%|▎         | 1/31 [00:07<03:59,  7.97s/it]Training epoch 16:   3%|▎         | 1/31 [00:07<03:59,  7.97s/it, loss=1.9893, batch_acc=0.6250, running_acc=0.6250, grad=10.0744]Training epoch 16:   6%|▋         | 2/31 [00:09<02:03,  4.25s/it, loss=1.9893, batch_acc=0.6250, running_acc=0.6250, grad=10.0744]Training epoch 16:   6%|▋         | 2/31 [00:09<02:03,  4.25s/it, loss=2.1107, batch_acc=0.4062, running_acc=0.5156, grad=15.3044]Training epoch 16:  10%|▉         | 3/31 [00:11<01:23,  3.00s/it, loss=2.1107, batch_acc=0.4062, running_acc=0.5156, grad=15.3044]Training epoch 16:  10%|▉         | 3/31 [00:11<01:23,  3.00s/it, loss=2.2078, batch_acc=0.5625, running_acc=0.5312, grad=7.8533] Training epoch 16:  13%|█▎        | 4/31 [00:12<01:05,  2.43s/it, loss=2.2078, batch_acc=0.5625, running_acc=0.5312, grad=7.8533]Training epoch 16:  13%|█▎        | 4/31 [00:12<01:05,  2.43s/it, loss=1.8558, batch_acc=0.6875, running_acc=0.5703, grad=7.2422]Training epoch 16:  16%|█▌        | 5/31 [00:14<00:54,  2.09s/it, loss=1.8558, batch_acc=0.6875, running_acc=0.5703, grad=7.2422]Training epoch 16:  16%|█▌        | 5/31 [00:14<00:54,  2.09s/it, loss=1.8115, batch_acc=0.5312, running_acc=0.5625, grad=7.1134]Training epoch 16:  19%|█▉        | 6/31 [00:16<00:56,  2.27s/it, loss=1.8115, batch_acc=0.5312, running_acc=0.5625, grad=7.1134]Training epoch 16:  19%|█▉        | 6/31 [00:16<00:56,  2.27s/it, loss=1.7962, batch_acc=0.6250, running_acc=0.5729, grad=58.5702]Training epoch 16:  23%|██▎       | 7/31 [00:18<00:48,  2.02s/it, loss=1.7962, batch_acc=0.6250, running_acc=0.5729, grad=58.5702]Training epoch 16:  23%|██▎       | 7/31 [00:18<00:48,  2.02s/it, loss=1.9539, batch_acc=0.5312, running_acc=0.5670, grad=8.8627] Training epoch 16:  26%|██▌       | 8/31 [00:19<00:42,  1.86s/it, loss=1.9539, batch_acc=0.5312, running_acc=0.5670, grad=8.8627]Training epoch 16:  26%|██▌       | 8/31 [00:19<00:42,  1.86s/it, loss=1.8149, batch_acc=0.6250, running_acc=0.5742, grad=6.1748]Training epoch 16:  29%|██▉       | 9/31 [00:21<00:38,  1.75s/it, loss=1.8149, batch_acc=0.6250, running_acc=0.5742, grad=6.1748]Training epoch 16:  29%|██▉       | 9/31 [00:21<00:38,  1.75s/it, loss=1.6345, batch_acc=0.6250, running_acc=0.5799, grad=11.0527]Training epoch 16:  32%|███▏      | 10/31 [00:25<00:53,  2.55s/it, loss=1.6345, batch_acc=0.6250, running_acc=0.5799, grad=11.0527]Training epoch 16:  32%|███▏      | 10/31 [00:25<00:53,  2.55s/it, loss=1.8548, batch_acc=0.5938, running_acc=0.5813, grad=9.2974] Training epoch 16:  35%|███▌      | 11/31 [00:27<00:44,  2.23s/it, loss=1.8548, batch_acc=0.5938, running_acc=0.5813, grad=9.2974]Training epoch 16:  35%|███▌      | 11/31 [00:27<00:44,  2.23s/it, loss=2.2985, batch_acc=0.3125, running_acc=0.5568, grad=16.1073]Training epoch 16:  39%|███▊      | 12/31 [00:28<00:38,  2.01s/it, loss=2.2985, batch_acc=0.3125, running_acc=0.5568, grad=16.1073]Training epoch 16:  39%|███▊      | 12/31 [00:28<00:38,  2.01s/it, loss=1.8954, batch_acc=0.5000, running_acc=0.5521, grad=9.9357] Training epoch 16:  42%|████▏     | 13/31 [00:30<00:33,  1.86s/it, loss=1.8954, batch_acc=0.5000, running_acc=0.5521, grad=9.9357]Training epoch 16:  42%|████▏     | 13/31 [00:30<00:33,  1.86s/it, loss=1.9670, batch_acc=0.5000, running_acc=0.5481, grad=8.5967]Training epoch 16:  45%|████▌     | 14/31 [00:33<00:37,  2.23s/it, loss=1.9670, batch_acc=0.5000, running_acc=0.5481, grad=8.5967]Training epoch 16:  45%|████▌     | 14/31 [00:33<00:37,  2.23s/it, loss=1.7087, batch_acc=0.6250, running_acc=0.5536, grad=17.8155]Training epoch 16:  48%|████▊     | 15/31 [00:34<00:32,  2.01s/it, loss=1.7087, batch_acc=0.6250, running_acc=0.5536, grad=17.8155]Training epoch 16:  48%|████▊     | 15/31 [00:34<00:32,  2.01s/it, loss=1.8266, batch_acc=0.6562, running_acc=0.5604, grad=33.4484]Training epoch 16:  52%|█████▏    | 16/31 [00:36<00:27,  1.87s/it, loss=1.8266, batch_acc=0.6562, running_acc=0.5604, grad=33.4484]Training epoch 16:  52%|█████▏    | 16/31 [00:36<00:27,  1.87s/it, loss=1.8788, batch_acc=0.6562, running_acc=0.5664, grad=22.3666]Training epoch 16:  55%|█████▍    | 17/31 [00:37<00:24,  1.76s/it, loss=1.8788, batch_acc=0.6562, running_acc=0.5664, grad=22.3666]Training epoch 16:  55%|█████▍    | 17/31 [00:37<00:24,  1.76s/it, loss=1.8286, batch_acc=0.5312, running_acc=0.5643, grad=10.2967]Training epoch 16:  58%|█████▊    | 18/31 [00:48<00:58,  4.47s/it, loss=1.8286, batch_acc=0.5312, running_acc=0.5643, grad=10.2967]Training epoch 16:  58%|█████▊    | 18/31 [00:48<00:58,  4.47s/it, loss=1.8712, batch_acc=0.5625, running_acc=0.5642, grad=39.1270]Training epoch 16:  61%|██████▏   | 19/31 [00:50<00:42,  3.58s/it, loss=1.8712, batch_acc=0.5625, running_acc=0.5642, grad=39.1270]Training epoch 16:  61%|██████▏   | 19/31 [00:50<00:42,  3.58s/it, loss=1.8546, batch_acc=0.6562, running_acc=0.5691, grad=12.4055]Training epoch 16:  65%|██████▍   | 20/31 [00:51<00:32,  2.96s/it, loss=1.8546, batch_acc=0.6562, running_acc=0.5691, grad=12.4055]Training epoch 16:  65%|██████▍   | 20/31 [00:51<00:32,  2.96s/it, loss=1.8296, batch_acc=0.5312, running_acc=0.5672, grad=8.4485] Training epoch 16:  68%|██████▊   | 21/31 [00:53<00:25,  2.52s/it, loss=1.8296, batch_acc=0.5312, running_acc=0.5672, grad=8.4485]Training epoch 16:  68%|██████▊   | 21/31 [00:53<00:25,  2.52s/it, loss=1.9200, batch_acc=0.5625, running_acc=0.5670, grad=9.9583]Training epoch 16:  71%|███████   | 22/31 [00:58<00:31,  3.48s/it, loss=1.9200, batch_acc=0.5625, running_acc=0.5670, grad=9.9583]Training epoch 16:  71%|███████   | 22/31 [00:58<00:31,  3.48s/it, loss=1.8415, batch_acc=0.6562, running_acc=0.5710, grad=8.7924]Training epoch 16:  74%|███████▍  | 23/31 [01:00<00:23,  2.88s/it, loss=1.8415, batch_acc=0.6562, running_acc=0.5710, grad=8.7924]Training epoch 16:  74%|███████▍  | 23/31 [01:00<00:23,  2.88s/it, loss=1.9132, batch_acc=0.5625, running_acc=0.5707, grad=14.1838]Training epoch 16:  77%|███████▋  | 24/31 [01:01<00:17,  2.47s/it, loss=1.9132, batch_acc=0.5625, running_acc=0.5707, grad=14.1838]Training epoch 16:  77%|███████▋  | 24/31 [01:01<00:17,  2.47s/it, loss=1.8081, batch_acc=0.6875, running_acc=0.5755, grad=9.7708] Training epoch 16:  81%|████████  | 25/31 [01:03<00:13,  2.18s/it, loss=1.8081, batch_acc=0.6875, running_acc=0.5755, grad=9.7708]Training epoch 16:  81%|████████  | 25/31 [01:03<00:13,  2.18s/it, loss=1.7968, batch_acc=0.6250, running_acc=0.5775, grad=13.4580]Training epoch 16:  84%|████████▍ | 26/31 [01:09<00:16,  3.26s/it, loss=1.7968, batch_acc=0.6250, running_acc=0.5775, grad=13.4580]Training epoch 16:  84%|████████▍ | 26/31 [01:09<00:16,  3.26s/it, loss=1.9204, batch_acc=0.5312, running_acc=0.5757, grad=14.9216]Training epoch 16:  87%|████████▋ | 27/31 [01:10<00:10,  2.73s/it, loss=1.9204, batch_acc=0.5312, running_acc=0.5757, grad=14.9216]Training epoch 16:  87%|████████▋ | 27/31 [01:10<00:10,  2.73s/it, loss=2.1864, batch_acc=0.4688, running_acc=0.5718, grad=10.1677]Training epoch 16:  90%|█████████ | 28/31 [01:12<00:07,  2.36s/it, loss=2.1864, batch_acc=0.4688, running_acc=0.5718, grad=10.1677]Training epoch 16:  90%|█████████ | 28/31 [01:12<00:07,  2.36s/it, loss=1.7006, batch_acc=0.6250, running_acc=0.5737, grad=17.3646]Training epoch 16:  94%|█████████▎| 29/31 [01:13<00:04,  2.10s/it, loss=1.7006, batch_acc=0.6250, running_acc=0.5737, grad=17.3646]Training epoch 16:  94%|█████████▎| 29/31 [01:13<00:04,  2.10s/it, loss=1.7819, batch_acc=0.5312, running_acc=0.5722, grad=78.1195]Training epoch 16:  97%|█████████▋| 30/31 [01:15<00:01,  1.92s/it, loss=1.7819, batch_acc=0.5312, running_acc=0.5722, grad=78.1195]Training epoch 16:  97%|█████████▋| 30/31 [01:15<00:01,  1.92s/it, loss=2.1573, batch_acc=0.5000, running_acc=0.5698, grad=11.8138]Training epoch 16: 100%|██████████| 31/31 [01:15<00:00,  1.41s/it, loss=2.1573, batch_acc=0.5000, running_acc=0.5698, grad=11.8138]Training epoch 16: 100%|██████████| 31/31 [01:15<00:00,  1.41s/it, loss=1.7249, batch_acc=0.5000, running_acc=0.5696, grad=22.1558]Training epoch 16: 100%|██████████| 31/31 [01:15<00:00,  2.43s/it, loss=1.7249, batch_acc=0.5000, running_acc=0.5696, grad=22.1558]
Evaluation epoch 16:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 16:  20%|██        | 1/5 [00:12<00:50, 12.54s/it]Evaluation epoch 16:  20%|██        | 1/5 [00:12<00:50, 12.54s/it, loss=1.7401, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 16:  40%|████      | 2/5 [00:13<00:16,  5.60s/it, loss=1.7401, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 16:  40%|████      | 2/5 [00:13<00:16,  5.60s/it, loss=1.5441, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 16:  60%|██████    | 3/5 [00:14<00:06,  3.38s/it, loss=1.5441, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 16:  60%|██████    | 3/5 [00:14<00:06,  3.38s/it, loss=2.2187, batch_acc=0.3438, running_acc=0.5938]Evaluation epoch 16:  80%|████████  | 4/5 [00:18<00:03,  3.99s/it, loss=2.2187, batch_acc=0.3438, running_acc=0.5938]Evaluation epoch 16:  80%|████████  | 4/5 [00:18<00:03,  3.99s/it, loss=2.2683, batch_acc=0.3438, running_acc=0.5312]Evaluation epoch 16: 100%|██████████| 5/5 [00:19<00:00,  2.84s/it, loss=2.2683, batch_acc=0.3438, running_acc=0.5312]Evaluation epoch 16: 100%|██████████| 5/5 [00:19<00:00,  2.84s/it, loss=1.9714, batch_acc=0.6250, running_acc=0.5500]Evaluation epoch 16: 100%|██████████| 5/5 [00:19<00:00,  3.95s/it, loss=1.9714, batch_acc=0.6250, running_acc=0.5500]
Training epoch 17:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 17:   3%|▎         | 1/31 [00:11<05:56, 11.87s/it]Training epoch 17:   3%|▎         | 1/31 [00:11<05:56, 11.87s/it, loss=1.8031, batch_acc=0.5312, running_acc=0.5312, grad=13.2202]Training epoch 17:   6%|▋         | 2/31 [00:13<02:47,  5.78s/it, loss=1.8031, batch_acc=0.5312, running_acc=0.5312, grad=13.2202]Training epoch 17:   6%|▋         | 2/31 [00:13<02:47,  5.78s/it, loss=1.7669, batch_acc=0.6250, running_acc=0.5781, grad=9.6029] Training epoch 17:  10%|▉         | 3/31 [00:14<01:47,  3.83s/it, loss=1.7669, batch_acc=0.6250, running_acc=0.5781, grad=9.6029]Training epoch 17:  10%|▉         | 3/31 [00:14<01:47,  3.83s/it, loss=2.0166, batch_acc=0.5938, running_acc=0.5833, grad=18.4794]Training epoch 17:  13%|█▎        | 4/31 [00:16<01:18,  2.91s/it, loss=2.0166, batch_acc=0.5938, running_acc=0.5833, grad=18.4794]Training epoch 17:  13%|█▎        | 4/31 [00:16<01:18,  2.91s/it, loss=1.7050, batch_acc=0.6875, running_acc=0.6094, grad=9.5161] Training epoch 17:  16%|█▌        | 5/31 [00:17<01:02,  2.41s/it, loss=1.7050, batch_acc=0.6875, running_acc=0.6094, grad=9.5161]Training epoch 17:  16%|█▌        | 5/31 [00:17<01:02,  2.41s/it, loss=1.7849, batch_acc=0.6562, running_acc=0.6188, grad=9.6831]Training epoch 17:  19%|█▉        | 6/31 [00:19<00:52,  2.10s/it, loss=1.7849, batch_acc=0.6562, running_acc=0.6188, grad=9.6831]Training epoch 17:  19%|█▉        | 6/31 [00:19<00:52,  2.10s/it, loss=1.7821, batch_acc=0.7500, running_acc=0.6406, grad=7.8307]Training epoch 17:  23%|██▎       | 7/31 [00:20<00:45,  1.91s/it, loss=1.7821, batch_acc=0.7500, running_acc=0.6406, grad=7.8307]Training epoch 17:  23%|██▎       | 7/31 [00:20<00:45,  1.91s/it, loss=1.5813, batch_acc=0.7500, running_acc=0.6562, grad=7.8476]Training epoch 17:  26%|██▌       | 8/31 [00:23<00:46,  2.02s/it, loss=1.5813, batch_acc=0.7500, running_acc=0.6562, grad=7.8476]Training epoch 17:  26%|██▌       | 8/31 [00:23<00:46,  2.02s/it, loss=2.1534, batch_acc=0.4688, running_acc=0.6328, grad=14.0042]Training epoch 17:  29%|██▉       | 9/31 [00:24<00:40,  1.86s/it, loss=2.1534, batch_acc=0.4688, running_acc=0.6328, grad=14.0042]Training epoch 17:  29%|██▉       | 9/31 [00:24<00:40,  1.86s/it, loss=1.8242, batch_acc=0.5000, running_acc=0.6181, grad=12.8147]Training epoch 17:  32%|███▏      | 10/31 [00:26<00:36,  1.76s/it, loss=1.8242, batch_acc=0.5000, running_acc=0.6181, grad=12.8147]Training epoch 17:  32%|███▏      | 10/31 [00:26<00:36,  1.76s/it, loss=1.7947, batch_acc=0.6875, running_acc=0.6250, grad=17.6601]Training epoch 17:  35%|███▌      | 11/31 [00:27<00:33,  1.68s/it, loss=1.7947, batch_acc=0.6875, running_acc=0.6250, grad=17.6601]Training epoch 17:  35%|███▌      | 11/31 [00:27<00:33,  1.68s/it, loss=2.0176, batch_acc=0.4688, running_acc=0.6108, grad=13.7277]Training epoch 17:  39%|███▊      | 12/31 [00:29<00:30,  1.63s/it, loss=2.0176, batch_acc=0.4688, running_acc=0.6108, grad=13.7277]Training epoch 17:  39%|███▊      | 12/31 [00:29<00:30,  1.63s/it, loss=1.7621, batch_acc=0.5938, running_acc=0.6094, grad=19.7936]Training epoch 17:  42%|████▏     | 13/31 [00:30<00:28,  1.59s/it, loss=1.7621, batch_acc=0.5938, running_acc=0.6094, grad=19.7936]Training epoch 17:  42%|████▏     | 13/31 [00:30<00:28,  1.59s/it, loss=1.9806, batch_acc=0.6562, running_acc=0.6130, grad=21.0903]Training epoch 17:  45%|████▌     | 14/31 [00:36<00:48,  2.85s/it, loss=1.9806, batch_acc=0.6562, running_acc=0.6130, grad=21.0903]Training epoch 17:  45%|████▌     | 14/31 [00:36<00:48,  2.85s/it, loss=2.0304, batch_acc=0.5000, running_acc=0.6049, grad=6.8588] Training epoch 17:  48%|████▊     | 15/31 [00:38<00:39,  2.45s/it, loss=2.0304, batch_acc=0.5000, running_acc=0.6049, grad=6.8588]Training epoch 17:  48%|████▊     | 15/31 [00:38<00:39,  2.45s/it, loss=2.0150, batch_acc=0.5938, running_acc=0.6042, grad=18.9529]Training epoch 17:  52%|█████▏    | 16/31 [00:39<00:32,  2.17s/it, loss=2.0150, batch_acc=0.5938, running_acc=0.6042, grad=18.9529]Training epoch 17:  52%|█████▏    | 16/31 [00:39<00:32,  2.17s/it, loss=2.0574, batch_acc=0.5000, running_acc=0.5977, grad=11.2015]Training epoch 17:  55%|█████▍    | 17/31 [00:41<00:27,  1.97s/it, loss=2.0574, batch_acc=0.5000, running_acc=0.5977, grad=11.2015]Training epoch 17:  55%|█████▍    | 17/31 [00:41<00:27,  1.97s/it, loss=2.1206, batch_acc=0.5000, running_acc=0.5919, grad=8.6864] Training epoch 17:  58%|█████▊    | 18/31 [00:48<00:45,  3.53s/it, loss=2.1206, batch_acc=0.5000, running_acc=0.5919, grad=8.6864]Training epoch 17:  58%|█████▊    | 18/31 [00:48<00:45,  3.53s/it, loss=2.0709, batch_acc=0.5000, running_acc=0.5868, grad=6.8783]Training epoch 17:  61%|██████▏   | 19/31 [00:49<00:35,  2.92s/it, loss=2.0709, batch_acc=0.5000, running_acc=0.5868, grad=6.8783]Training epoch 17:  61%|██████▏   | 19/31 [00:49<00:35,  2.92s/it, loss=1.9018, batch_acc=0.5938, running_acc=0.5872, grad=29.8037]Training epoch 17:  65%|██████▍   | 20/31 [00:51<00:27,  2.50s/it, loss=1.9018, batch_acc=0.5938, running_acc=0.5872, grad=29.8037]Training epoch 17:  65%|██████▍   | 20/31 [00:51<00:27,  2.50s/it, loss=2.2486, batch_acc=0.4375, running_acc=0.5797, grad=15.7898]Training epoch 17:  68%|██████▊   | 21/31 [00:52<00:22,  2.20s/it, loss=2.2486, batch_acc=0.4375, running_acc=0.5797, grad=15.7898]Training epoch 17:  68%|██████▊   | 21/31 [00:52<00:22,  2.20s/it, loss=1.8657, batch_acc=0.6250, running_acc=0.5818, grad=10.1808]Training epoch 17:  71%|███████   | 22/31 [00:58<00:28,  3.22s/it, loss=1.8657, batch_acc=0.6250, running_acc=0.5818, grad=10.1808]Training epoch 17:  71%|███████   | 22/31 [00:58<00:28,  3.22s/it, loss=1.8788, batch_acc=0.5000, running_acc=0.5781, grad=8.7322] Training epoch 17:  74%|███████▍  | 23/31 [00:59<00:21,  2.70s/it, loss=1.8788, batch_acc=0.5000, running_acc=0.5781, grad=8.7322]Training epoch 17:  74%|███████▍  | 23/31 [00:59<00:21,  2.70s/it, loss=2.0878, batch_acc=0.4688, running_acc=0.5734, grad=14.0470]Training epoch 17:  77%|███████▋  | 24/31 [01:01<00:16,  2.35s/it, loss=2.0878, batch_acc=0.4688, running_acc=0.5734, grad=14.0470]Training epoch 17:  77%|███████▋  | 24/31 [01:01<00:16,  2.35s/it, loss=1.8991, batch_acc=0.5938, running_acc=0.5742, grad=8.4737] Training epoch 17:  81%|████████  | 25/31 [01:02<00:12,  2.10s/it, loss=1.8991, batch_acc=0.5938, running_acc=0.5742, grad=8.4737]Training epoch 17:  81%|████████  | 25/31 [01:02<00:12,  2.10s/it, loss=2.0035, batch_acc=0.4688, running_acc=0.5700, grad=7.6562]Training epoch 17:  84%|████████▍ | 26/31 [01:04<00:09,  1.92s/it, loss=2.0035, batch_acc=0.4688, running_acc=0.5700, grad=7.6562]Training epoch 17:  84%|████████▍ | 26/31 [01:04<00:09,  1.92s/it, loss=1.8804, batch_acc=0.6250, running_acc=0.5721, grad=11.7433]Training epoch 17:  87%|████████▋ | 27/31 [01:05<00:07,  1.80s/it, loss=1.8804, batch_acc=0.6250, running_acc=0.5721, grad=11.7433]Training epoch 17:  87%|████████▋ | 27/31 [01:05<00:07,  1.80s/it, loss=1.7506, batch_acc=0.6875, running_acc=0.5764, grad=53.1226]Training epoch 17:  90%|█████████ | 28/31 [01:07<00:05,  1.71s/it, loss=1.7506, batch_acc=0.6875, running_acc=0.5764, grad=53.1226]Training epoch 17:  90%|█████████ | 28/31 [01:07<00:05,  1.71s/it, loss=1.5843, batch_acc=0.7500, running_acc=0.5826, grad=7.7163] Training epoch 17:  94%|█████████▎| 29/31 [01:08<00:03,  1.65s/it, loss=1.5843, batch_acc=0.7500, running_acc=0.5826, grad=7.7163]Training epoch 17:  94%|█████████▎| 29/31 [01:08<00:03,  1.65s/it, loss=1.6782, batch_acc=0.7188, running_acc=0.5873, grad=6.7599]Training epoch 17:  97%|█████████▋| 30/31 [01:10<00:01,  1.60s/it, loss=1.6782, batch_acc=0.7188, running_acc=0.5873, grad=6.7599]Training epoch 17:  97%|█████████▋| 30/31 [01:10<00:01,  1.60s/it, loss=2.1516, batch_acc=0.4688, running_acc=0.5833, grad=15.6593]Training epoch 17: 100%|██████████| 31/31 [01:10<00:00,  1.18s/it, loss=2.1516, batch_acc=0.4688, running_acc=0.5833, grad=15.6593]Training epoch 17: 100%|██████████| 31/31 [01:10<00:00,  1.18s/it, loss=1.0019, batch_acc=1.0000, running_acc=0.5842, grad=24.8111]Training epoch 17: 100%|██████████| 31/31 [01:10<00:00,  2.28s/it, loss=1.0019, batch_acc=1.0000, running_acc=0.5842, grad=24.8111]
Evaluation epoch 17:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 17:  20%|██        | 1/5 [00:04<00:19,  4.80s/it]Evaluation epoch 17:  20%|██        | 1/5 [00:04<00:19,  4.80s/it, loss=1.6672, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 17:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.6672, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 17:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.3688, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 17:  60%|██████    | 3/5 [00:06<00:03,  1.66s/it, loss=1.3688, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 17:  60%|██████    | 3/5 [00:06<00:03,  1.66s/it, loss=2.5032, batch_acc=0.3125, running_acc=0.6042]Evaluation epoch 17:  80%|████████  | 4/5 [00:07<00:01,  1.53s/it, loss=2.5032, batch_acc=0.3125, running_acc=0.6042]Evaluation epoch 17:  80%|████████  | 4/5 [00:07<00:01,  1.53s/it, loss=2.1212, batch_acc=0.3438, running_acc=0.5391]Evaluation epoch 17: 100%|██████████| 5/5 [00:08<00:00,  1.26s/it, loss=2.1212, batch_acc=0.3438, running_acc=0.5391]Evaluation epoch 17: 100%|██████████| 5/5 [00:08<00:00,  1.26s/it, loss=2.1699, batch_acc=0.5625, running_acc=0.5437]Evaluation epoch 17: 100%|██████████| 5/5 [00:08<00:00,  1.68s/it, loss=2.1699, batch_acc=0.5625, running_acc=0.5437]
Training epoch 18:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 18:   3%|▎         | 1/31 [00:08<04:03,  8.13s/it]Training epoch 18:   3%|▎         | 1/31 [00:08<04:03,  8.13s/it, loss=1.8488, batch_acc=0.5938, running_acc=0.5938, grad=9.2497]Training epoch 18:   6%|▋         | 2/31 [00:09<02:02,  4.24s/it, loss=1.8488, batch_acc=0.5938, running_acc=0.5938, grad=9.2497]Training epoch 18:   6%|▋         | 2/31 [00:09<02:02,  4.24s/it, loss=2.0449, batch_acc=0.5000, running_acc=0.5469, grad=15.8766]Training epoch 18:  10%|▉         | 3/31 [00:11<01:23,  2.99s/it, loss=2.0449, batch_acc=0.5000, running_acc=0.5469, grad=15.8766]Training epoch 18:  10%|▉         | 3/31 [00:11<01:23,  2.99s/it, loss=2.2018, batch_acc=0.5000, running_acc=0.5312, grad=7.5894] Training epoch 18:  13%|█▎        | 4/31 [00:12<01:05,  2.42s/it, loss=2.2018, batch_acc=0.5000, running_acc=0.5312, grad=7.5894]Training epoch 18:  13%|█▎        | 4/31 [00:12<01:05,  2.42s/it, loss=1.6231, batch_acc=0.6562, running_acc=0.5625, grad=10.0502]Training epoch 18:  16%|█▌        | 5/31 [00:14<00:54,  2.09s/it, loss=1.6231, batch_acc=0.6562, running_acc=0.5625, grad=10.0502]Training epoch 18:  16%|█▌        | 5/31 [00:14<00:54,  2.09s/it, loss=2.0977, batch_acc=0.5000, running_acc=0.5500, grad=14.2751]Training epoch 18:  19%|█▉        | 6/31 [00:15<00:47,  1.89s/it, loss=2.0977, batch_acc=0.5000, running_acc=0.5500, grad=14.2751]Training epoch 18:  19%|█▉        | 6/31 [00:17<00:47,  1.89s/it, loss=1.9412, batch_acc=0.5000, running_acc=0.5417, grad=8.8710] Training epoch 18:  23%|██▎       | 7/31 [00:19<00:59,  2.47s/it, loss=1.9412, batch_acc=0.5000, running_acc=0.5417, grad=8.8710]Training epoch 18:  23%|██▎       | 7/31 [00:19<00:59,  2.47s/it, loss=1.9159, batch_acc=0.5938, running_acc=0.5491, grad=8.0387]Training epoch 18:  26%|██▌       | 8/31 [00:20<00:49,  2.16s/it, loss=1.9159, batch_acc=0.5938, running_acc=0.5491, grad=8.0387]Training epoch 18:  26%|██▌       | 8/31 [00:20<00:49,  2.16s/it, loss=1.9037, batch_acc=0.5000, running_acc=0.5430, grad=8.9711]Training epoch 18:  29%|██▉       | 9/31 [00:22<00:43,  1.96s/it, loss=1.9037, batch_acc=0.5000, running_acc=0.5430, grad=8.9711]Training epoch 18:  29%|██▉       | 9/31 [00:22<00:43,  1.96s/it, loss=1.8469, batch_acc=0.6562, running_acc=0.5556, grad=12.4758]Training epoch 18:  32%|███▏      | 10/31 [00:25<00:46,  2.23s/it, loss=1.8469, batch_acc=0.6562, running_acc=0.5556, grad=12.4758]Training epoch 18:  32%|███▏      | 10/31 [00:25<00:46,  2.23s/it, loss=1.9379, batch_acc=0.6250, running_acc=0.5625, grad=9.1280] Training epoch 18:  35%|███▌      | 11/31 [00:26<00:40,  2.01s/it, loss=1.9379, batch_acc=0.6250, running_acc=0.5625, grad=9.1280]Training epoch 18:  35%|███▌      | 11/31 [00:26<00:40,  2.01s/it, loss=1.5085, batch_acc=0.8438, running_acc=0.5881, grad=10.2625]Training epoch 18:  39%|███▊      | 12/31 [00:28<00:35,  1.86s/it, loss=1.5085, batch_acc=0.8438, running_acc=0.5881, grad=10.2625]Training epoch 18:  39%|███▊      | 12/31 [00:28<00:35,  1.86s/it, loss=1.8586, batch_acc=0.5000, running_acc=0.5807, grad=11.6019]Training epoch 18:  42%|████▏     | 13/31 [00:29<00:31,  1.75s/it, loss=1.8586, batch_acc=0.5000, running_acc=0.5807, grad=11.6019]Training epoch 18:  42%|████▏     | 13/31 [00:29<00:31,  1.75s/it, loss=1.6838, batch_acc=0.6562, running_acc=0.5865, grad=11.7822]Training epoch 18:  45%|████▌     | 14/31 [00:32<00:33,  1.95s/it, loss=1.6838, batch_acc=0.6562, running_acc=0.5865, grad=11.7822]Training epoch 18:  45%|████▌     | 14/31 [00:32<00:33,  1.95s/it, loss=1.7204, batch_acc=0.6875, running_acc=0.5938, grad=12.9405]Training epoch 18:  48%|████▊     | 15/31 [00:33<00:29,  1.82s/it, loss=1.7204, batch_acc=0.6875, running_acc=0.5938, grad=12.9405]Training epoch 18:  48%|████▊     | 15/31 [00:33<00:29,  1.82s/it, loss=1.6885, batch_acc=0.6250, running_acc=0.5958, grad=7.6009] Training epoch 18:  52%|█████▏    | 16/31 [00:35<00:25,  1.72s/it, loss=1.6885, batch_acc=0.6250, running_acc=0.5958, grad=7.6009]Training epoch 18:  52%|█████▏    | 16/31 [00:35<00:25,  1.72s/it, loss=2.1257, batch_acc=0.5000, running_acc=0.5898, grad=10.8338]Training epoch 18:  55%|█████▍    | 17/31 [00:38<00:32,  2.32s/it, loss=2.1257, batch_acc=0.5000, running_acc=0.5898, grad=10.8338]Training epoch 18:  55%|█████▍    | 17/31 [00:38<00:32,  2.32s/it, loss=1.7983, batch_acc=0.5312, running_acc=0.5864, grad=40.6580]Training epoch 18:  58%|█████▊    | 18/31 [00:40<00:27,  2.08s/it, loss=1.7983, batch_acc=0.5312, running_acc=0.5864, grad=40.6580]Training epoch 18:  58%|█████▊    | 18/31 [00:40<00:27,  2.08s/it, loss=1.8009, batch_acc=0.6875, running_acc=0.5920, grad=24.1363]Training epoch 18:  61%|██████▏   | 19/31 [00:41<00:22,  1.91s/it, loss=1.8009, batch_acc=0.6875, running_acc=0.5920, grad=24.1363]Training epoch 18:  61%|██████▏   | 19/31 [00:41<00:22,  1.91s/it, loss=1.8121, batch_acc=0.5625, running_acc=0.5905, grad=12.0091]Training epoch 18:  65%|██████▍   | 20/31 [00:43<00:19,  1.79s/it, loss=1.8121, batch_acc=0.5625, running_acc=0.5905, grad=12.0091]Training epoch 18:  65%|██████▍   | 20/31 [00:43<00:19,  1.79s/it, loss=2.0380, batch_acc=0.5938, running_acc=0.5906, grad=7.8657] Training epoch 18:  68%|██████▊   | 21/31 [00:51<00:36,  3.65s/it, loss=2.0380, batch_acc=0.5938, running_acc=0.5906, grad=7.8657]Training epoch 18:  68%|██████▊   | 21/31 [00:51<00:36,  3.65s/it, loss=1.9134, batch_acc=0.5938, running_acc=0.5908, grad=15.1790]Training epoch 18:  71%|███████   | 22/31 [00:56<00:35,  3.98s/it, loss=1.9134, batch_acc=0.5938, running_acc=0.5908, grad=15.1790]Training epoch 18:  71%|███████   | 22/31 [00:56<00:35,  3.98s/it, loss=1.8206, batch_acc=0.5312, running_acc=0.5881, grad=11.5721]Training epoch 18:  74%|███████▍  | 23/31 [00:57<00:25,  3.23s/it, loss=1.8206, batch_acc=0.5312, running_acc=0.5881, grad=11.5721]Training epoch 18:  74%|███████▍  | 23/31 [00:57<00:25,  3.23s/it, loss=1.8942, batch_acc=0.5000, running_acc=0.5842, grad=15.4483]Training epoch 18:  77%|███████▋  | 24/31 [00:59<00:19,  2.72s/it, loss=1.8942, batch_acc=0.5000, running_acc=0.5842, grad=15.4483]Training epoch 18:  77%|███████▋  | 24/31 [00:59<00:19,  2.72s/it, loss=1.7254, batch_acc=0.6250, running_acc=0.5859, grad=22.9278]Training epoch 18:  81%|████████  | 25/31 [01:00<00:14,  2.40s/it, loss=1.7254, batch_acc=0.6250, running_acc=0.5859, grad=22.9278]Training epoch 18:  81%|████████  | 25/31 [01:00<00:14,  2.40s/it, loss=1.7884, batch_acc=0.5625, running_acc=0.5850, grad=13.2143]Training epoch 18:  84%|████████▍ | 26/31 [01:09<00:21,  4.25s/it, loss=1.7884, batch_acc=0.5625, running_acc=0.5850, grad=13.2143]Training epoch 18:  84%|████████▍ | 26/31 [01:09<00:21,  4.25s/it, loss=1.7010, batch_acc=0.7500, running_acc=0.5913, grad=10.0268]Training epoch 18:  87%|████████▋ | 27/31 [01:10<00:13,  3.43s/it, loss=1.7010, batch_acc=0.7500, running_acc=0.5913, grad=10.0268]Training epoch 18:  87%|████████▋ | 27/31 [01:10<00:13,  3.43s/it, loss=1.8160, batch_acc=0.7188, running_acc=0.5961, grad=9.9780] Training epoch 18:  90%|█████████ | 28/31 [01:12<00:08,  2.86s/it, loss=1.8160, batch_acc=0.7188, running_acc=0.5961, grad=9.9780]Training epoch 18:  90%|█████████ | 28/31 [01:12<00:08,  2.86s/it, loss=1.8095, batch_acc=0.4688, running_acc=0.5915, grad=10.4543]Training epoch 18:  94%|█████████▎| 29/31 [01:13<00:04,  2.45s/it, loss=1.8095, batch_acc=0.4688, running_acc=0.5915, grad=10.4543]Training epoch 18:  94%|█████████▎| 29/31 [01:13<00:04,  2.45s/it, loss=1.9252, batch_acc=0.5312, running_acc=0.5894, grad=11.7195]Training epoch 18:  97%|█████████▋| 30/31 [01:15<00:02,  2.17s/it, loss=1.9252, batch_acc=0.5312, running_acc=0.5894, grad=11.7195]Training epoch 18:  97%|█████████▋| 30/31 [01:15<00:02,  2.17s/it, loss=1.7237, batch_acc=0.7188, running_acc=0.5938, grad=12.1179]Training epoch 18: 100%|██████████| 31/31 [01:15<00:00,  1.58s/it, loss=1.7237, batch_acc=0.7188, running_acc=0.5938, grad=12.1179]Training epoch 18: 100%|██████████| 31/31 [01:15<00:00,  1.58s/it, loss=3.1466, batch_acc=0.5000, running_acc=0.5936, grad=23.6033]Training epoch 18: 100%|██████████| 31/31 [01:15<00:00,  2.44s/it, loss=3.1466, batch_acc=0.5000, running_acc=0.5936, grad=23.6033]
Evaluation epoch 18:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 18:  20%|██        | 1/5 [00:11<00:45, 11.36s/it]Evaluation epoch 18:  20%|██        | 1/5 [00:11<00:45, 11.36s/it, loss=1.6974, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 18:  40%|████      | 2/5 [00:12<00:15,  5.11s/it, loss=1.6974, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 18:  40%|████      | 2/5 [00:12<00:15,  5.11s/it, loss=1.6805, batch_acc=0.6562, running_acc=0.6250]Evaluation epoch 18:  60%|██████    | 3/5 [00:12<00:06,  3.12s/it, loss=1.6805, batch_acc=0.6562, running_acc=0.6250]Evaluation epoch 18:  60%|██████    | 3/5 [00:12<00:06,  3.12s/it, loss=2.0726, batch_acc=0.4688, running_acc=0.5729]Evaluation epoch 18:  80%|████████  | 4/5 [00:18<00:04,  4.26s/it, loss=2.0726, batch_acc=0.4688, running_acc=0.5729]Evaluation epoch 18:  80%|████████  | 4/5 [00:18<00:04,  4.26s/it, loss=1.9719, batch_acc=0.4688, running_acc=0.5469]Evaluation epoch 18: 100%|██████████| 5/5 [00:19<00:00,  3.00s/it, loss=1.9719, batch_acc=0.4688, running_acc=0.5469]Evaluation epoch 18: 100%|██████████| 5/5 [00:19<00:00,  3.00s/it, loss=1.9795, batch_acc=0.6250, running_acc=0.5625]Evaluation epoch 18: 100%|██████████| 5/5 [00:19<00:00,  3.93s/it, loss=1.9795, batch_acc=0.6250, running_acc=0.5625]
Training epoch 19:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 19:   3%|▎         | 1/31 [00:07<03:58,  7.95s/it]Training epoch 19:   3%|▎         | 1/31 [00:07<03:58,  7.95s/it, loss=1.7705, batch_acc=0.6562, running_acc=0.6562, grad=8.8249]Training epoch 19:   6%|▋         | 2/31 [00:11<02:28,  5.13s/it, loss=1.7705, batch_acc=0.6562, running_acc=0.6562, grad=8.8249]Training epoch 19:   6%|▋         | 2/31 [00:11<02:28,  5.13s/it, loss=1.8287, batch_acc=0.5625, running_acc=0.6094, grad=33.5125]Training epoch 19:  10%|▉         | 3/31 [00:12<01:37,  3.48s/it, loss=1.8287, batch_acc=0.5625, running_acc=0.6094, grad=33.5125]Training epoch 19:  10%|▉         | 3/31 [00:12<01:37,  3.48s/it, loss=1.9056, batch_acc=0.5938, running_acc=0.6042, grad=23.9561]Training epoch 19:  13%|█▎        | 4/31 [00:14<01:12,  2.70s/it, loss=1.9056, batch_acc=0.5938, running_acc=0.6042, grad=23.9561]Training epoch 19:  13%|█▎        | 4/31 [00:14<01:12,  2.70s/it, loss=1.5115, batch_acc=0.7188, running_acc=0.6328, grad=152.7934]Training epoch 19:  16%|█▌        | 5/31 [00:15<00:59,  2.29s/it, loss=1.5115, batch_acc=0.7188, running_acc=0.6328, grad=152.7934]Training epoch 19:  16%|█▌        | 5/31 [00:15<00:59,  2.29s/it, loss=1.8295, batch_acc=0.4375, running_acc=0.5938, grad=19.9766] Training epoch 19:  19%|█▉        | 6/31 [00:17<00:50,  2.02s/it, loss=1.8295, batch_acc=0.4375, running_acc=0.5938, grad=19.9766]Training epoch 19:  19%|█▉        | 6/31 [00:17<00:50,  2.02s/it, loss=1.6823, batch_acc=0.7188, running_acc=0.6146, grad=9.2046] Training epoch 19:  23%|██▎       | 7/31 [00:18<00:44,  1.86s/it, loss=1.6823, batch_acc=0.7188, running_acc=0.6146, grad=9.2046]Training epoch 19:  23%|██▎       | 7/31 [00:18<00:44,  1.86s/it, loss=2.0537, batch_acc=0.5625, running_acc=0.6071, grad=13.9888]Training epoch 19:  26%|██▌       | 8/31 [00:20<00:40,  1.74s/it, loss=2.0537, batch_acc=0.5625, running_acc=0.6071, grad=13.9888]Training epoch 19:  26%|██▌       | 8/31 [00:20<00:40,  1.74s/it, loss=1.9620, batch_acc=0.5938, running_acc=0.6055, grad=9.5601] Training epoch 19:  29%|██▉       | 9/31 [00:21<00:37,  1.71s/it, loss=1.9620, batch_acc=0.5938, running_acc=0.6055, grad=9.5601]Training epoch 19:  29%|██▉       | 9/31 [00:21<00:37,  1.71s/it, loss=1.7693, batch_acc=0.5312, running_acc=0.5972, grad=19.7907]Training epoch 19:  32%|███▏      | 10/31 [00:23<00:36,  1.76s/it, loss=1.7693, batch_acc=0.5312, running_acc=0.5972, grad=19.7907]Training epoch 19:  32%|███▏      | 10/31 [00:23<00:36,  1.76s/it, loss=1.8843, batch_acc=0.4688, running_acc=0.5844, grad=17.7791]Training epoch 19:  35%|███▌      | 11/31 [00:25<00:33,  1.68s/it, loss=1.8843, batch_acc=0.4688, running_acc=0.5844, grad=17.7791]Training epoch 19:  35%|███▌      | 11/31 [00:25<00:33,  1.68s/it, loss=1.7015, batch_acc=0.6562, running_acc=0.5909, grad=7.4628] Training epoch 19:  39%|███▊      | 12/31 [00:26<00:31,  1.63s/it, loss=1.7015, batch_acc=0.6562, running_acc=0.5909, grad=7.4628]Training epoch 19:  39%|███▊      | 12/31 [00:26<00:31,  1.63s/it, loss=1.8245, batch_acc=0.5312, running_acc=0.5859, grad=14.1379]Training epoch 19:  42%|████▏     | 13/31 [00:29<00:33,  1.84s/it, loss=1.8245, batch_acc=0.5312, running_acc=0.5859, grad=14.1379]Training epoch 19:  42%|████▏     | 13/31 [00:29<00:33,  1.84s/it, loss=1.9030, batch_acc=0.6562, running_acc=0.5913, grad=9.2290] Training epoch 19:  45%|████▌     | 14/31 [00:30<00:29,  1.74s/it, loss=1.9030, batch_acc=0.6562, running_acc=0.5913, grad=9.2290]Training epoch 19:  45%|████▌     | 14/31 [00:30<00:29,  1.74s/it, loss=1.8736, batch_acc=0.4375, running_acc=0.5804, grad=8.6041]Training epoch 19:  48%|████▊     | 15/31 [00:32<00:26,  1.67s/it, loss=1.8736, batch_acc=0.4375, running_acc=0.5804, grad=8.6041]Training epoch 19:  48%|████▊     | 15/31 [00:32<00:26,  1.67s/it, loss=1.9621, batch_acc=0.5625, running_acc=0.5792, grad=17.0849]Training epoch 19:  52%|█████▏    | 16/31 [00:34<00:30,  2.04s/it, loss=1.9621, batch_acc=0.5625, running_acc=0.5792, grad=17.0849]Training epoch 19:  52%|█████▏    | 16/31 [00:34<00:30,  2.04s/it, loss=1.6851, batch_acc=0.6875, running_acc=0.5859, grad=6.8590] Training epoch 19:  55%|█████▍    | 17/31 [00:39<00:39,  2.82s/it, loss=1.6851, batch_acc=0.6875, running_acc=0.5859, grad=6.8590]Training epoch 19:  55%|█████▍    | 17/31 [00:39<00:39,  2.82s/it, loss=1.7967, batch_acc=0.6250, running_acc=0.5882, grad=15.7277]Training epoch 19:  58%|█████▊    | 18/31 [00:41<00:31,  2.42s/it, loss=1.7967, batch_acc=0.6250, running_acc=0.5882, grad=15.7277]Training epoch 19:  58%|█████▊    | 18/31 [00:41<00:31,  2.42s/it, loss=2.0340, batch_acc=0.4688, running_acc=0.5816, grad=9.0760] Training epoch 19:  61%|██████▏   | 19/31 [00:42<00:25,  2.15s/it, loss=2.0340, batch_acc=0.4688, running_acc=0.5816, grad=9.0760]Training epoch 19:  61%|██████▏   | 19/31 [00:42<00:25,  2.15s/it, loss=1.8098, batch_acc=0.5625, running_acc=0.5806, grad=16.7870]Training epoch 19:  65%|██████▍   | 20/31 [00:44<00:21,  1.96s/it, loss=1.8098, batch_acc=0.5625, running_acc=0.5806, grad=16.7870]Training epoch 19:  65%|██████▍   | 20/31 [00:44<00:21,  1.96s/it, loss=1.6984, batch_acc=0.6562, running_acc=0.5844, grad=15.1466]Training epoch 19:  68%|██████▊   | 21/31 [00:50<00:33,  3.34s/it, loss=1.6984, batch_acc=0.6562, running_acc=0.5844, grad=15.1466]Training epoch 19:  68%|██████▊   | 21/31 [00:50<00:33,  3.34s/it, loss=1.7622, batch_acc=0.6562, running_acc=0.5878, grad=7.9143] Training epoch 19:  71%|███████   | 22/31 [00:52<00:25,  2.79s/it, loss=1.7622, batch_acc=0.6562, running_acc=0.5878, grad=7.9143]Training epoch 19:  71%|███████   | 22/31 [00:52<00:25,  2.79s/it, loss=2.2875, batch_acc=0.3438, running_acc=0.5767, grad=7.3712]Training epoch 19:  74%|███████▍  | 23/31 [00:53<00:19,  2.41s/it, loss=2.2875, batch_acc=0.3438, running_acc=0.5767, grad=7.3712]Training epoch 19:  74%|███████▍  | 23/31 [00:53<00:19,  2.41s/it, loss=1.5173, batch_acc=0.8125, running_acc=0.5870, grad=14.0444]Training epoch 19:  77%|███████▋  | 24/31 [00:55<00:14,  2.14s/it, loss=1.5173, batch_acc=0.8125, running_acc=0.5870, grad=14.0444]Training epoch 19:  77%|███████▋  | 24/31 [00:55<00:14,  2.14s/it, loss=1.5902, batch_acc=0.5625, running_acc=0.5859, grad=22.9798]Training epoch 19:  81%|████████  | 25/31 [01:02<00:21,  3.64s/it, loss=1.5902, batch_acc=0.5625, running_acc=0.5859, grad=22.9798]Training epoch 19:  81%|████████  | 25/31 [01:02<00:21,  3.64s/it, loss=1.7438, batch_acc=0.6562, running_acc=0.5887, grad=10.8943]Training epoch 19:  84%|████████▍ | 26/31 [01:03<00:15,  3.00s/it, loss=1.7438, batch_acc=0.6562, running_acc=0.5887, grad=10.8943]Training epoch 19:  84%|████████▍ | 26/31 [01:03<00:15,  3.00s/it, loss=1.6796, batch_acc=0.6875, running_acc=0.5925, grad=27.9282]Training epoch 19:  87%|████████▋ | 27/31 [01:05<00:10,  2.55s/it, loss=1.6796, batch_acc=0.6875, running_acc=0.5925, grad=27.9282]Training epoch 19:  87%|████████▋ | 27/31 [01:05<00:10,  2.55s/it, loss=1.7671, batch_acc=0.5312, running_acc=0.5903, grad=8.1445] Training epoch 19:  90%|█████████ | 28/31 [01:06<00:06,  2.24s/it, loss=1.7671, batch_acc=0.5312, running_acc=0.5903, grad=8.1445]Training epoch 19:  90%|█████████ | 28/31 [01:06<00:06,  2.24s/it, loss=1.8260, batch_acc=0.5625, running_acc=0.5893, grad=82.7077]Training epoch 19:  94%|█████████▎| 29/31 [01:12<00:06,  3.16s/it, loss=1.8260, batch_acc=0.5625, running_acc=0.5893, grad=82.7077]Training epoch 19:  94%|█████████▎| 29/31 [01:12<00:06,  3.16s/it, loss=1.9443, batch_acc=0.6250, running_acc=0.5905, grad=11.0174]Training epoch 19:  97%|█████████▋| 30/31 [01:13<00:02,  2.67s/it, loss=1.9443, batch_acc=0.6250, running_acc=0.5905, grad=11.0174]Training epoch 19:  97%|█████████▋| 30/31 [01:13<00:02,  2.67s/it, loss=1.7714, batch_acc=0.5312, running_acc=0.5885, grad=37.6869]Training epoch 19: 100%|██████████| 31/31 [01:13<00:00,  1.93s/it, loss=1.7714, batch_acc=0.5312, running_acc=0.5885, grad=37.6869]Training epoch 19: 100%|██████████| 31/31 [01:13<00:00,  1.93s/it, loss=2.9077, batch_acc=0.0000, running_acc=0.5873, grad=30.2145]Training epoch 19: 100%|██████████| 31/31 [01:13<00:00,  2.38s/it, loss=2.9077, batch_acc=0.0000, running_acc=0.5873, grad=30.2145]
Evaluation epoch 19:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 19:  20%|██        | 1/5 [00:14<00:58, 14.59s/it]Evaluation epoch 19:  20%|██        | 1/5 [00:14<00:58, 14.59s/it, loss=1.5971, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 19:  40%|████      | 2/5 [00:15<00:19,  6.45s/it, loss=1.5971, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 19:  40%|████      | 2/5 [00:15<00:19,  6.45s/it, loss=1.5101, batch_acc=0.7500, running_acc=0.6875]Evaluation epoch 19:  60%|██████    | 3/5 [00:16<00:07,  3.84s/it, loss=1.5101, batch_acc=0.7500, running_acc=0.6875]Evaluation epoch 19:  60%|██████    | 3/5 [00:16<00:07,  3.84s/it, loss=2.1524, batch_acc=0.4062, running_acc=0.5938]Evaluation epoch 19:  80%|████████  | 4/5 [00:23<00:05,  5.07s/it, loss=2.1524, batch_acc=0.4062, running_acc=0.5938]Evaluation epoch 19:  80%|████████  | 4/5 [00:23<00:05,  5.07s/it, loss=2.0384, batch_acc=0.4062, running_acc=0.5469]Evaluation epoch 19: 100%|██████████| 5/5 [00:23<00:00,  3.53s/it, loss=2.0384, batch_acc=0.4062, running_acc=0.5469]Evaluation epoch 19: 100%|██████████| 5/5 [00:23<00:00,  3.53s/it, loss=2.0594, batch_acc=0.5000, running_acc=0.5375]Evaluation epoch 19: 100%|██████████| 5/5 [00:23<00:00,  4.77s/it, loss=2.0594, batch_acc=0.5000, running_acc=0.5375]
Training epoch 20:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 20:   3%|▎         | 1/31 [00:06<03:29,  6.97s/it]Training epoch 20:   3%|▎         | 1/31 [00:06<03:29,  6.97s/it, loss=1.8782, batch_acc=0.5000, running_acc=0.5000, grad=11.0870]Training epoch 20:   6%|▋         | 2/31 [00:11<02:36,  5.40s/it, loss=1.8782, batch_acc=0.5000, running_acc=0.5000, grad=11.0870]Training epoch 20:   6%|▋         | 2/31 [00:11<02:36,  5.40s/it, loss=1.6544, batch_acc=0.5938, running_acc=0.5469, grad=17.1301]Training epoch 20:  10%|▉         | 3/31 [00:12<01:41,  3.62s/it, loss=1.6544, batch_acc=0.5938, running_acc=0.5469, grad=17.1301]Training epoch 20:  10%|▉         | 3/31 [00:12<01:41,  3.62s/it, loss=1.6818, batch_acc=0.7500, running_acc=0.6146, grad=6.6718] Training epoch 20:  13%|█▎        | 4/31 [00:15<01:23,  3.09s/it, loss=1.6818, batch_acc=0.7500, running_acc=0.6146, grad=6.6718]Training epoch 20:  13%|█▎        | 4/31 [00:15<01:23,  3.09s/it, loss=1.7459, batch_acc=0.5625, running_acc=0.6016, grad=7.4471]Training epoch 20:  16%|█▌        | 5/31 [00:16<01:05,  2.52s/it, loss=1.7459, batch_acc=0.5625, running_acc=0.6016, grad=7.4471]Training epoch 20:  16%|█▌        | 5/31 [00:16<01:05,  2.52s/it, loss=1.6173, batch_acc=0.7188, running_acc=0.6250, grad=15.0915]Training epoch 20:  19%|█▉        | 6/31 [00:18<00:54,  2.18s/it, loss=1.6173, batch_acc=0.7188, running_acc=0.6250, grad=15.0915]Training epoch 20:  19%|█▉        | 6/31 [00:18<00:54,  2.18s/it, loss=1.5979, batch_acc=0.7188, running_acc=0.6406, grad=9.7578] Training epoch 20:  23%|██▎       | 7/31 [00:19<00:46,  1.96s/it, loss=1.5979, batch_acc=0.7188, running_acc=0.6406, grad=9.7578]Training epoch 20:  23%|██▎       | 7/31 [00:19<00:46,  1.96s/it, loss=1.5487, batch_acc=0.7188, running_acc=0.6518, grad=13.4038]Training epoch 20:  26%|██▌       | 8/31 [00:21<00:41,  1.82s/it, loss=1.5487, batch_acc=0.7188, running_acc=0.6518, grad=13.4038]Training epoch 20:  26%|██▌       | 8/31 [00:21<00:41,  1.82s/it, loss=1.5592, batch_acc=0.6562, running_acc=0.6523, grad=8.8396] Training epoch 20:  29%|██▉       | 9/31 [00:22<00:37,  1.72s/it, loss=1.5592, batch_acc=0.6562, running_acc=0.6523, grad=8.8396]Training epoch 20:  29%|██▉       | 9/31 [00:22<00:37,  1.72s/it, loss=1.8046, batch_acc=0.6250, running_acc=0.6493, grad=28.8720]Training epoch 20:  32%|███▏      | 10/31 [00:26<00:51,  2.43s/it, loss=1.8046, batch_acc=0.6250, running_acc=0.6493, grad=28.8720]Training epoch 20:  32%|███▏      | 10/31 [00:26<00:51,  2.43s/it, loss=2.1086, batch_acc=0.5000, running_acc=0.6344, grad=12.2688]Training epoch 20:  35%|███▌      | 11/31 [00:28<00:43,  2.16s/it, loss=2.1086, batch_acc=0.5000, running_acc=0.6344, grad=12.2688]Training epoch 20:  35%|███▌      | 11/31 [00:28<00:43,  2.16s/it, loss=2.0195, batch_acc=0.5312, running_acc=0.6250, grad=15.6795]Training epoch 20:  39%|███▊      | 12/31 [00:29<00:37,  1.96s/it, loss=2.0195, batch_acc=0.5312, running_acc=0.6250, grad=15.6795]Training epoch 20:  39%|███▊      | 12/31 [00:29<00:37,  1.96s/it, loss=1.8409, batch_acc=0.5625, running_acc=0.6198, grad=17.9757]Training epoch 20:  42%|████▏     | 13/31 [00:31<00:32,  1.82s/it, loss=1.8409, batch_acc=0.5625, running_acc=0.6198, grad=17.9757]Training epoch 20:  42%|████▏     | 13/31 [00:31<00:32,  1.82s/it, loss=1.7781, batch_acc=0.6875, running_acc=0.6250, grad=9.2870] Training epoch 20:  45%|████▌     | 14/31 [00:32<00:29,  1.73s/it, loss=1.7781, batch_acc=0.6875, running_acc=0.6250, grad=9.2870]Training epoch 20:  45%|████▌     | 14/31 [00:32<00:29,  1.73s/it, loss=1.6926, batch_acc=0.6875, running_acc=0.6295, grad=11.5849]Training epoch 20:  48%|████▊     | 15/31 [00:34<00:26,  1.66s/it, loss=1.6926, batch_acc=0.6875, running_acc=0.6295, grad=11.5849]Training epoch 20:  48%|████▊     | 15/31 [00:34<00:26,  1.66s/it, loss=1.8064, batch_acc=0.5938, running_acc=0.6271, grad=9.7414] Training epoch 20:  52%|█████▏    | 16/31 [00:35<00:24,  1.62s/it, loss=1.8064, batch_acc=0.5938, running_acc=0.6271, grad=9.7414]Training epoch 20:  52%|█████▏    | 16/31 [00:35<00:24,  1.62s/it, loss=1.6473, batch_acc=0.6250, running_acc=0.6270, grad=11.9720]Training epoch 20:  55%|█████▍    | 17/31 [00:37<00:22,  1.59s/it, loss=1.6473, batch_acc=0.6250, running_acc=0.6270, grad=11.9720]Training epoch 20:  55%|█████▍    | 17/31 [00:37<00:22,  1.59s/it, loss=1.8892, batch_acc=0.5938, running_acc=0.6250, grad=32.7195]Training epoch 20:  58%|█████▊    | 18/31 [00:38<00:21,  1.62s/it, loss=1.8892, batch_acc=0.5938, running_acc=0.6250, grad=32.7195]Training epoch 20:  58%|█████▊    | 18/31 [00:38<00:21,  1.62s/it, loss=1.6851, batch_acc=0.6250, running_acc=0.6250, grad=36.2884]Training epoch 20:  61%|██████▏   | 19/31 [00:42<00:24,  2.06s/it, loss=1.6851, batch_acc=0.6250, running_acc=0.6250, grad=36.2884]Training epoch 20:  61%|██████▏   | 19/31 [00:42<00:24,  2.06s/it, loss=1.9338, batch_acc=0.5938, running_acc=0.6234, grad=13.2175]Training epoch 20:  65%|██████▍   | 20/31 [00:43<00:20,  1.89s/it, loss=1.9338, batch_acc=0.5938, running_acc=0.6234, grad=13.2175]Training epoch 20:  65%|██████▍   | 20/31 [00:43<00:20,  1.89s/it, loss=1.5998, batch_acc=0.6562, running_acc=0.6250, grad=7.4909] Training epoch 20:  68%|██████▊   | 21/31 [00:45<00:17,  1.78s/it, loss=1.5998, batch_acc=0.6562, running_acc=0.6250, grad=7.4909]Training epoch 20:  68%|██████▊   | 21/31 [00:45<00:17,  1.78s/it, loss=1.7173, batch_acc=0.5938, running_acc=0.6235, grad=9.5064]Training epoch 20:  71%|███████   | 22/31 [00:47<00:17,  2.00s/it, loss=1.7173, batch_acc=0.5938, running_acc=0.6235, grad=9.5064]Training epoch 20:  71%|███████   | 22/31 [00:47<00:17,  2.00s/it, loss=1.7051, batch_acc=0.6250, running_acc=0.6236, grad=51.6646]Training epoch 20:  74%|███████▍  | 23/31 [00:51<00:20,  2.55s/it, loss=1.7051, batch_acc=0.6250, running_acc=0.6236, grad=51.6646]Training epoch 20:  74%|███████▍  | 23/31 [00:51<00:20,  2.55s/it, loss=1.7402, batch_acc=0.6250, running_acc=0.6236, grad=11.7478]Training epoch 20:  77%|███████▋  | 24/31 [00:52<00:15,  2.24s/it, loss=1.7402, batch_acc=0.6250, running_acc=0.6236, grad=11.7478]Training epoch 20:  77%|███████▋  | 24/31 [00:52<00:15,  2.24s/it, loss=2.1366, batch_acc=0.6250, running_acc=0.6237, grad=13.0158]Training epoch 20:  81%|████████  | 25/31 [00:54<00:12,  2.02s/it, loss=2.1366, batch_acc=0.6250, running_acc=0.6237, grad=13.0158]Training epoch 20:  81%|████████  | 25/31 [00:54<00:12,  2.02s/it, loss=1.6981, batch_acc=0.6562, running_acc=0.6250, grad=9.0912] Training epoch 20:  84%|████████▍ | 26/31 [00:55<00:09,  1.87s/it, loss=1.6981, batch_acc=0.6562, running_acc=0.6250, grad=9.0912]Training epoch 20:  84%|████████▍ | 26/31 [00:55<00:09,  1.87s/it, loss=1.9038, batch_acc=0.5938, running_acc=0.6238, grad=17.4879]Training epoch 20:  87%|████████▋ | 27/31 [01:04<00:16,  4.00s/it, loss=1.9038, batch_acc=0.5938, running_acc=0.6238, grad=17.4879]Training epoch 20:  87%|████████▋ | 27/31 [01:04<00:16,  4.00s/it, loss=1.5841, batch_acc=0.6875, running_acc=0.6262, grad=9.5471] Training epoch 20:  90%|█████████ | 28/31 [01:06<00:09,  3.25s/it, loss=1.5841, batch_acc=0.6875, running_acc=0.6262, grad=9.5471]Training epoch 20:  90%|█████████ | 28/31 [01:06<00:09,  3.25s/it, loss=1.7319, batch_acc=0.5938, running_acc=0.6250, grad=30.6165]Training epoch 20:  94%|█████████▎| 29/31 [01:07<00:05,  2.73s/it, loss=1.7319, batch_acc=0.5938, running_acc=0.6250, grad=30.6165]Training epoch 20:  94%|█████████▎| 29/31 [01:07<00:05,  2.73s/it, loss=1.7858, batch_acc=0.5938, running_acc=0.6239, grad=18.1675]Training epoch 20:  97%|█████████▋| 30/31 [01:09<00:02,  2.36s/it, loss=1.7858, batch_acc=0.5938, running_acc=0.6239, grad=18.1675]Training epoch 20:  97%|█████████▋| 30/31 [01:09<00:02,  2.36s/it, loss=2.3423, batch_acc=0.3750, running_acc=0.6156, grad=11.4876]Training epoch 20: 100%|██████████| 31/31 [01:09<00:00,  1.71s/it, loss=2.3423, batch_acc=0.3750, running_acc=0.6156, grad=11.4876]Training epoch 20: 100%|██████████| 31/31 [01:09<00:00,  1.71s/it, loss=0.7497, batch_acc=1.0000, running_acc=0.6164, grad=27.2795]Training epoch 20: 100%|██████████| 31/31 [01:09<00:00,  2.25s/it, loss=0.7497, batch_acc=1.0000, running_acc=0.6164, grad=27.2795]
Evaluation epoch 20:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 20:  20%|██        | 1/5 [00:04<00:19,  4.97s/it]Evaluation epoch 20:  20%|██        | 1/5 [00:04<00:19,  4.97s/it, loss=1.7650, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 20:  40%|████      | 2/5 [00:05<00:07,  2.49s/it, loss=1.7650, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 20:  40%|████      | 2/5 [00:05<00:07,  2.49s/it, loss=1.4178, batch_acc=0.7500, running_acc=0.6406]Evaluation epoch 20:  60%|██████    | 3/5 [00:06<00:03,  1.69s/it, loss=1.4178, batch_acc=0.7500, running_acc=0.6406]Evaluation epoch 20:  60%|██████    | 3/5 [00:06<00:03,  1.69s/it, loss=2.1959, batch_acc=0.4375, running_acc=0.5729]Evaluation epoch 20:  80%|████████  | 4/5 [00:07<00:01,  1.61s/it, loss=2.1959, batch_acc=0.4375, running_acc=0.5729]Evaluation epoch 20:  80%|████████  | 4/5 [00:07<00:01,  1.61s/it, loss=2.1353, batch_acc=0.4375, running_acc=0.5391]Evaluation epoch 20: 100%|██████████| 5/5 [00:08<00:00,  1.31s/it, loss=2.1353, batch_acc=0.4375, running_acc=0.5391]Evaluation epoch 20: 100%|██████████| 5/5 [00:08<00:00,  1.31s/it, loss=2.1788, batch_acc=0.4375, running_acc=0.5188]Evaluation epoch 20: 100%|██████████| 5/5 [00:08<00:00,  1.75s/it, loss=2.1788, batch_acc=0.4375, running_acc=0.5188]
Training epoch 21:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 21:   3%|▎         | 1/31 [00:05<02:50,  5.67s/it]Training epoch 21:   3%|▎         | 1/31 [00:05<02:50,  5.67s/it, loss=1.7885, batch_acc=0.6562, running_acc=0.6562, grad=10.1437]Training epoch 21:   6%|▋         | 2/31 [00:07<01:33,  3.22s/it, loss=1.7885, batch_acc=0.6562, running_acc=0.6562, grad=10.1437]Training epoch 21:   6%|▋         | 2/31 [00:07<01:33,  3.22s/it, loss=1.6913, batch_acc=0.6562, running_acc=0.6562, grad=13.5132]Training epoch 21:  10%|▉         | 3/31 [00:08<01:08,  2.44s/it, loss=1.6913, batch_acc=0.6562, running_acc=0.6562, grad=13.5132]Training epoch 21:  10%|▉         | 3/31 [00:08<01:08,  2.44s/it, loss=1.6862, batch_acc=0.6875, running_acc=0.6667, grad=10.6310]Training epoch 21:  13%|█▎        | 4/31 [00:10<00:56,  2.07s/it, loss=1.6862, batch_acc=0.6875, running_acc=0.6667, grad=10.6310]Training epoch 21:  13%|█▎        | 4/31 [00:10<00:56,  2.07s/it, loss=1.8731, batch_acc=0.5000, running_acc=0.6250, grad=9.9339] Training epoch 21:  16%|█▌        | 5/31 [00:11<00:48,  1.87s/it, loss=1.8731, batch_acc=0.5000, running_acc=0.6250, grad=9.9339]Training epoch 21:  16%|█▌        | 5/31 [00:11<00:48,  1.87s/it, loss=1.6760, batch_acc=0.6562, running_acc=0.6312, grad=9.0340]Training epoch 21:  19%|█▉        | 6/31 [00:13<00:43,  1.75s/it, loss=1.6760, batch_acc=0.6562, running_acc=0.6312, grad=9.0340]Training epoch 21:  19%|█▉        | 6/31 [00:13<00:43,  1.75s/it, loss=1.6937, batch_acc=0.7188, running_acc=0.6458, grad=7.5513]Training epoch 21:  23%|██▎       | 7/31 [00:14<00:40,  1.67s/it, loss=1.6937, batch_acc=0.7188, running_acc=0.6458, grad=7.5513]Training epoch 21:  23%|██▎       | 7/31 [00:14<00:40,  1.67s/it, loss=2.2299, batch_acc=0.3750, running_acc=0.6071, grad=29.0032]Training epoch 21:  26%|██▌       | 8/31 [00:16<00:37,  1.64s/it, loss=2.2299, batch_acc=0.3750, running_acc=0.6071, grad=29.0032]Training epoch 21:  26%|██▌       | 8/31 [00:16<00:37,  1.64s/it, loss=1.6410, batch_acc=0.5938, running_acc=0.6055, grad=36.5242]Training epoch 21:  29%|██▉       | 9/31 [00:17<00:35,  1.60s/it, loss=1.6410, batch_acc=0.5938, running_acc=0.6055, grad=36.5242]Training epoch 21:  29%|██▉       | 9/31 [00:17<00:35,  1.60s/it, loss=1.4018, batch_acc=0.8438, running_acc=0.6319, grad=15.4758]Training epoch 21:  32%|███▏      | 10/31 [00:19<00:33,  1.57s/it, loss=1.4018, batch_acc=0.8438, running_acc=0.6319, grad=15.4758]Training epoch 21:  32%|███▏      | 10/31 [00:19<00:33,  1.57s/it, loss=1.8377, batch_acc=0.5000, running_acc=0.6188, grad=8.2081] Training epoch 21:  35%|███▌      | 11/31 [00:20<00:31,  1.56s/it, loss=1.8377, batch_acc=0.5000, running_acc=0.6188, grad=8.2081]Training epoch 21:  35%|███▌      | 11/31 [00:20<00:31,  1.56s/it, loss=1.8191, batch_acc=0.5938, running_acc=0.6165, grad=11.2028]Training epoch 21:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.8191, batch_acc=0.5938, running_acc=0.6165, grad=11.2028]Training epoch 21:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.8149, batch_acc=0.5938, running_acc=0.6146, grad=11.6248]Training epoch 21:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=1.8149, batch_acc=0.5938, running_acc=0.6146, grad=11.6248]Training epoch 21:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=1.7133, batch_acc=0.5625, running_acc=0.6106, grad=30.4968]Training epoch 21:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.7133, batch_acc=0.5625, running_acc=0.6106, grad=30.4968]Training epoch 21:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.6761, batch_acc=0.5625, running_acc=0.6071, grad=7.7515] Training epoch 21:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.6761, batch_acc=0.5625, running_acc=0.6071, grad=7.7515]Training epoch 21:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.6254, batch_acc=0.6562, running_acc=0.6104, grad=23.4571]Training epoch 21:  52%|█████▏    | 16/31 [00:28<00:22,  1.51s/it, loss=1.6254, batch_acc=0.6562, running_acc=0.6104, grad=23.4571]Training epoch 21:  52%|█████▏    | 16/31 [00:28<00:22,  1.51s/it, loss=1.9337, batch_acc=0.5000, running_acc=0.6035, grad=6.5598] Training epoch 21:  55%|█████▍    | 17/31 [00:29<00:21,  1.51s/it, loss=1.9337, batch_acc=0.5000, running_acc=0.6035, grad=6.5598]Training epoch 21:  55%|█████▍    | 17/31 [00:29<00:21,  1.51s/it, loss=1.8433, batch_acc=0.5625, running_acc=0.6011, grad=12.7709]Training epoch 21:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=1.8433, batch_acc=0.5625, running_acc=0.6011, grad=12.7709]Training epoch 21:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=2.0556, batch_acc=0.4688, running_acc=0.5938, grad=9.6355] Training epoch 21:  61%|██████▏   | 19/31 [00:32<00:18,  1.52s/it, loss=2.0556, batch_acc=0.4688, running_acc=0.5938, grad=9.6355]Training epoch 21:  61%|██████▏   | 19/31 [00:32<00:18,  1.52s/it, loss=1.5956, batch_acc=0.5938, running_acc=0.5938, grad=9.3061]Training epoch 21:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.5956, batch_acc=0.5938, running_acc=0.5938, grad=9.3061]Training epoch 21:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.8316, batch_acc=0.5938, running_acc=0.5938, grad=11.4746]Training epoch 21:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.8316, batch_acc=0.5938, running_acc=0.5938, grad=11.4746]Training epoch 21:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.5781, batch_acc=0.7188, running_acc=0.5997, grad=11.4508]Training epoch 21:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.5781, batch_acc=0.7188, running_acc=0.5997, grad=11.4508]Training epoch 21:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.6829, batch_acc=0.6875, running_acc=0.6037, grad=9.6451] Training epoch 21:  74%|███████▍  | 23/31 [00:38<00:12,  1.51s/it, loss=1.6829, batch_acc=0.6875, running_acc=0.6037, grad=9.6451]Training epoch 21:  74%|███████▍  | 23/31 [00:38<00:12,  1.51s/it, loss=1.6330, batch_acc=0.7188, running_acc=0.6087, grad=7.6914]Training epoch 21:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.6330, batch_acc=0.7188, running_acc=0.6087, grad=7.6914]Training epoch 21:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.9213, batch_acc=0.5625, running_acc=0.6068, grad=15.9090]Training epoch 21:  81%|████████  | 25/31 [00:41<00:09,  1.51s/it, loss=1.9213, batch_acc=0.5625, running_acc=0.6068, grad=15.9090]Training epoch 21:  81%|████████  | 25/31 [00:41<00:09,  1.51s/it, loss=1.6380, batch_acc=0.7500, running_acc=0.6125, grad=24.5547]Training epoch 21:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.6380, batch_acc=0.7500, running_acc=0.6125, grad=24.5547]Training epoch 21:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.7425, batch_acc=0.5938, running_acc=0.6118, grad=133.0434]Training epoch 21:  87%|████████▋ | 27/31 [00:44<00:06,  1.51s/it, loss=1.7425, batch_acc=0.5938, running_acc=0.6118, grad=133.0434]Training epoch 21:  87%|████████▋ | 27/31 [00:44<00:06,  1.51s/it, loss=1.7913, batch_acc=0.5625, running_acc=0.6100, grad=7.0409]  Training epoch 21:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=1.7913, batch_acc=0.5625, running_acc=0.6100, grad=7.0409]Training epoch 21:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=2.2810, batch_acc=0.5312, running_acc=0.6071, grad=12.8713]Training epoch 21:  94%|█████████▎| 29/31 [00:47<00:03,  1.51s/it, loss=2.2810, batch_acc=0.5312, running_acc=0.6071, grad=12.8713]Training epoch 21:  94%|█████████▎| 29/31 [00:47<00:03,  1.51s/it, loss=1.5924, batch_acc=0.6250, running_acc=0.6078, grad=62.2493]Training epoch 21:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.5924, batch_acc=0.6250, running_acc=0.6078, grad=62.2493]Training epoch 21:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.7197, batch_acc=0.6562, running_acc=0.6094, grad=13.0697]Training epoch 21: 100%|██████████| 31/31 [00:49<00:00,  1.11s/it, loss=1.7197, batch_acc=0.6562, running_acc=0.6094, grad=13.0697]Training epoch 21: 100%|██████████| 31/31 [00:49<00:00,  1.11s/it, loss=3.1674, batch_acc=0.5000, running_acc=0.6091, grad=30.5435]Training epoch 21: 100%|██████████| 31/31 [00:49<00:00,  1.60s/it, loss=3.1674, batch_acc=0.5000, running_acc=0.6091, grad=30.5435]
Evaluation epoch 21:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 21:  20%|██        | 1/5 [00:05<00:21,  5.42s/it]Evaluation epoch 21:  20%|██        | 1/5 [00:05<00:21,  5.42s/it, loss=1.7116, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 21:  40%|████      | 2/5 [00:06<00:08,  2.67s/it, loss=1.7116, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 21:  40%|████      | 2/5 [00:06<00:08,  2.67s/it, loss=1.6271, batch_acc=0.6562, running_acc=0.6250]Evaluation epoch 21:  60%|██████    | 3/5 [00:06<00:03,  1.79s/it, loss=1.6271, batch_acc=0.6562, running_acc=0.6250]Evaluation epoch 21:  60%|██████    | 3/5 [00:06<00:03,  1.79s/it, loss=1.7244, batch_acc=0.5312, running_acc=0.5938]Evaluation epoch 21:  80%|████████  | 4/5 [00:08<00:01,  1.52s/it, loss=1.7244, batch_acc=0.5312, running_acc=0.5938]Evaluation epoch 21:  80%|████████  | 4/5 [00:08<00:01,  1.52s/it, loss=1.8990, batch_acc=0.5312, running_acc=0.5781]Evaluation epoch 21: 100%|██████████| 5/5 [00:08<00:00,  1.25s/it, loss=1.8990, batch_acc=0.5312, running_acc=0.5781]Evaluation epoch 21: 100%|██████████| 5/5 [00:08<00:00,  1.25s/it, loss=2.2190, batch_acc=0.4688, running_acc=0.5563]Evaluation epoch 21: 100%|██████████| 5/5 [00:08<00:00,  1.76s/it, loss=2.2190, batch_acc=0.4688, running_acc=0.5563]
Training epoch 22:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 22:   3%|▎         | 1/31 [00:08<04:07,  8.24s/it]Training epoch 22:   3%|▎         | 1/31 [00:08<04:07,  8.24s/it, loss=1.8259, batch_acc=0.5312, running_acc=0.5312, grad=34.1848]Training epoch 22:   6%|▋         | 2/31 [00:09<02:04,  4.28s/it, loss=1.8259, batch_acc=0.5312, running_acc=0.5312, grad=34.1848]Training epoch 22:   6%|▋         | 2/31 [00:09<02:04,  4.28s/it, loss=1.8285, batch_acc=0.6250, running_acc=0.5781, grad=7.6364] Training epoch 22:  10%|▉         | 3/31 [00:11<01:24,  3.01s/it, loss=1.8285, batch_acc=0.6250, running_acc=0.5781, grad=7.6364]Training epoch 22:  10%|▉         | 3/31 [00:11<01:24,  3.01s/it, loss=1.6559, batch_acc=0.6875, running_acc=0.6146, grad=17.5333]Training epoch 22:  13%|█▎        | 4/31 [00:17<01:54,  4.24s/it, loss=1.6559, batch_acc=0.6875, running_acc=0.6146, grad=17.5333]Training epoch 22:  13%|█▎        | 4/31 [00:17<01:54,  4.24s/it, loss=1.5902, batch_acc=0.6562, running_acc=0.6250, grad=6.2412] Training epoch 22:  16%|█▌        | 5/31 [00:18<01:24,  3.25s/it, loss=1.5902, batch_acc=0.6562, running_acc=0.6250, grad=6.2412]Training epoch 22:  16%|█▌        | 5/31 [00:18<01:24,  3.25s/it, loss=1.7897, batch_acc=0.5938, running_acc=0.6188, grad=8.4526]Training epoch 22:  19%|█▉        | 6/31 [00:20<01:06,  2.66s/it, loss=1.7897, batch_acc=0.5938, running_acc=0.6188, grad=8.4526]Training epoch 22:  19%|█▉        | 6/31 [00:20<01:06,  2.66s/it, loss=2.0012, batch_acc=0.6250, running_acc=0.6198, grad=10.7314]Training epoch 22:  23%|██▎       | 7/31 [00:21<00:55,  2.30s/it, loss=2.0012, batch_acc=0.6250, running_acc=0.6198, grad=10.7314]Training epoch 22:  23%|██▎       | 7/31 [00:21<00:55,  2.30s/it, loss=1.7268, batch_acc=0.6562, running_acc=0.6250, grad=7.9844] Training epoch 22:  26%|██▌       | 8/31 [00:23<00:47,  2.05s/it, loss=1.7268, batch_acc=0.6562, running_acc=0.6250, grad=7.9844]Training epoch 22:  26%|██▌       | 8/31 [00:23<00:47,  2.05s/it, loss=1.7277, batch_acc=0.6250, running_acc=0.6250, grad=11.1923]Training epoch 22:  29%|██▉       | 9/31 [00:24<00:41,  1.88s/it, loss=1.7277, batch_acc=0.6250, running_acc=0.6250, grad=11.1923]Training epoch 22:  29%|██▉       | 9/31 [00:24<00:41,  1.88s/it, loss=1.6861, batch_acc=0.6250, running_acc=0.6250, grad=17.5161]Training epoch 22:  32%|███▏      | 10/31 [00:26<00:37,  1.77s/it, loss=1.6861, batch_acc=0.6250, running_acc=0.6250, grad=17.5161]Training epoch 22:  32%|███▏      | 10/31 [00:26<00:37,  1.77s/it, loss=1.9916, batch_acc=0.5938, running_acc=0.6219, grad=34.4632]Training epoch 22:  35%|███▌      | 11/31 [00:31<00:53,  2.69s/it, loss=1.9916, batch_acc=0.5938, running_acc=0.6219, grad=34.4632]Training epoch 22:  35%|███▌      | 11/31 [00:31<00:53,  2.69s/it, loss=1.7880, batch_acc=0.5312, running_acc=0.6136, grad=21.0275]Training epoch 22:  39%|███▊      | 12/31 [00:32<00:44,  2.33s/it, loss=1.7880, batch_acc=0.5312, running_acc=0.6136, grad=21.0275]Training epoch 22:  39%|███▊      | 12/31 [00:32<00:44,  2.33s/it, loss=1.8680, batch_acc=0.5938, running_acc=0.6120, grad=11.9916]Training epoch 22:  42%|████▏     | 13/31 [00:34<00:37,  2.08s/it, loss=1.8680, batch_acc=0.5938, running_acc=0.6120, grad=11.9916]Training epoch 22:  42%|████▏     | 13/31 [00:34<00:37,  2.08s/it, loss=1.6440, batch_acc=0.6562, running_acc=0.6154, grad=11.8988]Training epoch 22:  45%|████▌     | 14/31 [00:35<00:32,  1.91s/it, loss=1.6440, batch_acc=0.6562, running_acc=0.6154, grad=11.8988]Training epoch 22:  45%|████▌     | 14/31 [00:35<00:32,  1.91s/it, loss=1.6177, batch_acc=0.7812, running_acc=0.6272, grad=6.4067] Training epoch 22:  48%|████▊     | 15/31 [00:38<00:34,  2.14s/it, loss=1.6177, batch_acc=0.7812, running_acc=0.6272, grad=6.4067]Training epoch 22:  48%|████▊     | 15/31 [00:38<00:34,  2.14s/it, loss=1.6778, batch_acc=0.5312, running_acc=0.6208, grad=14.3440]Training epoch 22:  52%|█████▏    | 16/31 [00:39<00:29,  1.95s/it, loss=1.6778, batch_acc=0.5312, running_acc=0.6208, grad=14.3440]Training epoch 22:  52%|█████▏    | 16/31 [00:39<00:29,  1.95s/it, loss=1.7852, batch_acc=0.5938, running_acc=0.6191, grad=9.1114] Training epoch 22:  55%|█████▍    | 17/31 [00:43<00:35,  2.53s/it, loss=1.7852, batch_acc=0.5938, running_acc=0.6191, grad=9.1114]Training epoch 22:  55%|█████▍    | 17/31 [00:43<00:35,  2.53s/it, loss=1.7205, batch_acc=0.4375, running_acc=0.6085, grad=15.0946]Training epoch 22:  58%|█████▊    | 18/31 [00:45<00:28,  2.22s/it, loss=1.7205, batch_acc=0.4375, running_acc=0.6085, grad=15.0946]Training epoch 22:  58%|█████▊    | 18/31 [00:45<00:28,  2.22s/it, loss=1.6736, batch_acc=0.7500, running_acc=0.6163, grad=12.6209]Training epoch 22:  61%|██████▏   | 19/31 [00:46<00:24,  2.01s/it, loss=1.6736, batch_acc=0.7500, running_acc=0.6163, grad=12.6209]Training epoch 22:  61%|██████▏   | 19/31 [00:46<00:24,  2.01s/it, loss=1.6212, batch_acc=0.6562, running_acc=0.6184, grad=6.4812] Training epoch 22:  65%|██████▍   | 20/31 [00:48<00:20,  1.86s/it, loss=1.6212, batch_acc=0.6562, running_acc=0.6184, grad=6.4812]Training epoch 22:  65%|██████▍   | 20/31 [00:48<00:20,  1.86s/it, loss=1.5663, batch_acc=0.6875, running_acc=0.6219, grad=17.9254]Training epoch 22:  68%|██████▊   | 21/31 [00:52<00:24,  2.50s/it, loss=1.5663, batch_acc=0.6875, running_acc=0.6219, grad=17.9254]Training epoch 22:  68%|██████▊   | 21/31 [00:52<00:24,  2.50s/it, loss=1.6579, batch_acc=0.6875, running_acc=0.6250, grad=7.0461] Training epoch 22:  71%|███████   | 22/31 [00:53<00:19,  2.20s/it, loss=1.6579, batch_acc=0.6875, running_acc=0.6250, grad=7.0461]Training epoch 22:  71%|███████   | 22/31 [00:53<00:19,  2.20s/it, loss=1.4920, batch_acc=0.6562, running_acc=0.6264, grad=9.4703]Training epoch 22:  74%|███████▍  | 23/31 [00:55<00:15,  1.99s/it, loss=1.4920, batch_acc=0.6562, running_acc=0.6264, grad=9.4703]Training epoch 22:  74%|███████▍  | 23/31 [00:55<00:15,  1.99s/it, loss=1.5513, batch_acc=0.7188, running_acc=0.6304, grad=14.3969]Training epoch 22:  77%|███████▋  | 24/31 [00:57<00:13,  1.93s/it, loss=1.5513, batch_acc=0.7188, running_acc=0.6304, grad=14.3969]Training epoch 22:  77%|███████▋  | 24/31 [00:57<00:13,  1.93s/it, loss=1.8311, batch_acc=0.6250, running_acc=0.6302, grad=11.6523]Training epoch 22:  81%|████████  | 25/31 [01:04<00:21,  3.57s/it, loss=1.8311, batch_acc=0.6250, running_acc=0.6302, grad=11.6523]Training epoch 22:  81%|████████  | 25/31 [01:04<00:21,  3.57s/it, loss=1.5793, batch_acc=0.6875, running_acc=0.6325, grad=18.2795]Training epoch 22:  84%|████████▍ | 26/31 [01:06<00:14,  2.95s/it, loss=1.5793, batch_acc=0.6875, running_acc=0.6325, grad=18.2795]Training epoch 22:  84%|████████▍ | 26/31 [01:06<00:14,  2.95s/it, loss=1.7785, batch_acc=0.6250, running_acc=0.6322, grad=249.6861]Training epoch 22:  87%|████████▋ | 27/31 [01:07<00:10,  2.52s/it, loss=1.7785, batch_acc=0.6250, running_acc=0.6322, grad=249.6861]Training epoch 22:  87%|████████▋ | 27/31 [01:07<00:10,  2.52s/it, loss=1.6214, batch_acc=0.5625, running_acc=0.6296, grad=9.0585]  Training epoch 22:  90%|█████████ | 28/31 [01:09<00:06,  2.21s/it, loss=1.6214, batch_acc=0.5625, running_acc=0.6296, grad=9.0585]Training epoch 22:  90%|█████████ | 28/31 [01:09<00:06,  2.21s/it, loss=1.6968, batch_acc=0.6562, running_acc=0.6306, grad=51.7950]Training epoch 22:  94%|█████████▎| 29/31 [01:18<00:08,  4.28s/it, loss=1.6968, batch_acc=0.6562, running_acc=0.6306, grad=51.7950]Training epoch 22:  94%|█████████▎| 29/31 [01:18<00:08,  4.28s/it, loss=1.7588, batch_acc=0.5625, running_acc=0.6282, grad=25.7965]Training epoch 22:  97%|█████████▋| 30/31 [01:19<00:03,  3.45s/it, loss=1.7588, batch_acc=0.5625, running_acc=0.6282, grad=25.7965]Training epoch 22:  97%|█████████▋| 30/31 [01:19<00:03,  3.45s/it, loss=1.7866, batch_acc=0.6875, running_acc=0.6302, grad=9.2568] Training epoch 22: 100%|██████████| 31/31 [01:19<00:00,  2.48s/it, loss=1.7866, batch_acc=0.6875, running_acc=0.6302, grad=9.2568]Training epoch 22: 100%|██████████| 31/31 [01:19<00:00,  2.48s/it, loss=2.5756, batch_acc=0.5000, running_acc=0.6299, grad=65.4709]Training epoch 22: 100%|██████████| 31/31 [01:19<00:00,  2.58s/it, loss=2.5756, batch_acc=0.5000, running_acc=0.6299, grad=65.4709]
Evaluation epoch 22:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 22:  20%|██        | 1/5 [00:14<00:58, 14.62s/it]Evaluation epoch 22:  20%|██        | 1/5 [00:14<00:58, 14.62s/it, loss=1.4904, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 22:  40%|████      | 2/5 [00:15<00:19,  6.46s/it, loss=1.4904, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 22:  40%|████      | 2/5 [00:15<00:19,  6.46s/it, loss=1.3575, batch_acc=0.7500, running_acc=0.7031]Evaluation epoch 22:  60%|██████    | 3/5 [00:16<00:07,  3.85s/it, loss=1.3575, batch_acc=0.7500, running_acc=0.7031]Evaluation epoch 22:  60%|██████    | 3/5 [00:16<00:07,  3.85s/it, loss=2.0915, batch_acc=0.5312, running_acc=0.6458]Evaluation epoch 22:  80%|████████  | 4/5 [00:20<00:03,  3.97s/it, loss=2.0915, batch_acc=0.5312, running_acc=0.6458]Evaluation epoch 22:  80%|████████  | 4/5 [00:20<00:03,  3.97s/it, loss=2.0647, batch_acc=0.4375, running_acc=0.5938]Evaluation epoch 22: 100%|██████████| 5/5 [00:21<00:00,  2.82s/it, loss=2.0647, batch_acc=0.4375, running_acc=0.5938]Evaluation epoch 22: 100%|██████████| 5/5 [00:21<00:00,  2.82s/it, loss=1.9903, batch_acc=0.6250, running_acc=0.6000]Evaluation epoch 22: 100%|██████████| 5/5 [00:21<00:00,  4.21s/it, loss=1.9903, batch_acc=0.6250, running_acc=0.6000]
Training epoch 23:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 23:   3%|▎         | 1/31 [00:08<04:16,  8.56s/it]Training epoch 23:   3%|▎         | 1/31 [00:08<04:16,  8.56s/it, loss=1.5776, batch_acc=0.7188, running_acc=0.7188, grad=11.9536]Training epoch 23:   6%|▋         | 2/31 [00:10<02:10,  4.50s/it, loss=1.5776, batch_acc=0.7188, running_acc=0.7188, grad=11.9536]Training epoch 23:   6%|▋         | 2/31 [00:10<02:10,  4.50s/it, loss=1.7210, batch_acc=0.6250, running_acc=0.6719, grad=9.6656] Training epoch 23:  10%|▉         | 3/31 [00:11<01:28,  3.15s/it, loss=1.7210, batch_acc=0.6250, running_acc=0.6719, grad=9.6656]Training epoch 23:  10%|▉         | 3/31 [00:11<01:28,  3.15s/it, loss=1.5623, batch_acc=0.7188, running_acc=0.6875, grad=7.8521]Training epoch 23:  13%|█▎        | 4/31 [00:13<01:07,  2.50s/it, loss=1.5623, batch_acc=0.7188, running_acc=0.6875, grad=7.8521]Training epoch 23:  13%|█▎        | 4/31 [00:13<01:07,  2.50s/it, loss=1.6340, batch_acc=0.6250, running_acc=0.6719, grad=12.8305]Training epoch 23:  16%|█▌        | 5/31 [00:18<01:26,  3.31s/it, loss=1.6340, batch_acc=0.6250, running_acc=0.6719, grad=12.8305]Training epoch 23:  16%|█▌        | 5/31 [00:18<01:26,  3.31s/it, loss=1.8957, batch_acc=0.5938, running_acc=0.6562, grad=6.9090] Training epoch 23:  19%|█▉        | 6/31 [00:19<01:07,  2.70s/it, loss=1.8957, batch_acc=0.5938, running_acc=0.6562, grad=6.9090]Training epoch 23:  19%|█▉        | 6/31 [00:19<01:07,  2.70s/it, loss=1.5713, batch_acc=0.7188, running_acc=0.6667, grad=28.3686]Training epoch 23:  23%|██▎       | 7/31 [00:21<00:55,  2.31s/it, loss=1.5713, batch_acc=0.7188, running_acc=0.6667, grad=28.3686]Training epoch 23:  23%|██▎       | 7/31 [00:21<00:55,  2.31s/it, loss=1.9060, batch_acc=0.5625, running_acc=0.6518, grad=16.7871]Training epoch 23:  26%|██▌       | 8/31 [00:22<00:47,  2.06s/it, loss=1.9060, batch_acc=0.5625, running_acc=0.6518, grad=16.7871]Training epoch 23:  26%|██▌       | 8/31 [00:22<00:47,  2.06s/it, loss=1.7282, batch_acc=0.6562, running_acc=0.6523, grad=21.4308]Training epoch 23:  29%|██▉       | 9/31 [00:24<00:41,  1.89s/it, loss=1.7282, batch_acc=0.6562, running_acc=0.6523, grad=21.4308]Training epoch 23:  29%|██▉       | 9/31 [00:24<00:41,  1.89s/it, loss=1.4878, batch_acc=0.7500, running_acc=0.6632, grad=8.8987] Training epoch 23:  32%|███▏      | 10/31 [00:25<00:37,  1.77s/it, loss=1.4878, batch_acc=0.7500, running_acc=0.6632, grad=8.8987]Training epoch 23:  32%|███▏      | 10/31 [00:25<00:37,  1.77s/it, loss=1.7397, batch_acc=0.6562, running_acc=0.6625, grad=22.3403]Training epoch 23:  35%|███▌      | 11/31 [00:27<00:33,  1.69s/it, loss=1.7397, batch_acc=0.6562, running_acc=0.6625, grad=22.3403]Training epoch 23:  35%|███▌      | 11/31 [00:27<00:33,  1.69s/it, loss=1.7808, batch_acc=0.5938, running_acc=0.6562, grad=8.9037] Training epoch 23:  39%|███▊      | 12/31 [00:38<01:28,  4.65s/it, loss=1.7808, batch_acc=0.5938, running_acc=0.6562, grad=8.9037]Training epoch 23:  39%|███▊      | 12/31 [00:38<01:28,  4.65s/it, loss=1.8138, batch_acc=0.5625, running_acc=0.6484, grad=13.7235]Training epoch 23:  42%|████▏     | 13/31 [00:40<01:11,  3.96s/it, loss=1.8138, batch_acc=0.5625, running_acc=0.6484, grad=13.7235]Training epoch 23:  42%|████▏     | 13/31 [00:40<01:11,  3.96s/it, loss=1.9426, batch_acc=0.4062, running_acc=0.6298, grad=10.0543]Training epoch 23:  45%|████▌     | 14/31 [00:42<00:54,  3.22s/it, loss=1.9426, batch_acc=0.4062, running_acc=0.6298, grad=10.0543]Training epoch 23:  45%|████▌     | 14/31 [00:42<00:54,  3.22s/it, loss=1.6006, batch_acc=0.6562, running_acc=0.6317, grad=71.0314]Training epoch 23:  48%|████▊     | 15/31 [00:43<00:43,  2.71s/it, loss=1.6006, batch_acc=0.6562, running_acc=0.6317, grad=71.0314]Training epoch 23:  48%|████▊     | 15/31 [00:43<00:43,  2.71s/it, loss=1.8336, batch_acc=0.4688, running_acc=0.6208, grad=10.7268]Training epoch 23:  52%|█████▏    | 16/31 [00:47<00:44,  2.96s/it, loss=1.8336, batch_acc=0.4688, running_acc=0.6208, grad=10.7268]Training epoch 23:  52%|█████▏    | 16/31 [00:47<00:44,  2.96s/it, loss=1.8123, batch_acc=0.5000, running_acc=0.6133, grad=24.2890]Training epoch 23:  55%|█████▍    | 17/31 [00:52<00:48,  3.47s/it, loss=1.8123, batch_acc=0.5000, running_acc=0.6133, grad=24.2890]Training epoch 23:  55%|█████▍    | 17/31 [00:52<00:48,  3.47s/it, loss=1.6422, batch_acc=0.6250, running_acc=0.6140, grad=12.3182]Training epoch 23:  58%|█████▊    | 18/31 [00:53<00:37,  2.88s/it, loss=1.6422, batch_acc=0.6250, running_acc=0.6140, grad=12.3182]Training epoch 23:  58%|█████▊    | 18/31 [00:53<00:37,  2.88s/it, loss=1.7980, batch_acc=0.5625, running_acc=0.6111, grad=10.5710]Training epoch 23:  61%|██████▏   | 19/31 [00:55<00:29,  2.47s/it, loss=1.7980, batch_acc=0.5625, running_acc=0.6111, grad=10.5710]Training epoch 23:  61%|██████▏   | 19/31 [00:55<00:29,  2.47s/it, loss=1.6583, batch_acc=0.6250, running_acc=0.6118, grad=14.5544]Training epoch 23:  65%|██████▍   | 20/31 [00:56<00:24,  2.18s/it, loss=1.6583, batch_acc=0.6250, running_acc=0.6118, grad=14.5544]Training epoch 23:  65%|██████▍   | 20/31 [00:56<00:24,  2.18s/it, loss=1.4557, batch_acc=0.7500, running_acc=0.6188, grad=11.7107]Training epoch 23:  68%|██████▊   | 21/31 [00:58<00:21,  2.17s/it, loss=1.4557, batch_acc=0.7500, running_acc=0.6188, grad=11.7107]Training epoch 23:  68%|██████▊   | 21/31 [00:58<00:21,  2.17s/it, loss=1.8423, batch_acc=0.6250, running_acc=0.6190, grad=22.5027]Training epoch 23:  71%|███████   | 22/31 [01:00<00:17,  1.97s/it, loss=1.8423, batch_acc=0.6250, running_acc=0.6190, grad=22.5027]Training epoch 23:  71%|███████   | 22/31 [01:00<00:17,  1.97s/it, loss=1.8480, batch_acc=0.6562, running_acc=0.6207, grad=6.3513] Training epoch 23:  74%|███████▍  | 23/31 [01:01<00:14,  1.83s/it, loss=1.8480, batch_acc=0.6562, running_acc=0.6207, grad=6.3513]Training epoch 23:  74%|███████▍  | 23/31 [01:01<00:14,  1.83s/it, loss=1.6340, batch_acc=0.5938, running_acc=0.6196, grad=9.2303]Training epoch 23:  77%|███████▋  | 24/31 [01:04<00:14,  2.11s/it, loss=1.6340, batch_acc=0.5938, running_acc=0.6196, grad=9.2303]Training epoch 23:  77%|███████▋  | 24/31 [01:04<00:14,  2.11s/it, loss=1.8581, batch_acc=0.6562, running_acc=0.6211, grad=22.7845]Training epoch 23:  81%|████████  | 25/31 [01:06<00:11,  1.93s/it, loss=1.8581, batch_acc=0.6562, running_acc=0.6211, grad=22.7845]Training epoch 23:  81%|████████  | 25/31 [01:06<00:11,  1.93s/it, loss=1.6046, batch_acc=0.6562, running_acc=0.6225, grad=7.8271] Training epoch 23:  84%|████████▍ | 26/31 [01:07<00:09,  1.80s/it, loss=1.6046, batch_acc=0.6562, running_acc=0.6225, grad=7.8271]Training epoch 23:  84%|████████▍ | 26/31 [01:07<00:09,  1.80s/it, loss=1.4024, batch_acc=0.8125, running_acc=0.6298, grad=7.8903]Training epoch 23:  87%|████████▋ | 27/31 [01:09<00:06,  1.71s/it, loss=1.4024, batch_acc=0.8125, running_acc=0.6298, grad=7.8903]Training epoch 23:  87%|████████▋ | 27/31 [01:09<00:06,  1.71s/it, loss=1.6064, batch_acc=0.5938, running_acc=0.6285, grad=10.6901]Training epoch 23:  90%|█████████ | 28/31 [01:11<00:05,  1.95s/it, loss=1.6064, batch_acc=0.5938, running_acc=0.6285, grad=10.6901]Training epoch 23:  90%|█████████ | 28/31 [01:11<00:05,  1.95s/it, loss=1.6020, batch_acc=0.8125, running_acc=0.6350, grad=21.9860]Training epoch 23:  94%|█████████▎| 29/31 [01:15<00:05,  2.55s/it, loss=1.6020, batch_acc=0.8125, running_acc=0.6350, grad=21.9860]Training epoch 23:  94%|█████████▎| 29/31 [01:15<00:05,  2.55s/it, loss=1.7833, batch_acc=0.6562, running_acc=0.6358, grad=10.4362]Training epoch 23:  97%|█████████▋| 30/31 [01:17<00:02,  2.24s/it, loss=1.7833, batch_acc=0.6562, running_acc=0.6358, grad=10.4362]Training epoch 23:  97%|█████████▋| 30/31 [01:17<00:02,  2.24s/it, loss=1.7548, batch_acc=0.5625, running_acc=0.6333, grad=17.3056]Training epoch 23: 100%|██████████| 31/31 [01:17<00:00,  1.63s/it, loss=1.7548, batch_acc=0.5625, running_acc=0.6333, grad=17.3056]Training epoch 23: 100%|██████████| 31/31 [01:17<00:00,  1.63s/it, loss=2.3840, batch_acc=0.5000, running_acc=0.6331, grad=418.2149]Training epoch 23: 100%|██████████| 31/31 [01:17<00:00,  2.49s/it, loss=2.3840, batch_acc=0.5000, running_acc=0.6331, grad=418.2149]
Evaluation epoch 23:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 23:  20%|██        | 1/5 [00:09<00:36,  9.07s/it]Evaluation epoch 23:  20%|██        | 1/5 [00:09<00:36,  9.07s/it, loss=1.6327, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 23:  40%|████      | 2/5 [00:09<00:12,  4.18s/it, loss=1.6327, batch_acc=0.5312, running_acc=0.5312]Evaluation epoch 23:  40%|████      | 2/5 [00:09<00:12,  4.18s/it, loss=1.4041, batch_acc=0.6875, running_acc=0.6094]Evaluation epoch 23:  60%|██████    | 3/5 [00:10<00:05,  2.61s/it, loss=1.4041, batch_acc=0.6875, running_acc=0.6094]Evaluation epoch 23:  60%|██████    | 3/5 [00:10<00:05,  2.61s/it, loss=1.7696, batch_acc=0.5625, running_acc=0.5938]Evaluation epoch 23:  80%|████████  | 4/5 [00:16<00:04,  4.06s/it, loss=1.7696, batch_acc=0.5625, running_acc=0.5938]Evaluation epoch 23:  80%|████████  | 4/5 [00:16<00:04,  4.06s/it, loss=1.9946, batch_acc=0.4688, running_acc=0.5625]Evaluation epoch 23: 100%|██████████| 5/5 [00:17<00:00,  2.88s/it, loss=1.9946, batch_acc=0.4688, running_acc=0.5625]Evaluation epoch 23: 100%|██████████| 5/5 [00:17<00:00,  2.88s/it, loss=2.1998, batch_acc=0.5000, running_acc=0.5500]Evaluation epoch 23: 100%|██████████| 5/5 [00:17<00:00,  3.53s/it, loss=2.1998, batch_acc=0.5000, running_acc=0.5500]
Training epoch 24:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 24:   3%|▎         | 1/31 [00:13<06:35, 13.18s/it]Training epoch 24:   3%|▎         | 1/31 [00:13<06:35, 13.18s/it, loss=1.3466, batch_acc=0.8125, running_acc=0.8125, grad=24.6532]Training epoch 24:   6%|▋         | 2/31 [00:14<03:03,  6.32s/it, loss=1.3466, batch_acc=0.8125, running_acc=0.8125, grad=24.6532]Training epoch 24:   6%|▋         | 2/31 [00:14<03:03,  6.32s/it, loss=1.4123, batch_acc=0.7500, running_acc=0.7812, grad=11.5481]Training epoch 24:  10%|▉         | 3/31 [00:16<01:55,  4.12s/it, loss=1.4123, batch_acc=0.7500, running_acc=0.7812, grad=11.5481]Training epoch 24:  10%|▉         | 3/31 [00:16<01:55,  4.12s/it, loss=1.6064, batch_acc=0.6250, running_acc=0.7292, grad=15.9406]Training epoch 24:  13%|█▎        | 4/31 [00:17<01:23,  3.09s/it, loss=1.6064, batch_acc=0.6250, running_acc=0.7292, grad=15.9406]Training epoch 24:  13%|█▎        | 4/31 [00:18<01:23,  3.09s/it, loss=1.9959, batch_acc=0.5312, running_acc=0.6797, grad=9.8468] Training epoch 24:  16%|█▌        | 5/31 [00:19<01:11,  2.75s/it, loss=1.9959, batch_acc=0.5312, running_acc=0.6797, grad=9.8468]Training epoch 24:  16%|█▌        | 5/31 [00:19<01:11,  2.75s/it, loss=1.5960, batch_acc=0.6875, running_acc=0.6813, grad=25.5491]Training epoch 24:  19%|█▉        | 6/31 [00:21<00:58,  2.33s/it, loss=1.5960, batch_acc=0.6875, running_acc=0.6813, grad=25.5491]Training epoch 24:  19%|█▉        | 6/31 [00:21<00:58,  2.33s/it, loss=1.6376, batch_acc=0.5938, running_acc=0.6667, grad=9.8204] Training epoch 24:  23%|██▎       | 7/31 [00:22<00:49,  2.06s/it, loss=1.6376, batch_acc=0.5938, running_acc=0.6667, grad=9.8204]Training epoch 24:  23%|██▎       | 7/31 [00:22<00:49,  2.06s/it, loss=1.6103, batch_acc=0.6562, running_acc=0.6652, grad=13.7694]Training epoch 24:  26%|██▌       | 8/31 [00:24<00:43,  1.88s/it, loss=1.6103, batch_acc=0.6562, running_acc=0.6652, grad=13.7694]Training epoch 24:  26%|██▌       | 8/31 [00:24<00:43,  1.88s/it, loss=1.7003, batch_acc=0.6562, running_acc=0.6641, grad=16.1200]Training epoch 24:  29%|██▉       | 9/31 [00:25<00:39,  1.78s/it, loss=1.7003, batch_acc=0.6562, running_acc=0.6641, grad=16.1200]Training epoch 24:  29%|██▉       | 9/31 [00:25<00:39,  1.78s/it, loss=1.6888, batch_acc=0.5938, running_acc=0.6562, grad=15.7520]Training epoch 24:  32%|███▏      | 10/31 [00:27<00:35,  1.69s/it, loss=1.6888, batch_acc=0.5938, running_acc=0.6562, grad=15.7520]Training epoch 24:  32%|███▏      | 10/31 [00:27<00:35,  1.69s/it, loss=1.6692, batch_acc=0.6250, running_acc=0.6531, grad=14.5107]Training epoch 24:  35%|███▌      | 11/31 [00:28<00:32,  1.64s/it, loss=1.6692, batch_acc=0.6250, running_acc=0.6531, grad=14.5107]Training epoch 24:  35%|███▌      | 11/31 [00:28<00:32,  1.64s/it, loss=1.7038, batch_acc=0.6562, running_acc=0.6534, grad=9.2910] Training epoch 24:  39%|███▊      | 12/31 [00:30<00:30,  1.60s/it, loss=1.7038, batch_acc=0.6562, running_acc=0.6534, grad=9.2910]Training epoch 24:  39%|███▊      | 12/31 [00:30<00:30,  1.60s/it, loss=1.6025, batch_acc=0.6250, running_acc=0.6510, grad=22.5269]Training epoch 24:  42%|████▏     | 13/31 [00:31<00:28,  1.57s/it, loss=1.6025, batch_acc=0.6250, running_acc=0.6510, grad=22.5269]Training epoch 24:  42%|████▏     | 13/31 [00:31<00:28,  1.57s/it, loss=2.0935, batch_acc=0.4062, running_acc=0.6322, grad=12.9479]Training epoch 24:  45%|████▌     | 14/31 [00:33<00:26,  1.55s/it, loss=2.0935, batch_acc=0.4062, running_acc=0.6322, grad=12.9479]Training epoch 24:  45%|████▌     | 14/31 [00:33<00:26,  1.55s/it, loss=2.0699, batch_acc=0.5312, running_acc=0.6250, grad=13.6999]Training epoch 24:  48%|████▊     | 15/31 [00:34<00:24,  1.54s/it, loss=2.0699, batch_acc=0.5312, running_acc=0.6250, grad=13.6999]Training epoch 24:  48%|████▊     | 15/31 [00:34<00:24,  1.54s/it, loss=1.5558, batch_acc=0.6875, running_acc=0.6292, grad=7.1667] Training epoch 24:  52%|█████▏    | 16/31 [00:36<00:22,  1.53s/it, loss=1.5558, batch_acc=0.6875, running_acc=0.6292, grad=7.1667]Training epoch 24:  52%|█████▏    | 16/31 [00:36<00:22,  1.53s/it, loss=1.7765, batch_acc=0.6562, running_acc=0.6309, grad=61.0882]Training epoch 24:  55%|█████▍    | 17/31 [00:41<00:37,  2.66s/it, loss=1.7765, batch_acc=0.6562, running_acc=0.6309, grad=61.0882]Training epoch 24:  55%|█████▍    | 17/31 [00:41<00:37,  2.66s/it, loss=1.8064, batch_acc=0.6250, running_acc=0.6305, grad=13.3979]Training epoch 24:  58%|█████▊    | 18/31 [00:43<00:30,  2.31s/it, loss=1.8064, batch_acc=0.6250, running_acc=0.6305, grad=13.3979]Training epoch 24:  58%|█████▊    | 18/31 [00:43<00:30,  2.31s/it, loss=1.9236, batch_acc=0.5625, running_acc=0.6267, grad=19.1401]Training epoch 24:  61%|██████▏   | 19/31 [00:44<00:24,  2.07s/it, loss=1.9236, batch_acc=0.5625, running_acc=0.6267, grad=19.1401]Training epoch 24:  61%|██████▏   | 19/31 [00:44<00:24,  2.07s/it, loss=1.9742, batch_acc=0.5312, running_acc=0.6217, grad=15.1525]Training epoch 24:  65%|██████▍   | 20/31 [00:46<00:20,  1.90s/it, loss=1.9742, batch_acc=0.5312, running_acc=0.6217, grad=15.1525]Training epoch 24:  65%|██████▍   | 20/31 [00:46<00:20,  1.90s/it, loss=2.0089, batch_acc=0.5625, running_acc=0.6188, grad=9.5840] Training epoch 24:  68%|██████▊   | 21/31 [00:50<00:25,  2.60s/it, loss=2.0089, batch_acc=0.5625, running_acc=0.6188, grad=9.5840]Training epoch 24:  68%|██████▊   | 21/31 [00:50<00:25,  2.60s/it, loss=1.7423, batch_acc=0.5938, running_acc=0.6176, grad=11.5091]Training epoch 24:  71%|███████   | 22/31 [00:52<00:20,  2.27s/it, loss=1.7423, batch_acc=0.5938, running_acc=0.6176, grad=11.5091]Training epoch 24:  71%|███████   | 22/31 [00:52<00:20,  2.27s/it, loss=1.7101, batch_acc=0.5625, running_acc=0.6151, grad=12.4127]Training epoch 24:  74%|███████▍  | 23/31 [00:53<00:16,  2.05s/it, loss=1.7101, batch_acc=0.5625, running_acc=0.6151, grad=12.4127]Training epoch 24:  74%|███████▍  | 23/31 [00:53<00:16,  2.05s/it, loss=1.6392, batch_acc=0.5938, running_acc=0.6141, grad=6.2585] Training epoch 24:  77%|███████▋  | 24/31 [00:55<00:13,  1.88s/it, loss=1.6392, batch_acc=0.5938, running_acc=0.6141, grad=6.2585]Training epoch 24:  77%|███████▋  | 24/31 [00:55<00:13,  1.88s/it, loss=1.5643, batch_acc=0.6875, running_acc=0.6172, grad=14.7039]Training epoch 24:  81%|████████  | 25/31 [00:56<00:10,  1.77s/it, loss=1.5643, batch_acc=0.6875, running_acc=0.6172, grad=14.7039]Training epoch 24:  81%|████████  | 25/31 [00:56<00:10,  1.77s/it, loss=1.5612, batch_acc=0.7188, running_acc=0.6212, grad=10.0301]Training epoch 24:  84%|████████▍ | 26/31 [00:58<00:08,  1.69s/it, loss=1.5612, batch_acc=0.7188, running_acc=0.6212, grad=10.0301]Training epoch 24:  84%|████████▍ | 26/31 [00:58<00:08,  1.69s/it, loss=1.6674, batch_acc=0.6250, running_acc=0.6214, grad=13.8773]Training epoch 24:  87%|████████▋ | 27/31 [00:59<00:06,  1.64s/it, loss=1.6674, batch_acc=0.6250, running_acc=0.6214, grad=13.8773]Training epoch 24:  87%|████████▋ | 27/31 [00:59<00:06,  1.64s/it, loss=1.8611, batch_acc=0.5000, running_acc=0.6169, grad=13.5183]Training epoch 24:  90%|█████████ | 28/31 [01:01<00:04,  1.60s/it, loss=1.8611, batch_acc=0.5000, running_acc=0.6169, grad=13.5183]Training epoch 24:  90%|█████████ | 28/31 [01:01<00:04,  1.60s/it, loss=1.5558, batch_acc=0.6562, running_acc=0.6183, grad=40.8168]Training epoch 24:  94%|█████████▎| 29/31 [01:16<00:11,  5.75s/it, loss=1.5558, batch_acc=0.6562, running_acc=0.6183, grad=40.8168]Training epoch 24:  94%|█████████▎| 29/31 [01:16<00:11,  5.75s/it, loss=1.5364, batch_acc=0.6562, running_acc=0.6196, grad=25.2024]Training epoch 24:  97%|█████████▋| 30/31 [01:18<00:04,  4.48s/it, loss=1.5364, batch_acc=0.6562, running_acc=0.6196, grad=25.2024]Training epoch 24:  97%|█████████▋| 30/31 [01:18<00:04,  4.48s/it, loss=1.5354, batch_acc=0.7188, running_acc=0.6229, grad=28.7123]Training epoch 24: 100%|██████████| 31/31 [01:18<00:00,  3.19s/it, loss=1.5354, batch_acc=0.7188, running_acc=0.6229, grad=28.7123]Training epoch 24: 100%|██████████| 31/31 [01:18<00:00,  3.19s/it, loss=2.2032, batch_acc=0.5000, running_acc=0.6227, grad=21.2274]Training epoch 24: 100%|██████████| 31/31 [01:18<00:00,  2.52s/it, loss=2.2032, batch_acc=0.5000, running_acc=0.6227, grad=21.2274]
Evaluation epoch 24:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 24:  20%|██        | 1/5 [00:18<01:15, 18.99s/it]Evaluation epoch 24:  20%|██        | 1/5 [00:18<01:15, 18.99s/it, loss=1.6140, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 24:  40%|████      | 2/5 [00:19<00:24,  8.26s/it, loss=1.6140, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 24:  40%|████      | 2/5 [00:19<00:24,  8.26s/it, loss=1.4274, batch_acc=0.7188, running_acc=0.7031]Evaluation epoch 24:  60%|██████    | 3/5 [00:23<00:12,  6.04s/it, loss=1.4274, batch_acc=0.7188, running_acc=0.7031]Evaluation epoch 24:  60%|██████    | 3/5 [00:23<00:12,  6.04s/it, loss=1.8392, batch_acc=0.5625, running_acc=0.6562]Evaluation epoch 24:  80%|████████  | 4/5 [00:23<00:03,  3.95s/it, loss=1.8392, batch_acc=0.5625, running_acc=0.6562]Evaluation epoch 24:  80%|████████  | 4/5 [00:23<00:03,  3.95s/it, loss=2.0489, batch_acc=0.5000, running_acc=0.6172]Evaluation epoch 24: 100%|██████████| 5/5 [00:24<00:00,  2.81s/it, loss=2.0489, batch_acc=0.5000, running_acc=0.6172]Evaluation epoch 24: 100%|██████████| 5/5 [00:24<00:00,  2.81s/it, loss=2.2065, batch_acc=0.4375, running_acc=0.5813]Evaluation epoch 24: 100%|██████████| 5/5 [00:24<00:00,  4.94s/it, loss=2.2065, batch_acc=0.4375, running_acc=0.5813]
Training epoch 25:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 25:   3%|▎         | 1/31 [00:10<05:04, 10.15s/it]Training epoch 25:   3%|▎         | 1/31 [00:10<05:04, 10.15s/it, loss=1.4329, batch_acc=0.8125, running_acc=0.8125, grad=15.1215]Training epoch 25:   6%|▋         | 2/31 [00:11<02:26,  5.06s/it, loss=1.4329, batch_acc=0.8125, running_acc=0.8125, grad=15.1215]Training epoch 25:   6%|▋         | 2/31 [00:11<02:26,  5.06s/it, loss=1.5242, batch_acc=0.6875, running_acc=0.7500, grad=13.4738]Training epoch 25:  10%|▉         | 3/31 [00:13<01:36,  3.44s/it, loss=1.5242, batch_acc=0.6875, running_acc=0.7500, grad=13.4738]Training epoch 25:  10%|▉         | 3/31 [00:13<01:36,  3.44s/it, loss=1.5236, batch_acc=0.7500, running_acc=0.7500, grad=19.2989]Training epoch 25:  13%|█▎        | 4/31 [00:17<01:41,  3.74s/it, loss=1.5236, batch_acc=0.7500, running_acc=0.7500, grad=19.2989]Training epoch 25:  13%|█▎        | 4/31 [00:17<01:41,  3.74s/it, loss=1.6757, batch_acc=0.5938, running_acc=0.7109, grad=8.9996] Training epoch 25:  16%|█▌        | 5/31 [00:18<01:16,  2.94s/it, loss=1.6757, batch_acc=0.5938, running_acc=0.7109, grad=8.9996]Training epoch 25:  16%|█▌        | 5/31 [00:18<01:16,  2.94s/it, loss=1.7170, batch_acc=0.6875, running_acc=0.7063, grad=7.2658]Training epoch 25:  19%|█▉        | 6/31 [00:24<01:32,  3.68s/it, loss=1.7170, batch_acc=0.6875, running_acc=0.7063, grad=7.2658]Training epoch 25:  19%|█▉        | 6/31 [00:24<01:32,  3.68s/it, loss=1.9490, batch_acc=0.5312, running_acc=0.6771, grad=12.9090]Training epoch 25:  23%|██▎       | 7/31 [00:25<01:11,  2.97s/it, loss=1.9490, batch_acc=0.5312, running_acc=0.6771, grad=12.9090]Training epoch 25:  23%|██▎       | 7/31 [00:25<01:11,  2.97s/it, loss=1.8475, batch_acc=0.4688, running_acc=0.6473, grad=8.9178] Training epoch 25:  26%|██▌       | 8/31 [00:27<00:57,  2.51s/it, loss=1.8475, batch_acc=0.4688, running_acc=0.6473, grad=8.9178]Training epoch 25:  26%|██▌       | 8/31 [00:27<00:57,  2.51s/it, loss=1.4403, batch_acc=0.7812, running_acc=0.6641, grad=14.7686]Training epoch 25:  29%|██▉       | 9/31 [00:28<00:48,  2.20s/it, loss=1.4403, batch_acc=0.7812, running_acc=0.6641, grad=14.7686]Training epoch 25:  29%|██▉       | 9/31 [00:28<00:48,  2.20s/it, loss=1.6639, batch_acc=0.6562, running_acc=0.6632, grad=21.4987]Training epoch 25:  32%|███▏      | 10/31 [00:30<00:41,  1.99s/it, loss=1.6639, batch_acc=0.6562, running_acc=0.6632, grad=21.4987]Training epoch 25:  32%|███▏      | 10/31 [00:30<00:41,  1.99s/it, loss=1.7184, batch_acc=0.6250, running_acc=0.6594, grad=24.6988]Training epoch 25:  35%|███▌      | 11/31 [00:31<00:36,  1.84s/it, loss=1.7184, batch_acc=0.6250, running_acc=0.6594, grad=24.6988]Training epoch 25:  35%|███▌      | 11/31 [00:31<00:36,  1.84s/it, loss=1.4440, batch_acc=0.7500, running_acc=0.6676, grad=9.2603] Training epoch 25:  39%|███▊      | 12/31 [00:34<00:39,  2.09s/it, loss=1.4440, batch_acc=0.7500, running_acc=0.6676, grad=9.2603]Training epoch 25:  39%|███▊      | 12/31 [00:34<00:39,  2.09s/it, loss=1.9190, batch_acc=0.5938, running_acc=0.6615, grad=23.1922]Training epoch 25:  42%|████▏     | 13/31 [00:35<00:34,  1.91s/it, loss=1.9190, batch_acc=0.5938, running_acc=0.6615, grad=23.1922]Training epoch 25:  42%|████▏     | 13/31 [00:35<00:34,  1.91s/it, loss=1.6950, batch_acc=0.6250, running_acc=0.6587, grad=9.5641] Training epoch 25:  45%|████▌     | 14/31 [00:42<00:58,  3.45s/it, loss=1.6950, batch_acc=0.6250, running_acc=0.6587, grad=9.5641]Training epoch 25:  45%|████▌     | 14/31 [00:42<00:58,  3.45s/it, loss=1.8287, batch_acc=0.5312, running_acc=0.6496, grad=11.8624]Training epoch 25:  48%|████▊     | 15/31 [00:44<00:45,  2.87s/it, loss=1.8287, batch_acc=0.5312, running_acc=0.6496, grad=11.8624]Training epoch 25:  48%|████▊     | 15/31 [00:44<00:45,  2.87s/it, loss=1.7495, batch_acc=0.5938, running_acc=0.6458, grad=8.1580] Training epoch 25:  52%|█████▏    | 16/31 [00:45<00:36,  2.46s/it, loss=1.7495, batch_acc=0.5938, running_acc=0.6458, grad=8.1580]Training epoch 25:  52%|█████▏    | 16/31 [00:45<00:36,  2.46s/it, loss=1.9956, batch_acc=0.4688, running_acc=0.6348, grad=38.4947]Training epoch 25:  55%|█████▍    | 17/31 [00:47<00:33,  2.36s/it, loss=1.9956, batch_acc=0.4688, running_acc=0.6348, grad=38.4947]Training epoch 25:  55%|█████▍    | 17/31 [00:47<00:33,  2.36s/it, loss=1.9777, batch_acc=0.4375, running_acc=0.6232, grad=15.2479]Training epoch 25:  58%|█████▊    | 18/31 [01:01<01:13,  5.68s/it, loss=1.9777, batch_acc=0.4375, running_acc=0.6232, grad=15.2479]Training epoch 25:  58%|█████▊    | 18/31 [01:01<01:13,  5.68s/it, loss=1.5701, batch_acc=0.5625, running_acc=0.6198, grad=12.3406]Training epoch 25:  61%|██████▏   | 19/31 [01:02<00:53,  4.43s/it, loss=1.5701, batch_acc=0.5625, running_acc=0.6198, grad=12.3406]Training epoch 25:  61%|██████▏   | 19/31 [01:02<00:53,  4.43s/it, loss=2.1846, batch_acc=0.4375, running_acc=0.6102, grad=10.3886]Training epoch 25:  65%|██████▍   | 20/31 [01:04<00:39,  3.55s/it, loss=2.1846, batch_acc=0.4375, running_acc=0.6102, grad=10.3886]Training epoch 25:  65%|██████▍   | 20/31 [01:04<00:39,  3.55s/it, loss=1.6187, batch_acc=0.6250, running_acc=0.6109, grad=26.4935]Training epoch 25:  68%|██████▊   | 21/31 [01:05<00:29,  2.94s/it, loss=1.6187, batch_acc=0.6250, running_acc=0.6109, grad=26.4935]Training epoch 25:  68%|██████▊   | 21/31 [01:05<00:29,  2.94s/it, loss=1.7186, batch_acc=0.6250, running_acc=0.6116, grad=8.7348] Training epoch 25:  71%|███████   | 22/31 [01:21<01:01,  6.86s/it, loss=1.7186, batch_acc=0.6250, running_acc=0.6116, grad=8.7348]Training epoch 25:  71%|███████   | 22/31 [01:21<01:01,  6.86s/it, loss=1.6457, batch_acc=0.6250, running_acc=0.6122, grad=6.1548]Training epoch 25:  74%|███████▍  | 23/31 [01:23<00:42,  5.26s/it, loss=1.6457, batch_acc=0.6250, running_acc=0.6122, grad=6.1548]Training epoch 25:  74%|███████▍  | 23/31 [01:23<00:42,  5.26s/it, loss=1.7845, batch_acc=0.5938, running_acc=0.6114, grad=8.3264]Training epoch 25:  77%|███████▋  | 24/31 [01:24<00:28,  4.13s/it, loss=1.7845, batch_acc=0.5938, running_acc=0.6114, grad=8.3264]Training epoch 25:  77%|███████▋  | 24/31 [01:24<00:28,  4.13s/it, loss=1.9654, batch_acc=0.4062, running_acc=0.6029, grad=8.5976]Training epoch 25:  81%|████████  | 25/31 [01:26<00:20,  3.34s/it, loss=1.9654, batch_acc=0.4062, running_acc=0.6029, grad=8.5976]Training epoch 25:  81%|████████  | 25/31 [01:26<00:20,  3.34s/it, loss=2.1775, batch_acc=0.5000, running_acc=0.5988, grad=7.9675]Training epoch 25:  84%|████████▍ | 26/31 [01:31<00:19,  3.85s/it, loss=2.1775, batch_acc=0.5000, running_acc=0.5988, grad=7.9675]Training epoch 25:  84%|████████▍ | 26/31 [01:31<00:19,  3.85s/it, loss=1.6792, batch_acc=0.5625, running_acc=0.5974, grad=23.8995]Training epoch 25:  87%|████████▋ | 27/31 [01:32<00:12,  3.15s/it, loss=1.6792, batch_acc=0.5625, running_acc=0.5974, grad=23.8995]Training epoch 25:  87%|████████▋ | 27/31 [01:32<00:12,  3.15s/it, loss=1.4811, batch_acc=0.6562, running_acc=0.5995, grad=9.9591] Training epoch 25:  90%|█████████ | 28/31 [01:34<00:07,  2.66s/it, loss=1.4811, batch_acc=0.6562, running_acc=0.5995, grad=9.9591]Training epoch 25:  90%|█████████ | 28/31 [01:34<00:07,  2.66s/it, loss=1.9085, batch_acc=0.5938, running_acc=0.5993, grad=9.3769]Training epoch 25:  94%|█████████▎| 29/31 [01:35<00:04,  2.31s/it, loss=1.9085, batch_acc=0.5938, running_acc=0.5993, grad=9.3769]Training epoch 25:  94%|█████████▎| 29/31 [01:35<00:04,  2.31s/it, loss=1.6886, batch_acc=0.6250, running_acc=0.6002, grad=9.4051]Training epoch 25:  97%|█████████▋| 30/31 [01:37<00:02,  2.07s/it, loss=1.6886, batch_acc=0.6250, running_acc=0.6002, grad=9.4051]Training epoch 25:  97%|█████████▋| 30/31 [01:37<00:02,  2.07s/it, loss=1.4843, batch_acc=0.6875, running_acc=0.6031, grad=28.6310]Training epoch 25: 100%|██████████| 31/31 [01:37<00:00,  1.51s/it, loss=1.4843, batch_acc=0.6875, running_acc=0.6031, grad=28.6310]Training epoch 25: 100%|██████████| 31/31 [01:37<00:00,  1.51s/it, loss=1.3306, batch_acc=1.0000, running_acc=0.6040, grad=18.5143]Training epoch 25: 100%|██████████| 31/31 [01:37<00:00,  3.15s/it, loss=1.3306, batch_acc=1.0000, running_acc=0.6040, grad=18.5143]
Evaluation epoch 25:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 25:  20%|██        | 1/5 [00:04<00:19,  4.85s/it]Evaluation epoch 25:  20%|██        | 1/5 [00:04<00:19,  4.85s/it, loss=1.4938, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 25:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.4938, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 25:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.3520, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 25:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.3520, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 25:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.7382, batch_acc=0.6250, running_acc=0.6979]Evaluation epoch 25:  80%|████████  | 4/5 [00:07<00:01,  1.45s/it, loss=1.7382, batch_acc=0.6250, running_acc=0.6979]Evaluation epoch 25:  80%|████████  | 4/5 [00:07<00:01,  1.45s/it, loss=2.0427, batch_acc=0.4062, running_acc=0.6250]Evaluation epoch 25: 100%|██████████| 5/5 [00:08<00:00,  1.21s/it, loss=2.0427, batch_acc=0.4062, running_acc=0.6250]Evaluation epoch 25: 100%|██████████| 5/5 [00:08<00:00,  1.21s/it, loss=2.0917, batch_acc=0.4688, running_acc=0.5938]Evaluation epoch 25: 100%|██████████| 5/5 [00:08<00:00,  1.65s/it, loss=2.0917, batch_acc=0.4688, running_acc=0.5938]
Training epoch 26:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 26:   3%|▎         | 1/31 [00:09<04:32,  9.09s/it]Training epoch 26:   3%|▎         | 1/31 [00:09<04:32,  9.09s/it, loss=1.2534, batch_acc=0.7812, running_acc=0.7812, grad=15.8271]Training epoch 26:   6%|▋         | 2/31 [00:10<02:14,  4.63s/it, loss=1.2534, batch_acc=0.7812, running_acc=0.7812, grad=15.8271]Training epoch 26:   6%|▋         | 2/31 [00:10<02:14,  4.63s/it, loss=1.5901, batch_acc=0.6875, running_acc=0.7344, grad=9.7632] Training epoch 26:  10%|▉         | 3/31 [00:12<01:29,  3.21s/it, loss=1.5901, batch_acc=0.6875, running_acc=0.7344, grad=9.7632]Training epoch 26:  10%|▉         | 3/31 [00:12<01:29,  3.21s/it, loss=1.8186, batch_acc=0.5938, running_acc=0.6875, grad=10.1773]Training epoch 26:  13%|█▎        | 4/31 [00:13<01:08,  2.54s/it, loss=1.8186, batch_acc=0.5938, running_acc=0.6875, grad=10.1773]Training epoch 26:  13%|█▎        | 4/31 [00:13<01:08,  2.54s/it, loss=1.5348, batch_acc=0.7812, running_acc=0.7109, grad=108.6791]Training epoch 26:  16%|█▌        | 5/31 [00:15<00:56,  2.17s/it, loss=1.5348, batch_acc=0.7812, running_acc=0.7109, grad=108.6791]Training epoch 26:  16%|█▌        | 5/31 [00:15<00:56,  2.17s/it, loss=1.4952, batch_acc=0.8438, running_acc=0.7375, grad=28.5017] Training epoch 26:  19%|█▉        | 6/31 [00:16<00:48,  1.95s/it, loss=1.4952, batch_acc=0.8438, running_acc=0.7375, grad=28.5017]Training epoch 26:  19%|█▉        | 6/31 [00:16<00:48,  1.95s/it, loss=1.5793, batch_acc=0.7188, running_acc=0.7344, grad=13.2604]Training epoch 26:  23%|██▎       | 7/31 [00:18<00:43,  1.81s/it, loss=1.5793, batch_acc=0.7188, running_acc=0.7344, grad=13.2604]Training epoch 26:  23%|██▎       | 7/31 [00:18<00:43,  1.81s/it, loss=1.7233, batch_acc=0.5312, running_acc=0.7054, grad=9.4040] Training epoch 26:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=1.7233, batch_acc=0.5312, running_acc=0.7054, grad=9.4040]Training epoch 26:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=1.4228, batch_acc=0.8438, running_acc=0.7227, grad=23.1529]Training epoch 26:  29%|██▉       | 9/31 [00:21<00:36,  1.65s/it, loss=1.4228, batch_acc=0.8438, running_acc=0.7227, grad=23.1529]Training epoch 26:  29%|██▉       | 9/31 [00:21<00:36,  1.65s/it, loss=1.7839, batch_acc=0.5625, running_acc=0.7049, grad=6.4279] Training epoch 26:  32%|███▏      | 10/31 [00:22<00:33,  1.61s/it, loss=1.7839, batch_acc=0.5625, running_acc=0.7049, grad=6.4279]Training epoch 26:  32%|███▏      | 10/31 [00:22<00:33,  1.61s/it, loss=1.3517, batch_acc=0.8125, running_acc=0.7156, grad=6.8698]Training epoch 26:  35%|███▌      | 11/31 [00:24<00:31,  1.58s/it, loss=1.3517, batch_acc=0.8125, running_acc=0.7156, grad=6.8698]Training epoch 26:  35%|███▌      | 11/31 [00:24<00:31,  1.58s/it, loss=1.8043, batch_acc=0.5000, running_acc=0.6960, grad=10.0269]Training epoch 26:  39%|███▊      | 12/31 [00:25<00:29,  1.57s/it, loss=1.8043, batch_acc=0.5000, running_acc=0.6960, grad=10.0269]Training epoch 26:  39%|███▊      | 12/31 [00:25<00:29,  1.57s/it, loss=1.5910, batch_acc=0.6875, running_acc=0.6953, grad=19.0553]Training epoch 26:  42%|████▏     | 13/31 [00:27<00:28,  1.56s/it, loss=1.5910, batch_acc=0.6875, running_acc=0.6953, grad=19.0553]Training epoch 26:  42%|████▏     | 13/31 [00:27<00:28,  1.56s/it, loss=1.6745, batch_acc=0.6875, running_acc=0.6947, grad=28.1250]Training epoch 26:  45%|████▌     | 14/31 [00:28<00:26,  1.55s/it, loss=1.6745, batch_acc=0.6875, running_acc=0.6947, grad=28.1250]Training epoch 26:  45%|████▌     | 14/31 [00:28<00:26,  1.55s/it, loss=1.8339, batch_acc=0.5312, running_acc=0.6830, grad=8.4887] Training epoch 26:  48%|████▊     | 15/31 [00:30<00:24,  1.54s/it, loss=1.8339, batch_acc=0.5312, running_acc=0.6830, grad=8.4887]Training epoch 26:  48%|████▊     | 15/31 [00:30<00:24,  1.54s/it, loss=1.6570, batch_acc=0.6562, running_acc=0.6813, grad=26.3180]Training epoch 26:  52%|█████▏    | 16/31 [00:31<00:22,  1.53s/it, loss=1.6570, batch_acc=0.6562, running_acc=0.6813, grad=26.3180]Training epoch 26:  52%|█████▏    | 16/31 [00:31<00:22,  1.53s/it, loss=1.6464, batch_acc=0.6562, running_acc=0.6797, grad=14.3657]Training epoch 26:  55%|█████▍    | 17/31 [00:33<00:21,  1.53s/it, loss=1.6464, batch_acc=0.6562, running_acc=0.6797, grad=14.3657]Training epoch 26:  55%|█████▍    | 17/31 [00:33<00:21,  1.53s/it, loss=1.6412, batch_acc=0.5625, running_acc=0.6728, grad=12.5993]Training epoch 26:  58%|█████▊    | 18/31 [00:34<00:19,  1.53s/it, loss=1.6412, batch_acc=0.5625, running_acc=0.6728, grad=12.5993]Training epoch 26:  58%|█████▊    | 18/31 [00:34<00:19,  1.53s/it, loss=1.4701, batch_acc=0.7188, running_acc=0.6753, grad=21.8874]Training epoch 26:  61%|██████▏   | 19/31 [00:36<00:18,  1.52s/it, loss=1.4701, batch_acc=0.7188, running_acc=0.6753, grad=21.8874]Training epoch 26:  61%|██████▏   | 19/31 [00:36<00:18,  1.52s/it, loss=1.6645, batch_acc=0.6250, running_acc=0.6727, grad=12.8123]Training epoch 26:  65%|██████▍   | 20/31 [00:37<00:16,  1.52s/it, loss=1.6645, batch_acc=0.6250, running_acc=0.6727, grad=12.8123]Training epoch 26:  65%|██████▍   | 20/31 [00:37<00:16,  1.52s/it, loss=1.6436, batch_acc=0.6250, running_acc=0.6703, grad=9.6860] Training epoch 26:  68%|██████▊   | 21/31 [00:39<00:15,  1.52s/it, loss=1.6436, batch_acc=0.6250, running_acc=0.6703, grad=9.6860]Training epoch 26:  68%|██████▊   | 21/31 [00:39<00:15,  1.52s/it, loss=1.9255, batch_acc=0.5625, running_acc=0.6652, grad=8.5442]Training epoch 26:  71%|███████   | 22/31 [00:41<00:14,  1.57s/it, loss=1.9255, batch_acc=0.5625, running_acc=0.6652, grad=8.5442]Training epoch 26:  71%|███████   | 22/31 [00:41<00:14,  1.57s/it, loss=1.5727, batch_acc=0.6562, running_acc=0.6648, grad=7.7396]Training epoch 26:  74%|███████▍  | 23/31 [00:42<00:12,  1.61s/it, loss=1.5727, batch_acc=0.6562, running_acc=0.6648, grad=7.7396]Training epoch 26:  74%|███████▍  | 23/31 [00:42<00:12,  1.61s/it, loss=1.6474, batch_acc=0.7188, running_acc=0.6671, grad=9.5138]Training epoch 26:  77%|███████▋  | 24/31 [00:44<00:11,  1.66s/it, loss=1.6474, batch_acc=0.7188, running_acc=0.6671, grad=9.5138]Training epoch 26:  77%|███████▋  | 24/31 [00:44<00:11,  1.66s/it, loss=1.6151, batch_acc=0.5938, running_acc=0.6641, grad=10.9923]Training epoch 26:  81%|████████  | 25/31 [00:46<00:09,  1.62s/it, loss=1.6151, batch_acc=0.5938, running_acc=0.6641, grad=10.9923]Training epoch 26:  81%|████████  | 25/31 [00:46<00:09,  1.62s/it, loss=1.4669, batch_acc=0.7500, running_acc=0.6675, grad=7.0158] Training epoch 26:  84%|████████▍ | 26/31 [00:48<00:09,  1.96s/it, loss=1.4669, batch_acc=0.7500, running_acc=0.6675, grad=7.0158]Training epoch 26:  84%|████████▍ | 26/31 [00:48<00:09,  1.96s/it, loss=1.4320, batch_acc=0.6875, running_acc=0.6683, grad=37.9041]Training epoch 26:  87%|████████▋ | 27/31 [00:50<00:07,  1.82s/it, loss=1.4320, batch_acc=0.6875, running_acc=0.6683, grad=37.9041]Training epoch 26:  87%|████████▋ | 27/31 [00:50<00:07,  1.82s/it, loss=1.6986, batch_acc=0.6875, running_acc=0.6690, grad=29.2883]Training epoch 26:  90%|█████████ | 28/31 [00:53<00:06,  2.26s/it, loss=1.6986, batch_acc=0.6875, running_acc=0.6690, grad=29.2883]Training epoch 26:  90%|█████████ | 28/31 [00:53<00:06,  2.26s/it, loss=1.5936, batch_acc=0.6875, running_acc=0.6696, grad=6.7050] Training epoch 26:  94%|█████████▎| 29/31 [00:55<00:04,  2.03s/it, loss=1.5936, batch_acc=0.6875, running_acc=0.6696, grad=6.7050]Training epoch 26:  94%|█████████▎| 29/31 [00:55<00:04,  2.03s/it, loss=1.5673, batch_acc=0.6875, running_acc=0.6703, grad=541.6843]Training epoch 26:  97%|█████████▋| 30/31 [00:56<00:01,  1.87s/it, loss=1.5673, batch_acc=0.6875, running_acc=0.6703, grad=541.6843]Training epoch 26:  97%|█████████▋| 30/31 [00:56<00:01,  1.87s/it, loss=1.6803, batch_acc=0.5938, running_acc=0.6677, grad=7.8807]  Training epoch 26: 100%|██████████| 31/31 [00:56<00:00,  1.37s/it, loss=1.6803, batch_acc=0.5938, running_acc=0.6677, grad=7.8807]Training epoch 26: 100%|██████████| 31/31 [00:56<00:00,  1.37s/it, loss=1.1579, batch_acc=1.0000, running_acc=0.6684, grad=19.8610]Training epoch 26: 100%|██████████| 31/31 [00:56<00:00,  1.84s/it, loss=1.1579, batch_acc=1.0000, running_acc=0.6684, grad=19.8610]
Evaluation epoch 26:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 26:  20%|██        | 1/5 [00:10<00:42, 10.71s/it]Evaluation epoch 26:  20%|██        | 1/5 [00:10<00:42, 10.71s/it, loss=1.4018, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 26:  40%|████      | 2/5 [00:11<00:14,  4.85s/it, loss=1.4018, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 26:  40%|████      | 2/5 [00:11<00:14,  4.85s/it, loss=1.3394, batch_acc=0.8438, running_acc=0.7656]Evaluation epoch 26:  60%|██████    | 3/5 [00:12<00:05,  2.97s/it, loss=1.3394, batch_acc=0.8438, running_acc=0.7656]Evaluation epoch 26:  60%|██████    | 3/5 [00:12<00:05,  2.97s/it, loss=1.7469, batch_acc=0.5312, running_acc=0.6875]Evaluation epoch 26:  80%|████████  | 4/5 [00:15<00:03,  3.01s/it, loss=1.7469, batch_acc=0.5312, running_acc=0.6875]Evaluation epoch 26:  80%|████████  | 4/5 [00:15<00:03,  3.01s/it, loss=1.8685, batch_acc=0.5312, running_acc=0.6484]Evaluation epoch 26: 100%|██████████| 5/5 [00:16<00:00,  2.21s/it, loss=1.8685, batch_acc=0.5312, running_acc=0.6484]Evaluation epoch 26: 100%|██████████| 5/5 [00:16<00:00,  2.21s/it, loss=2.1065, batch_acc=0.4375, running_acc=0.6062]Evaluation epoch 26: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it, loss=2.1065, batch_acc=0.4375, running_acc=0.6062]
Training epoch 27:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 27:   3%|▎         | 1/31 [00:08<04:10,  8.35s/it]Training epoch 27:   3%|▎         | 1/31 [00:08<04:10,  8.35s/it, loss=1.6838, batch_acc=0.5625, running_acc=0.5625, grad=7.3246]Training epoch 27:   6%|▋         | 2/31 [00:09<02:05,  4.33s/it, loss=1.6838, batch_acc=0.5625, running_acc=0.5625, grad=7.3246]Training epoch 27:   6%|▋         | 2/31 [00:09<02:05,  4.33s/it, loss=1.4706, batch_acc=0.6562, running_acc=0.6094, grad=19.7055]Training epoch 27:  10%|▉         | 3/31 [00:11<01:25,  3.04s/it, loss=1.4706, batch_acc=0.6562, running_acc=0.6094, grad=19.7055]Training epoch 27:  10%|▉         | 3/31 [00:11<01:25,  3.04s/it, loss=1.8154, batch_acc=0.6562, running_acc=0.6250, grad=17.2714]Training epoch 27:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=1.8154, batch_acc=0.6562, running_acc=0.6250, grad=17.2714]Training epoch 27:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=1.6499, batch_acc=0.6562, running_acc=0.6328, grad=6.8291] Training epoch 27:  16%|█▌        | 5/31 [00:14<00:55,  2.15s/it, loss=1.6499, batch_acc=0.6562, running_acc=0.6328, grad=6.8291]Training epoch 27:  16%|█▌        | 5/31 [00:14<00:55,  2.15s/it, loss=1.7613, batch_acc=0.7188, running_acc=0.6500, grad=10.0210]Training epoch 27:  19%|█▉        | 6/31 [00:16<00:48,  1.93s/it, loss=1.7613, batch_acc=0.7188, running_acc=0.6500, grad=10.0210]Training epoch 27:  19%|█▉        | 6/31 [00:16<00:48,  1.93s/it, loss=1.5423, batch_acc=0.6875, running_acc=0.6562, grad=8.3652] Training epoch 27:  23%|██▎       | 7/31 [00:17<00:43,  1.79s/it, loss=1.5423, batch_acc=0.6875, running_acc=0.6562, grad=8.3652]Training epoch 27:  23%|██▎       | 7/31 [00:17<00:43,  1.79s/it, loss=1.9159, batch_acc=0.5000, running_acc=0.6339, grad=9.7312]Training epoch 27:  26%|██▌       | 8/31 [00:19<00:39,  1.70s/it, loss=1.9159, batch_acc=0.5000, running_acc=0.6339, grad=9.7312]Training epoch 27:  26%|██▌       | 8/31 [00:19<00:39,  1.70s/it, loss=1.4560, batch_acc=0.6875, running_acc=0.6406, grad=12.9959]Training epoch 27:  29%|██▉       | 9/31 [00:20<00:36,  1.64s/it, loss=1.4560, batch_acc=0.6875, running_acc=0.6406, grad=12.9959]Training epoch 27:  29%|██▉       | 9/31 [00:20<00:36,  1.64s/it, loss=1.8499, batch_acc=0.5625, running_acc=0.6319, grad=11.7659]Training epoch 27:  32%|███▏      | 10/31 [00:22<00:33,  1.60s/it, loss=1.8499, batch_acc=0.5625, running_acc=0.6319, grad=11.7659]Training epoch 27:  32%|███▏      | 10/31 [00:22<00:33,  1.60s/it, loss=1.7023, batch_acc=0.5938, running_acc=0.6281, grad=16.3180]Training epoch 27:  35%|███▌      | 11/31 [00:23<00:31,  1.57s/it, loss=1.7023, batch_acc=0.5938, running_acc=0.6281, grad=16.3180]Training epoch 27:  35%|███▌      | 11/31 [00:23<00:31,  1.57s/it, loss=1.5917, batch_acc=0.6250, running_acc=0.6278, grad=12.5522]Training epoch 27:  39%|███▊      | 12/31 [00:25<00:29,  1.55s/it, loss=1.5917, batch_acc=0.6250, running_acc=0.6278, grad=12.5522]Training epoch 27:  39%|███▊      | 12/31 [00:25<00:29,  1.55s/it, loss=1.3632, batch_acc=0.7812, running_acc=0.6406, grad=46.7710]Training epoch 27:  42%|████▏     | 13/31 [00:27<00:30,  1.68s/it, loss=1.3632, batch_acc=0.7812, running_acc=0.6406, grad=46.7710]Training epoch 27:  42%|████▏     | 13/31 [00:27<00:30,  1.68s/it, loss=1.7953, batch_acc=0.6250, running_acc=0.6394, grad=13.1551]Training epoch 27:  45%|████▌     | 14/31 [00:28<00:27,  1.64s/it, loss=1.7953, batch_acc=0.6250, running_acc=0.6394, grad=13.1551]Training epoch 27:  45%|████▌     | 14/31 [00:28<00:27,  1.64s/it, loss=1.5408, batch_acc=0.7500, running_acc=0.6473, grad=7.8237] Training epoch 27:  48%|████▊     | 15/31 [00:30<00:25,  1.60s/it, loss=1.5408, batch_acc=0.7500, running_acc=0.6473, grad=7.8237]Training epoch 27:  48%|████▊     | 15/31 [00:30<00:25,  1.60s/it, loss=1.2766, batch_acc=0.8125, running_acc=0.6583, grad=9.9124]Training epoch 27:  52%|█████▏    | 16/31 [00:31<00:23,  1.57s/it, loss=1.2766, batch_acc=0.8125, running_acc=0.6583, grad=9.9124]Training epoch 27:  52%|█████▏    | 16/31 [00:31<00:23,  1.57s/it, loss=1.7974, batch_acc=0.6250, running_acc=0.6562, grad=10.0938]Training epoch 27:  55%|█████▍    | 17/31 [00:33<00:21,  1.55s/it, loss=1.7974, batch_acc=0.6250, running_acc=0.6562, grad=10.0938]Training epoch 27:  55%|█████▍    | 17/31 [00:33<00:21,  1.55s/it, loss=1.7176, batch_acc=0.6562, running_acc=0.6562, grad=27.1881]Training epoch 27:  58%|█████▊    | 18/31 [00:35<00:23,  1.78s/it, loss=1.7176, batch_acc=0.6562, running_acc=0.6562, grad=27.1881]Training epoch 27:  58%|█████▊    | 18/31 [00:35<00:23,  1.78s/it, loss=1.3621, batch_acc=0.7188, running_acc=0.6597, grad=6.9956] Training epoch 27:  61%|██████▏   | 19/31 [00:36<00:20,  1.69s/it, loss=1.3621, batch_acc=0.7188, running_acc=0.6597, grad=6.9956]Training epoch 27:  61%|██████▏   | 19/31 [00:36<00:20,  1.69s/it, loss=1.4616, batch_acc=0.6875, running_acc=0.6612, grad=13.2514]Training epoch 27:  65%|██████▍   | 20/31 [00:38<00:18,  1.64s/it, loss=1.4616, batch_acc=0.6875, running_acc=0.6612, grad=13.2514]Training epoch 27:  65%|██████▍   | 20/31 [00:38<00:18,  1.64s/it, loss=1.4984, batch_acc=0.6562, running_acc=0.6609, grad=12.0226]Training epoch 27:  68%|██████▊   | 21/31 [00:40<00:16,  1.62s/it, loss=1.4984, batch_acc=0.6562, running_acc=0.6609, grad=12.0226]Training epoch 27:  68%|██████▊   | 21/31 [00:40<00:16,  1.62s/it, loss=1.5612, batch_acc=0.7188, running_acc=0.6637, grad=12.8747]Training epoch 27:  71%|███████   | 22/31 [00:45<00:25,  2.85s/it, loss=1.5612, batch_acc=0.7188, running_acc=0.6637, grad=12.8747]Training epoch 27:  71%|███████   | 22/31 [00:45<00:25,  2.85s/it, loss=1.5167, batch_acc=0.7500, running_acc=0.6676, grad=12.3197]Training epoch 27:  74%|███████▍  | 23/31 [00:47<00:19,  2.45s/it, loss=1.5167, batch_acc=0.7500, running_acc=0.6676, grad=12.3197]Training epoch 27:  74%|███████▍  | 23/31 [00:47<00:19,  2.45s/it, loss=1.4012, batch_acc=0.7188, running_acc=0.6698, grad=12.5791]Training epoch 27:  77%|███████▋  | 24/31 [00:48<00:15,  2.17s/it, loss=1.4012, batch_acc=0.7188, running_acc=0.6698, grad=12.5791]Training epoch 27:  77%|███████▋  | 24/31 [00:48<00:15,  2.17s/it, loss=1.4157, batch_acc=0.7188, running_acc=0.6719, grad=8.6782] Training epoch 27:  81%|████████  | 25/31 [00:50<00:11,  1.97s/it, loss=1.4157, batch_acc=0.7188, running_acc=0.6719, grad=8.6782]Training epoch 27:  81%|████████  | 25/31 [00:50<00:11,  1.97s/it, loss=1.6571, batch_acc=0.5938, running_acc=0.6687, grad=16.8958]Training epoch 27:  84%|████████▍ | 26/31 [00:51<00:09,  1.83s/it, loss=1.6571, batch_acc=0.5938, running_acc=0.6687, grad=16.8958]Training epoch 27:  84%|████████▍ | 26/31 [00:51<00:09,  1.83s/it, loss=1.9535, batch_acc=0.5000, running_acc=0.6623, grad=15.8314]Training epoch 27:  87%|████████▋ | 27/31 [00:53<00:06,  1.73s/it, loss=1.9535, batch_acc=0.5000, running_acc=0.6623, grad=15.8314]Training epoch 27:  87%|████████▋ | 27/31 [00:53<00:06,  1.73s/it, loss=1.4573, batch_acc=0.7500, running_acc=0.6655, grad=15.8632]Training epoch 27:  90%|█████████ | 28/31 [00:54<00:04,  1.66s/it, loss=1.4573, batch_acc=0.7500, running_acc=0.6655, grad=15.8632]Training epoch 27:  90%|█████████ | 28/31 [00:54<00:04,  1.66s/it, loss=1.4832, batch_acc=0.6562, running_acc=0.6652, grad=15.2574]Training epoch 27:  94%|█████████▎| 29/31 [00:56<00:03,  1.62s/it, loss=1.4832, batch_acc=0.6562, running_acc=0.6652, grad=15.2574]Training epoch 27:  94%|█████████▎| 29/31 [00:56<00:03,  1.62s/it, loss=1.4420, batch_acc=0.6562, running_acc=0.6649, grad=16.6005]Training epoch 27:  97%|█████████▋| 30/31 [00:57<00:01,  1.58s/it, loss=1.4420, batch_acc=0.6562, running_acc=0.6649, grad=16.6005]Training epoch 27:  97%|█████████▋| 30/31 [00:57<00:01,  1.58s/it, loss=1.3992, batch_acc=0.7812, running_acc=0.6687, grad=29.1221]Training epoch 27: 100%|██████████| 31/31 [00:58<00:00,  1.17s/it, loss=1.3992, batch_acc=0.7812, running_acc=0.6687, grad=29.1221]Training epoch 27: 100%|██████████| 31/31 [00:58<00:00,  1.17s/it, loss=0.9275, batch_acc=1.0000, running_acc=0.6694, grad=11.5948]Training epoch 27: 100%|██████████| 31/31 [00:58<00:00,  1.87s/it, loss=0.9275, batch_acc=1.0000, running_acc=0.6694, grad=11.5948]
Evaluation epoch 27:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 27:  20%|██        | 1/5 [00:12<00:48, 12.10s/it]Evaluation epoch 27:  20%|██        | 1/5 [00:12<00:48, 12.10s/it, loss=1.4257, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 27:  40%|████      | 2/5 [00:12<00:16,  5.42s/it, loss=1.4257, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 27:  40%|████      | 2/5 [00:12<00:16,  5.42s/it, loss=1.3281, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 27:  60%|██████    | 3/5 [00:13<00:06,  3.28s/it, loss=1.3281, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 27:  60%|██████    | 3/5 [00:13<00:06,  3.28s/it, loss=1.6533, batch_acc=0.5625, running_acc=0.6875]Evaluation epoch 27:  80%|████████  | 4/5 [00:17<00:03,  3.55s/it, loss=1.6533, batch_acc=0.5625, running_acc=0.6875]Evaluation epoch 27:  80%|████████  | 4/5 [00:17<00:03,  3.55s/it, loss=1.8478, batch_acc=0.4688, running_acc=0.6328]Evaluation epoch 27: 100%|██████████| 5/5 [00:18<00:00,  2.55s/it, loss=1.8478, batch_acc=0.4688, running_acc=0.6328]Evaluation epoch 27: 100%|██████████| 5/5 [00:18<00:00,  2.55s/it, loss=2.0252, batch_acc=0.5000, running_acc=0.6062]Evaluation epoch 27: 100%|██████████| 5/5 [00:18<00:00,  3.66s/it, loss=2.0252, batch_acc=0.5000, running_acc=0.6062]
Training epoch 28:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 28:   3%|▎         | 1/31 [00:08<04:26,  8.87s/it]Training epoch 28:   3%|▎         | 1/31 [00:08<04:26,  8.87s/it, loss=1.6738, batch_acc=0.7188, running_acc=0.7188, grad=9.3590]Training epoch 28:   6%|▋         | 2/31 [00:10<02:11,  4.54s/it, loss=1.6738, batch_acc=0.7188, running_acc=0.7188, grad=9.3590]Training epoch 28:   6%|▋         | 2/31 [00:10<02:11,  4.54s/it, loss=1.4431, batch_acc=0.7500, running_acc=0.7344, grad=20.8331]Training epoch 28:  10%|▉         | 3/31 [00:11<01:28,  3.16s/it, loss=1.4431, batch_acc=0.7500, running_acc=0.7344, grad=20.8331]Training epoch 28:  10%|▉         | 3/31 [00:11<01:28,  3.16s/it, loss=1.5095, batch_acc=0.6562, running_acc=0.7083, grad=10.4157]Training epoch 28:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=1.5095, batch_acc=0.6562, running_acc=0.7083, grad=10.4157]Training epoch 28:  13%|█▎        | 4/31 [00:13<01:07,  2.51s/it, loss=1.6862, batch_acc=0.5938, running_acc=0.6797, grad=7.7857] Training epoch 28:  16%|█▌        | 5/31 [00:17<01:18,  3.03s/it, loss=1.6862, batch_acc=0.5938, running_acc=0.6797, grad=7.7857]Training epoch 28:  16%|█▌        | 5/31 [00:17<01:18,  3.03s/it, loss=1.4434, batch_acc=0.7188, running_acc=0.6875, grad=10.6086]Training epoch 28:  19%|█▉        | 6/31 [00:18<01:03,  2.53s/it, loss=1.4434, batch_acc=0.7188, running_acc=0.6875, grad=10.6086]Training epoch 28:  19%|█▉        | 6/31 [00:18<01:03,  2.53s/it, loss=1.5054, batch_acc=0.7188, running_acc=0.6927, grad=9.2140] Training epoch 28:  23%|██▎       | 7/31 [00:20<00:52,  2.19s/it, loss=1.5054, batch_acc=0.7188, running_acc=0.6927, grad=9.2140]Training epoch 28:  23%|██▎       | 7/31 [00:20<00:52,  2.19s/it, loss=1.5749, batch_acc=0.6562, running_acc=0.6875, grad=11.7040]Training epoch 28:  26%|██▌       | 8/31 [00:21<00:45,  1.98s/it, loss=1.5749, batch_acc=0.6562, running_acc=0.6875, grad=11.7040]Training epoch 28:  26%|██▌       | 8/31 [00:21<00:45,  1.98s/it, loss=1.4773, batch_acc=0.6875, running_acc=0.6875, grad=8.6055] Training epoch 28:  29%|██▉       | 9/31 [00:23<00:40,  1.83s/it, loss=1.4773, batch_acc=0.6875, running_acc=0.6875, grad=8.6055]Training epoch 28:  29%|██▉       | 9/31 [00:23<00:40,  1.83s/it, loss=1.3181, batch_acc=0.7812, running_acc=0.6979, grad=37.8470]Training epoch 28:  32%|███▏      | 10/31 [00:24<00:36,  1.73s/it, loss=1.3181, batch_acc=0.7812, running_acc=0.6979, grad=37.8470]Training epoch 28:  32%|███▏      | 10/31 [00:24<00:36,  1.73s/it, loss=1.4505, batch_acc=0.6250, running_acc=0.6906, grad=18.5042]Training epoch 28:  35%|███▌      | 11/31 [00:26<00:33,  1.66s/it, loss=1.4505, batch_acc=0.6250, running_acc=0.6906, grad=18.5042]Training epoch 28:  35%|███▌      | 11/31 [00:26<00:33,  1.66s/it, loss=1.3149, batch_acc=0.7188, running_acc=0.6932, grad=20.4476]Training epoch 28:  39%|███▊      | 12/31 [00:27<00:30,  1.62s/it, loss=1.3149, batch_acc=0.7188, running_acc=0.6932, grad=20.4476]Training epoch 28:  39%|███▊      | 12/31 [00:27<00:30,  1.62s/it, loss=1.3953, batch_acc=0.6875, running_acc=0.6927, grad=12.3153]Training epoch 28:  42%|████▏     | 13/31 [00:29<00:28,  1.59s/it, loss=1.3953, batch_acc=0.6875, running_acc=0.6927, grad=12.3153]Training epoch 28:  42%|████▏     | 13/31 [00:29<00:28,  1.59s/it, loss=1.5886, batch_acc=0.7500, running_acc=0.6971, grad=6.4817] Training epoch 28:  45%|████▌     | 14/31 [00:30<00:26,  1.56s/it, loss=1.5886, batch_acc=0.7500, running_acc=0.6971, grad=6.4817]Training epoch 28:  45%|████▌     | 14/31 [00:30<00:26,  1.56s/it, loss=1.6144, batch_acc=0.6250, running_acc=0.6920, grad=13.8134]Training epoch 28:  48%|████▊     | 15/31 [00:32<00:24,  1.55s/it, loss=1.6144, batch_acc=0.6250, running_acc=0.6920, grad=13.8134]Training epoch 28:  48%|████▊     | 15/31 [00:32<00:24,  1.55s/it, loss=1.8584, batch_acc=0.5000, running_acc=0.6792, grad=16.0215]Training epoch 28:  52%|█████▏    | 16/31 [00:35<00:27,  1.86s/it, loss=1.8584, batch_acc=0.5000, running_acc=0.6792, grad=16.0215]Training epoch 28:  52%|█████▏    | 16/31 [00:35<00:27,  1.86s/it, loss=1.6214, batch_acc=0.7500, running_acc=0.6836, grad=13.0168]Training epoch 28:  55%|█████▍    | 17/31 [00:37<00:27,  1.97s/it, loss=1.6214, batch_acc=0.7500, running_acc=0.6836, grad=13.0168]Training epoch 28:  55%|█████▍    | 17/31 [00:37<00:27,  1.97s/it, loss=1.5880, batch_acc=0.6250, running_acc=0.6801, grad=13.6191]Training epoch 28:  58%|█████▊    | 18/31 [00:38<00:23,  1.83s/it, loss=1.5880, batch_acc=0.6250, running_acc=0.6801, grad=13.6191]Training epoch 28:  58%|█████▊    | 18/31 [00:38<00:23,  1.83s/it, loss=1.5622, batch_acc=0.7500, running_acc=0.6840, grad=9.7127] Training epoch 28:  61%|██████▏   | 19/31 [00:40<00:20,  1.74s/it, loss=1.5622, batch_acc=0.7500, running_acc=0.6840, grad=9.7127]Training epoch 28:  61%|██████▏   | 19/31 [00:40<00:20,  1.74s/it, loss=1.6090, batch_acc=0.6562, running_acc=0.6826, grad=18.7063]Training epoch 28:  65%|██████▍   | 20/31 [00:45<00:30,  2.76s/it, loss=1.6090, batch_acc=0.6562, running_acc=0.6826, grad=18.7063]Training epoch 28:  65%|██████▍   | 20/31 [00:45<00:30,  2.76s/it, loss=1.6303, batch_acc=0.5938, running_acc=0.6781, grad=38.4356]Training epoch 28:  68%|██████▊   | 21/31 [00:47<00:23,  2.39s/it, loss=1.6303, batch_acc=0.5938, running_acc=0.6781, grad=38.4356]Training epoch 28:  68%|██████▊   | 21/31 [00:47<00:23,  2.39s/it, loss=1.3921, batch_acc=0.6562, running_acc=0.6771, grad=7.1150] Training epoch 28:  71%|███████   | 22/31 [00:48<00:19,  2.12s/it, loss=1.3921, batch_acc=0.6562, running_acc=0.6771, grad=7.1150]Training epoch 28:  71%|███████   | 22/31 [00:48<00:19,  2.12s/it, loss=1.7700, batch_acc=0.6562, running_acc=0.6761, grad=15.1324]Training epoch 28:  74%|███████▍  | 23/31 [00:50<00:15,  1.94s/it, loss=1.7700, batch_acc=0.6562, running_acc=0.6761, grad=15.1324]Training epoch 28:  74%|███████▍  | 23/31 [00:50<00:15,  1.94s/it, loss=1.4783, batch_acc=0.7812, running_acc=0.6807, grad=12.4628]Training epoch 28:  77%|███████▋  | 24/31 [00:54<00:18,  2.66s/it, loss=1.4783, batch_acc=0.7812, running_acc=0.6807, grad=12.4628]Training epoch 28:  77%|███████▋  | 24/31 [00:54<00:18,  2.66s/it, loss=1.9088, batch_acc=0.4688, running_acc=0.6719, grad=11.2045]Training epoch 28:  81%|████████  | 25/31 [00:55<00:13,  2.31s/it, loss=1.9088, batch_acc=0.4688, running_acc=0.6719, grad=11.2045]Training epoch 28:  81%|████████  | 25/31 [00:55<00:13,  2.31s/it, loss=1.6535, batch_acc=0.5312, running_acc=0.6663, grad=5.4534] Training epoch 28:  84%|████████▍ | 26/31 [00:57<00:10,  2.07s/it, loss=1.6535, batch_acc=0.5312, running_acc=0.6663, grad=5.4534]Training epoch 28:  84%|████████▍ | 26/31 [00:57<00:10,  2.07s/it, loss=1.4003, batch_acc=0.8125, running_acc=0.6719, grad=11.5687]Training epoch 28:  87%|████████▋ | 27/31 [00:58<00:07,  1.90s/it, loss=1.4003, batch_acc=0.8125, running_acc=0.6719, grad=11.5687]Training epoch 28:  87%|████████▋ | 27/31 [00:58<00:07,  1.90s/it, loss=1.7145, batch_acc=0.6562, running_acc=0.6713, grad=6.9708] Training epoch 28:  90%|█████████ | 28/31 [01:00<00:05,  1.78s/it, loss=1.7145, batch_acc=0.6562, running_acc=0.6713, grad=6.9708]Training epoch 28:  90%|█████████ | 28/31 [01:00<00:05,  1.78s/it, loss=1.5813, batch_acc=0.6875, running_acc=0.6719, grad=11.4258]Training epoch 28:  94%|█████████▎| 29/31 [01:01<00:03,  1.70s/it, loss=1.5813, batch_acc=0.6875, running_acc=0.6719, grad=11.4258]Training epoch 28:  94%|█████████▎| 29/31 [01:01<00:03,  1.70s/it, loss=1.3943, batch_acc=0.8125, running_acc=0.6767, grad=8.7621] Training epoch 28:  97%|█████████▋| 30/31 [01:03<00:01,  1.64s/it, loss=1.3943, batch_acc=0.8125, running_acc=0.6767, grad=8.7621]Training epoch 28:  97%|█████████▋| 30/31 [01:03<00:01,  1.64s/it, loss=1.7814, batch_acc=0.5938, running_acc=0.6740, grad=9.3615]Training epoch 28: 100%|██████████| 31/31 [01:03<00:00,  1.21s/it, loss=1.7814, batch_acc=0.5938, running_acc=0.6740, grad=9.3615]Training epoch 28: 100%|██████████| 31/31 [01:03<00:00,  1.21s/it, loss=0.9825, batch_acc=1.0000, running_acc=0.6746, grad=14.7266]Training epoch 28: 100%|██████████| 31/31 [01:03<00:00,  2.05s/it, loss=0.9825, batch_acc=1.0000, running_acc=0.6746, grad=14.7266]
Evaluation epoch 28:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 28:  20%|██        | 1/5 [00:04<00:18,  4.73s/it]Evaluation epoch 28:  20%|██        | 1/5 [00:04<00:18,  4.73s/it, loss=1.4936, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 28:  40%|████      | 2/5 [00:05<00:07,  2.38s/it, loss=1.4936, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 28:  40%|████      | 2/5 [00:05<00:07,  2.38s/it, loss=1.2503, batch_acc=0.7812, running_acc=0.7188]Evaluation epoch 28:  60%|██████    | 3/5 [00:06<00:03,  1.65s/it, loss=1.2503, batch_acc=0.7812, running_acc=0.7188]Evaluation epoch 28:  60%|██████    | 3/5 [00:06<00:03,  1.65s/it, loss=1.6078, batch_acc=0.4688, running_acc=0.6354]Evaluation epoch 28:  80%|████████  | 4/5 [00:07<00:01,  1.49s/it, loss=1.6078, batch_acc=0.4688, running_acc=0.6354]Evaluation epoch 28:  80%|████████  | 4/5 [00:07<00:01,  1.49s/it, loss=1.9870, batch_acc=0.4375, running_acc=0.5859]Evaluation epoch 28: 100%|██████████| 5/5 [00:08<00:00,  1.23s/it, loss=1.9870, batch_acc=0.4375, running_acc=0.5859]Evaluation epoch 28: 100%|██████████| 5/5 [00:08<00:00,  1.23s/it, loss=1.9182, batch_acc=0.5312, running_acc=0.5750]Evaluation epoch 28: 100%|██████████| 5/5 [00:08<00:00,  1.66s/it, loss=1.9182, batch_acc=0.5312, running_acc=0.5750]
Training epoch 29:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 29:   3%|▎         | 1/31 [00:08<04:24,  8.81s/it]Training epoch 29:   3%|▎         | 1/31 [00:08<04:24,  8.81s/it, loss=1.4744, batch_acc=0.7500, running_acc=0.7500, grad=15.4097]Training epoch 29:   6%|▋         | 2/31 [00:11<02:32,  5.26s/it, loss=1.4744, batch_acc=0.7500, running_acc=0.7500, grad=15.4097]Training epoch 29:   6%|▋         | 2/31 [00:11<02:32,  5.26s/it, loss=1.8109, batch_acc=0.5938, running_acc=0.6719, grad=21.1599]Training epoch 29:  10%|▉         | 3/31 [00:13<01:39,  3.55s/it, loss=1.8109, batch_acc=0.5938, running_acc=0.6719, grad=21.1599]Training epoch 29:  10%|▉         | 3/31 [00:13<01:39,  3.55s/it, loss=1.5009, batch_acc=0.7500, running_acc=0.6979, grad=8.6731] Training epoch 29:  13%|█▎        | 4/31 [00:17<01:46,  3.93s/it, loss=1.5009, batch_acc=0.7500, running_acc=0.6979, grad=8.6731]Training epoch 29:  13%|█▎        | 4/31 [00:17<01:46,  3.93s/it, loss=1.8363, batch_acc=0.5625, running_acc=0.6641, grad=8.2832]Training epoch 29:  16%|█▌        | 5/31 [00:19<01:19,  3.06s/it, loss=1.8363, batch_acc=0.5625, running_acc=0.6641, grad=8.2832]Training epoch 29:  16%|█▌        | 5/31 [00:19<01:19,  3.06s/it, loss=1.3014, batch_acc=0.8438, running_acc=0.7000, grad=31.5929]Training epoch 29:  19%|█▉        | 6/31 [00:20<01:03,  2.53s/it, loss=1.3014, batch_acc=0.8438, running_acc=0.7000, grad=31.5929]Training epoch 29:  19%|█▉        | 6/31 [00:20<01:03,  2.53s/it, loss=1.4489, batch_acc=0.7500, running_acc=0.7083, grad=14.1897]Training epoch 29:  23%|██▎       | 7/31 [00:22<00:52,  2.20s/it, loss=1.4489, batch_acc=0.7500, running_acc=0.7083, grad=14.1897]Training epoch 29:  23%|██▎       | 7/31 [00:22<00:52,  2.20s/it, loss=1.6191, batch_acc=0.6250, running_acc=0.6964, grad=10.5952]Training epoch 29:  26%|██▌       | 8/31 [00:23<00:45,  1.98s/it, loss=1.6191, batch_acc=0.6250, running_acc=0.6964, grad=10.5952]Training epoch 29:  26%|██▌       | 8/31 [00:23<00:45,  1.98s/it, loss=1.5393, batch_acc=0.7500, running_acc=0.7031, grad=10.6945]Training epoch 29:  29%|██▉       | 9/31 [00:25<00:40,  1.83s/it, loss=1.5393, batch_acc=0.7500, running_acc=0.7031, grad=10.6945]Training epoch 29:  29%|██▉       | 9/31 [00:25<00:40,  1.83s/it, loss=1.7284, batch_acc=0.5000, running_acc=0.6806, grad=20.7838]Training epoch 29:  32%|███▏      | 10/31 [00:26<00:36,  1.73s/it, loss=1.7284, batch_acc=0.5000, running_acc=0.6806, grad=20.7838]Training epoch 29:  32%|███▏      | 10/31 [00:26<00:36,  1.73s/it, loss=1.5279, batch_acc=0.6562, running_acc=0.6781, grad=12.4062]Training epoch 29:  35%|███▌      | 11/31 [00:28<00:33,  1.66s/it, loss=1.5279, batch_acc=0.6562, running_acc=0.6781, grad=12.4062]Training epoch 29:  35%|███▌      | 11/31 [00:28<00:33,  1.66s/it, loss=1.6808, batch_acc=0.6875, running_acc=0.6790, grad=10.7012]Training epoch 29:  39%|███▊      | 12/31 [00:29<00:30,  1.62s/it, loss=1.6808, batch_acc=0.6875, running_acc=0.6790, grad=10.7012]Training epoch 29:  39%|███▊      | 12/31 [00:29<00:30,  1.62s/it, loss=1.4366, batch_acc=0.6875, running_acc=0.6797, grad=9.2136] Training epoch 29:  42%|████▏     | 13/31 [00:31<00:28,  1.58s/it, loss=1.4366, batch_acc=0.6875, running_acc=0.6797, grad=9.2136]Training epoch 29:  42%|████▏     | 13/31 [00:31<00:28,  1.58s/it, loss=1.8023, batch_acc=0.6250, running_acc=0.6755, grad=20.8056]Training epoch 29:  45%|████▌     | 14/31 [00:32<00:26,  1.56s/it, loss=1.8023, batch_acc=0.6250, running_acc=0.6755, grad=20.8056]Training epoch 29:  45%|████▌     | 14/31 [00:32<00:26,  1.56s/it, loss=1.3350, batch_acc=0.8750, running_acc=0.6897, grad=11.0098]Training epoch 29:  48%|████▊     | 15/31 [00:34<00:24,  1.54s/it, loss=1.3350, batch_acc=0.8750, running_acc=0.6897, grad=11.0098]Training epoch 29:  48%|████▊     | 15/31 [00:34<00:24,  1.54s/it, loss=1.5413, batch_acc=0.6562, running_acc=0.6875, grad=7.5531] Training epoch 29:  52%|█████▏    | 16/31 [00:41<00:50,  3.36s/it, loss=1.5413, batch_acc=0.6562, running_acc=0.6875, grad=7.5531]Training epoch 29:  52%|█████▏    | 16/31 [00:41<00:50,  3.36s/it, loss=1.5516, batch_acc=0.6250, running_acc=0.6836, grad=12.2803]Training epoch 29:  55%|█████▍    | 17/31 [00:43<00:39,  2.80s/it, loss=1.5516, batch_acc=0.6250, running_acc=0.6836, grad=12.2803]Training epoch 29:  55%|█████▍    | 17/31 [00:43<00:39,  2.80s/it, loss=1.6374, batch_acc=0.6562, running_acc=0.6820, grad=23.5043]Training epoch 29:  58%|█████▊    | 18/31 [00:44<00:31,  2.41s/it, loss=1.6374, batch_acc=0.6562, running_acc=0.6820, grad=23.5043]Training epoch 29:  58%|█████▊    | 18/31 [00:44<00:31,  2.41s/it, loss=1.2472, batch_acc=0.8750, running_acc=0.6927, grad=13.3336]Training epoch 29:  61%|██████▏   | 19/31 [00:46<00:25,  2.14s/it, loss=1.2472, batch_acc=0.8750, running_acc=0.6927, grad=13.3336]Training epoch 29:  61%|██████▏   | 19/31 [00:46<00:25,  2.14s/it, loss=1.5607, batch_acc=0.6875, running_acc=0.6924, grad=7.5747] Training epoch 29:  65%|██████▍   | 20/31 [00:48<00:22,  2.03s/it, loss=1.5607, batch_acc=0.6875, running_acc=0.6924, grad=7.5747]Training epoch 29:  65%|██████▍   | 20/31 [00:48<00:22,  2.03s/it, loss=1.7935, batch_acc=0.5625, running_acc=0.6859, grad=22.0381]Training epoch 29:  68%|██████▊   | 21/31 [00:49<00:18,  1.87s/it, loss=1.7935, batch_acc=0.5625, running_acc=0.6859, grad=22.0381]Training epoch 29:  68%|██████▊   | 21/31 [00:49<00:18,  1.87s/it, loss=1.3763, batch_acc=0.6875, running_acc=0.6860, grad=13.1144]Training epoch 29:  71%|███████   | 22/31 [00:51<00:15,  1.76s/it, loss=1.3763, batch_acc=0.6875, running_acc=0.6860, grad=13.1144]Training epoch 29:  71%|███████   | 22/31 [00:51<00:15,  1.76s/it, loss=1.4033, batch_acc=0.7500, running_acc=0.6889, grad=16.3870]Training epoch 29:  74%|███████▍  | 23/31 [00:53<00:14,  1.86s/it, loss=1.4033, batch_acc=0.7500, running_acc=0.6889, grad=16.3870]Training epoch 29:  74%|███████▍  | 23/31 [00:53<00:14,  1.86s/it, loss=1.4636, batch_acc=0.6562, running_acc=0.6875, grad=7.6735] Training epoch 29:  77%|███████▋  | 24/31 [00:57<00:19,  2.74s/it, loss=1.4636, batch_acc=0.6562, running_acc=0.6875, grad=7.6735]Training epoch 29:  77%|███████▋  | 24/31 [00:57<00:19,  2.74s/it, loss=2.0063, batch_acc=0.5000, running_acc=0.6797, grad=16.5029]Training epoch 29:  81%|████████  | 25/31 [00:59<00:14,  2.37s/it, loss=2.0063, batch_acc=0.5000, running_acc=0.6797, grad=16.5029]Training epoch 29:  81%|████████  | 25/31 [00:59<00:14,  2.37s/it, loss=1.5818, batch_acc=0.6562, running_acc=0.6787, grad=21.0005]Training epoch 29:  84%|████████▍ | 26/31 [01:00<00:10,  2.11s/it, loss=1.5818, batch_acc=0.6562, running_acc=0.6787, grad=21.0005]Training epoch 29:  84%|████████▍ | 26/31 [01:01<00:10,  2.11s/it, loss=1.8798, batch_acc=0.6250, running_acc=0.6767, grad=36.1233]Training epoch 29:  87%|████████▋ | 27/31 [01:02<00:07,  1.94s/it, loss=1.8798, batch_acc=0.6250, running_acc=0.6767, grad=36.1233]Training epoch 29:  87%|████████▋ | 27/31 [01:02<00:07,  1.94s/it, loss=1.6353, batch_acc=0.6562, running_acc=0.6759, grad=12.2738]Training epoch 29:  90%|█████████ | 28/31 [01:12<00:12,  4.23s/it, loss=1.6353, batch_acc=0.6562, running_acc=0.6759, grad=12.2738]Training epoch 29:  90%|█████████ | 28/31 [01:12<00:12,  4.23s/it, loss=1.7848, batch_acc=0.6250, running_acc=0.6741, grad=13.8686]Training epoch 29:  94%|█████████▎| 29/31 [01:13<00:06,  3.41s/it, loss=1.7848, batch_acc=0.6250, running_acc=0.6741, grad=13.8686]Training epoch 29:  94%|█████████▎| 29/31 [01:13<00:06,  3.41s/it, loss=1.3616, batch_acc=0.7188, running_acc=0.6756, grad=22.8523]Training epoch 29:  97%|█████████▋| 30/31 [01:15<00:02,  2.84s/it, loss=1.3616, batch_acc=0.7188, running_acc=0.6756, grad=22.8523]Training epoch 29:  97%|█████████▋| 30/31 [01:15<00:02,  2.84s/it, loss=1.3975, batch_acc=0.7812, running_acc=0.6792, grad=7.1475] Training epoch 29: 100%|██████████| 31/31 [01:15<00:00,  2.05s/it, loss=1.3975, batch_acc=0.7812, running_acc=0.6792, grad=7.1475]Training epoch 29: 100%|██████████| 31/31 [01:15<00:00,  2.05s/it, loss=1.4585, batch_acc=0.5000, running_acc=0.6788, grad=28.5120]Training epoch 29: 100%|██████████| 31/31 [01:15<00:00,  2.43s/it, loss=1.4585, batch_acc=0.5000, running_acc=0.6788, grad=28.5120]
Evaluation epoch 29:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 29:  20%|██        | 1/5 [00:12<00:50, 12.52s/it]Evaluation epoch 29:  20%|██        | 1/5 [00:12<00:50, 12.52s/it, loss=1.4967, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 29:  40%|████      | 2/5 [00:13<00:16,  5.59s/it, loss=1.4967, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 29:  40%|████      | 2/5 [00:13<00:16,  5.59s/it, loss=1.2000, batch_acc=0.8125, running_acc=0.7344]Evaluation epoch 29:  60%|██████    | 3/5 [00:14<00:06,  3.38s/it, loss=1.2000, batch_acc=0.8125, running_acc=0.7344]Evaluation epoch 29:  60%|██████    | 3/5 [00:14<00:06,  3.38s/it, loss=1.7879, batch_acc=0.4688, running_acc=0.6458]Evaluation epoch 29:  80%|████████  | 4/5 [00:27<00:07,  7.42s/it, loss=1.7879, batch_acc=0.4688, running_acc=0.6458]Evaluation epoch 29:  80%|████████  | 4/5 [00:27<00:07,  7.42s/it, loss=1.9516, batch_acc=0.4375, running_acc=0.5938]Evaluation epoch 29: 100%|██████████| 5/5 [00:28<00:00,  5.02s/it, loss=1.9516, batch_acc=0.4375, running_acc=0.5938]Evaluation epoch 29: 100%|██████████| 5/5 [00:28<00:00,  5.02s/it, loss=1.8996, batch_acc=0.5000, running_acc=0.5750]Evaluation epoch 29: 100%|██████████| 5/5 [00:28<00:00,  5.68s/it, loss=1.8996, batch_acc=0.5000, running_acc=0.5750]
Training epoch 30:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 30:   3%|▎         | 1/31 [00:05<02:57,  5.93s/it]Training epoch 30:   3%|▎         | 1/31 [00:05<02:57,  5.93s/it, loss=1.5686, batch_acc=0.7812, running_acc=0.7812, grad=12.4571]Training epoch 30:   6%|▋         | 2/31 [00:07<01:36,  3.33s/it, loss=1.5686, batch_acc=0.7812, running_acc=0.7812, grad=12.4571]Training epoch 30:   6%|▋         | 2/31 [00:07<01:36,  3.33s/it, loss=1.5206, batch_acc=0.6250, running_acc=0.7031, grad=10.2954]Training epoch 30:  10%|▉         | 3/31 [00:08<01:09,  2.50s/it, loss=1.5206, batch_acc=0.6250, running_acc=0.7031, grad=10.2954]Training epoch 30:  10%|▉         | 3/31 [00:08<01:09,  2.50s/it, loss=1.5784, batch_acc=0.6875, running_acc=0.6979, grad=10.5554]Training epoch 30:  13%|█▎        | 4/31 [00:10<00:56,  2.11s/it, loss=1.5784, batch_acc=0.6875, running_acc=0.6979, grad=10.5554]Training epoch 30:  13%|█▎        | 4/31 [00:10<00:56,  2.11s/it, loss=1.5295, batch_acc=0.6562, running_acc=0.6875, grad=12.1003]Training epoch 30:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=1.5295, batch_acc=0.6562, running_acc=0.6875, grad=12.1003]Training epoch 30:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=1.6104, batch_acc=0.5625, running_acc=0.6625, grad=12.1132]Training epoch 30:  19%|█▉        | 6/31 [00:13<00:44,  1.76s/it, loss=1.6104, batch_acc=0.5625, running_acc=0.6625, grad=12.1132]Training epoch 30:  19%|█▉        | 6/31 [00:13<00:44,  1.76s/it, loss=1.6052, batch_acc=0.7188, running_acc=0.6719, grad=8.8464] Training epoch 30:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.6052, batch_acc=0.7188, running_acc=0.6719, grad=8.8464]Training epoch 30:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.5323, batch_acc=0.6875, running_acc=0.6741, grad=6.7882]Training epoch 30:  26%|██▌       | 8/31 [00:16<00:37,  1.65s/it, loss=1.5323, batch_acc=0.6875, running_acc=0.6741, grad=6.7882]Training epoch 30:  26%|██▌       | 8/31 [00:16<00:37,  1.65s/it, loss=1.4969, batch_acc=0.7812, running_acc=0.6875, grad=55.1563]Training epoch 30:  29%|██▉       | 9/31 [00:18<00:35,  1.61s/it, loss=1.4969, batch_acc=0.7812, running_acc=0.6875, grad=55.1563]Training epoch 30:  29%|██▉       | 9/31 [00:18<00:35,  1.61s/it, loss=1.3224, batch_acc=0.7500, running_acc=0.6944, grad=9.2327] Training epoch 30:  32%|███▏      | 10/31 [00:19<00:33,  1.58s/it, loss=1.3224, batch_acc=0.7500, running_acc=0.6944, grad=9.2327]Training epoch 30:  32%|███▏      | 10/31 [00:19<00:33,  1.58s/it, loss=1.7083, batch_acc=0.5938, running_acc=0.6844, grad=16.4902]Training epoch 30:  35%|███▌      | 11/31 [00:21<00:31,  1.56s/it, loss=1.7083, batch_acc=0.5938, running_acc=0.6844, grad=16.4902]Training epoch 30:  35%|███▌      | 11/31 [00:21<00:31,  1.56s/it, loss=1.9288, batch_acc=0.4688, running_acc=0.6648, grad=14.0033]Training epoch 30:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.9288, batch_acc=0.4688, running_acc=0.6648, grad=14.0033]Training epoch 30:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.7720, batch_acc=0.5938, running_acc=0.6589, grad=10.1577]Training epoch 30:  42%|████▏     | 13/31 [00:24<00:27,  1.53s/it, loss=1.7720, batch_acc=0.5938, running_acc=0.6589, grad=10.1577]Training epoch 30:  42%|████▏     | 13/31 [00:24<00:27,  1.53s/it, loss=1.3610, batch_acc=0.7500, running_acc=0.6659, grad=7.2349] Training epoch 30:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.3610, batch_acc=0.7500, running_acc=0.6659, grad=7.2349]Training epoch 30:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.4964, batch_acc=0.6562, running_acc=0.6652, grad=10.3102]Training epoch 30:  48%|████▊     | 15/31 [00:27<00:24,  1.52s/it, loss=1.4964, batch_acc=0.6562, running_acc=0.6652, grad=10.3102]Training epoch 30:  48%|████▊     | 15/31 [00:27<00:24,  1.52s/it, loss=1.5666, batch_acc=0.6875, running_acc=0.6667, grad=11.0809]Training epoch 30:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.5666, batch_acc=0.6875, running_acc=0.6667, grad=11.0809]Training epoch 30:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.1668, batch_acc=0.8438, running_acc=0.6777, grad=11.4307]Training epoch 30:  55%|█████▍    | 17/31 [00:30<00:21,  1.51s/it, loss=1.1668, batch_acc=0.8438, running_acc=0.6777, grad=11.4307]Training epoch 30:  55%|█████▍    | 17/31 [00:30<00:21,  1.51s/it, loss=1.3635, batch_acc=0.7812, running_acc=0.6838, grad=37.3202]Training epoch 30:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.3635, batch_acc=0.7812, running_acc=0.6838, grad=37.3202]Training epoch 30:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.5048, batch_acc=0.7500, running_acc=0.6875, grad=13.4277]Training epoch 30:  61%|██████▏   | 19/31 [00:33<00:18,  1.52s/it, loss=1.5048, batch_acc=0.7500, running_acc=0.6875, grad=13.4277]Training epoch 30:  61%|██████▏   | 19/31 [00:33<00:18,  1.52s/it, loss=1.4229, batch_acc=0.7188, running_acc=0.6891, grad=21.8593]Training epoch 30:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.4229, batch_acc=0.7188, running_acc=0.6891, grad=21.8593]Training epoch 30:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.8245, batch_acc=0.5000, running_acc=0.6797, grad=12.0998]Training epoch 30:  68%|██████▊   | 21/31 [00:36<00:15,  1.51s/it, loss=1.8245, batch_acc=0.5000, running_acc=0.6797, grad=12.0998]Training epoch 30:  68%|██████▊   | 21/31 [00:36<00:15,  1.51s/it, loss=1.6273, batch_acc=0.5938, running_acc=0.6756, grad=7.5182] Training epoch 30:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.6273, batch_acc=0.5938, running_acc=0.6756, grad=7.5182]Training epoch 30:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.4396, batch_acc=0.7188, running_acc=0.6776, grad=12.6021]Training epoch 30:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.4396, batch_acc=0.7188, running_acc=0.6776, grad=12.6021]Training epoch 30:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.5757, batch_acc=0.6875, running_acc=0.6780, grad=7.4533] Training epoch 30:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.5757, batch_acc=0.6875, running_acc=0.6780, grad=7.4533]Training epoch 30:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.6243, batch_acc=0.6562, running_acc=0.6771, grad=5.8933]Training epoch 30:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=1.6243, batch_acc=0.6562, running_acc=0.6771, grad=5.8933]Training epoch 30:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=1.3144, batch_acc=0.8125, running_acc=0.6825, grad=13.8313]Training epoch 30:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.3144, batch_acc=0.8125, running_acc=0.6825, grad=13.8313]Training epoch 30:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.2217, batch_acc=0.8438, running_acc=0.6887, grad=30.9003]Training epoch 30:  87%|████████▋ | 27/31 [00:45<00:06,  1.50s/it, loss=1.2217, batch_acc=0.8438, running_acc=0.6887, grad=30.9003]Training epoch 30:  87%|████████▋ | 27/31 [00:45<00:06,  1.50s/it, loss=1.4989, batch_acc=0.7188, running_acc=0.6898, grad=6.2011] Training epoch 30:  90%|█████████ | 28/31 [00:46<00:04,  1.50s/it, loss=1.4989, batch_acc=0.7188, running_acc=0.6898, grad=6.2011]Training epoch 30:  90%|█████████ | 28/31 [00:46<00:04,  1.50s/it, loss=1.4891, batch_acc=0.6875, running_acc=0.6897, grad=10.3301]Training epoch 30:  94%|█████████▎| 29/31 [00:48<00:03,  1.50s/it, loss=1.4891, batch_acc=0.6875, running_acc=0.6897, grad=10.3301]Training epoch 30:  94%|█████████▎| 29/31 [00:48<00:03,  1.50s/it, loss=1.7152, batch_acc=0.6250, running_acc=0.6875, grad=20.2941]Training epoch 30:  97%|█████████▋| 30/31 [00:49<00:01,  1.50s/it, loss=1.7152, batch_acc=0.6250, running_acc=0.6875, grad=20.2941]Training epoch 30:  97%|█████████▋| 30/31 [00:49<00:01,  1.50s/it, loss=1.4668, batch_acc=0.6875, running_acc=0.6875, grad=10.8606]Training epoch 30: 100%|██████████| 31/31 [00:49<00:00,  1.11s/it, loss=1.4668, batch_acc=0.6875, running_acc=0.6875, grad=10.8606]Training epoch 30: 100%|██████████| 31/31 [00:49<00:00,  1.11s/it, loss=1.6237, batch_acc=0.5000, running_acc=0.6871, grad=25.6949]Training epoch 30: 100%|██████████| 31/31 [00:49<00:00,  1.61s/it, loss=1.6237, batch_acc=0.5000, running_acc=0.6871, grad=25.6949]
Evaluation epoch 30:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 30:  20%|██        | 1/5 [00:04<00:19,  4.86s/it]Evaluation epoch 30:  20%|██        | 1/5 [00:04<00:19,  4.86s/it, loss=1.4566, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 30:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.4566, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 30:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.3388, batch_acc=0.7812, running_acc=0.7656]Evaluation epoch 30:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.3388, batch_acc=0.7812, running_acc=0.7656]Evaluation epoch 30:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.6688, batch_acc=0.5625, running_acc=0.6979]Evaluation epoch 30:  80%|████████  | 4/5 [00:07<00:01,  1.60s/it, loss=1.6688, batch_acc=0.5625, running_acc=0.6979]Evaluation epoch 30:  80%|████████  | 4/5 [00:07<00:01,  1.60s/it, loss=1.8328, batch_acc=0.5625, running_acc=0.6641]Evaluation epoch 30: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=1.8328, batch_acc=0.5625, running_acc=0.6641]Evaluation epoch 30: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=1.8589, batch_acc=0.5938, running_acc=0.6500]Evaluation epoch 30: 100%|██████████| 5/5 [00:08<00:00,  1.73s/it, loss=1.8589, batch_acc=0.5938, running_acc=0.6500]
Training epoch 31:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 31:   3%|▎         | 1/31 [00:06<03:26,  6.88s/it]Training epoch 31:   3%|▎         | 1/31 [00:06<03:26,  6.88s/it, loss=1.5435, batch_acc=0.5312, running_acc=0.5312, grad=9.5767]Training epoch 31:   6%|▋         | 2/31 [00:08<01:47,  3.72s/it, loss=1.5435, batch_acc=0.5312, running_acc=0.5312, grad=9.5767]Training epoch 31:   6%|▋         | 2/31 [00:08<01:47,  3.72s/it, loss=1.4685, batch_acc=0.6875, running_acc=0.6094, grad=10.0679]Training epoch 31:  10%|▉         | 3/31 [00:09<01:15,  2.71s/it, loss=1.4685, batch_acc=0.6875, running_acc=0.6094, grad=10.0679]Training epoch 31:  10%|▉         | 3/31 [00:09<01:15,  2.71s/it, loss=1.8883, batch_acc=0.5312, running_acc=0.5833, grad=14.4478]Training epoch 31:  13%|█▎        | 4/31 [00:12<01:15,  2.80s/it, loss=1.8883, batch_acc=0.5312, running_acc=0.5833, grad=14.4478]Training epoch 31:  13%|█▎        | 4/31 [00:12<01:15,  2.80s/it, loss=1.6763, batch_acc=0.6562, running_acc=0.6016, grad=16.7371]Training epoch 31:  16%|█▌        | 5/31 [00:15<01:10,  2.71s/it, loss=1.6763, batch_acc=0.6562, running_acc=0.6016, grad=16.7371]Training epoch 31:  16%|█▌        | 5/31 [00:15<01:10,  2.71s/it, loss=1.4856, batch_acc=0.6250, running_acc=0.6062, grad=11.2023]Training epoch 31:  19%|█▉        | 6/31 [00:16<00:57,  2.30s/it, loss=1.4856, batch_acc=0.6250, running_acc=0.6062, grad=11.2023]Training epoch 31:  19%|█▉        | 6/31 [00:16<00:57,  2.30s/it, loss=1.4598, batch_acc=0.7812, running_acc=0.6354, grad=18.2609]Training epoch 31:  23%|██▎       | 7/31 [00:18<00:48,  2.04s/it, loss=1.4598, batch_acc=0.7812, running_acc=0.6354, grad=18.2609]Training epoch 31:  23%|██▎       | 7/31 [00:18<00:48,  2.04s/it, loss=1.4136, batch_acc=0.7188, running_acc=0.6473, grad=12.5214]Training epoch 31:  26%|██▌       | 8/31 [00:21<00:53,  2.33s/it, loss=1.4136, batch_acc=0.7188, running_acc=0.6473, grad=12.5214]Training epoch 31:  26%|██▌       | 8/31 [00:21<00:53,  2.33s/it, loss=1.6301, batch_acc=0.6250, running_acc=0.6445, grad=10.4859]Training epoch 31:  29%|██▉       | 9/31 [00:23<00:48,  2.18s/it, loss=1.6301, batch_acc=0.6250, running_acc=0.6445, grad=10.4859]Training epoch 31:  29%|██▉       | 9/31 [00:23<00:48,  2.18s/it, loss=1.4069, batch_acc=0.7812, running_acc=0.6597, grad=7.4874] Training epoch 31:  32%|███▏      | 10/31 [00:24<00:41,  1.98s/it, loss=1.4069, batch_acc=0.7812, running_acc=0.6597, grad=7.4874]Training epoch 31:  32%|███▏      | 10/31 [00:24<00:41,  1.98s/it, loss=1.7510, batch_acc=0.5938, running_acc=0.6531, grad=38.7410]Training epoch 31:  35%|███▌      | 11/31 [00:26<00:36,  1.83s/it, loss=1.7510, batch_acc=0.5938, running_acc=0.6531, grad=38.7410]Training epoch 31:  35%|███▌      | 11/31 [00:26<00:36,  1.83s/it, loss=1.4765, batch_acc=0.5938, running_acc=0.6477, grad=10.8265]Training epoch 31:  39%|███▊      | 12/31 [00:27<00:32,  1.74s/it, loss=1.4765, batch_acc=0.5938, running_acc=0.6477, grad=10.8265]Training epoch 31:  39%|███▊      | 12/31 [00:27<00:32,  1.74s/it, loss=1.5948, batch_acc=0.6562, running_acc=0.6484, grad=9.2808] Training epoch 31:  42%|████▏     | 13/31 [00:32<00:45,  2.51s/it, loss=1.5948, batch_acc=0.6562, running_acc=0.6484, grad=9.2808]Training epoch 31:  42%|████▏     | 13/31 [00:32<00:45,  2.51s/it, loss=1.3549, batch_acc=0.6875, running_acc=0.6514, grad=13.1703]Training epoch 31:  45%|████▌     | 14/31 [00:33<00:37,  2.21s/it, loss=1.3549, batch_acc=0.6875, running_acc=0.6514, grad=13.1703]Training epoch 31:  45%|████▌     | 14/31 [00:33<00:37,  2.21s/it, loss=1.4038, batch_acc=0.7188, running_acc=0.6562, grad=23.4925]Training epoch 31:  48%|████▊     | 15/31 [00:35<00:31,  2.00s/it, loss=1.4038, batch_acc=0.7188, running_acc=0.6562, grad=23.4925]Training epoch 31:  48%|████▊     | 15/31 [00:35<00:31,  2.00s/it, loss=1.2745, batch_acc=0.8438, running_acc=0.6687, grad=8.6860] Training epoch 31:  52%|█████▏    | 16/31 [00:36<00:27,  1.85s/it, loss=1.2745, batch_acc=0.8438, running_acc=0.6687, grad=8.6860]Training epoch 31:  52%|█████▏    | 16/31 [00:36<00:27,  1.85s/it, loss=1.6164, batch_acc=0.6562, running_acc=0.6680, grad=8.2664]Training epoch 31:  55%|█████▍    | 17/31 [00:40<00:33,  2.41s/it, loss=1.6164, batch_acc=0.6562, running_acc=0.6680, grad=8.2664]Training epoch 31:  55%|█████▍    | 17/31 [00:40<00:33,  2.41s/it, loss=1.6161, batch_acc=0.6250, running_acc=0.6654, grad=8.2078]Training epoch 31:  58%|█████▊    | 18/31 [00:43<00:32,  2.52s/it, loss=1.6161, batch_acc=0.6250, running_acc=0.6654, grad=8.2078]Training epoch 31:  58%|█████▊    | 18/31 [00:43<00:32,  2.52s/it, loss=1.5355, batch_acc=0.7812, running_acc=0.6719, grad=52.2676]Training epoch 31:  61%|██████▏   | 19/31 [00:44<00:26,  2.22s/it, loss=1.5355, batch_acc=0.7812, running_acc=0.6719, grad=52.2676]Training epoch 31:  61%|██████▏   | 19/31 [00:44<00:26,  2.22s/it, loss=1.5536, batch_acc=0.6562, running_acc=0.6711, grad=16.3500]Training epoch 31:  65%|██████▍   | 20/31 [00:46<00:22,  2.00s/it, loss=1.5536, batch_acc=0.6562, running_acc=0.6711, grad=16.3500]Training epoch 31:  65%|██████▍   | 20/31 [00:46<00:22,  2.00s/it, loss=1.5979, batch_acc=0.7500, running_acc=0.6750, grad=17.9767]Training epoch 31:  68%|██████▊   | 21/31 [01:01<00:59,  5.94s/it, loss=1.5979, batch_acc=0.7500, running_acc=0.6750, grad=17.9767]Training epoch 31:  68%|██████▊   | 21/31 [01:01<00:59,  5.94s/it, loss=1.5854, batch_acc=0.7188, running_acc=0.6771, grad=15.7120]Training epoch 31:  71%|███████   | 22/31 [01:02<00:41,  4.61s/it, loss=1.5854, batch_acc=0.7188, running_acc=0.6771, grad=15.7120]Training epoch 31:  71%|███████   | 22/31 [01:02<00:41,  4.61s/it, loss=1.7693, batch_acc=0.5625, running_acc=0.6719, grad=9.0241] Training epoch 31:  74%|███████▍  | 23/31 [01:04<00:29,  3.68s/it, loss=1.7693, batch_acc=0.5625, running_acc=0.6719, grad=9.0241]Training epoch 31:  74%|███████▍  | 23/31 [01:04<00:29,  3.68s/it, loss=1.4201, batch_acc=0.6875, running_acc=0.6726, grad=14.5103]Training epoch 31:  77%|███████▋  | 24/31 [01:05<00:21,  3.03s/it, loss=1.4201, batch_acc=0.6875, running_acc=0.6726, grad=14.5103]Training epoch 31:  77%|███████▋  | 24/31 [01:05<00:21,  3.03s/it, loss=1.3054, batch_acc=0.7500, running_acc=0.6758, grad=17.9072]Training epoch 31:  81%|████████  | 25/31 [01:12<00:24,  4.01s/it, loss=1.3054, batch_acc=0.7500, running_acc=0.6758, grad=17.9072]Training epoch 31:  81%|████████  | 25/31 [01:12<00:24,  4.01s/it, loss=1.8394, batch_acc=0.5312, running_acc=0.6700, grad=21.0682]Training epoch 31:  84%|████████▍ | 26/31 [01:13<00:16,  3.26s/it, loss=1.8394, batch_acc=0.5312, running_acc=0.6700, grad=21.0682]Training epoch 31:  84%|████████▍ | 26/31 [01:13<00:16,  3.26s/it, loss=1.3902, batch_acc=0.6875, running_acc=0.6707, grad=17.9518]Training epoch 31:  87%|████████▋ | 27/31 [01:15<00:10,  2.74s/it, loss=1.3902, batch_acc=0.6875, running_acc=0.6707, grad=17.9518]Training epoch 31:  87%|████████▋ | 27/31 [01:15<00:10,  2.74s/it, loss=1.4535, batch_acc=0.6562, running_acc=0.6701, grad=33.1593]Training epoch 31:  90%|█████████ | 28/31 [01:16<00:07,  2.37s/it, loss=1.4535, batch_acc=0.6562, running_acc=0.6701, grad=33.1593]Training epoch 31:  90%|█████████ | 28/31 [01:16<00:07,  2.37s/it, loss=1.3735, batch_acc=0.7500, running_acc=0.6730, grad=24.1687]Training epoch 31:  94%|█████████▎| 29/31 [01:19<00:05,  2.62s/it, loss=1.3735, batch_acc=0.7500, running_acc=0.6730, grad=24.1687]Training epoch 31:  94%|█████████▎| 29/31 [01:19<00:05,  2.62s/it, loss=1.4380, batch_acc=0.7500, running_acc=0.6756, grad=11.3285]Training epoch 31:  97%|█████████▋| 30/31 [01:21<00:02,  2.29s/it, loss=1.4380, batch_acc=0.7500, running_acc=0.6756, grad=11.3285]Training epoch 31:  97%|█████████▋| 30/31 [01:21<00:02,  2.29s/it, loss=1.5837, batch_acc=0.6562, running_acc=0.6750, grad=40.5489]Training epoch 31: 100%|██████████| 31/31 [01:21<00:00,  1.66s/it, loss=1.5837, batch_acc=0.6562, running_acc=0.6750, grad=40.5489]Training epoch 31: 100%|██████████| 31/31 [01:21<00:00,  1.66s/it, loss=1.6489, batch_acc=0.5000, running_acc=0.6746, grad=141.0261]Training epoch 31: 100%|██████████| 31/31 [01:21<00:00,  2.63s/it, loss=1.6489, batch_acc=0.5000, running_acc=0.6746, grad=141.0261]
Evaluation epoch 31:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 31:  20%|██        | 1/5 [00:06<00:24,  6.11s/it]Evaluation epoch 31:  20%|██        | 1/5 [00:06<00:24,  6.11s/it, loss=1.4580, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 31:  40%|████      | 2/5 [00:06<00:08,  2.95s/it, loss=1.4580, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 31:  40%|████      | 2/5 [00:06<00:08,  2.95s/it, loss=1.3251, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 31:  60%|██████    | 3/5 [00:07<00:03,  1.94s/it, loss=1.3251, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 31:  60%|██████    | 3/5 [00:07<00:03,  1.94s/it, loss=1.6803, batch_acc=0.5938, running_acc=0.6979]Evaluation epoch 31:  80%|████████  | 4/5 [00:08<00:01,  1.47s/it, loss=1.6803, batch_acc=0.5938, running_acc=0.6979]Evaluation epoch 31:  80%|████████  | 4/5 [00:08<00:01,  1.47s/it, loss=1.8018, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 31: 100%|██████████| 5/5 [00:09<00:00,  1.23s/it, loss=1.8018, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 31: 100%|██████████| 5/5 [00:09<00:00,  1.23s/it, loss=1.8448, batch_acc=0.5625, running_acc=0.6375]Evaluation epoch 31: 100%|██████████| 5/5 [00:09<00:00,  1.83s/it, loss=1.8448, batch_acc=0.5625, running_acc=0.6375]
Training epoch 32:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 32:   3%|▎         | 1/31 [00:10<05:05, 10.20s/it]Training epoch 32:   3%|▎         | 1/31 [00:10<05:05, 10.20s/it, loss=1.4951, batch_acc=0.7188, running_acc=0.7188, grad=13.7417]Training epoch 32:   6%|▋         | 2/31 [00:11<02:27,  5.09s/it, loss=1.4951, batch_acc=0.7188, running_acc=0.7188, grad=13.7417]Training epoch 32:   6%|▋         | 2/31 [00:11<02:27,  5.09s/it, loss=1.4291, batch_acc=0.6875, running_acc=0.7031, grad=19.3034]Training epoch 32:  10%|▉         | 3/31 [00:16<02:13,  4.76s/it, loss=1.4291, batch_acc=0.6875, running_acc=0.7031, grad=19.3034]Training epoch 32:  10%|▉         | 3/31 [00:16<02:13,  4.76s/it, loss=1.6478, batch_acc=0.6250, running_acc=0.6771, grad=24.1801]Training epoch 32:  13%|█▎        | 4/31 [00:17<01:33,  3.48s/it, loss=1.6478, batch_acc=0.6250, running_acc=0.6771, grad=24.1801]Training epoch 32:  13%|█▎        | 4/31 [00:17<01:33,  3.48s/it, loss=1.4942, batch_acc=0.7188, running_acc=0.6875, grad=93.4444]Training epoch 32:  16%|█▌        | 5/31 [00:19<01:11,  2.77s/it, loss=1.4942, batch_acc=0.7188, running_acc=0.6875, grad=93.4444]Training epoch 32:  16%|█▌        | 5/31 [00:19<01:11,  2.77s/it, loss=1.6902, batch_acc=0.5000, running_acc=0.6500, grad=16.8910]Training epoch 32:  19%|█▉        | 6/31 [00:20<00:58,  2.34s/it, loss=1.6902, batch_acc=0.5000, running_acc=0.6500, grad=16.8910]Training epoch 32:  19%|█▉        | 6/31 [00:20<00:58,  2.34s/it, loss=1.5150, batch_acc=0.7188, running_acc=0.6615, grad=21.0537]Training epoch 32:  23%|██▎       | 7/31 [00:28<01:39,  4.15s/it, loss=1.5150, batch_acc=0.7188, running_acc=0.6615, grad=21.0537]Training epoch 32:  23%|██▎       | 7/31 [00:28<01:39,  4.15s/it, loss=1.1754, batch_acc=0.7812, running_acc=0.6786, grad=8.6429] Training epoch 32:  26%|██▌       | 8/31 [00:30<01:16,  3.31s/it, loss=1.1754, batch_acc=0.7812, running_acc=0.6786, grad=8.6429]Training epoch 32:  26%|██▌       | 8/31 [00:30<01:16,  3.31s/it, loss=1.5332, batch_acc=0.6250, running_acc=0.6719, grad=12.3253]Training epoch 32:  29%|██▉       | 9/31 [00:31<01:00,  2.75s/it, loss=1.5332, batch_acc=0.6250, running_acc=0.6719, grad=12.3253]Training epoch 32:  29%|██▉       | 9/31 [00:31<01:00,  2.75s/it, loss=1.6343, batch_acc=0.6250, running_acc=0.6667, grad=7.3474] Training epoch 32:  32%|███▏      | 10/31 [00:33<00:49,  2.37s/it, loss=1.6343, batch_acc=0.6250, running_acc=0.6667, grad=7.3474]Training epoch 32:  32%|███▏      | 10/31 [00:33<00:49,  2.37s/it, loss=1.4267, batch_acc=0.6562, running_acc=0.6656, grad=7.8677]Training epoch 32:  35%|███▌      | 11/31 [00:34<00:42,  2.11s/it, loss=1.4267, batch_acc=0.6562, running_acc=0.6656, grad=7.8677]Training epoch 32:  35%|███▌      | 11/31 [00:34<00:42,  2.11s/it, loss=1.5036, batch_acc=0.7188, running_acc=0.6705, grad=15.6078]Training epoch 32:  39%|███▊      | 12/31 [00:36<00:36,  1.93s/it, loss=1.5036, batch_acc=0.7188, running_acc=0.6705, grad=15.6078]Training epoch 32:  39%|███▊      | 12/31 [00:36<00:36,  1.93s/it, loss=1.5098, batch_acc=0.7188, running_acc=0.6745, grad=9.3484] Training epoch 32:  42%|████▏     | 13/31 [00:37<00:32,  1.80s/it, loss=1.5098, batch_acc=0.7188, running_acc=0.6745, grad=9.3484]Training epoch 32:  42%|████▏     | 13/31 [00:37<00:32,  1.80s/it, loss=1.4903, batch_acc=0.6875, running_acc=0.6755, grad=8.5950]Training epoch 32:  45%|████▌     | 14/31 [00:43<00:53,  3.14s/it, loss=1.4903, batch_acc=0.6875, running_acc=0.6755, grad=8.5950]Training epoch 32:  45%|████▌     | 14/31 [00:43<00:53,  3.14s/it, loss=1.7349, batch_acc=0.5625, running_acc=0.6674, grad=32.1894]Training epoch 32:  48%|████▊     | 15/31 [00:45<00:42,  2.65s/it, loss=1.7349, batch_acc=0.5625, running_acc=0.6674, grad=32.1894]Training epoch 32:  48%|████▊     | 15/31 [00:45<00:42,  2.65s/it, loss=1.4181, batch_acc=0.7188, running_acc=0.6708, grad=10.4633]Training epoch 32:  52%|█████▏    | 16/31 [00:46<00:34,  2.31s/it, loss=1.4181, batch_acc=0.7188, running_acc=0.6708, grad=10.4633]Training epoch 32:  52%|█████▏    | 16/31 [00:46<00:34,  2.31s/it, loss=1.3479, batch_acc=0.6562, running_acc=0.6699, grad=13.4227]Training epoch 32:  55%|█████▍    | 17/31 [00:48<00:28,  2.07s/it, loss=1.3479, batch_acc=0.6562, running_acc=0.6699, grad=13.4227]Training epoch 32:  55%|█████▍    | 17/31 [00:48<00:28,  2.07s/it, loss=1.5366, batch_acc=0.7500, running_acc=0.6746, grad=11.5634]Training epoch 32:  58%|█████▊    | 18/31 [00:53<00:37,  2.86s/it, loss=1.5366, batch_acc=0.7500, running_acc=0.6746, grad=11.5634]Training epoch 32:  58%|█████▊    | 18/31 [00:53<00:37,  2.86s/it, loss=1.5632, batch_acc=0.6875, running_acc=0.6753, grad=14.8427]Training epoch 32:  61%|██████▏   | 19/31 [00:54<00:29,  2.45s/it, loss=1.5632, batch_acc=0.6875, running_acc=0.6753, grad=14.8427]Training epoch 32:  61%|██████▏   | 19/31 [00:54<00:29,  2.45s/it, loss=1.6692, batch_acc=0.5938, running_acc=0.6711, grad=64.9670]Training epoch 32:  65%|██████▍   | 20/31 [00:56<00:23,  2.17s/it, loss=1.6692, batch_acc=0.5938, running_acc=0.6711, grad=64.9670]Training epoch 32:  65%|██████▍   | 20/31 [00:56<00:23,  2.17s/it, loss=1.3487, batch_acc=0.7188, running_acc=0.6734, grad=17.2141]Training epoch 32:  68%|██████▊   | 21/31 [00:57<00:19,  1.97s/it, loss=1.3487, batch_acc=0.7188, running_acc=0.6734, grad=17.2141]Training epoch 32:  68%|██████▊   | 21/31 [00:57<00:19,  1.97s/it, loss=1.4197, batch_acc=0.7500, running_acc=0.6771, grad=21.5241]Training epoch 32:  71%|███████   | 22/31 [01:04<00:31,  3.47s/it, loss=1.4197, batch_acc=0.7500, running_acc=0.6771, grad=21.5241]Training epoch 32:  71%|███████   | 22/31 [01:04<00:31,  3.47s/it, loss=1.4653, batch_acc=0.6562, running_acc=0.6761, grad=12.5314]Training epoch 32:  74%|███████▍  | 23/31 [01:07<00:26,  3.32s/it, loss=1.4653, batch_acc=0.6562, running_acc=0.6761, grad=12.5314]Training epoch 32:  74%|███████▍  | 23/31 [01:07<00:26,  3.32s/it, loss=1.5435, batch_acc=0.7188, running_acc=0.6780, grad=40.4603]Training epoch 32:  77%|███████▋  | 24/31 [01:09<00:19,  2.78s/it, loss=1.5435, batch_acc=0.7188, running_acc=0.6780, grad=40.4603]Training epoch 32:  77%|███████▋  | 24/31 [01:09<00:19,  2.78s/it, loss=1.5901, batch_acc=0.6562, running_acc=0.6771, grad=7.2156] Training epoch 32:  81%|████████  | 25/31 [01:10<00:14,  2.40s/it, loss=1.5901, batch_acc=0.6562, running_acc=0.6771, grad=7.2156]Training epoch 32:  81%|████████  | 25/31 [01:10<00:14,  2.40s/it, loss=1.9298, batch_acc=0.6562, running_acc=0.6763, grad=7.0145]Training epoch 32:  84%|████████▍ | 26/31 [01:17<00:18,  3.79s/it, loss=1.9298, batch_acc=0.6562, running_acc=0.6763, grad=7.0145]Training epoch 32:  84%|████████▍ | 26/31 [01:17<00:18,  3.79s/it, loss=1.8679, batch_acc=0.5625, running_acc=0.6719, grad=9.7968]Training epoch 32:  87%|████████▋ | 27/31 [01:19<00:12,  3.10s/it, loss=1.8679, batch_acc=0.5625, running_acc=0.6719, grad=9.7968]Training epoch 32:  87%|████████▋ | 27/31 [01:19<00:12,  3.10s/it, loss=1.2513, batch_acc=0.8438, running_acc=0.6782, grad=10.9807]Training epoch 32:  90%|█████████ | 28/31 [01:20<00:07,  2.62s/it, loss=1.2513, batch_acc=0.8438, running_acc=0.6782, grad=10.9807]Training epoch 32:  90%|█████████ | 28/31 [01:20<00:07,  2.62s/it, loss=1.3016, batch_acc=0.8438, running_acc=0.6842, grad=20.7161]Training epoch 32:  94%|█████████▎| 29/31 [01:22<00:04,  2.29s/it, loss=1.3016, batch_acc=0.8438, running_acc=0.6842, grad=20.7161]Training epoch 32:  94%|█████████▎| 29/31 [01:22<00:04,  2.29s/it, loss=1.3413, batch_acc=0.8125, running_acc=0.6886, grad=18.1794]Training epoch 32:  97%|█████████▋| 30/31 [01:23<00:02,  2.06s/it, loss=1.3413, batch_acc=0.8125, running_acc=0.6886, grad=18.1794]Training epoch 32:  97%|█████████▋| 30/31 [01:23<00:02,  2.06s/it, loss=1.3557, batch_acc=0.7188, running_acc=0.6896, grad=68.9389]Training epoch 32: 100%|██████████| 31/31 [01:23<00:00,  1.50s/it, loss=1.3557, batch_acc=0.7188, running_acc=0.6896, grad=68.9389]Training epoch 32: 100%|██████████| 31/31 [01:23<00:00,  1.50s/it, loss=1.1176, batch_acc=1.0000, running_acc=0.6902, grad=29.6019]Training epoch 32: 100%|██████████| 31/31 [01:23<00:00,  2.70s/it, loss=1.1176, batch_acc=1.0000, running_acc=0.6902, grad=29.6019]
Evaluation epoch 32:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 32:  20%|██        | 1/5 [00:18<01:14, 18.71s/it]Evaluation epoch 32:  20%|██        | 1/5 [00:18<01:14, 18.71s/it, loss=1.3712, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 32:  40%|████      | 2/5 [00:19<00:24,  8.14s/it, loss=1.3712, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 32:  40%|████      | 2/5 [00:19<00:24,  8.14s/it, loss=1.3411, batch_acc=0.7812, running_acc=0.7656]Evaluation epoch 32:  60%|██████    | 3/5 [00:20<00:09,  4.77s/it, loss=1.3411, batch_acc=0.7812, running_acc=0.7656]Evaluation epoch 32:  60%|██████    | 3/5 [00:20<00:09,  4.77s/it, loss=1.7729, batch_acc=0.5000, running_acc=0.6771]Evaluation epoch 32:  80%|████████  | 4/5 [00:21<00:03,  3.46s/it, loss=1.7729, batch_acc=0.5000, running_acc=0.6771]Evaluation epoch 32:  80%|████████  | 4/5 [00:21<00:03,  3.46s/it, loss=1.7331, batch_acc=0.5938, running_acc=0.6562]Evaluation epoch 32: 100%|██████████| 5/5 [00:22<00:00,  2.50s/it, loss=1.7331, batch_acc=0.5938, running_acc=0.6562]Evaluation epoch 32: 100%|██████████| 5/5 [00:22<00:00,  2.50s/it, loss=1.9192, batch_acc=0.5625, running_acc=0.6375]Evaluation epoch 32: 100%|██████████| 5/5 [00:22<00:00,  4.49s/it, loss=1.9192, batch_acc=0.5625, running_acc=0.6375]
Training epoch 33:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 33:   3%|▎         | 1/31 [00:10<05:16, 10.56s/it]Training epoch 33:   3%|▎         | 1/31 [00:10<05:16, 10.56s/it, loss=1.4709, batch_acc=0.6562, running_acc=0.6562, grad=10.9972]Training epoch 33:   6%|▋         | 2/31 [00:12<02:31,  5.24s/it, loss=1.4709, batch_acc=0.6562, running_acc=0.6562, grad=10.9972]Training epoch 33:   6%|▋         | 2/31 [00:12<02:31,  5.24s/it, loss=1.6005, batch_acc=0.5938, running_acc=0.6250, grad=12.3607]Training epoch 33:  10%|▉         | 3/31 [00:13<01:38,  3.54s/it, loss=1.6005, batch_acc=0.5938, running_acc=0.6250, grad=12.3607]Training epoch 33:  10%|▉         | 3/31 [00:13<01:38,  3.54s/it, loss=1.4122, batch_acc=0.6875, running_acc=0.6458, grad=8.5952] Training epoch 33:  13%|█▎        | 4/31 [00:16<01:29,  3.33s/it, loss=1.4122, batch_acc=0.6875, running_acc=0.6458, grad=8.5952]Training epoch 33:  13%|█▎        | 4/31 [00:16<01:29,  3.33s/it, loss=1.3383, batch_acc=0.6875, running_acc=0.6562, grad=8.5260]Training epoch 33:  16%|█▌        | 5/31 [00:20<01:34,  3.64s/it, loss=1.3383, batch_acc=0.6875, running_acc=0.6562, grad=8.5260]Training epoch 33:  16%|█▌        | 5/31 [00:20<01:34,  3.64s/it, loss=1.5370, batch_acc=0.6562, running_acc=0.6562, grad=15.8215]Training epoch 33:  19%|█▉        | 6/31 [00:22<01:12,  2.92s/it, loss=1.5370, batch_acc=0.6562, running_acc=0.6562, grad=15.8215]Training epoch 33:  19%|█▉        | 6/31 [00:22<01:12,  2.92s/it, loss=1.6454, batch_acc=0.5625, running_acc=0.6406, grad=12.3289]Training epoch 33:  23%|██▎       | 7/31 [00:23<00:58,  2.46s/it, loss=1.6454, batch_acc=0.5625, running_acc=0.6406, grad=12.3289]Training epoch 33:  23%|██▎       | 7/31 [00:23<00:58,  2.46s/it, loss=1.6669, batch_acc=0.5938, running_acc=0.6339, grad=8.0202] Training epoch 33:  26%|██▌       | 8/31 [00:25<00:49,  2.15s/it, loss=1.6669, batch_acc=0.5938, running_acc=0.6339, grad=8.0202]Training epoch 33:  26%|██▌       | 8/31 [00:25<00:49,  2.15s/it, loss=1.2712, batch_acc=0.8438, running_acc=0.6602, grad=24.1541]Training epoch 33:  29%|██▉       | 9/31 [00:27<00:44,  2.02s/it, loss=1.2712, batch_acc=0.8438, running_acc=0.6602, grad=24.1541]Training epoch 33:  29%|██▉       | 9/31 [00:27<00:44,  2.02s/it, loss=1.4478, batch_acc=0.8750, running_acc=0.6840, grad=13.2146]Training epoch 33:  32%|███▏      | 10/31 [00:28<00:39,  1.87s/it, loss=1.4478, batch_acc=0.8750, running_acc=0.6840, grad=13.2146]Training epoch 33:  32%|███▏      | 10/31 [00:28<00:39,  1.87s/it, loss=1.3609, batch_acc=0.7812, running_acc=0.6937, grad=40.2458]Training epoch 33:  35%|███▌      | 11/31 [00:30<00:35,  1.76s/it, loss=1.3609, batch_acc=0.7812, running_acc=0.6937, grad=40.2458]Training epoch 33:  35%|███▌      | 11/31 [00:30<00:35,  1.76s/it, loss=1.5548, batch_acc=0.6562, running_acc=0.6903, grad=8.3332] Training epoch 33:  39%|███▊      | 12/31 [00:31<00:31,  1.68s/it, loss=1.5548, batch_acc=0.6562, running_acc=0.6903, grad=8.3332]Training epoch 33:  39%|███▊      | 12/31 [00:31<00:31,  1.68s/it, loss=1.7907, batch_acc=0.5625, running_acc=0.6797, grad=13.0936]Training epoch 33:  42%|████▏     | 13/31 [00:33<00:31,  1.73s/it, loss=1.7907, batch_acc=0.5625, running_acc=0.6797, grad=13.0936]Training epoch 33:  42%|████▏     | 13/31 [00:33<00:31,  1.73s/it, loss=1.6010, batch_acc=0.6250, running_acc=0.6755, grad=10.5783]Training epoch 33:  45%|████▌     | 14/31 [00:34<00:28,  1.67s/it, loss=1.6010, batch_acc=0.6250, running_acc=0.6755, grad=10.5783]Training epoch 33:  45%|████▌     | 14/31 [00:34<00:28,  1.67s/it, loss=1.3887, batch_acc=0.7188, running_acc=0.6786, grad=36.2350]Training epoch 33:  48%|████▊     | 15/31 [00:36<00:25,  1.62s/it, loss=1.3887, batch_acc=0.7188, running_acc=0.6786, grad=36.2350]Training epoch 33:  48%|████▊     | 15/31 [00:36<00:25,  1.62s/it, loss=1.4289, batch_acc=0.6875, running_acc=0.6792, grad=50.6533]Training epoch 33:  52%|█████▏    | 16/31 [00:44<00:51,  3.44s/it, loss=1.4289, batch_acc=0.6875, running_acc=0.6792, grad=50.6533]Training epoch 33:  52%|█████▏    | 16/31 [00:44<00:51,  3.44s/it, loss=1.5455, batch_acc=0.6250, running_acc=0.6758, grad=9.9361] Training epoch 33:  55%|█████▍    | 17/31 [00:45<00:39,  2.86s/it, loss=1.5455, batch_acc=0.6250, running_acc=0.6758, grad=9.9361]Training epoch 33:  55%|█████▍    | 17/31 [00:45<00:39,  2.86s/it, loss=1.6896, batch_acc=0.5938, running_acc=0.6710, grad=5.9454]Training epoch 33:  58%|█████▊    | 18/31 [00:47<00:31,  2.45s/it, loss=1.6896, batch_acc=0.5938, running_acc=0.6710, grad=5.9454]Training epoch 33:  58%|█████▊    | 18/31 [00:47<00:31,  2.45s/it, loss=1.4571, batch_acc=0.6562, running_acc=0.6701, grad=13.1952]Training epoch 33:  61%|██████▏   | 19/31 [00:48<00:26,  2.17s/it, loss=1.4571, batch_acc=0.6562, running_acc=0.6701, grad=13.1952]Training epoch 33:  61%|██████▏   | 19/31 [00:48<00:26,  2.17s/it, loss=1.4343, batch_acc=0.7812, running_acc=0.6760, grad=53.0363]Training epoch 33:  65%|██████▍   | 20/31 [00:59<00:52,  4.75s/it, loss=1.4343, batch_acc=0.7812, running_acc=0.6760, grad=53.0363]Training epoch 33:  65%|██████▍   | 20/31 [00:59<00:52,  4.75s/it, loss=1.3441, batch_acc=0.6875, running_acc=0.6766, grad=22.7598]Training epoch 33:  68%|██████▊   | 21/31 [01:00<00:37,  3.78s/it, loss=1.3441, batch_acc=0.6875, running_acc=0.6766, grad=22.7598]Training epoch 33:  68%|██████▊   | 21/31 [01:00<00:37,  3.78s/it, loss=1.5635, batch_acc=0.6250, running_acc=0.6741, grad=15.9669]Training epoch 33:  71%|███████   | 22/31 [01:02<00:27,  3.10s/it, loss=1.5635, batch_acc=0.6250, running_acc=0.6741, grad=15.9669]Training epoch 33:  71%|███████   | 22/31 [01:02<00:27,  3.10s/it, loss=1.5697, batch_acc=0.7188, running_acc=0.6761, grad=15.6329]Training epoch 33:  74%|███████▍  | 23/31 [01:03<00:20,  2.62s/it, loss=1.5697, batch_acc=0.7188, running_acc=0.6761, grad=15.6329]Training epoch 33:  74%|███████▍  | 23/31 [01:03<00:20,  2.62s/it, loss=1.4999, batch_acc=0.6562, running_acc=0.6753, grad=26.2268]Training epoch 33:  77%|███████▋  | 24/31 [01:09<00:23,  3.41s/it, loss=1.4999, batch_acc=0.6562, running_acc=0.6753, grad=26.2268]Training epoch 33:  77%|███████▋  | 24/31 [01:09<00:23,  3.41s/it, loss=1.3943, batch_acc=0.7188, running_acc=0.6771, grad=25.4461]Training epoch 33:  81%|████████  | 25/31 [01:10<00:17,  2.84s/it, loss=1.3943, batch_acc=0.7188, running_acc=0.6771, grad=25.4461]Training epoch 33:  81%|████████  | 25/31 [01:10<00:17,  2.84s/it, loss=1.4115, batch_acc=0.7812, running_acc=0.6813, grad=7.2127] Training epoch 33:  84%|████████▍ | 26/31 [01:12<00:12,  2.44s/it, loss=1.4115, batch_acc=0.7812, running_acc=0.6813, grad=7.2127]Training epoch 33:  84%|████████▍ | 26/31 [01:12<00:12,  2.44s/it, loss=1.5147, batch_acc=0.7188, running_acc=0.6827, grad=13.0315]Training epoch 33:  87%|████████▋ | 27/31 [01:13<00:08,  2.16s/it, loss=1.5147, batch_acc=0.7188, running_acc=0.6827, grad=13.0315]Training epoch 33:  87%|████████▋ | 27/31 [01:13<00:08,  2.16s/it, loss=1.5252, batch_acc=0.6875, running_acc=0.6829, grad=8.2594] Training epoch 33:  90%|█████████ | 28/31 [01:21<00:11,  3.97s/it, loss=1.5252, batch_acc=0.6875, running_acc=0.6829, grad=8.2594]Training epoch 33:  90%|█████████ | 28/31 [01:21<00:11,  3.97s/it, loss=1.8332, batch_acc=0.5625, running_acc=0.6786, grad=20.7893]Training epoch 33:  94%|█████████▎| 29/31 [01:23<00:06,  3.23s/it, loss=1.8332, batch_acc=0.5625, running_acc=0.6786, grad=20.7893]Training epoch 33:  94%|█████████▎| 29/31 [01:23<00:06,  3.23s/it, loss=1.5300, batch_acc=0.6875, running_acc=0.6789, grad=60.5866]Training epoch 33:  97%|█████████▋| 30/31 [01:24<00:02,  2.72s/it, loss=1.5300, batch_acc=0.6875, running_acc=0.6789, grad=60.5866]Training epoch 33:  97%|█████████▋| 30/31 [01:24<00:02,  2.72s/it, loss=1.4049, batch_acc=0.6875, running_acc=0.6792, grad=10.9415]Training epoch 33: 100%|██████████| 31/31 [01:25<00:00,  1.96s/it, loss=1.4049, batch_acc=0.6875, running_acc=0.6792, grad=10.9415]Training epoch 33: 100%|██████████| 31/31 [01:25<00:00,  1.96s/it, loss=1.0640, batch_acc=1.0000, running_acc=0.6798, grad=25.7007]Training epoch 33: 100%|██████████| 31/31 [01:25<00:00,  2.75s/it, loss=1.0640, batch_acc=1.0000, running_acc=0.6798, grad=25.7007]
Evaluation epoch 33:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 33:  20%|██        | 1/5 [00:12<00:49, 12.33s/it]Evaluation epoch 33:  20%|██        | 1/5 [00:12<00:49, 12.33s/it, loss=1.3815, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 33:  40%|████      | 2/5 [00:13<00:16,  5.51s/it, loss=1.3815, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 33:  40%|████      | 2/5 [00:13<00:16,  5.51s/it, loss=1.3189, batch_acc=0.7188, running_acc=0.7344]Evaluation epoch 33:  60%|██████    | 3/5 [00:13<00:06,  3.33s/it, loss=1.3189, batch_acc=0.7188, running_acc=0.7344]Evaluation epoch 33:  60%|██████    | 3/5 [00:13<00:06,  3.33s/it, loss=1.7347, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 33:  80%|████████  | 4/5 [00:20<00:04,  4.61s/it, loss=1.7347, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 33:  80%|████████  | 4/5 [00:20<00:04,  4.61s/it, loss=1.7225, batch_acc=0.5625, running_acc=0.6328]Evaluation epoch 33: 100%|██████████| 5/5 [00:21<00:00,  3.23s/it, loss=1.7225, batch_acc=0.5625, running_acc=0.6328]Evaluation epoch 33: 100%|██████████| 5/5 [00:21<00:00,  3.23s/it, loss=1.9032, batch_acc=0.6250, running_acc=0.6312]Evaluation epoch 33: 100%|██████████| 5/5 [00:21<00:00,  4.23s/it, loss=1.9032, batch_acc=0.6250, running_acc=0.6312]
Training epoch 34:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 34:   3%|▎         | 1/31 [00:13<06:47, 13.57s/it]Training epoch 34:   3%|▎         | 1/31 [00:13<06:47, 13.57s/it, loss=1.2286, batch_acc=0.7812, running_acc=0.7812, grad=19.4149]Training epoch 34:   6%|▋         | 2/31 [00:15<03:07,  6.47s/it, loss=1.2286, batch_acc=0.7812, running_acc=0.7812, grad=19.4149]Training epoch 34:   6%|▋         | 2/31 [00:15<03:07,  6.47s/it, loss=1.3687, batch_acc=0.7188, running_acc=0.7500, grad=10.1583]Training epoch 34:  10%|▉         | 3/31 [00:16<01:57,  4.21s/it, loss=1.3687, batch_acc=0.7188, running_acc=0.7500, grad=10.1583]Training epoch 34:  10%|▉         | 3/31 [00:16<01:57,  4.21s/it, loss=1.1493, batch_acc=0.8125, running_acc=0.7708, grad=137.8339]Training epoch 34:  13%|█▎        | 4/31 [00:19<01:39,  3.69s/it, loss=1.1493, batch_acc=0.8125, running_acc=0.7708, grad=137.8339]Training epoch 34:  13%|█▎        | 4/31 [00:19<01:39,  3.69s/it, loss=1.3837, batch_acc=0.8438, running_acc=0.7891, grad=10.9555] Training epoch 34:  16%|█▌        | 5/31 [00:23<01:41,  3.91s/it, loss=1.3837, batch_acc=0.8438, running_acc=0.7891, grad=10.9555]Training epoch 34:  16%|█▌        | 5/31 [00:23<01:41,  3.91s/it, loss=1.4740, batch_acc=0.7188, running_acc=0.7750, grad=11.9256]Training epoch 34:  19%|█▉        | 6/31 [00:25<01:17,  3.10s/it, loss=1.4740, batch_acc=0.7188, running_acc=0.7750, grad=11.9256]Training epoch 34:  19%|█▉        | 6/31 [00:25<01:17,  3.10s/it, loss=1.6125, batch_acc=0.6562, running_acc=0.7552, grad=23.9459]Training epoch 34:  23%|██▎       | 7/31 [00:26<01:01,  2.58s/it, loss=1.6125, batch_acc=0.6562, running_acc=0.7552, grad=23.9459]Training epoch 34:  23%|██▎       | 7/31 [00:26<01:01,  2.58s/it, loss=1.6555, batch_acc=0.5000, running_acc=0.7188, grad=14.5464]Training epoch 34:  26%|██▌       | 8/31 [00:30<01:07,  2.92s/it, loss=1.6555, batch_acc=0.5000, running_acc=0.7188, grad=14.5464]Training epoch 34:  26%|██▌       | 8/31 [00:30<01:07,  2.92s/it, loss=1.3153, batch_acc=0.7812, running_acc=0.7266, grad=8.0249] Training epoch 34:  29%|██▉       | 9/31 [00:31<00:54,  2.48s/it, loss=1.3153, batch_acc=0.7812, running_acc=0.7266, grad=8.0249]Training epoch 34:  29%|██▉       | 9/31 [00:31<00:54,  2.48s/it, loss=1.5900, batch_acc=0.6250, running_acc=0.7153, grad=14.7868]Training epoch 34:  32%|███▏      | 10/31 [00:33<00:45,  2.18s/it, loss=1.5900, batch_acc=0.6250, running_acc=0.7153, grad=14.7868]Training epoch 34:  32%|███▏      | 10/31 [00:33<00:45,  2.18s/it, loss=1.4586, batch_acc=0.6875, running_acc=0.7125, grad=20.1375]Training epoch 34:  35%|███▌      | 11/31 [00:34<00:39,  1.97s/it, loss=1.4586, batch_acc=0.6875, running_acc=0.7125, grad=20.1375]Training epoch 34:  35%|███▌      | 11/31 [00:34<00:39,  1.97s/it, loss=1.7277, batch_acc=0.6875, running_acc=0.7102, grad=15.6127]Training epoch 34:  39%|███▊      | 12/31 [00:36<00:34,  1.83s/it, loss=1.7277, batch_acc=0.6875, running_acc=0.7102, grad=15.6127]Training epoch 34:  39%|███▊      | 12/31 [00:36<00:34,  1.83s/it, loss=1.3684, batch_acc=0.7188, running_acc=0.7109, grad=13.1339]Training epoch 34:  42%|████▏     | 13/31 [00:38<00:31,  1.74s/it, loss=1.3684, batch_acc=0.7188, running_acc=0.7109, grad=13.1339]Training epoch 34:  42%|████▏     | 13/31 [00:38<00:31,  1.74s/it, loss=1.4267, batch_acc=0.5938, running_acc=0.7019, grad=81.9368]Training epoch 34:  45%|████▌     | 14/31 [00:39<00:28,  1.67s/it, loss=1.4267, batch_acc=0.5938, running_acc=0.7019, grad=81.9368]Training epoch 34:  45%|████▌     | 14/31 [00:39<00:28,  1.67s/it, loss=1.4132, batch_acc=0.7188, running_acc=0.7031, grad=29.0866]Training epoch 34:  48%|████▊     | 15/31 [00:41<00:25,  1.62s/it, loss=1.4132, batch_acc=0.7188, running_acc=0.7031, grad=29.0866]Training epoch 34:  48%|████▊     | 15/31 [00:41<00:25,  1.62s/it, loss=1.6890, batch_acc=0.5938, running_acc=0.6958, grad=10.6063]Training epoch 34:  52%|█████▏    | 16/31 [00:43<00:29,  1.97s/it, loss=1.6890, batch_acc=0.5938, running_acc=0.6958, grad=10.6063]Training epoch 34:  52%|█████▏    | 16/31 [00:43<00:29,  1.97s/it, loss=1.6032, batch_acc=0.6875, running_acc=0.6953, grad=13.2049]Training epoch 34:  55%|█████▍    | 17/31 [00:45<00:26,  1.86s/it, loss=1.6032, batch_acc=0.6875, running_acc=0.6953, grad=13.2049]Training epoch 34:  55%|█████▍    | 17/31 [00:45<00:26,  1.86s/it, loss=1.5698, batch_acc=0.6562, running_acc=0.6930, grad=20.5128]Training epoch 34:  58%|█████▊    | 18/31 [00:46<00:22,  1.76s/it, loss=1.5698, batch_acc=0.6562, running_acc=0.6930, grad=20.5128]Training epoch 34:  58%|█████▊    | 18/31 [00:46<00:22,  1.76s/it, loss=1.5567, batch_acc=0.6562, running_acc=0.6910, grad=9.9335] Training epoch 34:  61%|██████▏   | 19/31 [00:48<00:20,  1.68s/it, loss=1.5567, batch_acc=0.6562, running_acc=0.6910, grad=9.9335]Training epoch 34:  61%|██████▏   | 19/31 [00:48<00:20,  1.68s/it, loss=1.3405, batch_acc=0.7500, running_acc=0.6941, grad=12.7959]Training epoch 34:  65%|██████▍   | 20/31 [00:58<00:45,  4.17s/it, loss=1.3405, batch_acc=0.7500, running_acc=0.6941, grad=12.7959]Training epoch 34:  65%|██████▍   | 20/31 [00:58<00:45,  4.17s/it, loss=1.4770, batch_acc=0.5625, running_acc=0.6875, grad=23.9536]Training epoch 34:  68%|██████▊   | 21/31 [01:00<00:34,  3.49s/it, loss=1.4770, batch_acc=0.5625, running_acc=0.6875, grad=23.9536]Training epoch 34:  68%|██████▊   | 21/31 [01:00<00:34,  3.49s/it, loss=1.5933, batch_acc=0.6875, running_acc=0.6875, grad=13.4770]Training epoch 34:  71%|███████   | 22/31 [01:01<00:26,  2.89s/it, loss=1.5933, batch_acc=0.6875, running_acc=0.6875, grad=13.4770]Training epoch 34:  71%|███████   | 22/31 [01:01<00:26,  2.89s/it, loss=1.5769, batch_acc=0.6250, running_acc=0.6847, grad=25.2839]Training epoch 34:  74%|███████▍  | 23/31 [01:03<00:19,  2.48s/it, loss=1.5769, batch_acc=0.6250, running_acc=0.6847, grad=25.2839]Training epoch 34:  74%|███████▍  | 23/31 [01:03<00:19,  2.48s/it, loss=1.6845, batch_acc=0.6562, running_acc=0.6834, grad=10.7018]Training epoch 34:  77%|███████▋  | 24/31 [01:05<00:17,  2.49s/it, loss=1.6845, batch_acc=0.6562, running_acc=0.6834, grad=10.7018]Training epoch 34:  77%|███████▋  | 24/31 [01:05<00:17,  2.49s/it, loss=1.4581, batch_acc=0.7812, running_acc=0.6875, grad=10.5108]Training epoch 34:  81%|████████  | 25/31 [01:07<00:13,  2.21s/it, loss=1.4581, batch_acc=0.7812, running_acc=0.6875, grad=10.5108]Training epoch 34:  81%|████████  | 25/31 [01:07<00:13,  2.21s/it, loss=1.1965, batch_acc=0.8438, running_acc=0.6937, grad=40.8769]Training epoch 34:  84%|████████▍ | 26/31 [01:12<00:15,  3.01s/it, loss=1.1965, batch_acc=0.8438, running_acc=0.6937, grad=40.8769]Training epoch 34:  84%|████████▍ | 26/31 [01:12<00:15,  3.01s/it, loss=1.6408, batch_acc=0.6562, running_acc=0.6923, grad=22.9834]Training epoch 34:  87%|████████▋ | 27/31 [01:13<00:10,  2.56s/it, loss=1.6408, batch_acc=0.6562, running_acc=0.6923, grad=22.9834]Training epoch 34:  87%|████████▋ | 27/31 [01:13<00:10,  2.56s/it, loss=1.4985, batch_acc=0.6562, running_acc=0.6910, grad=16.7409]Training epoch 34:  90%|█████████ | 28/31 [01:15<00:06,  2.24s/it, loss=1.4985, batch_acc=0.6562, running_acc=0.6910, grad=16.7409]Training epoch 34:  90%|█████████ | 28/31 [01:15<00:06,  2.24s/it, loss=1.7961, batch_acc=0.5625, running_acc=0.6864, grad=11.8591]Training epoch 34:  94%|█████████▎| 29/31 [01:16<00:04,  2.02s/it, loss=1.7961, batch_acc=0.5625, running_acc=0.6864, grad=11.8591]Training epoch 34:  94%|█████████▎| 29/31 [01:16<00:04,  2.02s/it, loss=1.5443, batch_acc=0.6875, running_acc=0.6864, grad=30.2620]Training epoch 34:  97%|█████████▋| 30/31 [01:18<00:01,  1.88s/it, loss=1.5443, batch_acc=0.6875, running_acc=0.6864, grad=30.2620]Training epoch 34:  97%|█████████▋| 30/31 [01:18<00:01,  1.88s/it, loss=1.7706, batch_acc=0.5000, running_acc=0.6802, grad=13.2177]Training epoch 34: 100%|██████████| 31/31 [01:18<00:00,  1.38s/it, loss=1.7706, batch_acc=0.5000, running_acc=0.6802, grad=13.2177]Training epoch 34: 100%|██████████| 31/31 [01:18<00:00,  1.38s/it, loss=0.5704, batch_acc=1.0000, running_acc=0.6809, grad=16.5256]Training epoch 34: 100%|██████████| 31/31 [01:18<00:00,  2.54s/it, loss=0.5704, batch_acc=1.0000, running_acc=0.6809, grad=16.5256]
Evaluation epoch 34:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 34:  20%|██        | 1/5 [00:13<00:55, 13.86s/it]Evaluation epoch 34:  20%|██        | 1/5 [00:13<00:55, 13.86s/it, loss=1.4820, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 34:  40%|████      | 2/5 [00:14<00:18,  6.15s/it, loss=1.4820, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 34:  40%|████      | 2/5 [00:14<00:18,  6.15s/it, loss=1.2836, batch_acc=0.7812, running_acc=0.7344]Evaluation epoch 34:  60%|██████    | 3/5 [00:15<00:07,  3.68s/it, loss=1.2836, batch_acc=0.7812, running_acc=0.7344]Evaluation epoch 34:  60%|██████    | 3/5 [00:15<00:07,  3.68s/it, loss=1.7095, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 34:  80%|████████  | 4/5 [00:16<00:02,  2.75s/it, loss=1.7095, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 34:  80%|████████  | 4/5 [00:16<00:02,  2.75s/it, loss=1.6799, batch_acc=0.5625, running_acc=0.6328]Evaluation epoch 34: 100%|██████████| 5/5 [00:17<00:00,  2.04s/it, loss=1.6799, batch_acc=0.5625, running_acc=0.6328]Evaluation epoch 34: 100%|██████████| 5/5 [00:17<00:00,  2.04s/it, loss=1.9195, batch_acc=0.5312, running_acc=0.6125]Evaluation epoch 34: 100%|██████████| 5/5 [00:17<00:00,  3.49s/it, loss=1.9195, batch_acc=0.5312, running_acc=0.6125]
Training epoch 35:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 35:   3%|▎         | 1/31 [00:09<04:32,  9.08s/it]Training epoch 35:   3%|▎         | 1/31 [00:09<04:32,  9.08s/it, loss=1.4499, batch_acc=0.7812, running_acc=0.7812, grad=23.6955]Training epoch 35:   6%|▋         | 2/31 [00:10<02:14,  4.63s/it, loss=1.4499, batch_acc=0.7812, running_acc=0.7812, grad=23.6955]Training epoch 35:   6%|▋         | 2/31 [00:10<02:14,  4.63s/it, loss=1.7245, batch_acc=0.5625, running_acc=0.6719, grad=27.3774]Training epoch 35:  10%|▉         | 3/31 [00:12<01:29,  3.20s/it, loss=1.7245, batch_acc=0.5625, running_acc=0.6719, grad=27.3774]Training epoch 35:  10%|▉         | 3/31 [00:12<01:29,  3.20s/it, loss=1.6504, batch_acc=0.6250, running_acc=0.6562, grad=20.4569]Training epoch 35:  13%|█▎        | 4/31 [00:13<01:09,  2.56s/it, loss=1.6504, batch_acc=0.6250, running_acc=0.6562, grad=20.4569]Training epoch 35:  13%|█▎        | 4/31 [00:13<01:09,  2.56s/it, loss=1.5676, batch_acc=0.6250, running_acc=0.6484, grad=11.0592]Training epoch 35:  16%|█▌        | 5/31 [00:15<00:56,  2.18s/it, loss=1.5676, batch_acc=0.6250, running_acc=0.6484, grad=11.0592]Training epoch 35:  16%|█▌        | 5/31 [00:15<00:56,  2.18s/it, loss=1.4962, batch_acc=0.7188, running_acc=0.6625, grad=11.2506]Training epoch 35:  19%|█▉        | 6/31 [00:16<00:48,  1.95s/it, loss=1.4962, batch_acc=0.7188, running_acc=0.6625, grad=11.2506]Training epoch 35:  19%|█▉        | 6/31 [00:16<00:48,  1.95s/it, loss=1.5891, batch_acc=0.6875, running_acc=0.6667, grad=10.3118]Training epoch 35:  23%|██▎       | 7/31 [00:18<00:43,  1.81s/it, loss=1.5891, batch_acc=0.6875, running_acc=0.6667, grad=10.3118]Training epoch 35:  23%|██▎       | 7/31 [00:18<00:43,  1.81s/it, loss=1.4082, batch_acc=0.6875, running_acc=0.6696, grad=14.7246]Training epoch 35:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=1.4082, batch_acc=0.6875, running_acc=0.6696, grad=14.7246]Training epoch 35:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=1.2821, batch_acc=0.7188, running_acc=0.6758, grad=18.5027]Training epoch 35:  29%|██▉       | 9/31 [00:21<00:36,  1.65s/it, loss=1.2821, batch_acc=0.7188, running_acc=0.6758, grad=18.5027]Training epoch 35:  29%|██▉       | 9/31 [00:21<00:36,  1.65s/it, loss=1.4627, batch_acc=0.6875, running_acc=0.6771, grad=124.5245]Training epoch 35:  32%|███▏      | 10/31 [00:22<00:33,  1.61s/it, loss=1.4627, batch_acc=0.6875, running_acc=0.6771, grad=124.5245]Training epoch 35:  32%|███▏      | 10/31 [00:22<00:33,  1.61s/it, loss=1.5754, batch_acc=0.6875, running_acc=0.6781, grad=19.2955] Training epoch 35:  35%|███▌      | 11/31 [00:24<00:32,  1.62s/it, loss=1.5754, batch_acc=0.6875, running_acc=0.6781, grad=19.2955]Training epoch 35:  35%|███▌      | 11/31 [00:24<00:32,  1.62s/it, loss=1.5929, batch_acc=0.6250, running_acc=0.6733, grad=16.6523]Training epoch 35:  39%|███▊      | 12/31 [00:25<00:30,  1.59s/it, loss=1.5929, batch_acc=0.6250, running_acc=0.6733, grad=16.6523]Training epoch 35:  39%|███▊      | 12/31 [00:25<00:30,  1.59s/it, loss=1.6547, batch_acc=0.6250, running_acc=0.6693, grad=30.6579]Training epoch 35:  42%|████▏     | 13/31 [00:27<00:28,  1.56s/it, loss=1.6547, batch_acc=0.6250, running_acc=0.6693, grad=30.6579]Training epoch 35:  42%|████▏     | 13/31 [00:27<00:28,  1.56s/it, loss=1.6431, batch_acc=0.5938, running_acc=0.6635, grad=16.3021]Training epoch 35:  45%|████▌     | 14/31 [00:28<00:26,  1.55s/it, loss=1.6431, batch_acc=0.5938, running_acc=0.6635, grad=16.3021]Training epoch 35:  45%|████▌     | 14/31 [00:28<00:26,  1.55s/it, loss=1.5866, batch_acc=0.6562, running_acc=0.6629, grad=14.4803]Training epoch 35:  48%|████▊     | 15/31 [00:30<00:24,  1.54s/it, loss=1.5866, batch_acc=0.6562, running_acc=0.6629, grad=14.4803]Training epoch 35:  48%|████▊     | 15/31 [00:30<00:24,  1.54s/it, loss=1.4064, batch_acc=0.7812, running_acc=0.6708, grad=13.7263]Training epoch 35:  52%|█████▏    | 16/31 [00:31<00:22,  1.53s/it, loss=1.4064, batch_acc=0.7812, running_acc=0.6708, grad=13.7263]Training epoch 35:  52%|█████▏    | 16/31 [00:31<00:22,  1.53s/it, loss=1.4401, batch_acc=0.6562, running_acc=0.6699, grad=26.6959]Training epoch 35:  55%|█████▍    | 17/31 [00:33<00:21,  1.52s/it, loss=1.4401, batch_acc=0.6562, running_acc=0.6699, grad=26.6959]Training epoch 35:  55%|█████▍    | 17/31 [00:33<00:21,  1.52s/it, loss=1.4877, batch_acc=0.5938, running_acc=0.6654, grad=14.9384]Training epoch 35:  58%|█████▊    | 18/31 [00:34<00:19,  1.52s/it, loss=1.4877, batch_acc=0.5938, running_acc=0.6654, grad=14.9384]Training epoch 35:  58%|█████▊    | 18/31 [00:34<00:19,  1.52s/it, loss=1.2495, batch_acc=0.7500, running_acc=0.6701, grad=12.3931]Training epoch 35:  61%|██████▏   | 19/31 [00:36<00:18,  1.52s/it, loss=1.2495, batch_acc=0.7500, running_acc=0.6701, grad=12.3931]Training epoch 35:  61%|██████▏   | 19/31 [00:36<00:18,  1.52s/it, loss=1.6633, batch_acc=0.5938, running_acc=0.6661, grad=19.4033]Training epoch 35:  65%|██████▍   | 20/31 [00:37<00:16,  1.51s/it, loss=1.6633, batch_acc=0.5938, running_acc=0.6661, grad=19.4033]Training epoch 35:  65%|██████▍   | 20/31 [00:37<00:16,  1.51s/it, loss=1.4235, batch_acc=0.7812, running_acc=0.6719, grad=21.0503]Training epoch 35:  68%|██████▊   | 21/31 [00:39<00:15,  1.51s/it, loss=1.4235, batch_acc=0.7812, running_acc=0.6719, grad=21.0503]Training epoch 35:  68%|██████▊   | 21/31 [00:39<00:15,  1.51s/it, loss=1.3070, batch_acc=0.8125, running_acc=0.6786, grad=6.1275] Training epoch 35:  71%|███████   | 22/31 [00:40<00:13,  1.51s/it, loss=1.3070, batch_acc=0.8125, running_acc=0.6786, grad=6.1275]Training epoch 35:  71%|███████   | 22/31 [00:40<00:13,  1.51s/it, loss=1.5109, batch_acc=0.6562, running_acc=0.6776, grad=8.3016]Training epoch 35:  74%|███████▍  | 23/31 [00:42<00:12,  1.51s/it, loss=1.5109, batch_acc=0.6562, running_acc=0.6776, grad=8.3016]Training epoch 35:  74%|███████▍  | 23/31 [00:42<00:12,  1.51s/it, loss=1.3656, batch_acc=0.7500, running_acc=0.6807, grad=7.6780]Training epoch 35:  77%|███████▋  | 24/31 [00:44<00:10,  1.51s/it, loss=1.3656, batch_acc=0.7500, running_acc=0.6807, grad=7.6780]Training epoch 35:  77%|███████▋  | 24/31 [00:44<00:10,  1.51s/it, loss=1.6230, batch_acc=0.6250, running_acc=0.6784, grad=16.7416]Training epoch 35:  81%|████████  | 25/31 [00:45<00:09,  1.51s/it, loss=1.6230, batch_acc=0.6250, running_acc=0.6784, grad=16.7416]Training epoch 35:  81%|████████  | 25/31 [00:45<00:09,  1.51s/it, loss=1.7111, batch_acc=0.5938, running_acc=0.6750, grad=59.1955]Training epoch 35:  84%|████████▍ | 26/31 [00:47<00:07,  1.51s/it, loss=1.7111, batch_acc=0.5938, running_acc=0.6750, grad=59.1955]Training epoch 35:  84%|████████▍ | 26/31 [00:47<00:07,  1.51s/it, loss=1.2297, batch_acc=0.8125, running_acc=0.6803, grad=9.1364] Training epoch 35:  87%|████████▋ | 27/31 [00:48<00:06,  1.50s/it, loss=1.2297, batch_acc=0.8125, running_acc=0.6803, grad=9.1364]Training epoch 35:  87%|████████▋ | 27/31 [00:48<00:06,  1.50s/it, loss=1.3910, batch_acc=0.7500, running_acc=0.6829, grad=16.1010]Training epoch 35:  90%|█████████ | 28/31 [00:50<00:04,  1.50s/it, loss=1.3910, batch_acc=0.7500, running_acc=0.6829, grad=16.1010]Training epoch 35:  90%|█████████ | 28/31 [00:50<00:04,  1.50s/it, loss=1.2882, batch_acc=0.8125, running_acc=0.6875, grad=14.8425]Training epoch 35:  94%|█████████▎| 29/31 [00:51<00:03,  1.50s/it, loss=1.2882, batch_acc=0.8125, running_acc=0.6875, grad=14.8425]Training epoch 35:  94%|█████████▎| 29/31 [00:51<00:03,  1.50s/it, loss=1.3454, batch_acc=0.7500, running_acc=0.6897, grad=18.7640]Training epoch 35:  97%|█████████▋| 30/31 [00:53<00:01,  1.50s/it, loss=1.3454, batch_acc=0.7500, running_acc=0.6897, grad=18.7640]Training epoch 35:  97%|█████████▋| 30/31 [00:53<00:01,  1.50s/it, loss=1.7782, batch_acc=0.5938, running_acc=0.6865, grad=10.3043]Training epoch 35: 100%|██████████| 31/31 [00:53<00:00,  1.11s/it, loss=1.7782, batch_acc=0.5938, running_acc=0.6865, grad=10.3043]Training epoch 35: 100%|██████████| 31/31 [00:53<00:00,  1.11s/it, loss=0.7268, batch_acc=1.0000, running_acc=0.6871, grad=186.2183]Training epoch 35: 100%|██████████| 31/31 [00:53<00:00,  1.72s/it, loss=0.7268, batch_acc=1.0000, running_acc=0.6871, grad=186.2183]
Evaluation epoch 35:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 35:  20%|██        | 1/5 [00:04<00:19,  4.90s/it]Evaluation epoch 35:  20%|██        | 1/5 [00:04<00:19,  4.90s/it, loss=1.4971, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 35:  40%|████      | 2/5 [00:05<00:07,  2.45s/it, loss=1.4971, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 35:  40%|████      | 2/5 [00:05<00:07,  2.45s/it, loss=1.3172, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 35:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.3172, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 35:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.5780, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 35:  80%|████████  | 4/5 [00:07<00:01,  1.52s/it, loss=1.5780, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 35:  80%|████████  | 4/5 [00:07<00:01,  1.52s/it, loss=1.7151, batch_acc=0.5312, running_acc=0.6406]Evaluation epoch 35: 100%|██████████| 5/5 [00:08<00:00,  1.26s/it, loss=1.7151, batch_acc=0.5312, running_acc=0.6406]Evaluation epoch 35: 100%|██████████| 5/5 [00:08<00:00,  1.26s/it, loss=1.9504, batch_acc=0.5312, running_acc=0.6188]Evaluation epoch 35: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it, loss=1.9504, batch_acc=0.5312, running_acc=0.6188]
Training epoch 36:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 36:   3%|▎         | 1/31 [00:12<06:09, 12.33s/it]Training epoch 36:   3%|▎         | 1/31 [00:12<06:09, 12.33s/it, loss=1.7126, batch_acc=0.6875, running_acc=0.6875, grad=12.5139]Training epoch 36:   6%|▋         | 2/31 [00:13<02:52,  5.96s/it, loss=1.7126, batch_acc=0.6875, running_acc=0.6875, grad=12.5139]Training epoch 36:   6%|▋         | 2/31 [00:13<02:52,  5.96s/it, loss=1.6399, batch_acc=0.5938, running_acc=0.6406, grad=12.2076]Training epoch 36:  10%|▉         | 3/31 [00:15<01:49,  3.93s/it, loss=1.6399, batch_acc=0.5938, running_acc=0.6406, grad=12.2076]Training epoch 36:  10%|▉         | 3/31 [00:15<01:49,  3.93s/it, loss=1.4948, batch_acc=0.7812, running_acc=0.6875, grad=12.3881]Training epoch 36:  13%|█▎        | 4/31 [00:17<01:30,  3.36s/it, loss=1.4948, batch_acc=0.7812, running_acc=0.6875, grad=12.3881]Training epoch 36:  13%|█▎        | 4/31 [00:17<01:30,  3.36s/it, loss=1.4664, batch_acc=0.8125, running_acc=0.7188, grad=8.4515] Training epoch 36:  16%|█▌        | 5/31 [00:19<01:10,  2.69s/it, loss=1.4664, batch_acc=0.8125, running_acc=0.7188, grad=8.4515]Training epoch 36:  16%|█▌        | 5/31 [00:19<01:10,  2.69s/it, loss=1.4230, batch_acc=0.7812, running_acc=0.7312, grad=8.6944]Training epoch 36:  19%|█▉        | 6/31 [00:20<00:57,  2.29s/it, loss=1.4230, batch_acc=0.7812, running_acc=0.7312, grad=8.6944]Training epoch 36:  19%|█▉        | 6/31 [00:20<00:57,  2.29s/it, loss=1.7746, batch_acc=0.5312, running_acc=0.6979, grad=23.0801]Training epoch 36:  23%|██▎       | 7/31 [00:22<00:48,  2.03s/it, loss=1.7746, batch_acc=0.5312, running_acc=0.6979, grad=23.0801]Training epoch 36:  23%|██▎       | 7/31 [00:22<00:48,  2.03s/it, loss=1.3356, batch_acc=0.7500, running_acc=0.7054, grad=18.4229]Training epoch 36:  26%|██▌       | 8/31 [00:30<01:30,  3.94s/it, loss=1.3356, batch_acc=0.7500, running_acc=0.7054, grad=18.4229]Training epoch 36:  26%|██▌       | 8/31 [00:30<01:30,  3.94s/it, loss=1.3075, batch_acc=0.7500, running_acc=0.7109, grad=7.4112] Training epoch 36:  29%|██▉       | 9/31 [00:31<01:09,  3.18s/it, loss=1.3075, batch_acc=0.7500, running_acc=0.7109, grad=7.4112]Training epoch 36:  29%|██▉       | 9/31 [00:31<01:09,  3.18s/it, loss=1.4221, batch_acc=0.7500, running_acc=0.7153, grad=7.4289]Training epoch 36:  32%|███▏      | 10/31 [00:33<00:55,  2.66s/it, loss=1.4221, batch_acc=0.7500, running_acc=0.7153, grad=7.4289]Training epoch 36:  32%|███▏      | 10/31 [00:33<00:55,  2.66s/it, loss=1.6236, batch_acc=0.6250, running_acc=0.7063, grad=8.9273]Training epoch 36:  35%|███▌      | 11/31 [00:34<00:46,  2.31s/it, loss=1.6236, batch_acc=0.6250, running_acc=0.7063, grad=8.9273]Training epoch 36:  35%|███▌      | 11/31 [00:34<00:46,  2.31s/it, loss=1.4654, batch_acc=0.6875, running_acc=0.7045, grad=127.9812]Training epoch 36:  39%|███▊      | 12/31 [00:36<00:39,  2.07s/it, loss=1.4654, batch_acc=0.6875, running_acc=0.7045, grad=127.9812]Training epoch 36:  39%|███▊      | 12/31 [00:36<00:39,  2.07s/it, loss=1.3451, batch_acc=0.7188, running_acc=0.7057, grad=8.0918]  Training epoch 36:  42%|████▏     | 13/31 [00:37<00:34,  1.90s/it, loss=1.3451, batch_acc=0.7188, running_acc=0.7057, grad=8.0918]Training epoch 36:  42%|████▏     | 13/31 [00:37<00:34,  1.90s/it, loss=1.2923, batch_acc=0.8125, running_acc=0.7139, grad=11.8326]Training epoch 36:  45%|████▌     | 14/31 [00:39<00:30,  1.78s/it, loss=1.2923, batch_acc=0.8125, running_acc=0.7139, grad=11.8326]Training epoch 36:  45%|████▌     | 14/31 [00:39<00:30,  1.78s/it, loss=1.6164, batch_acc=0.5938, running_acc=0.7054, grad=18.9030]Training epoch 36:  48%|████▊     | 15/31 [00:40<00:27,  1.70s/it, loss=1.6164, batch_acc=0.5938, running_acc=0.7054, grad=18.9030]Training epoch 36:  48%|████▊     | 15/31 [00:40<00:27,  1.70s/it, loss=1.4332, batch_acc=0.6250, running_acc=0.7000, grad=448.2253]Training epoch 36:  52%|█████▏    | 16/31 [00:42<00:24,  1.67s/it, loss=1.4332, batch_acc=0.6250, running_acc=0.7000, grad=448.2253]Training epoch 36:  52%|█████▏    | 16/31 [00:42<00:24,  1.67s/it, loss=1.6951, batch_acc=0.6875, running_acc=0.6992, grad=21.5818] Training epoch 36:  55%|█████▍    | 17/31 [00:44<00:22,  1.62s/it, loss=1.6951, batch_acc=0.6875, running_acc=0.6992, grad=21.5818]Training epoch 36:  55%|█████▍    | 17/31 [00:44<00:22,  1.62s/it, loss=1.2311, batch_acc=0.8125, running_acc=0.7059, grad=19.9364]Training epoch 36:  58%|█████▊    | 18/31 [00:45<00:20,  1.58s/it, loss=1.2311, batch_acc=0.8125, running_acc=0.7059, grad=19.9364]Training epoch 36:  58%|█████▊    | 18/31 [00:45<00:20,  1.58s/it, loss=1.4096, batch_acc=0.6875, running_acc=0.7049, grad=16.8858]Training epoch 36:  61%|██████▏   | 19/31 [00:47<00:18,  1.56s/it, loss=1.4096, batch_acc=0.6875, running_acc=0.7049, grad=16.8858]Training epoch 36:  61%|██████▏   | 19/31 [00:47<00:18,  1.56s/it, loss=1.4899, batch_acc=0.5625, running_acc=0.6974, grad=24.3157]Training epoch 36:  65%|██████▍   | 20/31 [00:52<00:31,  2.84s/it, loss=1.4899, batch_acc=0.5625, running_acc=0.6974, grad=24.3157]Training epoch 36:  65%|██████▍   | 20/31 [00:52<00:31,  2.84s/it, loss=1.4838, batch_acc=0.7812, running_acc=0.7016, grad=13.1122]Training epoch 36:  68%|██████▊   | 21/31 [00:54<00:24,  2.44s/it, loss=1.4838, batch_acc=0.7812, running_acc=0.7016, grad=13.1122]Training epoch 36:  68%|██████▊   | 21/31 [00:54<00:24,  2.44s/it, loss=1.7318, batch_acc=0.5625, running_acc=0.6949, grad=7.1634] Training epoch 36:  71%|███████   | 22/31 [00:55<00:19,  2.16s/it, loss=1.7318, batch_acc=0.5625, running_acc=0.6949, grad=7.1634]Training epoch 36:  71%|███████   | 22/31 [00:55<00:19,  2.16s/it, loss=1.5077, batch_acc=0.7812, running_acc=0.6989, grad=8.8794]Training epoch 36:  74%|███████▍  | 23/31 [00:57<00:15,  1.96s/it, loss=1.5077, batch_acc=0.7812, running_acc=0.6989, grad=8.8794]Training epoch 36:  74%|███████▍  | 23/31 [00:57<00:15,  1.96s/it, loss=1.4553, batch_acc=0.7188, running_acc=0.6997, grad=7.3452]Training epoch 36:  77%|███████▋  | 24/31 [01:00<00:16,  2.38s/it, loss=1.4553, batch_acc=0.7188, running_acc=0.6997, grad=7.3452]Training epoch 36:  77%|███████▋  | 24/31 [01:00<00:16,  2.38s/it, loss=1.4162, batch_acc=0.7500, running_acc=0.7018, grad=14.0858]Training epoch 36:  81%|████████  | 25/31 [01:02<00:12,  2.11s/it, loss=1.4162, batch_acc=0.7500, running_acc=0.7018, grad=14.0858]Training epoch 36:  81%|████████  | 25/31 [01:02<00:12,  2.11s/it, loss=1.3473, batch_acc=0.8125, running_acc=0.7063, grad=28.6882]Training epoch 36:  84%|████████▍ | 26/31 [01:03<00:09,  1.93s/it, loss=1.3473, batch_acc=0.8125, running_acc=0.7063, grad=28.6882]Training epoch 36:  84%|████████▍ | 26/31 [01:03<00:09,  1.93s/it, loss=1.2243, batch_acc=0.7812, running_acc=0.7091, grad=8.4780] Training epoch 36:  87%|████████▋ | 27/31 [01:10<00:13,  3.39s/it, loss=1.2243, batch_acc=0.7812, running_acc=0.7091, grad=8.4780]Training epoch 36:  87%|████████▋ | 27/31 [01:10<00:13,  3.39s/it, loss=1.4303, batch_acc=0.6250, running_acc=0.7060, grad=12.7088]Training epoch 36:  90%|█████████ | 28/31 [01:20<00:16,  5.35s/it, loss=1.4303, batch_acc=0.6250, running_acc=0.7060, grad=12.7088]Training epoch 36:  90%|█████████ | 28/31 [01:20<00:16,  5.35s/it, loss=1.4465, batch_acc=0.6875, running_acc=0.7054, grad=10.7740]Training epoch 36:  94%|█████████▎| 29/31 [01:21<00:08,  4.20s/it, loss=1.4465, batch_acc=0.6875, running_acc=0.7054, grad=10.7740]Training epoch 36:  94%|█████████▎| 29/31 [01:21<00:08,  4.20s/it, loss=1.5021, batch_acc=0.6875, running_acc=0.7047, grad=31.5086]Training epoch 36:  97%|█████████▋| 30/31 [01:23<00:03,  3.39s/it, loss=1.5021, batch_acc=0.6875, running_acc=0.7047, grad=31.5086]Training epoch 36:  97%|█████████▋| 30/31 [01:23<00:03,  3.39s/it, loss=1.6826, batch_acc=0.5625, running_acc=0.7000, grad=10.4591]Training epoch 36: 100%|██████████| 31/31 [01:23<00:00,  2.44s/it, loss=1.6826, batch_acc=0.5625, running_acc=0.7000, grad=10.4591]Training epoch 36: 100%|██████████| 31/31 [01:23<00:00,  2.44s/it, loss=2.1331, batch_acc=0.5000, running_acc=0.6996, grad=21.3339]Training epoch 36: 100%|██████████| 31/31 [01:23<00:00,  2.70s/it, loss=2.1331, batch_acc=0.5000, running_acc=0.6996, grad=21.3339]
Evaluation epoch 36:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 36:  20%|██        | 1/5 [00:07<00:28,  7.03s/it]Evaluation epoch 36:  20%|██        | 1/5 [00:07<00:28,  7.03s/it, loss=1.4963, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 36:  40%|████      | 2/5 [00:07<00:10,  3.33s/it, loss=1.4963, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 36:  40%|████      | 2/5 [00:07<00:10,  3.33s/it, loss=1.3107, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 36:  60%|██████    | 3/5 [00:08<00:04,  2.17s/it, loss=1.3107, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 36:  60%|██████    | 3/5 [00:08<00:04,  2.17s/it, loss=1.5878, batch_acc=0.5938, running_acc=0.6771]Evaluation epoch 36:  80%|████████  | 4/5 [00:12<00:02,  2.84s/it, loss=1.5878, batch_acc=0.5938, running_acc=0.6771]Evaluation epoch 36:  80%|████████  | 4/5 [00:12<00:02,  2.84s/it, loss=1.7289, batch_acc=0.5312, running_acc=0.6406]Evaluation epoch 36: 100%|██████████| 5/5 [00:13<00:00,  2.09s/it, loss=1.7289, batch_acc=0.5312, running_acc=0.6406]Evaluation epoch 36: 100%|██████████| 5/5 [00:13<00:00,  2.09s/it, loss=1.8900, batch_acc=0.6250, running_acc=0.6375]Evaluation epoch 36: 100%|██████████| 5/5 [00:13<00:00,  2.64s/it, loss=1.8900, batch_acc=0.6250, running_acc=0.6375]
Training epoch 37:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 37:   3%|▎         | 1/31 [00:14<07:00, 14.03s/it]Training epoch 37:   3%|▎         | 1/31 [00:14<07:00, 14.03s/it, loss=1.5614, batch_acc=0.5625, running_acc=0.5625, grad=18.3988]Training epoch 37:   6%|▋         | 2/31 [00:15<03:13,  6.66s/it, loss=1.5614, batch_acc=0.5625, running_acc=0.5625, grad=18.3988]Training epoch 37:   6%|▋         | 2/31 [00:15<03:13,  6.66s/it, loss=1.5839, batch_acc=0.5938, running_acc=0.5781, grad=15.8066]Training epoch 37:  10%|▉         | 3/31 [00:17<02:00,  4.31s/it, loss=1.5839, batch_acc=0.5938, running_acc=0.5781, grad=15.8066]Training epoch 37:  10%|▉         | 3/31 [00:17<02:00,  4.31s/it, loss=1.4996, batch_acc=0.7188, running_acc=0.6250, grad=28.9608]Training epoch 37:  13%|█▎        | 4/31 [00:26<02:47,  6.19s/it, loss=1.4996, batch_acc=0.7188, running_acc=0.6250, grad=28.9608]Training epoch 37:  13%|█▎        | 4/31 [00:26<02:47,  6.19s/it, loss=1.5024, batch_acc=0.6562, running_acc=0.6328, grad=9.9191] Training epoch 37:  16%|█▌        | 5/31 [00:27<01:57,  4.50s/it, loss=1.5024, batch_acc=0.6562, running_acc=0.6328, grad=9.9191]Training epoch 37:  16%|█▌        | 5/31 [00:27<01:57,  4.50s/it, loss=1.6320, batch_acc=0.6562, running_acc=0.6375, grad=66.8051]Training epoch 37:  19%|█▉        | 6/31 [00:29<01:27,  3.48s/it, loss=1.6320, batch_acc=0.6562, running_acc=0.6375, grad=66.8051]Training epoch 37:  19%|█▉        | 6/31 [00:29<01:27,  3.48s/it, loss=1.4114, batch_acc=0.7188, running_acc=0.6510, grad=22.4477]Training epoch 37:  23%|██▎       | 7/31 [00:30<01:08,  2.84s/it, loss=1.4114, batch_acc=0.7188, running_acc=0.6510, grad=22.4477]Training epoch 37:  23%|██▎       | 7/31 [00:30<01:08,  2.84s/it, loss=1.2904, batch_acc=0.7500, running_acc=0.6652, grad=8.6446] Training epoch 37:  26%|██▌       | 8/31 [00:36<01:24,  3.66s/it, loss=1.2904, batch_acc=0.7500, running_acc=0.6652, grad=8.6446]Training epoch 37:  26%|██▌       | 8/31 [00:36<01:24,  3.66s/it, loss=1.5783, batch_acc=0.6562, running_acc=0.6641, grad=13.4670]Training epoch 37:  29%|██▉       | 9/31 [00:37<01:05,  2.99s/it, loss=1.5783, batch_acc=0.6562, running_acc=0.6641, grad=13.4670]Training epoch 37:  29%|██▉       | 9/31 [00:37<01:05,  2.99s/it, loss=1.4357, batch_acc=0.7500, running_acc=0.6736, grad=18.2451]Training epoch 37:  32%|███▏      | 10/31 [00:39<00:53,  2.53s/it, loss=1.4357, batch_acc=0.7500, running_acc=0.6736, grad=18.2451]Training epoch 37:  32%|███▏      | 10/31 [00:39<00:53,  2.53s/it, loss=1.6168, batch_acc=0.6250, running_acc=0.6687, grad=301.2258]Training epoch 37:  35%|███▌      | 11/31 [00:40<00:44,  2.22s/it, loss=1.6168, batch_acc=0.6250, running_acc=0.6687, grad=301.2258]Training epoch 37:  35%|███▌      | 11/31 [00:40<00:44,  2.22s/it, loss=1.8083, batch_acc=0.6875, running_acc=0.6705, grad=19.0220] Training epoch 37:  39%|███▊      | 12/31 [00:44<00:52,  2.78s/it, loss=1.8083, batch_acc=0.6875, running_acc=0.6705, grad=19.0220]Training epoch 37:  39%|███▊      | 12/31 [00:44<00:52,  2.78s/it, loss=1.5262, batch_acc=0.7500, running_acc=0.6771, grad=10.7707]Training epoch 37:  42%|████▏     | 13/31 [00:46<00:43,  2.40s/it, loss=1.5262, batch_acc=0.7500, running_acc=0.6771, grad=10.7707]Training epoch 37:  42%|████▏     | 13/31 [00:46<00:43,  2.40s/it, loss=1.4057, batch_acc=0.6875, running_acc=0.6779, grad=12.3719]Training epoch 37:  45%|████▌     | 14/31 [00:47<00:36,  2.13s/it, loss=1.4057, batch_acc=0.6875, running_acc=0.6779, grad=12.3719]Training epoch 37:  45%|████▌     | 14/31 [00:47<00:36,  2.13s/it, loss=1.3373, batch_acc=0.7500, running_acc=0.6830, grad=12.1436]Training epoch 37:  48%|████▊     | 15/31 [00:49<00:31,  1.94s/it, loss=1.3373, batch_acc=0.7500, running_acc=0.6830, grad=12.1436]Training epoch 37:  48%|████▊     | 15/31 [00:49<00:31,  1.94s/it, loss=1.3844, batch_acc=0.7500, running_acc=0.6875, grad=44.2426]Training epoch 37:  52%|█████▏    | 16/31 [00:50<00:28,  1.89s/it, loss=1.3844, batch_acc=0.7500, running_acc=0.6875, grad=44.2426]Training epoch 37:  52%|█████▏    | 16/31 [00:50<00:28,  1.89s/it, loss=1.3382, batch_acc=0.7188, running_acc=0.6895, grad=11.6991]Training epoch 37:  55%|█████▍    | 17/31 [00:52<00:24,  1.78s/it, loss=1.3382, batch_acc=0.7188, running_acc=0.6895, grad=11.6991]Training epoch 37:  55%|█████▍    | 17/31 [00:52<00:24,  1.78s/it, loss=1.3321, batch_acc=0.7812, running_acc=0.6949, grad=52.3130]Training epoch 37:  58%|█████▊    | 18/31 [00:53<00:22,  1.70s/it, loss=1.3321, batch_acc=0.7812, running_acc=0.6949, grad=52.3130]Training epoch 37:  58%|█████▊    | 18/31 [00:53<00:22,  1.70s/it, loss=1.3960, batch_acc=0.6875, running_acc=0.6944, grad=26.6933]Training epoch 37:  61%|██████▏   | 19/31 [00:55<00:19,  1.64s/it, loss=1.3960, batch_acc=0.6875, running_acc=0.6944, grad=26.6933]Training epoch 37:  61%|██████▏   | 19/31 [00:55<00:19,  1.64s/it, loss=1.3339, batch_acc=0.7812, running_acc=0.6990, grad=11.1606]Training epoch 37:  65%|██████▍   | 20/31 [01:05<00:45,  4.17s/it, loss=1.3339, batch_acc=0.7812, running_acc=0.6990, grad=11.1606]Training epoch 37:  65%|██████▍   | 20/31 [01:05<00:45,  4.17s/it, loss=1.6313, batch_acc=0.6250, running_acc=0.6953, grad=9.1790] Training epoch 37:  68%|██████▊   | 21/31 [01:14<00:56,  5.65s/it, loss=1.6313, batch_acc=0.6250, running_acc=0.6953, grad=9.1790]Training epoch 37:  68%|██████▊   | 21/31 [01:14<00:56,  5.65s/it, loss=1.2714, batch_acc=0.7812, running_acc=0.6994, grad=204.2786]Training epoch 37:  71%|███████   | 22/31 [01:16<00:39,  4.41s/it, loss=1.2714, batch_acc=0.7812, running_acc=0.6994, grad=204.2786]Training epoch 37:  71%|███████   | 22/31 [01:16<00:39,  4.41s/it, loss=1.3102, batch_acc=0.7188, running_acc=0.7003, grad=14.0142] Training epoch 37:  74%|███████▍  | 23/31 [01:17<00:28,  3.54s/it, loss=1.3102, batch_acc=0.7188, running_acc=0.7003, grad=14.0142]Training epoch 37:  74%|███████▍  | 23/31 [01:17<00:28,  3.54s/it, loss=1.2621, batch_acc=0.8438, running_acc=0.7065, grad=9.5873] Training epoch 37:  77%|███████▋  | 24/31 [01:19<00:20,  2.93s/it, loss=1.2621, batch_acc=0.8438, running_acc=0.7065, grad=9.5873]Training epoch 37:  77%|███████▋  | 24/31 [01:19<00:20,  2.93s/it, loss=1.3999, batch_acc=0.7188, running_acc=0.7070, grad=17.0892]Training epoch 37:  81%|████████  | 25/31 [01:20<00:15,  2.50s/it, loss=1.3999, batch_acc=0.7188, running_acc=0.7070, grad=17.0892]Training epoch 37:  81%|████████  | 25/31 [01:20<00:15,  2.50s/it, loss=1.5788, batch_acc=0.7500, running_acc=0.7087, grad=14.8715]Training epoch 37:  84%|████████▍ | 26/31 [01:22<00:11,  2.21s/it, loss=1.5788, batch_acc=0.7500, running_acc=0.7087, grad=14.8715]Training epoch 37:  84%|████████▍ | 26/31 [01:22<00:11,  2.21s/it, loss=1.3696, batch_acc=0.6875, running_acc=0.7079, grad=8.0674] Training epoch 37:  87%|████████▋ | 27/31 [01:23<00:07,  2.00s/it, loss=1.3696, batch_acc=0.6875, running_acc=0.7079, grad=8.0674]Training epoch 37:  87%|████████▋ | 27/31 [01:23<00:07,  2.00s/it, loss=1.3728, batch_acc=0.6875, running_acc=0.7072, grad=21.0475]Training epoch 37:  90%|█████████ | 28/31 [01:25<00:05,  1.89s/it, loss=1.3728, batch_acc=0.6875, running_acc=0.7072, grad=21.0475]Training epoch 37:  90%|█████████ | 28/31 [01:25<00:05,  1.89s/it, loss=1.6889, batch_acc=0.5625, running_acc=0.7020, grad=22.5861]Training epoch 37:  94%|█████████▎| 29/31 [01:26<00:03,  1.78s/it, loss=1.6889, batch_acc=0.5625, running_acc=0.7020, grad=22.5861]Training epoch 37:  94%|█████████▎| 29/31 [01:26<00:03,  1.78s/it, loss=1.6481, batch_acc=0.5938, running_acc=0.6983, grad=27.2181]Training epoch 37:  97%|█████████▋| 30/31 [01:28<00:01,  1.70s/it, loss=1.6481, batch_acc=0.5938, running_acc=0.6983, grad=27.2181]Training epoch 37:  97%|█████████▋| 30/31 [01:28<00:01,  1.70s/it, loss=1.5222, batch_acc=0.6562, running_acc=0.6969, grad=16.1142]Training epoch 37: 100%|██████████| 31/31 [01:28<00:00,  1.25s/it, loss=1.5222, batch_acc=0.6562, running_acc=0.6969, grad=16.1142]Training epoch 37: 100%|██████████| 31/31 [01:28<00:00,  1.25s/it, loss=0.6974, batch_acc=1.0000, running_acc=0.6975, grad=5.7037] Training epoch 37: 100%|██████████| 31/31 [01:28<00:00,  2.86s/it, loss=0.6974, batch_acc=1.0000, running_acc=0.6975, grad=5.7037]
Evaluation epoch 37:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 37:  20%|██        | 1/5 [00:11<00:46, 11.68s/it]Evaluation epoch 37:  20%|██        | 1/5 [00:11<00:46, 11.68s/it, loss=1.4040, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 37:  40%|████      | 2/5 [00:12<00:15,  5.25s/it, loss=1.4040, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 37:  40%|████      | 2/5 [00:12<00:15,  5.25s/it, loss=1.3112, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 37:  60%|██████    | 3/5 [00:13<00:06,  3.19s/it, loss=1.3112, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 37:  60%|██████    | 3/5 [00:13<00:06,  3.19s/it, loss=1.6231, batch_acc=0.6250, running_acc=0.7083]Evaluation epoch 37:  80%|████████  | 4/5 [00:13<00:02,  2.23s/it, loss=1.6231, batch_acc=0.6250, running_acc=0.7083]Evaluation epoch 37:  80%|████████  | 4/5 [00:13<00:02,  2.23s/it, loss=1.7623, batch_acc=0.5625, running_acc=0.6719]Evaluation epoch 37: 100%|██████████| 5/5 [00:14<00:00,  1.71s/it, loss=1.7623, batch_acc=0.5625, running_acc=0.6719]Evaluation epoch 37: 100%|██████████| 5/5 [00:14<00:00,  1.71s/it, loss=1.9063, batch_acc=0.5938, running_acc=0.6562]Evaluation epoch 37: 100%|██████████| 5/5 [00:14<00:00,  2.94s/it, loss=1.9063, batch_acc=0.5938, running_acc=0.6562]
Training epoch 38:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 38:   3%|▎         | 1/31 [00:07<03:45,  7.53s/it]Training epoch 38:   3%|▎         | 1/31 [00:07<03:45,  7.53s/it, loss=1.6638, batch_acc=0.5312, running_acc=0.5312, grad=8.0256]Training epoch 38:   6%|▋         | 2/31 [00:09<01:55,  3.99s/it, loss=1.6638, batch_acc=0.5312, running_acc=0.5312, grad=8.0256]Training epoch 38:   6%|▋         | 2/31 [00:09<01:55,  3.99s/it, loss=1.3971, batch_acc=0.6562, running_acc=0.5938, grad=24.8072]Training epoch 38:  10%|▉         | 3/31 [00:10<01:19,  2.86s/it, loss=1.3971, batch_acc=0.6562, running_acc=0.5938, grad=24.8072]Training epoch 38:  10%|▉         | 3/31 [00:10<01:19,  2.86s/it, loss=1.4123, batch_acc=0.6875, running_acc=0.6250, grad=19.1762]Training epoch 38:  13%|█▎        | 4/31 [00:12<01:03,  2.35s/it, loss=1.4123, batch_acc=0.6875, running_acc=0.6250, grad=19.1762]Training epoch 38:  13%|█▎        | 4/31 [00:12<01:03,  2.35s/it, loss=1.1999, batch_acc=0.7812, running_acc=0.6641, grad=11.1359]Training epoch 38:  16%|█▌        | 5/31 [00:13<00:53,  2.04s/it, loss=1.1999, batch_acc=0.7812, running_acc=0.6641, grad=11.1359]Training epoch 38:  16%|█▌        | 5/31 [00:13<00:53,  2.04s/it, loss=1.4925, batch_acc=0.6562, running_acc=0.6625, grad=15.5705]Training epoch 38:  19%|█▉        | 6/31 [00:15<00:46,  1.86s/it, loss=1.4925, batch_acc=0.6562, running_acc=0.6625, grad=15.5705]Training epoch 38:  19%|█▉        | 6/31 [00:15<00:46,  1.86s/it, loss=1.3097, batch_acc=0.7188, running_acc=0.6719, grad=7.0533] Training epoch 38:  23%|██▎       | 7/31 [00:16<00:41,  1.75s/it, loss=1.3097, batch_acc=0.7188, running_acc=0.6719, grad=7.0533]Training epoch 38:  23%|██▎       | 7/31 [00:16<00:41,  1.75s/it, loss=1.6564, batch_acc=0.5938, running_acc=0.6607, grad=15.9307]Training epoch 38:  26%|██▌       | 8/31 [00:19<00:48,  2.10s/it, loss=1.6564, batch_acc=0.5938, running_acc=0.6607, grad=15.9307]Training epoch 38:  26%|██▌       | 8/31 [00:19<00:48,  2.10s/it, loss=1.2896, batch_acc=0.7500, running_acc=0.6719, grad=6.3176] Training epoch 38:  29%|██▉       | 9/31 [00:21<00:42,  1.92s/it, loss=1.2896, batch_acc=0.7500, running_acc=0.6719, grad=6.3176]Training epoch 38:  29%|██▉       | 9/31 [00:21<00:42,  1.92s/it, loss=1.4195, batch_acc=0.8125, running_acc=0.6875, grad=9.6365]Training epoch 38:  32%|███▏      | 10/31 [00:22<00:37,  1.79s/it, loss=1.4195, batch_acc=0.8125, running_acc=0.6875, grad=9.6365]Training epoch 38:  32%|███▏      | 10/31 [00:22<00:37,  1.79s/it, loss=1.1531, batch_acc=0.8125, running_acc=0.7000, grad=14.4727]Training epoch 38:  35%|███▌      | 11/31 [00:24<00:34,  1.71s/it, loss=1.1531, batch_acc=0.8125, running_acc=0.7000, grad=14.4727]Training epoch 38:  35%|███▌      | 11/31 [00:24<00:34,  1.71s/it, loss=1.5016, batch_acc=0.6250, running_acc=0.6932, grad=21.2631]Training epoch 38:  39%|███▊      | 12/31 [00:26<00:35,  1.87s/it, loss=1.5016, batch_acc=0.6250, running_acc=0.6932, grad=21.2631]Training epoch 38:  39%|███▊      | 12/31 [00:26<00:35,  1.87s/it, loss=1.5707, batch_acc=0.7188, running_acc=0.6953, grad=10.8969]Training epoch 38:  42%|████▏     | 13/31 [00:27<00:31,  1.76s/it, loss=1.5707, batch_acc=0.7188, running_acc=0.6953, grad=10.8969]Training epoch 38:  42%|████▏     | 13/31 [00:27<00:31,  1.76s/it, loss=1.4150, batch_acc=0.7188, running_acc=0.6971, grad=10.0246]Training epoch 38:  45%|████▌     | 14/31 [00:29<00:28,  1.69s/it, loss=1.4150, batch_acc=0.7188, running_acc=0.6971, grad=10.0246]Training epoch 38:  45%|████▌     | 14/31 [00:29<00:28,  1.69s/it, loss=1.4870, batch_acc=0.6562, running_acc=0.6942, grad=7.1484] Training epoch 38:  48%|████▊     | 15/31 [00:30<00:26,  1.63s/it, loss=1.4870, batch_acc=0.6562, running_acc=0.6942, grad=7.1484]Training epoch 38:  48%|████▊     | 15/31 [00:30<00:26,  1.63s/it, loss=1.3245, batch_acc=0.6562, running_acc=0.6917, grad=8.3475]Training epoch 38:  52%|█████▏    | 16/31 [00:39<00:56,  3.74s/it, loss=1.3245, batch_acc=0.6562, running_acc=0.6917, grad=8.3475]Training epoch 38:  52%|█████▏    | 16/31 [00:39<00:56,  3.74s/it, loss=1.5567, batch_acc=0.6562, running_acc=0.6895, grad=14.7207]Training epoch 38:  55%|█████▍    | 17/31 [00:40<00:42,  3.07s/it, loss=1.5567, batch_acc=0.6562, running_acc=0.6895, grad=14.7207]Training epoch 38:  55%|█████▍    | 17/31 [00:40<00:42,  3.07s/it, loss=1.3764, batch_acc=0.8125, running_acc=0.6967, grad=25.4342]Training epoch 38:  58%|█████▊    | 18/31 [00:42<00:33,  2.60s/it, loss=1.3764, batch_acc=0.8125, running_acc=0.6967, grad=25.4342]Training epoch 38:  58%|█████▊    | 18/31 [00:42<00:33,  2.60s/it, loss=1.6023, batch_acc=0.6250, running_acc=0.6927, grad=13.2260]Training epoch 38:  61%|██████▏   | 19/31 [00:43<00:27,  2.27s/it, loss=1.6023, batch_acc=0.6250, running_acc=0.6927, grad=13.2260]Training epoch 38:  61%|██████▏   | 19/31 [00:43<00:27,  2.27s/it, loss=1.2959, batch_acc=0.7812, running_acc=0.6974, grad=13.0358]Training epoch 38:  65%|██████▍   | 20/31 [00:52<00:44,  4.06s/it, loss=1.2959, batch_acc=0.7812, running_acc=0.6974, grad=13.0358]Training epoch 38:  65%|██████▍   | 20/31 [00:52<00:44,  4.06s/it, loss=1.7017, batch_acc=0.6562, running_acc=0.6953, grad=8.2062] Training epoch 38:  68%|██████▊   | 21/31 [00:54<00:35,  3.55s/it, loss=1.7017, batch_acc=0.6562, running_acc=0.6953, grad=8.2062]Training epoch 38:  68%|██████▊   | 21/31 [00:54<00:35,  3.55s/it, loss=1.6667, batch_acc=0.6250, running_acc=0.6920, grad=16.9304]Training epoch 38:  71%|███████   | 22/31 [00:56<00:26,  2.93s/it, loss=1.6667, batch_acc=0.6250, running_acc=0.6920, grad=16.9304]Training epoch 38:  71%|███████   | 22/31 [00:56<00:26,  2.93s/it, loss=1.5471, batch_acc=0.7188, running_acc=0.6932, grad=7.7017] Training epoch 38:  74%|███████▍  | 23/31 [00:57<00:20,  2.51s/it, loss=1.5471, batch_acc=0.7188, running_acc=0.6932, grad=7.7017]Training epoch 38:  74%|███████▍  | 23/31 [00:57<00:20,  2.51s/it, loss=1.4553, batch_acc=0.6562, running_acc=0.6916, grad=7.9060]Training epoch 38:  77%|███████▋  | 24/31 [01:02<00:22,  3.20s/it, loss=1.4553, batch_acc=0.6562, running_acc=0.6916, grad=7.9060]Training epoch 38:  77%|███████▋  | 24/31 [01:02<00:22,  3.20s/it, loss=1.7305, batch_acc=0.5938, running_acc=0.6875, grad=10.2282]Training epoch 38:  81%|████████  | 25/31 [01:06<00:20,  3.43s/it, loss=1.7305, batch_acc=0.5938, running_acc=0.6875, grad=10.2282]Training epoch 38:  81%|████████  | 25/31 [01:06<00:20,  3.43s/it, loss=1.2342, batch_acc=0.8125, running_acc=0.6925, grad=10.2402]Training epoch 38:  84%|████████▍ | 26/31 [01:07<00:14,  2.85s/it, loss=1.2342, batch_acc=0.8125, running_acc=0.6925, grad=10.2402]Training epoch 38:  84%|████████▍ | 26/31 [01:07<00:14,  2.85s/it, loss=1.5393, batch_acc=0.7188, running_acc=0.6935, grad=34.4164]Training epoch 38:  87%|████████▋ | 27/31 [01:09<00:09,  2.46s/it, loss=1.5393, batch_acc=0.7188, running_acc=0.6935, grad=34.4164]Training epoch 38:  87%|████████▋ | 27/31 [01:09<00:09,  2.46s/it, loss=1.4607, batch_acc=0.7812, running_acc=0.6968, grad=15.8090]Training epoch 38:  90%|█████████ | 28/31 [01:10<00:06,  2.17s/it, loss=1.4607, batch_acc=0.7812, running_acc=0.6968, grad=15.8090]Training epoch 38:  90%|█████████ | 28/31 [01:10<00:06,  2.17s/it, loss=1.4641, batch_acc=0.7500, running_acc=0.6987, grad=21.7286]Training epoch 38:  94%|█████████▎| 29/31 [01:12<00:03,  1.97s/it, loss=1.4641, batch_acc=0.7500, running_acc=0.6987, grad=21.7286]Training epoch 38:  94%|█████████▎| 29/31 [01:12<00:03,  1.97s/it, loss=1.4228, batch_acc=0.7188, running_acc=0.6994, grad=10.2107]Training epoch 38:  97%|█████████▋| 30/31 [01:13<00:01,  1.83s/it, loss=1.4228, batch_acc=0.7188, running_acc=0.6994, grad=10.2107]Training epoch 38:  97%|█████████▋| 30/31 [01:13<00:01,  1.83s/it, loss=1.5908, batch_acc=0.6875, running_acc=0.6990, grad=15.4017]Training epoch 38: 100%|██████████| 31/31 [01:14<00:00,  1.35s/it, loss=1.5908, batch_acc=0.6875, running_acc=0.6990, grad=15.4017]Training epoch 38: 100%|██████████| 31/31 [01:14<00:00,  1.35s/it, loss=0.6130, batch_acc=1.0000, running_acc=0.6996, grad=11.7142]Training epoch 38: 100%|██████████| 31/31 [01:14<00:00,  2.39s/it, loss=0.6130, batch_acc=1.0000, running_acc=0.6996, grad=11.7142]
Evaluation epoch 38:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 38:  20%|██        | 1/5 [00:15<01:03, 15.84s/it]Evaluation epoch 38:  20%|██        | 1/5 [00:15<01:03, 15.84s/it, loss=1.4805, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 38:  40%|████      | 2/5 [00:16<00:20,  6.96s/it, loss=1.4805, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 38:  40%|████      | 2/5 [00:16<00:20,  6.96s/it, loss=1.3275, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 38:  60%|██████    | 3/5 [00:17<00:08,  4.13s/it, loss=1.3275, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 38:  60%|██████    | 3/5 [00:17<00:08,  4.13s/it, loss=1.6220, batch_acc=0.5938, running_acc=0.6771]Evaluation epoch 38:  80%|████████  | 4/5 [00:18<00:03,  3.02s/it, loss=1.6220, batch_acc=0.5938, running_acc=0.6771]Evaluation epoch 38:  80%|████████  | 4/5 [00:18<00:03,  3.02s/it, loss=1.6897, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 38: 100%|██████████| 5/5 [00:19<00:00,  2.21s/it, loss=1.6897, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 38: 100%|██████████| 5/5 [00:19<00:00,  2.21s/it, loss=1.8840, batch_acc=0.5938, running_acc=0.6500]Evaluation epoch 38: 100%|██████████| 5/5 [00:19<00:00,  3.89s/it, loss=1.8840, batch_acc=0.5938, running_acc=0.6500]
Training epoch 39:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 39:   3%|▎         | 1/31 [00:08<04:08,  8.29s/it]Training epoch 39:   3%|▎         | 1/31 [00:08<04:08,  8.29s/it, loss=1.3869, batch_acc=0.6562, running_acc=0.6562, grad=21.5318]Training epoch 39:   6%|▋         | 2/31 [00:09<02:04,  4.30s/it, loss=1.3869, batch_acc=0.6562, running_acc=0.6562, grad=21.5318]Training epoch 39:   6%|▋         | 2/31 [00:09<02:04,  4.30s/it, loss=1.2832, batch_acc=0.8750, running_acc=0.7656, grad=8.9450] Training epoch 39:  10%|▉         | 3/31 [00:15<02:21,  5.06s/it, loss=1.2832, batch_acc=0.8750, running_acc=0.7656, grad=8.9450]Training epoch 39:  10%|▉         | 3/31 [00:15<02:21,  5.06s/it, loss=1.5575, batch_acc=0.6875, running_acc=0.7396, grad=12.3101]Training epoch 39:  13%|█▎        | 4/31 [00:17<01:38,  3.66s/it, loss=1.5575, batch_acc=0.6875, running_acc=0.7396, grad=12.3101]Training epoch 39:  13%|█▎        | 4/31 [00:17<01:38,  3.66s/it, loss=1.5606, batch_acc=0.6562, running_acc=0.7188, grad=10.6456]Training epoch 39:  16%|█▌        | 5/31 [00:18<01:14,  2.88s/it, loss=1.5606, batch_acc=0.6562, running_acc=0.7188, grad=10.6456]Training epoch 39:  16%|█▌        | 5/31 [00:18<01:14,  2.88s/it, loss=1.5679, batch_acc=0.7500, running_acc=0.7250, grad=10.8706]Training epoch 39:  19%|█▉        | 6/31 [00:20<01:00,  2.42s/it, loss=1.5679, batch_acc=0.7500, running_acc=0.7250, grad=10.8706]Training epoch 39:  19%|█▉        | 6/31 [00:20<01:00,  2.42s/it, loss=1.4390, batch_acc=0.7188, running_acc=0.7240, grad=71.1451]Training epoch 39:  23%|██▎       | 7/31 [00:21<00:50,  2.12s/it, loss=1.4390, batch_acc=0.7188, running_acc=0.7240, grad=71.1451]Training epoch 39:  23%|██▎       | 7/31 [00:21<00:50,  2.12s/it, loss=1.5384, batch_acc=0.6875, running_acc=0.7188, grad=12.5285]Training epoch 39:  26%|██▌       | 8/31 [00:23<00:44,  1.93s/it, loss=1.5384, batch_acc=0.6875, running_acc=0.7188, grad=12.5285]Training epoch 39:  26%|██▌       | 8/31 [00:23<00:44,  1.93s/it, loss=1.7002, batch_acc=0.5000, running_acc=0.6914, grad=12.6987]Training epoch 39:  29%|██▉       | 9/31 [00:24<00:39,  1.80s/it, loss=1.7002, batch_acc=0.5000, running_acc=0.6914, grad=12.6987]Training epoch 39:  29%|██▉       | 9/31 [00:24<00:39,  1.80s/it, loss=1.6865, batch_acc=0.5312, running_acc=0.6736, grad=13.7154]Training epoch 39:  32%|███▏      | 10/31 [00:26<00:35,  1.71s/it, loss=1.6865, batch_acc=0.5312, running_acc=0.6736, grad=13.7154]Training epoch 39:  32%|███▏      | 10/31 [00:26<00:35,  1.71s/it, loss=1.3992, batch_acc=0.7812, running_acc=0.6844, grad=22.0753]Training epoch 39:  35%|███▌      | 11/31 [00:27<00:33,  1.68s/it, loss=1.3992, batch_acc=0.7812, running_acc=0.6844, grad=22.0753]Training epoch 39:  35%|███▌      | 11/31 [00:27<00:33,  1.68s/it, loss=1.2389, batch_acc=0.7188, running_acc=0.6875, grad=7.6528] Training epoch 39:  39%|███▊      | 12/31 [00:29<00:30,  1.63s/it, loss=1.2389, batch_acc=0.7188, running_acc=0.6875, grad=7.6528]Training epoch 39:  39%|███▊      | 12/31 [00:29<00:30,  1.63s/it, loss=1.7750, batch_acc=0.6562, running_acc=0.6849, grad=17.3960]Training epoch 39:  42%|████▏     | 13/31 [00:30<00:28,  1.59s/it, loss=1.7750, batch_acc=0.6562, running_acc=0.6849, grad=17.3960]Training epoch 39:  42%|████▏     | 13/31 [00:30<00:28,  1.59s/it, loss=1.3629, batch_acc=0.7188, running_acc=0.6875, grad=6.3198] Training epoch 39:  45%|████▌     | 14/31 [00:32<00:26,  1.57s/it, loss=1.3629, batch_acc=0.7188, running_acc=0.6875, grad=6.3198]Training epoch 39:  45%|████▌     | 14/31 [00:32<00:26,  1.57s/it, loss=1.2404, batch_acc=0.7812, running_acc=0.6942, grad=12.3811]Training epoch 39:  48%|████▊     | 15/31 [00:36<00:35,  2.22s/it, loss=1.2404, batch_acc=0.7812, running_acc=0.6942, grad=12.3811]Training epoch 39:  48%|████▊     | 15/31 [00:36<00:35,  2.22s/it, loss=1.3300, batch_acc=0.7500, running_acc=0.6979, grad=13.5923]Training epoch 39:  52%|█████▏    | 16/31 [00:38<00:33,  2.23s/it, loss=1.3300, batch_acc=0.7500, running_acc=0.6979, grad=13.5923]Training epoch 39:  52%|█████▏    | 16/31 [00:38<00:33,  2.23s/it, loss=1.4696, batch_acc=0.7188, running_acc=0.6992, grad=6.3848] Training epoch 39:  55%|█████▍    | 17/31 [00:39<00:28,  2.01s/it, loss=1.4696, batch_acc=0.7188, running_acc=0.6992, grad=6.3848]Training epoch 39:  55%|█████▍    | 17/31 [00:39<00:28,  2.01s/it, loss=1.2485, batch_acc=0.7500, running_acc=0.7022, grad=14.6641]Training epoch 39:  58%|█████▊    | 18/31 [00:41<00:24,  1.86s/it, loss=1.2485, batch_acc=0.7500, running_acc=0.7022, grad=14.6641]Training epoch 39:  58%|█████▊    | 18/31 [00:41<00:24,  1.86s/it, loss=1.2517, batch_acc=0.8125, running_acc=0.7083, grad=7.3208] Training epoch 39:  61%|██████▏   | 19/31 [00:42<00:21,  1.76s/it, loss=1.2517, batch_acc=0.8125, running_acc=0.7083, grad=7.3208]Training epoch 39:  61%|██████▏   | 19/31 [00:43<00:21,  1.76s/it, loss=1.3584, batch_acc=0.7500, running_acc=0.7105, grad=13.0790]Training epoch 39:  65%|██████▍   | 20/31 [00:51<00:42,  3.84s/it, loss=1.3584, batch_acc=0.7500, running_acc=0.7105, grad=13.0790]Training epoch 39:  65%|██████▍   | 20/31 [00:51<00:42,  3.84s/it, loss=1.3333, batch_acc=0.7188, running_acc=0.7109, grad=7.3393] Training epoch 39:  68%|██████▊   | 21/31 [00:53<00:31,  3.14s/it, loss=1.3333, batch_acc=0.7188, running_acc=0.7109, grad=7.3393]Training epoch 39:  68%|██████▊   | 21/31 [00:53<00:31,  3.14s/it, loss=1.3003, batch_acc=0.7500, running_acc=0.7128, grad=15.3145]Training epoch 39:  71%|███████   | 22/31 [00:54<00:23,  2.65s/it, loss=1.3003, batch_acc=0.7500, running_acc=0.7128, grad=15.3145]Training epoch 39:  71%|███████   | 22/31 [00:54<00:23,  2.65s/it, loss=1.4746, batch_acc=0.7188, running_acc=0.7131, grad=28.8752]Training epoch 39:  74%|███████▍  | 23/31 [01:01<00:30,  3.82s/it, loss=1.4746, batch_acc=0.7188, running_acc=0.7131, grad=28.8752]Training epoch 39:  74%|███████▍  | 23/31 [01:01<00:30,  3.82s/it, loss=1.9111, batch_acc=0.5625, running_acc=0.7065, grad=42.2427]Training epoch 39:  77%|███████▋  | 24/31 [01:02<00:21,  3.13s/it, loss=1.9111, batch_acc=0.5625, running_acc=0.7065, grad=42.2427]Training epoch 39:  77%|███████▋  | 24/31 [01:02<00:21,  3.13s/it, loss=1.6137, batch_acc=0.6250, running_acc=0.7031, grad=32.4975]Training epoch 39:  81%|████████  | 25/31 [01:04<00:15,  2.64s/it, loss=1.6137, batch_acc=0.6250, running_acc=0.7031, grad=32.4975]Training epoch 39:  81%|████████  | 25/31 [01:04<00:15,  2.64s/it, loss=1.6294, batch_acc=0.6875, running_acc=0.7025, grad=14.6100]Training epoch 39:  84%|████████▍ | 26/31 [01:05<00:11,  2.30s/it, loss=1.6294, batch_acc=0.6875, running_acc=0.7025, grad=14.6100]Training epoch 39:  84%|████████▍ | 26/31 [01:05<00:11,  2.30s/it, loss=1.3711, batch_acc=0.6562, running_acc=0.7007, grad=8.8132] Training epoch 39:  87%|████████▋ | 27/31 [01:11<00:12,  3.20s/it, loss=1.3711, batch_acc=0.6562, running_acc=0.7007, grad=8.8132]Training epoch 39:  87%|████████▋ | 27/31 [01:11<00:12,  3.20s/it, loss=1.5055, batch_acc=0.7188, running_acc=0.7014, grad=17.1388]Training epoch 39:  90%|█████████ | 28/31 [01:12<00:08,  2.69s/it, loss=1.5055, batch_acc=0.7188, running_acc=0.7014, grad=17.1388]Training epoch 39:  90%|█████████ | 28/31 [01:12<00:08,  2.69s/it, loss=1.4577, batch_acc=0.5938, running_acc=0.6975, grad=123.3780]Training epoch 39:  94%|█████████▎| 29/31 [01:14<00:04,  2.33s/it, loss=1.4577, batch_acc=0.5938, running_acc=0.6975, grad=123.3780]Training epoch 39:  94%|█████████▎| 29/31 [01:14<00:04,  2.33s/it, loss=1.3787, batch_acc=0.7500, running_acc=0.6994, grad=8.8673]  Training epoch 39:  97%|█████████▋| 30/31 [01:15<00:02,  2.09s/it, loss=1.3787, batch_acc=0.7500, running_acc=0.6994, grad=8.8673]Training epoch 39:  97%|█████████▋| 30/31 [01:15<00:02,  2.09s/it, loss=1.3131, batch_acc=0.7500, running_acc=0.7010, grad=20.7260]Training epoch 39: 100%|██████████| 31/31 [01:15<00:00,  1.52s/it, loss=1.3131, batch_acc=0.7500, running_acc=0.7010, grad=20.7260]Training epoch 39: 100%|██████████| 31/31 [01:15<00:00,  1.52s/it, loss=1.0528, batch_acc=1.0000, running_acc=0.7017, grad=62.0493]Training epoch 39: 100%|██████████| 31/31 [01:15<00:00,  2.44s/it, loss=1.0528, batch_acc=1.0000, running_acc=0.7017, grad=62.0493]
Evaluation epoch 39:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 39:  20%|██        | 1/5 [00:11<00:46, 11.57s/it]Evaluation epoch 39:  20%|██        | 1/5 [00:11<00:46, 11.57s/it, loss=1.5118, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 39:  40%|████      | 2/5 [00:12<00:15,  5.20s/it, loss=1.5118, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 39:  40%|████      | 2/5 [00:12<00:15,  5.20s/it, loss=1.2847, batch_acc=0.7500, running_acc=0.6562]Evaluation epoch 39:  60%|██████    | 3/5 [00:13<00:06,  3.17s/it, loss=1.2847, batch_acc=0.7500, running_acc=0.6562]Evaluation epoch 39:  60%|██████    | 3/5 [00:13<00:06,  3.17s/it, loss=1.5745, batch_acc=0.5312, running_acc=0.6146]Evaluation epoch 39:  80%|████████  | 4/5 [00:31<00:09,  9.24s/it, loss=1.5745, batch_acc=0.5312, running_acc=0.6146]Evaluation epoch 39:  80%|████████  | 4/5 [00:31<00:09,  9.24s/it, loss=1.7428, batch_acc=0.5625, running_acc=0.6016]Evaluation epoch 39: 100%|██████████| 5/5 [00:32<00:00,  6.19s/it, loss=1.7428, batch_acc=0.5625, running_acc=0.6016]Evaluation epoch 39: 100%|██████████| 5/5 [00:32<00:00,  6.19s/it, loss=1.9173, batch_acc=0.5312, running_acc=0.5875]Evaluation epoch 39: 100%|██████████| 5/5 [00:32<00:00,  6.48s/it, loss=1.9173, batch_acc=0.5312, running_acc=0.5875]
Training epoch 40:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 40:   3%|▎         | 1/31 [00:05<02:58,  5.94s/it]Training epoch 40:   3%|▎         | 1/31 [00:05<02:58,  5.94s/it, loss=1.5417, batch_acc=0.6562, running_acc=0.6562, grad=17.3558]Training epoch 40:   6%|▋         | 2/31 [00:07<01:36,  3.33s/it, loss=1.5417, batch_acc=0.6562, running_acc=0.6562, grad=17.3558]Training epoch 40:   6%|▋         | 2/31 [00:07<01:36,  3.33s/it, loss=1.7918, batch_acc=0.5938, running_acc=0.6250, grad=14.2822]Training epoch 40:  10%|▉         | 3/31 [00:08<01:09,  2.50s/it, loss=1.7918, batch_acc=0.5938, running_acc=0.6250, grad=14.2822]Training epoch 40:  10%|▉         | 3/31 [00:08<01:09,  2.50s/it, loss=1.5686, batch_acc=0.6562, running_acc=0.6354, grad=22.4506]Training epoch 40:  13%|█▎        | 4/31 [00:10<00:56,  2.11s/it, loss=1.5686, batch_acc=0.6562, running_acc=0.6354, grad=22.4506]Training epoch 40:  13%|█▎        | 4/31 [00:10<00:56,  2.11s/it, loss=1.4588, batch_acc=0.6875, running_acc=0.6484, grad=22.4022]Training epoch 40:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=1.4588, batch_acc=0.6875, running_acc=0.6484, grad=22.4022]Training epoch 40:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=1.5123, batch_acc=0.5938, running_acc=0.6375, grad=48.6418]Training epoch 40:  19%|█▉        | 6/31 [00:13<00:44,  1.76s/it, loss=1.5123, batch_acc=0.5938, running_acc=0.6375, grad=48.6418]Training epoch 40:  19%|█▉        | 6/31 [00:13<00:44,  1.76s/it, loss=1.7040, batch_acc=0.5625, running_acc=0.6250, grad=18.5743]Training epoch 40:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.7040, batch_acc=0.5625, running_acc=0.6250, grad=18.5743]Training epoch 40:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.3285, batch_acc=0.7500, running_acc=0.6429, grad=15.6575]Training epoch 40:  26%|██▌       | 8/31 [00:16<00:37,  1.63s/it, loss=1.3285, batch_acc=0.7500, running_acc=0.6429, grad=15.6575]Training epoch 40:  26%|██▌       | 8/31 [00:16<00:37,  1.63s/it, loss=1.5636, batch_acc=0.6250, running_acc=0.6406, grad=11.0385]Training epoch 40:  29%|██▉       | 9/31 [00:18<00:35,  1.59s/it, loss=1.5636, batch_acc=0.6250, running_acc=0.6406, grad=11.0385]Training epoch 40:  29%|██▉       | 9/31 [00:18<00:35,  1.59s/it, loss=1.1064, batch_acc=0.9062, running_acc=0.6701, grad=94.0684]Training epoch 40:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.1064, batch_acc=0.9062, running_acc=0.6701, grad=94.0684]Training epoch 40:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.3955, batch_acc=0.7500, running_acc=0.6781, grad=21.4100]Training epoch 40:  35%|███▌      | 11/31 [00:21<00:31,  1.55s/it, loss=1.3955, batch_acc=0.7500, running_acc=0.6781, grad=21.4100]Training epoch 40:  35%|███▌      | 11/31 [00:21<00:31,  1.55s/it, loss=1.2974, batch_acc=0.7500, running_acc=0.6847, grad=6.7693] Training epoch 40:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.2974, batch_acc=0.7500, running_acc=0.6847, grad=6.7693]Training epoch 40:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.7231, batch_acc=0.5938, running_acc=0.6771, grad=17.1117]Training epoch 40:  42%|████▏     | 13/31 [00:24<00:27,  1.53s/it, loss=1.7231, batch_acc=0.5938, running_acc=0.6771, grad=17.1117]Training epoch 40:  42%|████▏     | 13/31 [00:24<00:27,  1.53s/it, loss=1.5706, batch_acc=0.6250, running_acc=0.6731, grad=10.0843]Training epoch 40:  45%|████▌     | 14/31 [00:25<00:25,  1.53s/it, loss=1.5706, batch_acc=0.6250, running_acc=0.6731, grad=10.0843]Training epoch 40:  45%|████▌     | 14/31 [00:25<00:25,  1.53s/it, loss=1.3665, batch_acc=0.6562, running_acc=0.6719, grad=7.5815] Training epoch 40:  48%|████▊     | 15/31 [00:27<00:24,  1.52s/it, loss=1.3665, batch_acc=0.6562, running_acc=0.6719, grad=7.5815]Training epoch 40:  48%|████▊     | 15/31 [00:27<00:24,  1.52s/it, loss=1.3379, batch_acc=0.7188, running_acc=0.6750, grad=18.0155]Training epoch 40:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.3379, batch_acc=0.7188, running_acc=0.6750, grad=18.0155]Training epoch 40:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.4795, batch_acc=0.7188, running_acc=0.6777, grad=41.1749]Training epoch 40:  55%|█████▍    | 17/31 [00:30<00:21,  1.52s/it, loss=1.4795, batch_acc=0.7188, running_acc=0.6777, grad=41.1749]Training epoch 40:  55%|█████▍    | 17/31 [00:30<00:21,  1.52s/it, loss=1.1829, batch_acc=0.8125, running_acc=0.6857, grad=11.2113]Training epoch 40:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=1.1829, batch_acc=0.8125, running_acc=0.6857, grad=11.2113]Training epoch 40:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=1.4667, batch_acc=0.6562, running_acc=0.6840, grad=11.6436]Training epoch 40:  61%|██████▏   | 19/31 [00:33<00:18,  1.51s/it, loss=1.4667, batch_acc=0.6562, running_acc=0.6840, grad=11.6436]Training epoch 40:  61%|██████▏   | 19/31 [00:33<00:18,  1.51s/it, loss=1.3881, batch_acc=0.6875, running_acc=0.6842, grad=11.0541]Training epoch 40:  65%|██████▍   | 20/31 [00:34<00:16,  1.52s/it, loss=1.3881, batch_acc=0.6875, running_acc=0.6842, grad=11.0541]Training epoch 40:  65%|██████▍   | 20/31 [00:34<00:16,  1.52s/it, loss=1.4299, batch_acc=0.7812, running_acc=0.6891, grad=7.5383] Training epoch 40:  68%|██████▊   | 21/31 [00:36<00:15,  1.51s/it, loss=1.4299, batch_acc=0.7812, running_acc=0.6891, grad=7.5383]Training epoch 40:  68%|██████▊   | 21/31 [00:36<00:15,  1.51s/it, loss=1.4251, batch_acc=0.6875, running_acc=0.6890, grad=7.7531]Training epoch 40:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.4251, batch_acc=0.6875, running_acc=0.6890, grad=7.7531]Training epoch 40:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.2222, batch_acc=0.8125, running_acc=0.6946, grad=10.1612]Training epoch 40:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.2222, batch_acc=0.8125, running_acc=0.6946, grad=10.1612]Training epoch 40:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.5733, batch_acc=0.5312, running_acc=0.6875, grad=6.3391] Training epoch 40:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.5733, batch_acc=0.5312, running_acc=0.6875, grad=6.3391]Training epoch 40:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.4191, batch_acc=0.6875, running_acc=0.6875, grad=15.4091]Training epoch 40:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=1.4191, batch_acc=0.6875, running_acc=0.6875, grad=15.4091]Training epoch 40:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=1.5589, batch_acc=0.6562, running_acc=0.6863, grad=11.6879]Training epoch 40:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.5589, batch_acc=0.6562, running_acc=0.6863, grad=11.6879]Training epoch 40:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.5268, batch_acc=0.6875, running_acc=0.6863, grad=16.8181]Training epoch 40:  87%|████████▋ | 27/31 [00:45<00:06,  1.51s/it, loss=1.5268, batch_acc=0.6875, running_acc=0.6863, grad=16.8181]Training epoch 40:  87%|████████▋ | 27/31 [00:45<00:06,  1.51s/it, loss=1.3154, batch_acc=0.7500, running_acc=0.6887, grad=45.9536]Training epoch 40:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=1.3154, batch_acc=0.7500, running_acc=0.6887, grad=45.9536]Training epoch 40:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=1.4095, batch_acc=0.6875, running_acc=0.6886, grad=13.1601]Training epoch 40:  94%|█████████▎| 29/31 [00:48<00:03,  1.51s/it, loss=1.4095, batch_acc=0.6875, running_acc=0.6886, grad=13.1601]Training epoch 40:  94%|█████████▎| 29/31 [00:48<00:03,  1.51s/it, loss=1.9909, batch_acc=0.4062, running_acc=0.6789, grad=12.6471]Training epoch 40:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.9909, batch_acc=0.4062, running_acc=0.6789, grad=12.6471]Training epoch 40:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.2992, batch_acc=0.7188, running_acc=0.6802, grad=8.3180] Training epoch 40: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.2992, batch_acc=0.7188, running_acc=0.6802, grad=8.3180]Training epoch 40: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.1799, batch_acc=1.0000, running_acc=0.6809, grad=18.9275]Training epoch 40: 100%|██████████| 31/31 [00:49<00:00,  1.61s/it, loss=1.1799, batch_acc=1.0000, running_acc=0.6809, grad=18.9275]
Evaluation epoch 40:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 40:  20%|██        | 1/5 [00:04<00:19,  4.80s/it]Evaluation epoch 40:  20%|██        | 1/5 [00:04<00:19,  4.80s/it, loss=1.4500, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 40:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.4500, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 40:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.2988, batch_acc=0.7500, running_acc=0.6875]Evaluation epoch 40:  60%|██████    | 3/5 [00:06<00:03,  1.65s/it, loss=1.2988, batch_acc=0.7500, running_acc=0.6875]Evaluation epoch 40:  60%|██████    | 3/5 [00:06<00:03,  1.65s/it, loss=1.6147, batch_acc=0.5000, running_acc=0.6250]Evaluation epoch 40:  80%|████████  | 4/5 [00:07<00:01,  1.60s/it, loss=1.6147, batch_acc=0.5000, running_acc=0.6250]Evaluation epoch 40:  80%|████████  | 4/5 [00:07<00:01,  1.60s/it, loss=1.7341, batch_acc=0.5625, running_acc=0.6094]Evaluation epoch 40: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=1.7341, batch_acc=0.5625, running_acc=0.6094]Evaluation epoch 40: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=1.8889, batch_acc=0.5625, running_acc=0.6000]Evaluation epoch 40: 100%|██████████| 5/5 [00:08<00:00,  1.72s/it, loss=1.8889, batch_acc=0.5625, running_acc=0.6000]
Training epoch 41:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 41:   3%|▎         | 1/31 [00:09<04:40,  9.34s/it]Training epoch 41:   3%|▎         | 1/31 [00:09<04:40,  9.34s/it, loss=1.5771, batch_acc=0.6875, running_acc=0.6875, grad=23.9940]Training epoch 41:   6%|▋         | 2/31 [00:10<02:17,  4.73s/it, loss=1.5771, batch_acc=0.6875, running_acc=0.6875, grad=23.9940]Training epoch 41:   6%|▋         | 2/31 [00:10<02:17,  4.73s/it, loss=1.3312, batch_acc=0.6562, running_acc=0.6719, grad=11.4666]Training epoch 41:  10%|▉         | 3/31 [00:12<01:31,  3.26s/it, loss=1.3312, batch_acc=0.6562, running_acc=0.6719, grad=11.4666]Training epoch 41:  10%|▉         | 3/31 [00:12<01:31,  3.26s/it, loss=1.3300, batch_acc=0.7500, running_acc=0.6979, grad=11.5693]Training epoch 41:  13%|█▎        | 4/31 [00:13<01:09,  2.58s/it, loss=1.3300, batch_acc=0.7500, running_acc=0.6979, grad=11.5693]Training epoch 41:  13%|█▎        | 4/31 [00:13<01:09,  2.58s/it, loss=1.6570, batch_acc=0.5938, running_acc=0.6719, grad=23.1550]Training epoch 41:  16%|█▌        | 5/31 [00:15<00:57,  2.20s/it, loss=1.6570, batch_acc=0.5938, running_acc=0.6719, grad=23.1550]Training epoch 41:  16%|█▌        | 5/31 [00:15<00:57,  2.20s/it, loss=1.3942, batch_acc=0.7500, running_acc=0.6875, grad=11.9323]Training epoch 41:  19%|█▉        | 6/31 [00:16<00:49,  1.97s/it, loss=1.3942, batch_acc=0.7500, running_acc=0.6875, grad=11.9323]Training epoch 41:  19%|█▉        | 6/31 [00:16<00:49,  1.97s/it, loss=1.5453, batch_acc=0.5625, running_acc=0.6667, grad=10.8014]Training epoch 41:  23%|██▎       | 7/31 [00:18<00:43,  1.82s/it, loss=1.5453, batch_acc=0.5625, running_acc=0.6667, grad=10.8014]Training epoch 41:  23%|██▎       | 7/31 [00:18<00:43,  1.82s/it, loss=1.3941, batch_acc=0.7188, running_acc=0.6741, grad=11.6862]Training epoch 41:  26%|██▌       | 8/31 [00:19<00:39,  1.72s/it, loss=1.3941, batch_acc=0.7188, running_acc=0.6741, grad=11.6862]Training epoch 41:  26%|██▌       | 8/31 [00:19<00:39,  1.72s/it, loss=1.5367, batch_acc=0.5938, running_acc=0.6641, grad=13.3298]Training epoch 41:  29%|██▉       | 9/31 [00:21<00:36,  1.66s/it, loss=1.5367, batch_acc=0.5938, running_acc=0.6641, grad=13.3298]Training epoch 41:  29%|██▉       | 9/31 [00:21<00:36,  1.66s/it, loss=1.4190, batch_acc=0.7812, running_acc=0.6771, grad=10.9283]Training epoch 41:  32%|███▏      | 10/31 [00:24<00:43,  2.10s/it, loss=1.4190, batch_acc=0.7812, running_acc=0.6771, grad=10.9283]Training epoch 41:  32%|███▏      | 10/31 [00:24<00:43,  2.10s/it, loss=1.6393, batch_acc=0.5312, running_acc=0.6625, grad=9.2350] Training epoch 41:  35%|███▌      | 11/31 [00:26<00:38,  1.91s/it, loss=1.6393, batch_acc=0.5312, running_acc=0.6625, grad=9.2350]Training epoch 41:  35%|███▌      | 11/31 [00:26<00:38,  1.91s/it, loss=1.1701, batch_acc=0.8438, running_acc=0.6790, grad=15.6116]Training epoch 41:  39%|███▊      | 12/31 [00:27<00:34,  1.79s/it, loss=1.1701, batch_acc=0.8438, running_acc=0.6790, grad=15.6116]Training epoch 41:  39%|███▊      | 12/31 [00:27<00:34,  1.79s/it, loss=1.5389, batch_acc=0.6562, running_acc=0.6771, grad=13.3369]Training epoch 41:  42%|████▏     | 13/31 [00:29<00:31,  1.76s/it, loss=1.5389, batch_acc=0.6562, running_acc=0.6771, grad=13.3369]Training epoch 41:  42%|████▏     | 13/31 [00:29<00:31,  1.76s/it, loss=1.5050, batch_acc=0.6250, running_acc=0.6731, grad=11.0590]Training epoch 41:  45%|████▌     | 14/31 [00:30<00:28,  1.70s/it, loss=1.5050, batch_acc=0.6250, running_acc=0.6731, grad=11.0590]Training epoch 41:  45%|████▌     | 14/31 [00:30<00:28,  1.70s/it, loss=1.3634, batch_acc=0.6250, running_acc=0.6696, grad=9.5130] Training epoch 41:  48%|████▊     | 15/31 [00:32<00:26,  1.64s/it, loss=1.3634, batch_acc=0.6250, running_acc=0.6696, grad=9.5130]Training epoch 41:  48%|████▊     | 15/31 [00:32<00:26,  1.64s/it, loss=1.3005, batch_acc=0.7500, running_acc=0.6750, grad=23.2446]Training epoch 41:  52%|█████▏    | 16/31 [00:33<00:23,  1.60s/it, loss=1.3005, batch_acc=0.7500, running_acc=0.6750, grad=23.2446]Training epoch 41:  52%|█████▏    | 16/31 [00:33<00:23,  1.60s/it, loss=1.4975, batch_acc=0.7500, running_acc=0.6797, grad=12.9043]Training epoch 41:  55%|█████▍    | 17/31 [00:38<00:35,  2.51s/it, loss=1.4975, batch_acc=0.7500, running_acc=0.6797, grad=12.9043]Training epoch 41:  55%|█████▍    | 17/31 [00:38<00:35,  2.51s/it, loss=1.3710, batch_acc=0.7188, running_acc=0.6820, grad=16.4702]Training epoch 41:  58%|█████▊    | 18/31 [00:40<00:30,  2.34s/it, loss=1.3710, batch_acc=0.7188, running_acc=0.6820, grad=16.4702]Training epoch 41:  58%|█████▊    | 18/31 [00:40<00:30,  2.34s/it, loss=1.2752, batch_acc=0.7188, running_acc=0.6840, grad=22.3043]Training epoch 41:  61%|██████▏   | 19/31 [00:41<00:25,  2.09s/it, loss=1.2752, batch_acc=0.7188, running_acc=0.6840, grad=22.3043]Training epoch 41:  61%|██████▏   | 19/31 [00:41<00:25,  2.09s/it, loss=1.3591, batch_acc=0.7812, running_acc=0.6891, grad=9.8113] Training epoch 41:  65%|██████▍   | 20/31 [00:43<00:21,  1.91s/it, loss=1.3591, batch_acc=0.7812, running_acc=0.6891, grad=9.8113]Training epoch 41:  65%|██████▍   | 20/31 [00:43<00:21,  1.91s/it, loss=1.4127, batch_acc=0.6875, running_acc=0.6891, grad=12.8200]Training epoch 41:  68%|██████▊   | 21/31 [00:44<00:17,  1.79s/it, loss=1.4127, batch_acc=0.6875, running_acc=0.6891, grad=12.8200]Training epoch 41:  68%|██████▊   | 21/31 [00:44<00:17,  1.79s/it, loss=1.4531, batch_acc=0.5938, running_acc=0.6845, grad=24.7369]Training epoch 41:  71%|███████   | 22/31 [00:50<00:27,  3.01s/it, loss=1.4531, batch_acc=0.5938, running_acc=0.6845, grad=24.7369]Training epoch 41:  71%|███████   | 22/31 [00:50<00:27,  3.01s/it, loss=1.5545, batch_acc=0.6875, running_acc=0.6847, grad=8.9388] Training epoch 41:  74%|███████▍  | 23/31 [00:52<00:20,  2.56s/it, loss=1.5545, batch_acc=0.6875, running_acc=0.6847, grad=8.9388]Training epoch 41:  74%|███████▍  | 23/31 [00:52<00:20,  2.56s/it, loss=1.5761, batch_acc=0.6250, running_acc=0.6821, grad=14.9740]Training epoch 41:  77%|███████▋  | 24/31 [00:53<00:15,  2.24s/it, loss=1.5761, batch_acc=0.6250, running_acc=0.6821, grad=14.9740]Training epoch 41:  77%|███████▋  | 24/31 [00:53<00:15,  2.24s/it, loss=1.2119, batch_acc=0.7500, running_acc=0.6849, grad=14.3196]Training epoch 41:  81%|████████  | 25/31 [00:55<00:12,  2.02s/it, loss=1.2119, batch_acc=0.7500, running_acc=0.6849, grad=14.3196]Training epoch 41:  81%|████████  | 25/31 [00:55<00:12,  2.02s/it, loss=1.7890, batch_acc=0.7188, running_acc=0.6863, grad=14.4559]Training epoch 41:  84%|████████▍ | 26/31 [01:11<00:30,  6.15s/it, loss=1.7890, batch_acc=0.7188, running_acc=0.6863, grad=14.4559]Training epoch 41:  84%|████████▍ | 26/31 [01:11<00:30,  6.15s/it, loss=1.3924, batch_acc=0.7812, running_acc=0.6899, grad=9.1196] Training epoch 41:  87%|████████▋ | 27/31 [01:12<00:19,  4.77s/it, loss=1.3924, batch_acc=0.7812, running_acc=0.6899, grad=9.1196]Training epoch 41:  87%|████████▋ | 27/31 [01:12<00:19,  4.77s/it, loss=1.4628, batch_acc=0.6875, running_acc=0.6898, grad=9.9087]Training epoch 41:  90%|█████████ | 28/31 [01:14<00:11,  3.79s/it, loss=1.4628, batch_acc=0.6875, running_acc=0.6898, grad=9.9087]Training epoch 41:  90%|█████████ | 28/31 [01:14<00:11,  3.79s/it, loss=1.4414, batch_acc=0.7188, running_acc=0.6908, grad=9.1763]Training epoch 41:  94%|█████████▎| 29/31 [01:15<00:06,  3.10s/it, loss=1.4414, batch_acc=0.7188, running_acc=0.6908, grad=9.1763]Training epoch 41:  94%|█████████▎| 29/31 [01:15<00:06,  3.10s/it, loss=1.3100, batch_acc=0.7500, running_acc=0.6929, grad=7.9426]Training epoch 41:  97%|█████████▋| 30/31 [01:17<00:02,  2.63s/it, loss=1.3100, batch_acc=0.7500, running_acc=0.6929, grad=7.9426]Training epoch 41:  97%|█████████▋| 30/31 [01:17<00:02,  2.63s/it, loss=1.6284, batch_acc=0.6875, running_acc=0.6927, grad=18.3021]Training epoch 41: 100%|██████████| 31/31 [01:17<00:00,  1.90s/it, loss=1.6284, batch_acc=0.6875, running_acc=0.6927, grad=18.3021]Training epoch 41: 100%|██████████| 31/31 [01:17<00:00,  1.90s/it, loss=1.3930, batch_acc=0.5000, running_acc=0.6923, grad=19.0014]Training epoch 41: 100%|██████████| 31/31 [01:17<00:00,  2.49s/it, loss=1.3930, batch_acc=0.5000, running_acc=0.6923, grad=19.0014]
Evaluation epoch 41:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 41:  20%|██        | 1/5 [00:21<01:27, 21.79s/it]Evaluation epoch 41:  20%|██        | 1/5 [00:21<01:27, 21.79s/it, loss=1.4313, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 41:  40%|████      | 2/5 [00:22<00:28,  9.41s/it, loss=1.4313, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 41:  40%|████      | 2/5 [00:22<00:28,  9.41s/it, loss=1.2840, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 41:  60%|██████    | 3/5 [00:23<00:10,  5.45s/it, loss=1.2840, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 41:  60%|██████    | 3/5 [00:23<00:10,  5.45s/it, loss=1.5959, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 41:  80%|████████  | 4/5 [00:31<00:06,  6.65s/it, loss=1.5959, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 41:  80%|████████  | 4/5 [00:31<00:06,  6.65s/it, loss=1.6866, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 41: 100%|██████████| 5/5 [00:32<00:00,  4.53s/it, loss=1.6866, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 41: 100%|██████████| 5/5 [00:32<00:00,  4.53s/it, loss=1.9052, batch_acc=0.5312, running_acc=0.6250]Evaluation epoch 41: 100%|██████████| 5/5 [00:32<00:00,  6.51s/it, loss=1.9052, batch_acc=0.5312, running_acc=0.6250]
Training epoch 42:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 42:   3%|▎         | 1/31 [00:21<10:32, 21.07s/it]Training epoch 42:   3%|▎         | 1/31 [00:21<10:32, 21.07s/it, loss=1.7523, batch_acc=0.6250, running_acc=0.6250, grad=8.5690]Training epoch 42:   6%|▋         | 2/31 [00:22<04:37,  9.56s/it, loss=1.7523, batch_acc=0.6250, running_acc=0.6250, grad=8.5690]Training epoch 42:   6%|▋         | 2/31 [00:22<04:37,  9.56s/it, loss=1.4335, batch_acc=0.7188, running_acc=0.6719, grad=10.9348]Training epoch 42:  10%|▉         | 3/31 [00:24<02:44,  5.89s/it, loss=1.4335, batch_acc=0.7188, running_acc=0.6719, grad=10.9348]Training epoch 42:  10%|▉         | 3/31 [00:24<02:44,  5.89s/it, loss=1.6191, batch_acc=0.7188, running_acc=0.6875, grad=18.0842]Training epoch 42:  13%|█▎        | 4/31 [00:26<02:06,  4.67s/it, loss=1.6191, batch_acc=0.7188, running_acc=0.6875, grad=18.0842]Training epoch 42:  13%|█▎        | 4/31 [00:27<02:06,  4.67s/it, loss=1.6711, batch_acc=0.6250, running_acc=0.6719, grad=11.4658]Training epoch 42:  16%|█▌        | 5/31 [00:32<02:07,  4.89s/it, loss=1.6711, batch_acc=0.6250, running_acc=0.6719, grad=11.4658]Training epoch 42:  16%|█▌        | 5/31 [00:32<02:07,  4.89s/it, loss=1.2685, batch_acc=0.8125, running_acc=0.7000, grad=16.4000]Training epoch 42:  19%|█▉        | 6/31 [00:35<01:49,  4.40s/it, loss=1.2685, batch_acc=0.8125, running_acc=0.7000, grad=16.4000]Training epoch 42:  19%|█▉        | 6/31 [00:35<01:49,  4.40s/it, loss=1.3933, batch_acc=0.6875, running_acc=0.6979, grad=11.1118]Training epoch 42:  23%|██▎       | 7/31 [00:37<01:22,  3.45s/it, loss=1.3933, batch_acc=0.6875, running_acc=0.6979, grad=11.1118]Training epoch 42:  23%|██▎       | 7/31 [00:37<01:22,  3.45s/it, loss=1.4266, batch_acc=0.6875, running_acc=0.6964, grad=24.3486]Training epoch 42:  26%|██▌       | 8/31 [00:38<01:05,  2.83s/it, loss=1.4266, batch_acc=0.6875, running_acc=0.6964, grad=24.3486]Training epoch 42:  26%|██▌       | 8/31 [00:38<01:05,  2.83s/it, loss=1.2812, batch_acc=0.6562, running_acc=0.6914, grad=9.1290] Training epoch 42:  29%|██▉       | 9/31 [00:44<01:22,  3.77s/it, loss=1.2812, batch_acc=0.6562, running_acc=0.6914, grad=9.1290]Training epoch 42:  29%|██▉       | 9/31 [00:44<01:22,  3.77s/it, loss=1.3225, batch_acc=0.7500, running_acc=0.6979, grad=54.2441]Training epoch 42:  32%|███▏      | 10/31 [00:50<01:35,  4.56s/it, loss=1.3225, batch_acc=0.7500, running_acc=0.6979, grad=54.2441]Training epoch 42:  32%|███▏      | 10/31 [00:50<01:35,  4.56s/it, loss=1.7315, batch_acc=0.6250, running_acc=0.6906, grad=12.1040]Training epoch 42:  35%|███▌      | 11/31 [00:52<01:12,  3.63s/it, loss=1.7315, batch_acc=0.6250, running_acc=0.6906, grad=12.1040]Training epoch 42:  35%|███▌      | 11/31 [00:52<01:12,  3.63s/it, loss=1.3537, batch_acc=0.7188, running_acc=0.6932, grad=13.3227]Training epoch 42:  39%|███▊      | 12/31 [00:53<00:56,  2.98s/it, loss=1.3537, batch_acc=0.7188, running_acc=0.6932, grad=13.3227]Training epoch 42:  39%|███▊      | 12/31 [00:53<00:56,  2.98s/it, loss=1.3852, batch_acc=0.7500, running_acc=0.6979, grad=9.5548] Training epoch 42:  42%|████▏     | 13/31 [00:55<00:45,  2.54s/it, loss=1.3852, batch_acc=0.7500, running_acc=0.6979, grad=9.5548]Training epoch 42:  42%|████▏     | 13/31 [00:55<00:45,  2.54s/it, loss=1.4165, batch_acc=0.6250, running_acc=0.6923, grad=12.3932]Training epoch 42:  45%|████▌     | 14/31 [01:06<01:29,  5.29s/it, loss=1.4165, batch_acc=0.6250, running_acc=0.6923, grad=12.3932]Training epoch 42:  45%|████▌     | 14/31 [01:06<01:29,  5.29s/it, loss=1.3310, batch_acc=0.7188, running_acc=0.6942, grad=18.1102]Training epoch 42:  48%|████▊     | 15/31 [01:08<01:06,  4.15s/it, loss=1.3310, batch_acc=0.7188, running_acc=0.6942, grad=18.1102]Training epoch 42:  48%|████▊     | 15/31 [01:08<01:06,  4.15s/it, loss=1.2422, batch_acc=0.8125, running_acc=0.7021, grad=9.0147] Training epoch 42:  52%|█████▏    | 16/31 [01:09<00:50,  3.35s/it, loss=1.2422, batch_acc=0.8125, running_acc=0.7021, grad=9.0147]Training epoch 42:  52%|█████▏    | 16/31 [01:09<00:50,  3.35s/it, loss=1.3220, batch_acc=0.7500, running_acc=0.7051, grad=35.0011]Training epoch 42:  55%|█████▍    | 17/31 [01:11<00:39,  2.80s/it, loss=1.3220, batch_acc=0.7500, running_acc=0.7051, grad=35.0011]Training epoch 42:  55%|█████▍    | 17/31 [01:11<00:39,  2.80s/it, loss=1.4372, batch_acc=0.6875, running_acc=0.7040, grad=23.6621]Training epoch 42:  58%|█████▊    | 18/31 [01:15<00:39,  3.07s/it, loss=1.4372, batch_acc=0.6875, running_acc=0.7040, grad=23.6621]Training epoch 42:  58%|█████▊    | 18/31 [01:15<00:39,  3.07s/it, loss=1.2685, batch_acc=0.7188, running_acc=0.7049, grad=17.5223]Training epoch 42:  61%|██████▏   | 19/31 [01:16<00:31,  2.60s/it, loss=1.2685, batch_acc=0.7188, running_acc=0.7049, grad=17.5223]Training epoch 42:  61%|██████▏   | 19/31 [01:16<00:31,  2.60s/it, loss=1.3577, batch_acc=0.7188, running_acc=0.7056, grad=7.7119] Training epoch 42:  65%|██████▍   | 20/31 [01:18<00:24,  2.27s/it, loss=1.3577, batch_acc=0.7188, running_acc=0.7056, grad=7.7119]Training epoch 42:  65%|██████▍   | 20/31 [01:18<00:24,  2.27s/it, loss=1.5649, batch_acc=0.6875, running_acc=0.7047, grad=13.4693]Training epoch 42:  68%|██████▊   | 21/31 [01:19<00:20,  2.04s/it, loss=1.5649, batch_acc=0.6875, running_acc=0.7047, grad=13.4693]Training epoch 42:  68%|██████▊   | 21/31 [01:19<00:20,  2.04s/it, loss=1.5775, batch_acc=0.6250, running_acc=0.7009, grad=9.5999] Training epoch 42:  71%|███████   | 22/31 [01:28<00:36,  4.07s/it, loss=1.5775, batch_acc=0.6250, running_acc=0.7009, grad=9.5999]Training epoch 42:  71%|███████   | 22/31 [01:28<00:36,  4.07s/it, loss=1.4919, batch_acc=0.7500, running_acc=0.7031, grad=10.7743]Training epoch 42:  74%|███████▍  | 23/31 [01:30<00:26,  3.30s/it, loss=1.4919, batch_acc=0.7500, running_acc=0.7031, grad=10.7743]Training epoch 42:  74%|███████▍  | 23/31 [01:30<00:26,  3.30s/it, loss=1.7172, batch_acc=0.5000, running_acc=0.6943, grad=10.0259]Training epoch 42:  77%|███████▋  | 24/31 [01:31<00:19,  2.76s/it, loss=1.7172, batch_acc=0.5000, running_acc=0.6943, grad=10.0259]Training epoch 42:  77%|███████▋  | 24/31 [01:31<00:19,  2.76s/it, loss=1.4057, batch_acc=0.6250, running_acc=0.6914, grad=12.9209]Training epoch 42:  81%|████████  | 25/31 [01:33<00:14,  2.39s/it, loss=1.4057, batch_acc=0.6250, running_acc=0.6914, grad=12.9209]Training epoch 42:  81%|████████  | 25/31 [01:33<00:14,  2.39s/it, loss=1.4032, batch_acc=0.7188, running_acc=0.6925, grad=15.0242]Training epoch 42:  84%|████████▍ | 26/31 [01:41<00:21,  4.36s/it, loss=1.4032, batch_acc=0.7188, running_acc=0.6925, grad=15.0242]Training epoch 42:  84%|████████▍ | 26/31 [01:41<00:21,  4.36s/it, loss=1.3274, batch_acc=0.7500, running_acc=0.6947, grad=10.5991]Training epoch 42:  87%|████████▋ | 27/31 [01:43<00:14,  3.50s/it, loss=1.3274, batch_acc=0.7500, running_acc=0.6947, grad=10.5991]Training epoch 42:  87%|████████▋ | 27/31 [01:43<00:14,  3.50s/it, loss=1.5704, batch_acc=0.6562, running_acc=0.6933, grad=9.2587] Training epoch 42:  90%|█████████ | 28/31 [01:44<00:08,  2.90s/it, loss=1.5704, batch_acc=0.6562, running_acc=0.6933, grad=9.2587]Training epoch 42:  90%|█████████ | 28/31 [01:44<00:08,  2.90s/it, loss=1.4310, batch_acc=0.7188, running_acc=0.6942, grad=9.2688]Training epoch 42:  94%|█████████▎| 29/31 [01:46<00:04,  2.48s/it, loss=1.4310, batch_acc=0.7188, running_acc=0.6942, grad=9.2688]Training epoch 42:  94%|█████████▎| 29/31 [01:46<00:04,  2.48s/it, loss=1.4002, batch_acc=0.7500, running_acc=0.6961, grad=23.5540]Training epoch 42:  97%|█████████▋| 30/31 [01:47<00:02,  2.19s/it, loss=1.4002, batch_acc=0.7500, running_acc=0.6961, grad=23.5540]Training epoch 42:  97%|█████████▋| 30/31 [01:47<00:02,  2.19s/it, loss=1.4853, batch_acc=0.7188, running_acc=0.6969, grad=9.4869] Training epoch 42: 100%|██████████| 31/31 [01:48<00:00,  1.59s/it, loss=1.4853, batch_acc=0.7188, running_acc=0.6969, grad=9.4869]Training epoch 42: 100%|██████████| 31/31 [01:48<00:00,  1.59s/it, loss=0.8143, batch_acc=1.0000, running_acc=0.6975, grad=225.2452]Training epoch 42: 100%|██████████| 31/31 [01:48<00:00,  3.49s/it, loss=0.8143, batch_acc=1.0000, running_acc=0.6975, grad=225.2452]
Evaluation epoch 42:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 42:  20%|██        | 1/5 [00:04<00:19,  4.86s/it]Evaluation epoch 42:  20%|██        | 1/5 [00:04<00:19,  4.86s/it, loss=1.4494, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 42:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.4494, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 42:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.3098, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 42:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.3098, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 42:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.6356, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 42:  80%|████████  | 4/5 [00:07<00:01,  1.58s/it, loss=1.6356, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 42:  80%|████████  | 4/5 [00:07<00:01,  1.58s/it, loss=1.7022, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 42: 100%|██████████| 5/5 [00:08<00:00,  1.29s/it, loss=1.7022, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 42: 100%|██████████| 5/5 [00:08<00:00,  1.29s/it, loss=1.8395, batch_acc=0.5312, running_acc=0.6250]Evaluation epoch 42: 100%|██████████| 5/5 [00:08<00:00,  1.71s/it, loss=1.8395, batch_acc=0.5312, running_acc=0.6250]
Training epoch 43:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 43:   3%|▎         | 1/31 [00:05<02:51,  5.71s/it]Training epoch 43:   3%|▎         | 1/31 [00:05<02:51,  5.71s/it, loss=1.7212, batch_acc=0.5625, running_acc=0.5625, grad=9.6720]Training epoch 43:   6%|▋         | 2/31 [00:07<01:34,  3.26s/it, loss=1.7212, batch_acc=0.5625, running_acc=0.5625, grad=9.6720]Training epoch 43:   6%|▋         | 2/31 [00:07<01:34,  3.26s/it, loss=1.2533, batch_acc=0.7188, running_acc=0.6406, grad=7.4594]Training epoch 43:  10%|▉         | 3/31 [00:08<01:08,  2.46s/it, loss=1.2533, batch_acc=0.7188, running_acc=0.6406, grad=7.4594]Training epoch 43:  10%|▉         | 3/31 [00:08<01:08,  2.46s/it, loss=1.2099, batch_acc=0.7188, running_acc=0.6667, grad=12.8014]Training epoch 43:  13%|█▎        | 4/31 [00:10<00:56,  2.09s/it, loss=1.2099, batch_acc=0.7188, running_acc=0.6667, grad=12.8014]Training epoch 43:  13%|█▎        | 4/31 [00:10<00:56,  2.09s/it, loss=1.3637, batch_acc=0.6875, running_acc=0.6719, grad=17.9276]Training epoch 43:  16%|█▌        | 5/31 [00:11<00:48,  1.88s/it, loss=1.3637, batch_acc=0.6875, running_acc=0.6719, grad=17.9276]Training epoch 43:  16%|█▌        | 5/31 [00:11<00:48,  1.88s/it, loss=1.5055, batch_acc=0.6562, running_acc=0.6687, grad=10.5014]Training epoch 43:  19%|█▉        | 6/31 [00:13<00:43,  1.76s/it, loss=1.5055, batch_acc=0.6562, running_acc=0.6687, grad=10.5014]Training epoch 43:  19%|█▉        | 6/31 [00:13<00:43,  1.76s/it, loss=1.5460, batch_acc=0.6875, running_acc=0.6719, grad=16.3100]Training epoch 43:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.5460, batch_acc=0.6875, running_acc=0.6719, grad=16.3100]Training epoch 43:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.6661, batch_acc=0.7188, running_acc=0.6786, grad=15.7193]Training epoch 43:  26%|██▌       | 8/31 [00:16<00:37,  1.63s/it, loss=1.6661, batch_acc=0.7188, running_acc=0.6786, grad=15.7193]Training epoch 43:  26%|██▌       | 8/31 [00:16<00:37,  1.63s/it, loss=1.4889, batch_acc=0.6875, running_acc=0.6797, grad=12.8162]Training epoch 43:  29%|██▉       | 9/31 [00:17<00:35,  1.59s/it, loss=1.4889, batch_acc=0.6875, running_acc=0.6797, grad=12.8162]Training epoch 43:  29%|██▉       | 9/31 [00:17<00:35,  1.59s/it, loss=1.4052, batch_acc=0.7500, running_acc=0.6875, grad=25.9178]Training epoch 43:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.4052, batch_acc=0.7500, running_acc=0.6875, grad=25.9178]Training epoch 43:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.1132, batch_acc=0.8750, running_acc=0.7063, grad=6.3782] Training epoch 43:  35%|███▌      | 11/31 [00:20<00:30,  1.55s/it, loss=1.1132, batch_acc=0.8750, running_acc=0.7063, grad=6.3782]Training epoch 43:  35%|███▌      | 11/31 [00:20<00:30,  1.55s/it, loss=1.4262, batch_acc=0.6875, running_acc=0.7045, grad=23.0999]Training epoch 43:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.4262, batch_acc=0.6875, running_acc=0.7045, grad=23.0999]Training epoch 43:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.3934, batch_acc=0.6875, running_acc=0.7031, grad=37.9524]Training epoch 43:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=1.3934, batch_acc=0.6875, running_acc=0.7031, grad=37.9524]Training epoch 43:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=1.1753, batch_acc=0.8438, running_acc=0.7139, grad=23.3590]Training epoch 43:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.1753, batch_acc=0.8438, running_acc=0.7139, grad=23.3590]Training epoch 43:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.4147, batch_acc=0.6562, running_acc=0.7098, grad=13.7252]Training epoch 43:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.4147, batch_acc=0.6562, running_acc=0.7098, grad=13.7252]Training epoch 43:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.3483, batch_acc=0.7500, running_acc=0.7125, grad=10.5746]Training epoch 43:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.3483, batch_acc=0.7500, running_acc=0.7125, grad=10.5746]Training epoch 43:  52%|█████▏    | 16/31 [00:28<00:22,  1.52s/it, loss=1.7535, batch_acc=0.5312, running_acc=0.7012, grad=8.4957] Training epoch 43:  55%|█████▍    | 17/31 [00:29<00:21,  1.52s/it, loss=1.7535, batch_acc=0.5312, running_acc=0.7012, grad=8.4957]Training epoch 43:  55%|█████▍    | 17/31 [00:29<00:21,  1.52s/it, loss=1.7698, batch_acc=0.5312, running_acc=0.6912, grad=8.5389]Training epoch 43:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.7698, batch_acc=0.5312, running_acc=0.6912, grad=8.5389]Training epoch 43:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.5263, batch_acc=0.6250, running_acc=0.6875, grad=10.9823]Training epoch 43:  61%|██████▏   | 19/31 [00:32<00:18,  1.51s/it, loss=1.5263, batch_acc=0.6250, running_acc=0.6875, grad=10.9823]Training epoch 43:  61%|██████▏   | 19/31 [00:32<00:18,  1.51s/it, loss=1.3493, batch_acc=0.7500, running_acc=0.6908, grad=9.3992] Training epoch 43:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.3493, batch_acc=0.7500, running_acc=0.6908, grad=9.3992]Training epoch 43:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.5063, batch_acc=0.7188, running_acc=0.6922, grad=11.2467]Training epoch 43:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.5063, batch_acc=0.7188, running_acc=0.6922, grad=11.2467]Training epoch 43:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.5524, batch_acc=0.6875, running_acc=0.6920, grad=17.6855]Training epoch 43:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.5524, batch_acc=0.6875, running_acc=0.6920, grad=17.6855]Training epoch 43:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.6008, batch_acc=0.5312, running_acc=0.6847, grad=16.4336]Training epoch 43:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.6008, batch_acc=0.5312, running_acc=0.6847, grad=16.4336]Training epoch 43:  74%|███████▍  | 23/31 [00:39<00:12,  1.51s/it, loss=1.5084, batch_acc=0.5625, running_acc=0.6793, grad=11.6328]Training epoch 43:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.5084, batch_acc=0.5625, running_acc=0.6793, grad=11.6328]Training epoch 43:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.4633, batch_acc=0.7812, running_acc=0.6836, grad=13.6428]Training epoch 43:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=1.4633, batch_acc=0.7812, running_acc=0.6836, grad=13.6428]Training epoch 43:  81%|████████  | 25/31 [00:42<00:09,  1.51s/it, loss=1.3233, batch_acc=0.7500, running_acc=0.6863, grad=15.1134]Training epoch 43:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.3233, batch_acc=0.7500, running_acc=0.6863, grad=15.1134]Training epoch 43:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.3599, batch_acc=0.6562, running_acc=0.6851, grad=23.6081]Training epoch 43:  87%|████████▋ | 27/31 [00:45<00:06,  1.51s/it, loss=1.3599, batch_acc=0.6562, running_acc=0.6851, grad=23.6081]Training epoch 43:  87%|████████▋ | 27/31 [00:45<00:06,  1.51s/it, loss=1.3017, batch_acc=0.7500, running_acc=0.6875, grad=9.0887] Training epoch 43:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=1.3017, batch_acc=0.7500, running_acc=0.6875, grad=9.0887]Training epoch 43:  90%|█████████ | 28/31 [00:46<00:04,  1.51s/it, loss=1.3468, batch_acc=0.7500, running_acc=0.6897, grad=7.3249]Training epoch 43:  94%|█████████▎| 29/31 [00:48<00:03,  1.51s/it, loss=1.3468, batch_acc=0.7500, running_acc=0.6897, grad=7.3249]Training epoch 43:  94%|█████████▎| 29/31 [00:48<00:03,  1.51s/it, loss=1.4207, batch_acc=0.7812, running_acc=0.6929, grad=9.1657]Training epoch 43:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.4207, batch_acc=0.7812, running_acc=0.6929, grad=9.1657]Training epoch 43:  97%|█████████▋| 30/31 [00:49<00:01,  1.51s/it, loss=1.4965, batch_acc=0.7812, running_acc=0.6958, grad=10.9563]Training epoch 43: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.4965, batch_acc=0.7812, running_acc=0.6958, grad=10.9563]Training epoch 43: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.3476, batch_acc=0.5000, running_acc=0.6954, grad=144.5808]Training epoch 43: 100%|██████████| 31/31 [00:49<00:00,  1.60s/it, loss=1.3476, batch_acc=0.5000, running_acc=0.6954, grad=144.5808]
Evaluation epoch 43:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 43:  20%|██        | 1/5 [00:04<00:19,  4.93s/it]Evaluation epoch 43:  20%|██        | 1/5 [00:04<00:19,  4.93s/it, loss=1.4485, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 43:  40%|████      | 2/5 [00:05<00:07,  2.47s/it, loss=1.4485, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 43:  40%|████      | 2/5 [00:05<00:07,  2.47s/it, loss=1.2990, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 43:  60%|██████    | 3/5 [00:06<00:03,  1.68s/it, loss=1.2990, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 43:  60%|██████    | 3/5 [00:06<00:03,  1.68s/it, loss=1.6135, batch_acc=0.5625, running_acc=0.6667]Evaluation epoch 43:  80%|████████  | 4/5 [00:07<00:01,  1.43s/it, loss=1.6135, batch_acc=0.5625, running_acc=0.6667]Evaluation epoch 43:  80%|████████  | 4/5 [00:07<00:01,  1.43s/it, loss=1.6981, batch_acc=0.5938, running_acc=0.6484]Evaluation epoch 43: 100%|██████████| 5/5 [00:08<00:00,  1.20s/it, loss=1.6981, batch_acc=0.5938, running_acc=0.6484]Evaluation epoch 43: 100%|██████████| 5/5 [00:08<00:00,  1.20s/it, loss=1.8568, batch_acc=0.6250, running_acc=0.6438]Evaluation epoch 43: 100%|██████████| 5/5 [00:08<00:00,  1.65s/it, loss=1.8568, batch_acc=0.6250, running_acc=0.6438]
Training epoch 44:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 44:   3%|▎         | 1/31 [00:08<04:21,  8.72s/it]Training epoch 44:   3%|▎         | 1/31 [00:08<04:21,  8.72s/it, loss=1.7996, batch_acc=0.5625, running_acc=0.5625, grad=12.3172]Training epoch 44:   6%|▋         | 2/31 [00:10<02:09,  4.48s/it, loss=1.7996, batch_acc=0.5625, running_acc=0.5625, grad=12.3172]Training epoch 44:   6%|▋         | 2/31 [00:10<02:09,  4.48s/it, loss=1.3368, batch_acc=0.7500, running_acc=0.6562, grad=17.8051]Training epoch 44:  10%|▉         | 3/31 [00:11<01:27,  3.13s/it, loss=1.3368, batch_acc=0.7500, running_acc=0.6562, grad=17.8051]Training epoch 44:  10%|▉         | 3/31 [00:11<01:27,  3.13s/it, loss=1.3675, batch_acc=0.7188, running_acc=0.6771, grad=23.0147]Training epoch 44:  13%|█▎        | 4/31 [00:13<01:11,  2.63s/it, loss=1.3675, batch_acc=0.7188, running_acc=0.6771, grad=23.0147]Training epoch 44:  13%|█▎        | 4/31 [00:13<01:11,  2.63s/it, loss=1.4251, batch_acc=0.7500, running_acc=0.6953, grad=35.9992]Training epoch 44:  16%|█▌        | 5/31 [00:15<01:02,  2.40s/it, loss=1.4251, batch_acc=0.7500, running_acc=0.6953, grad=35.9992]Training epoch 44:  16%|█▌        | 5/31 [00:15<01:02,  2.40s/it, loss=1.3544, batch_acc=0.6562, running_acc=0.6875, grad=18.2745]Training epoch 44:  19%|█▉        | 6/31 [00:17<00:52,  2.10s/it, loss=1.3544, batch_acc=0.6562, running_acc=0.6875, grad=18.2745]Training epoch 44:  19%|█▉        | 6/31 [00:17<00:52,  2.10s/it, loss=1.4630, batch_acc=0.6250, running_acc=0.6771, grad=8.2598] Training epoch 44:  23%|██▎       | 7/31 [00:18<00:45,  1.91s/it, loss=1.4630, batch_acc=0.6250, running_acc=0.6771, grad=8.2598]Training epoch 44:  23%|██▎       | 7/31 [00:18<00:45,  1.91s/it, loss=1.4675, batch_acc=0.5938, running_acc=0.6652, grad=8.2915]Training epoch 44:  26%|██▌       | 8/31 [00:20<00:40,  1.78s/it, loss=1.4675, batch_acc=0.5938, running_acc=0.6652, grad=8.2915]Training epoch 44:  26%|██▌       | 8/31 [00:20<00:40,  1.78s/it, loss=1.2821, batch_acc=0.7812, running_acc=0.6797, grad=12.5387]Training epoch 44:  29%|██▉       | 9/31 [00:21<00:37,  1.70s/it, loss=1.2821, batch_acc=0.7812, running_acc=0.6797, grad=12.5387]Training epoch 44:  29%|██▉       | 9/31 [00:21<00:37,  1.70s/it, loss=1.7131, batch_acc=0.5625, running_acc=0.6667, grad=8.5653] Training epoch 44:  32%|███▏      | 10/31 [00:23<00:34,  1.64s/it, loss=1.7131, batch_acc=0.5625, running_acc=0.6667, grad=8.5653]Training epoch 44:  32%|███▏      | 10/31 [00:23<00:34,  1.64s/it, loss=1.4252, batch_acc=0.7500, running_acc=0.6750, grad=9.3264]Training epoch 44:  35%|███▌      | 11/31 [00:24<00:31,  1.60s/it, loss=1.4252, batch_acc=0.7500, running_acc=0.6750, grad=9.3264]Training epoch 44:  35%|███▌      | 11/31 [00:24<00:31,  1.60s/it, loss=1.1901, batch_acc=0.8125, running_acc=0.6875, grad=15.9748]Training epoch 44:  39%|███▊      | 12/31 [00:26<00:29,  1.57s/it, loss=1.1901, batch_acc=0.8125, running_acc=0.6875, grad=15.9748]Training epoch 44:  39%|███▊      | 12/31 [00:26<00:29,  1.57s/it, loss=1.2817, batch_acc=0.7812, running_acc=0.6953, grad=7.4241] Training epoch 44:  42%|████▏     | 13/31 [00:27<00:27,  1.55s/it, loss=1.2817, batch_acc=0.7812, running_acc=0.6953, grad=7.4241]Training epoch 44:  42%|████▏     | 13/31 [00:27<00:27,  1.55s/it, loss=1.6231, batch_acc=0.5938, running_acc=0.6875, grad=11.6104]Training epoch 44:  45%|████▌     | 14/31 [00:29<00:26,  1.54s/it, loss=1.6231, batch_acc=0.5938, running_acc=0.6875, grad=11.6104]Training epoch 44:  45%|████▌     | 14/31 [00:29<00:26,  1.54s/it, loss=1.4874, batch_acc=0.6875, running_acc=0.6875, grad=13.9723]Training epoch 44:  48%|████▊     | 15/31 [00:30<00:24,  1.54s/it, loss=1.4874, batch_acc=0.6875, running_acc=0.6875, grad=13.9723]Training epoch 44:  48%|████▊     | 15/31 [00:30<00:24,  1.54s/it, loss=1.1458, batch_acc=0.7500, running_acc=0.6917, grad=9.4512] Training epoch 44:  52%|█████▏    | 16/31 [00:32<00:22,  1.53s/it, loss=1.1458, batch_acc=0.7500, running_acc=0.6917, grad=9.4512]Training epoch 44:  52%|█████▏    | 16/31 [00:32<00:22,  1.53s/it, loss=1.2998, batch_acc=0.6875, running_acc=0.6914, grad=12.7997]Training epoch 44:  55%|█████▍    | 17/31 [00:33<00:21,  1.52s/it, loss=1.2998, batch_acc=0.6875, running_acc=0.6914, grad=12.7997]Training epoch 44:  55%|█████▍    | 17/31 [00:33<00:21,  1.52s/it, loss=1.7657, batch_acc=0.5625, running_acc=0.6838, grad=20.6781]Training epoch 44:  58%|█████▊    | 18/31 [00:35<00:19,  1.52s/it, loss=1.7657, batch_acc=0.5625, running_acc=0.6838, grad=20.6781]Training epoch 44:  58%|█████▊    | 18/31 [00:35<00:19,  1.52s/it, loss=1.3653, batch_acc=0.7812, running_acc=0.6892, grad=11.8446]Training epoch 44:  61%|██████▏   | 19/31 [00:36<00:18,  1.51s/it, loss=1.3653, batch_acc=0.7812, running_acc=0.6892, grad=11.8446]Training epoch 44:  61%|██████▏   | 19/31 [00:36<00:18,  1.51s/it, loss=1.2721, batch_acc=0.7188, running_acc=0.6908, grad=24.8282]Training epoch 44:  65%|██████▍   | 20/31 [00:38<00:16,  1.51s/it, loss=1.2721, batch_acc=0.7188, running_acc=0.6908, grad=24.8282]Training epoch 44:  65%|██████▍   | 20/31 [00:38<00:16,  1.51s/it, loss=1.4449, batch_acc=0.6562, running_acc=0.6891, grad=12.4242]Training epoch 44:  68%|██████▊   | 21/31 [00:39<00:15,  1.51s/it, loss=1.4449, batch_acc=0.6562, running_acc=0.6891, grad=12.4242]Training epoch 44:  68%|██████▊   | 21/31 [00:39<00:15,  1.51s/it, loss=1.3915, batch_acc=0.6562, running_acc=0.6875, grad=8.7428] Training epoch 44:  71%|███████   | 22/31 [00:41<00:13,  1.51s/it, loss=1.3915, batch_acc=0.6562, running_acc=0.6875, grad=8.7428]Training epoch 44:  71%|███████   | 22/31 [00:41<00:13,  1.51s/it, loss=1.5841, batch_acc=0.6562, running_acc=0.6861, grad=299.0272]Training epoch 44:  74%|███████▍  | 23/31 [00:43<00:13,  1.69s/it, loss=1.5841, batch_acc=0.6562, running_acc=0.6861, grad=299.0272]Training epoch 44:  74%|███████▍  | 23/31 [00:43<00:13,  1.69s/it, loss=1.6925, batch_acc=0.6250, running_acc=0.6834, grad=12.7998] Training epoch 44:  77%|███████▋  | 24/31 [00:44<00:11,  1.64s/it, loss=1.6925, batch_acc=0.6250, running_acc=0.6834, grad=12.7998]Training epoch 44:  77%|███████▋  | 24/31 [00:44<00:11,  1.64s/it, loss=1.5688, batch_acc=0.6250, running_acc=0.6810, grad=8.9963] Training epoch 44:  81%|████████  | 25/31 [00:46<00:09,  1.60s/it, loss=1.5688, batch_acc=0.6250, running_acc=0.6810, grad=8.9963]Training epoch 44:  81%|████████  | 25/31 [00:46<00:09,  1.60s/it, loss=1.5096, batch_acc=0.6562, running_acc=0.6800, grad=13.5036]Training epoch 44:  84%|████████▍ | 26/31 [00:47<00:07,  1.57s/it, loss=1.5096, batch_acc=0.6562, running_acc=0.6800, grad=13.5036]Training epoch 44:  84%|████████▍ | 26/31 [00:47<00:07,  1.57s/it, loss=1.4416, batch_acc=0.6875, running_acc=0.6803, grad=36.7153]Training epoch 44:  87%|████████▋ | 27/31 [00:49<00:06,  1.55s/it, loss=1.4416, batch_acc=0.6875, running_acc=0.6803, grad=36.7153]Training epoch 44:  87%|████████▋ | 27/31 [00:49<00:06,  1.55s/it, loss=1.1659, batch_acc=0.8750, running_acc=0.6875, grad=27.3968]Training epoch 44:  90%|█████████ | 28/31 [00:50<00:04,  1.54s/it, loss=1.1659, batch_acc=0.8750, running_acc=0.6875, grad=27.3968]Training epoch 44:  90%|█████████ | 28/31 [00:50<00:04,  1.54s/it, loss=1.5807, batch_acc=0.5938, running_acc=0.6842, grad=9.3431] Training epoch 44:  94%|█████████▎| 29/31 [00:52<00:03,  1.53s/it, loss=1.5807, batch_acc=0.5938, running_acc=0.6842, grad=9.3431]Training epoch 44:  94%|█████████▎| 29/31 [00:52<00:03,  1.53s/it, loss=1.2132, batch_acc=0.7812, running_acc=0.6875, grad=11.2551]Training epoch 44:  97%|█████████▋| 30/31 [00:53<00:01,  1.52s/it, loss=1.2132, batch_acc=0.7812, running_acc=0.6875, grad=11.2551]Training epoch 44:  97%|█████████▋| 30/31 [00:53<00:01,  1.52s/it, loss=1.3236, batch_acc=0.7812, running_acc=0.6906, grad=12.0157]Training epoch 44: 100%|██████████| 31/31 [00:54<00:00,  1.13s/it, loss=1.3236, batch_acc=0.7812, running_acc=0.6906, grad=12.0157]Training epoch 44: 100%|██████████| 31/31 [00:54<00:00,  1.13s/it, loss=0.9175, batch_acc=1.0000, running_acc=0.6913, grad=52.9785]Training epoch 44: 100%|██████████| 31/31 [00:54<00:00,  1.75s/it, loss=0.9175, batch_acc=1.0000, running_acc=0.6913, grad=52.9785]
Evaluation epoch 44:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 44:  20%|██        | 1/5 [00:15<01:01, 15.27s/it]Evaluation epoch 44:  20%|██        | 1/5 [00:15<01:01, 15.27s/it, loss=1.4517, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 44:  40%|████      | 2/5 [00:16<00:20,  6.72s/it, loss=1.4517, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 44:  40%|████      | 2/5 [00:16<00:20,  6.72s/it, loss=1.2981, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 44:  60%|██████    | 3/5 [00:16<00:07,  3.99s/it, loss=1.2981, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 44:  60%|██████    | 3/5 [00:16<00:07,  3.99s/it, loss=1.5961, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 44:  80%|████████  | 4/5 [00:21<00:04,  4.11s/it, loss=1.5961, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 44:  80%|████████  | 4/5 [00:21<00:04,  4.11s/it, loss=1.6831, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 44: 100%|██████████| 5/5 [00:21<00:00,  2.90s/it, loss=1.6831, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 44: 100%|██████████| 5/5 [00:21<00:00,  2.90s/it, loss=1.8593, batch_acc=0.6250, running_acc=0.6438]Evaluation epoch 44: 100%|██████████| 5/5 [00:21<00:00,  4.36s/it, loss=1.8593, batch_acc=0.6250, running_acc=0.6438]
Training epoch 45:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 45:   3%|▎         | 1/31 [00:08<04:12,  8.42s/it]Training epoch 45:   3%|▎         | 1/31 [00:08<04:12,  8.42s/it, loss=1.6384, batch_acc=0.6250, running_acc=0.6250, grad=23.9194]Training epoch 45:   6%|▋         | 2/31 [00:09<02:06,  4.35s/it, loss=1.6384, batch_acc=0.6250, running_acc=0.6250, grad=23.9194]Training epoch 45:   6%|▋         | 2/31 [00:09<02:06,  4.35s/it, loss=1.3362, batch_acc=0.8438, running_acc=0.7344, grad=8.9199] Training epoch 45:  10%|▉         | 3/31 [00:11<01:25,  3.05s/it, loss=1.3362, batch_acc=0.8438, running_acc=0.7344, grad=8.9199]Training epoch 45:  10%|▉         | 3/31 [00:11<01:25,  3.05s/it, loss=1.2953, batch_acc=0.7500, running_acc=0.7396, grad=15.0444]Training epoch 45:  13%|█▎        | 4/31 [00:12<01:05,  2.44s/it, loss=1.2953, batch_acc=0.7500, running_acc=0.7396, grad=15.0444]Training epoch 45:  13%|█▎        | 4/31 [00:12<01:05,  2.44s/it, loss=1.5072, batch_acc=0.6875, running_acc=0.7266, grad=11.7548]Training epoch 45:  16%|█▌        | 5/31 [00:14<00:58,  2.26s/it, loss=1.5072, batch_acc=0.6875, running_acc=0.7266, grad=11.7548]Training epoch 45:  16%|█▌        | 5/31 [00:14<00:58,  2.26s/it, loss=1.5071, batch_acc=0.6250, running_acc=0.7063, grad=13.3188]Training epoch 45:  19%|█▉        | 6/31 [00:16<00:50,  2.00s/it, loss=1.5071, batch_acc=0.6250, running_acc=0.7063, grad=13.3188]Training epoch 45:  19%|█▉        | 6/31 [00:16<00:50,  2.00s/it, loss=1.3682, batch_acc=0.6875, running_acc=0.7031, grad=16.8432]Training epoch 45:  23%|██▎       | 7/31 [00:17<00:44,  1.84s/it, loss=1.3682, batch_acc=0.6875, running_acc=0.7031, grad=16.8432]Training epoch 45:  23%|██▎       | 7/31 [00:17<00:44,  1.84s/it, loss=1.2928, batch_acc=0.7188, running_acc=0.7054, grad=14.7816]Training epoch 45:  26%|██▌       | 8/31 [00:19<00:41,  1.82s/it, loss=1.2928, batch_acc=0.7188, running_acc=0.7054, grad=14.7816]Training epoch 45:  26%|██▌       | 8/31 [00:19<00:41,  1.82s/it, loss=1.5542, batch_acc=0.5938, running_acc=0.6914, grad=11.1490]Training epoch 45:  29%|██▉       | 9/31 [00:22<00:44,  2.02s/it, loss=1.5542, batch_acc=0.5938, running_acc=0.6914, grad=11.1490]Training epoch 45:  29%|██▉       | 9/31 [00:22<00:44,  2.02s/it, loss=1.6034, batch_acc=0.5938, running_acc=0.6806, grad=15.4875]Training epoch 45:  32%|███▏      | 10/31 [00:23<00:39,  1.87s/it, loss=1.6034, batch_acc=0.5938, running_acc=0.6806, grad=15.4875]Training epoch 45:  32%|███▏      | 10/31 [00:23<00:39,  1.87s/it, loss=1.6106, batch_acc=0.5938, running_acc=0.6719, grad=10.9629]Training epoch 45:  35%|███▌      | 11/31 [00:25<00:35,  1.76s/it, loss=1.6106, batch_acc=0.5938, running_acc=0.6719, grad=10.9629]Training epoch 45:  35%|███▌      | 11/31 [00:25<00:35,  1.76s/it, loss=1.4520, batch_acc=0.6562, running_acc=0.6705, grad=7.6408] Training epoch 45:  39%|███▊      | 12/31 [00:26<00:32,  1.71s/it, loss=1.4520, batch_acc=0.6562, running_acc=0.6705, grad=7.6408]Training epoch 45:  39%|███▊      | 12/31 [00:26<00:32,  1.71s/it, loss=1.3742, batch_acc=0.7812, running_acc=0.6797, grad=18.9625]Training epoch 45:  42%|████▏     | 13/31 [00:30<00:39,  2.19s/it, loss=1.3742, batch_acc=0.7812, running_acc=0.6797, grad=18.9625]Training epoch 45:  42%|████▏     | 13/31 [00:30<00:39,  2.19s/it, loss=1.3419, batch_acc=0.7188, running_acc=0.6827, grad=55.0837]Training epoch 45:  45%|████▌     | 14/31 [00:31<00:33,  1.98s/it, loss=1.3419, batch_acc=0.7188, running_acc=0.6827, grad=55.0837]Training epoch 45:  45%|████▌     | 14/31 [00:31<00:33,  1.98s/it, loss=1.4878, batch_acc=0.5938, running_acc=0.6763, grad=8.6258] Training epoch 45:  48%|████▊     | 15/31 [00:33<00:29,  1.84s/it, loss=1.4878, batch_acc=0.5938, running_acc=0.6763, grad=8.6258]Training epoch 45:  48%|████▊     | 15/31 [00:33<00:29,  1.84s/it, loss=1.5162, batch_acc=0.6562, running_acc=0.6750, grad=20.6831]Training epoch 45:  52%|█████▏    | 16/31 [00:34<00:26,  1.74s/it, loss=1.5162, batch_acc=0.6562, running_acc=0.6750, grad=20.6831]Training epoch 45:  52%|█████▏    | 16/31 [00:34<00:26,  1.74s/it, loss=1.3541, batch_acc=0.6875, running_acc=0.6758, grad=9.0277] Training epoch 45:  55%|█████▍    | 17/31 [00:38<00:33,  2.42s/it, loss=1.3541, batch_acc=0.6875, running_acc=0.6758, grad=9.0277]Training epoch 45:  55%|█████▍    | 17/31 [00:38<00:33,  2.42s/it, loss=1.3927, batch_acc=0.7500, running_acc=0.6801, grad=44.4427]Training epoch 45:  58%|█████▊    | 18/31 [00:40<00:27,  2.14s/it, loss=1.3927, batch_acc=0.7500, running_acc=0.6801, grad=44.4427]Training epoch 45:  58%|█████▊    | 18/31 [00:40<00:27,  2.14s/it, loss=1.4502, batch_acc=0.8125, running_acc=0.6875, grad=91.5538]Training epoch 45:  61%|██████▏   | 19/31 [00:45<00:36,  3.04s/it, loss=1.4502, batch_acc=0.8125, running_acc=0.6875, grad=91.5538]Training epoch 45:  61%|██████▏   | 19/31 [00:45<00:36,  3.04s/it, loss=1.3823, batch_acc=0.7812, running_acc=0.6924, grad=6.3210] Training epoch 45:  65%|██████▍   | 20/31 [00:46<00:28,  2.58s/it, loss=1.3823, batch_acc=0.7812, running_acc=0.6924, grad=6.3210]Training epoch 45:  65%|██████▍   | 20/31 [00:46<00:28,  2.58s/it, loss=1.4972, batch_acc=0.6562, running_acc=0.6906, grad=9.9023]Training epoch 45:  68%|██████▊   | 21/31 [00:48<00:22,  2.27s/it, loss=1.4972, batch_acc=0.6562, running_acc=0.6906, grad=9.9023]Training epoch 45:  68%|██████▊   | 21/31 [00:48<00:22,  2.27s/it, loss=1.4089, batch_acc=0.7812, running_acc=0.6949, grad=25.0686]Training epoch 45:  71%|███████   | 22/31 [00:49<00:18,  2.04s/it, loss=1.4089, batch_acc=0.7812, running_acc=0.6949, grad=25.0686]Training epoch 45:  71%|███████   | 22/31 [00:49<00:18,  2.04s/it, loss=1.4321, batch_acc=0.6875, running_acc=0.6946, grad=8.1558] Training epoch 45:  74%|███████▍  | 23/31 [00:55<00:24,  3.01s/it, loss=1.4321, batch_acc=0.6875, running_acc=0.6946, grad=8.1558]Training epoch 45:  74%|███████▍  | 23/31 [00:55<00:24,  3.01s/it, loss=1.4762, batch_acc=0.6562, running_acc=0.6929, grad=10.5069]Training epoch 45:  77%|███████▋  | 24/31 [00:56<00:17,  2.56s/it, loss=1.4762, batch_acc=0.6562, running_acc=0.6929, grad=10.5069]Training epoch 45:  77%|███████▋  | 24/31 [00:56<00:17,  2.56s/it, loss=1.1533, batch_acc=0.8438, running_acc=0.6992, grad=6.5618] Training epoch 45:  81%|████████  | 25/31 [01:00<00:17,  2.87s/it, loss=1.1533, batch_acc=0.8438, running_acc=0.6992, grad=6.5618]Training epoch 45:  81%|████████  | 25/31 [01:00<00:17,  2.87s/it, loss=1.4292, batch_acc=0.7500, running_acc=0.7013, grad=10.1585]Training epoch 45:  84%|████████▍ | 26/31 [01:01<00:12,  2.46s/it, loss=1.4292, batch_acc=0.7500, running_acc=0.7013, grad=10.1585]Training epoch 45:  84%|████████▍ | 26/31 [01:01<00:12,  2.46s/it, loss=1.4406, batch_acc=0.5938, running_acc=0.6971, grad=9.1906] Training epoch 45:  87%|████████▋ | 27/31 [01:11<00:18,  4.56s/it, loss=1.4406, batch_acc=0.5938, running_acc=0.6971, grad=9.1906]Training epoch 45:  87%|████████▋ | 27/31 [01:11<00:18,  4.56s/it, loss=1.3710, batch_acc=0.7500, running_acc=0.6991, grad=26.2445]Training epoch 45:  90%|█████████ | 28/31 [01:12<00:10,  3.64s/it, loss=1.3710, batch_acc=0.7500, running_acc=0.6991, grad=26.2445]Training epoch 45:  90%|█████████ | 28/31 [01:12<00:10,  3.64s/it, loss=1.5095, batch_acc=0.6562, running_acc=0.6975, grad=11.7753]Training epoch 45:  94%|█████████▎| 29/31 [01:14<00:06,  3.00s/it, loss=1.5095, batch_acc=0.6562, running_acc=0.6975, grad=11.7753]Training epoch 45:  94%|█████████▎| 29/31 [01:14<00:06,  3.00s/it, loss=1.4432, batch_acc=0.6875, running_acc=0.6972, grad=9.6964] Training epoch 45:  97%|█████████▋| 30/31 [01:15<00:02,  2.56s/it, loss=1.4432, batch_acc=0.6875, running_acc=0.6972, grad=9.6964]Training epoch 45:  97%|█████████▋| 30/31 [01:15<00:02,  2.56s/it, loss=1.2986, batch_acc=0.8125, running_acc=0.7010, grad=10.7326]Training epoch 45: 100%|██████████| 31/31 [01:15<00:00,  1.85s/it, loss=1.2986, batch_acc=0.8125, running_acc=0.7010, grad=10.7326]Training epoch 45: 100%|██████████| 31/31 [01:15<00:00,  1.85s/it, loss=1.5500, batch_acc=0.5000, running_acc=0.7006, grad=19.0515]Training epoch 45: 100%|██████████| 31/31 [01:15<00:00,  2.45s/it, loss=1.5500, batch_acc=0.5000, running_acc=0.7006, grad=19.0515]
Evaluation epoch 45:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 45:  20%|██        | 1/5 [00:04<00:19,  4.92s/it]Evaluation epoch 45:  20%|██        | 1/5 [00:04<00:19,  4.92s/it, loss=1.4514, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 45:  40%|████      | 2/5 [00:05<00:07,  2.46s/it, loss=1.4514, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 45:  40%|████      | 2/5 [00:05<00:07,  2.46s/it, loss=1.3079, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 45:  60%|██████    | 3/5 [00:06<00:03,  1.68s/it, loss=1.3079, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 45:  60%|██████    | 3/5 [00:06<00:03,  1.68s/it, loss=1.5839, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 45:  80%|████████  | 4/5 [00:07<00:01,  1.43s/it, loss=1.5839, batch_acc=0.5312, running_acc=0.6562]Evaluation epoch 45:  80%|████████  | 4/5 [00:07<00:01,  1.43s/it, loss=1.6798, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 45: 100%|██████████| 5/5 [00:08<00:00,  1.20s/it, loss=1.6798, batch_acc=0.6250, running_acc=0.6484]Evaluation epoch 45: 100%|██████████| 5/5 [00:08<00:00,  1.20s/it, loss=1.8720, batch_acc=0.6250, running_acc=0.6438]Evaluation epoch 45: 100%|██████████| 5/5 [00:08<00:00,  1.65s/it, loss=1.8720, batch_acc=0.6250, running_acc=0.6438]
Training epoch 46:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 46:   3%|▎         | 1/31 [00:05<02:45,  5.51s/it]Training epoch 46:   3%|▎         | 1/31 [00:05<02:45,  5.51s/it, loss=1.2329, batch_acc=0.8438, running_acc=0.8438, grad=10.8877]Training epoch 46:   6%|▋         | 2/31 [00:07<01:31,  3.16s/it, loss=1.2329, batch_acc=0.8438, running_acc=0.8438, grad=10.8877]Training epoch 46:   6%|▋         | 2/31 [00:07<01:31,  3.16s/it, loss=1.6103, batch_acc=0.5938, running_acc=0.7188, grad=12.1237]Training epoch 46:  10%|▉         | 3/31 [00:08<01:08,  2.45s/it, loss=1.6103, batch_acc=0.5938, running_acc=0.7188, grad=12.1237]Training epoch 46:  10%|▉         | 3/31 [00:08<01:08,  2.45s/it, loss=1.1652, batch_acc=0.8125, running_acc=0.7500, grad=11.0436]Training epoch 46:  13%|█▎        | 4/31 [00:10<00:56,  2.08s/it, loss=1.1652, batch_acc=0.8125, running_acc=0.7500, grad=11.0436]Training epoch 46:  13%|█▎        | 4/31 [00:10<00:56,  2.08s/it, loss=1.4376, batch_acc=0.7500, running_acc=0.7500, grad=22.5700]Training epoch 46:  16%|█▌        | 5/31 [00:11<00:48,  1.87s/it, loss=1.4376, batch_acc=0.7500, running_acc=0.7500, grad=22.5700]Training epoch 46:  16%|█▌        | 5/31 [00:11<00:48,  1.87s/it, loss=1.2322, batch_acc=0.8125, running_acc=0.7625, grad=9.5241] Training epoch 46:  19%|█▉        | 6/31 [00:13<00:43,  1.75s/it, loss=1.2322, batch_acc=0.8125, running_acc=0.7625, grad=9.5241]Training epoch 46:  19%|█▉        | 6/31 [00:13<00:43,  1.75s/it, loss=1.3346, batch_acc=0.7500, running_acc=0.7604, grad=5.4670]Training epoch 46:  23%|██▎       | 7/31 [00:14<00:40,  1.67s/it, loss=1.3346, batch_acc=0.7500, running_acc=0.7604, grad=5.4670]Training epoch 46:  23%|██▎       | 7/31 [00:14<00:40,  1.67s/it, loss=1.3143, batch_acc=0.8125, running_acc=0.7679, grad=13.0857]Training epoch 46:  26%|██▌       | 8/31 [00:16<00:37,  1.64s/it, loss=1.3143, batch_acc=0.8125, running_acc=0.7679, grad=13.0857]Training epoch 46:  26%|██▌       | 8/31 [00:16<00:37,  1.64s/it, loss=1.8106, batch_acc=0.5625, running_acc=0.7422, grad=13.6009]Training epoch 46:  29%|██▉       | 9/31 [00:17<00:35,  1.60s/it, loss=1.8106, batch_acc=0.5625, running_acc=0.7422, grad=13.6009]Training epoch 46:  29%|██▉       | 9/31 [00:17<00:35,  1.60s/it, loss=1.3849, batch_acc=0.6875, running_acc=0.7361, grad=8.5759] Training epoch 46:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.3849, batch_acc=0.6875, running_acc=0.7361, grad=8.5759]Training epoch 46:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.4913, batch_acc=0.6562, running_acc=0.7281, grad=9.1688]Training epoch 46:  35%|███▌      | 11/31 [00:20<00:31,  1.55s/it, loss=1.4913, batch_acc=0.6562, running_acc=0.7281, grad=9.1688]Training epoch 46:  35%|███▌      | 11/31 [00:20<00:31,  1.55s/it, loss=1.3378, batch_acc=0.7812, running_acc=0.7330, grad=23.9477]Training epoch 46:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.3378, batch_acc=0.7812, running_acc=0.7330, grad=23.9477]Training epoch 46:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.2981, batch_acc=0.7500, running_acc=0.7344, grad=10.1983]Training epoch 46:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=1.2981, batch_acc=0.7500, running_acc=0.7344, grad=10.1983]Training epoch 46:  42%|████▏     | 13/31 [00:23<00:27,  1.53s/it, loss=1.5996, batch_acc=0.6562, running_acc=0.7284, grad=6.8721] Training epoch 46:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.5996, batch_acc=0.6562, running_acc=0.7284, grad=6.8721]Training epoch 46:  45%|████▌     | 14/31 [00:25<00:25,  1.52s/it, loss=1.3017, batch_acc=0.7812, running_acc=0.7321, grad=9.8988]Training epoch 46:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.3017, batch_acc=0.7812, running_acc=0.7321, grad=9.8988]Training epoch 46:  48%|████▊     | 15/31 [00:26<00:24,  1.52s/it, loss=1.4871, batch_acc=0.6250, running_acc=0.7250, grad=19.1178]Training epoch 46:  52%|█████▏    | 16/31 [00:28<00:22,  1.51s/it, loss=1.4871, batch_acc=0.6250, running_acc=0.7250, grad=19.1178]Training epoch 46:  52%|█████▏    | 16/31 [00:28<00:22,  1.51s/it, loss=1.2574, batch_acc=0.7812, running_acc=0.7285, grad=14.2058]Training epoch 46:  55%|█████▍    | 17/31 [00:29<00:21,  1.51s/it, loss=1.2574, batch_acc=0.7812, running_acc=0.7285, grad=14.2058]Training epoch 46:  55%|█████▍    | 17/31 [00:29<00:21,  1.51s/it, loss=1.5168, batch_acc=0.6875, running_acc=0.7261, grad=18.3993]Training epoch 46:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.5168, batch_acc=0.6875, running_acc=0.7261, grad=18.3993]Training epoch 46:  58%|█████▊    | 18/31 [00:31<00:19,  1.51s/it, loss=1.6007, batch_acc=0.6875, running_acc=0.7240, grad=13.4986]Training epoch 46:  61%|██████▏   | 19/31 [00:32<00:18,  1.51s/it, loss=1.6007, batch_acc=0.6875, running_acc=0.7240, grad=13.4986]Training epoch 46:  61%|██████▏   | 19/31 [00:32<00:18,  1.51s/it, loss=1.4672, batch_acc=0.6562, running_acc=0.7204, grad=35.1642]Training epoch 46:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.4672, batch_acc=0.6562, running_acc=0.7204, grad=35.1642]Training epoch 46:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.2463, batch_acc=0.7500, running_acc=0.7219, grad=17.9029]Training epoch 46:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.2463, batch_acc=0.7500, running_acc=0.7219, grad=17.9029]Training epoch 46:  68%|██████▊   | 21/31 [00:35<00:15,  1.51s/it, loss=1.4449, batch_acc=0.7188, running_acc=0.7217, grad=7.9860] Training epoch 46:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.4449, batch_acc=0.7188, running_acc=0.7217, grad=7.9860]Training epoch 46:  71%|███████   | 22/31 [00:37<00:13,  1.51s/it, loss=1.3971, batch_acc=0.6875, running_acc=0.7202, grad=10.0054]Training epoch 46:  74%|███████▍  | 23/31 [00:38<00:12,  1.51s/it, loss=1.3971, batch_acc=0.6875, running_acc=0.7202, grad=10.0054]Training epoch 46:  74%|███████▍  | 23/31 [00:38<00:12,  1.51s/it, loss=1.3637, batch_acc=0.6250, running_acc=0.7160, grad=24.4998]Training epoch 46:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.3637, batch_acc=0.6250, running_acc=0.7160, grad=24.4998]Training epoch 46:  77%|███████▋  | 24/31 [00:40<00:10,  1.51s/it, loss=1.7582, batch_acc=0.6250, running_acc=0.7122, grad=12.1154]Training epoch 46:  81%|████████  | 25/31 [00:41<00:09,  1.50s/it, loss=1.7582, batch_acc=0.6250, running_acc=0.7122, grad=12.1154]Training epoch 46:  81%|████████  | 25/31 [00:41<00:09,  1.50s/it, loss=1.5176, batch_acc=0.5938, running_acc=0.7075, grad=9.1907] Training epoch 46:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.5176, batch_acc=0.5938, running_acc=0.7075, grad=9.1907]Training epoch 46:  84%|████████▍ | 26/31 [00:43<00:07,  1.51s/it, loss=1.5514, batch_acc=0.6562, running_acc=0.7055, grad=10.6904]Training epoch 46:  87%|████████▋ | 27/31 [00:44<00:06,  1.55s/it, loss=1.5514, batch_acc=0.6562, running_acc=0.7055, grad=10.6904]Training epoch 46:  87%|████████▋ | 27/31 [00:44<00:06,  1.55s/it, loss=1.3493, batch_acc=0.7188, running_acc=0.7060, grad=7.0781] Training epoch 46:  90%|█████████ | 28/31 [00:46<00:04,  1.53s/it, loss=1.3493, batch_acc=0.7188, running_acc=0.7060, grad=7.0781]Training epoch 46:  90%|█████████ | 28/31 [00:46<00:04,  1.53s/it, loss=1.4911, batch_acc=0.7500, running_acc=0.7076, grad=7.7775]Training epoch 46:  94%|█████████▎| 29/31 [00:47<00:03,  1.52s/it, loss=1.4911, batch_acc=0.7500, running_acc=0.7076, grad=7.7775]Training epoch 46:  94%|█████████▎| 29/31 [00:47<00:03,  1.52s/it, loss=1.2891, batch_acc=0.6562, running_acc=0.7058, grad=163.9985]Training epoch 46:  97%|█████████▋| 30/31 [00:49<00:01,  1.52s/it, loss=1.2891, batch_acc=0.6562, running_acc=0.7058, grad=163.9985]Training epoch 46:  97%|█████████▋| 30/31 [00:49<00:01,  1.52s/it, loss=1.3398, batch_acc=0.6562, running_acc=0.7042, grad=28.4222] Training epoch 46: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.3398, batch_acc=0.6562, running_acc=0.7042, grad=28.4222]Training epoch 46: 100%|██████████| 31/31 [00:49<00:00,  1.12s/it, loss=1.5291, batch_acc=0.5000, running_acc=0.7037, grad=16.6237]Training epoch 46: 100%|██████████| 31/31 [00:49<00:00,  1.60s/it, loss=1.5291, batch_acc=0.5000, running_acc=0.7037, grad=16.6237]
Evaluation epoch 46:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 46:  20%|██        | 1/5 [00:04<00:19,  4.87s/it]Evaluation epoch 46:  20%|██        | 1/5 [00:04<00:19,  4.87s/it, loss=1.4614, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 46:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.4614, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 46:  40%|████      | 2/5 [00:05<00:07,  2.44s/it, loss=1.3177, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 46:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.3177, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 46:  60%|██████    | 3/5 [00:06<00:03,  1.67s/it, loss=1.5702, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 46:  80%|████████  | 4/5 [00:07<00:01,  1.58s/it, loss=1.5702, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 46:  80%|████████  | 4/5 [00:07<00:01,  1.58s/it, loss=1.6611, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 46: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=1.6611, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 46: 100%|██████████| 5/5 [00:08<00:00,  1.30s/it, loss=1.8755, batch_acc=0.5625, running_acc=0.6438]Evaluation epoch 46: 100%|██████████| 5/5 [00:08<00:00,  1.72s/it, loss=1.8755, batch_acc=0.5625, running_acc=0.6438]
Training epoch 47:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 47:   3%|▎         | 1/31 [00:09<04:34,  9.14s/it]Training epoch 47:   3%|▎         | 1/31 [00:09<04:34,  9.14s/it, loss=1.4173, batch_acc=0.7812, running_acc=0.7812, grad=16.1459]Training epoch 47:   6%|▋         | 2/31 [00:10<02:14,  4.65s/it, loss=1.4173, batch_acc=0.7812, running_acc=0.7812, grad=16.1459]Training epoch 47:   6%|▋         | 2/31 [00:10<02:14,  4.65s/it, loss=1.6386, batch_acc=0.5938, running_acc=0.6875, grad=10.4032]Training epoch 47:  10%|▉         | 3/31 [00:12<01:29,  3.21s/it, loss=1.6386, batch_acc=0.5938, running_acc=0.6875, grad=10.4032]Training epoch 47:  10%|▉         | 3/31 [00:12<01:29,  3.21s/it, loss=1.2990, batch_acc=0.6562, running_acc=0.6771, grad=17.2118]Training epoch 47:  13%|█▎        | 4/31 [00:13<01:08,  2.54s/it, loss=1.2990, batch_acc=0.6562, running_acc=0.6771, grad=17.2118]Training epoch 47:  13%|█▎        | 4/31 [00:13<01:08,  2.54s/it, loss=1.5125, batch_acc=0.6250, running_acc=0.6641, grad=12.4381]Training epoch 47:  16%|█▌        | 5/31 [00:15<00:56,  2.17s/it, loss=1.5125, batch_acc=0.6250, running_acc=0.6641, grad=12.4381]Training epoch 47:  16%|█▌        | 5/31 [00:15<00:56,  2.17s/it, loss=1.6367, batch_acc=0.5625, running_acc=0.6438, grad=17.4443]Training epoch 47:  19%|█▉        | 6/31 [00:16<00:48,  1.94s/it, loss=1.6367, batch_acc=0.5625, running_acc=0.6438, grad=17.4443]Training epoch 47:  19%|█▉        | 6/31 [00:16<00:48,  1.94s/it, loss=1.3345, batch_acc=0.7500, running_acc=0.6615, grad=7.5473] Training epoch 47:  23%|██▎       | 7/31 [00:18<00:43,  1.80s/it, loss=1.3345, batch_acc=0.7500, running_acc=0.6615, grad=7.5473]Training epoch 47:  23%|██▎       | 7/31 [00:18<00:43,  1.80s/it, loss=1.3624, batch_acc=0.6562, running_acc=0.6607, grad=18.7720]Training epoch 47:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=1.3624, batch_acc=0.6562, running_acc=0.6607, grad=18.7720]Training epoch 47:  26%|██▌       | 8/31 [00:19<00:39,  1.71s/it, loss=1.5832, batch_acc=0.5625, running_acc=0.6484, grad=14.4534]Training epoch 47:  29%|██▉       | 9/31 [00:21<00:36,  1.64s/it, loss=1.5832, batch_acc=0.5625, running_acc=0.6484, grad=14.4534]Training epoch 47:  29%|██▉       | 9/31 [00:21<00:36,  1.64s/it, loss=1.6086, batch_acc=0.5625, running_acc=0.6389, grad=33.0804]Training epoch 47:  32%|███▏      | 10/31 [00:22<00:33,  1.61s/it, loss=1.6086, batch_acc=0.5625, running_acc=0.6389, grad=33.0804]Training epoch 47:  32%|███▏      | 10/31 [00:22<00:33,  1.61s/it, loss=1.2380, batch_acc=0.7812, running_acc=0.6531, grad=7.1616] Training epoch 47:  35%|███▌      | 11/31 [00:24<00:31,  1.58s/it, loss=1.2380, batch_acc=0.7812, running_acc=0.6531, grad=7.1616]Training epoch 47:  35%|███▌      | 11/31 [00:24<00:31,  1.58s/it, loss=1.2460, batch_acc=0.8125, running_acc=0.6676, grad=13.0097]Training epoch 47:  39%|███▊      | 12/31 [00:26<00:33,  1.76s/it, loss=1.2460, batch_acc=0.8125, running_acc=0.6676, grad=13.0097]Training epoch 47:  39%|███▊      | 12/31 [00:26<00:33,  1.76s/it, loss=1.2218, batch_acc=0.7812, running_acc=0.6771, grad=10.7582]Training epoch 47:  42%|████▏     | 13/31 [00:27<00:30,  1.68s/it, loss=1.2218, batch_acc=0.7812, running_acc=0.6771, grad=10.7582]Training epoch 47:  42%|████▏     | 13/31 [00:27<00:30,  1.68s/it, loss=1.3262, batch_acc=0.7500, running_acc=0.6827, grad=14.4348]Training epoch 47:  45%|████▌     | 14/31 [00:29<00:27,  1.63s/it, loss=1.3262, batch_acc=0.7500, running_acc=0.6827, grad=14.4348]Training epoch 47:  45%|████▌     | 14/31 [00:29<00:27,  1.63s/it, loss=1.1248, batch_acc=0.8438, running_acc=0.6942, grad=6.8476] Training epoch 47:  48%|████▊     | 15/31 [00:30<00:25,  1.59s/it, loss=1.1248, batch_acc=0.8438, running_acc=0.6942, grad=6.8476]Training epoch 47:  48%|████▊     | 15/31 [00:30<00:25,  1.59s/it, loss=1.3263, batch_acc=0.6562, running_acc=0.6917, grad=12.6039]Training epoch 47:  52%|█████▏    | 16/31 [00:32<00:23,  1.57s/it, loss=1.3263, batch_acc=0.6562, running_acc=0.6917, grad=12.6039]Training epoch 47:  52%|█████▏    | 16/31 [00:32<00:23,  1.57s/it, loss=1.3554, batch_acc=0.6562, running_acc=0.6895, grad=21.8731]Training epoch 47:  55%|█████▍    | 17/31 [00:33<00:21,  1.55s/it, loss=1.3554, batch_acc=0.6562, running_acc=0.6895, grad=21.8731]Training epoch 47:  55%|█████▍    | 17/31 [00:33<00:21,  1.55s/it, loss=1.5234, batch_acc=0.7188, running_acc=0.6912, grad=10.8626]Training epoch 47:  58%|█████▊    | 18/31 [00:35<00:20,  1.54s/it, loss=1.5234, batch_acc=0.7188, running_acc=0.6912, grad=10.8626]Training epoch 47:  58%|█████▊    | 18/31 [00:35<00:20,  1.54s/it, loss=1.3119, batch_acc=0.8438, running_acc=0.6997, grad=9.6248] Training epoch 47:  61%|██████▏   | 19/31 [00:36<00:18,  1.53s/it, loss=1.3119, batch_acc=0.8438, running_acc=0.6997, grad=9.6248]Training epoch 47:  61%|██████▏   | 19/31 [00:36<00:18,  1.53s/it, loss=1.3693, batch_acc=0.7500, running_acc=0.7023, grad=13.0283]Training epoch 47:  65%|██████▍   | 20/31 [00:38<00:16,  1.53s/it, loss=1.3693, batch_acc=0.7500, running_acc=0.7023, grad=13.0283]Training epoch 47:  65%|██████▍   | 20/31 [00:38<00:16,  1.53s/it, loss=1.5153, batch_acc=0.6875, running_acc=0.7016, grad=19.5640]Training epoch 47:  68%|██████▊   | 21/31 [00:45<00:31,  3.11s/it, loss=1.5153, batch_acc=0.6875, running_acc=0.7016, grad=19.5640]Training epoch 47:  68%|██████▊   | 21/31 [00:45<00:31,  3.11s/it, loss=1.3552, batch_acc=0.6875, running_acc=0.7009, grad=10.0868]Training epoch 47:  71%|███████   | 22/31 [00:46<00:23,  2.63s/it, loss=1.3552, batch_acc=0.6875, running_acc=0.7009, grad=10.0868]Training epoch 47:  71%|███████   | 22/31 [00:46<00:23,  2.63s/it, loss=1.5745, batch_acc=0.5938, running_acc=0.6960, grad=12.2869]Training epoch 47:  74%|███████▍  | 23/31 [00:48<00:18,  2.29s/it, loss=1.5745, batch_acc=0.5938, running_acc=0.6960, grad=12.2869]Training epoch 47:  74%|███████▍  | 23/31 [00:48<00:18,  2.29s/it, loss=1.6876, batch_acc=0.6875, running_acc=0.6957, grad=16.0538]Training epoch 47:  77%|███████▋  | 24/31 [00:49<00:14,  2.06s/it, loss=1.6876, batch_acc=0.6875, running_acc=0.6957, grad=16.0538]Training epoch 47:  77%|███████▋  | 24/31 [00:49<00:14,  2.06s/it, loss=1.0455, batch_acc=0.8438, running_acc=0.7018, grad=14.1509]Training epoch 47:  81%|████████  | 25/31 [00:51<00:12,  2.08s/it, loss=1.0455, batch_acc=0.8438, running_acc=0.7018, grad=14.1509]Training epoch 47:  81%|████████  | 25/31 [00:51<00:12,  2.08s/it, loss=1.2788, batch_acc=0.8125, running_acc=0.7063, grad=9.7075] Training epoch 47:  84%|████████▍ | 26/31 [00:53<00:09,  1.91s/it, loss=1.2788, batch_acc=0.8125, running_acc=0.7063, grad=9.7075]Training epoch 47:  84%|████████▍ | 26/31 [00:53<00:09,  1.91s/it, loss=1.2935, batch_acc=0.6875, running_acc=0.7055, grad=12.8474]Training epoch 47:  87%|████████▋ | 27/31 [00:55<00:08,  2.02s/it, loss=1.2935, batch_acc=0.6875, running_acc=0.7055, grad=12.8474]Training epoch 47:  87%|████████▋ | 27/31 [00:55<00:08,  2.02s/it, loss=1.7952, batch_acc=0.6875, running_acc=0.7049, grad=10.8151]Training epoch 47:  90%|█████████ | 28/31 [00:57<00:05,  1.87s/it, loss=1.7952, batch_acc=0.6875, running_acc=0.7049, grad=10.8151]Training epoch 47:  90%|█████████ | 28/31 [00:57<00:05,  1.87s/it, loss=1.4305, batch_acc=0.6875, running_acc=0.7042, grad=9.6338] Training epoch 47:  94%|█████████▎| 29/31 [00:59<00:04,  2.10s/it, loss=1.4305, batch_acc=0.6875, running_acc=0.7042, grad=9.6338]Training epoch 47:  94%|█████████▎| 29/31 [00:59<00:04,  2.10s/it, loss=1.5923, batch_acc=0.6875, running_acc=0.7037, grad=10.4932]Training epoch 47:  97%|█████████▋| 30/31 [01:01<00:01,  1.92s/it, loss=1.5923, batch_acc=0.6875, running_acc=0.7037, grad=10.4932]Training epoch 47:  97%|█████████▋| 30/31 [01:01<00:01,  1.92s/it, loss=1.3919, batch_acc=0.6250, running_acc=0.7010, grad=8.5341] Training epoch 47: 100%|██████████| 31/31 [01:01<00:00,  1.41s/it, loss=1.3919, batch_acc=0.6250, running_acc=0.7010, grad=8.5341]Training epoch 47: 100%|██████████| 31/31 [01:01<00:00,  1.41s/it, loss=1.4762, batch_acc=1.0000, running_acc=0.7017, grad=24.2382]Training epoch 47: 100%|██████████| 31/31 [01:01<00:00,  1.99s/it, loss=1.4762, batch_acc=1.0000, running_acc=0.7017, grad=24.2382]
Evaluation epoch 47:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 47:  20%|██        | 1/5 [00:13<00:52, 13.08s/it]Evaluation epoch 47:  20%|██        | 1/5 [00:13<00:52, 13.08s/it, loss=1.4467, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 47:  40%|████      | 2/5 [00:13<00:17,  5.83s/it, loss=1.4467, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 47:  40%|████      | 2/5 [00:13<00:17,  5.83s/it, loss=1.3135, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 47:  60%|██████    | 3/5 [00:17<00:09,  4.95s/it, loss=1.3135, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 47:  60%|██████    | 3/5 [00:17<00:09,  4.95s/it, loss=1.5766, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 47:  80%|████████  | 4/5 [00:18<00:03,  3.29s/it, loss=1.5766, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 47:  80%|████████  | 4/5 [00:18<00:03,  3.29s/it, loss=1.6638, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 47: 100%|██████████| 5/5 [00:19<00:00,  2.38s/it, loss=1.6638, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 47: 100%|██████████| 5/5 [00:19<00:00,  2.38s/it, loss=1.8750, batch_acc=0.5625, running_acc=0.6438]Evaluation epoch 47: 100%|██████████| 5/5 [00:19<00:00,  3.85s/it, loss=1.8750, batch_acc=0.5625, running_acc=0.6438]
Training epoch 48:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 48:   3%|▎         | 1/31 [00:08<04:18,  8.63s/it]Training epoch 48:   3%|▎         | 1/31 [00:08<04:18,  8.63s/it, loss=1.4769, batch_acc=0.7812, running_acc=0.7812, grad=9.3044]Training epoch 48:   6%|▋         | 2/31 [00:10<02:08,  4.44s/it, loss=1.4769, batch_acc=0.7812, running_acc=0.7812, grad=9.3044]Training epoch 48:   6%|▋         | 2/31 [00:10<02:08,  4.44s/it, loss=1.6499, batch_acc=0.5938, running_acc=0.6875, grad=6.0604]Training epoch 48:  10%|▉         | 3/31 [00:11<01:26,  3.10s/it, loss=1.6499, batch_acc=0.5938, running_acc=0.6875, grad=6.0604]Training epoch 48:  10%|▉         | 3/31 [00:11<01:26,  3.10s/it, loss=1.3858, batch_acc=0.6562, running_acc=0.6771, grad=10.4727]Training epoch 48:  13%|█▎        | 4/31 [00:13<01:06,  2.47s/it, loss=1.3858, batch_acc=0.6562, running_acc=0.6771, grad=10.4727]Training epoch 48:  13%|█▎        | 4/31 [00:13<01:06,  2.47s/it, loss=1.2594, batch_acc=0.7812, running_acc=0.7031, grad=11.4579]Training epoch 48:  16%|█▌        | 5/31 [00:15<01:03,  2.43s/it, loss=1.2594, batch_acc=0.7812, running_acc=0.7031, grad=11.4579]Training epoch 48:  16%|█▌        | 5/31 [00:15<01:03,  2.43s/it, loss=1.3129, batch_acc=0.8125, running_acc=0.7250, grad=13.8098]Training epoch 48:  19%|█▉        | 6/31 [00:17<00:53,  2.12s/it, loss=1.3129, batch_acc=0.8125, running_acc=0.7250, grad=13.8098]Training epoch 48:  19%|█▉        | 6/31 [00:17<00:53,  2.12s/it, loss=1.2791, batch_acc=0.7812, running_acc=0.7344, grad=7.3633] Training epoch 48:  23%|██▎       | 7/31 [00:18<00:46,  1.92s/it, loss=1.2791, batch_acc=0.7812, running_acc=0.7344, grad=7.3633]Training epoch 48:  23%|██▎       | 7/31 [00:18<00:46,  1.92s/it, loss=1.4842, batch_acc=0.6562, running_acc=0.7232, grad=21.1944]Training epoch 48:  26%|██▌       | 8/31 [00:20<00:41,  1.79s/it, loss=1.4842, batch_acc=0.6562, running_acc=0.7232, grad=21.1944]Training epoch 48:  26%|██▌       | 8/31 [00:20<00:41,  1.79s/it, loss=1.5857, batch_acc=0.5938, running_acc=0.7070, grad=9.8584] Training epoch 48:  29%|██▉       | 9/31 [00:21<00:37,  1.70s/it, loss=1.5857, batch_acc=0.5938, running_acc=0.7070, grad=9.8584]Training epoch 48:  29%|██▉       | 9/31 [00:21<00:37,  1.70s/it, loss=1.5270, batch_acc=0.5938, running_acc=0.6944, grad=10.8968]Training epoch 48:  32%|███▏      | 10/31 [00:23<00:34,  1.64s/it, loss=1.5270, batch_acc=0.5938, running_acc=0.6944, grad=10.8968]Training epoch 48:  32%|███▏      | 10/31 [00:23<00:34,  1.64s/it, loss=1.1899, batch_acc=0.7812, running_acc=0.7031, grad=8.0713] Training epoch 48:  35%|███▌      | 11/31 [00:24<00:32,  1.60s/it, loss=1.1899, batch_acc=0.7812, running_acc=0.7031, grad=8.0713]Training epoch 48:  35%|███▌      | 11/31 [00:24<00:32,  1.60s/it, loss=1.6580, batch_acc=0.5938, running_acc=0.6932, grad=5.6570]Training epoch 48:  39%|███▊      | 12/31 [00:26<00:29,  1.57s/it, loss=1.6580, batch_acc=0.5938, running_acc=0.6932, grad=5.6570]Training epoch 48:  39%|███▊      | 12/31 [00:26<00:29,  1.57s/it, loss=1.4256, batch_acc=0.7500, running_acc=0.6979, grad=10.7558]Training epoch 48:  42%|████▏     | 13/31 [00:27<00:27,  1.55s/it, loss=1.4256, batch_acc=0.7500, running_acc=0.6979, grad=10.7558]Training epoch 48:  42%|████▏     | 13/31 [00:27<00:27,  1.55s/it, loss=1.4204, batch_acc=0.7188, running_acc=0.6995, grad=9.2819] Training epoch 48:  45%|████▌     | 14/31 [00:29<00:26,  1.54s/it, loss=1.4204, batch_acc=0.7188, running_acc=0.6995, grad=9.2819]Training epoch 48:  45%|████▌     | 14/31 [00:29<00:26,  1.54s/it, loss=1.5557, batch_acc=0.5938, running_acc=0.6920, grad=9.2346]Training epoch 48:  48%|████▊     | 15/31 [00:32<00:32,  2.06s/it, loss=1.5557, batch_acc=0.5938, running_acc=0.6920, grad=9.2346]Training epoch 48:  48%|████▊     | 15/31 [00:32<00:32,  2.06s/it, loss=1.6799, batch_acc=0.5625, running_acc=0.6833, grad=9.9478]Training epoch 48:  52%|█████▏    | 16/31 [00:33<00:28,  1.89s/it, loss=1.6799, batch_acc=0.5625, running_acc=0.6833, grad=9.9478]Training epoch 48:  52%|█████▏    | 16/31 [00:33<00:28,  1.89s/it, loss=1.5171, batch_acc=0.6875, running_acc=0.6836, grad=19.8868]Training epoch 48:  55%|█████▍    | 17/31 [00:36<00:28,  2.04s/it, loss=1.5171, batch_acc=0.6875, running_acc=0.6836, grad=19.8868]Training epoch 48:  55%|█████▍    | 17/31 [00:36<00:28,  2.04s/it, loss=1.1612, batch_acc=0.7188, running_acc=0.6857, grad=8.3432] Training epoch 48:  58%|█████▊    | 18/31 [00:37<00:24,  1.88s/it, loss=1.1612, batch_acc=0.7188, running_acc=0.6857, grad=8.3432]Training epoch 48:  58%|█████▊    | 18/31 [00:37<00:24,  1.88s/it, loss=1.2360, batch_acc=0.8125, running_acc=0.6927, grad=11.9158]Training epoch 48:  61%|██████▏   | 19/31 [00:39<00:21,  1.80s/it, loss=1.2360, batch_acc=0.8125, running_acc=0.6927, grad=11.9158]Training epoch 48:  61%|██████▏   | 19/31 [00:39<00:21,  1.80s/it, loss=1.3128, batch_acc=0.7500, running_acc=0.6957, grad=8.8287] Training epoch 48:  65%|██████▍   | 20/31 [00:42<00:25,  2.34s/it, loss=1.3128, batch_acc=0.7500, running_acc=0.6957, grad=8.8287]Training epoch 48:  65%|██████▍   | 20/31 [00:42<00:25,  2.34s/it, loss=1.3695, batch_acc=0.6875, running_acc=0.6953, grad=6.7425]Training epoch 48:  68%|██████▊   | 21/31 [00:46<00:27,  2.74s/it, loss=1.3695, batch_acc=0.6875, running_acc=0.6953, grad=6.7425]Training epoch 48:  68%|██████▊   | 21/31 [00:46<00:27,  2.74s/it, loss=1.3852, batch_acc=0.6562, running_acc=0.6935, grad=11.0962]Training epoch 48:  71%|███████   | 22/31 [00:48<00:21,  2.37s/it, loss=1.3852, batch_acc=0.6562, running_acc=0.6935, grad=11.0962]Training epoch 48:  71%|███████   | 22/31 [00:48<00:21,  2.37s/it, loss=1.2825, batch_acc=0.7188, running_acc=0.6946, grad=20.5347]Training epoch 48:  74%|███████▍  | 23/31 [00:49<00:16,  2.11s/it, loss=1.2825, batch_acc=0.7188, running_acc=0.6946, grad=20.5347]Training epoch 48:  74%|███████▍  | 23/31 [00:49<00:16,  2.11s/it, loss=1.4044, batch_acc=0.7500, running_acc=0.6970, grad=12.8804]Training epoch 48:  77%|███████▋  | 24/31 [00:54<00:19,  2.79s/it, loss=1.4044, batch_acc=0.7500, running_acc=0.6970, grad=12.8804]Training epoch 48:  77%|███████▋  | 24/31 [00:54<00:19,  2.79s/it, loss=1.2182, batch_acc=0.8750, running_acc=0.7044, grad=25.1393]Training epoch 48:  81%|████████  | 25/31 [01:00<00:23,  3.87s/it, loss=1.2182, batch_acc=0.8750, running_acc=0.7044, grad=25.1393]Training epoch 48:  81%|████████  | 25/31 [01:00<00:23,  3.87s/it, loss=1.3202, batch_acc=0.7500, running_acc=0.7063, grad=6.6886] Training epoch 48:  84%|████████▍ | 26/31 [01:01<00:15,  3.16s/it, loss=1.3202, batch_acc=0.7500, running_acc=0.7063, grad=6.6886]Training epoch 48:  84%|████████▍ | 26/31 [01:01<00:15,  3.16s/it, loss=1.3995, batch_acc=0.6875, running_acc=0.7055, grad=11.7964]Training epoch 48:  87%|████████▋ | 27/31 [01:03<00:10,  2.67s/it, loss=1.3995, batch_acc=0.6875, running_acc=0.7055, grad=11.7964]Training epoch 48:  87%|████████▋ | 27/31 [01:03<00:10,  2.67s/it, loss=1.6502, batch_acc=0.6562, running_acc=0.7037, grad=15.8386]Training epoch 48:  90%|█████████ | 28/31 [01:04<00:06,  2.32s/it, loss=1.6502, batch_acc=0.6562, running_acc=0.7037, grad=15.8386]Training epoch 48:  90%|█████████ | 28/31 [01:04<00:06,  2.32s/it, loss=1.3658, batch_acc=0.6562, running_acc=0.7020, grad=9.7692] Training epoch 48:  94%|█████████▎| 29/31 [01:06<00:04,  2.08s/it, loss=1.3658, batch_acc=0.6562, running_acc=0.7020, grad=9.7692]Training epoch 48:  94%|█████████▎| 29/31 [01:06<00:04,  2.08s/it, loss=1.2499, batch_acc=0.8438, running_acc=0.7069, grad=21.7663]Training epoch 48:  97%|█████████▋| 30/31 [01:07<00:01,  1.90s/it, loss=1.2499, batch_acc=0.8438, running_acc=0.7069, grad=21.7663]Training epoch 48:  97%|█████████▋| 30/31 [01:07<00:01,  1.90s/it, loss=1.5438, batch_acc=0.6250, running_acc=0.7042, grad=7.5910] Training epoch 48: 100%|██████████| 31/31 [01:08<00:00,  1.40s/it, loss=1.5438, batch_acc=0.6250, running_acc=0.7042, grad=7.5910]Training epoch 48: 100%|██████████| 31/31 [01:08<00:00,  1.40s/it, loss=1.6451, batch_acc=0.5000, running_acc=0.7037, grad=37.0902]Training epoch 48: 100%|██████████| 31/31 [01:08<00:00,  2.20s/it, loss=1.6451, batch_acc=0.5000, running_acc=0.7037, grad=37.0902]
Evaluation epoch 48:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 48:  20%|██        | 1/5 [00:08<00:33,  8.45s/it]Evaluation epoch 48:  20%|██        | 1/5 [00:08<00:33,  8.45s/it, loss=1.4584, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 48:  40%|████      | 2/5 [00:09<00:11,  3.92s/it, loss=1.4584, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 48:  40%|████      | 2/5 [00:09<00:11,  3.92s/it, loss=1.3171, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 48:  60%|██████    | 3/5 [00:09<00:04,  2.47s/it, loss=1.3171, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 48:  60%|██████    | 3/5 [00:09<00:04,  2.47s/it, loss=1.5945, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 48:  80%|████████  | 4/5 [00:14<00:03,  3.21s/it, loss=1.5945, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 48:  80%|████████  | 4/5 [00:14<00:03,  3.21s/it, loss=1.6701, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 48: 100%|██████████| 5/5 [00:15<00:00,  2.34s/it, loss=1.6701, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 48: 100%|██████████| 5/5 [00:15<00:00,  2.34s/it, loss=1.8813, batch_acc=0.5625, running_acc=0.6438]Evaluation epoch 48: 100%|██████████| 5/5 [00:15<00:00,  3.02s/it, loss=1.8813, batch_acc=0.5625, running_acc=0.6438]
Training epoch 49:   0%|          | 0/31 [00:00<?, ?it/s]Training epoch 49:   3%|▎         | 1/31 [00:05<02:52,  5.75s/it]Training epoch 49:   3%|▎         | 1/31 [00:05<02:52,  5.75s/it, loss=1.4468, batch_acc=0.6875, running_acc=0.6875, grad=6.0491]Training epoch 49:   6%|▋         | 2/31 [00:07<01:36,  3.31s/it, loss=1.4468, batch_acc=0.6875, running_acc=0.6875, grad=6.0491]Training epoch 49:   6%|▋         | 2/31 [00:07<01:36,  3.31s/it, loss=1.9253, batch_acc=0.5312, running_acc=0.6094, grad=31.4440]Training epoch 49:  10%|▉         | 3/31 [00:08<01:09,  2.49s/it, loss=1.9253, batch_acc=0.5312, running_acc=0.6094, grad=31.4440]Training epoch 49:  10%|▉         | 3/31 [00:08<01:09,  2.49s/it, loss=1.3606, batch_acc=0.7500, running_acc=0.6562, grad=13.7491]Training epoch 49:  13%|█▎        | 4/31 [00:10<00:56,  2.11s/it, loss=1.3606, batch_acc=0.7500, running_acc=0.6562, grad=13.7491]Training epoch 49:  13%|█▎        | 4/31 [00:10<00:56,  2.11s/it, loss=1.4009, batch_acc=0.6562, running_acc=0.6562, grad=12.8228]Training epoch 49:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=1.4009, batch_acc=0.6562, running_acc=0.6562, grad=12.8228]Training epoch 49:  16%|█▌        | 5/31 [00:11<00:49,  1.89s/it, loss=1.2057, batch_acc=0.8750, running_acc=0.7000, grad=8.5336] Training epoch 49:  19%|█▉        | 6/31 [00:13<00:44,  1.76s/it, loss=1.2057, batch_acc=0.8750, running_acc=0.7000, grad=8.5336]Training epoch 49:  19%|█▉        | 6/31 [00:13<00:44,  1.76s/it, loss=1.2864, batch_acc=0.7500, running_acc=0.7083, grad=6.6662]Training epoch 49:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.2864, batch_acc=0.7500, running_acc=0.7083, grad=6.6662]Training epoch 49:  23%|██▎       | 7/31 [00:14<00:40,  1.68s/it, loss=1.5771, batch_acc=0.6562, running_acc=0.7009, grad=11.3887]Training epoch 49:  26%|██▌       | 8/31 [00:16<00:37,  1.63s/it, loss=1.5771, batch_acc=0.6562, running_acc=0.7009, grad=11.3887]Training epoch 49:  26%|██▌       | 8/31 [00:16<00:37,  1.63s/it, loss=1.2622, batch_acc=0.7188, running_acc=0.7031, grad=9.7723] Training epoch 49:  29%|██▉       | 9/31 [00:17<00:35,  1.59s/it, loss=1.2622, batch_acc=0.7188, running_acc=0.7031, grad=9.7723]Training epoch 49:  29%|██▉       | 9/31 [00:17<00:35,  1.59s/it, loss=1.2491, batch_acc=0.7188, running_acc=0.7049, grad=14.5164]Training epoch 49:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.2491, batch_acc=0.7188, running_acc=0.7049, grad=14.5164]Training epoch 49:  32%|███▏      | 10/31 [00:19<00:32,  1.57s/it, loss=1.4689, batch_acc=0.7500, running_acc=0.7094, grad=24.0896]Training epoch 49:  35%|███▌      | 11/31 [00:20<00:30,  1.55s/it, loss=1.4689, batch_acc=0.7500, running_acc=0.7094, grad=24.0896]Training epoch 49:  35%|███▌      | 11/31 [00:20<00:30,  1.55s/it, loss=1.4686, batch_acc=0.6875, running_acc=0.7074, grad=13.5541]Training epoch 49:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.4686, batch_acc=0.6875, running_acc=0.7074, grad=13.5541]Training epoch 49:  39%|███▊      | 12/31 [00:22<00:29,  1.54s/it, loss=1.5446, batch_acc=0.6875, running_acc=0.7057, grad=6.2237] Training epoch 49:  42%|████▏     | 13/31 [00:24<00:28,  1.56s/it, loss=1.5446, batch_acc=0.6875, running_acc=0.7057, grad=6.2237]Training epoch 49:  42%|████▏     | 13/31 [00:24<00:28,  1.56s/it, loss=1.3512, batch_acc=0.7812, running_acc=0.7115, grad=17.7798]Training epoch 49:  45%|████▌     | 14/31 [00:25<00:26,  1.54s/it, loss=1.3512, batch_acc=0.7812, running_acc=0.7115, grad=17.7798]Training epoch 49:  45%|████▌     | 14/31 [00:25<00:26,  1.54s/it, loss=1.3228, batch_acc=0.6875, running_acc=0.7098, grad=9.6053] Training epoch 49:  48%|████▊     | 15/31 [00:27<00:24,  1.53s/it, loss=1.3228, batch_acc=0.6875, running_acc=0.7098, grad=9.6053]Training epoch 49:  48%|████▊     | 15/31 [00:27<00:24,  1.53s/it, loss=1.4084, batch_acc=0.6875, running_acc=0.7083, grad=10.1132]Training epoch 49:  52%|█████▏    | 16/31 [00:28<00:22,  1.53s/it, loss=1.4084, batch_acc=0.6875, running_acc=0.7083, grad=10.1132]Training epoch 49:  52%|█████▏    | 16/31 [00:28<00:22,  1.53s/it, loss=1.5274, batch_acc=0.6250, running_acc=0.7031, grad=12.7627]Training epoch 49:  55%|█████▍    | 17/31 [00:30<00:21,  1.52s/it, loss=1.5274, batch_acc=0.6250, running_acc=0.7031, grad=12.7627]Training epoch 49:  55%|█████▍    | 17/31 [00:30<00:21,  1.52s/it, loss=1.3118, batch_acc=0.7500, running_acc=0.7059, grad=17.3399]Training epoch 49:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=1.3118, batch_acc=0.7500, running_acc=0.7059, grad=17.3399]Training epoch 49:  58%|█████▊    | 18/31 [00:31<00:19,  1.52s/it, loss=1.3508, batch_acc=0.7188, running_acc=0.7066, grad=6.6790] Training epoch 49:  61%|██████▏   | 19/31 [00:33<00:18,  1.51s/it, loss=1.3508, batch_acc=0.7188, running_acc=0.7066, grad=6.6790]Training epoch 49:  61%|██████▏   | 19/31 [00:33<00:18,  1.51s/it, loss=1.3727, batch_acc=0.6562, running_acc=0.7039, grad=7.9818]Training epoch 49:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.3727, batch_acc=0.6562, running_acc=0.7039, grad=7.9818]Training epoch 49:  65%|██████▍   | 20/31 [00:34<00:16,  1.51s/it, loss=1.2606, batch_acc=0.8438, running_acc=0.7109, grad=18.8051]Training epoch 49:  68%|██████▊   | 21/31 [00:36<00:16,  1.65s/it, loss=1.2606, batch_acc=0.8438, running_acc=0.7109, grad=18.8051]Training epoch 49:  68%|██████▊   | 21/31 [00:36<00:16,  1.65s/it, loss=1.2475, batch_acc=0.7812, running_acc=0.7143, grad=12.2538]Training epoch 49:  71%|███████   | 22/31 [00:38<00:14,  1.60s/it, loss=1.2475, batch_acc=0.7812, running_acc=0.7143, grad=12.2538]Training epoch 49:  71%|███████   | 22/31 [00:38<00:14,  1.60s/it, loss=1.2138, batch_acc=0.8438, running_acc=0.7202, grad=19.2613]Training epoch 49:  74%|███████▍  | 23/31 [00:39<00:12,  1.58s/it, loss=1.2138, batch_acc=0.8438, running_acc=0.7202, grad=19.2613]Training epoch 49:  74%|███████▍  | 23/31 [00:39<00:12,  1.58s/it, loss=1.5211, batch_acc=0.5938, running_acc=0.7147, grad=37.8505]Training epoch 49:  77%|███████▋  | 24/31 [00:43<00:15,  2.18s/it, loss=1.5211, batch_acc=0.5938, running_acc=0.7147, grad=37.8505]Training epoch 49:  77%|███████▋  | 24/31 [00:43<00:15,  2.18s/it, loss=1.4153, batch_acc=0.6875, running_acc=0.7135, grad=13.3954]Training epoch 49:  81%|████████  | 25/31 [00:44<00:11,  1.98s/it, loss=1.4153, batch_acc=0.6875, running_acc=0.7135, grad=13.3954]Training epoch 49:  81%|████████  | 25/31 [00:44<00:11,  1.98s/it, loss=1.5041, batch_acc=0.5625, running_acc=0.7075, grad=6.7946] Training epoch 49:  84%|████████▍ | 26/31 [00:46<00:09,  1.84s/it, loss=1.5041, batch_acc=0.5625, running_acc=0.7075, grad=6.7946]Training epoch 49:  84%|████████▍ | 26/31 [00:46<00:09,  1.84s/it, loss=1.2700, batch_acc=0.7500, running_acc=0.7091, grad=14.4746]Training epoch 49:  87%|████████▋ | 27/31 [00:49<00:09,  2.36s/it, loss=1.2700, batch_acc=0.7500, running_acc=0.7091, grad=14.4746]Training epoch 49:  87%|████████▋ | 27/31 [00:49<00:09,  2.36s/it, loss=1.4314, batch_acc=0.7188, running_acc=0.7095, grad=13.6641]Training epoch 49:  90%|█████████ | 28/31 [00:54<00:09,  3.05s/it, loss=1.4314, batch_acc=0.7188, running_acc=0.7095, grad=13.6641]Training epoch 49:  90%|█████████ | 28/31 [00:54<00:09,  3.05s/it, loss=1.9324, batch_acc=0.5312, running_acc=0.7031, grad=9.8692] Training epoch 49:  94%|█████████▎| 29/31 [00:55<00:05,  2.59s/it, loss=1.9324, batch_acc=0.5312, running_acc=0.7031, grad=9.8692]Training epoch 49:  94%|█████████▎| 29/31 [00:55<00:05,  2.59s/it, loss=1.3080, batch_acc=0.7500, running_acc=0.7047, grad=9.4582]Training epoch 49:  97%|█████████▋| 30/31 [00:57<00:02,  2.26s/it, loss=1.3080, batch_acc=0.7500, running_acc=0.7047, grad=9.4582]Training epoch 49:  97%|█████████▋| 30/31 [00:57<00:02,  2.26s/it, loss=1.2771, batch_acc=0.7500, running_acc=0.7063, grad=8.4331]Training epoch 49: 100%|██████████| 31/31 [00:57<00:00,  1.64s/it, loss=1.2771, batch_acc=0.7500, running_acc=0.7063, grad=8.4331]Training epoch 49: 100%|██████████| 31/31 [00:57<00:00,  1.64s/it, loss=2.0482, batch_acc=0.0000, running_acc=0.7048, grad=22.7532]Training epoch 49: 100%|██████████| 31/31 [00:57<00:00,  1.86s/it, loss=2.0482, batch_acc=0.0000, running_acc=0.7048, grad=22.7532]
Evaluation epoch 49:   0%|          | 0/5 [00:00<?, ?it/s]Evaluation epoch 49:  20%|██        | 1/5 [00:04<00:19,  4.82s/it]Evaluation epoch 49:  20%|██        | 1/5 [00:04<00:19,  4.82s/it, loss=1.4568, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 49:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.4568, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 49:  40%|████      | 2/5 [00:05<00:07,  2.42s/it, loss=1.3181, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 49:  60%|██████    | 3/5 [00:06<00:03,  1.66s/it, loss=1.3181, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 49:  60%|██████    | 3/5 [00:06<00:03,  1.66s/it, loss=1.5832, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 49:  80%|████████  | 4/5 [00:10<00:02,  2.51s/it, loss=1.5832, batch_acc=0.5625, running_acc=0.6771]Evaluation epoch 49:  80%|████████  | 4/5 [00:10<00:02,  2.51s/it, loss=1.6647, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 49: 100%|██████████| 5/5 [00:10<00:00,  1.89s/it, loss=1.6647, batch_acc=0.6250, running_acc=0.6641]Evaluation epoch 49: 100%|██████████| 5/5 [00:10<00:00,  1.89s/it, loss=1.8902, batch_acc=0.5625, running_acc=0.6438]Evaluation epoch 49: 100%|██████████| 5/5 [00:10<00:00,  2.19s/it, loss=1.8902, batch_acc=0.5625, running_acc=0.6438]
Evaluation epoch 49:   0%|          | 0/6 [00:00<?, ?it/s]Evaluation epoch 49:  17%|█▋        | 1/6 [00:18<01:33, 18.74s/it]Evaluation epoch 49:  17%|█▋        | 1/6 [00:18<01:33, 18.74s/it, loss=1.5185, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 49:  33%|███▎      | 2/6 [00:19<00:32,  8.15s/it, loss=1.5185, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 49:  33%|███▎      | 2/6 [00:19<00:32,  8.15s/it, loss=1.5985, batch_acc=0.6562, running_acc=0.6406]Evaluation epoch 49:  50%|█████     | 3/6 [00:20<00:14,  4.77s/it, loss=1.5985, batch_acc=0.6562, running_acc=0.6406]Evaluation epoch 49:  50%|█████     | 3/6 [00:20<00:14,  4.77s/it, loss=1.5585, batch_acc=0.6250, running_acc=0.6354]Evaluation epoch 49:  67%|██████▋   | 4/6 [00:31<00:14,  7.31s/it, loss=1.5585, batch_acc=0.6250, running_acc=0.6354]Evaluation epoch 49:  67%|██████▋   | 4/6 [00:31<00:14,  7.31s/it, loss=1.6595, batch_acc=0.4375, running_acc=0.5859]Evaluation epoch 49:  83%|████████▎ | 5/6 [00:32<00:04,  4.95s/it, loss=1.6595, batch_acc=0.4375, running_acc=0.5859]Evaluation epoch 49:  83%|████████▎ | 5/6 [00:32<00:04,  4.95s/it, loss=1.6224, batch_acc=0.6562, running_acc=0.6000]Evaluation epoch 49: 100%|██████████| 6/6 [00:33<00:00,  3.82s/it, loss=1.6224, batch_acc=0.6562, running_acc=0.6000]Evaluation epoch 49: 100%|██████████| 6/6 [00:33<00:00,  3.82s/it, loss=1.7729, batch_acc=0.6000, running_acc=0.6000]Evaluation epoch 49: 100%|██████████| 6/6 [00:33<00:00,  5.64s/it, loss=1.7729, batch_acc=0.6000, running_acc=0.6000]
