Training epoch 0:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 0:   1%|          | 1/163 [00:08<22:59,  8.52s/it]Training epoch 0:   1%|          | 1/163 [00:08<22:59,  8.52s/it, loss=3.9124, batch_acc=0.0000, running_acc=0.0000, grad=7.7531]Training epoch 0:   1%|          | 2/163 [00:09<10:48,  4.03s/it, loss=3.9124, batch_acc=0.0000, running_acc=0.0000, grad=7.7531]Training epoch 0:   1%|          | 2/163 [00:09<10:48,  4.03s/it, loss=4.0821, batch_acc=0.0625, running_acc=0.0312, grad=7.9554]Training epoch 0:   2%|▏         | 3/163 [00:10<06:54,  2.59s/it, loss=4.0821, batch_acc=0.0625, running_acc=0.0312, grad=7.9554]Training epoch 0:   2%|▏         | 3/163 [00:10<06:54,  2.59s/it, loss=4.2521, batch_acc=0.0312, running_acc=0.0312, grad=6.9177]Training epoch 0:   2%|▏         | 4/163 [00:11<05:04,  1.91s/it, loss=4.2521, batch_acc=0.0312, running_acc=0.0312, grad=6.9177]Training epoch 0:   2%|▏         | 4/163 [00:11<05:04,  1.91s/it, loss=4.3195, batch_acc=0.0625, running_acc=0.0391, grad=6.8021]Training epoch 0:   3%|▎         | 5/163 [00:12<04:03,  1.54s/it, loss=4.3195, batch_acc=0.0625, running_acc=0.0391, grad=6.8021]Training epoch 0:   3%|▎         | 5/163 [00:12<04:03,  1.54s/it, loss=4.1264, batch_acc=0.0312, running_acc=0.0375, grad=5.6977]Training epoch 0:   4%|▎         | 6/163 [00:12<03:26,  1.32s/it, loss=4.1264, batch_acc=0.0312, running_acc=0.0375, grad=5.6977]Training epoch 0:   4%|▎         | 6/163 [00:12<03:26,  1.32s/it, loss=3.8897, batch_acc=0.0625, running_acc=0.0417, grad=5.3204]Training epoch 0:   4%|▍         | 7/163 [00:13<03:03,  1.17s/it, loss=3.8897, batch_acc=0.0625, running_acc=0.0417, grad=5.3204]Training epoch 0:   4%|▍         | 7/163 [00:13<03:03,  1.17s/it, loss=3.8580, batch_acc=0.0625, running_acc=0.0446, grad=5.6976]Training epoch 0:   5%|▍         | 8/163 [00:14<02:52,  1.12s/it, loss=3.8580, batch_acc=0.0625, running_acc=0.0446, grad=5.6976]Training epoch 0:   5%|▍         | 8/163 [00:14<02:52,  1.12s/it, loss=4.1153, batch_acc=0.0625, running_acc=0.0469, grad=5.4318]Training epoch 0:   6%|▌         | 9/163 [00:15<02:40,  1.04s/it, loss=4.1153, batch_acc=0.0625, running_acc=0.0469, grad=5.4318]Training epoch 0:   6%|▌         | 9/163 [00:15<02:40,  1.04s/it, loss=4.1468, batch_acc=0.0312, running_acc=0.0451, grad=6.2911]Training epoch 0:   6%|▌         | 10/163 [00:16<02:31,  1.01it/s, loss=4.1468, batch_acc=0.0312, running_acc=0.0451, grad=6.2911]Training epoch 0:   6%|▌         | 10/163 [00:16<02:31,  1.01it/s, loss=3.9150, batch_acc=0.0625, running_acc=0.0469, grad=5.2998]Training epoch 0:   7%|▋         | 11/163 [00:17<02:25,  1.04it/s, loss=3.9150, batch_acc=0.0625, running_acc=0.0469, grad=5.2998]Training epoch 0:   7%|▋         | 11/163 [00:17<02:25,  1.04it/s, loss=4.0687, batch_acc=0.0312, running_acc=0.0455, grad=5.2460]Training epoch 0:   7%|▋         | 12/163 [00:19<03:16,  1.30s/it, loss=4.0687, batch_acc=0.0312, running_acc=0.0455, grad=5.2460]Training epoch 0:   7%|▋         | 12/163 [00:19<03:16,  1.30s/it, loss=3.8090, batch_acc=0.0312, running_acc=0.0443, grad=4.8506]Training epoch 0:   8%|▊         | 13/163 [00:20<02:55,  1.17s/it, loss=3.8090, batch_acc=0.0312, running_acc=0.0443, grad=4.8506]Training epoch 0:   8%|▊         | 13/163 [00:20<02:55,  1.17s/it, loss=4.2206, batch_acc=0.0000, running_acc=0.0409, grad=5.4029]Training epoch 0:   9%|▊         | 14/163 [00:21<02:41,  1.08s/it, loss=4.2206, batch_acc=0.0000, running_acc=0.0409, grad=5.4029]Training epoch 0:   9%|▊         | 14/163 [00:21<02:41,  1.08s/it, loss=4.2297, batch_acc=0.0000, running_acc=0.0379, grad=5.1486]Training epoch 0:   9%|▉         | 15/163 [00:22<02:31,  1.02s/it, loss=4.2297, batch_acc=0.0000, running_acc=0.0379, grad=5.1486]Training epoch 0:   9%|▉         | 15/163 [00:22<02:31,  1.02s/it, loss=3.8693, batch_acc=0.0625, running_acc=0.0396, grad=5.1600]Training epoch 0:  10%|▉         | 16/163 [00:24<03:18,  1.35s/it, loss=3.8693, batch_acc=0.0625, running_acc=0.0396, grad=5.1600]Training epoch 0:  10%|▉         | 16/163 [00:24<03:18,  1.35s/it, loss=3.8976, batch_acc=0.0000, running_acc=0.0371, grad=5.4050]Training epoch 0:  10%|█         | 17/163 [00:25<02:57,  1.21s/it, loss=3.8976, batch_acc=0.0000, running_acc=0.0371, grad=5.4050]Training epoch 0:  10%|█         | 17/163 [00:25<02:57,  1.21s/it, loss=3.5078, batch_acc=0.1250, running_acc=0.0423, grad=5.0114]Training epoch 0:  11%|█         | 18/163 [00:26<02:41,  1.11s/it, loss=3.5078, batch_acc=0.1250, running_acc=0.0423, grad=5.0114]Training epoch 0:  11%|█         | 18/163 [00:26<02:41,  1.11s/it, loss=3.8460, batch_acc=0.1250, running_acc=0.0469, grad=4.5501]Training epoch 0:  12%|█▏        | 19/163 [00:26<02:30,  1.04s/it, loss=3.8460, batch_acc=0.1250, running_acc=0.0469, grad=4.5501]Training epoch 0:  12%|█▏        | 19/163 [00:26<02:30,  1.04s/it, loss=4.0064, batch_acc=0.0938, running_acc=0.0493, grad=5.2799]Training epoch 0:  12%|█▏        | 20/163 [00:28<02:58,  1.25s/it, loss=4.0064, batch_acc=0.0938, running_acc=0.0493, grad=5.2799]Training epoch 0:  12%|█▏        | 20/163 [00:28<02:58,  1.25s/it, loss=3.6933, batch_acc=0.0000, running_acc=0.0469, grad=5.1845]Training epoch 0:  13%|█▎        | 21/163 [00:29<02:41,  1.14s/it, loss=3.6933, batch_acc=0.0000, running_acc=0.0469, grad=5.1845]Training epoch 0:  13%|█▎        | 21/163 [00:29<02:41,  1.14s/it, loss=3.7591, batch_acc=0.0938, running_acc=0.0491, grad=4.6927]Training epoch 0:  13%|█▎        | 22/163 [00:30<02:29,  1.06s/it, loss=3.7591, batch_acc=0.0938, running_acc=0.0491, grad=4.6927]Training epoch 0:  13%|█▎        | 22/163 [00:30<02:29,  1.06s/it, loss=3.7757, batch_acc=0.0625, running_acc=0.0497, grad=5.0911]Training epoch 0:  14%|█▍        | 23/163 [00:31<02:21,  1.01s/it, loss=3.7757, batch_acc=0.0625, running_acc=0.0497, grad=5.0911]Training epoch 0:  14%|█▍        | 23/163 [00:31<02:21,  1.01s/it, loss=3.6766, batch_acc=0.0625, running_acc=0.0503, grad=4.7069]Training epoch 0:  15%|█▍        | 24/163 [00:33<03:03,  1.32s/it, loss=3.6766, batch_acc=0.0625, running_acc=0.0503, grad=4.7069]Training epoch 0:  15%|█▍        | 24/163 [00:33<03:03,  1.32s/it, loss=3.6293, batch_acc=0.1250, running_acc=0.0534, grad=5.0608]Training epoch 0:  15%|█▌        | 25/163 [00:34<02:43,  1.19s/it, loss=3.6293, batch_acc=0.1250, running_acc=0.0534, grad=5.0608]Training epoch 0:  15%|█▌        | 25/163 [00:34<02:43,  1.19s/it, loss=3.8398, batch_acc=0.0625, running_acc=0.0537, grad=5.0961]Training epoch 0:  16%|█▌        | 26/163 [00:35<02:30,  1.10s/it, loss=3.8398, batch_acc=0.0625, running_acc=0.0537, grad=5.0961]Training epoch 0:  16%|█▌        | 26/163 [00:35<02:30,  1.10s/it, loss=3.8098, batch_acc=0.0312, running_acc=0.0529, grad=4.7419]Training epoch 0:  17%|█▋        | 27/163 [00:35<02:20,  1.03s/it, loss=3.8098, batch_acc=0.0312, running_acc=0.0529, grad=4.7419]Training epoch 0:  17%|█▋        | 27/163 [00:35<02:20,  1.03s/it, loss=4.0498, batch_acc=0.0000, running_acc=0.0509, grad=5.3084]Training epoch 0:  17%|█▋        | 28/163 [00:37<02:49,  1.25s/it, loss=4.0498, batch_acc=0.0000, running_acc=0.0509, grad=5.3084]Training epoch 0:  17%|█▋        | 28/163 [00:37<02:49,  1.25s/it, loss=3.6669, batch_acc=0.0312, running_acc=0.0502, grad=5.2739]Training epoch 0:  18%|█▊        | 29/163 [00:38<02:33,  1.14s/it, loss=3.6669, batch_acc=0.0312, running_acc=0.0502, grad=5.2739]Training epoch 0:  18%|█▊        | 29/163 [00:38<02:33,  1.14s/it, loss=3.9574, batch_acc=0.0000, running_acc=0.0485, grad=5.6825]Training epoch 0:  18%|█▊        | 30/163 [00:39<02:21,  1.06s/it, loss=3.9574, batch_acc=0.0000, running_acc=0.0485, grad=5.6825]Training epoch 0:  18%|█▊        | 30/163 [00:39<02:21,  1.06s/it, loss=3.6063, batch_acc=0.0938, running_acc=0.0500, grad=4.9240]Training epoch 0:  19%|█▉        | 31/163 [00:40<02:13,  1.01s/it, loss=3.6063, batch_acc=0.0938, running_acc=0.0500, grad=4.9240]Training epoch 0:  19%|█▉        | 31/163 [00:40<02:13,  1.01s/it, loss=3.9535, batch_acc=0.0312, running_acc=0.0494, grad=4.6424]Training epoch 0:  20%|█▉        | 32/163 [00:42<02:52,  1.32s/it, loss=3.9535, batch_acc=0.0312, running_acc=0.0494, grad=4.6424]Training epoch 0:  20%|█▉        | 32/163 [00:42<02:52,  1.32s/it, loss=3.7005, batch_acc=0.0625, running_acc=0.0498, grad=4.7232]Training epoch 0:  20%|██        | 33/163 [00:43<02:34,  1.19s/it, loss=3.7005, batch_acc=0.0625, running_acc=0.0498, grad=4.7232]Training epoch 0:  20%|██        | 33/163 [00:43<02:34,  1.19s/it, loss=3.7557, batch_acc=0.0312, running_acc=0.0492, grad=3.9823]Training epoch 0:  21%|██        | 34/163 [00:44<02:21,  1.10s/it, loss=3.7557, batch_acc=0.0312, running_acc=0.0492, grad=3.9823]Training epoch 0:  21%|██        | 34/163 [00:44<02:21,  1.10s/it, loss=3.4815, batch_acc=0.1250, running_acc=0.0515, grad=4.6144]Training epoch 0:  21%|██▏       | 35/163 [00:45<02:12,  1.03s/it, loss=3.4815, batch_acc=0.1250, running_acc=0.0515, grad=4.6144]Training epoch 0:  21%|██▏       | 35/163 [00:45<02:12,  1.03s/it, loss=3.5393, batch_acc=0.0938, running_acc=0.0527, grad=5.3883]Training epoch 0:  22%|██▏       | 36/163 [00:47<02:46,  1.31s/it, loss=3.5393, batch_acc=0.0938, running_acc=0.0527, grad=5.3883]Training epoch 0:  22%|██▏       | 36/163 [00:47<02:46,  1.31s/it, loss=3.6836, batch_acc=0.1250, running_acc=0.0547, grad=4.3848]Training epoch 0:  23%|██▎       | 37/163 [00:47<02:29,  1.18s/it, loss=3.6836, batch_acc=0.1250, running_acc=0.0547, grad=4.3848]Training epoch 0:  23%|██▎       | 37/163 [00:47<02:29,  1.18s/it, loss=3.7261, batch_acc=0.0312, running_acc=0.0541, grad=4.5556]Training epoch 0:  23%|██▎       | 38/163 [00:48<02:16,  1.09s/it, loss=3.7261, batch_acc=0.0312, running_acc=0.0541, grad=4.5556]Training epoch 0:  23%|██▎       | 38/163 [00:48<02:16,  1.09s/it, loss=3.7728, batch_acc=0.0938, running_acc=0.0551, grad=4.4593]Training epoch 0:  24%|██▍       | 39/163 [00:49<02:07,  1.03s/it, loss=3.7728, batch_acc=0.0938, running_acc=0.0551, grad=4.4593]Training epoch 0:  24%|██▍       | 39/163 [00:49<02:07,  1.03s/it, loss=3.4675, batch_acc=0.1562, running_acc=0.0577, grad=5.0840]Training epoch 0:  25%|██▍       | 40/163 [00:51<02:29,  1.22s/it, loss=3.4675, batch_acc=0.1562, running_acc=0.0577, grad=5.0840]Training epoch 0:  25%|██▍       | 40/163 [00:51<02:29,  1.22s/it, loss=3.6771, batch_acc=0.0938, running_acc=0.0586, grad=5.0622]Training epoch 0:  25%|██▌       | 41/163 [00:52<02:16,  1.12s/it, loss=3.6771, batch_acc=0.0938, running_acc=0.0586, grad=5.0622]Training epoch 0:  25%|██▌       | 41/163 [00:52<02:16,  1.12s/it, loss=3.5718, batch_acc=0.1250, running_acc=0.0602, grad=5.0225]Training epoch 0:  26%|██▌       | 42/163 [00:53<02:06,  1.05s/it, loss=3.5718, batch_acc=0.1250, running_acc=0.0602, grad=5.0225]Training epoch 0:  26%|██▌       | 42/163 [00:53<02:06,  1.05s/it, loss=3.3929, batch_acc=0.1250, running_acc=0.0618, grad=4.4202]Training epoch 0:  26%|██▋       | 43/163 [00:54<01:59,  1.00it/s, loss=3.3929, batch_acc=0.1250, running_acc=0.0618, grad=4.4202]Training epoch 0:  26%|██▋       | 43/163 [00:54<01:59,  1.00it/s, loss=3.2130, batch_acc=0.1250, running_acc=0.0632, grad=5.1036]Training epoch 0:  27%|██▋       | 44/163 [00:56<02:44,  1.38s/it, loss=3.2130, batch_acc=0.1250, running_acc=0.0632, grad=5.1036]Training epoch 0:  27%|██▋       | 44/163 [00:56<02:44,  1.38s/it, loss=3.3692, batch_acc=0.1875, running_acc=0.0661, grad=4.4197]Training epoch 0:  28%|██▊       | 45/163 [00:57<02:25,  1.23s/it, loss=3.3692, batch_acc=0.1875, running_acc=0.0661, grad=4.4197]Training epoch 0:  28%|██▊       | 45/163 [00:57<02:25,  1.23s/it, loss=3.1946, batch_acc=0.2500, running_acc=0.0701, grad=4.8252]Training epoch 0:  28%|██▊       | 46/163 [00:58<02:12,  1.13s/it, loss=3.1946, batch_acc=0.2500, running_acc=0.0701, grad=4.8252]Training epoch 0:  28%|██▊       | 46/163 [00:58<02:12,  1.13s/it, loss=3.6728, batch_acc=0.0625, running_acc=0.0700, grad=5.3501]Training epoch 0:  29%|██▉       | 47/163 [00:58<02:02,  1.06s/it, loss=3.6728, batch_acc=0.0625, running_acc=0.0700, grad=5.3501]Training epoch 0:  29%|██▉       | 47/163 [00:58<02:02,  1.06s/it, loss=3.3427, batch_acc=0.1562, running_acc=0.0718, grad=4.6712]Training epoch 0:  29%|██▉       | 48/163 [01:00<02:09,  1.12s/it, loss=3.3427, batch_acc=0.1562, running_acc=0.0718, grad=4.6712]Training epoch 0:  29%|██▉       | 48/163 [01:00<02:09,  1.12s/it, loss=3.5244, batch_acc=0.0938, running_acc=0.0723, grad=4.2384]Training epoch 0:  30%|███       | 49/163 [01:01<01:59,  1.05s/it, loss=3.5244, batch_acc=0.0938, running_acc=0.0723, grad=4.2384]Training epoch 0:  30%|███       | 49/163 [01:01<01:59,  1.05s/it, loss=3.3978, batch_acc=0.1562, running_acc=0.0740, grad=5.0223]Training epoch 0:  31%|███       | 50/163 [01:02<01:54,  1.02s/it, loss=3.3978, batch_acc=0.1562, running_acc=0.0740, grad=5.0223]Training epoch 0:  31%|███       | 50/163 [01:02<01:54,  1.02s/it, loss=3.1744, batch_acc=0.2812, running_acc=0.0781, grad=4.8446]Training epoch 0:  31%|███▏      | 51/163 [01:02<01:49,  1.03it/s, loss=3.1744, batch_acc=0.2812, running_acc=0.0781, grad=4.8446]Training epoch 0:  31%|███▏      | 51/163 [01:02<01:49,  1.03it/s, loss=3.5785, batch_acc=0.0938, running_acc=0.0784, grad=5.6586]Training epoch 0:  32%|███▏      | 52/163 [01:04<01:54,  1.03s/it, loss=3.5785, batch_acc=0.0938, running_acc=0.0784, grad=5.6586]Training epoch 0:  32%|███▏      | 52/163 [01:04<01:54,  1.03s/it, loss=3.4802, batch_acc=0.0938, running_acc=0.0787, grad=4.6090]Training epoch 0:  33%|███▎      | 53/163 [01:04<01:48,  1.01it/s, loss=3.4802, batch_acc=0.0938, running_acc=0.0787, grad=4.6090]Training epoch 0:  33%|███▎      | 53/163 [01:04<01:48,  1.01it/s, loss=3.5579, batch_acc=0.0938, running_acc=0.0790, grad=5.0489]Training epoch 0:  33%|███▎      | 54/163 [01:05<01:44,  1.05it/s, loss=3.5579, batch_acc=0.0938, running_acc=0.0790, grad=5.0489]Training epoch 0:  33%|███▎      | 54/163 [01:05<01:44,  1.05it/s, loss=3.6097, batch_acc=0.0625, running_acc=0.0787, grad=4.2521]Training epoch 0:  34%|███▎      | 55/163 [01:06<01:40,  1.07it/s, loss=3.6097, batch_acc=0.0625, running_acc=0.0787, grad=4.2521]Training epoch 0:  34%|███▎      | 55/163 [01:06<01:40,  1.07it/s, loss=3.6239, batch_acc=0.0938, running_acc=0.0790, grad=5.7667]Training epoch 0:  34%|███▍      | 56/163 [01:08<01:58,  1.11s/it, loss=3.6239, batch_acc=0.0938, running_acc=0.0790, grad=5.7667]Training epoch 0:  34%|███▍      | 56/163 [01:08<01:58,  1.11s/it, loss=3.6587, batch_acc=0.0938, running_acc=0.0792, grad=4.7312]Training epoch 0:  35%|███▍      | 57/163 [01:09<01:50,  1.04s/it, loss=3.6587, batch_acc=0.0938, running_acc=0.0792, grad=4.7312]Training epoch 0:  35%|███▍      | 57/163 [01:09<01:50,  1.04s/it, loss=3.6456, batch_acc=0.1250, running_acc=0.0800, grad=4.7494]Training epoch 0:  36%|███▌      | 58/163 [01:10<01:45,  1.01s/it, loss=3.6456, batch_acc=0.1250, running_acc=0.0800, grad=4.7494]Training epoch 0:  36%|███▌      | 58/163 [01:10<01:45,  1.01s/it, loss=3.5467, batch_acc=0.1250, running_acc=0.0808, grad=4.8698]Training epoch 0:  36%|███▌      | 59/163 [01:10<01:40,  1.03it/s, loss=3.5467, batch_acc=0.1250, running_acc=0.0808, grad=4.8698]Training epoch 0:  36%|███▌      | 59/163 [01:10<01:40,  1.03it/s, loss=3.6938, batch_acc=0.0938, running_acc=0.0810, grad=5.5519]Training epoch 0:  37%|███▋      | 60/163 [01:12<01:59,  1.16s/it, loss=3.6938, batch_acc=0.0938, running_acc=0.0810, grad=5.5519]Training epoch 0:  37%|███▋      | 60/163 [01:12<01:59,  1.16s/it, loss=3.4647, batch_acc=0.1562, running_acc=0.0823, grad=4.4606]Training epoch 0:  37%|███▋      | 61/163 [01:13<01:49,  1.08s/it, loss=3.4647, batch_acc=0.1562, running_acc=0.0823, grad=4.4606]Training epoch 0:  37%|███▋      | 61/163 [01:13<01:49,  1.08s/it, loss=3.3331, batch_acc=0.1562, running_acc=0.0835, grad=4.5289]Training epoch 0:  38%|███▊      | 62/163 [01:14<01:44,  1.04s/it, loss=3.3331, batch_acc=0.1562, running_acc=0.0835, grad=4.5289]Training epoch 0:  38%|███▊      | 62/163 [01:14<01:44,  1.04s/it, loss=3.3612, batch_acc=0.1250, running_acc=0.0842, grad=4.6113]Training epoch 0:  39%|███▊      | 63/163 [01:15<01:39,  1.01it/s, loss=3.3612, batch_acc=0.1250, running_acc=0.0842, grad=4.6113]Training epoch 0:  39%|███▊      | 63/163 [01:15<01:39,  1.01it/s, loss=3.0580, batch_acc=0.2500, running_acc=0.0868, grad=5.0177]Training epoch 0:  39%|███▉      | 64/163 [01:17<02:04,  1.26s/it, loss=3.0580, batch_acc=0.2500, running_acc=0.0868, grad=5.0177]Training epoch 0:  39%|███▉      | 64/163 [01:17<02:04,  1.26s/it, loss=3.4781, batch_acc=0.0938, running_acc=0.0869, grad=5.6066]Training epoch 0:  40%|███▉      | 65/163 [01:18<01:52,  1.14s/it, loss=3.4781, batch_acc=0.0938, running_acc=0.0869, grad=5.6066]Training epoch 0:  40%|███▉      | 65/163 [01:18<01:52,  1.14s/it, loss=3.5201, batch_acc=0.0625, running_acc=0.0865, grad=4.9466]Training epoch 0:  40%|████      | 66/163 [01:18<01:43,  1.07s/it, loss=3.5201, batch_acc=0.0625, running_acc=0.0865, grad=4.9466]Training epoch 0:  40%|████      | 66/163 [01:18<01:43,  1.07s/it, loss=3.5095, batch_acc=0.1250, running_acc=0.0871, grad=5.4420]Training epoch 0:  41%|████      | 67/163 [01:19<01:37,  1.01s/it, loss=3.5095, batch_acc=0.1250, running_acc=0.0871, grad=5.4420]Training epoch 0:  41%|████      | 67/163 [01:19<01:37,  1.01s/it, loss=3.6546, batch_acc=0.0625, running_acc=0.0868, grad=5.2986]Training epoch 0:  42%|████▏     | 68/163 [01:21<02:01,  1.28s/it, loss=3.6546, batch_acc=0.0625, running_acc=0.0868, grad=5.2986]Training epoch 0:  42%|████▏     | 68/163 [01:21<02:01,  1.28s/it, loss=3.1022, batch_acc=0.1562, running_acc=0.0878, grad=4.7340]Training epoch 0:  42%|████▏     | 69/163 [01:22<01:48,  1.16s/it, loss=3.1022, batch_acc=0.1562, running_acc=0.0878, grad=4.7340]Training epoch 0:  42%|████▏     | 69/163 [01:22<01:48,  1.16s/it, loss=3.4257, batch_acc=0.1875, running_acc=0.0892, grad=5.7633]Training epoch 0:  43%|████▎     | 70/163 [01:23<01:40,  1.08s/it, loss=3.4257, batch_acc=0.1875, running_acc=0.0892, grad=5.7633]Training epoch 0:  43%|████▎     | 70/163 [01:23<01:40,  1.08s/it, loss=3.3290, batch_acc=0.1250, running_acc=0.0897, grad=4.2647]Training epoch 0:  44%|████▎     | 71/163 [01:24<01:33,  1.02s/it, loss=3.3290, batch_acc=0.1250, running_acc=0.0897, grad=4.2647]Training epoch 0:  44%|████▎     | 71/163 [01:24<01:33,  1.02s/it, loss=3.0415, batch_acc=0.1562, running_acc=0.0907, grad=4.4661]Training epoch 0:  44%|████▍     | 72/163 [01:26<01:59,  1.32s/it, loss=3.0415, batch_acc=0.1562, running_acc=0.0907, grad=4.4661]Training epoch 0:  44%|████▍     | 72/163 [01:26<01:59,  1.32s/it, loss=3.3223, batch_acc=0.1562, running_acc=0.0916, grad=5.4392]Training epoch 0:  45%|████▍     | 73/163 [01:27<01:46,  1.19s/it, loss=3.3223, batch_acc=0.1562, running_acc=0.0916, grad=5.4392]Training epoch 0:  45%|████▍     | 73/163 [01:27<01:46,  1.19s/it, loss=3.3905, batch_acc=0.1250, running_acc=0.0920, grad=4.7346]Training epoch 0:  45%|████▌     | 74/163 [01:28<01:37,  1.10s/it, loss=3.3905, batch_acc=0.1250, running_acc=0.0920, grad=4.7346]Training epoch 0:  45%|████▌     | 74/163 [01:28<01:37,  1.10s/it, loss=3.4200, batch_acc=0.0938, running_acc=0.0921, grad=4.8830]Training epoch 0:  46%|████▌     | 75/163 [01:29<01:30,  1.03s/it, loss=3.4200, batch_acc=0.0938, running_acc=0.0921, grad=4.8830]Training epoch 0:  46%|████▌     | 75/163 [01:29<01:30,  1.03s/it, loss=3.8675, batch_acc=0.0000, running_acc=0.0908, grad=5.2355]Training epoch 0:  47%|████▋     | 76/163 [01:30<01:52,  1.29s/it, loss=3.8675, batch_acc=0.0000, running_acc=0.0908, grad=5.2355]Training epoch 0:  47%|████▋     | 76/163 [01:30<01:52,  1.29s/it, loss=3.6526, batch_acc=0.1250, running_acc=0.0913, grad=4.4440]Training epoch 0:  47%|████▋     | 77/163 [01:31<01:40,  1.17s/it, loss=3.6526, batch_acc=0.1250, running_acc=0.0913, grad=4.4440]Training epoch 0:  47%|████▋     | 77/163 [01:31<01:40,  1.17s/it, loss=3.0901, batch_acc=0.1250, running_acc=0.0917, grad=4.5760]Training epoch 0:  48%|████▊     | 78/163 [01:32<01:32,  1.08s/it, loss=3.0901, batch_acc=0.1250, running_acc=0.0917, grad=4.5760]Training epoch 0:  48%|████▊     | 78/163 [01:32<01:32,  1.08s/it, loss=3.0194, batch_acc=0.2188, running_acc=0.0933, grad=4.1002]Training epoch 0:  48%|████▊     | 79/163 [01:33<01:25,  1.02s/it, loss=3.0194, batch_acc=0.2188, running_acc=0.0933, grad=4.1002]Training epoch 0:  48%|████▊     | 79/163 [01:33<01:25,  1.02s/it, loss=3.1888, batch_acc=0.1875, running_acc=0.0945, grad=4.2969]Training epoch 0:  49%|████▉     | 80/163 [01:35<01:50,  1.33s/it, loss=3.1888, batch_acc=0.1875, running_acc=0.0945, grad=4.2969]Training epoch 0:  49%|████▉     | 80/163 [01:35<01:50,  1.33s/it, loss=3.7281, batch_acc=0.1250, running_acc=0.0949, grad=5.2751]Training epoch 0:  50%|████▉     | 81/163 [01:36<01:38,  1.20s/it, loss=3.7281, batch_acc=0.1250, running_acc=0.0949, grad=5.2751]Training epoch 0:  50%|████▉     | 81/163 [01:36<01:38,  1.20s/it, loss=3.3101, batch_acc=0.1562, running_acc=0.0957, grad=4.5777]Training epoch 0:  50%|█████     | 82/163 [01:37<01:29,  1.10s/it, loss=3.3101, batch_acc=0.1562, running_acc=0.0957, grad=4.5777]Training epoch 0:  50%|█████     | 82/163 [01:37<01:29,  1.10s/it, loss=3.3101, batch_acc=0.0625, running_acc=0.0953, grad=4.5435]Training epoch 0:  51%|█████     | 83/163 [01:38<01:22,  1.04s/it, loss=3.3101, batch_acc=0.0625, running_acc=0.0953, grad=4.5435]Training epoch 0:  51%|█████     | 83/163 [01:38<01:22,  1.04s/it, loss=3.4437, batch_acc=0.1250, running_acc=0.0956, grad=5.1522]Training epoch 0:  52%|█████▏    | 84/163 [01:40<01:43,  1.31s/it, loss=3.4437, batch_acc=0.1250, running_acc=0.0956, grad=5.1522]Training epoch 0:  52%|█████▏    | 84/163 [01:40<01:43,  1.31s/it, loss=3.1335, batch_acc=0.1250, running_acc=0.0960, grad=5.2460]Training epoch 0:  52%|█████▏    | 85/163 [01:41<01:31,  1.18s/it, loss=3.1335, batch_acc=0.1250, running_acc=0.0960, grad=5.2460]Training epoch 0:  52%|█████▏    | 85/163 [01:41<01:31,  1.18s/it, loss=3.3357, batch_acc=0.1875, running_acc=0.0971, grad=4.7237]Training epoch 0:  53%|█████▎    | 86/163 [01:41<01:23,  1.09s/it, loss=3.3357, batch_acc=0.1875, running_acc=0.0971, grad=4.7237]Training epoch 0:  53%|█████▎    | 86/163 [01:41<01:23,  1.09s/it, loss=3.1837, batch_acc=0.0938, running_acc=0.0970, grad=4.5559]Training epoch 0:  53%|█████▎    | 87/163 [01:42<01:18,  1.03s/it, loss=3.1837, batch_acc=0.0938, running_acc=0.0970, grad=4.5559]Training epoch 0:  53%|█████▎    | 87/163 [01:42<01:18,  1.03s/it, loss=3.4035, batch_acc=0.0312, running_acc=0.0963, grad=5.3513]Training epoch 0:  54%|█████▍    | 88/163 [01:44<01:39,  1.32s/it, loss=3.4035, batch_acc=0.0312, running_acc=0.0963, grad=5.3513]Training epoch 0:  54%|█████▍    | 88/163 [01:44<01:39,  1.32s/it, loss=3.4358, batch_acc=0.1250, running_acc=0.0966, grad=5.2319]Training epoch 0:  55%|█████▍    | 89/163 [01:45<01:28,  1.19s/it, loss=3.4358, batch_acc=0.1250, running_acc=0.0966, grad=5.2319]Training epoch 0:  55%|█████▍    | 89/163 [01:45<01:28,  1.19s/it, loss=3.4105, batch_acc=0.2188, running_acc=0.0980, grad=4.3506]Training epoch 0:  55%|█████▌    | 90/163 [01:46<01:20,  1.10s/it, loss=3.4105, batch_acc=0.2188, running_acc=0.0980, grad=4.3506]Training epoch 0:  55%|█████▌    | 90/163 [01:46<01:20,  1.10s/it, loss=3.2706, batch_acc=0.1875, running_acc=0.0990, grad=5.8177]Training epoch 0:  56%|█████▌    | 91/163 [01:47<01:14,  1.03s/it, loss=3.2706, batch_acc=0.1875, running_acc=0.0990, grad=5.8177]Training epoch 0:  56%|█████▌    | 91/163 [01:47<01:14,  1.03s/it, loss=3.3218, batch_acc=0.1562, running_acc=0.0996, grad=4.4771]Training epoch 0:  56%|█████▋    | 92/163 [01:49<01:34,  1.32s/it, loss=3.3218, batch_acc=0.1562, running_acc=0.0996, grad=4.4771]Training epoch 0:  56%|█████▋    | 92/163 [01:49<01:34,  1.32s/it, loss=3.5108, batch_acc=0.0625, running_acc=0.0992, grad=5.4080]Training epoch 0:  57%|█████▋    | 93/163 [01:50<01:23,  1.19s/it, loss=3.5108, batch_acc=0.0625, running_acc=0.0992, grad=5.4080]Training epoch 0:  57%|█████▋    | 93/163 [01:50<01:23,  1.19s/it, loss=3.2139, batch_acc=0.2188, running_acc=0.1005, grad=5.7009]Training epoch 0:  58%|█████▊    | 94/163 [01:51<01:15,  1.10s/it, loss=3.2139, batch_acc=0.2188, running_acc=0.1005, grad=5.7009]Training epoch 0:  58%|█████▊    | 94/163 [01:51<01:15,  1.10s/it, loss=3.1936, batch_acc=0.1562, running_acc=0.1011, grad=4.2833]Training epoch 0:  58%|█████▊    | 95/163 [01:52<01:10,  1.03s/it, loss=3.1936, batch_acc=0.1562, running_acc=0.1011, grad=4.2833]Training epoch 0:  58%|█████▊    | 95/163 [01:52<01:10,  1.03s/it, loss=3.3677, batch_acc=0.1250, running_acc=0.1013, grad=4.8478]Training epoch 0:  59%|█████▉    | 96/163 [01:54<01:28,  1.32s/it, loss=3.3677, batch_acc=0.1250, running_acc=0.1013, grad=4.8478]Training epoch 0:  59%|█████▉    | 96/163 [01:54<01:28,  1.32s/it, loss=3.1265, batch_acc=0.1875, running_acc=0.1022, grad=5.6451]Training epoch 0:  60%|█████▉    | 97/163 [01:55<01:18,  1.19s/it, loss=3.1265, batch_acc=0.1875, running_acc=0.1022, grad=5.6451]Training epoch 0:  60%|█████▉    | 97/163 [01:55<01:18,  1.19s/it, loss=3.0187, batch_acc=0.1562, running_acc=0.1028, grad=5.3204]Training epoch 0:  60%|██████    | 98/163 [01:55<01:11,  1.09s/it, loss=3.0187, batch_acc=0.1562, running_acc=0.1028, grad=5.3204]Training epoch 0:  60%|██████    | 98/163 [01:55<01:11,  1.09s/it, loss=3.1795, batch_acc=0.0938, running_acc=0.1027, grad=5.7048]Training epoch 0:  61%|██████    | 99/163 [01:56<01:05,  1.03s/it, loss=3.1795, batch_acc=0.0938, running_acc=0.1027, grad=5.7048]Training epoch 0:  61%|██████    | 99/163 [01:56<01:05,  1.03s/it, loss=3.3856, batch_acc=0.0625, running_acc=0.1023, grad=5.0393]Training epoch 0:  61%|██████▏   | 100/163 [01:58<01:18,  1.25s/it, loss=3.3856, batch_acc=0.0625, running_acc=0.1023, grad=5.0393]Training epoch 0:  61%|██████▏   | 100/163 [01:58<01:18,  1.25s/it, loss=3.0175, batch_acc=0.2188, running_acc=0.1034, grad=6.3591]Training epoch 0:  62%|██████▏   | 101/163 [01:59<01:10,  1.14s/it, loss=3.0175, batch_acc=0.2188, running_acc=0.1034, grad=6.3591]Training epoch 0:  62%|██████▏   | 101/163 [01:59<01:10,  1.14s/it, loss=3.4080, batch_acc=0.0938, running_acc=0.1033, grad=6.7625]Training epoch 0:  63%|██████▎   | 102/163 [02:00<01:04,  1.06s/it, loss=3.4080, batch_acc=0.0938, running_acc=0.1033, grad=6.7625]Training epoch 0:  63%|██████▎   | 102/163 [02:00<01:04,  1.06s/it, loss=3.4165, batch_acc=0.0938, running_acc=0.1032, grad=5.2015]Training epoch 0:  63%|██████▎   | 103/163 [02:01<01:00,  1.01s/it, loss=3.4165, batch_acc=0.0938, running_acc=0.1032, grad=5.2015]Training epoch 0:  63%|██████▎   | 103/163 [02:01<01:00,  1.01s/it, loss=3.5089, batch_acc=0.1250, running_acc=0.1035, grad=7.8448]Training epoch 0:  64%|██████▍   | 104/163 [02:04<01:32,  1.56s/it, loss=3.5089, batch_acc=0.1250, running_acc=0.1035, grad=7.8448]Training epoch 0:  64%|██████▍   | 104/163 [02:04<01:32,  1.56s/it, loss=3.3251, batch_acc=0.2188, running_acc=0.1046, grad=5.9740]Training epoch 0:  64%|██████▍   | 105/163 [02:04<01:18,  1.36s/it, loss=3.3251, batch_acc=0.2188, running_acc=0.1046, grad=5.9740]Training epoch 0:  64%|██████▍   | 105/163 [02:04<01:18,  1.36s/it, loss=3.1762, batch_acc=0.1562, running_acc=0.1051, grad=5.0279]Training epoch 0:  65%|██████▌   | 106/163 [02:05<01:09,  1.22s/it, loss=3.1762, batch_acc=0.1562, running_acc=0.1051, grad=5.0279]Training epoch 0:  65%|██████▌   | 106/163 [02:05<01:09,  1.22s/it, loss=3.2285, batch_acc=0.1562, running_acc=0.1055, grad=4.7570]Training epoch 0:  66%|██████▌   | 107/163 [02:06<01:02,  1.12s/it, loss=3.2285, batch_acc=0.1562, running_acc=0.1055, grad=4.7570]Training epoch 0:  66%|██████▌   | 107/163 [02:06<01:02,  1.12s/it, loss=3.2999, batch_acc=0.1250, running_acc=0.1057, grad=5.4010]Training epoch 0:  66%|██████▋   | 108/163 [02:10<01:43,  1.88s/it, loss=3.2999, batch_acc=0.1250, running_acc=0.1057, grad=5.4010]Training epoch 0:  66%|██████▋   | 108/163 [02:10<01:43,  1.88s/it, loss=3.4110, batch_acc=0.2188, running_acc=0.1068, grad=5.3059]Training epoch 0:  67%|██████▋   | 109/163 [02:11<01:25,  1.58s/it, loss=3.4110, batch_acc=0.2188, running_acc=0.1068, grad=5.3059]Training epoch 0:  67%|██████▋   | 109/163 [02:11<01:25,  1.58s/it, loss=3.3155, batch_acc=0.0312, running_acc=0.1061, grad=4.6525]Training epoch 0:  67%|██████▋   | 110/163 [02:12<01:12,  1.37s/it, loss=3.3155, batch_acc=0.0312, running_acc=0.1061, grad=4.6525]Training epoch 0:  67%|██████▋   | 110/163 [02:12<01:12,  1.37s/it, loss=3.2841, batch_acc=0.1562, running_acc=0.1065, grad=7.8351]Training epoch 0:  68%|██████▊   | 111/163 [02:12<01:03,  1.22s/it, loss=3.2841, batch_acc=0.1562, running_acc=0.1065, grad=7.8351]Training epoch 0:  68%|██████▊   | 111/163 [02:12<01:03,  1.22s/it, loss=3.6229, batch_acc=0.0938, running_acc=0.1064, grad=7.6878]Training epoch 0:  69%|██████▊   | 112/163 [02:15<01:19,  1.57s/it, loss=3.6229, batch_acc=0.0938, running_acc=0.1064, grad=7.6878]Training epoch 0:  69%|██████▊   | 112/163 [02:15<01:19,  1.57s/it, loss=3.0380, batch_acc=0.2812, running_acc=0.1080, grad=5.0800]Training epoch 0:  69%|██████▉   | 113/163 [02:16<01:08,  1.36s/it, loss=3.0380, batch_acc=0.2812, running_acc=0.1080, grad=5.0800]Training epoch 0:  69%|██████▉   | 113/163 [02:16<01:08,  1.36s/it, loss=3.2640, batch_acc=0.0938, running_acc=0.1079, grad=5.3645]Training epoch 0:  70%|██████▉   | 114/163 [02:17<00:59,  1.22s/it, loss=3.2640, batch_acc=0.0938, running_acc=0.1079, grad=5.3645]Training epoch 0:  70%|██████▉   | 114/163 [02:17<00:59,  1.22s/it, loss=3.1176, batch_acc=0.1875, running_acc=0.1086, grad=4.8498]Training epoch 0:  71%|███████   | 115/163 [02:18<00:53,  1.12s/it, loss=3.1176, batch_acc=0.1875, running_acc=0.1086, grad=4.8498]Training epoch 0:  71%|███████   | 115/163 [02:18<00:53,  1.12s/it, loss=3.4427, batch_acc=0.0938, running_acc=0.1084, grad=4.9499]Training epoch 0:  71%|███████   | 116/163 [02:20<01:16,  1.63s/it, loss=3.4427, batch_acc=0.0938, running_acc=0.1084, grad=4.9499]Training epoch 0:  71%|███████   | 116/163 [02:20<01:16,  1.63s/it, loss=3.6100, batch_acc=0.0312, running_acc=0.1078, grad=5.3718]Training epoch 0:  72%|███████▏  | 117/163 [02:21<01:04,  1.40s/it, loss=3.6100, batch_acc=0.0312, running_acc=0.1078, grad=5.3718]Training epoch 0:  72%|███████▏  | 117/163 [02:21<01:04,  1.40s/it, loss=3.5868, batch_acc=0.1250, running_acc=0.1079, grad=5.4161]Training epoch 0:  72%|███████▏  | 118/163 [02:22<00:56,  1.25s/it, loss=3.5868, batch_acc=0.1250, running_acc=0.1079, grad=5.4161]Training epoch 0:  72%|███████▏  | 118/163 [02:22<00:56,  1.25s/it, loss=3.3204, batch_acc=0.0625, running_acc=0.1075, grad=4.8075]Training epoch 0:  73%|███████▎  | 119/163 [02:23<00:49,  1.13s/it, loss=3.3204, batch_acc=0.0625, running_acc=0.1075, grad=4.8075]Training epoch 0:  73%|███████▎  | 119/163 [02:23<00:49,  1.13s/it, loss=3.3002, batch_acc=0.0938, running_acc=0.1074, grad=5.9326]Training epoch 0:  74%|███████▎  | 120/163 [02:25<00:58,  1.35s/it, loss=3.3002, batch_acc=0.0938, running_acc=0.1074, grad=5.9326]Training epoch 0:  74%|███████▎  | 120/163 [02:25<00:58,  1.35s/it, loss=3.3396, batch_acc=0.1562, running_acc=0.1078, grad=4.9401]Training epoch 0:  74%|███████▍  | 121/163 [02:26<00:50,  1.21s/it, loss=3.3396, batch_acc=0.1562, running_acc=0.1078, grad=4.9401]Training epoch 0:  74%|███████▍  | 121/163 [02:26<00:50,  1.21s/it, loss=3.3375, batch_acc=0.0625, running_acc=0.1074, grad=4.3111]Training epoch 0:  75%|███████▍  | 122/163 [02:27<00:45,  1.11s/it, loss=3.3375, batch_acc=0.0625, running_acc=0.1074, grad=4.3111]Training epoch 0:  75%|███████▍  | 122/163 [02:27<00:45,  1.11s/it, loss=3.4891, batch_acc=0.0625, running_acc=0.1071, grad=5.1554]Training epoch 0:  75%|███████▌  | 123/163 [02:27<00:41,  1.04s/it, loss=3.4891, batch_acc=0.0625, running_acc=0.1071, grad=5.1554]Training epoch 0:  75%|███████▌  | 123/163 [02:27<00:41,  1.04s/it, loss=3.2433, batch_acc=0.1250, running_acc=0.1072, grad=4.9024]Training epoch 0:  76%|███████▌  | 124/163 [02:29<00:47,  1.22s/it, loss=3.2433, batch_acc=0.1250, running_acc=0.1072, grad=4.9024]Training epoch 0:  76%|███████▌  | 124/163 [02:29<00:47,  1.22s/it, loss=3.3348, batch_acc=0.0938, running_acc=0.1071, grad=6.1012]Training epoch 0:  77%|███████▋  | 125/163 [02:30<00:42,  1.12s/it, loss=3.3348, batch_acc=0.0938, running_acc=0.1071, grad=6.1012]Training epoch 0:  77%|███████▋  | 125/163 [02:30<00:42,  1.12s/it, loss=2.8868, batch_acc=0.1562, running_acc=0.1075, grad=4.7077]Training epoch 0:  77%|███████▋  | 126/163 [02:31<00:38,  1.05s/it, loss=2.8868, batch_acc=0.1562, running_acc=0.1075, grad=4.7077]Training epoch 0:  77%|███████▋  | 126/163 [02:31<00:38,  1.05s/it, loss=3.2898, batch_acc=0.1875, running_acc=0.1081, grad=5.4107]Training epoch 0:  78%|███████▊  | 127/163 [02:32<00:35,  1.00it/s, loss=3.2898, batch_acc=0.1875, running_acc=0.1081, grad=5.4107]Training epoch 0:  78%|███████▊  | 127/163 [02:32<00:35,  1.00it/s, loss=3.2855, batch_acc=0.0938, running_acc=0.1080, grad=4.6383]Training epoch 0:  79%|███████▊  | 128/163 [02:34<00:43,  1.23s/it, loss=3.2855, batch_acc=0.0938, running_acc=0.1080, grad=4.6383]Training epoch 0:  79%|███████▊  | 128/163 [02:34<00:43,  1.23s/it, loss=2.9584, batch_acc=0.2500, running_acc=0.1091, grad=5.0342]Training epoch 0:  79%|███████▉  | 129/163 [02:34<00:38,  1.12s/it, loss=2.9584, batch_acc=0.2500, running_acc=0.1091, grad=5.0342]Training epoch 0:  79%|███████▉  | 129/163 [02:34<00:38,  1.12s/it, loss=3.3334, batch_acc=0.1562, running_acc=0.1095, grad=4.7596]Training epoch 0:  80%|███████▉  | 130/163 [02:35<00:34,  1.05s/it, loss=3.3334, batch_acc=0.1562, running_acc=0.1095, grad=4.7596]Training epoch 0:  80%|███████▉  | 130/163 [02:35<00:34,  1.05s/it, loss=3.0305, batch_acc=0.1875, running_acc=0.1101, grad=5.3900]Training epoch 0:  80%|████████  | 131/163 [02:36<00:31,  1.00it/s, loss=3.0305, batch_acc=0.1875, running_acc=0.1101, grad=5.3900]Training epoch 0:  80%|████████  | 131/163 [02:36<00:31,  1.00it/s, loss=3.2281, batch_acc=0.1250, running_acc=0.1102, grad=4.6912]Training epoch 0:  81%|████████  | 132/163 [02:38<00:39,  1.29s/it, loss=3.2281, batch_acc=0.1250, running_acc=0.1102, grad=4.6912]Training epoch 0:  81%|████████  | 132/163 [02:38<00:39,  1.29s/it, loss=3.4901, batch_acc=0.1562, running_acc=0.1106, grad=5.2551]Training epoch 0:  82%|████████▏ | 133/163 [02:39<00:34,  1.17s/it, loss=3.4901, batch_acc=0.1562, running_acc=0.1106, grad=5.2551]Training epoch 0:  82%|████████▏ | 133/163 [02:39<00:34,  1.17s/it, loss=2.9224, batch_acc=0.3125, running_acc=0.1121, grad=4.7913]Training epoch 0:  82%|████████▏ | 134/163 [02:40<00:31,  1.08s/it, loss=2.9224, batch_acc=0.3125, running_acc=0.1121, grad=4.7913]Training epoch 0:  82%|████████▏ | 134/163 [02:40<00:31,  1.08s/it, loss=2.8615, batch_acc=0.1562, running_acc=0.1124, grad=4.4230]Training epoch 0:  83%|████████▎ | 135/163 [02:41<00:28,  1.02s/it, loss=2.8615, batch_acc=0.1562, running_acc=0.1124, grad=4.4230]Training epoch 0:  83%|████████▎ | 135/163 [02:41<00:28,  1.02s/it, loss=3.0225, batch_acc=0.1875, running_acc=0.1130, grad=5.1592]Training epoch 0:  83%|████████▎ | 136/163 [02:43<00:35,  1.31s/it, loss=3.0225, batch_acc=0.1875, running_acc=0.1130, grad=5.1592]Training epoch 0:  83%|████████▎ | 136/163 [02:43<00:35,  1.31s/it, loss=3.1757, batch_acc=0.1562, running_acc=0.1133, grad=4.7579]Training epoch 0:  84%|████████▍ | 137/163 [02:44<00:30,  1.18s/it, loss=3.1757, batch_acc=0.1562, running_acc=0.1133, grad=4.7579]Training epoch 0:  84%|████████▍ | 137/163 [02:44<00:30,  1.18s/it, loss=3.3877, batch_acc=0.0938, running_acc=0.1131, grad=5.2992]Training epoch 0:  85%|████████▍ | 138/163 [02:45<00:27,  1.09s/it, loss=3.3877, batch_acc=0.0938, running_acc=0.1131, grad=5.2992]Training epoch 0:  85%|████████▍ | 138/163 [02:45<00:27,  1.09s/it, loss=2.8933, batch_acc=0.1875, running_acc=0.1137, grad=5.1574]Training epoch 0:  85%|████████▌ | 139/163 [02:45<00:24,  1.03s/it, loss=2.8933, batch_acc=0.1875, running_acc=0.1137, grad=5.1574]Training epoch 0:  85%|████████▌ | 139/163 [02:45<00:24,  1.03s/it, loss=3.3366, batch_acc=0.0625, running_acc=0.1133, grad=4.9551]Training epoch 0:  86%|████████▌ | 140/163 [02:47<00:27,  1.22s/it, loss=3.3366, batch_acc=0.0625, running_acc=0.1133, grad=4.9551]Training epoch 0:  86%|████████▌ | 140/163 [02:47<00:27,  1.22s/it, loss=3.0917, batch_acc=0.1250, running_acc=0.1134, grad=4.6086]Training epoch 0:  87%|████████▋ | 141/163 [02:48<00:24,  1.12s/it, loss=3.0917, batch_acc=0.1250, running_acc=0.1134, grad=4.6086]Training epoch 0:  87%|████████▋ | 141/163 [02:48<00:24,  1.12s/it, loss=2.9022, batch_acc=0.2500, running_acc=0.1144, grad=4.5932]Training epoch 0:  87%|████████▋ | 142/163 [02:49<00:21,  1.05s/it, loss=2.9022, batch_acc=0.2500, running_acc=0.1144, grad=4.5932]Training epoch 0:  87%|████████▋ | 142/163 [02:49<00:21,  1.05s/it, loss=3.2347, batch_acc=0.1250, running_acc=0.1144, grad=5.2965]Training epoch 0:  88%|████████▊ | 143/163 [02:50<00:19,  1.00it/s, loss=3.2347, batch_acc=0.1250, running_acc=0.1144, grad=5.2965]Training epoch 0:  88%|████████▊ | 143/163 [02:50<00:19,  1.00it/s, loss=3.1162, batch_acc=0.2188, running_acc=0.1152, grad=4.7941]Training epoch 0:  88%|████████▊ | 144/163 [02:51<00:21,  1.12s/it, loss=3.1162, batch_acc=0.2188, running_acc=0.1152, grad=4.7941]Training epoch 0:  88%|████████▊ | 144/163 [02:51<00:21,  1.12s/it, loss=3.2845, batch_acc=0.1562, running_acc=0.1155, grad=5.5860]Training epoch 0:  89%|████████▉ | 145/163 [02:52<00:18,  1.05s/it, loss=3.2845, batch_acc=0.1562, running_acc=0.1155, grad=5.5860]Training epoch 0:  89%|████████▉ | 145/163 [02:52<00:18,  1.05s/it, loss=3.4473, batch_acc=0.0312, running_acc=0.1149, grad=7.9421]Training epoch 0:  90%|████████▉ | 146/163 [02:53<00:16,  1.00it/s, loss=3.4473, batch_acc=0.0312, running_acc=0.1149, grad=7.9421]Training epoch 0:  90%|████████▉ | 146/163 [02:53<00:16,  1.00it/s, loss=2.8785, batch_acc=0.3438, running_acc=0.1164, grad=6.3671]Training epoch 0:  90%|█████████ | 147/163 [02:54<00:15,  1.04it/s, loss=2.8785, batch_acc=0.3438, running_acc=0.1164, grad=6.3671]Training epoch 0:  90%|█████████ | 147/163 [02:54<00:15,  1.04it/s, loss=2.9262, batch_acc=0.2500, running_acc=0.1173, grad=6.4354]Training epoch 0:  91%|█████████ | 148/163 [02:56<00:19,  1.32s/it, loss=2.9262, batch_acc=0.2500, running_acc=0.1173, grad=6.4354]Training epoch 0:  91%|█████████ | 148/163 [02:56<00:19,  1.32s/it, loss=2.7811, batch_acc=0.2188, running_acc=0.1180, grad=5.1625]Training epoch 0:  91%|█████████▏| 149/163 [02:57<00:16,  1.19s/it, loss=2.7811, batch_acc=0.2188, running_acc=0.1180, grad=5.1625]Training epoch 0:  91%|█████████▏| 149/163 [02:57<00:16,  1.19s/it, loss=2.7612, batch_acc=0.2188, running_acc=0.1187, grad=4.2774]Training epoch 0:  92%|█████████▏| 150/163 [02:58<00:14,  1.10s/it, loss=2.7612, batch_acc=0.2188, running_acc=0.1187, grad=4.2774]Training epoch 0:  92%|█████████▏| 150/163 [02:58<00:14,  1.10s/it, loss=2.8138, batch_acc=0.1562, running_acc=0.1190, grad=5.2675]Training epoch 0:  93%|█████████▎| 151/163 [02:59<00:12,  1.03s/it, loss=2.8138, batch_acc=0.1562, running_acc=0.1190, grad=5.2675]Training epoch 0:  93%|█████████▎| 151/163 [02:59<00:12,  1.03s/it, loss=2.9426, batch_acc=0.1250, running_acc=0.1190, grad=5.2628]Training epoch 0:  93%|█████████▎| 152/163 [03:01<00:14,  1.31s/it, loss=2.9426, batch_acc=0.1250, running_acc=0.1190, grad=5.2628]Training epoch 0:  93%|█████████▎| 152/163 [03:01<00:14,  1.31s/it, loss=3.3162, batch_acc=0.0938, running_acc=0.1188, grad=5.4822]Training epoch 0:  94%|█████████▍| 153/163 [03:01<00:11,  1.18s/it, loss=3.3162, batch_acc=0.0938, running_acc=0.1188, grad=5.4822]Training epoch 0:  94%|█████████▍| 153/163 [03:01<00:11,  1.18s/it, loss=3.4256, batch_acc=0.0938, running_acc=0.1187, grad=6.0880]Training epoch 0:  94%|█████████▍| 154/163 [03:02<00:09,  1.09s/it, loss=3.4256, batch_acc=0.0938, running_acc=0.1187, grad=6.0880]Training epoch 0:  94%|█████████▍| 154/163 [03:02<00:09,  1.09s/it, loss=2.8541, batch_acc=0.2812, running_acc=0.1197, grad=5.4708]Training epoch 0:  95%|█████████▌| 155/163 [03:03<00:08,  1.03s/it, loss=2.8541, batch_acc=0.2812, running_acc=0.1197, grad=5.4708]Training epoch 0:  95%|█████████▌| 155/163 [03:03<00:08,  1.03s/it, loss=3.0874, batch_acc=0.1562, running_acc=0.1200, grad=5.9591]Training epoch 0:  96%|█████████▌| 156/163 [03:05<00:09,  1.32s/it, loss=3.0874, batch_acc=0.1562, running_acc=0.1200, grad=5.9591]Training epoch 0:  96%|█████████▌| 156/163 [03:05<00:09,  1.32s/it, loss=3.0357, batch_acc=0.1875, running_acc=0.1204, grad=4.9791]Training epoch 0:  96%|█████████▋| 157/163 [03:06<00:07,  1.18s/it, loss=3.0357, batch_acc=0.1875, running_acc=0.1204, grad=4.9791]Training epoch 0:  96%|█████████▋| 157/163 [03:06<00:07,  1.18s/it, loss=3.2400, batch_acc=0.0938, running_acc=0.1202, grad=4.9998]Training epoch 0:  97%|█████████▋| 158/163 [03:07<00:05,  1.09s/it, loss=3.2400, batch_acc=0.0938, running_acc=0.1202, grad=4.9998]Training epoch 0:  97%|█████████▋| 158/163 [03:07<00:05,  1.09s/it, loss=2.7097, batch_acc=0.0938, running_acc=0.1201, grad=4.6131]Training epoch 0:  98%|█████████▊| 159/163 [03:08<00:04,  1.03s/it, loss=2.7097, batch_acc=0.0938, running_acc=0.1201, grad=4.6131]Training epoch 0:  98%|█████████▊| 159/163 [03:08<00:04,  1.03s/it, loss=2.7197, batch_acc=0.0938, running_acc=0.1199, grad=5.6004]Training epoch 0:  98%|█████████▊| 160/163 [03:09<00:03,  1.19s/it, loss=2.7197, batch_acc=0.0938, running_acc=0.1199, grad=5.6004]Training epoch 0:  98%|█████████▊| 160/163 [03:09<00:03,  1.19s/it, loss=3.1158, batch_acc=0.1250, running_acc=0.1199, grad=5.4173]Training epoch 0:  99%|█████████▉| 161/163 [03:10<00:02,  1.10s/it, loss=3.1158, batch_acc=0.1250, running_acc=0.1199, grad=5.4173]Training epoch 0:  99%|█████████▉| 161/163 [03:10<00:02,  1.10s/it, loss=2.8063, batch_acc=0.2188, running_acc=0.1205, grad=4.8802]Training epoch 0:  99%|█████████▉| 162/163 [03:11<00:01,  1.03s/it, loss=2.8063, batch_acc=0.2188, running_acc=0.1205, grad=4.8802]Training epoch 0:  99%|█████████▉| 162/163 [03:11<00:01,  1.03s/it, loss=3.4778, batch_acc=0.1562, running_acc=0.1208, grad=4.9501]Training epoch 0: 100%|██████████| 163/163 [03:12<00:00,  1.09it/s, loss=3.4778, batch_acc=0.1562, running_acc=0.1208, grad=4.9501]Training epoch 0: 100%|██████████| 163/163 [03:12<00:00,  1.09it/s, loss=2.8392, batch_acc=0.1905, running_acc=0.1210, grad=5.9606]Training epoch 0: 100%|██████████| 163/163 [03:12<00:00,  1.18s/it, loss=2.8392, batch_acc=0.1905, running_acc=0.1210, grad=5.9606]
Evaluation epoch 0:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 0:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it]Evaluation epoch 0:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it, loss=2.1964, batch_acc=0.4062, running_acc=0.4062]Evaluation epoch 0:   7%|▋         | 2/28 [00:05<00:57,  2.23s/it, loss=2.1964, batch_acc=0.4062, running_acc=0.4062]Evaluation epoch 0:   7%|▋         | 2/28 [00:05<00:57,  2.23s/it, loss=3.1248, batch_acc=0.0938, running_acc=0.2500]Evaluation epoch 0:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=3.1248, batch_acc=0.0938, running_acc=0.2500]Evaluation epoch 0:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=3.0638, batch_acc=0.1562, running_acc=0.2188]Evaluation epoch 0:  14%|█▍        | 4/28 [00:09<01:00,  2.51s/it, loss=3.0638, batch_acc=0.1562, running_acc=0.2188]Evaluation epoch 0:  14%|█▍        | 4/28 [00:09<01:00,  2.51s/it, loss=3.6844, batch_acc=0.0000, running_acc=0.1641]Evaluation epoch 0:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=3.6844, batch_acc=0.0000, running_acc=0.1641]Evaluation epoch 0:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=3.2456, batch_acc=0.0625, running_acc=0.1437]Evaluation epoch 0:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=3.2456, batch_acc=0.0625, running_acc=0.1437]Evaluation epoch 0:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=2.7643, batch_acc=0.3750, running_acc=0.1823]Evaluation epoch 0:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=2.7643, batch_acc=0.3750, running_acc=0.1823]Evaluation epoch 0:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=3.7200, batch_acc=0.0000, running_acc=0.1562]Evaluation epoch 0:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=3.7200, batch_acc=0.0000, running_acc=0.1562]Evaluation epoch 0:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=2.5708, batch_acc=0.1875, running_acc=0.1602]Evaluation epoch 0:  32%|███▏      | 9/28 [00:14<00:26,  1.37s/it, loss=2.5708, batch_acc=0.1875, running_acc=0.1602]Evaluation epoch 0:  32%|███▏      | 9/28 [00:14<00:26,  1.37s/it, loss=3.5094, batch_acc=0.0625, running_acc=0.1493]Evaluation epoch 0:  36%|███▌      | 10/28 [00:14<00:18,  1.03s/it, loss=3.5094, batch_acc=0.0625, running_acc=0.1493]Evaluation epoch 0:  36%|███▌      | 10/28 [00:14<00:18,  1.03s/it, loss=1.8305, batch_acc=0.6250, running_acc=0.1969]Evaluation epoch 0:  39%|███▉      | 11/28 [00:15<00:13,  1.26it/s, loss=1.8305, batch_acc=0.6250, running_acc=0.1969]Evaluation epoch 0:  39%|███▉      | 11/28 [00:15<00:13,  1.26it/s, loss=2.7501, batch_acc=0.3438, running_acc=0.2102]Evaluation epoch 0:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.7501, batch_acc=0.3438, running_acc=0.2102]Evaluation epoch 0:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.8056, batch_acc=0.2812, running_acc=0.2161]Evaluation epoch 0:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=2.8056, batch_acc=0.2812, running_acc=0.2161]Evaluation epoch 0:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=2.9702, batch_acc=0.1250, running_acc=0.2091]Evaluation epoch 0:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=2.9702, batch_acc=0.1250, running_acc=0.2091]Evaluation epoch 0:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=3.1150, batch_acc=0.1562, running_acc=0.2054]Evaluation epoch 0:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=3.1150, batch_acc=0.1562, running_acc=0.2054]Evaluation epoch 0:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=3.5261, batch_acc=0.0000, running_acc=0.1917]Evaluation epoch 0:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=3.5261, batch_acc=0.0000, running_acc=0.1917]Evaluation epoch 0:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=3.5629, batch_acc=0.1875, running_acc=0.1914]Evaluation epoch 0:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=3.5629, batch_acc=0.1875, running_acc=0.1914]Evaluation epoch 0:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=3.1706, batch_acc=0.2188, running_acc=0.1930]Evaluation epoch 0:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=3.1706, batch_acc=0.2188, running_acc=0.1930]Evaluation epoch 0:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=2.6271, batch_acc=0.2812, running_acc=0.1979]Evaluation epoch 0:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.6271, batch_acc=0.2812, running_acc=0.1979]Evaluation epoch 0:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.8029, batch_acc=0.1250, running_acc=0.1941]Evaluation epoch 0:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=2.8029, batch_acc=0.1250, running_acc=0.1941]Evaluation epoch 0:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=3.4284, batch_acc=0.0938, running_acc=0.1891]Evaluation epoch 0:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=3.4284, batch_acc=0.0938, running_acc=0.1891]Evaluation epoch 0:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=3.3533, batch_acc=0.2188, running_acc=0.1905]Evaluation epoch 0:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=3.3533, batch_acc=0.2188, running_acc=0.1905]Evaluation epoch 0:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=3.4475, batch_acc=0.0625, running_acc=0.1847]Evaluation epoch 0:  82%|████████▏ | 23/28 [00:29<00:03,  1.53it/s, loss=3.4475, batch_acc=0.0625, running_acc=0.1847]Evaluation epoch 0:  82%|████████▏ | 23/28 [00:29<00:03,  1.53it/s, loss=2.9508, batch_acc=0.2500, running_acc=0.1875]Evaluation epoch 0:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=2.9508, batch_acc=0.2500, running_acc=0.1875]Evaluation epoch 0:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=2.4227, batch_acc=0.2812, running_acc=0.1914]Evaluation epoch 0:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=2.4227, batch_acc=0.2812, running_acc=0.1914]Evaluation epoch 0:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=1.8776, batch_acc=0.5000, running_acc=0.2037]Evaluation epoch 0:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.8776, batch_acc=0.5000, running_acc=0.2037]Evaluation epoch 0:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=2.3493, batch_acc=0.4062, running_acc=0.2115]Evaluation epoch 0:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=2.3493, batch_acc=0.4062, running_acc=0.2115]Evaluation epoch 0:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=2.9307, batch_acc=0.0938, running_acc=0.2072]Evaluation epoch 0: 100%|██████████| 28/28 [00:35<00:00,  1.53it/s, loss=2.9307, batch_acc=0.0938, running_acc=0.2072]Evaluation epoch 0: 100%|██████████| 28/28 [00:35<00:00,  1.53it/s, loss=2.5287, batch_acc=0.3333, running_acc=0.2076]Evaluation epoch 0: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=2.5287, batch_acc=0.3333, running_acc=0.2076]
Training epoch 1:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 1:   1%|          | 1/163 [00:06<16:36,  6.15s/it]Training epoch 1:   1%|          | 1/163 [00:06<16:36,  6.15s/it, loss=2.7938, batch_acc=0.2188, running_acc=0.2188, grad=4.2980]Training epoch 1:   1%|          | 2/163 [00:07<08:11,  3.05s/it, loss=2.7938, batch_acc=0.2188, running_acc=0.2188, grad=4.2980]Training epoch 1:   1%|          | 2/163 [00:07<08:11,  3.05s/it, loss=3.4664, batch_acc=0.1875, running_acc=0.2031, grad=5.0035]Training epoch 1:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=3.4664, batch_acc=0.1875, running_acc=0.2031, grad=5.0035]Training epoch 1:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=2.5919, batch_acc=0.2812, running_acc=0.2292, grad=4.2044]Training epoch 1:   2%|▏         | 4/163 [00:11<06:48,  2.57s/it, loss=2.5919, batch_acc=0.2812, running_acc=0.2292, grad=4.2044]Training epoch 1:   2%|▏         | 4/163 [00:11<06:48,  2.57s/it, loss=3.0824, batch_acc=0.1562, running_acc=0.2109, grad=4.8109]Training epoch 1:   3%|▎         | 5/163 [00:12<05:09,  1.96s/it, loss=3.0824, batch_acc=0.1562, running_acc=0.2109, grad=4.8109]Training epoch 1:   3%|▎         | 5/163 [00:12<05:09,  1.96s/it, loss=3.1542, batch_acc=0.1250, running_acc=0.1938, grad=6.1666]Training epoch 1:   4%|▎         | 6/163 [00:13<04:10,  1.59s/it, loss=3.1542, batch_acc=0.1250, running_acc=0.1938, grad=6.1666]Training epoch 1:   4%|▎         | 6/163 [00:13<04:10,  1.59s/it, loss=2.9298, batch_acc=0.1562, running_acc=0.1875, grad=5.1064]Training epoch 1:   4%|▍         | 7/163 [00:13<03:32,  1.36s/it, loss=2.9298, batch_acc=0.1562, running_acc=0.1875, grad=5.1064]Training epoch 1:   4%|▍         | 7/163 [00:13<03:32,  1.36s/it, loss=2.8993, batch_acc=0.2188, running_acc=0.1920, grad=5.2584]Training epoch 1:   5%|▍         | 8/163 [00:16<04:13,  1.63s/it, loss=2.8993, batch_acc=0.2188, running_acc=0.1920, grad=5.2584]Training epoch 1:   5%|▍         | 8/163 [00:16<04:13,  1.63s/it, loss=2.9026, batch_acc=0.2188, running_acc=0.1953, grad=5.1548]Training epoch 1:   6%|▌         | 9/163 [00:17<03:35,  1.40s/it, loss=2.9026, batch_acc=0.2188, running_acc=0.1953, grad=5.1548]Training epoch 1:   6%|▌         | 9/163 [00:17<03:35,  1.40s/it, loss=2.8652, batch_acc=0.1562, running_acc=0.1910, grad=4.6581]Training epoch 1:   6%|▌         | 10/163 [00:17<03:09,  1.24s/it, loss=2.8652, batch_acc=0.1562, running_acc=0.1910, grad=4.6581]Training epoch 1:   6%|▌         | 10/163 [00:17<03:09,  1.24s/it, loss=2.4640, batch_acc=0.3438, running_acc=0.2062, grad=4.1914]Training epoch 1:   7%|▋         | 11/163 [00:18<02:51,  1.13s/it, loss=2.4640, batch_acc=0.3438, running_acc=0.2062, grad=4.1914]Training epoch 1:   7%|▋         | 11/163 [00:18<02:51,  1.13s/it, loss=3.2083, batch_acc=0.0938, running_acc=0.1960, grad=8.1748]Training epoch 1:   7%|▋         | 12/163 [00:20<03:20,  1.33s/it, loss=3.2083, batch_acc=0.0938, running_acc=0.1960, grad=8.1748]Training epoch 1:   7%|▋         | 12/163 [00:20<03:20,  1.33s/it, loss=3.3919, batch_acc=0.1250, running_acc=0.1901, grad=7.4821]Training epoch 1:   8%|▊         | 13/163 [00:21<02:59,  1.19s/it, loss=3.3919, batch_acc=0.1250, running_acc=0.1901, grad=7.4821]Training epoch 1:   8%|▊         | 13/163 [00:21<02:59,  1.19s/it, loss=2.8558, batch_acc=0.1562, running_acc=0.1875, grad=4.8707]Training epoch 1:   9%|▊         | 14/163 [00:22<02:43,  1.10s/it, loss=2.8558, batch_acc=0.1562, running_acc=0.1875, grad=4.8707]Training epoch 1:   9%|▊         | 14/163 [00:22<02:43,  1.10s/it, loss=2.6726, batch_acc=0.3438, running_acc=0.1987, grad=4.4422]Training epoch 1:   9%|▉         | 15/163 [00:23<02:33,  1.03s/it, loss=2.6726, batch_acc=0.3438, running_acc=0.1987, grad=4.4422]Training epoch 1:   9%|▉         | 15/163 [00:23<02:33,  1.03s/it, loss=2.9966, batch_acc=0.2500, running_acc=0.2021, grad=4.5055]Training epoch 1:  10%|▉         | 16/163 [00:25<03:08,  1.28s/it, loss=2.9966, batch_acc=0.2500, running_acc=0.2021, grad=4.5055]Training epoch 1:  10%|▉         | 16/163 [00:25<03:08,  1.28s/it, loss=2.9531, batch_acc=0.1875, running_acc=0.2012, grad=6.5152]Training epoch 1:  10%|█         | 17/163 [00:25<02:49,  1.16s/it, loss=2.9531, batch_acc=0.1875, running_acc=0.2012, grad=6.5152]Training epoch 1:  10%|█         | 17/163 [00:25<02:49,  1.16s/it, loss=2.9669, batch_acc=0.1875, running_acc=0.2004, grad=4.5447]Training epoch 1:  11%|█         | 18/163 [00:26<02:36,  1.08s/it, loss=2.9669, batch_acc=0.1875, running_acc=0.2004, grad=4.5447]Training epoch 1:  11%|█         | 18/163 [00:26<02:36,  1.08s/it, loss=2.3918, batch_acc=0.3750, running_acc=0.2101, grad=4.5898]Training epoch 1:  12%|█▏        | 19/163 [00:27<02:26,  1.02s/it, loss=2.3918, batch_acc=0.3750, running_acc=0.2101, grad=4.5898]Training epoch 1:  12%|█▏        | 19/163 [00:27<02:26,  1.02s/it, loss=3.0670, batch_acc=0.1250, running_acc=0.2056, grad=4.9025]Training epoch 1:  12%|█▏        | 20/163 [00:29<03:12,  1.35s/it, loss=3.0670, batch_acc=0.1250, running_acc=0.2056, grad=4.9025]Training epoch 1:  12%|█▏        | 20/163 [00:29<03:12,  1.35s/it, loss=2.9439, batch_acc=0.1875, running_acc=0.2047, grad=4.5754]Training epoch 1:  13%|█▎        | 21/163 [00:30<02:51,  1.21s/it, loss=2.9439, batch_acc=0.1875, running_acc=0.2047, grad=4.5754]Training epoch 1:  13%|█▎        | 21/163 [00:30<02:51,  1.21s/it, loss=2.7249, batch_acc=0.1875, running_acc=0.2039, grad=6.0932]Training epoch 1:  13%|█▎        | 22/163 [00:31<02:36,  1.11s/it, loss=2.7249, batch_acc=0.1875, running_acc=0.2039, grad=6.0932]Training epoch 1:  13%|█▎        | 22/163 [00:31<02:36,  1.11s/it, loss=3.1310, batch_acc=0.0938, running_acc=0.1989, grad=6.6204]Training epoch 1:  14%|█▍        | 23/163 [00:32<02:25,  1.04s/it, loss=3.1310, batch_acc=0.0938, running_acc=0.1989, grad=6.6204]Training epoch 1:  14%|█▍        | 23/163 [00:32<02:25,  1.04s/it, loss=3.3625, batch_acc=0.0312, running_acc=0.1916, grad=5.5304]Training epoch 1:  15%|█▍        | 24/163 [00:33<02:45,  1.19s/it, loss=3.3625, batch_acc=0.0312, running_acc=0.1916, grad=5.5304]Training epoch 1:  15%|█▍        | 24/163 [00:33<02:45,  1.19s/it, loss=3.1951, batch_acc=0.0625, running_acc=0.1862, grad=5.1751]Training epoch 1:  15%|█▌        | 25/163 [00:34<02:31,  1.10s/it, loss=3.1951, batch_acc=0.0625, running_acc=0.1862, grad=5.1751]Training epoch 1:  15%|█▌        | 25/163 [00:34<02:31,  1.10s/it, loss=2.8486, batch_acc=0.1875, running_acc=0.1862, grad=6.5787]Training epoch 1:  16%|█▌        | 26/163 [00:35<02:21,  1.03s/it, loss=2.8486, batch_acc=0.1875, running_acc=0.1862, grad=6.5787]Training epoch 1:  16%|█▌        | 26/163 [00:35<02:21,  1.03s/it, loss=3.2681, batch_acc=0.0938, running_acc=0.1827, grad=5.0692]Training epoch 1:  17%|█▋        | 27/163 [00:36<02:13,  1.02it/s, loss=3.2681, batch_acc=0.0938, running_acc=0.1827, grad=5.0692]Training epoch 1:  17%|█▋        | 27/163 [00:36<02:13,  1.02it/s, loss=2.9936, batch_acc=0.1562, running_acc=0.1817, grad=4.7091]Training epoch 1:  17%|█▋        | 28/163 [00:38<02:38,  1.18s/it, loss=2.9936, batch_acc=0.1562, running_acc=0.1817, grad=4.7091]Training epoch 1:  17%|█▋        | 28/163 [00:38<02:38,  1.18s/it, loss=2.4998, batch_acc=0.2812, running_acc=0.1853, grad=4.5341]Training epoch 1:  18%|█▊        | 29/163 [00:39<02:25,  1.09s/it, loss=2.4998, batch_acc=0.2812, running_acc=0.1853, grad=4.5341]Training epoch 1:  18%|█▊        | 29/163 [00:39<02:25,  1.09s/it, loss=2.8921, batch_acc=0.2188, running_acc=0.1864, grad=5.9359]Training epoch 1:  18%|█▊        | 30/163 [00:40<02:16,  1.02s/it, loss=2.8921, batch_acc=0.2188, running_acc=0.1864, grad=5.9359]Training epoch 1:  18%|█▊        | 30/163 [00:40<02:16,  1.02s/it, loss=2.7484, batch_acc=0.1562, running_acc=0.1854, grad=4.7782]Training epoch 1:  19%|█▉        | 31/163 [00:40<02:09,  1.02it/s, loss=2.7484, batch_acc=0.1562, running_acc=0.1854, grad=4.7782]Training epoch 1:  19%|█▉        | 31/163 [00:40<02:09,  1.02it/s, loss=2.9101, batch_acc=0.2500, running_acc=0.1875, grad=5.9803]Training epoch 1:  20%|█▉        | 32/163 [00:42<02:40,  1.23s/it, loss=2.9101, batch_acc=0.2500, running_acc=0.1875, grad=5.9803]Training epoch 1:  20%|█▉        | 32/163 [00:42<02:40,  1.23s/it, loss=2.5016, batch_acc=0.1875, running_acc=0.1875, grad=7.7059]Training epoch 1:  20%|██        | 33/163 [00:43<02:25,  1.12s/it, loss=2.5016, batch_acc=0.1875, running_acc=0.1875, grad=7.7059]Training epoch 1:  20%|██        | 33/163 [00:43<02:25,  1.12s/it, loss=2.9670, batch_acc=0.2812, running_acc=0.1903, grad=5.1502]Training epoch 1:  21%|██        | 34/163 [00:44<02:15,  1.05s/it, loss=2.9670, batch_acc=0.2812, running_acc=0.1903, grad=5.1502]Training epoch 1:  21%|██        | 34/163 [00:44<02:15,  1.05s/it, loss=2.5777, batch_acc=0.2812, running_acc=0.1930, grad=6.1905]Training epoch 1:  21%|██▏       | 35/163 [00:45<02:07,  1.00it/s, loss=2.5777, batch_acc=0.2812, running_acc=0.1930, grad=6.1905]Training epoch 1:  21%|██▏       | 35/163 [00:45<02:07,  1.00it/s, loss=3.0083, batch_acc=0.1250, running_acc=0.1911, grad=5.1778]Training epoch 1:  22%|██▏       | 36/163 [00:47<02:45,  1.31s/it, loss=3.0083, batch_acc=0.1250, running_acc=0.1911, grad=5.1778]Training epoch 1:  22%|██▏       | 36/163 [00:47<02:45,  1.31s/it, loss=2.9443, batch_acc=0.2500, running_acc=0.1927, grad=5.3374]Training epoch 1:  23%|██▎       | 37/163 [00:48<02:28,  1.18s/it, loss=2.9443, batch_acc=0.2500, running_acc=0.1927, grad=5.3374]Training epoch 1:  23%|██▎       | 37/163 [00:48<02:28,  1.18s/it, loss=2.4989, batch_acc=0.2188, running_acc=0.1934, grad=4.7602]Training epoch 1:  23%|██▎       | 38/163 [00:49<02:16,  1.09s/it, loss=2.4989, batch_acc=0.2188, running_acc=0.1934, grad=4.7602]Training epoch 1:  23%|██▎       | 38/163 [00:49<02:16,  1.09s/it, loss=2.6193, batch_acc=0.2812, running_acc=0.1957, grad=5.1514]Training epoch 1:  24%|██▍       | 39/163 [00:49<02:07,  1.03s/it, loss=2.6193, batch_acc=0.2812, running_acc=0.1957, grad=5.1514]Training epoch 1:  24%|██▍       | 39/163 [00:49<02:07,  1.03s/it, loss=2.7800, batch_acc=0.2188, running_acc=0.1963, grad=7.5220]Training epoch 1:  25%|██▍       | 40/163 [00:51<02:30,  1.22s/it, loss=2.7800, batch_acc=0.2188, running_acc=0.1963, grad=7.5220]Training epoch 1:  25%|██▍       | 40/163 [00:51<02:30,  1.22s/it, loss=2.8418, batch_acc=0.1875, running_acc=0.1961, grad=5.4875]Training epoch 1:  25%|██▌       | 41/163 [00:52<02:16,  1.12s/it, loss=2.8418, batch_acc=0.1875, running_acc=0.1961, grad=5.4875]Training epoch 1:  25%|██▌       | 41/163 [00:52<02:16,  1.12s/it, loss=2.9220, batch_acc=0.2188, running_acc=0.1966, grad=4.8720]Training epoch 1:  26%|██▌       | 42/163 [00:53<02:06,  1.05s/it, loss=2.9220, batch_acc=0.2188, running_acc=0.1966, grad=4.8720]Training epoch 1:  26%|██▌       | 42/163 [00:53<02:06,  1.05s/it, loss=2.9151, batch_acc=0.1562, running_acc=0.1957, grad=6.5999]Training epoch 1:  26%|██▋       | 43/163 [00:54<01:59,  1.00it/s, loss=2.9151, batch_acc=0.1562, running_acc=0.1957, grad=6.5999]Training epoch 1:  26%|██▋       | 43/163 [00:54<01:59,  1.00it/s, loss=2.9843, batch_acc=0.1875, running_acc=0.1955, grad=5.7512]Training epoch 1:  27%|██▋       | 44/163 [00:56<02:39,  1.34s/it, loss=2.9843, batch_acc=0.1875, running_acc=0.1955, grad=5.7512]Training epoch 1:  27%|██▋       | 44/163 [00:56<02:39,  1.34s/it, loss=2.6924, batch_acc=0.1875, running_acc=0.1953, grad=4.8882]Training epoch 1:  28%|██▊       | 45/163 [00:57<02:22,  1.20s/it, loss=2.6924, batch_acc=0.1875, running_acc=0.1953, grad=4.8882]Training epoch 1:  28%|██▊       | 45/163 [00:57<02:22,  1.20s/it, loss=2.8277, batch_acc=0.1250, running_acc=0.1938, grad=7.7019]Training epoch 1:  28%|██▊       | 46/163 [00:58<02:09,  1.11s/it, loss=2.8277, batch_acc=0.1250, running_acc=0.1938, grad=7.7019]Training epoch 1:  28%|██▊       | 46/163 [00:58<02:09,  1.11s/it, loss=2.4159, batch_acc=0.3438, running_acc=0.1970, grad=5.4887]Training epoch 1:  29%|██▉       | 47/163 [00:59<02:00,  1.04s/it, loss=2.4159, batch_acc=0.3438, running_acc=0.1970, grad=5.4887]Training epoch 1:  29%|██▉       | 47/163 [00:59<02:00,  1.04s/it, loss=2.9785, batch_acc=0.2188, running_acc=0.1975, grad=5.8441]Training epoch 1:  29%|██▉       | 48/163 [01:00<02:08,  1.12s/it, loss=2.9785, batch_acc=0.2188, running_acc=0.1975, grad=5.8441]Training epoch 1:  29%|██▉       | 48/163 [01:00<02:08,  1.12s/it, loss=2.6580, batch_acc=0.2812, running_acc=0.1992, grad=6.7316]Training epoch 1:  30%|███       | 49/163 [01:01<01:59,  1.05s/it, loss=2.6580, batch_acc=0.2812, running_acc=0.1992, grad=6.7316]Training epoch 1:  30%|███       | 49/163 [01:01<01:59,  1.05s/it, loss=3.1252, batch_acc=0.2188, running_acc=0.1996, grad=5.0349]Training epoch 1:  31%|███       | 50/163 [01:02<01:52,  1.00it/s, loss=3.1252, batch_acc=0.2188, running_acc=0.1996, grad=5.0349]Training epoch 1:  31%|███       | 50/163 [01:02<01:52,  1.00it/s, loss=3.0877, batch_acc=0.2188, running_acc=0.2000, grad=5.7685]Training epoch 1:  31%|███▏      | 51/163 [01:03<01:47,  1.04it/s, loss=3.0877, batch_acc=0.2188, running_acc=0.2000, grad=5.7685]Training epoch 1:  31%|███▏      | 51/163 [01:03<01:47,  1.04it/s, loss=2.6349, batch_acc=0.1875, running_acc=0.1998, grad=7.3117]Training epoch 1:  32%|███▏      | 52/163 [01:04<02:11,  1.19s/it, loss=2.6349, batch_acc=0.1875, running_acc=0.1998, grad=7.3117]Training epoch 1:  32%|███▏      | 52/163 [01:04<02:11,  1.19s/it, loss=2.7096, batch_acc=0.2188, running_acc=0.2001, grad=5.4229]Training epoch 1:  33%|███▎      | 53/163 [01:05<02:00,  1.10s/it, loss=2.7096, batch_acc=0.2188, running_acc=0.2001, grad=5.4229]Training epoch 1:  33%|███▎      | 53/163 [01:05<02:00,  1.10s/it, loss=2.5197, batch_acc=0.3438, running_acc=0.2028, grad=4.7631]Training epoch 1:  33%|███▎      | 54/163 [01:06<01:52,  1.03s/it, loss=2.5197, batch_acc=0.3438, running_acc=0.2028, grad=4.7631]Training epoch 1:  33%|███▎      | 54/163 [01:06<01:52,  1.03s/it, loss=2.8379, batch_acc=0.1562, running_acc=0.2020, grad=6.0295]Training epoch 1:  34%|███▎      | 55/163 [01:07<01:46,  1.01it/s, loss=2.8379, batch_acc=0.1562, running_acc=0.2020, grad=6.0295]Training epoch 1:  34%|███▎      | 55/163 [01:07<01:46,  1.01it/s, loss=3.1556, batch_acc=0.1562, running_acc=0.2011, grad=7.6220]Training epoch 1:  34%|███▍      | 56/163 [01:09<02:15,  1.27s/it, loss=3.1556, batch_acc=0.1562, running_acc=0.2011, grad=7.6220]Training epoch 1:  34%|███▍      | 56/163 [01:09<02:15,  1.27s/it, loss=2.7032, batch_acc=0.2812, running_acc=0.2026, grad=4.6531]Training epoch 1:  35%|███▍      | 57/163 [01:10<02:02,  1.15s/it, loss=2.7032, batch_acc=0.2812, running_acc=0.2026, grad=4.6531]Training epoch 1:  35%|███▍      | 57/163 [01:10<02:02,  1.15s/it, loss=2.8647, batch_acc=0.2188, running_acc=0.2029, grad=4.8603]Training epoch 1:  36%|███▌      | 58/163 [01:11<01:52,  1.07s/it, loss=2.8647, batch_acc=0.2188, running_acc=0.2029, grad=4.8603]Training epoch 1:  36%|███▌      | 58/163 [01:11<01:52,  1.07s/it, loss=2.9207, batch_acc=0.2500, running_acc=0.2037, grad=5.2466]Training epoch 1:  36%|███▌      | 59/163 [01:11<01:45,  1.01s/it, loss=2.9207, batch_acc=0.2500, running_acc=0.2037, grad=5.2466]Training epoch 1:  36%|███▌      | 59/163 [01:11<01:45,  1.01s/it, loss=2.8050, batch_acc=0.2188, running_acc=0.2039, grad=5.4075]Training epoch 1:  37%|███▋      | 60/163 [01:13<02:11,  1.28s/it, loss=2.8050, batch_acc=0.2188, running_acc=0.2039, grad=5.4075]Training epoch 1:  37%|███▋      | 60/163 [01:13<02:11,  1.28s/it, loss=2.5184, batch_acc=0.2812, running_acc=0.2052, grad=5.6886]Training epoch 1:  37%|███▋      | 61/163 [01:14<01:58,  1.16s/it, loss=2.5184, batch_acc=0.2812, running_acc=0.2052, grad=5.6886]Training epoch 1:  37%|███▋      | 61/163 [01:14<01:58,  1.16s/it, loss=2.9755, batch_acc=0.2188, running_acc=0.2054, grad=5.6462]Training epoch 1:  38%|███▊      | 62/163 [01:15<01:48,  1.07s/it, loss=2.9755, batch_acc=0.2188, running_acc=0.2054, grad=5.6462]Training epoch 1:  38%|███▊      | 62/163 [01:15<01:48,  1.07s/it, loss=2.9089, batch_acc=0.2500, running_acc=0.2061, grad=5.5966]Training epoch 1:  39%|███▊      | 63/163 [01:16<01:41,  1.02s/it, loss=2.9089, batch_acc=0.2500, running_acc=0.2061, grad=5.5966]Training epoch 1:  39%|███▊      | 63/163 [01:16<01:41,  1.02s/it, loss=2.9102, batch_acc=0.1875, running_acc=0.2059, grad=6.3946]Training epoch 1:  39%|███▉      | 64/163 [01:17<01:46,  1.08s/it, loss=2.9102, batch_acc=0.1875, running_acc=0.2059, grad=6.3946]Training epoch 1:  39%|███▉      | 64/163 [01:17<01:46,  1.08s/it, loss=2.9702, batch_acc=0.2500, running_acc=0.2065, grad=5.6033]Training epoch 1:  40%|███▉      | 65/163 [01:18<01:39,  1.02s/it, loss=2.9702, batch_acc=0.2500, running_acc=0.2065, grad=5.6033]Training epoch 1:  40%|███▉      | 65/163 [01:18<01:39,  1.02s/it, loss=2.6415, batch_acc=0.2188, running_acc=0.2067, grad=6.3324]Training epoch 1:  40%|████      | 66/163 [01:19<01:34,  1.03it/s, loss=2.6415, batch_acc=0.2188, running_acc=0.2067, grad=6.3324]Training epoch 1:  40%|████      | 66/163 [01:19<01:34,  1.03it/s, loss=2.4090, batch_acc=0.4062, running_acc=0.2098, grad=5.3988]Training epoch 1:  41%|████      | 67/163 [01:20<01:30,  1.06it/s, loss=2.4090, batch_acc=0.4062, running_acc=0.2098, grad=5.3988]Training epoch 1:  41%|████      | 67/163 [01:20<01:30,  1.06it/s, loss=2.9583, batch_acc=0.1875, running_acc=0.2094, grad=5.7628]Training epoch 1:  42%|████▏     | 68/163 [01:22<01:54,  1.20s/it, loss=2.9583, batch_acc=0.1875, running_acc=0.2094, grad=5.7628]Training epoch 1:  42%|████▏     | 68/163 [01:22<01:54,  1.20s/it, loss=2.8113, batch_acc=0.2812, running_acc=0.2105, grad=5.2232]Training epoch 1:  42%|████▏     | 69/163 [01:23<01:43,  1.10s/it, loss=2.8113, batch_acc=0.2812, running_acc=0.2105, grad=5.2232]Training epoch 1:  42%|████▏     | 69/163 [01:23<01:43,  1.10s/it, loss=2.7670, batch_acc=0.3125, running_acc=0.2120, grad=6.3782]Training epoch 1:  43%|████▎     | 70/163 [01:23<01:36,  1.04s/it, loss=2.7670, batch_acc=0.3125, running_acc=0.2120, grad=6.3782]Training epoch 1:  43%|████▎     | 70/163 [01:23<01:36,  1.04s/it, loss=3.0653, batch_acc=0.1250, running_acc=0.2107, grad=5.0209]Training epoch 1:  44%|████▎     | 71/163 [01:24<01:31,  1.01it/s, loss=3.0653, batch_acc=0.1250, running_acc=0.2107, grad=5.0209]Training epoch 1:  44%|████▎     | 71/163 [01:24<01:31,  1.01it/s, loss=2.6087, batch_acc=0.2812, running_acc=0.2117, grad=5.4697]Training epoch 1:  44%|████▍     | 72/163 [01:26<01:50,  1.21s/it, loss=2.6087, batch_acc=0.2812, running_acc=0.2117, grad=5.4697]Training epoch 1:  44%|████▍     | 72/163 [01:26<01:50,  1.21s/it, loss=2.5581, batch_acc=0.2812, running_acc=0.2127, grad=5.3292]Training epoch 1:  45%|████▍     | 73/163 [01:27<01:40,  1.11s/it, loss=2.5581, batch_acc=0.2812, running_acc=0.2127, grad=5.3292]Training epoch 1:  45%|████▍     | 73/163 [01:27<01:40,  1.11s/it, loss=2.8976, batch_acc=0.2188, running_acc=0.2128, grad=6.2818]Training epoch 1:  45%|████▌     | 74/163 [01:28<01:32,  1.04s/it, loss=2.8976, batch_acc=0.2188, running_acc=0.2128, grad=6.2818]Training epoch 1:  45%|████▌     | 74/163 [01:28<01:32,  1.04s/it, loss=2.4080, batch_acc=0.2500, running_acc=0.2133, grad=5.9689]Training epoch 1:  46%|████▌     | 75/163 [01:29<01:27,  1.01it/s, loss=2.4080, batch_acc=0.2500, running_acc=0.2133, grad=5.9689]Training epoch 1:  46%|████▌     | 75/163 [01:29<01:27,  1.01it/s, loss=2.7774, batch_acc=0.2188, running_acc=0.2133, grad=6.1835]Training epoch 1:  47%|████▋     | 76/163 [01:31<01:55,  1.33s/it, loss=2.7774, batch_acc=0.2188, running_acc=0.2133, grad=6.1835]Training epoch 1:  47%|████▋     | 76/163 [01:31<01:55,  1.33s/it, loss=2.9246, batch_acc=0.1875, running_acc=0.2130, grad=5.7435]Training epoch 1:  47%|████▋     | 77/163 [01:32<01:42,  1.19s/it, loss=2.9246, batch_acc=0.1875, running_acc=0.2130, grad=5.7435]Training epoch 1:  47%|████▋     | 77/163 [01:32<01:42,  1.19s/it, loss=2.6217, batch_acc=0.1875, running_acc=0.2127, grad=5.9025]Training epoch 1:  48%|████▊     | 78/163 [01:33<01:33,  1.10s/it, loss=2.6217, batch_acc=0.1875, running_acc=0.2127, grad=5.9025]Training epoch 1:  48%|████▊     | 78/163 [01:33<01:33,  1.10s/it, loss=2.5763, batch_acc=0.3750, running_acc=0.2147, grad=5.1065]Training epoch 1:  48%|████▊     | 79/163 [01:33<01:26,  1.03s/it, loss=2.5763, batch_acc=0.3750, running_acc=0.2147, grad=5.1065]Training epoch 1:  48%|████▊     | 79/163 [01:33<01:26,  1.03s/it, loss=2.8058, batch_acc=0.2500, running_acc=0.2152, grad=6.0955]Training epoch 1:  49%|████▉     | 80/163 [01:35<01:39,  1.20s/it, loss=2.8058, batch_acc=0.2500, running_acc=0.2152, grad=6.0955]Training epoch 1:  49%|████▉     | 80/163 [01:35<01:39,  1.20s/it, loss=2.7141, batch_acc=0.2812, running_acc=0.2160, grad=4.4861]Training epoch 1:  50%|████▉     | 81/163 [01:36<01:30,  1.10s/it, loss=2.7141, batch_acc=0.2812, running_acc=0.2160, grad=4.4861]Training epoch 1:  50%|████▉     | 81/163 [01:36<01:30,  1.10s/it, loss=2.7885, batch_acc=0.1875, running_acc=0.2157, grad=6.0749]Training epoch 1:  50%|█████     | 82/163 [01:37<01:24,  1.04s/it, loss=2.7885, batch_acc=0.1875, running_acc=0.2157, grad=6.0749]Training epoch 1:  50%|█████     | 82/163 [01:37<01:24,  1.04s/it, loss=2.3503, batch_acc=0.3438, running_acc=0.2172, grad=5.7298]Training epoch 1:  51%|█████     | 83/163 [01:38<01:19,  1.01it/s, loss=2.3503, batch_acc=0.3438, running_acc=0.2172, grad=5.7298]Training epoch 1:  51%|█████     | 83/163 [01:38<01:19,  1.01it/s, loss=2.4289, batch_acc=0.3125, running_acc=0.2184, grad=7.1060]Training epoch 1:  52%|█████▏    | 84/163 [01:40<01:49,  1.39s/it, loss=2.4289, batch_acc=0.3125, running_acc=0.2184, grad=7.1060]Training epoch 1:  52%|█████▏    | 84/163 [01:40<01:49,  1.39s/it, loss=2.5110, batch_acc=0.3125, running_acc=0.2195, grad=7.8838]Training epoch 1:  52%|█████▏    | 85/163 [01:41<01:36,  1.24s/it, loss=2.5110, batch_acc=0.3125, running_acc=0.2195, grad=7.8838]Training epoch 1:  52%|█████▏    | 85/163 [01:41<01:36,  1.24s/it, loss=2.8675, batch_acc=0.2188, running_acc=0.2195, grad=8.7070]Training epoch 1:  53%|█████▎    | 86/163 [01:42<01:26,  1.13s/it, loss=2.8675, batch_acc=0.2188, running_acc=0.2195, grad=8.7070]Training epoch 1:  53%|█████▎    | 86/163 [01:42<01:26,  1.13s/it, loss=2.9027, batch_acc=0.1875, running_acc=0.2191, grad=5.6134]Training epoch 1:  53%|█████▎    | 87/163 [01:43<01:20,  1.05s/it, loss=2.9027, batch_acc=0.1875, running_acc=0.2191, grad=5.6134]Training epoch 1:  53%|█████▎    | 87/163 [01:43<01:20,  1.05s/it, loss=2.9957, batch_acc=0.1875, running_acc=0.2188, grad=5.9272]Training epoch 1:  54%|█████▍    | 88/163 [01:44<01:22,  1.10s/it, loss=2.9957, batch_acc=0.1875, running_acc=0.2188, grad=5.9272]Training epoch 1:  54%|█████▍    | 88/163 [01:44<01:22,  1.10s/it, loss=2.9979, batch_acc=0.1562, running_acc=0.2180, grad=7.0454]Training epoch 1:  55%|█████▍    | 89/163 [01:45<01:16,  1.03s/it, loss=2.9979, batch_acc=0.1562, running_acc=0.2180, grad=7.0454]Training epoch 1:  55%|█████▍    | 89/163 [01:45<01:16,  1.03s/it, loss=3.0842, batch_acc=0.2500, running_acc=0.2184, grad=11.5988]Training epoch 1:  55%|█████▌    | 90/163 [01:46<01:12,  1.01it/s, loss=3.0842, batch_acc=0.2500, running_acc=0.2184, grad=11.5988]Training epoch 1:  55%|█████▌    | 90/163 [01:46<01:12,  1.01it/s, loss=2.3904, batch_acc=0.4375, running_acc=0.2208, grad=5.9778] Training epoch 1:  56%|█████▌    | 91/163 [01:46<01:08,  1.05it/s, loss=2.3904, batch_acc=0.4375, running_acc=0.2208, grad=5.9778]Training epoch 1:  56%|█████▌    | 91/163 [01:46<01:08,  1.05it/s, loss=2.6989, batch_acc=0.2188, running_acc=0.2208, grad=5.9964]Training epoch 1:  56%|█████▋    | 92/163 [01:48<01:17,  1.09s/it, loss=2.6989, batch_acc=0.2188, running_acc=0.2208, grad=5.9964]Training epoch 1:  56%|█████▋    | 92/163 [01:48<01:17,  1.09s/it, loss=3.0167, batch_acc=0.1250, running_acc=0.2198, grad=5.8783]Training epoch 1:  57%|█████▋    | 93/163 [01:49<01:11,  1.03s/it, loss=3.0167, batch_acc=0.1250, running_acc=0.2198, grad=5.8783]Training epoch 1:  57%|█████▋    | 93/163 [01:49<01:11,  1.03s/it, loss=2.3754, batch_acc=0.4062, running_acc=0.2218, grad=6.9410]Training epoch 1:  58%|█████▊    | 94/163 [01:50<01:07,  1.02it/s, loss=2.3754, batch_acc=0.4062, running_acc=0.2218, grad=6.9410]Training epoch 1:  58%|█████▊    | 94/163 [01:50<01:07,  1.02it/s, loss=2.3151, batch_acc=0.4688, running_acc=0.2244, grad=4.3982]Training epoch 1:  58%|█████▊    | 95/163 [01:50<01:04,  1.05it/s, loss=2.3151, batch_acc=0.4688, running_acc=0.2244, grad=4.3982]Training epoch 1:  58%|█████▊    | 95/163 [01:50<01:04,  1.05it/s, loss=2.8029, batch_acc=0.2188, running_acc=0.2243, grad=5.9415]Training epoch 1:  59%|█████▉    | 96/163 [01:52<01:20,  1.19s/it, loss=2.8029, batch_acc=0.2188, running_acc=0.2243, grad=5.9415]Training epoch 1:  59%|█████▉    | 96/163 [01:52<01:20,  1.19s/it, loss=2.4152, batch_acc=0.3125, running_acc=0.2253, grad=5.7515]Training epoch 1:  60%|█████▉    | 97/163 [01:53<01:12,  1.10s/it, loss=2.4152, batch_acc=0.3125, running_acc=0.2253, grad=5.7515]Training epoch 1:  60%|█████▉    | 97/163 [01:53<01:12,  1.10s/it, loss=2.6730, batch_acc=0.3125, running_acc=0.2262, grad=5.8003]Training epoch 1:  60%|██████    | 98/163 [01:54<01:07,  1.03s/it, loss=2.6730, batch_acc=0.3125, running_acc=0.2262, grad=5.8003]Training epoch 1:  60%|██████    | 98/163 [01:54<01:07,  1.03s/it, loss=2.5148, batch_acc=0.2500, running_acc=0.2264, grad=5.2595]Training epoch 1:  61%|██████    | 99/163 [01:55<01:03,  1.01it/s, loss=2.5148, batch_acc=0.2500, running_acc=0.2264, grad=5.2595]Training epoch 1:  61%|██████    | 99/163 [01:55<01:03,  1.01it/s, loss=2.5347, batch_acc=0.1875, running_acc=0.2260, grad=6.3654]Training epoch 1:  61%|██████▏   | 100/163 [01:56<01:07,  1.08s/it, loss=2.5347, batch_acc=0.1875, running_acc=0.2260, grad=6.3654]Training epoch 1:  61%|██████▏   | 100/163 [01:56<01:07,  1.08s/it, loss=2.7028, batch_acc=0.2500, running_acc=0.2263, grad=6.5505]Training epoch 1:  62%|██████▏   | 101/163 [01:57<01:02,  1.02s/it, loss=2.7028, batch_acc=0.2500, running_acc=0.2263, grad=6.5505]Training epoch 1:  62%|██████▏   | 101/163 [01:57<01:02,  1.02s/it, loss=2.6047, batch_acc=0.3125, running_acc=0.2271, grad=5.4385]Training epoch 1:  63%|██████▎   | 102/163 [01:58<00:59,  1.03it/s, loss=2.6047, batch_acc=0.3125, running_acc=0.2271, grad=5.4385]Training epoch 1:  63%|██████▎   | 102/163 [01:58<00:59,  1.03it/s, loss=3.0693, batch_acc=0.2812, running_acc=0.2276, grad=5.5909]Training epoch 1:  63%|██████▎   | 103/163 [01:59<00:56,  1.06it/s, loss=3.0693, batch_acc=0.2812, running_acc=0.2276, grad=5.5909]Training epoch 1:  63%|██████▎   | 103/163 [01:59<00:56,  1.06it/s, loss=2.6042, batch_acc=0.1875, running_acc=0.2272, grad=7.2799]Training epoch 1:  64%|██████▍   | 104/163 [02:00<00:56,  1.05it/s, loss=2.6042, batch_acc=0.1875, running_acc=0.2272, grad=7.2799]Training epoch 1:  64%|██████▍   | 104/163 [02:00<00:56,  1.05it/s, loss=2.6677, batch_acc=0.2812, running_acc=0.2278, grad=5.8921]Training epoch 1:  64%|██████▍   | 105/163 [02:01<00:53,  1.08it/s, loss=2.6677, batch_acc=0.2812, running_acc=0.2278, grad=5.8921]Training epoch 1:  64%|██████▍   | 105/163 [02:01<00:53,  1.08it/s, loss=3.2229, batch_acc=0.1250, running_acc=0.2268, grad=6.9798]Training epoch 1:  65%|██████▌   | 106/163 [02:02<00:52,  1.09it/s, loss=3.2229, batch_acc=0.1250, running_acc=0.2268, grad=6.9798]Training epoch 1:  65%|██████▌   | 106/163 [02:02<00:52,  1.09it/s, loss=2.9397, batch_acc=0.1562, running_acc=0.2261, grad=6.0483]Training epoch 1:  66%|██████▌   | 107/163 [02:02<00:50,  1.11it/s, loss=2.9397, batch_acc=0.1562, running_acc=0.2261, grad=6.0483]Training epoch 1:  66%|██████▌   | 107/163 [02:02<00:50,  1.11it/s, loss=2.6954, batch_acc=0.3438, running_acc=0.2272, grad=5.5222]Training epoch 1:  66%|██████▋   | 108/163 [02:04<00:54,  1.02it/s, loss=2.6954, batch_acc=0.3438, running_acc=0.2272, grad=5.5222]Training epoch 1:  66%|██████▋   | 108/163 [02:04<00:54,  1.02it/s, loss=2.8012, batch_acc=0.1562, running_acc=0.2266, grad=5.7600]Training epoch 1:  67%|██████▋   | 109/163 [02:04<00:51,  1.05it/s, loss=2.8012, batch_acc=0.1562, running_acc=0.2266, grad=5.7600]Training epoch 1:  67%|██████▋   | 109/163 [02:04<00:51,  1.05it/s, loss=2.4020, batch_acc=0.3125, running_acc=0.2274, grad=8.3863]Training epoch 1:  67%|██████▋   | 110/163 [02:05<00:49,  1.08it/s, loss=2.4020, batch_acc=0.3125, running_acc=0.2274, grad=8.3863]Training epoch 1:  67%|██████▋   | 110/163 [02:05<00:49,  1.08it/s, loss=2.0706, batch_acc=0.4688, running_acc=0.2295, grad=6.3234]Training epoch 1:  68%|██████▊   | 111/163 [02:06<00:47,  1.09it/s, loss=2.0706, batch_acc=0.4688, running_acc=0.2295, grad=6.3234]Training epoch 1:  68%|██████▊   | 111/163 [02:06<00:47,  1.09it/s, loss=2.4474, batch_acc=0.3438, running_acc=0.2306, grad=6.6772]Training epoch 1:  69%|██████▊   | 112/163 [02:08<00:53,  1.05s/it, loss=2.4474, batch_acc=0.3438, running_acc=0.2306, grad=6.6772]Training epoch 1:  69%|██████▊   | 112/163 [02:08<00:53,  1.05s/it, loss=2.8054, batch_acc=0.2188, running_acc=0.2305, grad=5.1641]Training epoch 1:  69%|██████▉   | 113/163 [02:08<00:49,  1.00it/s, loss=2.8054, batch_acc=0.2188, running_acc=0.2305, grad=5.1641]Training epoch 1:  69%|██████▉   | 113/163 [02:08<00:49,  1.00it/s, loss=2.3432, batch_acc=0.4688, running_acc=0.2326, grad=6.5515]Training epoch 1:  70%|██████▉   | 114/163 [02:09<00:47,  1.04it/s, loss=2.3432, batch_acc=0.4688, running_acc=0.2326, grad=6.5515]Training epoch 1:  70%|██████▉   | 114/163 [02:09<00:47,  1.04it/s, loss=2.6626, batch_acc=0.2188, running_acc=0.2325, grad=4.9606]Training epoch 1:  71%|███████   | 115/163 [02:10<00:44,  1.07it/s, loss=2.6626, batch_acc=0.2188, running_acc=0.2325, grad=4.9606]Training epoch 1:  71%|███████   | 115/163 [02:10<00:44,  1.07it/s, loss=2.6491, batch_acc=0.1562, running_acc=0.2318, grad=6.2952]Training epoch 1:  71%|███████   | 116/163 [02:11<00:45,  1.03it/s, loss=2.6491, batch_acc=0.1562, running_acc=0.2318, grad=6.2952]Training epoch 1:  71%|███████   | 116/163 [02:11<00:45,  1.03it/s, loss=2.6641, batch_acc=0.2812, running_acc=0.2322, grad=6.3702]Training epoch 1:  72%|███████▏  | 117/163 [02:12<00:43,  1.06it/s, loss=2.6641, batch_acc=0.2812, running_acc=0.2322, grad=6.3702]Training epoch 1:  72%|███████▏  | 117/163 [02:12<00:43,  1.06it/s, loss=2.6671, batch_acc=0.2812, running_acc=0.2326, grad=9.1104]Training epoch 1:  72%|███████▏  | 118/163 [02:13<00:41,  1.08it/s, loss=2.6671, batch_acc=0.2812, running_acc=0.2326, grad=9.1104]Training epoch 1:  72%|███████▏  | 118/163 [02:13<00:41,  1.08it/s, loss=2.5403, batch_acc=0.3125, running_acc=0.2333, grad=4.8457]Training epoch 1:  73%|███████▎  | 119/163 [02:14<00:39,  1.10it/s, loss=2.5403, batch_acc=0.3125, running_acc=0.2333, grad=4.8457]Training epoch 1:  73%|███████▎  | 119/163 [02:14<00:39,  1.10it/s, loss=2.3724, batch_acc=0.2812, running_acc=0.2337, grad=6.2766]Training epoch 1:  74%|███████▎  | 120/163 [02:15<00:41,  1.03it/s, loss=2.3724, batch_acc=0.2812, running_acc=0.2337, grad=6.2766]Training epoch 1:  74%|███████▎  | 120/163 [02:15<00:41,  1.03it/s, loss=2.5772, batch_acc=0.2188, running_acc=0.2336, grad=5.5296]Training epoch 1:  74%|███████▍  | 121/163 [02:16<00:39,  1.06it/s, loss=2.5772, batch_acc=0.2188, running_acc=0.2336, grad=5.5296]Training epoch 1:  74%|███████▍  | 121/163 [02:16<00:39,  1.06it/s, loss=2.5381, batch_acc=0.3438, running_acc=0.2345, grad=6.3022]Training epoch 1:  75%|███████▍  | 122/163 [02:17<00:37,  1.08it/s, loss=2.5381, batch_acc=0.3438, running_acc=0.2345, grad=6.3022]Training epoch 1:  75%|███████▍  | 122/163 [02:17<00:37,  1.08it/s, loss=2.4161, batch_acc=0.2812, running_acc=0.2349, grad=6.4378]Training epoch 1:  75%|███████▌  | 123/163 [02:18<00:36,  1.10it/s, loss=2.4161, batch_acc=0.2812, running_acc=0.2349, grad=6.4378]Training epoch 1:  75%|███████▌  | 123/163 [02:18<00:36,  1.10it/s, loss=2.6044, batch_acc=0.3125, running_acc=0.2355, grad=8.4029]Training epoch 1:  76%|███████▌  | 124/163 [02:20<00:47,  1.22s/it, loss=2.6044, batch_acc=0.3125, running_acc=0.2355, grad=8.4029]Training epoch 1:  76%|███████▌  | 124/163 [02:20<00:47,  1.22s/it, loss=2.6864, batch_acc=0.3125, running_acc=0.2361, grad=7.1206]Training epoch 1:  77%|███████▋  | 125/163 [02:20<00:42,  1.12s/it, loss=2.6864, batch_acc=0.3125, running_acc=0.2361, grad=7.1206]Training epoch 1:  77%|███████▋  | 125/163 [02:20<00:42,  1.12s/it, loss=2.4240, batch_acc=0.4062, running_acc=0.2375, grad=6.4352]Training epoch 1:  77%|███████▋  | 126/163 [02:21<00:38,  1.05s/it, loss=2.4240, batch_acc=0.4062, running_acc=0.2375, grad=6.4352]Training epoch 1:  77%|███████▋  | 126/163 [02:21<00:38,  1.05s/it, loss=2.4330, batch_acc=0.3125, running_acc=0.2381, grad=5.2815]Training epoch 1:  78%|███████▊  | 127/163 [02:22<00:35,  1.00it/s, loss=2.4330, batch_acc=0.3125, running_acc=0.2381, grad=5.2815]Training epoch 1:  78%|███████▊  | 127/163 [02:22<00:35,  1.00it/s, loss=2.4277, batch_acc=0.3125, running_acc=0.2387, grad=5.3577]Training epoch 1:  79%|███████▊  | 128/163 [02:24<00:46,  1.34s/it, loss=2.4277, batch_acc=0.3125, running_acc=0.2387, grad=5.3577]Training epoch 1:  79%|███████▊  | 128/163 [02:24<00:46,  1.34s/it, loss=2.3568, batch_acc=0.2500, running_acc=0.2388, grad=5.3227]Training epoch 1:  79%|███████▉  | 129/163 [02:25<00:40,  1.20s/it, loss=2.3568, batch_acc=0.2500, running_acc=0.2388, grad=5.3227]Training epoch 1:  79%|███████▉  | 129/163 [02:25<00:40,  1.20s/it, loss=2.6774, batch_acc=0.2188, running_acc=0.2386, grad=5.0897]Training epoch 1:  80%|███████▉  | 130/163 [02:26<00:36,  1.10s/it, loss=2.6774, batch_acc=0.2188, running_acc=0.2386, grad=5.0897]Training epoch 1:  80%|███████▉  | 130/163 [02:26<00:36,  1.10s/it, loss=2.5510, batch_acc=0.3750, running_acc=0.2397, grad=5.4073]Training epoch 1:  80%|████████  | 131/163 [02:27<00:33,  1.04s/it, loss=2.5510, batch_acc=0.3750, running_acc=0.2397, grad=5.4073]Training epoch 1:  80%|████████  | 131/163 [02:27<00:33,  1.04s/it, loss=2.8562, batch_acc=0.2500, running_acc=0.2397, grad=5.6078]Training epoch 1:  81%|████████  | 132/163 [02:28<00:31,  1.01s/it, loss=2.8562, batch_acc=0.2500, running_acc=0.2397, grad=5.6078]Training epoch 1:  81%|████████  | 132/163 [02:28<00:31,  1.01s/it, loss=2.7667, batch_acc=0.1875, running_acc=0.2393, grad=5.6550]Training epoch 1:  82%|████████▏ | 133/163 [02:29<00:29,  1.03it/s, loss=2.7667, batch_acc=0.1875, running_acc=0.2393, grad=5.6550]Training epoch 1:  82%|████████▏ | 133/163 [02:29<00:29,  1.03it/s, loss=2.5408, batch_acc=0.1562, running_acc=0.2387, grad=7.6922]Training epoch 1:  82%|████████▏ | 134/163 [02:30<00:27,  1.06it/s, loss=2.5408, batch_acc=0.1562, running_acc=0.2387, grad=7.6922]Training epoch 1:  82%|████████▏ | 134/163 [02:30<00:27,  1.06it/s, loss=2.4261, batch_acc=0.3125, running_acc=0.2393, grad=6.9943]Training epoch 1:  83%|████████▎ | 135/163 [02:31<00:25,  1.08it/s, loss=2.4261, batch_acc=0.3125, running_acc=0.2393, grad=6.9943]Training epoch 1:  83%|████████▎ | 135/163 [02:31<00:25,  1.08it/s, loss=2.5381, batch_acc=0.2188, running_acc=0.2391, grad=8.7192]Training epoch 1:  83%|████████▎ | 136/163 [02:32<00:27,  1.01s/it, loss=2.5381, batch_acc=0.2188, running_acc=0.2391, grad=8.7192]Training epoch 1:  83%|████████▎ | 136/163 [02:32<00:27,  1.01s/it, loss=2.6200, batch_acc=0.1875, running_acc=0.2387, grad=11.8554]Training epoch 1:  84%|████████▍ | 137/163 [02:33<00:25,  1.03it/s, loss=2.6200, batch_acc=0.1875, running_acc=0.2387, grad=11.8554]Training epoch 1:  84%|████████▍ | 137/163 [02:33<00:25,  1.03it/s, loss=2.7441, batch_acc=0.1875, running_acc=0.2384, grad=12.0348]Training epoch 1:  85%|████████▍ | 138/163 [02:34<00:23,  1.06it/s, loss=2.7441, batch_acc=0.1875, running_acc=0.2384, grad=12.0348]Training epoch 1:  85%|████████▍ | 138/163 [02:34<00:23,  1.06it/s, loss=2.6376, batch_acc=0.3750, running_acc=0.2394, grad=6.7393] Training epoch 1:  85%|████████▌ | 139/163 [02:34<00:22,  1.09it/s, loss=2.6376, batch_acc=0.3750, running_acc=0.2394, grad=6.7393]Training epoch 1:  85%|████████▌ | 139/163 [02:34<00:22,  1.09it/s, loss=2.5763, batch_acc=0.3125, running_acc=0.2399, grad=6.3416]Training epoch 1:  86%|████████▌ | 140/163 [02:36<00:23,  1.03s/it, loss=2.5763, batch_acc=0.3125, running_acc=0.2399, grad=6.3416]Training epoch 1:  86%|████████▌ | 140/163 [02:36<00:23,  1.03s/it, loss=2.1707, batch_acc=0.3750, running_acc=0.2408, grad=5.3750]Training epoch 1:  87%|████████▋ | 141/163 [02:37<00:21,  1.01it/s, loss=2.1707, batch_acc=0.3750, running_acc=0.2408, grad=5.3750]Training epoch 1:  87%|████████▋ | 141/163 [02:37<00:21,  1.01it/s, loss=2.4063, batch_acc=0.3125, running_acc=0.2414, grad=8.6050]Training epoch 1:  87%|████████▋ | 142/163 [02:37<00:20,  1.05it/s, loss=2.4063, batch_acc=0.3125, running_acc=0.2414, grad=8.6050]Training epoch 1:  87%|████████▋ | 142/163 [02:37<00:20,  1.05it/s, loss=2.9022, batch_acc=0.1562, running_acc=0.2408, grad=7.2140]Training epoch 1:  88%|████████▊ | 143/163 [02:38<00:18,  1.07it/s, loss=2.9022, batch_acc=0.1562, running_acc=0.2408, grad=7.2140]Training epoch 1:  88%|████████▊ | 143/163 [02:38<00:18,  1.07it/s, loss=2.6518, batch_acc=0.1562, running_acc=0.2402, grad=7.0131]Training epoch 1:  88%|████████▊ | 144/163 [02:40<00:23,  1.22s/it, loss=2.6518, batch_acc=0.1562, running_acc=0.2402, grad=7.0131]Training epoch 1:  88%|████████▊ | 144/163 [02:40<00:23,  1.22s/it, loss=2.9811, batch_acc=0.2188, running_acc=0.2400, grad=5.5290]Training epoch 1:  89%|████████▉ | 145/163 [02:41<00:20,  1.12s/it, loss=2.9811, batch_acc=0.2188, running_acc=0.2400, grad=5.5290]Training epoch 1:  89%|████████▉ | 145/163 [02:41<00:20,  1.12s/it, loss=2.6537, batch_acc=0.2188, running_acc=0.2399, grad=7.4406]Training epoch 1:  90%|████████▉ | 146/163 [02:42<00:17,  1.04s/it, loss=2.6537, batch_acc=0.2188, running_acc=0.2399, grad=7.4406]Training epoch 1:  90%|████████▉ | 146/163 [02:42<00:17,  1.04s/it, loss=2.0850, batch_acc=0.4062, running_acc=0.2410, grad=5.8094]Training epoch 1:  90%|█████████ | 147/163 [02:43<00:15,  1.01it/s, loss=2.0850, batch_acc=0.4062, running_acc=0.2410, grad=5.8094]Training epoch 1:  90%|█████████ | 147/163 [02:43<00:15,  1.01it/s, loss=2.5837, batch_acc=0.2188, running_acc=0.2409, grad=5.4576]Training epoch 1:  91%|█████████ | 148/163 [02:44<00:15,  1.06s/it, loss=2.5837, batch_acc=0.2188, running_acc=0.2409, grad=5.4576]Training epoch 1:  91%|█████████ | 148/163 [02:44<00:15,  1.06s/it, loss=2.3599, batch_acc=0.2812, running_acc=0.2411, grad=6.2630]Training epoch 1:  91%|█████████▏| 149/163 [02:45<00:14,  1.00s/it, loss=2.3599, batch_acc=0.2812, running_acc=0.2411, grad=6.2630]Training epoch 1:  91%|█████████▏| 149/163 [02:45<00:14,  1.00s/it, loss=2.8666, batch_acc=0.1875, running_acc=0.2408, grad=6.0467]Training epoch 1:  92%|█████████▏| 150/163 [02:46<00:12,  1.04it/s, loss=2.8666, batch_acc=0.1875, running_acc=0.2408, grad=6.0467]Training epoch 1:  92%|█████████▏| 150/163 [02:46<00:12,  1.04it/s, loss=2.5998, batch_acc=0.2500, running_acc=0.2408, grad=6.8842]Training epoch 1:  93%|█████████▎| 151/163 [02:47<00:11,  1.06it/s, loss=2.5998, batch_acc=0.2500, running_acc=0.2408, grad=6.8842]Training epoch 1:  93%|█████████▎| 151/163 [02:47<00:11,  1.06it/s, loss=2.6583, batch_acc=0.1250, running_acc=0.2401, grad=5.7724]Training epoch 1:  93%|█████████▎| 152/163 [02:48<00:10,  1.06it/s, loss=2.6583, batch_acc=0.1250, running_acc=0.2401, grad=5.7724]Training epoch 1:  93%|█████████▎| 152/163 [02:48<00:10,  1.06it/s, loss=2.5561, batch_acc=0.1875, running_acc=0.2397, grad=5.6376]Training epoch 1:  94%|█████████▍| 153/163 [02:49<00:09,  1.08it/s, loss=2.5561, batch_acc=0.1875, running_acc=0.2397, grad=5.6376]Training epoch 1:  94%|█████████▍| 153/163 [02:49<00:09,  1.08it/s, loss=2.5522, batch_acc=0.3125, running_acc=0.2402, grad=7.6854]Training epoch 1:  94%|█████████▍| 154/163 [02:49<00:08,  1.10it/s, loss=2.5522, batch_acc=0.3125, running_acc=0.2402, grad=7.6854]Training epoch 1:  94%|█████████▍| 154/163 [02:49<00:08,  1.10it/s, loss=2.5525, batch_acc=0.3438, running_acc=0.2409, grad=5.2085]Training epoch 1:  95%|█████████▌| 155/163 [02:50<00:07,  1.11it/s, loss=2.5525, batch_acc=0.3438, running_acc=0.2409, grad=5.2085]Training epoch 1:  95%|█████████▌| 155/163 [02:50<00:07,  1.11it/s, loss=2.2882, batch_acc=0.3125, running_acc=0.2413, grad=6.6927]Training epoch 1:  96%|█████████▌| 156/163 [02:52<00:07,  1.05s/it, loss=2.2882, batch_acc=0.3125, running_acc=0.2413, grad=6.6927]Training epoch 1:  96%|█████████▌| 156/163 [02:52<00:07,  1.05s/it, loss=2.5588, batch_acc=0.3438, running_acc=0.2420, grad=5.4613]Training epoch 1:  96%|█████████▋| 157/163 [02:53<00:05,  1.00it/s, loss=2.5588, batch_acc=0.3438, running_acc=0.2420, grad=5.4613]Training epoch 1:  96%|█████████▋| 157/163 [02:53<00:05,  1.00it/s, loss=2.5759, batch_acc=0.3438, running_acc=0.2426, grad=6.2195]Training epoch 1:  97%|█████████▋| 158/163 [02:53<00:04,  1.04it/s, loss=2.5759, batch_acc=0.3438, running_acc=0.2426, grad=6.2195]Training epoch 1:  97%|█████████▋| 158/163 [02:53<00:04,  1.04it/s, loss=2.1854, batch_acc=0.3125, running_acc=0.2431, grad=7.1264]Training epoch 1:  98%|█████████▊| 159/163 [02:54<00:03,  1.07it/s, loss=2.1854, batch_acc=0.3125, running_acc=0.2431, grad=7.1264]Training epoch 1:  98%|█████████▊| 159/163 [02:54<00:03,  1.07it/s, loss=2.6278, batch_acc=0.2812, running_acc=0.2433, grad=6.4729]Training epoch 1:  98%|█████████▊| 160/163 [02:56<00:03,  1.23s/it, loss=2.6278, batch_acc=0.2812, running_acc=0.2433, grad=6.4729]Training epoch 1:  98%|█████████▊| 160/163 [02:56<00:03,  1.23s/it, loss=2.9782, batch_acc=0.2188, running_acc=0.2432, grad=6.1296]Training epoch 1:  99%|█████████▉| 161/163 [02:57<00:02,  1.12s/it, loss=2.9782, batch_acc=0.2188, running_acc=0.2432, grad=6.1296]Training epoch 1:  99%|█████████▉| 161/163 [02:57<00:02,  1.12s/it, loss=2.2751, batch_acc=0.3438, running_acc=0.2438, grad=6.2430]Training epoch 1:  99%|█████████▉| 162/163 [02:58<00:01,  1.05s/it, loss=2.2751, batch_acc=0.3438, running_acc=0.2438, grad=6.2430]Training epoch 1:  99%|█████████▉| 162/163 [02:58<00:01,  1.05s/it, loss=2.4902, batch_acc=0.3438, running_acc=0.2444, grad=5.4261]Training epoch 1: 100%|██████████| 163/163 [02:59<00:00,  1.08it/s, loss=2.4902, batch_acc=0.3438, running_acc=0.2444, grad=5.4261]Training epoch 1: 100%|██████████| 163/163 [02:59<00:00,  1.08it/s, loss=2.1253, batch_acc=0.3333, running_acc=0.2448, grad=6.9993]Training epoch 1: 100%|██████████| 163/163 [02:59<00:00,  1.10s/it, loss=2.1253, batch_acc=0.3333, running_acc=0.2448, grad=6.9993]
Evaluation epoch 1:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 1:   4%|▎         | 1/28 [00:05<02:22,  5.28s/it]Evaluation epoch 1:   4%|▎         | 1/28 [00:05<02:22,  5.28s/it, loss=1.8956, batch_acc=0.3750, running_acc=0.3750]Evaluation epoch 1:   7%|▋         | 2/28 [00:05<01:00,  2.33s/it, loss=1.8956, batch_acc=0.3750, running_acc=0.3750]Evaluation epoch 1:   7%|▋         | 2/28 [00:05<01:00,  2.33s/it, loss=2.0715, batch_acc=0.3750, running_acc=0.3750]Evaluation epoch 1:  11%|█         | 3/28 [00:05<00:34,  1.39s/it, loss=2.0715, batch_acc=0.3750, running_acc=0.3750]Evaluation epoch 1:  11%|█         | 3/28 [00:05<00:34,  1.39s/it, loss=2.1564, batch_acc=0.1875, running_acc=0.3125]Evaluation epoch 1:  14%|█▍        | 4/28 [00:10<01:03,  2.67s/it, loss=2.1564, batch_acc=0.1875, running_acc=0.3125]Evaluation epoch 1:  14%|█▍        | 4/28 [00:10<01:03,  2.67s/it, loss=3.1306, batch_acc=0.0625, running_acc=0.2500]Evaluation epoch 1:  18%|█▊        | 5/28 [00:10<00:41,  1.80s/it, loss=3.1306, batch_acc=0.0625, running_acc=0.2500]Evaluation epoch 1:  18%|█▊        | 5/28 [00:10<00:41,  1.80s/it, loss=2.6377, batch_acc=0.2500, running_acc=0.2500]Evaluation epoch 1:  21%|██▏       | 6/28 [00:10<00:28,  1.28s/it, loss=2.6377, batch_acc=0.2500, running_acc=0.2500]Evaluation epoch 1:  21%|██▏       | 6/28 [00:10<00:28,  1.28s/it, loss=2.8618, batch_acc=0.3125, running_acc=0.2604]Evaluation epoch 1:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=2.8618, batch_acc=0.3125, running_acc=0.2604]Evaluation epoch 1:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=2.5553, batch_acc=0.1562, running_acc=0.2455]Evaluation epoch 1:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=2.5553, batch_acc=0.1562, running_acc=0.2455]Evaluation epoch 1:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=2.2817, batch_acc=0.2812, running_acc=0.2500]Evaluation epoch 1:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=2.2817, batch_acc=0.2812, running_acc=0.2500]Evaluation epoch 1:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=2.5782, batch_acc=0.3438, running_acc=0.2604]Evaluation epoch 1:  36%|███▌      | 10/28 [00:15<00:16,  1.07it/s, loss=2.5782, batch_acc=0.3438, running_acc=0.2604]Evaluation epoch 1:  36%|███▌      | 10/28 [00:15<00:16,  1.07it/s, loss=1.1914, batch_acc=0.8438, running_acc=0.3187]Evaluation epoch 1:  39%|███▉      | 11/28 [00:15<00:12,  1.37it/s, loss=1.1914, batch_acc=0.8438, running_acc=0.3187]Evaluation epoch 1:  39%|███▉      | 11/28 [00:15<00:12,  1.37it/s, loss=2.9639, batch_acc=0.1250, running_acc=0.3011]Evaluation epoch 1:  43%|████▎     | 12/28 [00:20<00:35,  2.25s/it, loss=2.9639, batch_acc=0.1250, running_acc=0.3011]Evaluation epoch 1:  43%|████▎     | 12/28 [00:20<00:35,  2.25s/it, loss=2.5139, batch_acc=0.2500, running_acc=0.2969]Evaluation epoch 1:  46%|████▋     | 13/28 [00:21<00:24,  1.64s/it, loss=2.5139, batch_acc=0.2500, running_acc=0.2969]Evaluation epoch 1:  46%|████▋     | 13/28 [00:21<00:24,  1.64s/it, loss=2.2515, batch_acc=0.5625, running_acc=0.3173]Evaluation epoch 1:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=2.2515, batch_acc=0.5625, running_acc=0.3173]Evaluation epoch 1:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=1.5111, batch_acc=0.6562, running_acc=0.3415]Evaluation epoch 1:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.5111, batch_acc=0.6562, running_acc=0.3415]Evaluation epoch 1:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=3.2160, batch_acc=0.2500, running_acc=0.3354]Evaluation epoch 1:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=3.2160, batch_acc=0.2500, running_acc=0.3354]Evaluation epoch 1:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=2.7017, batch_acc=0.2188, running_acc=0.3281]Evaluation epoch 1:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=2.7017, batch_acc=0.2188, running_acc=0.3281]Evaluation epoch 1:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=2.2620, batch_acc=0.3438, running_acc=0.3290]Evaluation epoch 1:  64%|██████▍   | 18/28 [00:25<00:08,  1.15it/s, loss=2.2620, batch_acc=0.3438, running_acc=0.3290]Evaluation epoch 1:  64%|██████▍   | 18/28 [00:25<00:08,  1.15it/s, loss=2.2215, batch_acc=0.4688, running_acc=0.3368]Evaluation epoch 1:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=2.2215, batch_acc=0.4688, running_acc=0.3368]Evaluation epoch 1:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=2.4092, batch_acc=0.1875, running_acc=0.3289]Evaluation epoch 1:  71%|███████▏  | 20/28 [00:28<00:10,  1.33s/it, loss=2.4092, batch_acc=0.1875, running_acc=0.3289]Evaluation epoch 1:  71%|███████▏  | 20/28 [00:28<00:10,  1.33s/it, loss=3.3036, batch_acc=0.0000, running_acc=0.3125]Evaluation epoch 1:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=3.3036, batch_acc=0.0000, running_acc=0.3125]Evaluation epoch 1:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=2.8981, batch_acc=0.0938, running_acc=0.3021]Evaluation epoch 1:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=2.8981, batch_acc=0.0938, running_acc=0.3021]Evaluation epoch 1:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=2.7503, batch_acc=0.1875, running_acc=0.2969]Evaluation epoch 1:  82%|████████▏ | 23/28 [00:29<00:03,  1.59it/s, loss=2.7503, batch_acc=0.1875, running_acc=0.2969]Evaluation epoch 1:  82%|████████▏ | 23/28 [00:29<00:03,  1.59it/s, loss=2.7868, batch_acc=0.0312, running_acc=0.2853]Evaluation epoch 1:  86%|████████▌ | 24/28 [00:34<00:08,  2.02s/it, loss=2.7868, batch_acc=0.0312, running_acc=0.2853]Evaluation epoch 1:  86%|████████▌ | 24/28 [00:34<00:08,  2.02s/it, loss=1.9556, batch_acc=0.4062, running_acc=0.2904]Evaluation epoch 1:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=1.9556, batch_acc=0.4062, running_acc=0.2904]Evaluation epoch 1:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=1.8851, batch_acc=0.5938, running_acc=0.3025]Evaluation epoch 1:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=1.8851, batch_acc=0.5938, running_acc=0.3025]Evaluation epoch 1:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=2.2858, batch_acc=0.3438, running_acc=0.3041]Evaluation epoch 1:  96%|█████████▋| 27/28 [00:35<00:00,  1.16it/s, loss=2.2858, batch_acc=0.3438, running_acc=0.3041]Evaluation epoch 1:  96%|█████████▋| 27/28 [00:35<00:00,  1.16it/s, loss=2.6352, batch_acc=0.1875, running_acc=0.2998]Evaluation epoch 1: 100%|██████████| 28/28 [00:35<00:00,  1.16it/s, loss=1.2521, batch_acc=0.6667, running_acc=0.3010]Evaluation epoch 1: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=1.2521, batch_acc=0.6667, running_acc=0.3010]
Training epoch 2:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 2:   1%|          | 1/163 [00:06<16:34,  6.14s/it]Training epoch 2:   1%|          | 1/163 [00:06<16:34,  6.14s/it, loss=2.1580, batch_acc=0.4062, running_acc=0.4062, grad=5.2198]Training epoch 2:   1%|          | 2/163 [00:07<08:10,  3.05s/it, loss=2.1580, batch_acc=0.4062, running_acc=0.4062, grad=5.2198]Training epoch 2:   1%|          | 2/163 [00:07<08:10,  3.05s/it, loss=2.3017, batch_acc=0.4375, running_acc=0.4219, grad=5.5868]Training epoch 2:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=2.3017, batch_acc=0.4375, running_acc=0.4219, grad=5.5868]Training epoch 2:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=2.6202, batch_acc=0.3750, running_acc=0.4062, grad=6.0121]Training epoch 2:   2%|▏         | 4/163 [00:10<06:30,  2.45s/it, loss=2.6202, batch_acc=0.3750, running_acc=0.4062, grad=6.0121]Training epoch 2:   2%|▏         | 4/163 [00:10<06:30,  2.45s/it, loss=2.5286, batch_acc=0.4062, running_acc=0.4062, grad=5.6405]Training epoch 2:   3%|▎         | 5/163 [00:11<04:57,  1.89s/it, loss=2.5286, batch_acc=0.4062, running_acc=0.4062, grad=5.6405]Training epoch 2:   3%|▎         | 5/163 [00:11<04:57,  1.89s/it, loss=2.3273, batch_acc=0.3438, running_acc=0.3937, grad=6.2140]Training epoch 2:   4%|▎         | 6/163 [00:12<04:02,  1.54s/it, loss=2.3273, batch_acc=0.3438, running_acc=0.3937, grad=6.2140]Training epoch 2:   4%|▎         | 6/163 [00:12<04:02,  1.54s/it, loss=2.2488, batch_acc=0.4062, running_acc=0.3958, grad=5.5748]Training epoch 2:   4%|▍         | 7/163 [00:13<03:26,  1.33s/it, loss=2.2488, batch_acc=0.4062, running_acc=0.3958, grad=5.5748]Training epoch 2:   4%|▍         | 7/163 [00:13<03:26,  1.33s/it, loss=2.5634, batch_acc=0.2500, running_acc=0.3750, grad=5.3146]Training epoch 2:   5%|▍         | 8/163 [00:14<03:25,  1.33s/it, loss=2.5634, batch_acc=0.2500, running_acc=0.3750, grad=5.3146]Training epoch 2:   5%|▍         | 8/163 [00:14<03:25,  1.33s/it, loss=1.9131, batch_acc=0.4062, running_acc=0.3789, grad=7.7354]Training epoch 2:   6%|▌         | 9/163 [00:15<03:02,  1.19s/it, loss=1.9131, batch_acc=0.4062, running_acc=0.3789, grad=7.7354]Training epoch 2:   6%|▌         | 9/163 [00:15<03:02,  1.19s/it, loss=2.2080, batch_acc=0.4062, running_acc=0.3819, grad=5.6195]Training epoch 2:   6%|▌         | 10/163 [00:16<02:50,  1.11s/it, loss=2.2080, batch_acc=0.4062, running_acc=0.3819, grad=5.6195]Training epoch 2:   6%|▌         | 10/163 [00:16<02:50,  1.11s/it, loss=2.6624, batch_acc=0.2812, running_acc=0.3719, grad=5.8859]Training epoch 2:   7%|▋         | 11/163 [00:17<02:38,  1.04s/it, loss=2.6624, batch_acc=0.2812, running_acc=0.3719, grad=5.8859]Training epoch 2:   7%|▋         | 11/163 [00:17<02:38,  1.04s/it, loss=2.3600, batch_acc=0.3438, running_acc=0.3693, grad=8.5425]Training epoch 2:   7%|▋         | 12/163 [00:18<02:51,  1.13s/it, loss=2.3600, batch_acc=0.3438, running_acc=0.3693, grad=8.5425]Training epoch 2:   7%|▋         | 12/163 [00:18<02:51,  1.13s/it, loss=2.3574, batch_acc=0.3438, running_acc=0.3672, grad=5.8240]Training epoch 2:   8%|▊         | 13/163 [00:19<02:38,  1.06s/it, loss=2.3574, batch_acc=0.3438, running_acc=0.3672, grad=5.8240]Training epoch 2:   8%|▊         | 13/163 [00:19<02:38,  1.06s/it, loss=2.6488, batch_acc=0.1250, running_acc=0.3486, grad=6.0519]Training epoch 2:   9%|▊         | 14/163 [00:20<02:29,  1.00s/it, loss=2.6488, batch_acc=0.1250, running_acc=0.3486, grad=6.0519]Training epoch 2:   9%|▊         | 14/163 [00:20<02:29,  1.00s/it, loss=2.3513, batch_acc=0.3750, running_acc=0.3504, grad=5.7326]Training epoch 2:   9%|▉         | 15/163 [00:21<02:22,  1.04it/s, loss=2.3513, batch_acc=0.3750, running_acc=0.3504, grad=5.7326]Training epoch 2:   9%|▉         | 15/163 [00:21<02:22,  1.04it/s, loss=2.4875, batch_acc=0.2812, running_acc=0.3458, grad=7.1475]Training epoch 2:  10%|▉         | 16/163 [00:23<02:52,  1.18s/it, loss=2.4875, batch_acc=0.2812, running_acc=0.3458, grad=7.1475]Training epoch 2:  10%|▉         | 16/163 [00:23<02:52,  1.18s/it, loss=2.2462, batch_acc=0.2812, running_acc=0.3418, grad=6.6869]Training epoch 2:  10%|█         | 17/163 [00:24<02:38,  1.09s/it, loss=2.2462, batch_acc=0.2812, running_acc=0.3418, grad=6.6869]Training epoch 2:  10%|█         | 17/163 [00:24<02:38,  1.09s/it, loss=2.4474, batch_acc=0.3125, running_acc=0.3401, grad=6.3813]Training epoch 2:  11%|█         | 18/163 [00:25<02:28,  1.02s/it, loss=2.4474, batch_acc=0.3125, running_acc=0.3401, grad=6.3813]Training epoch 2:  11%|█         | 18/163 [00:25<02:28,  1.02s/it, loss=2.3054, batch_acc=0.3125, running_acc=0.3385, grad=8.3946]Training epoch 2:  12%|█▏        | 19/163 [00:25<02:21,  1.02it/s, loss=2.3054, batch_acc=0.3125, running_acc=0.3385, grad=8.3946]Training epoch 2:  12%|█▏        | 19/163 [00:25<02:21,  1.02it/s, loss=2.0624, batch_acc=0.4062, running_acc=0.3421, grad=6.0366]Training epoch 2:  12%|█▏        | 20/163 [00:26<02:24,  1.01s/it, loss=2.0624, batch_acc=0.4062, running_acc=0.3421, grad=6.0366]Training epoch 2:  12%|█▏        | 20/163 [00:26<02:24,  1.01s/it, loss=2.2640, batch_acc=0.2812, running_acc=0.3391, grad=7.4422]Training epoch 2:  13%|█▎        | 21/163 [00:27<02:17,  1.03it/s, loss=2.2640, batch_acc=0.2812, running_acc=0.3391, grad=7.4422]Training epoch 2:  13%|█▎        | 21/163 [00:27<02:17,  1.03it/s, loss=2.7292, batch_acc=0.1562, running_acc=0.3304, grad=5.5909]Training epoch 2:  13%|█▎        | 22/163 [00:28<02:16,  1.04it/s, loss=2.7292, batch_acc=0.1562, running_acc=0.3304, grad=5.5909]Training epoch 2:  13%|█▎        | 22/163 [00:28<02:16,  1.04it/s, loss=2.5983, batch_acc=0.3125, running_acc=0.3295, grad=6.2957]Training epoch 2:  14%|█▍        | 23/163 [00:29<02:11,  1.07it/s, loss=2.5983, batch_acc=0.3125, running_acc=0.3295, grad=6.2957]Training epoch 2:  14%|█▍        | 23/163 [00:29<02:11,  1.07it/s, loss=2.5334, batch_acc=0.1875, running_acc=0.3234, grad=4.7443]Training epoch 2:  15%|█▍        | 24/163 [00:31<02:38,  1.14s/it, loss=2.5334, batch_acc=0.1875, running_acc=0.3234, grad=4.7443]Training epoch 2:  15%|█▍        | 24/163 [00:31<02:38,  1.14s/it, loss=2.5486, batch_acc=0.2500, running_acc=0.3203, grad=6.6101]Training epoch 2:  15%|█▌        | 25/163 [00:32<02:26,  1.06s/it, loss=2.5486, batch_acc=0.2500, running_acc=0.3203, grad=6.6101]Training epoch 2:  15%|█▌        | 25/163 [00:32<02:26,  1.06s/it, loss=2.3522, batch_acc=0.3750, running_acc=0.3225, grad=6.8374]Training epoch 2:  16%|█▌        | 26/163 [00:33<02:19,  1.02s/it, loss=2.3522, batch_acc=0.3750, running_acc=0.3225, grad=6.8374]Training epoch 2:  16%|█▌        | 26/163 [00:33<02:19,  1.02s/it, loss=2.7130, batch_acc=0.2188, running_acc=0.3185, grad=5.4963]Training epoch 2:  17%|█▋        | 27/163 [00:33<02:12,  1.03it/s, loss=2.7130, batch_acc=0.2188, running_acc=0.3185, grad=5.4963]Training epoch 2:  17%|█▋        | 27/163 [00:33<02:12,  1.03it/s, loss=2.4451, batch_acc=0.3750, running_acc=0.3206, grad=4.5561]Training epoch 2:  17%|█▋        | 28/163 [00:34<02:09,  1.04it/s, loss=2.4451, batch_acc=0.3750, running_acc=0.3206, grad=4.5561]Training epoch 2:  17%|█▋        | 28/163 [00:34<02:09,  1.04it/s, loss=2.0895, batch_acc=0.4062, running_acc=0.3237, grad=5.5984]Training epoch 2:  18%|█▊        | 29/163 [00:35<02:05,  1.07it/s, loss=2.0895, batch_acc=0.4062, running_acc=0.3237, grad=5.5984]Training epoch 2:  18%|█▊        | 29/163 [00:35<02:05,  1.07it/s, loss=1.8438, batch_acc=0.4688, running_acc=0.3287, grad=5.7048]Training epoch 2:  18%|█▊        | 30/163 [00:36<02:13,  1.00s/it, loss=1.8438, batch_acc=0.4688, running_acc=0.3287, grad=5.7048]Training epoch 2:  18%|█▊        | 30/163 [00:36<02:13,  1.00s/it, loss=2.1397, batch_acc=0.3750, running_acc=0.3302, grad=7.1532]Training epoch 2:  19%|█▉        | 31/163 [00:37<02:07,  1.03it/s, loss=2.1397, batch_acc=0.3750, running_acc=0.3302, grad=7.1532]Training epoch 2:  19%|█▉        | 31/163 [00:37<02:07,  1.03it/s, loss=2.3950, batch_acc=0.2188, running_acc=0.3266, grad=4.9292]Training epoch 2:  20%|█▉        | 32/163 [00:39<02:18,  1.06s/it, loss=2.3950, batch_acc=0.2188, running_acc=0.3266, grad=4.9292]Training epoch 2:  20%|█▉        | 32/163 [00:39<02:18,  1.06s/it, loss=2.5886, batch_acc=0.2812, running_acc=0.3252, grad=6.4604]Training epoch 2:  20%|██        | 33/163 [00:39<02:11,  1.01s/it, loss=2.5886, batch_acc=0.2812, running_acc=0.3252, grad=6.4604]Training epoch 2:  20%|██        | 33/163 [00:40<02:11,  1.01s/it, loss=2.0438, batch_acc=0.4062, running_acc=0.3277, grad=5.2135]Training epoch 2:  21%|██        | 34/163 [00:41<02:31,  1.17s/it, loss=2.0438, batch_acc=0.4062, running_acc=0.3277, grad=5.2135]Training epoch 2:  21%|██        | 34/163 [00:41<02:31,  1.17s/it, loss=2.2583, batch_acc=0.3438, running_acc=0.3281, grad=6.4639]Training epoch 2:  21%|██▏       | 35/163 [00:42<02:18,  1.08s/it, loss=2.2583, batch_acc=0.3438, running_acc=0.3281, grad=6.4639]Training epoch 2:  21%|██▏       | 35/163 [00:42<02:18,  1.08s/it, loss=2.4748, batch_acc=0.2812, running_acc=0.3268, grad=5.5676]Training epoch 2:  22%|██▏       | 36/163 [00:43<02:11,  1.03s/it, loss=2.4748, batch_acc=0.2812, running_acc=0.3268, grad=5.5676]Training epoch 2:  22%|██▏       | 36/163 [00:43<02:11,  1.03s/it, loss=2.2043, batch_acc=0.4062, running_acc=0.3290, grad=5.4794]Training epoch 2:  23%|██▎       | 37/163 [00:44<02:04,  1.01it/s, loss=2.2043, batch_acc=0.4062, running_acc=0.3290, grad=5.4794]Training epoch 2:  23%|██▎       | 37/163 [00:44<02:04,  1.01it/s, loss=2.2545, batch_acc=0.3438, running_acc=0.3294, grad=5.8768]Training epoch 2:  23%|██▎       | 38/163 [00:45<02:26,  1.17s/it, loss=2.2545, batch_acc=0.3438, running_acc=0.3294, grad=5.8768]Training epoch 2:  23%|██▎       | 38/163 [00:45<02:26,  1.17s/it, loss=2.2725, batch_acc=0.2812, running_acc=0.3281, grad=6.4761]Training epoch 2:  24%|██▍       | 39/163 [00:46<02:14,  1.08s/it, loss=2.2725, batch_acc=0.2812, running_acc=0.3281, grad=6.4761]Training epoch 2:  24%|██▍       | 39/163 [00:46<02:14,  1.08s/it, loss=2.3116, batch_acc=0.2812, running_acc=0.3269, grad=6.0991]Training epoch 2:  25%|██▍       | 40/163 [00:47<02:05,  1.02s/it, loss=2.3116, batch_acc=0.2812, running_acc=0.3269, grad=6.0991]Training epoch 2:  25%|██▍       | 40/163 [00:47<02:05,  1.02s/it, loss=1.9932, batch_acc=0.3438, running_acc=0.3273, grad=5.7049]Training epoch 2:  25%|██▌       | 41/163 [00:48<01:59,  1.02it/s, loss=1.9932, batch_acc=0.3438, running_acc=0.3273, grad=5.7049]Training epoch 2:  25%|██▌       | 41/163 [00:48<01:59,  1.02it/s, loss=2.3616, batch_acc=0.3438, running_acc=0.3277, grad=6.8718]Training epoch 2:  26%|██▌       | 42/163 [00:50<02:34,  1.27s/it, loss=2.3616, batch_acc=0.3438, running_acc=0.3277, grad=6.8718]Training epoch 2:  26%|██▌       | 42/163 [00:50<02:34,  1.27s/it, loss=2.2520, batch_acc=0.3438, running_acc=0.3281, grad=5.1382]Training epoch 2:  26%|██▋       | 43/163 [00:51<02:18,  1.16s/it, loss=2.2520, batch_acc=0.3438, running_acc=0.3281, grad=5.1382]Training epoch 2:  26%|██▋       | 43/163 [00:51<02:18,  1.16s/it, loss=2.1729, batch_acc=0.3125, running_acc=0.3278, grad=8.2810]Training epoch 2:  27%|██▋       | 44/163 [00:52<02:07,  1.07s/it, loss=2.1729, batch_acc=0.3125, running_acc=0.3278, grad=8.2810]Training epoch 2:  27%|██▋       | 44/163 [00:52<02:07,  1.07s/it, loss=2.4243, batch_acc=0.3438, running_acc=0.3281, grad=5.1029]Training epoch 2:  28%|██▊       | 45/163 [00:53<01:59,  1.01s/it, loss=2.4243, batch_acc=0.3438, running_acc=0.3281, grad=5.1029]Training epoch 2:  28%|██▊       | 45/163 [00:53<01:59,  1.01s/it, loss=2.3798, batch_acc=0.3438, running_acc=0.3285, grad=5.7900]Training epoch 2:  28%|██▊       | 46/163 [00:54<02:20,  1.20s/it, loss=2.3798, batch_acc=0.3438, running_acc=0.3285, grad=5.7900]Training epoch 2:  28%|██▊       | 46/163 [00:54<02:20,  1.20s/it, loss=2.5671, batch_acc=0.1875, running_acc=0.3254, grad=5.8412]Training epoch 2:  29%|██▉       | 47/163 [00:55<02:08,  1.10s/it, loss=2.5671, batch_acc=0.1875, running_acc=0.3254, grad=5.8412]Training epoch 2:  29%|██▉       | 47/163 [00:55<02:08,  1.10s/it, loss=2.4627, batch_acc=0.3125, running_acc=0.3251, grad=8.0365]Training epoch 2:  29%|██▉       | 48/163 [00:56<02:00,  1.05s/it, loss=2.4627, batch_acc=0.3125, running_acc=0.3251, grad=8.0365]Training epoch 2:  29%|██▉       | 48/163 [00:56<02:00,  1.05s/it, loss=2.2778, batch_acc=0.3750, running_acc=0.3262, grad=6.2310]Training epoch 2:  30%|███       | 49/163 [00:57<01:54,  1.00s/it, loss=2.2778, batch_acc=0.3750, running_acc=0.3262, grad=6.2310]Training epoch 2:  30%|███       | 49/163 [00:57<01:54,  1.00s/it, loss=2.0120, batch_acc=0.5625, running_acc=0.3310, grad=5.4314]Training epoch 2:  31%|███       | 50/163 [00:59<02:23,  1.27s/it, loss=2.0120, batch_acc=0.5625, running_acc=0.3310, grad=5.4314]Training epoch 2:  31%|███       | 50/163 [00:59<02:23,  1.27s/it, loss=2.4020, batch_acc=0.3750, running_acc=0.3319, grad=5.0175]Training epoch 2:  31%|███▏      | 51/163 [01:00<02:09,  1.15s/it, loss=2.4020, batch_acc=0.3750, running_acc=0.3319, grad=5.0175]Training epoch 2:  31%|███▏      | 51/163 [01:00<02:09,  1.15s/it, loss=1.8928, batch_acc=0.5000, running_acc=0.3352, grad=7.2477]Training epoch 2:  32%|███▏      | 52/163 [01:01<01:58,  1.07s/it, loss=1.8928, batch_acc=0.5000, running_acc=0.3352, grad=7.2477]Training epoch 2:  32%|███▏      | 52/163 [01:01<01:58,  1.07s/it, loss=2.8705, batch_acc=0.2500, running_acc=0.3335, grad=7.3609]Training epoch 2:  33%|███▎      | 53/163 [01:01<01:51,  1.01s/it, loss=2.8705, batch_acc=0.2500, running_acc=0.3335, grad=7.3609]Training epoch 2:  33%|███▎      | 53/163 [01:01<01:51,  1.01s/it, loss=2.3631, batch_acc=0.2188, running_acc=0.3314, grad=6.5995]Training epoch 2:  33%|███▎      | 54/163 [01:03<02:14,  1.23s/it, loss=2.3631, batch_acc=0.2188, running_acc=0.3314, grad=6.5995]Training epoch 2:  33%|███▎      | 54/163 [01:03<02:14,  1.23s/it, loss=2.3432, batch_acc=0.2812, running_acc=0.3304, grad=8.0805]Training epoch 2:  34%|███▎      | 55/163 [01:04<02:01,  1.13s/it, loss=2.3432, batch_acc=0.2812, running_acc=0.3304, grad=8.0805]Training epoch 2:  34%|███▎      | 55/163 [01:04<02:01,  1.13s/it, loss=2.6134, batch_acc=0.3438, running_acc=0.3307, grad=8.9047]Training epoch 2:  34%|███▍      | 56/163 [01:05<01:52,  1.05s/it, loss=2.6134, batch_acc=0.3438, running_acc=0.3307, grad=8.9047]Training epoch 2:  34%|███▍      | 56/163 [01:05<01:52,  1.05s/it, loss=2.2307, batch_acc=0.3438, running_acc=0.3309, grad=6.1352]Training epoch 2:  35%|███▍      | 57/163 [01:06<01:46,  1.00s/it, loss=2.2307, batch_acc=0.3438, running_acc=0.3309, grad=6.1352]Training epoch 2:  35%|███▍      | 57/163 [01:06<01:46,  1.00s/it, loss=2.4396, batch_acc=0.3438, running_acc=0.3311, grad=6.2785]Training epoch 2:  36%|███▌      | 58/163 [01:07<02:01,  1.16s/it, loss=2.4396, batch_acc=0.3438, running_acc=0.3311, grad=6.2785]Training epoch 2:  36%|███▌      | 58/163 [01:07<02:01,  1.16s/it, loss=2.5833, batch_acc=0.2812, running_acc=0.3303, grad=7.2702]Training epoch 2:  36%|███▌      | 59/163 [01:08<01:51,  1.07s/it, loss=2.5833, batch_acc=0.2812, running_acc=0.3303, grad=7.2702]Training epoch 2:  36%|███▌      | 59/163 [01:08<01:51,  1.07s/it, loss=2.2534, batch_acc=0.3438, running_acc=0.3305, grad=6.2925]Training epoch 2:  37%|███▋      | 60/163 [01:09<01:44,  1.02s/it, loss=2.2534, batch_acc=0.3438, running_acc=0.3305, grad=6.2925]Training epoch 2:  37%|███▋      | 60/163 [01:09<01:44,  1.02s/it, loss=1.8502, batch_acc=0.5000, running_acc=0.3333, grad=10.3494]Training epoch 2:  37%|███▋      | 61/163 [01:10<01:40,  1.01it/s, loss=1.8502, batch_acc=0.5000, running_acc=0.3333, grad=10.3494]Training epoch 2:  37%|███▋      | 61/163 [01:10<01:40,  1.01it/s, loss=1.8732, batch_acc=0.5312, running_acc=0.3366, grad=7.0046] Training epoch 2:  38%|███▊      | 62/163 [01:12<01:55,  1.14s/it, loss=1.8732, batch_acc=0.5312, running_acc=0.3366, grad=7.0046]Training epoch 2:  38%|███▊      | 62/163 [01:12<01:55,  1.14s/it, loss=2.0671, batch_acc=0.3438, running_acc=0.3367, grad=6.1153]Training epoch 2:  39%|███▊      | 63/163 [01:12<01:46,  1.06s/it, loss=2.0671, batch_acc=0.3438, running_acc=0.3367, grad=6.1153]Training epoch 2:  39%|███▊      | 63/163 [01:12<01:46,  1.06s/it, loss=2.0519, batch_acc=0.3750, running_acc=0.3373, grad=6.0611]Training epoch 2:  39%|███▉      | 64/163 [01:13<01:39,  1.01s/it, loss=2.0519, batch_acc=0.3750, running_acc=0.3373, grad=6.0611]Training epoch 2:  39%|███▉      | 64/163 [01:13<01:39,  1.01s/it, loss=2.1399, batch_acc=0.4375, running_acc=0.3389, grad=6.6645]Training epoch 2:  40%|███▉      | 65/163 [01:14<01:35,  1.03it/s, loss=2.1399, batch_acc=0.4375, running_acc=0.3389, grad=6.6645]Training epoch 2:  40%|███▉      | 65/163 [01:14<01:35,  1.03it/s, loss=2.2772, batch_acc=0.3750, running_acc=0.3394, grad=8.2736]Training epoch 2:  40%|████      | 66/163 [01:15<01:43,  1.07s/it, loss=2.2772, batch_acc=0.3750, running_acc=0.3394, grad=8.2736]Training epoch 2:  40%|████      | 66/163 [01:15<01:43,  1.07s/it, loss=2.4219, batch_acc=0.2812, running_acc=0.3385, grad=6.7277]Training epoch 2:  41%|████      | 67/163 [01:16<01:37,  1.01s/it, loss=2.4219, batch_acc=0.2812, running_acc=0.3385, grad=6.7277]Training epoch 2:  41%|████      | 67/163 [01:16<01:37,  1.01s/it, loss=2.4723, batch_acc=0.3438, running_acc=0.3386, grad=6.0320]Training epoch 2:  42%|████▏     | 68/163 [01:17<01:32,  1.03it/s, loss=2.4723, batch_acc=0.3438, running_acc=0.3386, grad=6.0320]Training epoch 2:  42%|████▏     | 68/163 [01:17<01:32,  1.03it/s, loss=2.1819, batch_acc=0.3750, running_acc=0.3392, grad=7.1777]Training epoch 2:  42%|████▏     | 69/163 [01:18<01:28,  1.06it/s, loss=2.1819, batch_acc=0.3750, running_acc=0.3392, grad=7.1777]Training epoch 2:  42%|████▏     | 69/163 [01:18<01:28,  1.06it/s, loss=2.5530, batch_acc=0.3125, running_acc=0.3388, grad=9.1290]Training epoch 2:  43%|████▎     | 70/163 [01:19<01:31,  1.02it/s, loss=2.5530, batch_acc=0.3125, running_acc=0.3388, grad=9.1290]Training epoch 2:  43%|████▎     | 70/163 [01:19<01:31,  1.02it/s, loss=2.4216, batch_acc=0.3125, running_acc=0.3384, grad=9.0432]Training epoch 2:  44%|████▎     | 71/163 [01:20<01:27,  1.05it/s, loss=2.4216, batch_acc=0.3125, running_acc=0.3384, grad=9.0432]Training epoch 2:  44%|████▎     | 71/163 [01:20<01:27,  1.05it/s, loss=2.3715, batch_acc=0.4062, running_acc=0.3393, grad=5.8188]Training epoch 2:  44%|████▍     | 72/163 [01:21<01:24,  1.08it/s, loss=2.3715, batch_acc=0.4062, running_acc=0.3393, grad=5.8188]Training epoch 2:  44%|████▍     | 72/163 [01:21<01:24,  1.08it/s, loss=2.2862, batch_acc=0.3438, running_acc=0.3394, grad=5.8869]Training epoch 2:  45%|████▍     | 73/163 [01:22<01:22,  1.10it/s, loss=2.2862, batch_acc=0.3438, running_acc=0.3394, grad=5.8869]Training epoch 2:  45%|████▍     | 73/163 [01:22<01:22,  1.10it/s, loss=2.0973, batch_acc=0.4375, running_acc=0.3408, grad=4.8187]Training epoch 2:  45%|████▌     | 74/163 [01:23<01:29,  1.01s/it, loss=2.0973, batch_acc=0.4375, running_acc=0.3408, grad=4.8187]Training epoch 2:  45%|████▌     | 74/163 [01:23<01:29,  1.01s/it, loss=2.2392, batch_acc=0.4062, running_acc=0.3416, grad=5.8322]Training epoch 2:  46%|████▌     | 75/163 [01:24<01:25,  1.03it/s, loss=2.2392, batch_acc=0.4062, running_acc=0.3416, grad=5.8322]Training epoch 2:  46%|████▌     | 75/163 [01:24<01:25,  1.03it/s, loss=2.5621, batch_acc=0.2500, running_acc=0.3404, grad=7.2973]Training epoch 2:  47%|████▋     | 76/163 [01:25<01:21,  1.06it/s, loss=2.5621, batch_acc=0.2500, running_acc=0.3404, grad=7.2973]Training epoch 2:  47%|████▋     | 76/163 [01:25<01:21,  1.06it/s, loss=2.0101, batch_acc=0.3750, running_acc=0.3409, grad=5.5704]Training epoch 2:  47%|████▋     | 77/163 [01:26<01:19,  1.08it/s, loss=2.0101, batch_acc=0.3750, running_acc=0.3409, grad=5.5704]Training epoch 2:  47%|████▋     | 77/163 [01:26<01:19,  1.08it/s, loss=2.1980, batch_acc=0.4062, running_acc=0.3417, grad=5.9345]Training epoch 2:  48%|████▊     | 78/163 [01:27<01:26,  1.01s/it, loss=2.1980, batch_acc=0.4062, running_acc=0.3417, grad=5.9345]Training epoch 2:  48%|████▊     | 78/163 [01:27<01:26,  1.01s/it, loss=2.0769, batch_acc=0.4062, running_acc=0.3425, grad=6.3700]Training epoch 2:  48%|████▊     | 79/163 [01:28<01:21,  1.03it/s, loss=2.0769, batch_acc=0.4062, running_acc=0.3425, grad=6.3700]Training epoch 2:  48%|████▊     | 79/163 [01:28<01:21,  1.03it/s, loss=2.2477, batch_acc=0.3438, running_acc=0.3426, grad=5.1065]Training epoch 2:  49%|████▉     | 80/163 [01:29<01:20,  1.03it/s, loss=2.2477, batch_acc=0.3438, running_acc=0.3426, grad=5.1065]Training epoch 2:  49%|████▉     | 80/163 [01:29<01:20,  1.03it/s, loss=2.2122, batch_acc=0.4375, running_acc=0.3438, grad=5.9016]Training epoch 2:  50%|████▉     | 81/163 [01:30<01:17,  1.06it/s, loss=2.2122, batch_acc=0.4375, running_acc=0.3438, grad=5.9016]Training epoch 2:  50%|████▉     | 81/163 [01:30<01:17,  1.06it/s, loss=2.0808, batch_acc=0.5000, running_acc=0.3457, grad=5.4960]Training epoch 2:  50%|█████     | 82/163 [01:31<01:26,  1.07s/it, loss=2.0808, batch_acc=0.5000, running_acc=0.3457, grad=5.4960]Training epoch 2:  50%|█████     | 82/163 [01:31<01:26,  1.07s/it, loss=2.2759, batch_acc=0.2812, running_acc=0.3449, grad=9.0414]Training epoch 2:  51%|█████     | 83/163 [01:32<01:21,  1.01s/it, loss=2.2759, batch_acc=0.2812, running_acc=0.3449, grad=9.0414]Training epoch 2:  51%|█████     | 83/163 [01:32<01:21,  1.01s/it, loss=2.2131, batch_acc=0.2812, running_acc=0.3441, grad=9.1756]Training epoch 2:  52%|█████▏    | 84/163 [01:33<01:16,  1.03it/s, loss=2.2131, batch_acc=0.2812, running_acc=0.3441, grad=9.1756]Training epoch 2:  52%|█████▏    | 84/163 [01:33<01:16,  1.03it/s, loss=2.1878, batch_acc=0.3750, running_acc=0.3445, grad=7.4116]Training epoch 2:  52%|█████▏    | 85/163 [01:34<01:13,  1.06it/s, loss=2.1878, batch_acc=0.3750, running_acc=0.3445, grad=7.4116]Training epoch 2:  52%|█████▏    | 85/163 [01:34<01:13,  1.06it/s, loss=2.3574, batch_acc=0.3125, running_acc=0.3441, grad=6.7075]Training epoch 2:  53%|█████▎    | 86/163 [01:36<01:40,  1.30s/it, loss=2.3574, batch_acc=0.3125, running_acc=0.3441, grad=6.7075]Training epoch 2:  53%|█████▎    | 86/163 [01:36<01:40,  1.30s/it, loss=2.8119, batch_acc=0.1875, running_acc=0.3423, grad=5.9090]Training epoch 2:  53%|█████▎    | 87/163 [01:37<01:29,  1.18s/it, loss=2.8119, batch_acc=0.1875, running_acc=0.3423, grad=5.9090]Training epoch 2:  53%|█████▎    | 87/163 [01:37<01:29,  1.18s/it, loss=2.3022, batch_acc=0.3125, running_acc=0.3420, grad=6.7668]Training epoch 2:  54%|█████▍    | 88/163 [01:37<01:21,  1.09s/it, loss=2.3022, batch_acc=0.3125, running_acc=0.3420, grad=6.7668]Training epoch 2:  54%|█████▍    | 88/163 [01:37<01:21,  1.09s/it, loss=2.2787, batch_acc=0.2812, running_acc=0.3413, grad=6.4647]Training epoch 2:  55%|█████▍    | 89/163 [01:38<01:15,  1.03s/it, loss=2.2787, batch_acc=0.2812, running_acc=0.3413, grad=6.4647]Training epoch 2:  55%|█████▍    | 89/163 [01:38<01:15,  1.03s/it, loss=2.0808, batch_acc=0.3750, running_acc=0.3416, grad=8.2735]Training epoch 2:  55%|█████▌    | 90/163 [01:40<01:26,  1.19s/it, loss=2.0808, batch_acc=0.3750, running_acc=0.3416, grad=8.2735]Training epoch 2:  55%|█████▌    | 90/163 [01:40<01:26,  1.19s/it, loss=2.0401, batch_acc=0.3750, running_acc=0.3420, grad=6.6688]Training epoch 2:  56%|█████▌    | 91/163 [01:41<01:18,  1.10s/it, loss=2.0401, batch_acc=0.3750, running_acc=0.3420, grad=6.6688]Training epoch 2:  56%|█████▌    | 91/163 [01:41<01:18,  1.10s/it, loss=2.3896, batch_acc=0.2812, running_acc=0.3413, grad=6.2875]Training epoch 2:  56%|█████▋    | 92/163 [01:42<01:13,  1.03s/it, loss=2.3896, batch_acc=0.2812, running_acc=0.3413, grad=6.2875]Training epoch 2:  56%|█████▋    | 92/163 [01:42<01:13,  1.03s/it, loss=2.2732, batch_acc=0.2812, running_acc=0.3407, grad=7.3428]Training epoch 2:  57%|█████▋    | 93/163 [01:43<01:09,  1.01it/s, loss=2.2732, batch_acc=0.2812, running_acc=0.3407, grad=7.3428]Training epoch 2:  57%|█████▋    | 93/163 [01:43<01:09,  1.01it/s, loss=2.1618, batch_acc=0.4375, running_acc=0.3417, grad=10.6556]Training epoch 2:  58%|█████▊    | 94/163 [01:45<01:28,  1.29s/it, loss=2.1618, batch_acc=0.4375, running_acc=0.3417, grad=10.6556]Training epoch 2:  58%|█████▊    | 94/163 [01:45<01:28,  1.29s/it, loss=2.2964, batch_acc=0.2188, running_acc=0.3404, grad=10.5428]Training epoch 2:  58%|█████▊    | 95/163 [01:45<01:19,  1.17s/it, loss=2.2964, batch_acc=0.2188, running_acc=0.3404, grad=10.5428]Training epoch 2:  58%|█████▊    | 95/163 [01:45<01:19,  1.17s/it, loss=2.6417, batch_acc=0.2188, running_acc=0.3391, grad=10.0190]Training epoch 2:  59%|█████▉    | 96/163 [01:46<01:12,  1.08s/it, loss=2.6417, batch_acc=0.2188, running_acc=0.3391, grad=10.0190]Training epoch 2:  59%|█████▉    | 96/163 [01:46<01:12,  1.08s/it, loss=2.2913, batch_acc=0.2812, running_acc=0.3385, grad=6.5500] Training epoch 2:  60%|█████▉    | 97/163 [01:47<01:07,  1.02s/it, loss=2.2913, batch_acc=0.2812, running_acc=0.3385, grad=6.5500]Training epoch 2:  60%|█████▉    | 97/163 [01:47<01:07,  1.02s/it, loss=2.1054, batch_acc=0.4062, running_acc=0.3392, grad=4.7223]Training epoch 2:  60%|██████    | 98/163 [01:48<01:09,  1.06s/it, loss=2.1054, batch_acc=0.4062, running_acc=0.3392, grad=4.7223]Training epoch 2:  60%|██████    | 98/163 [01:48<01:09,  1.06s/it, loss=2.1724, batch_acc=0.4062, running_acc=0.3399, grad=8.0590]Training epoch 2:  61%|██████    | 99/163 [01:49<01:04,  1.01s/it, loss=2.1724, batch_acc=0.4062, running_acc=0.3399, grad=8.0590]Training epoch 2:  61%|██████    | 99/163 [01:49<01:04,  1.01s/it, loss=2.6567, batch_acc=0.3438, running_acc=0.3400, grad=7.6743]Training epoch 2:  61%|██████▏   | 100/163 [01:50<01:01,  1.03it/s, loss=2.6567, batch_acc=0.3438, running_acc=0.3400, grad=7.6743]Training epoch 2:  61%|██████▏   | 100/163 [01:50<01:01,  1.03it/s, loss=2.2608, batch_acc=0.3125, running_acc=0.3397, grad=6.4850]Training epoch 2:  62%|██████▏   | 101/163 [01:51<00:58,  1.06it/s, loss=2.2608, batch_acc=0.3125, running_acc=0.3397, grad=6.4850]Training epoch 2:  62%|██████▏   | 101/163 [01:51<00:58,  1.06it/s, loss=2.6502, batch_acc=0.2500, running_acc=0.3388, grad=6.3877]Training epoch 2:  63%|██████▎   | 102/163 [01:52<01:07,  1.10s/it, loss=2.6502, batch_acc=0.2500, running_acc=0.3388, grad=6.3877]Training epoch 2:  63%|██████▎   | 102/163 [01:52<01:07,  1.10s/it, loss=1.6373, batch_acc=0.5312, running_acc=0.3407, grad=6.8705]Training epoch 2:  63%|██████▎   | 103/163 [01:53<01:02,  1.03s/it, loss=1.6373, batch_acc=0.5312, running_acc=0.3407, grad=6.8705]Training epoch 2:  63%|██████▎   | 103/163 [01:53<01:02,  1.03s/it, loss=2.2497, batch_acc=0.3750, running_acc=0.3410, grad=5.6001]Training epoch 2:  64%|██████▍   | 104/163 [01:54<00:58,  1.01it/s, loss=2.2497, batch_acc=0.3750, running_acc=0.3410, grad=5.6001]Training epoch 2:  64%|██████▍   | 104/163 [01:54<00:58,  1.01it/s, loss=2.6378, batch_acc=0.2188, running_acc=0.3398, grad=9.7032]Training epoch 2:  64%|██████▍   | 105/163 [01:55<00:55,  1.05it/s, loss=2.6378, batch_acc=0.2188, running_acc=0.3398, grad=9.7032]Training epoch 2:  64%|██████▍   | 105/163 [01:55<00:55,  1.05it/s, loss=2.7438, batch_acc=0.1875, running_acc=0.3384, grad=7.6845]Training epoch 2:  65%|██████▌   | 106/163 [01:56<00:54,  1.05it/s, loss=2.7438, batch_acc=0.1875, running_acc=0.3384, grad=7.6845]Training epoch 2:  65%|██████▌   | 106/163 [01:56<00:54,  1.05it/s, loss=2.4698, batch_acc=0.1250, running_acc=0.3364, grad=7.1345]Training epoch 2:  66%|██████▌   | 107/163 [01:57<00:52,  1.07it/s, loss=2.4698, batch_acc=0.1250, running_acc=0.3364, grad=7.1345]Training epoch 2:  66%|██████▌   | 107/163 [01:57<00:52,  1.07it/s, loss=1.9166, batch_acc=0.3750, running_acc=0.3367, grad=6.4308]Training epoch 2:  66%|██████▋   | 108/163 [01:58<00:51,  1.08it/s, loss=1.9166, batch_acc=0.3750, running_acc=0.3367, grad=6.4308]Training epoch 2:  66%|██████▋   | 108/163 [01:58<00:51,  1.08it/s, loss=2.4077, batch_acc=0.4062, running_acc=0.3374, grad=6.7319]Training epoch 2:  67%|██████▋   | 109/163 [01:59<00:49,  1.09it/s, loss=2.4077, batch_acc=0.4062, running_acc=0.3374, grad=6.7319]Training epoch 2:  67%|██████▋   | 109/163 [01:59<00:49,  1.09it/s, loss=2.0434, batch_acc=0.3750, running_acc=0.3377, grad=7.9692]Training epoch 2:  67%|██████▋   | 110/163 [02:00<00:51,  1.03it/s, loss=2.0434, batch_acc=0.3750, running_acc=0.3377, grad=7.9692]Training epoch 2:  67%|██████▋   | 110/163 [02:00<00:51,  1.03it/s, loss=2.6563, batch_acc=0.2500, running_acc=0.3369, grad=7.0937]Training epoch 2:  68%|██████▊   | 111/163 [02:01<00:49,  1.06it/s, loss=2.6563, batch_acc=0.2500, running_acc=0.3369, grad=7.0937]Training epoch 2:  68%|██████▊   | 111/163 [02:01<00:49,  1.06it/s, loss=2.1053, batch_acc=0.2500, running_acc=0.3361, grad=5.2134]Training epoch 2:  69%|██████▊   | 112/163 [02:02<00:47,  1.08it/s, loss=2.1053, batch_acc=0.2500, running_acc=0.3361, grad=5.2134]Training epoch 2:  69%|██████▊   | 112/163 [02:02<00:47,  1.08it/s, loss=2.1184, batch_acc=0.4062, running_acc=0.3368, grad=6.0243]Training epoch 2:  69%|██████▉   | 113/163 [02:03<00:45,  1.10it/s, loss=2.1184, batch_acc=0.4062, running_acc=0.3368, grad=6.0243]Training epoch 2:  69%|██████▉   | 113/163 [02:03<00:45,  1.10it/s, loss=2.3004, batch_acc=0.3438, running_acc=0.3368, grad=8.7280]Training epoch 2:  70%|██████▉   | 114/163 [02:04<00:57,  1.17s/it, loss=2.3004, batch_acc=0.3438, running_acc=0.3368, grad=8.7280]Training epoch 2:  70%|██████▉   | 114/163 [02:04<00:57,  1.17s/it, loss=2.0226, batch_acc=0.4375, running_acc=0.3377, grad=6.1256]Training epoch 2:  71%|███████   | 115/163 [02:05<00:51,  1.08s/it, loss=2.0226, batch_acc=0.4375, running_acc=0.3377, grad=6.1256]Training epoch 2:  71%|███████   | 115/163 [02:05<00:51,  1.08s/it, loss=2.7784, batch_acc=0.3125, running_acc=0.3375, grad=7.6066]Training epoch 2:  71%|███████   | 116/163 [02:06<00:48,  1.02s/it, loss=2.7784, batch_acc=0.3125, running_acc=0.3375, grad=7.6066]Training epoch 2:  71%|███████   | 116/163 [02:06<00:48,  1.02s/it, loss=2.2794, batch_acc=0.2812, running_acc=0.3370, grad=6.1906]Training epoch 2:  72%|███████▏  | 117/163 [02:07<00:45,  1.02it/s, loss=2.2794, batch_acc=0.2812, running_acc=0.3370, grad=6.1906]Training epoch 2:  72%|███████▏  | 117/163 [02:07<00:45,  1.02it/s, loss=2.0821, batch_acc=0.4062, running_acc=0.3376, grad=6.5633]Training epoch 2:  72%|███████▏  | 118/163 [02:09<00:55,  1.24s/it, loss=2.0821, batch_acc=0.4062, running_acc=0.3376, grad=6.5633]Training epoch 2:  72%|███████▏  | 118/163 [02:09<00:55,  1.24s/it, loss=2.3148, batch_acc=0.2500, running_acc=0.3369, grad=7.4324]Training epoch 2:  73%|███████▎  | 119/163 [02:10<00:49,  1.13s/it, loss=2.3148, batch_acc=0.2500, running_acc=0.3369, grad=7.4324]Training epoch 2:  73%|███████▎  | 119/163 [02:10<00:49,  1.13s/it, loss=2.0531, batch_acc=0.3750, running_acc=0.3372, grad=5.4936]Training epoch 2:  74%|███████▎  | 120/163 [02:11<00:45,  1.06s/it, loss=2.0531, batch_acc=0.3750, running_acc=0.3372, grad=5.4936]Training epoch 2:  74%|███████▎  | 120/163 [02:11<00:45,  1.06s/it, loss=2.4019, batch_acc=0.3438, running_acc=0.3372, grad=7.4436]Training epoch 2:  74%|███████▍  | 121/163 [02:11<00:42,  1.00s/it, loss=2.4019, batch_acc=0.3438, running_acc=0.3372, grad=7.4436]Training epoch 2:  74%|███████▍  | 121/163 [02:11<00:42,  1.00s/it, loss=2.2299, batch_acc=0.3750, running_acc=0.3376, grad=5.4050]Training epoch 2:  75%|███████▍  | 122/163 [02:13<00:46,  1.15s/it, loss=2.2299, batch_acc=0.3750, running_acc=0.3376, grad=5.4050]Training epoch 2:  75%|███████▍  | 122/163 [02:13<00:46,  1.15s/it, loss=2.0898, batch_acc=0.4375, running_acc=0.3384, grad=5.5824]Training epoch 2:  75%|███████▌  | 123/163 [02:14<00:42,  1.07s/it, loss=2.0898, batch_acc=0.4375, running_acc=0.3384, grad=5.5824]Training epoch 2:  75%|███████▌  | 123/163 [02:14<00:42,  1.07s/it, loss=1.7755, batch_acc=0.4688, running_acc=0.3394, grad=5.7979]Training epoch 2:  76%|███████▌  | 124/163 [02:15<00:39,  1.01s/it, loss=1.7755, batch_acc=0.4688, running_acc=0.3394, grad=5.7979]Training epoch 2:  76%|███████▌  | 124/163 [02:15<00:39,  1.01s/it, loss=2.4832, batch_acc=0.3125, running_acc=0.3392, grad=7.1310]Training epoch 2:  77%|███████▋  | 125/163 [02:16<00:36,  1.03it/s, loss=2.4832, batch_acc=0.3125, running_acc=0.3392, grad=7.1310]Training epoch 2:  77%|███████▋  | 125/163 [02:16<00:36,  1.03it/s, loss=2.5635, batch_acc=0.2812, running_acc=0.3387, grad=5.8545]Training epoch 2:  77%|███████▋  | 126/163 [02:17<00:39,  1.07s/it, loss=2.5635, batch_acc=0.2812, running_acc=0.3387, grad=5.8545]Training epoch 2:  77%|███████▋  | 126/163 [02:17<00:39,  1.07s/it, loss=2.2189, batch_acc=0.3125, running_acc=0.3385, grad=7.0827]Training epoch 2:  78%|███████▊  | 127/163 [02:18<00:36,  1.02s/it, loss=2.2189, batch_acc=0.3125, running_acc=0.3385, grad=7.0827]Training epoch 2:  78%|███████▊  | 127/163 [02:18<00:36,  1.02s/it, loss=2.3467, batch_acc=0.3125, running_acc=0.3383, grad=7.3259]Training epoch 2:  79%|███████▊  | 128/163 [02:19<00:34,  1.03it/s, loss=2.3467, batch_acc=0.3125, running_acc=0.3383, grad=7.3259]Training epoch 2:  79%|███████▊  | 128/163 [02:19<00:34,  1.03it/s, loss=1.9305, batch_acc=0.5000, running_acc=0.3396, grad=7.8892]Training epoch 2:  79%|███████▉  | 129/163 [02:19<00:32,  1.06it/s, loss=1.9305, batch_acc=0.5000, running_acc=0.3396, grad=7.8892]Training epoch 2:  79%|███████▉  | 129/163 [02:19<00:32,  1.06it/s, loss=1.9863, batch_acc=0.5312, running_acc=0.3411, grad=5.6966]Training epoch 2:  80%|███████▉  | 130/163 [02:21<00:40,  1.22s/it, loss=1.9863, batch_acc=0.5312, running_acc=0.3411, grad=5.6966]Training epoch 2:  80%|███████▉  | 130/163 [02:21<00:40,  1.22s/it, loss=2.5834, batch_acc=0.4375, running_acc=0.3418, grad=6.3074]Training epoch 2:  80%|████████  | 131/163 [02:22<00:35,  1.12s/it, loss=2.5834, batch_acc=0.4375, running_acc=0.3418, grad=6.3074]Training epoch 2:  80%|████████  | 131/163 [02:22<00:35,  1.12s/it, loss=2.4221, batch_acc=0.3750, running_acc=0.3421, grad=5.5479]Training epoch 2:  81%|████████  | 132/163 [02:23<00:32,  1.05s/it, loss=2.4221, batch_acc=0.3750, running_acc=0.3421, grad=5.5479]Training epoch 2:  81%|████████  | 132/163 [02:23<00:32,  1.05s/it, loss=2.3399, batch_acc=0.3438, running_acc=0.3421, grad=5.4975]Training epoch 2:  82%|████████▏ | 133/163 [02:24<00:29,  1.00it/s, loss=2.3399, batch_acc=0.3438, running_acc=0.3421, grad=5.4975]Training epoch 2:  82%|████████▏ | 133/163 [02:24<00:29,  1.00it/s, loss=2.1301, batch_acc=0.3125, running_acc=0.3419, grad=7.2068]Training epoch 2:  82%|████████▏ | 134/163 [02:25<00:28,  1.02it/s, loss=2.1301, batch_acc=0.3125, running_acc=0.3419, grad=7.2068]Training epoch 2:  82%|████████▏ | 134/163 [02:25<00:28,  1.02it/s, loss=1.7717, batch_acc=0.5625, running_acc=0.3435, grad=5.7568]Training epoch 2:  83%|████████▎ | 135/163 [02:26<00:26,  1.05it/s, loss=1.7717, batch_acc=0.5625, running_acc=0.3435, grad=5.7568]Training epoch 2:  83%|████████▎ | 135/163 [02:26<00:26,  1.05it/s, loss=2.2167, batch_acc=0.3750, running_acc=0.3438, grad=6.4825]Training epoch 2:  83%|████████▎ | 136/163 [02:27<00:25,  1.08it/s, loss=2.2167, batch_acc=0.3750, running_acc=0.3438, grad=6.4825]Training epoch 2:  83%|████████▎ | 136/163 [02:27<00:25,  1.08it/s, loss=2.1034, batch_acc=0.4688, running_acc=0.3447, grad=5.6267]Training epoch 2:  84%|████████▍ | 137/163 [02:28<00:23,  1.09it/s, loss=2.1034, batch_acc=0.4688, running_acc=0.3447, grad=5.6267]Training epoch 2:  84%|████████▍ | 137/163 [02:28<00:23,  1.09it/s, loss=2.1759, batch_acc=0.4062, running_acc=0.3451, grad=6.3250]Training epoch 2:  85%|████████▍ | 138/163 [02:29<00:25,  1.03s/it, loss=2.1759, batch_acc=0.4062, running_acc=0.3451, grad=6.3250]Training epoch 2:  85%|████████▍ | 138/163 [02:29<00:25,  1.03s/it, loss=2.1488, batch_acc=0.4062, running_acc=0.3456, grad=5.9596]Training epoch 2:  85%|████████▌ | 139/163 [02:30<00:23,  1.01it/s, loss=2.1488, batch_acc=0.4062, running_acc=0.3456, grad=5.9596]Training epoch 2:  85%|████████▌ | 139/163 [02:30<00:23,  1.01it/s, loss=2.2697, batch_acc=0.3438, running_acc=0.3455, grad=8.3464]Training epoch 2:  86%|████████▌ | 140/163 [02:31<00:21,  1.05it/s, loss=2.2697, batch_acc=0.3438, running_acc=0.3455, grad=8.3464]Training epoch 2:  86%|████████▌ | 140/163 [02:31<00:21,  1.05it/s, loss=1.9058, batch_acc=0.4375, running_acc=0.3462, grad=7.1991]Training epoch 2:  87%|████████▋ | 141/163 [02:32<00:20,  1.07it/s, loss=1.9058, batch_acc=0.4375, running_acc=0.3462, grad=7.1991]Training epoch 2:  87%|████████▋ | 141/163 [02:32<00:20,  1.07it/s, loss=1.9425, batch_acc=0.4062, running_acc=0.3466, grad=5.0368]Training epoch 2:  87%|████████▋ | 142/163 [02:33<00:23,  1.11s/it, loss=1.9425, batch_acc=0.4062, running_acc=0.3466, grad=5.0368]Training epoch 2:  87%|████████▋ | 142/163 [02:33<00:23,  1.11s/it, loss=2.3712, batch_acc=0.4375, running_acc=0.3473, grad=6.1722]Training epoch 2:  88%|████████▊ | 143/163 [02:34<00:20,  1.04s/it, loss=2.3712, batch_acc=0.4375, running_acc=0.3473, grad=6.1722]Training epoch 2:  88%|████████▊ | 143/163 [02:34<00:20,  1.04s/it, loss=2.3880, batch_acc=0.3750, running_acc=0.3475, grad=14.3201]Training epoch 2:  88%|████████▊ | 144/163 [02:35<00:18,  1.01it/s, loss=2.3880, batch_acc=0.3750, running_acc=0.3475, grad=14.3201]Training epoch 2:  88%|████████▊ | 144/163 [02:35<00:18,  1.01it/s, loss=2.1956, batch_acc=0.3438, running_acc=0.3474, grad=10.5224]Training epoch 2:  89%|████████▉ | 145/163 [02:36<00:17,  1.04it/s, loss=2.1956, batch_acc=0.3438, running_acc=0.3474, grad=10.5224]Training epoch 2:  89%|████████▉ | 145/163 [02:36<00:17,  1.04it/s, loss=2.1430, batch_acc=0.3750, running_acc=0.3476, grad=5.6496] Training epoch 2:  90%|████████▉ | 146/163 [02:37<00:16,  1.04it/s, loss=2.1430, batch_acc=0.3750, running_acc=0.3476, grad=5.6496]Training epoch 2:  90%|████████▉ | 146/163 [02:37<00:16,  1.04it/s, loss=2.2755, batch_acc=0.3125, running_acc=0.3474, grad=5.6870]Training epoch 2:  90%|█████████ | 147/163 [02:38<00:14,  1.07it/s, loss=2.2755, batch_acc=0.3125, running_acc=0.3474, grad=5.6870]Training epoch 2:  90%|█████████ | 147/163 [02:38<00:14,  1.07it/s, loss=2.0987, batch_acc=0.3750, running_acc=0.3476, grad=7.0101]Training epoch 2:  91%|█████████ | 148/163 [02:38<00:13,  1.09it/s, loss=2.0987, batch_acc=0.3750, running_acc=0.3476, grad=7.0101]Training epoch 2:  91%|█████████ | 148/163 [02:38<00:13,  1.09it/s, loss=2.1146, batch_acc=0.4375, running_acc=0.3482, grad=6.7284]Training epoch 2:  91%|█████████▏| 149/163 [02:39<00:12,  1.10it/s, loss=2.1146, batch_acc=0.4375, running_acc=0.3482, grad=6.7284]Training epoch 2:  91%|█████████▏| 149/163 [02:39<00:12,  1.10it/s, loss=2.0190, batch_acc=0.3750, running_acc=0.3484, grad=7.9287]Training epoch 2:  92%|█████████▏| 150/163 [02:40<00:11,  1.10it/s, loss=2.0190, batch_acc=0.3750, running_acc=0.3484, grad=7.9287]Training epoch 2:  92%|█████████▏| 150/163 [02:40<00:11,  1.10it/s, loss=2.0483, batch_acc=0.3750, running_acc=0.3485, grad=5.3080]Training epoch 2:  93%|█████████▎| 151/163 [02:41<00:10,  1.11it/s, loss=2.0483, batch_acc=0.3750, running_acc=0.3485, grad=5.3080]Training epoch 2:  93%|█████████▎| 151/163 [02:41<00:10,  1.11it/s, loss=2.0108, batch_acc=0.4062, running_acc=0.3489, grad=5.9083]Training epoch 2:  93%|█████████▎| 152/163 [02:42<00:09,  1.12it/s, loss=2.0108, batch_acc=0.4062, running_acc=0.3489, grad=5.9083]Training epoch 2:  93%|█████████▎| 152/163 [02:42<00:09,  1.12it/s, loss=2.3469, batch_acc=0.3438, running_acc=0.3489, grad=6.3118]Training epoch 2:  94%|█████████▍| 153/163 [02:43<00:08,  1.12it/s, loss=2.3469, batch_acc=0.3438, running_acc=0.3489, grad=6.3118]Training epoch 2:  94%|█████████▍| 153/163 [02:43<00:08,  1.12it/s, loss=2.1887, batch_acc=0.3750, running_acc=0.3491, grad=7.4076]Training epoch 2:  94%|█████████▍| 154/163 [02:44<00:09,  1.02s/it, loss=2.1887, batch_acc=0.3750, running_acc=0.3491, grad=7.4076]Training epoch 2:  94%|█████████▍| 154/163 [02:44<00:09,  1.02s/it, loss=1.9987, batch_acc=0.4375, running_acc=0.3496, grad=6.5826]Training epoch 2:  95%|█████████▌| 155/163 [02:45<00:07,  1.03it/s, loss=1.9987, batch_acc=0.4375, running_acc=0.3496, grad=6.5826]Training epoch 2:  95%|█████████▌| 155/163 [02:45<00:07,  1.03it/s, loss=2.1349, batch_acc=0.4062, running_acc=0.3500, grad=7.2043]Training epoch 2:  96%|█████████▌| 156/163 [02:46<00:06,  1.06it/s, loss=2.1349, batch_acc=0.4062, running_acc=0.3500, grad=7.2043]Training epoch 2:  96%|█████████▌| 156/163 [02:46<00:06,  1.06it/s, loss=2.4918, batch_acc=0.3438, running_acc=0.3500, grad=11.2172]Training epoch 2:  96%|█████████▋| 157/163 [02:47<00:05,  1.08it/s, loss=2.4918, batch_acc=0.3438, running_acc=0.3500, grad=11.2172]Training epoch 2:  96%|█████████▋| 157/163 [02:47<00:05,  1.08it/s, loss=1.8555, batch_acc=0.5312, running_acc=0.3511, grad=5.7074] Training epoch 2:  97%|█████████▋| 158/163 [02:48<00:05,  1.06s/it, loss=1.8555, batch_acc=0.5312, running_acc=0.3511, grad=5.7074]Training epoch 2:  97%|█████████▋| 158/163 [02:48<00:05,  1.06s/it, loss=2.4671, batch_acc=0.3750, running_acc=0.3513, grad=7.0306]Training epoch 2:  98%|█████████▊| 159/163 [02:49<00:04,  1.01s/it, loss=2.4671, batch_acc=0.3750, running_acc=0.3513, grad=7.0306]Training epoch 2:  98%|█████████▊| 159/163 [02:49<00:04,  1.01s/it, loss=2.4076, batch_acc=0.3125, running_acc=0.3510, grad=8.2593]Training epoch 2:  98%|█████████▊| 160/163 [02:50<00:02,  1.03it/s, loss=2.4076, batch_acc=0.3125, running_acc=0.3510, grad=8.2593]Training epoch 2:  98%|█████████▊| 160/163 [02:50<00:02,  1.03it/s, loss=2.1237, batch_acc=0.4062, running_acc=0.3514, grad=6.1328]Training epoch 2:  99%|█████████▉| 161/163 [02:51<00:01,  1.06it/s, loss=2.1237, batch_acc=0.4062, running_acc=0.3514, grad=6.1328]Training epoch 2:  99%|█████████▉| 161/163 [02:51<00:01,  1.06it/s, loss=2.4803, batch_acc=0.1875, running_acc=0.3503, grad=7.8812]Training epoch 2:  99%|█████████▉| 162/163 [02:52<00:00,  1.08it/s, loss=2.4803, batch_acc=0.1875, running_acc=0.3503, grad=7.8812]Training epoch 2:  99%|█████████▉| 162/163 [02:52<00:00,  1.08it/s, loss=2.4077, batch_acc=0.3750, running_acc=0.3505, grad=5.9073]Training epoch 2: 100%|██████████| 163/163 [02:52<00:00,  1.19it/s, loss=2.4077, batch_acc=0.3750, running_acc=0.3505, grad=5.9073]Training epoch 2: 100%|██████████| 163/163 [02:52<00:00,  1.19it/s, loss=2.4363, batch_acc=0.3333, running_acc=0.3504, grad=9.4030]Training epoch 2: 100%|██████████| 163/163 [02:52<00:00,  1.06s/it, loss=2.4363, batch_acc=0.3333, running_acc=0.3504, grad=9.4030]
Evaluation epoch 2:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 2:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it]Evaluation epoch 2:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it, loss=1.6785, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 2:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=1.6785, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 2:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=1.6898, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 2:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=1.6898, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 2:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=1.8485, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 2:  14%|█▍        | 4/28 [00:10<01:02,  2.61s/it, loss=1.8485, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 2:  14%|█▍        | 4/28 [00:10<01:02,  2.61s/it, loss=3.1126, batch_acc=0.0625, running_acc=0.4375]Evaluation epoch 2:  18%|█▊        | 5/28 [00:10<00:40,  1.76s/it, loss=3.1126, batch_acc=0.0625, running_acc=0.4375]Evaluation epoch 2:  18%|█▊        | 5/28 [00:10<00:40,  1.76s/it, loss=2.9953, batch_acc=0.3125, running_acc=0.4125]Evaluation epoch 2:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=2.9953, batch_acc=0.3125, running_acc=0.4125]Evaluation epoch 2:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=2.7738, batch_acc=0.2500, running_acc=0.3854]Evaluation epoch 2:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.7738, batch_acc=0.2500, running_acc=0.3854]Evaluation epoch 2:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.3724, batch_acc=0.3438, running_acc=0.3795]Evaluation epoch 2:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=2.3724, batch_acc=0.3438, running_acc=0.3795]Evaluation epoch 2:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=2.1962, batch_acc=0.3438, running_acc=0.3750]Evaluation epoch 2:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=2.1962, batch_acc=0.3438, running_acc=0.3750]Evaluation epoch 2:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=1.9337, batch_acc=0.4688, running_acc=0.3854]Evaluation epoch 2:  36%|███▌      | 10/28 [00:14<00:16,  1.07it/s, loss=1.9337, batch_acc=0.4688, running_acc=0.3854]Evaluation epoch 2:  36%|███▌      | 10/28 [00:14<00:16,  1.07it/s, loss=0.9820, batch_acc=0.7812, running_acc=0.4250]Evaluation epoch 2:  39%|███▉      | 11/28 [00:14<00:12,  1.37it/s, loss=0.9820, batch_acc=0.7812, running_acc=0.4250]Evaluation epoch 2:  39%|███▉      | 11/28 [00:14<00:12,  1.37it/s, loss=2.5305, batch_acc=0.1875, running_acc=0.4034]Evaluation epoch 2:  43%|████▎     | 12/28 [00:20<00:35,  2.24s/it, loss=2.5305, batch_acc=0.1875, running_acc=0.4034]Evaluation epoch 2:  43%|████▎     | 12/28 [00:20<00:35,  2.24s/it, loss=2.0959, batch_acc=0.4062, running_acc=0.4036]Evaluation epoch 2:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=2.0959, batch_acc=0.4062, running_acc=0.4036]Evaluation epoch 2:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=2.1436, batch_acc=0.3750, running_acc=0.4014]Evaluation epoch 2:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=2.1436, batch_acc=0.3750, running_acc=0.4014]Evaluation epoch 2:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=2.1531, batch_acc=0.4062, running_acc=0.4018]Evaluation epoch 2:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=2.1531, batch_acc=0.4062, running_acc=0.4018]Evaluation epoch 2:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=3.2284, batch_acc=0.1250, running_acc=0.3833]Evaluation epoch 2:  57%|█████▋    | 16/28 [00:24<00:18,  1.55s/it, loss=3.2284, batch_acc=0.1250, running_acc=0.3833]Evaluation epoch 2:  57%|█████▋    | 16/28 [00:24<00:18,  1.55s/it, loss=2.1313, batch_acc=0.3125, running_acc=0.3789]Evaluation epoch 2:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=2.1313, batch_acc=0.3125, running_acc=0.3789]Evaluation epoch 2:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=2.3073, batch_acc=0.1250, running_acc=0.3640]Evaluation epoch 2:  64%|██████▍   | 18/28 [00:24<00:08,  1.12it/s, loss=2.3073, batch_acc=0.1250, running_acc=0.3640]Evaluation epoch 2:  64%|██████▍   | 18/28 [00:24<00:08,  1.12it/s, loss=2.0282, batch_acc=0.4688, running_acc=0.3698]Evaluation epoch 2:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=2.0282, batch_acc=0.4688, running_acc=0.3698]Evaluation epoch 2:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=1.9370, batch_acc=0.3125, running_acc=0.3668]Evaluation epoch 2:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=1.9370, batch_acc=0.3125, running_acc=0.3668]Evaluation epoch 2:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=2.3506, batch_acc=0.3125, running_acc=0.3641]Evaluation epoch 2:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=2.3506, batch_acc=0.3125, running_acc=0.3641]Evaluation epoch 2:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=2.6902, batch_acc=0.1562, running_acc=0.3542]Evaluation epoch 2:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=2.6902, batch_acc=0.1562, running_acc=0.3542]Evaluation epoch 2:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=2.6603, batch_acc=0.2188, running_acc=0.3480]Evaluation epoch 2:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=2.6603, batch_acc=0.2188, running_acc=0.3480]Evaluation epoch 2:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=2.8535, batch_acc=0.1250, running_acc=0.3383]Evaluation epoch 2:  86%|████████▌ | 24/28 [00:34<00:08,  2.04s/it, loss=2.8535, batch_acc=0.1250, running_acc=0.3383]Evaluation epoch 2:  86%|████████▌ | 24/28 [00:34<00:08,  2.04s/it, loss=2.0550, batch_acc=0.3438, running_acc=0.3385]Evaluation epoch 2:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=2.0550, batch_acc=0.3438, running_acc=0.3385]Evaluation epoch 2:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=1.5023, batch_acc=0.5938, running_acc=0.3488]Evaluation epoch 2:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=1.5023, batch_acc=0.5938, running_acc=0.3488]Evaluation epoch 2:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=2.2273, batch_acc=0.4062, running_acc=0.3510]Evaluation epoch 2:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=2.2273, batch_acc=0.4062, running_acc=0.3510]Evaluation epoch 2:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=2.6542, batch_acc=0.4062, running_acc=0.3530]Evaluation epoch 2: 100%|██████████| 28/28 [00:35<00:00,  1.15it/s, loss=2.2374, batch_acc=0.3333, running_acc=0.3529]Evaluation epoch 2: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=2.2374, batch_acc=0.3333, running_acc=0.3529]
Training epoch 3:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 3:   1%|          | 1/163 [00:06<16:19,  6.05s/it]Training epoch 3:   1%|          | 1/163 [00:06<16:19,  6.05s/it, loss=2.1604, batch_acc=0.4062, running_acc=0.4062, grad=5.5452]Training epoch 3:   1%|          | 2/163 [00:06<08:03,  3.00s/it, loss=2.1604, batch_acc=0.4062, running_acc=0.4062, grad=5.5452]Training epoch 3:   1%|          | 2/163 [00:06<08:03,  3.00s/it, loss=2.1086, batch_acc=0.4375, running_acc=0.4219, grad=6.7983]Training epoch 3:   2%|▏         | 3/163 [00:07<05:25,  2.03s/it, loss=2.1086, batch_acc=0.4375, running_acc=0.4219, grad=6.7983]Training epoch 3:   2%|▏         | 3/163 [00:07<05:25,  2.03s/it, loss=1.8755, batch_acc=0.3750, running_acc=0.4062, grad=6.4349]Training epoch 3:   2%|▏         | 4/163 [00:09<05:32,  2.09s/it, loss=1.8755, batch_acc=0.3750, running_acc=0.4062, grad=6.4349]Training epoch 3:   2%|▏         | 4/163 [00:09<05:32,  2.09s/it, loss=2.2361, batch_acc=0.2812, running_acc=0.3750, grad=5.6034]Training epoch 3:   3%|▎         | 5/163 [00:10<04:21,  1.66s/it, loss=2.2361, batch_acc=0.2812, running_acc=0.3750, grad=5.6034]Training epoch 3:   3%|▎         | 5/163 [00:10<04:21,  1.66s/it, loss=2.1518, batch_acc=0.3438, running_acc=0.3688, grad=7.4096]Training epoch 3:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=2.1518, batch_acc=0.3438, running_acc=0.3688, grad=7.4096]Training epoch 3:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=1.9988, batch_acc=0.4375, running_acc=0.3802, grad=6.1868]Training epoch 3:   4%|▍         | 7/163 [00:12<03:10,  1.22s/it, loss=1.9988, batch_acc=0.4375, running_acc=0.3802, grad=6.1868]Training epoch 3:   4%|▍         | 7/163 [00:12<03:10,  1.22s/it, loss=2.0485, batch_acc=0.5625, running_acc=0.4062, grad=5.5376]Training epoch 3:   5%|▍         | 8/163 [00:14<03:18,  1.28s/it, loss=2.0485, batch_acc=0.5625, running_acc=0.4062, grad=5.5376]Training epoch 3:   5%|▍         | 8/163 [00:14<03:18,  1.28s/it, loss=1.7413, batch_acc=0.4375, running_acc=0.4102, grad=5.1833]Training epoch 3:   6%|▌         | 9/163 [00:14<03:00,  1.17s/it, loss=1.7413, batch_acc=0.4375, running_acc=0.4102, grad=5.1833]Training epoch 3:   6%|▌         | 9/163 [00:14<03:00,  1.17s/it, loss=2.0382, batch_acc=0.4062, running_acc=0.4097, grad=7.4393]Training epoch 3:   6%|▌         | 10/163 [00:15<02:45,  1.08s/it, loss=2.0382, batch_acc=0.4062, running_acc=0.4097, grad=7.4393]Training epoch 3:   6%|▌         | 10/163 [00:15<02:45,  1.08s/it, loss=2.2363, batch_acc=0.3438, running_acc=0.4031, grad=8.5414]Training epoch 3:   7%|▋         | 11/163 [00:16<02:34,  1.02s/it, loss=2.2363, batch_acc=0.3438, running_acc=0.4031, grad=8.5414]Training epoch 3:   7%|▋         | 11/163 [00:16<02:34,  1.02s/it, loss=1.9888, batch_acc=0.4062, running_acc=0.4034, grad=9.8973]Training epoch 3:   7%|▋         | 12/163 [00:17<02:41,  1.07s/it, loss=1.9888, batch_acc=0.4062, running_acc=0.4034, grad=9.8973]Training epoch 3:   7%|▋         | 12/163 [00:17<02:41,  1.07s/it, loss=1.8035, batch_acc=0.4688, running_acc=0.4089, grad=6.4057]Training epoch 3:   8%|▊         | 13/163 [00:18<02:40,  1.07s/it, loss=1.8035, batch_acc=0.4688, running_acc=0.4089, grad=6.4057]Training epoch 3:   8%|▊         | 13/163 [00:18<02:40,  1.07s/it, loss=2.4239, batch_acc=0.4062, running_acc=0.4087, grad=9.9909]Training epoch 3:   9%|▊         | 14/163 [00:19<02:33,  1.03s/it, loss=2.4239, batch_acc=0.4062, running_acc=0.4087, grad=9.9909]Training epoch 3:   9%|▊         | 14/163 [00:19<02:33,  1.03s/it, loss=2.2318, batch_acc=0.3438, running_acc=0.4040, grad=7.6715]Training epoch 3:   9%|▉         | 15/163 [00:20<02:25,  1.01it/s, loss=2.2318, batch_acc=0.3438, running_acc=0.4040, grad=7.6715]Training epoch 3:   9%|▉         | 15/163 [00:20<02:25,  1.01it/s, loss=2.0137, batch_acc=0.4062, running_acc=0.4042, grad=6.9752]Training epoch 3:  10%|▉         | 16/163 [00:21<02:33,  1.05s/it, loss=2.0137, batch_acc=0.4062, running_acc=0.4042, grad=6.9752]Training epoch 3:  10%|▉         | 16/163 [00:21<02:33,  1.05s/it, loss=2.1049, batch_acc=0.3750, running_acc=0.4023, grad=5.6096]Training epoch 3:  10%|█         | 17/163 [00:22<02:25,  1.00it/s, loss=2.1049, batch_acc=0.3750, running_acc=0.4023, grad=5.6096]Training epoch 3:  10%|█         | 17/163 [00:22<02:25,  1.00it/s, loss=2.1769, batch_acc=0.5000, running_acc=0.4081, grad=6.0422]Training epoch 3:  11%|█         | 18/163 [00:23<02:19,  1.04it/s, loss=2.1769, batch_acc=0.5000, running_acc=0.4081, grad=6.0422]Training epoch 3:  11%|█         | 18/163 [00:23<02:19,  1.04it/s, loss=1.8787, batch_acc=0.4688, running_acc=0.4115, grad=6.4625]Training epoch 3:  12%|█▏        | 19/163 [00:24<02:14,  1.07it/s, loss=1.8787, batch_acc=0.4688, running_acc=0.4115, grad=6.4625]Training epoch 3:  12%|█▏        | 19/163 [00:24<02:14,  1.07it/s, loss=2.0904, batch_acc=0.4375, running_acc=0.4128, grad=5.7388]Training epoch 3:  12%|█▏        | 20/163 [00:27<03:33,  1.49s/it, loss=2.0904, batch_acc=0.4375, running_acc=0.4128, grad=5.7388]Training epoch 3:  12%|█▏        | 20/163 [00:27<03:33,  1.49s/it, loss=2.0412, batch_acc=0.5625, running_acc=0.4203, grad=6.9023]Training epoch 3:  13%|█▎        | 21/163 [00:28<03:05,  1.31s/it, loss=2.0412, batch_acc=0.5625, running_acc=0.4203, grad=6.9023]Training epoch 3:  13%|█▎        | 21/163 [00:28<03:05,  1.31s/it, loss=1.7397, batch_acc=0.5312, running_acc=0.4256, grad=5.9275]Training epoch 3:  13%|█▎        | 22/163 [00:29<02:46,  1.18s/it, loss=1.7397, batch_acc=0.5312, running_acc=0.4256, grad=5.9275]Training epoch 3:  13%|█▎        | 22/163 [00:29<02:46,  1.18s/it, loss=2.1782, batch_acc=0.4062, running_acc=0.4247, grad=6.5912]Training epoch 3:  14%|█▍        | 23/163 [00:30<02:32,  1.09s/it, loss=2.1782, batch_acc=0.4062, running_acc=0.4247, grad=6.5912]Training epoch 3:  14%|█▍        | 23/163 [00:30<02:32,  1.09s/it, loss=2.1153, batch_acc=0.3750, running_acc=0.4226, grad=5.6687]Training epoch 3:  15%|█▍        | 24/163 [00:31<02:30,  1.08s/it, loss=2.1153, batch_acc=0.3750, running_acc=0.4226, grad=5.6687]Training epoch 3:  15%|█▍        | 24/163 [00:31<02:30,  1.08s/it, loss=2.0352, batch_acc=0.4688, running_acc=0.4245, grad=7.0259]Training epoch 3:  15%|█▌        | 25/163 [00:31<02:20,  1.02s/it, loss=2.0352, batch_acc=0.4688, running_acc=0.4245, grad=7.0259]Training epoch 3:  15%|█▌        | 25/163 [00:31<02:20,  1.02s/it, loss=1.7529, batch_acc=0.4375, running_acc=0.4250, grad=10.3929]Training epoch 3:  16%|█▌        | 26/163 [00:32<02:14,  1.02it/s, loss=1.7529, batch_acc=0.4375, running_acc=0.4250, grad=10.3929]Training epoch 3:  16%|█▌        | 26/163 [00:32<02:14,  1.02it/s, loss=2.0302, batch_acc=0.3750, running_acc=0.4231, grad=7.1540] Training epoch 3:  17%|█▋        | 27/163 [00:33<02:09,  1.05it/s, loss=2.0302, batch_acc=0.3750, running_acc=0.4231, grad=7.1540]Training epoch 3:  17%|█▋        | 27/163 [00:33<02:09,  1.05it/s, loss=1.9302, batch_acc=0.3750, running_acc=0.4213, grad=7.6212]Training epoch 3:  17%|█▋        | 28/163 [00:35<02:49,  1.26s/it, loss=1.9302, batch_acc=0.3750, running_acc=0.4213, grad=7.6212]Training epoch 3:  17%|█▋        | 28/163 [00:35<02:49,  1.26s/it, loss=2.2047, batch_acc=0.4688, running_acc=0.4230, grad=7.7349]Training epoch 3:  18%|█▊        | 29/163 [00:36<02:33,  1.14s/it, loss=2.2047, batch_acc=0.4688, running_acc=0.4230, grad=7.7349]Training epoch 3:  18%|█▊        | 29/163 [00:36<02:33,  1.14s/it, loss=2.1223, batch_acc=0.3438, running_acc=0.4203, grad=7.1253]Training epoch 3:  18%|█▊        | 30/163 [00:37<02:21,  1.06s/it, loss=2.1223, batch_acc=0.3438, running_acc=0.4203, grad=7.1253]Training epoch 3:  18%|█▊        | 30/163 [00:37<02:21,  1.06s/it, loss=2.1941, batch_acc=0.3438, running_acc=0.4177, grad=5.9566]Training epoch 3:  19%|█▉        | 31/163 [00:38<02:13,  1.01s/it, loss=2.1941, batch_acc=0.3438, running_acc=0.4177, grad=5.9566]Training epoch 3:  19%|█▉        | 31/163 [00:38<02:13,  1.01s/it, loss=1.6647, batch_acc=0.5312, running_acc=0.4214, grad=7.1140]Training epoch 3:  20%|█▉        | 32/163 [00:39<02:35,  1.19s/it, loss=1.6647, batch_acc=0.5312, running_acc=0.4214, grad=7.1140]Training epoch 3:  20%|█▉        | 32/163 [00:39<02:35,  1.19s/it, loss=1.8592, batch_acc=0.5000, running_acc=0.4238, grad=9.0379]Training epoch 3:  20%|██        | 33/163 [00:40<02:22,  1.09s/it, loss=1.8592, batch_acc=0.5000, running_acc=0.4238, grad=9.0379]Training epoch 3:  20%|██        | 33/163 [00:40<02:22,  1.09s/it, loss=2.2447, batch_acc=0.3750, running_acc=0.4223, grad=6.8831]Training epoch 3:  21%|██        | 34/163 [00:41<02:12,  1.03s/it, loss=2.2447, batch_acc=0.3750, running_acc=0.4223, grad=6.8831]Training epoch 3:  21%|██        | 34/163 [00:41<02:12,  1.03s/it, loss=1.9381, batch_acc=0.4062, running_acc=0.4219, grad=7.5104]Training epoch 3:  21%|██▏       | 35/163 [00:42<02:06,  1.02it/s, loss=1.9381, batch_acc=0.4062, running_acc=0.4219, grad=7.5104]Training epoch 3:  21%|██▏       | 35/163 [00:42<02:06,  1.02it/s, loss=2.0565, batch_acc=0.2812, running_acc=0.4179, grad=7.7949]Training epoch 3:  22%|██▏       | 36/163 [00:44<02:25,  1.14s/it, loss=2.0565, batch_acc=0.2812, running_acc=0.4179, grad=7.7949]Training epoch 3:  22%|██▏       | 36/163 [00:44<02:25,  1.14s/it, loss=1.9014, batch_acc=0.4375, running_acc=0.4184, grad=7.7620]Training epoch 3:  23%|██▎       | 37/163 [00:44<02:14,  1.06s/it, loss=1.9014, batch_acc=0.4375, running_acc=0.4184, grad=7.7620]Training epoch 3:  23%|██▎       | 37/163 [00:44<02:14,  1.06s/it, loss=2.1279, batch_acc=0.4375, running_acc=0.4189, grad=7.7053]Training epoch 3:  23%|██▎       | 38/163 [00:45<02:06,  1.01s/it, loss=2.1279, batch_acc=0.4375, running_acc=0.4189, grad=7.7053]Training epoch 3:  23%|██▎       | 38/163 [00:45<02:06,  1.01s/it, loss=2.3284, batch_acc=0.2500, running_acc=0.4145, grad=9.2944]Training epoch 3:  24%|██▍       | 39/163 [00:46<02:00,  1.03it/s, loss=2.3284, batch_acc=0.2500, running_acc=0.4145, grad=9.2944]Training epoch 3:  24%|██▍       | 39/163 [00:46<02:00,  1.03it/s, loss=2.0108, batch_acc=0.4062, running_acc=0.4143, grad=6.4714]Training epoch 3:  25%|██▍       | 40/163 [00:48<02:31,  1.23s/it, loss=2.0108, batch_acc=0.4062, running_acc=0.4143, grad=6.4714]Training epoch 3:  25%|██▍       | 40/163 [00:48<02:31,  1.23s/it, loss=2.2932, batch_acc=0.3750, running_acc=0.4133, grad=6.7395]Training epoch 3:  25%|██▌       | 41/163 [00:49<02:17,  1.12s/it, loss=2.2932, batch_acc=0.3750, running_acc=0.4133, grad=6.7395]Training epoch 3:  25%|██▌       | 41/163 [00:49<02:17,  1.12s/it, loss=1.8508, batch_acc=0.5000, running_acc=0.4154, grad=5.9630]Training epoch 3:  26%|██▌       | 42/163 [00:50<02:07,  1.05s/it, loss=1.8508, batch_acc=0.5000, running_acc=0.4154, grad=5.9630]Training epoch 3:  26%|██▌       | 42/163 [00:50<02:07,  1.05s/it, loss=1.7848, batch_acc=0.5312, running_acc=0.4182, grad=6.2781]Training epoch 3:  26%|██▋       | 43/163 [00:51<01:59,  1.00it/s, loss=1.7848, batch_acc=0.5312, running_acc=0.4182, grad=6.2781]Training epoch 3:  26%|██▋       | 43/163 [00:51<01:59,  1.00it/s, loss=1.7205, batch_acc=0.5625, running_acc=0.4215, grad=6.6572]Training epoch 3:  27%|██▋       | 44/163 [00:52<02:11,  1.11s/it, loss=1.7205, batch_acc=0.5625, running_acc=0.4215, grad=6.6572]Training epoch 3:  27%|██▋       | 44/163 [00:52<02:11,  1.11s/it, loss=1.8525, batch_acc=0.5312, running_acc=0.4240, grad=5.9753]Training epoch 3:  28%|██▊       | 45/163 [00:53<02:02,  1.04s/it, loss=1.8525, batch_acc=0.5312, running_acc=0.4240, grad=5.9753]Training epoch 3:  28%|██▊       | 45/163 [00:53<02:02,  1.04s/it, loss=1.9874, batch_acc=0.3125, running_acc=0.4215, grad=9.4441]Training epoch 3:  28%|██▊       | 46/163 [00:54<01:55,  1.01it/s, loss=1.9874, batch_acc=0.3125, running_acc=0.4215, grad=9.4441]Training epoch 3:  28%|██▊       | 46/163 [00:54<01:55,  1.01it/s, loss=1.8681, batch_acc=0.4375, running_acc=0.4219, grad=9.4046]Training epoch 3:  29%|██▉       | 47/163 [00:56<02:19,  1.21s/it, loss=1.8681, batch_acc=0.4375, running_acc=0.4219, grad=9.4046]Training epoch 3:  29%|██▉       | 47/163 [00:56<02:19,  1.21s/it, loss=2.3836, batch_acc=0.3438, running_acc=0.4202, grad=8.0067]Training epoch 3:  29%|██▉       | 48/163 [00:56<02:07,  1.11s/it, loss=2.3836, batch_acc=0.3438, running_acc=0.4202, grad=8.0067]Training epoch 3:  29%|██▉       | 48/163 [00:56<02:07,  1.11s/it, loss=1.7174, batch_acc=0.5625, running_acc=0.4232, grad=4.9866]Training epoch 3:  30%|███       | 49/163 [00:57<01:58,  1.04s/it, loss=1.7174, batch_acc=0.5625, running_acc=0.4232, grad=4.9866]Training epoch 3:  30%|███       | 49/163 [00:57<01:58,  1.04s/it, loss=1.9213, batch_acc=0.4375, running_acc=0.4235, grad=9.8961]Training epoch 3:  31%|███       | 50/163 [00:58<01:51,  1.01it/s, loss=1.9213, batch_acc=0.4375, running_acc=0.4235, grad=9.8961]Training epoch 3:  31%|███       | 50/163 [00:58<01:51,  1.01it/s, loss=1.8444, batch_acc=0.5312, running_acc=0.4256, grad=6.3339]Training epoch 3:  31%|███▏      | 51/163 [01:00<02:14,  1.20s/it, loss=1.8444, batch_acc=0.5312, running_acc=0.4256, grad=6.3339]Training epoch 3:  31%|███▏      | 51/163 [01:00<02:14,  1.20s/it, loss=1.8300, batch_acc=0.5000, running_acc=0.4271, grad=7.0061]Training epoch 3:  32%|███▏      | 52/163 [01:01<02:02,  1.11s/it, loss=1.8300, batch_acc=0.5000, running_acc=0.4271, grad=7.0061]Training epoch 3:  32%|███▏      | 52/163 [01:01<02:02,  1.11s/it, loss=1.7354, batch_acc=0.5938, running_acc=0.4303, grad=6.2320]Training epoch 3:  33%|███▎      | 53/163 [01:02<01:54,  1.04s/it, loss=1.7354, batch_acc=0.5938, running_acc=0.4303, grad=6.2320]Training epoch 3:  33%|███▎      | 53/163 [01:02<01:54,  1.04s/it, loss=1.9233, batch_acc=0.4375, running_acc=0.4304, grad=6.0798]Training epoch 3:  33%|███▎      | 54/163 [01:03<01:47,  1.01it/s, loss=1.9233, batch_acc=0.4375, running_acc=0.4304, grad=6.0798]Training epoch 3:  33%|███▎      | 54/163 [01:03<01:47,  1.01it/s, loss=1.8119, batch_acc=0.4688, running_acc=0.4311, grad=5.6856]Training epoch 3:  34%|███▎      | 55/163 [01:05<02:32,  1.41s/it, loss=1.8119, batch_acc=0.4688, running_acc=0.4311, grad=5.6856]Training epoch 3:  34%|███▎      | 55/163 [01:05<02:32,  1.41s/it, loss=1.9320, batch_acc=0.5625, running_acc=0.4335, grad=5.2769]Training epoch 3:  34%|███▍      | 56/163 [01:06<02:13,  1.25s/it, loss=1.9320, batch_acc=0.5625, running_acc=0.4335, grad=5.2769]Training epoch 3:  34%|███▍      | 56/163 [01:06<02:13,  1.25s/it, loss=1.6051, batch_acc=0.5312, running_acc=0.4353, grad=6.0862]Training epoch 3:  35%|███▍      | 57/163 [01:07<02:00,  1.14s/it, loss=1.6051, batch_acc=0.5312, running_acc=0.4353, grad=6.0862]Training epoch 3:  35%|███▍      | 57/163 [01:07<02:00,  1.14s/it, loss=1.8602, batch_acc=0.3125, running_acc=0.4331, grad=5.1913]Training epoch 3:  36%|███▌      | 58/163 [01:08<01:51,  1.06s/it, loss=1.8602, batch_acc=0.3125, running_acc=0.4331, grad=5.1913]Training epoch 3:  36%|███▌      | 58/163 [01:08<01:51,  1.06s/it, loss=2.0747, batch_acc=0.3750, running_acc=0.4321, grad=7.1973]Training epoch 3:  36%|███▌      | 59/163 [01:09<01:56,  1.12s/it, loss=2.0747, batch_acc=0.3750, running_acc=0.4321, grad=7.1973]Training epoch 3:  36%|███▌      | 59/163 [01:09<01:56,  1.12s/it, loss=1.7044, batch_acc=0.5312, running_acc=0.4338, grad=6.3258]Training epoch 3:  37%|███▋      | 60/163 [01:10<01:47,  1.05s/it, loss=1.7044, batch_acc=0.5312, running_acc=0.4338, grad=6.3258]Training epoch 3:  37%|███▋      | 60/163 [01:10<01:47,  1.05s/it, loss=1.7764, batch_acc=0.4375, running_acc=0.4339, grad=5.6935]Training epoch 3:  37%|███▋      | 61/163 [01:11<01:41,  1.00it/s, loss=1.7764, batch_acc=0.4375, running_acc=0.4339, grad=5.6935]Training epoch 3:  37%|███▋      | 61/163 [01:11<01:41,  1.00it/s, loss=1.8452, batch_acc=0.5625, running_acc=0.4360, grad=5.7428]Training epoch 3:  38%|███▊      | 62/163 [01:11<01:36,  1.04it/s, loss=1.8452, batch_acc=0.5625, running_acc=0.4360, grad=5.7428]Training epoch 3:  38%|███▊      | 62/163 [01:11<01:36,  1.04it/s, loss=1.7063, batch_acc=0.5625, running_acc=0.4380, grad=5.7458]Training epoch 3:  39%|███▊      | 63/163 [01:13<02:06,  1.26s/it, loss=1.7063, batch_acc=0.5625, running_acc=0.4380, grad=5.7458]Training epoch 3:  39%|███▊      | 63/163 [01:13<02:06,  1.26s/it, loss=2.0506, batch_acc=0.3750, running_acc=0.4370, grad=7.5277]Training epoch 3:  39%|███▉      | 64/163 [01:14<01:53,  1.15s/it, loss=2.0506, batch_acc=0.3750, running_acc=0.4370, grad=7.5277]Training epoch 3:  39%|███▉      | 64/163 [01:14<01:53,  1.15s/it, loss=2.4139, batch_acc=0.2812, running_acc=0.4346, grad=7.3382]Training epoch 3:  40%|███▉      | 65/163 [01:15<01:44,  1.07s/it, loss=2.4139, batch_acc=0.2812, running_acc=0.4346, grad=7.3382]Training epoch 3:  40%|███▉      | 65/163 [01:15<01:44,  1.07s/it, loss=2.1277, batch_acc=0.3750, running_acc=0.4337, grad=6.2846]Training epoch 3:  40%|████      | 66/163 [01:16<01:38,  1.01s/it, loss=2.1277, batch_acc=0.3750, running_acc=0.4337, grad=6.2846]Training epoch 3:  40%|████      | 66/163 [01:16<01:38,  1.01s/it, loss=2.1567, batch_acc=0.4062, running_acc=0.4332, grad=7.1446]Training epoch 3:  41%|████      | 67/163 [01:18<01:59,  1.24s/it, loss=2.1567, batch_acc=0.4062, running_acc=0.4332, grad=7.1446]Training epoch 3:  41%|████      | 67/163 [01:18<01:59,  1.24s/it, loss=1.8131, batch_acc=0.4375, running_acc=0.4333, grad=5.9339]Training epoch 3:  42%|████▏     | 68/163 [01:19<01:47,  1.13s/it, loss=1.8131, batch_acc=0.4375, running_acc=0.4333, grad=5.9339]Training epoch 3:  42%|████▏     | 68/163 [01:19<01:47,  1.13s/it, loss=1.7195, batch_acc=0.6250, running_acc=0.4361, grad=7.1839]Training epoch 3:  42%|████▏     | 69/163 [01:20<01:39,  1.06s/it, loss=1.7195, batch_acc=0.6250, running_acc=0.4361, grad=7.1839]Training epoch 3:  42%|████▏     | 69/163 [01:20<01:39,  1.06s/it, loss=1.7948, batch_acc=0.4375, running_acc=0.4361, grad=7.2669]Training epoch 3:  43%|████▎     | 70/163 [01:20<01:33,  1.00s/it, loss=1.7948, batch_acc=0.4375, running_acc=0.4361, grad=7.2669]Training epoch 3:  43%|████▎     | 70/163 [01:20<01:33,  1.00s/it, loss=1.6149, batch_acc=0.5625, running_acc=0.4379, grad=5.4337]Training epoch 3:  44%|████▎     | 71/163 [01:23<02:04,  1.35s/it, loss=1.6149, batch_acc=0.5625, running_acc=0.4379, grad=5.4337]Training epoch 3:  44%|████▎     | 71/163 [01:23<02:04,  1.35s/it, loss=1.6681, batch_acc=0.4375, running_acc=0.4379, grad=7.3932]Training epoch 3:  44%|████▍     | 72/163 [01:23<01:50,  1.21s/it, loss=1.6681, batch_acc=0.4375, running_acc=0.4379, grad=7.3932]Training epoch 3:  44%|████▍     | 72/163 [01:23<01:50,  1.21s/it, loss=2.0761, batch_acc=0.4062, running_acc=0.4375, grad=6.6459]Training epoch 3:  45%|████▍     | 73/163 [01:24<01:39,  1.11s/it, loss=2.0761, batch_acc=0.4062, running_acc=0.4375, grad=6.6459]Training epoch 3:  45%|████▍     | 73/163 [01:24<01:39,  1.11s/it, loss=1.8529, batch_acc=0.4375, running_acc=0.4375, grad=5.7279]Training epoch 3:  45%|████▌     | 74/163 [01:25<01:32,  1.04s/it, loss=1.8529, batch_acc=0.4375, running_acc=0.4375, grad=5.7279]Training epoch 3:  45%|████▌     | 74/163 [01:25<01:32,  1.04s/it, loss=1.8400, batch_acc=0.3438, running_acc=0.4362, grad=9.9830]Training epoch 3:  46%|████▌     | 75/163 [01:27<01:38,  1.11s/it, loss=1.8400, batch_acc=0.3438, running_acc=0.4362, grad=9.9830]Training epoch 3:  46%|████▌     | 75/163 [01:27<01:38,  1.11s/it, loss=1.9789, batch_acc=0.4062, running_acc=0.4358, grad=5.7065]Training epoch 3:  47%|████▋     | 76/163 [01:27<01:30,  1.04s/it, loss=1.9789, batch_acc=0.4062, running_acc=0.4358, grad=5.7065]Training epoch 3:  47%|████▋     | 76/163 [01:27<01:30,  1.04s/it, loss=2.0662, batch_acc=0.3438, running_acc=0.4346, grad=5.9393]Training epoch 3:  47%|████▋     | 77/163 [01:28<01:25,  1.01it/s, loss=2.0662, batch_acc=0.3438, running_acc=0.4346, grad=5.9393]Training epoch 3:  47%|████▋     | 77/163 [01:28<01:25,  1.01it/s, loss=2.0742, batch_acc=0.4375, running_acc=0.4347, grad=7.9143]Training epoch 3:  48%|████▊     | 78/163 [01:29<01:21,  1.04it/s, loss=2.0742, batch_acc=0.4375, running_acc=0.4347, grad=7.9143]Training epoch 3:  48%|████▊     | 78/163 [01:29<01:21,  1.04it/s, loss=1.7403, batch_acc=0.5000, running_acc=0.4355, grad=5.4021]Training epoch 3:  48%|████▊     | 79/163 [01:30<01:27,  1.04s/it, loss=1.7403, batch_acc=0.5000, running_acc=0.4355, grad=5.4021]Training epoch 3:  48%|████▊     | 79/163 [01:30<01:27,  1.04s/it, loss=2.0539, batch_acc=0.3750, running_acc=0.4347, grad=7.3716]Training epoch 3:  49%|████▉     | 80/163 [01:31<01:22,  1.01it/s, loss=2.0539, batch_acc=0.3750, running_acc=0.4347, grad=7.3716]Training epoch 3:  49%|████▉     | 80/163 [01:31<01:22,  1.01it/s, loss=2.1394, batch_acc=0.4688, running_acc=0.4352, grad=6.8762]Training epoch 3:  50%|████▉     | 81/163 [01:32<01:18,  1.04it/s, loss=2.1394, batch_acc=0.4688, running_acc=0.4352, grad=6.8762]Training epoch 3:  50%|████▉     | 81/163 [01:32<01:18,  1.04it/s, loss=1.6913, batch_acc=0.5312, running_acc=0.4363, grad=6.6031]Training epoch 3:  50%|█████     | 82/163 [01:33<01:15,  1.07it/s, loss=1.6913, batch_acc=0.5312, running_acc=0.4363, grad=6.6031]Training epoch 3:  50%|█████     | 82/163 [01:33<01:15,  1.07it/s, loss=1.6863, batch_acc=0.5625, running_acc=0.4379, grad=5.1064]Training epoch 3:  51%|█████     | 83/163 [01:35<01:33,  1.17s/it, loss=1.6863, batch_acc=0.5625, running_acc=0.4379, grad=5.1064]Training epoch 3:  51%|█████     | 83/163 [01:35<01:33,  1.17s/it, loss=1.8076, batch_acc=0.4375, running_acc=0.4379, grad=8.0338]Training epoch 3:  52%|█████▏    | 84/163 [01:36<01:25,  1.08s/it, loss=1.8076, batch_acc=0.4375, running_acc=0.4379, grad=8.0338]Training epoch 3:  52%|█████▏    | 84/163 [01:36<01:25,  1.08s/it, loss=1.7797, batch_acc=0.5000, running_acc=0.4386, grad=7.4479]Training epoch 3:  52%|█████▏    | 85/163 [01:37<01:19,  1.02s/it, loss=1.7797, batch_acc=0.5000, running_acc=0.4386, grad=7.4479]Training epoch 3:  52%|█████▏    | 85/163 [01:37<01:19,  1.02s/it, loss=1.7609, batch_acc=0.5312, running_acc=0.4397, grad=8.2552]Training epoch 3:  53%|█████▎    | 86/163 [01:37<01:15,  1.02it/s, loss=1.7609, batch_acc=0.5312, running_acc=0.4397, grad=8.2552]Training epoch 3:  53%|█████▎    | 86/163 [01:37<01:15,  1.02it/s, loss=1.6388, batch_acc=0.5625, running_acc=0.4411, grad=9.1802]Training epoch 3:  53%|█████▎    | 87/163 [01:39<01:34,  1.24s/it, loss=1.6388, batch_acc=0.5625, running_acc=0.4411, grad=9.1802]Training epoch 3:  53%|█████▎    | 87/163 [01:39<01:34,  1.24s/it, loss=1.7925, batch_acc=0.5625, running_acc=0.4425, grad=10.6278]Training epoch 3:  54%|█████▍    | 88/163 [01:40<01:24,  1.13s/it, loss=1.7925, batch_acc=0.5625, running_acc=0.4425, grad=10.6278]Training epoch 3:  54%|█████▍    | 88/163 [01:40<01:24,  1.13s/it, loss=2.0804, batch_acc=0.3125, running_acc=0.4411, grad=6.3953] Training epoch 3:  55%|█████▍    | 89/163 [01:41<01:18,  1.05s/it, loss=2.0804, batch_acc=0.3125, running_acc=0.4411, grad=6.3953]Training epoch 3:  55%|█████▍    | 89/163 [01:41<01:18,  1.05s/it, loss=1.7667, batch_acc=0.5938, running_acc=0.4428, grad=6.6039]Training epoch 3:  55%|█████▌    | 90/163 [01:42<01:13,  1.00s/it, loss=1.7667, batch_acc=0.5938, running_acc=0.4428, grad=6.6039]Training epoch 3:  55%|█████▌    | 90/163 [01:42<01:13,  1.00s/it, loss=1.6447, batch_acc=0.6250, running_acc=0.4448, grad=6.0874]Training epoch 3:  56%|█████▌    | 91/163 [01:43<01:19,  1.10s/it, loss=1.6447, batch_acc=0.6250, running_acc=0.4448, grad=6.0874]Training epoch 3:  56%|█████▌    | 91/163 [01:43<01:19,  1.10s/it, loss=1.8633, batch_acc=0.4688, running_acc=0.4451, grad=8.3593]Training epoch 3:  56%|█████▋    | 92/163 [01:44<01:13,  1.03s/it, loss=1.8633, batch_acc=0.4688, running_acc=0.4451, grad=8.3593]Training epoch 3:  56%|█████▋    | 92/163 [01:44<01:13,  1.03s/it, loss=2.0176, batch_acc=0.4688, running_acc=0.4453, grad=7.1656]Training epoch 3:  57%|█████▋    | 93/163 [01:45<01:09,  1.01it/s, loss=2.0176, batch_acc=0.4688, running_acc=0.4453, grad=7.1656]Training epoch 3:  57%|█████▋    | 93/163 [01:45<01:09,  1.01it/s, loss=1.7710, batch_acc=0.4375, running_acc=0.4452, grad=7.3324]Training epoch 3:  58%|█████▊    | 94/163 [01:46<01:05,  1.05it/s, loss=1.7710, batch_acc=0.4375, running_acc=0.4452, grad=7.3324]Training epoch 3:  58%|█████▊    | 94/163 [01:46<01:05,  1.05it/s, loss=1.6009, batch_acc=0.5625, running_acc=0.4465, grad=6.8821]Training epoch 3:  58%|█████▊    | 95/163 [01:47<01:14,  1.10s/it, loss=1.6009, batch_acc=0.5625, running_acc=0.4465, grad=6.8821]Training epoch 3:  58%|█████▊    | 95/163 [01:47<01:14,  1.10s/it, loss=2.0653, batch_acc=0.3750, running_acc=0.4457, grad=10.9961]Training epoch 3:  59%|█████▉    | 96/163 [01:48<01:09,  1.03s/it, loss=2.0653, batch_acc=0.3750, running_acc=0.4457, grad=10.9961]Training epoch 3:  59%|█████▉    | 96/163 [01:48<01:09,  1.03s/it, loss=2.0160, batch_acc=0.4375, running_acc=0.4456, grad=6.4470] Training epoch 3:  60%|█████▉    | 97/163 [01:49<01:05,  1.01it/s, loss=2.0160, batch_acc=0.4375, running_acc=0.4456, grad=6.4470]Training epoch 3:  60%|█████▉    | 97/163 [01:49<01:05,  1.01it/s, loss=2.3294, batch_acc=0.3438, running_acc=0.4446, grad=8.3814]Training epoch 3:  60%|██████    | 98/163 [01:50<01:01,  1.05it/s, loss=2.3294, batch_acc=0.3438, running_acc=0.4446, grad=8.3814]Training epoch 3:  60%|██████    | 98/163 [01:50<01:01,  1.05it/s, loss=1.6018, batch_acc=0.5312, running_acc=0.4455, grad=6.9125]Training epoch 3:  61%|██████    | 99/163 [01:51<01:11,  1.12s/it, loss=1.6018, batch_acc=0.5312, running_acc=0.4455, grad=6.9125]Training epoch 3:  61%|██████    | 99/163 [01:51<01:11,  1.12s/it, loss=2.0414, batch_acc=0.3750, running_acc=0.4448, grad=7.0023]Training epoch 3:  61%|██████▏   | 100/163 [01:52<01:05,  1.05s/it, loss=2.0414, batch_acc=0.3750, running_acc=0.4448, grad=7.0023]Training epoch 3:  61%|██████▏   | 100/163 [01:52<01:05,  1.05s/it, loss=2.0713, batch_acc=0.5000, running_acc=0.4453, grad=6.6122]Training epoch 3:  62%|██████▏   | 101/163 [01:53<01:01,  1.00it/s, loss=2.0713, batch_acc=0.5000, running_acc=0.4453, grad=6.6122]Training epoch 3:  62%|██████▏   | 101/163 [01:53<01:01,  1.00it/s, loss=1.6956, batch_acc=0.5312, running_acc=0.4462, grad=7.9389]Training epoch 3:  63%|██████▎   | 102/163 [01:54<00:58,  1.04it/s, loss=1.6956, batch_acc=0.5312, running_acc=0.4462, grad=7.9389]Training epoch 3:  63%|██████▎   | 102/163 [01:54<00:58,  1.04it/s, loss=1.9726, batch_acc=0.4375, running_acc=0.4461, grad=9.1613]Training epoch 3:  63%|██████▎   | 103/163 [01:56<01:10,  1.18s/it, loss=1.9726, batch_acc=0.4375, running_acc=0.4461, grad=9.1613]Training epoch 3:  63%|██████▎   | 103/163 [01:56<01:10,  1.18s/it, loss=2.2570, batch_acc=0.3750, running_acc=0.4454, grad=8.5651]Training epoch 3:  64%|██████▍   | 104/163 [01:57<01:04,  1.09s/it, loss=2.2570, batch_acc=0.3750, running_acc=0.4454, grad=8.5651]Training epoch 3:  64%|██████▍   | 104/163 [01:57<01:04,  1.09s/it, loss=2.0416, batch_acc=0.4062, running_acc=0.4450, grad=7.6922]Training epoch 3:  64%|██████▍   | 105/163 [01:57<00:59,  1.03s/it, loss=2.0416, batch_acc=0.4062, running_acc=0.4450, grad=7.6922]Training epoch 3:  64%|██████▍   | 105/163 [01:57<00:59,  1.03s/it, loss=2.0569, batch_acc=0.3750, running_acc=0.4443, grad=7.2736]Training epoch 3:  65%|██████▌   | 106/163 [01:58<00:56,  1.02it/s, loss=2.0569, batch_acc=0.3750, running_acc=0.4443, grad=7.2736]Training epoch 3:  65%|██████▌   | 106/163 [01:58<00:56,  1.02it/s, loss=1.8445, batch_acc=0.3750, running_acc=0.4437, grad=7.4411]Training epoch 3:  66%|██████▌   | 107/163 [02:00<01:08,  1.23s/it, loss=1.8445, batch_acc=0.3750, running_acc=0.4437, grad=7.4411]Training epoch 3:  66%|██████▌   | 107/163 [02:00<01:08,  1.23s/it, loss=1.2931, batch_acc=0.5938, running_acc=0.4451, grad=5.2963]Training epoch 3:  66%|██████▋   | 108/163 [02:01<01:01,  1.12s/it, loss=1.2931, batch_acc=0.5938, running_acc=0.4451, grad=5.2963]Training epoch 3:  66%|██████▋   | 108/163 [02:01<01:01,  1.12s/it, loss=1.7760, batch_acc=0.6250, running_acc=0.4468, grad=6.1236]Training epoch 3:  67%|██████▋   | 109/163 [02:02<00:56,  1.05s/it, loss=1.7760, batch_acc=0.6250, running_acc=0.4468, grad=6.1236]Training epoch 3:  67%|██████▋   | 109/163 [02:02<00:56,  1.05s/it, loss=1.5457, batch_acc=0.4688, running_acc=0.4470, grad=7.5000]Training epoch 3:  67%|██████▋   | 110/163 [02:03<00:52,  1.00it/s, loss=1.5457, batch_acc=0.4688, running_acc=0.4470, grad=7.5000]Training epoch 3:  67%|██████▋   | 110/163 [02:03<00:52,  1.00it/s, loss=1.5884, batch_acc=0.5312, running_acc=0.4477, grad=7.3619]Training epoch 3:  68%|██████▊   | 111/163 [02:05<01:04,  1.23s/it, loss=1.5884, batch_acc=0.5312, running_acc=0.4477, grad=7.3619]Training epoch 3:  68%|██████▊   | 111/163 [02:05<01:04,  1.23s/it, loss=1.7841, batch_acc=0.5312, running_acc=0.4485, grad=5.6057]Training epoch 3:  69%|██████▊   | 112/163 [02:05<00:57,  1.13s/it, loss=1.7841, batch_acc=0.5312, running_acc=0.4485, grad=5.6057]Training epoch 3:  69%|██████▊   | 112/163 [02:05<00:57,  1.13s/it, loss=2.3291, batch_acc=0.3125, running_acc=0.4473, grad=6.4092]Training epoch 3:  69%|██████▉   | 113/163 [02:06<00:52,  1.05s/it, loss=2.3291, batch_acc=0.3125, running_acc=0.4473, grad=6.4092]Training epoch 3:  69%|██████▉   | 113/163 [02:06<00:52,  1.05s/it, loss=1.8104, batch_acc=0.4375, running_acc=0.4472, grad=6.4144]Training epoch 3:  70%|██████▉   | 114/163 [02:07<00:48,  1.00it/s, loss=1.8104, batch_acc=0.4375, running_acc=0.4472, grad=6.4144]Training epoch 3:  70%|██████▉   | 114/163 [02:07<00:48,  1.00it/s, loss=1.7588, batch_acc=0.4375, running_acc=0.4471, grad=5.6553]Training epoch 3:  71%|███████   | 115/163 [02:09<00:59,  1.25s/it, loss=1.7588, batch_acc=0.4375, running_acc=0.4471, grad=5.6553]Training epoch 3:  71%|███████   | 115/163 [02:09<00:59,  1.25s/it, loss=1.9077, batch_acc=0.4688, running_acc=0.4473, grad=7.3462]Training epoch 3:  71%|███████   | 116/163 [02:10<00:53,  1.14s/it, loss=1.9077, batch_acc=0.4688, running_acc=0.4473, grad=7.3462]Training epoch 3:  71%|███████   | 116/163 [02:10<00:53,  1.14s/it, loss=2.1555, batch_acc=0.4375, running_acc=0.4472, grad=7.2537]Training epoch 3:  72%|███████▏  | 117/163 [02:11<00:48,  1.06s/it, loss=2.1555, batch_acc=0.4375, running_acc=0.4472, grad=7.2537]Training epoch 3:  72%|███████▏  | 117/163 [02:11<00:48,  1.06s/it, loss=1.9401, batch_acc=0.4688, running_acc=0.4474, grad=7.5534]Training epoch 3:  72%|███████▏  | 118/163 [02:12<00:45,  1.00s/it, loss=1.9401, batch_acc=0.4688, running_acc=0.4474, grad=7.5534]Training epoch 3:  72%|███████▏  | 118/163 [02:12<00:45,  1.00s/it, loss=1.8817, batch_acc=0.4375, running_acc=0.4473, grad=7.3571]Training epoch 3:  73%|███████▎  | 119/163 [02:14<00:57,  1.31s/it, loss=1.8817, batch_acc=0.4375, running_acc=0.4473, grad=7.3571]Training epoch 3:  73%|███████▎  | 119/163 [02:14<00:57,  1.31s/it, loss=2.1845, batch_acc=0.3438, running_acc=0.4464, grad=7.5428]Training epoch 3:  74%|███████▎  | 120/163 [02:15<00:50,  1.18s/it, loss=2.1845, batch_acc=0.3438, running_acc=0.4464, grad=7.5428]Training epoch 3:  74%|███████▎  | 120/163 [02:15<00:50,  1.18s/it, loss=1.9801, batch_acc=0.4062, running_acc=0.4461, grad=7.2605]Training epoch 3:  74%|███████▍  | 121/163 [02:15<00:45,  1.09s/it, loss=1.9801, batch_acc=0.4062, running_acc=0.4461, grad=7.2605]Training epoch 3:  74%|███████▍  | 121/163 [02:15<00:45,  1.09s/it, loss=1.4499, batch_acc=0.6250, running_acc=0.4476, grad=6.2611]Training epoch 3:  75%|███████▍  | 122/163 [02:16<00:42,  1.03s/it, loss=1.4499, batch_acc=0.6250, running_acc=0.4476, grad=6.2611]Training epoch 3:  75%|███████▍  | 122/163 [02:16<00:42,  1.03s/it, loss=1.8469, batch_acc=0.5000, running_acc=0.4480, grad=8.1454]Training epoch 3:  75%|███████▌  | 123/163 [02:18<00:48,  1.20s/it, loss=1.8469, batch_acc=0.5000, running_acc=0.4480, grad=8.1454]Training epoch 3:  75%|███████▌  | 123/163 [02:18<00:48,  1.20s/it, loss=1.7937, batch_acc=0.5000, running_acc=0.4484, grad=5.9617]Training epoch 3:  76%|███████▌  | 124/163 [02:19<00:43,  1.10s/it, loss=1.7937, batch_acc=0.5000, running_acc=0.4484, grad=5.9617]Training epoch 3:  76%|███████▌  | 124/163 [02:19<00:43,  1.10s/it, loss=1.4447, batch_acc=0.6562, running_acc=0.4501, grad=4.9198]Training epoch 3:  77%|███████▋  | 125/163 [02:20<00:39,  1.04s/it, loss=1.4447, batch_acc=0.6562, running_acc=0.4501, grad=4.9198]Training epoch 3:  77%|███████▋  | 125/163 [02:20<00:39,  1.04s/it, loss=1.4011, batch_acc=0.6562, running_acc=0.4517, grad=6.8192]Training epoch 3:  77%|███████▋  | 126/163 [02:21<00:36,  1.01it/s, loss=1.4011, batch_acc=0.6562, running_acc=0.4517, grad=6.8192]Training epoch 3:  77%|███████▋  | 126/163 [02:21<00:36,  1.01it/s, loss=1.8810, batch_acc=0.4375, running_acc=0.4516, grad=5.6238]Training epoch 3:  78%|███████▊  | 127/163 [02:22<00:39,  1.09s/it, loss=1.8810, batch_acc=0.4375, running_acc=0.4516, grad=5.6238]Training epoch 3:  78%|███████▊  | 127/163 [02:22<00:39,  1.09s/it, loss=1.9209, batch_acc=0.4688, running_acc=0.4518, grad=7.0861]Training epoch 3:  79%|███████▊  | 128/163 [02:23<00:36,  1.03s/it, loss=1.9209, batch_acc=0.4688, running_acc=0.4518, grad=7.0861]Training epoch 3:  79%|███████▊  | 128/163 [02:23<00:36,  1.03s/it, loss=1.8692, batch_acc=0.5000, running_acc=0.4521, grad=7.0993]Training epoch 3:  79%|███████▉  | 129/163 [02:24<00:33,  1.02it/s, loss=1.8692, batch_acc=0.5000, running_acc=0.4521, grad=7.0993]Training epoch 3:  79%|███████▉  | 129/163 [02:24<00:33,  1.02it/s, loss=1.4190, batch_acc=0.5312, running_acc=0.4528, grad=8.3939]Training epoch 3:  80%|███████▉  | 130/163 [02:25<00:31,  1.05it/s, loss=1.4190, batch_acc=0.5312, running_acc=0.4528, grad=8.3939]Training epoch 3:  80%|███████▉  | 130/163 [02:25<00:31,  1.05it/s, loss=1.7628, batch_acc=0.4375, running_acc=0.4526, grad=10.8814]Training epoch 3:  80%|████████  | 131/163 [02:26<00:38,  1.21s/it, loss=1.7628, batch_acc=0.4375, running_acc=0.4526, grad=10.8814]Training epoch 3:  80%|████████  | 131/163 [02:26<00:38,  1.21s/it, loss=2.0786, batch_acc=0.4375, running_acc=0.4525, grad=6.9471] Training epoch 3:  81%|████████  | 132/163 [02:27<00:34,  1.11s/it, loss=2.0786, batch_acc=0.4375, running_acc=0.4525, grad=6.9471]Training epoch 3:  81%|████████  | 132/163 [02:27<00:34,  1.11s/it, loss=1.6658, batch_acc=0.5625, running_acc=0.4534, grad=6.9070]Training epoch 3:  82%|████████▏ | 133/163 [02:28<00:31,  1.04s/it, loss=1.6658, batch_acc=0.5625, running_acc=0.4534, grad=6.9070]Training epoch 3:  82%|████████▏ | 133/163 [02:28<00:31,  1.04s/it, loss=1.9863, batch_acc=0.3750, running_acc=0.4528, grad=6.8910]Training epoch 3:  82%|████████▏ | 134/163 [02:29<00:28,  1.01it/s, loss=1.9863, batch_acc=0.3750, running_acc=0.4528, grad=6.8910]Training epoch 3:  82%|████████▏ | 134/163 [02:29<00:28,  1.01it/s, loss=1.8885, batch_acc=0.5312, running_acc=0.4534, grad=8.6273]Training epoch 3:  83%|████████▎ | 135/163 [02:31<00:32,  1.17s/it, loss=1.8885, batch_acc=0.5312, running_acc=0.4534, grad=8.6273]Training epoch 3:  83%|████████▎ | 135/163 [02:31<00:32,  1.17s/it, loss=1.7587, batch_acc=0.5312, running_acc=0.4539, grad=5.9847]Training epoch 3:  83%|████████▎ | 136/163 [02:31<00:29,  1.08s/it, loss=1.7587, batch_acc=0.5312, running_acc=0.4539, grad=5.9847]Training epoch 3:  83%|████████▎ | 136/163 [02:31<00:29,  1.08s/it, loss=1.8431, batch_acc=0.4062, running_acc=0.4536, grad=6.5111]Training epoch 3:  84%|████████▍ | 137/163 [02:32<00:26,  1.02s/it, loss=1.8431, batch_acc=0.4062, running_acc=0.4536, grad=6.5111]Training epoch 3:  84%|████████▍ | 137/163 [02:32<00:26,  1.02s/it, loss=1.8882, batch_acc=0.4688, running_acc=0.4537, grad=6.1873]Training epoch 3:  85%|████████▍ | 138/163 [02:33<00:24,  1.02it/s, loss=1.8882, batch_acc=0.4688, running_acc=0.4537, grad=6.1873]Training epoch 3:  85%|████████▍ | 138/163 [02:33<00:24,  1.02it/s, loss=1.6195, batch_acc=0.5312, running_acc=0.4543, grad=5.9998]Training epoch 3:  85%|████████▌ | 139/163 [02:35<00:30,  1.28s/it, loss=1.6195, batch_acc=0.5312, running_acc=0.4543, grad=5.9998]Training epoch 3:  85%|████████▌ | 139/163 [02:35<00:30,  1.28s/it, loss=2.2847, batch_acc=0.2500, running_acc=0.4528, grad=6.8880]Training epoch 3:  86%|████████▌ | 140/163 [02:36<00:26,  1.16s/it, loss=2.2847, batch_acc=0.2500, running_acc=0.4528, grad=6.8880]Training epoch 3:  86%|████████▌ | 140/163 [02:36<00:26,  1.16s/it, loss=1.6015, batch_acc=0.5625, running_acc=0.4536, grad=6.5421]Training epoch 3:  87%|████████▋ | 141/163 [02:37<00:23,  1.08s/it, loss=1.6015, batch_acc=0.5625, running_acc=0.4536, grad=6.5421]Training epoch 3:  87%|████████▋ | 141/163 [02:37<00:23,  1.08s/it, loss=2.1649, batch_acc=0.3750, running_acc=0.4530, grad=6.6925]Training epoch 3:  87%|████████▋ | 142/163 [02:38<00:21,  1.02s/it, loss=2.1649, batch_acc=0.3750, running_acc=0.4530, grad=6.6925]Training epoch 3:  87%|████████▋ | 142/163 [02:38<00:21,  1.02s/it, loss=1.5622, batch_acc=0.5000, running_acc=0.4533, grad=7.0485]Training epoch 3:  88%|████████▊ | 143/163 [02:40<00:27,  1.35s/it, loss=1.5622, batch_acc=0.5000, running_acc=0.4533, grad=7.0485]Training epoch 3:  88%|████████▊ | 143/163 [02:40<00:27,  1.35s/it, loss=1.9600, batch_acc=0.4688, running_acc=0.4535, grad=6.8616]Training epoch 3:  88%|████████▊ | 144/163 [02:41<00:22,  1.21s/it, loss=1.9600, batch_acc=0.4688, running_acc=0.4535, grad=6.8616]Training epoch 3:  88%|████████▊ | 144/163 [02:41<00:22,  1.21s/it, loss=2.2762, batch_acc=0.3438, running_acc=0.4527, grad=8.2913]Training epoch 3:  89%|████████▉ | 145/163 [02:42<00:19,  1.11s/it, loss=2.2762, batch_acc=0.3438, running_acc=0.4527, grad=8.2913]Training epoch 3:  89%|████████▉ | 145/163 [02:42<00:19,  1.11s/it, loss=1.7793, batch_acc=0.5000, running_acc=0.4530, grad=7.0414]Training epoch 3:  90%|████████▉ | 146/163 [02:43<00:17,  1.04s/it, loss=1.7793, batch_acc=0.5000, running_acc=0.4530, grad=7.0414]Training epoch 3:  90%|████████▉ | 146/163 [02:43<00:17,  1.04s/it, loss=1.9769, batch_acc=0.4375, running_acc=0.4529, grad=6.9205]Training epoch 3:  90%|█████████ | 147/163 [02:44<00:19,  1.24s/it, loss=1.9769, batch_acc=0.4375, running_acc=0.4529, grad=6.9205]Training epoch 3:  90%|█████████ | 147/163 [02:44<00:19,  1.24s/it, loss=1.6893, batch_acc=0.5312, running_acc=0.4534, grad=6.3195]Training epoch 3:  91%|█████████ | 148/163 [02:45<00:17,  1.13s/it, loss=1.6893, batch_acc=0.5312, running_acc=0.4534, grad=6.3195]Training epoch 3:  91%|█████████ | 148/163 [02:45<00:17,  1.13s/it, loss=1.7564, batch_acc=0.5312, running_acc=0.4540, grad=7.2275]Training epoch 3:  91%|█████████▏| 149/163 [02:46<00:14,  1.06s/it, loss=1.7564, batch_acc=0.5312, running_acc=0.4540, grad=7.2275]Training epoch 3:  91%|█████████▏| 149/163 [02:46<00:14,  1.06s/it, loss=1.6030, batch_acc=0.5625, running_acc=0.4547, grad=5.9278]Training epoch 3:  92%|█████████▏| 150/163 [02:47<00:13,  1.00s/it, loss=1.6030, batch_acc=0.5625, running_acc=0.4547, grad=5.9278]Training epoch 3:  92%|█████████▏| 150/163 [02:47<00:13,  1.00s/it, loss=1.4594, batch_acc=0.5625, running_acc=0.4554, grad=8.4010]Training epoch 3:  93%|█████████▎| 151/163 [02:49<00:15,  1.31s/it, loss=1.4594, batch_acc=0.5625, running_acc=0.4554, grad=8.4010]Training epoch 3:  93%|█████████▎| 151/163 [02:49<00:15,  1.31s/it, loss=1.7381, batch_acc=0.4062, running_acc=0.4551, grad=10.7080]Training epoch 3:  93%|█████████▎| 152/163 [02:50<00:12,  1.18s/it, loss=1.7381, batch_acc=0.4062, running_acc=0.4551, grad=10.7080]Training epoch 3:  93%|█████████▎| 152/163 [02:50<00:12,  1.18s/it, loss=2.1693, batch_acc=0.5000, running_acc=0.4554, grad=7.7340] Training epoch 3:  94%|█████████▍| 153/163 [02:51<00:10,  1.09s/it, loss=2.1693, batch_acc=0.5000, running_acc=0.4554, grad=7.7340]Training epoch 3:  94%|█████████▍| 153/163 [02:51<00:10,  1.09s/it, loss=1.8993, batch_acc=0.4062, running_acc=0.4551, grad=6.2545]Training epoch 3:  94%|█████████▍| 154/163 [02:52<00:09,  1.03s/it, loss=1.8993, batch_acc=0.4062, running_acc=0.4551, grad=6.2545]Training epoch 3:  94%|█████████▍| 154/163 [02:52<00:09,  1.03s/it, loss=1.9643, batch_acc=0.3750, running_acc=0.4545, grad=5.9577]Training epoch 3:  95%|█████████▌| 155/163 [02:53<00:09,  1.24s/it, loss=1.9643, batch_acc=0.3750, running_acc=0.4545, grad=5.9577]Training epoch 3:  95%|█████████▌| 155/163 [02:53<00:09,  1.24s/it, loss=1.8339, batch_acc=0.4688, running_acc=0.4546, grad=5.6744]Training epoch 3:  96%|█████████▌| 156/163 [02:54<00:07,  1.13s/it, loss=1.8339, batch_acc=0.4688, running_acc=0.4546, grad=5.6744]Training epoch 3:  96%|█████████▌| 156/163 [02:54<00:07,  1.13s/it, loss=1.8522, batch_acc=0.4375, running_acc=0.4545, grad=6.5830]Training epoch 3:  96%|█████████▋| 157/163 [02:55<00:06,  1.05s/it, loss=1.8522, batch_acc=0.4375, running_acc=0.4545, grad=6.5830]Training epoch 3:  96%|█████████▋| 157/163 [02:55<00:06,  1.05s/it, loss=1.6046, batch_acc=0.5312, running_acc=0.4550, grad=6.4590]Training epoch 3:  97%|█████████▋| 158/163 [02:56<00:05,  1.00s/it, loss=1.6046, batch_acc=0.5312, running_acc=0.4550, grad=6.4590]Training epoch 3:  97%|█████████▋| 158/163 [02:56<00:05,  1.00s/it, loss=1.6579, batch_acc=0.4375, running_acc=0.4549, grad=6.8956]Training epoch 3:  98%|█████████▊| 159/163 [02:58<00:04,  1.17s/it, loss=1.6579, batch_acc=0.4375, running_acc=0.4549, grad=6.8956]Training epoch 3:  98%|█████████▊| 159/163 [02:58<00:04,  1.17s/it, loss=1.9085, batch_acc=0.3750, running_acc=0.4544, grad=6.5667]Training epoch 3:  98%|█████████▊| 160/163 [02:58<00:03,  1.08s/it, loss=1.9085, batch_acc=0.3750, running_acc=0.4544, grad=6.5667]Training epoch 3:  98%|█████████▊| 160/163 [02:58<00:03,  1.08s/it, loss=1.8597, batch_acc=0.5312, running_acc=0.4549, grad=6.2930]Training epoch 3:  99%|█████████▉| 161/163 [02:59<00:02,  1.02s/it, loss=1.8597, batch_acc=0.5312, running_acc=0.4549, grad=6.2930]Training epoch 3:  99%|█████████▉| 161/163 [02:59<00:02,  1.02s/it, loss=1.8055, batch_acc=0.5000, running_acc=0.4552, grad=6.0502]Training epoch 3:  99%|█████████▉| 162/163 [03:00<00:00,  1.02it/s, loss=1.8055, batch_acc=0.5000, running_acc=0.4552, grad=6.0502]Training epoch 3:  99%|█████████▉| 162/163 [03:00<00:00,  1.02it/s, loss=1.9091, batch_acc=0.4375, running_acc=0.4551, grad=6.0398]Training epoch 3: 100%|██████████| 163/163 [03:01<00:00,  1.14it/s, loss=1.9091, batch_acc=0.4375, running_acc=0.4551, grad=6.0398]Training epoch 3: 100%|██████████| 163/163 [03:01<00:00,  1.14it/s, loss=1.9918, batch_acc=0.4286, running_acc=0.4549, grad=7.6249]Training epoch 3: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=1.9918, batch_acc=0.4286, running_acc=0.4549, grad=7.6249]
Evaluation epoch 3:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 3:   4%|▎         | 1/28 [00:05<02:21,  5.25s/it]Evaluation epoch 3:   4%|▎         | 1/28 [00:05<02:21,  5.25s/it, loss=1.0466, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 3:   7%|▋         | 2/28 [00:05<01:02,  2.39s/it, loss=1.0466, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 3:   7%|▋         | 2/28 [00:05<01:02,  2.39s/it, loss=1.5952, batch_acc=0.5312, running_acc=0.6406]Evaluation epoch 3:  11%|█         | 3/28 [00:05<00:35,  1.42s/it, loss=1.5952, batch_acc=0.5312, running_acc=0.6406]Evaluation epoch 3:  11%|█         | 3/28 [00:05<00:35,  1.42s/it, loss=1.5571, batch_acc=0.4688, running_acc=0.5833]Evaluation epoch 3:  14%|█▍        | 4/28 [00:10<01:02,  2.61s/it, loss=1.5571, batch_acc=0.4688, running_acc=0.5833]Evaluation epoch 3:  14%|█▍        | 4/28 [00:10<01:02,  2.61s/it, loss=2.2815, batch_acc=0.2188, running_acc=0.4922]Evaluation epoch 3:  18%|█▊        | 5/28 [00:10<00:40,  1.76s/it, loss=2.2815, batch_acc=0.2188, running_acc=0.4922]Evaluation epoch 3:  18%|█▊        | 5/28 [00:10<00:40,  1.76s/it, loss=2.4155, batch_acc=0.3438, running_acc=0.4625]Evaluation epoch 3:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=2.4155, batch_acc=0.3438, running_acc=0.4625]Evaluation epoch 3:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=2.7884, batch_acc=0.2500, running_acc=0.4271]Evaluation epoch 3:  25%|██▌       | 7/28 [00:11<00:19,  1.08it/s, loss=2.7884, batch_acc=0.2500, running_acc=0.4271]Evaluation epoch 3:  25%|██▌       | 7/28 [00:11<00:19,  1.08it/s, loss=2.1831, batch_acc=0.2812, running_acc=0.4062]Evaluation epoch 3:  29%|██▊       | 8/28 [00:14<00:36,  1.84s/it, loss=2.1831, batch_acc=0.2812, running_acc=0.4062]Evaluation epoch 3:  29%|██▊       | 8/28 [00:14<00:36,  1.84s/it, loss=1.9880, batch_acc=0.5000, running_acc=0.4180]Evaluation epoch 3:  32%|███▏      | 9/28 [00:15<00:25,  1.35s/it, loss=1.9880, batch_acc=0.5000, running_acc=0.4180]Evaluation epoch 3:  32%|███▏      | 9/28 [00:15<00:25,  1.35s/it, loss=2.2004, batch_acc=0.5312, running_acc=0.4306]Evaluation epoch 3:  36%|███▌      | 10/28 [00:15<00:18,  1.01s/it, loss=2.2004, batch_acc=0.5312, running_acc=0.4306]Evaluation epoch 3:  36%|███▌      | 10/28 [00:15<00:18,  1.01s/it, loss=0.8416, batch_acc=0.8438, running_acc=0.4719]Evaluation epoch 3:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=0.8416, batch_acc=0.8438, running_acc=0.4719]Evaluation epoch 3:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=2.2163, batch_acc=0.5000, running_acc=0.4744]Evaluation epoch 3:  43%|████▎     | 12/28 [00:21<00:36,  2.31s/it, loss=2.2163, batch_acc=0.5000, running_acc=0.4744]Evaluation epoch 3:  43%|████▎     | 12/28 [00:21<00:36,  2.31s/it, loss=1.3842, batch_acc=0.6562, running_acc=0.4896]Evaluation epoch 3:  46%|████▋     | 13/28 [00:21<00:25,  1.69s/it, loss=1.3842, batch_acc=0.6562, running_acc=0.4896]Evaluation epoch 3:  46%|████▋     | 13/28 [00:21<00:25,  1.69s/it, loss=1.4371, batch_acc=0.6250, running_acc=0.5000]Evaluation epoch 3:  50%|█████     | 14/28 [00:22<00:17,  1.26s/it, loss=1.4371, batch_acc=0.6250, running_acc=0.5000]Evaluation epoch 3:  50%|█████     | 14/28 [00:22<00:17,  1.26s/it, loss=1.8753, batch_acc=0.5000, running_acc=0.5000]Evaluation epoch 3:  54%|█████▎    | 15/28 [00:22<00:12,  1.05it/s, loss=1.8753, batch_acc=0.5000, running_acc=0.5000]Evaluation epoch 3:  54%|█████▎    | 15/28 [00:22<00:12,  1.05it/s, loss=2.8340, batch_acc=0.2500, running_acc=0.4833]Evaluation epoch 3:  57%|█████▋    | 16/28 [00:25<00:18,  1.56s/it, loss=2.8340, batch_acc=0.2500, running_acc=0.4833]Evaluation epoch 3:  57%|█████▋    | 16/28 [00:25<00:18,  1.56s/it, loss=1.8547, batch_acc=0.5625, running_acc=0.4883]Evaluation epoch 3:  61%|██████    | 17/28 [00:25<00:12,  1.17s/it, loss=1.8547, batch_acc=0.5625, running_acc=0.4883]Evaluation epoch 3:  61%|██████    | 17/28 [00:25<00:12,  1.17s/it, loss=1.4685, batch_acc=0.6562, running_acc=0.4982]Evaluation epoch 3:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=1.4685, batch_acc=0.6562, running_acc=0.4982]Evaluation epoch 3:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=1.6503, batch_acc=0.5000, running_acc=0.4983]Evaluation epoch 3:  68%|██████▊   | 19/28 [00:26<00:06,  1.42it/s, loss=1.6503, batch_acc=0.5000, running_acc=0.4983]Evaluation epoch 3:  68%|██████▊   | 19/28 [00:26<00:06,  1.42it/s, loss=1.7118, batch_acc=0.4375, running_acc=0.4951]Evaluation epoch 3:  71%|███████▏  | 20/28 [00:29<00:11,  1.44s/it, loss=1.7118, batch_acc=0.4375, running_acc=0.4951]Evaluation epoch 3:  71%|███████▏  | 20/28 [00:29<00:11,  1.44s/it, loss=2.6535, batch_acc=0.1250, running_acc=0.4766]Evaluation epoch 3:  75%|███████▌  | 21/28 [00:29<00:07,  1.09s/it, loss=2.6535, batch_acc=0.1250, running_acc=0.4766]Evaluation epoch 3:  75%|███████▌  | 21/28 [00:29<00:07,  1.09s/it, loss=2.3334, batch_acc=0.2500, running_acc=0.4658]Evaluation epoch 3:  79%|███████▊  | 22/28 [00:29<00:05,  1.19it/s, loss=2.3334, batch_acc=0.2500, running_acc=0.4658]Evaluation epoch 3:  79%|███████▊  | 22/28 [00:29<00:05,  1.19it/s, loss=2.2520, batch_acc=0.3125, running_acc=0.4588]Evaluation epoch 3:  82%|████████▏ | 23/28 [00:29<00:03,  1.50it/s, loss=2.2520, batch_acc=0.3125, running_acc=0.4588]Evaluation epoch 3:  82%|████████▏ | 23/28 [00:29<00:03,  1.50it/s, loss=1.7318, batch_acc=0.4375, running_acc=0.4579]Evaluation epoch 3:  86%|████████▌ | 24/28 [00:35<00:08,  2.15s/it, loss=1.7318, batch_acc=0.4375, running_acc=0.4579]Evaluation epoch 3:  86%|████████▌ | 24/28 [00:35<00:08,  2.15s/it, loss=0.9434, batch_acc=0.7500, running_acc=0.4701]Evaluation epoch 3:  89%|████████▉ | 25/28 [00:35<00:04,  1.58s/it, loss=0.9434, batch_acc=0.7500, running_acc=0.4701]Evaluation epoch 3:  89%|████████▉ | 25/28 [00:35<00:04,  1.58s/it, loss=1.1471, batch_acc=0.6562, running_acc=0.4775]Evaluation epoch 3:  93%|█████████▎| 26/28 [00:36<00:02,  1.19s/it, loss=1.1471, batch_acc=0.6562, running_acc=0.4775]Evaluation epoch 3:  93%|█████████▎| 26/28 [00:36<00:02,  1.19s/it, loss=1.8013, batch_acc=0.4062, running_acc=0.4748]Evaluation epoch 3:  96%|█████████▋| 27/28 [00:36<00:00,  1.10it/s, loss=1.8013, batch_acc=0.4062, running_acc=0.4748]Evaluation epoch 3:  96%|█████████▋| 27/28 [00:36<00:00,  1.10it/s, loss=1.9841, batch_acc=0.4062, running_acc=0.4722]Evaluation epoch 3: 100%|██████████| 28/28 [00:36<00:00,  1.10it/s, loss=0.9037, batch_acc=0.6667, running_acc=0.4729]Evaluation epoch 3: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.9037, batch_acc=0.6667, running_acc=0.4729]
Training epoch 4:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 4:   1%|          | 1/163 [00:05<14:38,  5.42s/it]Training epoch 4:   1%|          | 1/163 [00:05<14:38,  5.42s/it, loss=1.4644, batch_acc=0.6250, running_acc=0.6250, grad=8.3177]Training epoch 4:   1%|          | 2/163 [00:06<07:22,  2.75s/it, loss=1.4644, batch_acc=0.6250, running_acc=0.6250, grad=8.3177]Training epoch 4:   1%|          | 2/163 [00:06<07:22,  2.75s/it, loss=1.4938, batch_acc=0.6562, running_acc=0.6406, grad=6.9365]Training epoch 4:   2%|▏         | 3/163 [00:07<05:03,  1.89s/it, loss=1.4938, batch_acc=0.6562, running_acc=0.6406, grad=6.9365]Training epoch 4:   2%|▏         | 3/163 [00:07<05:03,  1.89s/it, loss=1.9217, batch_acc=0.4688, running_acc=0.5833, grad=6.7675]Training epoch 4:   2%|▏         | 4/163 [00:09<05:05,  1.92s/it, loss=1.9217, batch_acc=0.4688, running_acc=0.5833, grad=6.7675]Training epoch 4:   2%|▏         | 4/163 [00:09<05:05,  1.92s/it, loss=1.7803, batch_acc=0.5312, running_acc=0.5703, grad=7.1201]Training epoch 4:   3%|▎         | 5/163 [00:10<04:03,  1.54s/it, loss=1.7803, batch_acc=0.5312, running_acc=0.5703, grad=7.1201]Training epoch 4:   3%|▎         | 5/163 [00:10<04:03,  1.54s/it, loss=1.5528, batch_acc=0.4688, running_acc=0.5500, grad=6.6519]Training epoch 4:   4%|▎         | 6/163 [00:10<03:26,  1.32s/it, loss=1.5528, batch_acc=0.4688, running_acc=0.5500, grad=6.6519]Training epoch 4:   4%|▎         | 6/163 [00:10<03:26,  1.32s/it, loss=1.8253, batch_acc=0.4062, running_acc=0.5260, grad=7.3316]Training epoch 4:   4%|▍         | 7/163 [00:11<03:04,  1.18s/it, loss=1.8253, batch_acc=0.4062, running_acc=0.5260, grad=7.3316]Training epoch 4:   4%|▍         | 7/163 [00:11<03:04,  1.18s/it, loss=1.4850, batch_acc=0.5625, running_acc=0.5312, grad=6.9100]Training epoch 4:   5%|▍         | 8/163 [00:14<04:09,  1.61s/it, loss=1.4850, batch_acc=0.5625, running_acc=0.5312, grad=6.9100]Training epoch 4:   5%|▍         | 8/163 [00:14<04:09,  1.61s/it, loss=1.2971, batch_acc=0.6562, running_acc=0.5469, grad=7.1249]Training epoch 4:   6%|▌         | 9/163 [00:15<03:32,  1.38s/it, loss=1.2971, batch_acc=0.6562, running_acc=0.5469, grad=7.1249]Training epoch 4:   6%|▌         | 9/163 [00:15<03:32,  1.38s/it, loss=1.2286, batch_acc=0.7500, running_acc=0.5694, grad=7.9603]Training epoch 4:   6%|▌         | 10/163 [00:16<03:07,  1.23s/it, loss=1.2286, batch_acc=0.7500, running_acc=0.5694, grad=7.9603]Training epoch 4:   6%|▌         | 10/163 [00:16<03:07,  1.23s/it, loss=1.5482, batch_acc=0.5625, running_acc=0.5687, grad=7.6796]Training epoch 4:   7%|▋         | 11/163 [00:16<02:50,  1.12s/it, loss=1.5482, batch_acc=0.5625, running_acc=0.5687, grad=7.6796]Training epoch 4:   7%|▋         | 11/163 [00:16<02:50,  1.12s/it, loss=1.8226, batch_acc=0.3750, running_acc=0.5511, grad=8.9407]Training epoch 4:   7%|▋         | 12/163 [00:18<03:15,  1.29s/it, loss=1.8226, batch_acc=0.3750, running_acc=0.5511, grad=8.9407]Training epoch 4:   7%|▋         | 12/163 [00:18<03:15,  1.29s/it, loss=1.8725, batch_acc=0.4062, running_acc=0.5391, grad=7.7744]Training epoch 4:   8%|▊         | 13/163 [00:19<02:55,  1.17s/it, loss=1.8725, batch_acc=0.4062, running_acc=0.5391, grad=7.7744]Training epoch 4:   8%|▊         | 13/163 [00:19<02:55,  1.17s/it, loss=1.8066, batch_acc=0.5000, running_acc=0.5361, grad=9.0776]Training epoch 4:   9%|▊         | 14/163 [00:20<02:40,  1.08s/it, loss=1.8066, batch_acc=0.5000, running_acc=0.5361, grad=9.0776]Training epoch 4:   9%|▊         | 14/163 [00:20<02:40,  1.08s/it, loss=1.8351, batch_acc=0.4688, running_acc=0.5312, grad=8.8674]Training epoch 4:   9%|▉         | 15/163 [00:21<02:30,  1.02s/it, loss=1.8351, batch_acc=0.4688, running_acc=0.5312, grad=8.8674]Training epoch 4:   9%|▉         | 15/163 [00:21<02:30,  1.02s/it, loss=1.9992, batch_acc=0.4062, running_acc=0.5229, grad=8.2162]Training epoch 4:  10%|▉         | 16/163 [00:22<02:50,  1.16s/it, loss=1.9992, batch_acc=0.4062, running_acc=0.5229, grad=8.2162]Training epoch 4:  10%|▉         | 16/163 [00:22<02:50,  1.16s/it, loss=1.1777, batch_acc=0.7188, running_acc=0.5352, grad=6.4937]Training epoch 4:  10%|█         | 17/163 [00:23<02:41,  1.10s/it, loss=1.1777, batch_acc=0.7188, running_acc=0.5352, grad=6.4937]Training epoch 4:  10%|█         | 17/163 [00:23<02:41,  1.10s/it, loss=2.1602, batch_acc=0.4375, running_acc=0.5294, grad=7.1447]Training epoch 4:  11%|█         | 18/163 [00:24<02:30,  1.04s/it, loss=2.1602, batch_acc=0.4375, running_acc=0.5294, grad=7.1447]Training epoch 4:  11%|█         | 18/163 [00:24<02:30,  1.04s/it, loss=1.5477, batch_acc=0.5312, running_acc=0.5295, grad=7.1232]Training epoch 4:  12%|█▏        | 19/163 [00:25<02:22,  1.01it/s, loss=1.5477, batch_acc=0.5312, running_acc=0.5295, grad=7.1232]Training epoch 4:  12%|█▏        | 19/163 [00:25<02:22,  1.01it/s, loss=1.7846, batch_acc=0.5000, running_acc=0.5280, grad=9.0871]Training epoch 4:  12%|█▏        | 20/163 [00:26<02:35,  1.09s/it, loss=1.7846, batch_acc=0.5000, running_acc=0.5280, grad=9.0871]Training epoch 4:  12%|█▏        | 20/163 [00:26<02:35,  1.09s/it, loss=1.5847, batch_acc=0.5938, running_acc=0.5312, grad=6.9054]Training epoch 4:  13%|█▎        | 21/163 [00:27<02:25,  1.02s/it, loss=1.5847, batch_acc=0.5938, running_acc=0.5312, grad=6.9054]Training epoch 4:  13%|█▎        | 21/163 [00:27<02:25,  1.02s/it, loss=1.7747, batch_acc=0.4062, running_acc=0.5253, grad=6.1977]Training epoch 4:  13%|█▎        | 22/163 [00:28<02:23,  1.02s/it, loss=1.7747, batch_acc=0.4062, running_acc=0.5253, grad=6.1977]Training epoch 4:  13%|█▎        | 22/163 [00:28<02:23,  1.02s/it, loss=1.1710, batch_acc=0.7188, running_acc=0.5341, grad=5.5511]Training epoch 4:  14%|█▍        | 23/163 [00:29<02:19,  1.00it/s, loss=1.1710, batch_acc=0.7188, running_acc=0.5341, grad=5.5511]Training epoch 4:  14%|█▍        | 23/163 [00:29<02:19,  1.00it/s, loss=1.6451, batch_acc=0.4375, running_acc=0.5299, grad=7.7608]Training epoch 4:  15%|█▍        | 24/163 [00:31<03:02,  1.31s/it, loss=1.6451, batch_acc=0.4375, running_acc=0.5299, grad=7.7608]Training epoch 4:  15%|█▍        | 24/163 [00:31<03:02,  1.31s/it, loss=1.6567, batch_acc=0.5312, running_acc=0.5299, grad=7.1767]Training epoch 4:  15%|█▌        | 25/163 [00:32<02:42,  1.18s/it, loss=1.6567, batch_acc=0.5312, running_acc=0.5299, grad=7.1767]Training epoch 4:  15%|█▌        | 25/163 [00:32<02:42,  1.18s/it, loss=1.4619, batch_acc=0.5625, running_acc=0.5312, grad=7.2804]Training epoch 4:  16%|█▌        | 26/163 [00:33<02:29,  1.09s/it, loss=1.4619, batch_acc=0.5625, running_acc=0.5312, grad=7.2804]Training epoch 4:  16%|█▌        | 26/163 [00:33<02:29,  1.09s/it, loss=1.4306, batch_acc=0.5938, running_acc=0.5337, grad=9.8563]Training epoch 4:  17%|█▋        | 27/163 [00:34<02:19,  1.03s/it, loss=1.4306, batch_acc=0.5938, running_acc=0.5337, grad=9.8563]Training epoch 4:  17%|█▋        | 27/163 [00:34<02:19,  1.03s/it, loss=1.8428, batch_acc=0.4688, running_acc=0.5312, grad=8.4222]Training epoch 4:  17%|█▋        | 28/163 [00:35<02:43,  1.21s/it, loss=1.8428, batch_acc=0.4688, running_acc=0.5312, grad=8.4222]Training epoch 4:  17%|█▋        | 28/163 [00:35<02:43,  1.21s/it, loss=1.3629, batch_acc=0.6250, running_acc=0.5346, grad=6.8817]Training epoch 4:  18%|█▊        | 29/163 [00:36<02:28,  1.11s/it, loss=1.3629, batch_acc=0.6250, running_acc=0.5346, grad=6.8817]Training epoch 4:  18%|█▊        | 29/163 [00:36<02:28,  1.11s/it, loss=1.3453, batch_acc=0.6562, running_acc=0.5388, grad=5.0894]Training epoch 4:  18%|█▊        | 30/163 [00:37<02:18,  1.04s/it, loss=1.3453, batch_acc=0.6562, running_acc=0.5388, grad=5.0894]Training epoch 4:  18%|█▊        | 30/163 [00:37<02:18,  1.04s/it, loss=1.6155, batch_acc=0.5312, running_acc=0.5385, grad=7.7177]Training epoch 4:  19%|█▉        | 31/163 [00:38<02:10,  1.01it/s, loss=1.6155, batch_acc=0.5312, running_acc=0.5385, grad=7.7177]Training epoch 4:  19%|█▉        | 31/163 [00:38<02:10,  1.01it/s, loss=1.5752, batch_acc=0.3750, running_acc=0.5333, grad=11.5177]Training epoch 4:  20%|█▉        | 32/163 [00:40<02:34,  1.18s/it, loss=1.5752, batch_acc=0.3750, running_acc=0.5333, grad=11.5177]Training epoch 4:  20%|█▉        | 32/163 [00:40<02:34,  1.18s/it, loss=1.4844, batch_acc=0.5938, running_acc=0.5352, grad=6.2981] Training epoch 4:  20%|██        | 33/163 [00:41<02:21,  1.09s/it, loss=1.4844, batch_acc=0.5938, running_acc=0.5352, grad=6.2981]Training epoch 4:  20%|██        | 33/163 [00:41<02:21,  1.09s/it, loss=1.5889, batch_acc=0.5625, running_acc=0.5360, grad=6.1188]Training epoch 4:  21%|██        | 34/163 [00:41<02:12,  1.02s/it, loss=1.5889, batch_acc=0.5625, running_acc=0.5360, grad=6.1188]Training epoch 4:  21%|██        | 34/163 [00:41<02:12,  1.02s/it, loss=1.6873, batch_acc=0.3750, running_acc=0.5312, grad=13.3100]Training epoch 4:  21%|██▏       | 35/163 [00:42<02:05,  1.02it/s, loss=1.6873, batch_acc=0.3750, running_acc=0.5312, grad=13.3100]Training epoch 4:  21%|██▏       | 35/163 [00:42<02:05,  1.02it/s, loss=1.7279, batch_acc=0.4375, running_acc=0.5286, grad=11.8912]Training epoch 4:  22%|██▏       | 36/163 [00:44<02:13,  1.05s/it, loss=1.7279, batch_acc=0.4375, running_acc=0.5286, grad=11.8912]Training epoch 4:  22%|██▏       | 36/163 [00:44<02:13,  1.05s/it, loss=1.6979, batch_acc=0.5000, running_acc=0.5278, grad=9.3544] Training epoch 4:  23%|██▎       | 37/163 [00:44<02:06,  1.00s/it, loss=1.6979, batch_acc=0.5000, running_acc=0.5278, grad=9.3544]Training epoch 4:  23%|██▎       | 37/163 [00:44<02:06,  1.00s/it, loss=1.8475, batch_acc=0.5000, running_acc=0.5270, grad=6.6934]Training epoch 4:  23%|██▎       | 38/163 [00:45<02:00,  1.04it/s, loss=1.8475, batch_acc=0.5000, running_acc=0.5270, grad=6.6934]Training epoch 4:  23%|██▎       | 38/163 [00:45<02:00,  1.04it/s, loss=2.0932, batch_acc=0.4375, running_acc=0.5247, grad=7.5411]Training epoch 4:  24%|██▍       | 39/163 [00:46<02:04,  1.00s/it, loss=2.0932, batch_acc=0.4375, running_acc=0.5247, grad=7.5411]Training epoch 4:  24%|██▍       | 39/163 [00:46<02:04,  1.00s/it, loss=1.2079, batch_acc=0.7188, running_acc=0.5296, grad=9.0539]Training epoch 4:  25%|██▍       | 40/163 [00:48<02:34,  1.26s/it, loss=1.2079, batch_acc=0.7188, running_acc=0.5296, grad=9.0539]Training epoch 4:  25%|██▍       | 40/163 [00:48<02:34,  1.26s/it, loss=1.9295, batch_acc=0.5000, running_acc=0.5289, grad=9.8454]Training epoch 4:  25%|██▌       | 41/163 [00:49<02:19,  1.14s/it, loss=1.9295, batch_acc=0.5000, running_acc=0.5289, grad=9.8454]Training epoch 4:  25%|██▌       | 41/163 [00:49<02:19,  1.14s/it, loss=1.5765, batch_acc=0.5000, running_acc=0.5282, grad=8.6302]Training epoch 4:  26%|██▌       | 42/163 [00:50<02:08,  1.06s/it, loss=1.5765, batch_acc=0.5000, running_acc=0.5282, grad=8.6302]Training epoch 4:  26%|██▌       | 42/163 [00:50<02:08,  1.06s/it, loss=1.7183, batch_acc=0.4375, running_acc=0.5260, grad=6.3466]Training epoch 4:  26%|██▋       | 43/163 [00:51<02:02,  1.02s/it, loss=1.7183, batch_acc=0.4375, running_acc=0.5260, grad=6.3466]Training epoch 4:  26%|██▋       | 43/163 [00:51<02:02,  1.02s/it, loss=1.6583, batch_acc=0.5312, running_acc=0.5262, grad=8.6373]Training epoch 4:  27%|██▋       | 44/163 [00:53<02:28,  1.24s/it, loss=1.6583, batch_acc=0.5312, running_acc=0.5262, grad=8.6373]Training epoch 4:  27%|██▋       | 44/163 [00:53<02:28,  1.24s/it, loss=2.2706, batch_acc=0.3750, running_acc=0.5227, grad=10.6799]Training epoch 4:  28%|██▊       | 45/163 [00:54<02:13,  1.13s/it, loss=2.2706, batch_acc=0.3750, running_acc=0.5227, grad=10.6799]Training epoch 4:  28%|██▊       | 45/163 [00:54<02:13,  1.13s/it, loss=1.9255, batch_acc=0.4688, running_acc=0.5215, grad=9.8470] Training epoch 4:  28%|██▊       | 46/163 [00:54<02:03,  1.06s/it, loss=1.9255, batch_acc=0.4688, running_acc=0.5215, grad=9.8470]Training epoch 4:  28%|██▊       | 46/163 [00:54<02:03,  1.06s/it, loss=1.2714, batch_acc=0.6562, running_acc=0.5245, grad=7.0169]Training epoch 4:  29%|██▉       | 47/163 [00:55<01:56,  1.00s/it, loss=1.2714, batch_acc=0.6562, running_acc=0.5245, grad=7.0169]Training epoch 4:  29%|██▉       | 47/163 [00:55<01:56,  1.00s/it, loss=1.6919, batch_acc=0.5938, running_acc=0.5259, grad=8.7319]Training epoch 4:  29%|██▉       | 48/163 [00:57<02:25,  1.26s/it, loss=1.6919, batch_acc=0.5938, running_acc=0.5259, grad=8.7319]Training epoch 4:  29%|██▉       | 48/163 [00:57<02:25,  1.26s/it, loss=1.7102, batch_acc=0.4375, running_acc=0.5241, grad=7.7917]Training epoch 4:  30%|███       | 49/163 [00:58<02:11,  1.15s/it, loss=1.7102, batch_acc=0.4375, running_acc=0.5241, grad=7.7917]Training epoch 4:  30%|███       | 49/163 [00:58<02:11,  1.15s/it, loss=1.4792, batch_acc=0.5938, running_acc=0.5255, grad=5.7127]Training epoch 4:  31%|███       | 50/163 [00:59<02:00,  1.07s/it, loss=1.4792, batch_acc=0.5938, running_acc=0.5255, grad=5.7127]Training epoch 4:  31%|███       | 50/163 [00:59<02:00,  1.07s/it, loss=1.1989, batch_acc=0.6250, running_acc=0.5275, grad=4.7670]Training epoch 4:  31%|███▏      | 51/163 [01:00<01:53,  1.01s/it, loss=1.1989, batch_acc=0.6250, running_acc=0.5275, grad=4.7670]Training epoch 4:  31%|███▏      | 51/163 [01:00<01:53,  1.01s/it, loss=1.8273, batch_acc=0.4375, running_acc=0.5257, grad=6.8814]Training epoch 4:  32%|███▏      | 52/163 [01:01<02:04,  1.13s/it, loss=1.8273, batch_acc=0.4375, running_acc=0.5257, grad=6.8814]Training epoch 4:  32%|███▏      | 52/163 [01:01<02:04,  1.13s/it, loss=1.4749, batch_acc=0.4688, running_acc=0.5246, grad=8.8686]Training epoch 4:  33%|███▎      | 53/163 [01:02<01:55,  1.05s/it, loss=1.4749, batch_acc=0.4688, running_acc=0.5246, grad=8.8686]Training epoch 4:  33%|███▎      | 53/163 [01:02<01:55,  1.05s/it, loss=1.7230, batch_acc=0.5000, running_acc=0.5242, grad=7.2243]Training epoch 4:  33%|███▎      | 54/163 [01:03<01:48,  1.00it/s, loss=1.7230, batch_acc=0.5000, running_acc=0.5242, grad=7.2243]Training epoch 4:  33%|███▎      | 54/163 [01:03<01:48,  1.00it/s, loss=1.6762, batch_acc=0.4688, running_acc=0.5231, grad=8.5155]Training epoch 4:  34%|███▎      | 55/163 [01:04<01:43,  1.04it/s, loss=1.6762, batch_acc=0.4688, running_acc=0.5231, grad=8.5155]Training epoch 4:  34%|███▎      | 55/163 [01:04<01:43,  1.04it/s, loss=1.5918, batch_acc=0.5312, running_acc=0.5233, grad=6.9518]Training epoch 4:  34%|███▍      | 56/163 [01:06<02:25,  1.36s/it, loss=1.5918, batch_acc=0.5312, running_acc=0.5233, grad=6.9518]Training epoch 4:  34%|███▍      | 56/163 [01:06<02:25,  1.36s/it, loss=1.0844, batch_acc=0.6875, running_acc=0.5262, grad=8.0724]Training epoch 4:  35%|███▍      | 57/163 [01:07<02:09,  1.22s/it, loss=1.0844, batch_acc=0.6875, running_acc=0.5262, grad=8.0724]Training epoch 4:  35%|███▍      | 57/163 [01:07<02:09,  1.22s/it, loss=1.2911, batch_acc=0.5938, running_acc=0.5274, grad=6.2590]Training epoch 4:  36%|███▌      | 58/163 [01:08<01:58,  1.13s/it, loss=1.2911, batch_acc=0.5938, running_acc=0.5274, grad=6.2590]Training epoch 4:  36%|███▌      | 58/163 [01:08<01:58,  1.13s/it, loss=1.5054, batch_acc=0.5000, running_acc=0.5269, grad=7.6017]Training epoch 4:  36%|███▌      | 59/163 [01:09<01:49,  1.05s/it, loss=1.5054, batch_acc=0.5000, running_acc=0.5269, grad=7.6017]Training epoch 4:  36%|███▌      | 59/163 [01:09<01:49,  1.05s/it, loss=1.9196, batch_acc=0.3750, running_acc=0.5244, grad=7.1490]Training epoch 4:  37%|███▋      | 60/163 [01:11<02:19,  1.35s/it, loss=1.9196, batch_acc=0.3750, running_acc=0.5244, grad=7.1490]Training epoch 4:  37%|███▋      | 60/163 [01:11<02:19,  1.35s/it, loss=1.7915, batch_acc=0.4688, running_acc=0.5234, grad=12.9327]Training epoch 4:  37%|███▋      | 61/163 [01:12<02:03,  1.21s/it, loss=1.7915, batch_acc=0.4688, running_acc=0.5234, grad=12.9327]Training epoch 4:  37%|███▋      | 61/163 [01:12<02:03,  1.21s/it, loss=1.5961, batch_acc=0.5625, running_acc=0.5241, grad=12.0632]Training epoch 4:  38%|███▊      | 62/163 [01:13<01:52,  1.11s/it, loss=1.5961, batch_acc=0.5625, running_acc=0.5241, grad=12.0632]Training epoch 4:  38%|███▊      | 62/163 [01:13<01:52,  1.11s/it, loss=1.7147, batch_acc=0.4688, running_acc=0.5232, grad=7.8377] Training epoch 4:  39%|███▊      | 63/163 [01:14<01:44,  1.04s/it, loss=1.7147, batch_acc=0.4688, running_acc=0.5232, grad=7.8377]Training epoch 4:  39%|███▊      | 63/163 [01:14<01:44,  1.04s/it, loss=2.0110, batch_acc=0.4688, running_acc=0.5223, grad=11.7907]Training epoch 4:  39%|███▉      | 64/163 [01:15<01:46,  1.08s/it, loss=2.0110, batch_acc=0.4688, running_acc=0.5223, grad=11.7907]Training epoch 4:  39%|███▉      | 64/163 [01:15<01:46,  1.08s/it, loss=1.4953, batch_acc=0.6250, running_acc=0.5239, grad=9.4758] Training epoch 4:  40%|███▉      | 65/163 [01:16<01:39,  1.02s/it, loss=1.4953, batch_acc=0.6250, running_acc=0.5239, grad=9.4758]Training epoch 4:  40%|███▉      | 65/163 [01:16<01:39,  1.02s/it, loss=1.8919, batch_acc=0.4062, running_acc=0.5221, grad=8.9056]Training epoch 4:  40%|████      | 66/163 [01:16<01:34,  1.03it/s, loss=1.8919, batch_acc=0.4062, running_acc=0.5221, grad=8.9056]Training epoch 4:  40%|████      | 66/163 [01:16<01:34,  1.03it/s, loss=1.6099, batch_acc=0.5312, running_acc=0.5223, grad=6.8450]Training epoch 4:  41%|████      | 67/163 [01:18<01:37,  1.02s/it, loss=1.6099, batch_acc=0.5312, running_acc=0.5223, grad=6.8450]Training epoch 4:  41%|████      | 67/163 [01:18<01:37,  1.02s/it, loss=1.2729, batch_acc=0.5625, running_acc=0.5229, grad=10.1904]Training epoch 4:  42%|████▏     | 68/163 [01:18<01:33,  1.02it/s, loss=1.2729, batch_acc=0.5625, running_acc=0.5229, grad=10.1904]Training epoch 4:  42%|████▏     | 68/163 [01:18<01:33,  1.02it/s, loss=2.0448, batch_acc=0.2812, running_acc=0.5193, grad=10.7624]Training epoch 4:  42%|████▏     | 69/163 [01:19<01:29,  1.05it/s, loss=2.0448, batch_acc=0.2812, running_acc=0.5193, grad=10.7624]Training epoch 4:  42%|████▏     | 69/163 [01:19<01:29,  1.05it/s, loss=1.6701, batch_acc=0.5000, running_acc=0.5190, grad=6.5495] Training epoch 4:  43%|████▎     | 70/163 [01:20<01:30,  1.03it/s, loss=1.6701, batch_acc=0.5000, running_acc=0.5190, grad=6.5495]Training epoch 4:  43%|████▎     | 70/163 [01:20<01:30,  1.03it/s, loss=1.3754, batch_acc=0.6250, running_acc=0.5205, grad=9.7740]Training epoch 4:  44%|████▎     | 71/163 [01:22<01:47,  1.17s/it, loss=1.3754, batch_acc=0.6250, running_acc=0.5205, grad=9.7740]Training epoch 4:  44%|████▎     | 71/163 [01:22<01:47,  1.17s/it, loss=1.3545, batch_acc=0.6562, running_acc=0.5224, grad=6.9300]Training epoch 4:  44%|████▍     | 72/163 [01:23<01:38,  1.09s/it, loss=1.3545, batch_acc=0.6562, running_acc=0.5224, grad=6.9300]Training epoch 4:  44%|████▍     | 72/163 [01:23<01:38,  1.09s/it, loss=1.3446, batch_acc=0.7188, running_acc=0.5252, grad=6.4106]Training epoch 4:  45%|████▍     | 73/163 [01:24<01:32,  1.02s/it, loss=1.3446, batch_acc=0.7188, running_acc=0.5252, grad=6.4106]Training epoch 4:  45%|████▍     | 73/163 [01:24<01:32,  1.02s/it, loss=1.0860, batch_acc=0.7188, running_acc=0.5278, grad=5.4519]Training epoch 4:  45%|████▌     | 74/163 [01:25<01:28,  1.01it/s, loss=1.0860, batch_acc=0.7188, running_acc=0.5278, grad=5.4519]Training epoch 4:  45%|████▌     | 74/163 [01:25<01:28,  1.01it/s, loss=1.1826, batch_acc=0.7188, running_acc=0.5304, grad=9.3949]Training epoch 4:  46%|████▌     | 75/163 [01:26<01:44,  1.19s/it, loss=1.1826, batch_acc=0.7188, running_acc=0.5304, grad=9.3949]Training epoch 4:  46%|████▌     | 75/163 [01:26<01:44,  1.19s/it, loss=1.4203, batch_acc=0.5312, running_acc=0.5304, grad=8.3488]Training epoch 4:  47%|████▋     | 76/163 [01:27<01:35,  1.10s/it, loss=1.4203, batch_acc=0.5312, running_acc=0.5304, grad=8.3488]Training epoch 4:  47%|████▋     | 76/163 [01:27<01:35,  1.10s/it, loss=1.6440, batch_acc=0.5625, running_acc=0.5308, grad=7.3840]Training epoch 4:  47%|████▋     | 77/163 [01:28<01:28,  1.03s/it, loss=1.6440, batch_acc=0.5625, running_acc=0.5308, grad=7.3840]Training epoch 4:  47%|████▋     | 77/163 [01:28<01:28,  1.03s/it, loss=1.3856, batch_acc=0.6250, running_acc=0.5321, grad=6.2994]Training epoch 4:  48%|████▊     | 78/163 [01:29<01:32,  1.09s/it, loss=1.3856, batch_acc=0.6250, running_acc=0.5321, grad=6.2994]Training epoch 4:  48%|████▊     | 78/163 [01:29<01:32,  1.09s/it, loss=1.5176, batch_acc=0.4375, running_acc=0.5308, grad=6.8124]Training epoch 4:  48%|████▊     | 79/163 [01:31<01:43,  1.24s/it, loss=1.5176, batch_acc=0.4375, running_acc=0.5308, grad=6.8124]Training epoch 4:  48%|████▊     | 79/163 [01:31<01:43,  1.24s/it, loss=1.6591, batch_acc=0.4375, running_acc=0.5297, grad=9.1646]Training epoch 4:  49%|████▉     | 80/163 [01:32<01:34,  1.13s/it, loss=1.6591, batch_acc=0.4375, running_acc=0.5297, grad=9.1646]Training epoch 4:  49%|████▉     | 80/163 [01:32<01:34,  1.13s/it, loss=1.4726, batch_acc=0.5938, running_acc=0.5305, grad=8.2006]Training epoch 4:  50%|████▉     | 81/163 [01:33<01:26,  1.06s/it, loss=1.4726, batch_acc=0.5938, running_acc=0.5305, grad=8.2006]Training epoch 4:  50%|████▉     | 81/163 [01:33<01:26,  1.06s/it, loss=1.7373, batch_acc=0.4062, running_acc=0.5289, grad=6.3351]Training epoch 4:  50%|█████     | 82/163 [01:34<01:22,  1.02s/it, loss=1.7373, batch_acc=0.4062, running_acc=0.5289, grad=6.3351]Training epoch 4:  50%|█████     | 82/163 [01:34<01:22,  1.02s/it, loss=1.3695, batch_acc=0.6250, running_acc=0.5301, grad=6.2111]Training epoch 4:  51%|█████     | 83/163 [01:36<01:43,  1.29s/it, loss=1.3695, batch_acc=0.6250, running_acc=0.5301, grad=6.2111]Training epoch 4:  51%|█████     | 83/163 [01:36<01:43,  1.29s/it, loss=1.3247, batch_acc=0.6875, running_acc=0.5320, grad=9.6318]Training epoch 4:  52%|█████▏    | 84/163 [01:36<01:32,  1.17s/it, loss=1.3247, batch_acc=0.6875, running_acc=0.5320, grad=9.6318]Training epoch 4:  52%|█████▏    | 84/163 [01:36<01:32,  1.17s/it, loss=1.0757, batch_acc=0.6875, running_acc=0.5339, grad=5.4540]Training epoch 4:  52%|█████▏    | 85/163 [01:37<01:24,  1.08s/it, loss=1.0757, batch_acc=0.6875, running_acc=0.5339, grad=5.4540]Training epoch 4:  52%|█████▏    | 85/163 [01:37<01:24,  1.08s/it, loss=1.5003, batch_acc=0.5625, running_acc=0.5342, grad=8.1022]Training epoch 4:  53%|█████▎    | 86/163 [01:38<01:18,  1.02s/it, loss=1.5003, batch_acc=0.5625, running_acc=0.5342, grad=8.1022]Training epoch 4:  53%|█████▎    | 86/163 [01:38<01:18,  1.02s/it, loss=1.5766, batch_acc=0.5938, running_acc=0.5349, grad=5.8033]Training epoch 4:  53%|█████▎    | 87/163 [01:40<01:38,  1.29s/it, loss=1.5766, batch_acc=0.5938, running_acc=0.5349, grad=5.8033]Training epoch 4:  53%|█████▎    | 87/163 [01:40<01:38,  1.29s/it, loss=1.3976, batch_acc=0.6250, running_acc=0.5359, grad=7.5940]Training epoch 4:  54%|█████▍    | 88/163 [01:41<01:27,  1.17s/it, loss=1.3976, batch_acc=0.6250, running_acc=0.5359, grad=7.5940]Training epoch 4:  54%|█████▍    | 88/163 [01:41<01:27,  1.17s/it, loss=1.6039, batch_acc=0.5625, running_acc=0.5362, grad=8.1734]Training epoch 4:  55%|█████▍    | 89/163 [01:42<01:19,  1.08s/it, loss=1.6039, batch_acc=0.5625, running_acc=0.5362, grad=8.1734]Training epoch 4:  55%|█████▍    | 89/163 [01:42<01:19,  1.08s/it, loss=1.4476, batch_acc=0.5312, running_acc=0.5362, grad=6.7667]Training epoch 4:  55%|█████▌    | 90/163 [01:43<01:14,  1.02s/it, loss=1.4476, batch_acc=0.5312, running_acc=0.5362, grad=6.7667]Training epoch 4:  55%|█████▌    | 90/163 [01:43<01:14,  1.02s/it, loss=1.3943, batch_acc=0.6250, running_acc=0.5372, grad=5.5138]Training epoch 4:  56%|█████▌    | 91/163 [01:44<01:23,  1.16s/it, loss=1.3943, batch_acc=0.6250, running_acc=0.5372, grad=5.5138]Training epoch 4:  56%|█████▌    | 91/163 [01:44<01:23,  1.16s/it, loss=1.5105, batch_acc=0.5938, running_acc=0.5378, grad=7.6350]Training epoch 4:  56%|█████▋    | 92/163 [01:45<01:16,  1.07s/it, loss=1.5105, batch_acc=0.5938, running_acc=0.5378, grad=7.6350]Training epoch 4:  56%|█████▋    | 92/163 [01:45<01:16,  1.07s/it, loss=1.3602, batch_acc=0.5938, running_acc=0.5384, grad=6.2247]Training epoch 4:  57%|█████▋    | 93/163 [01:46<01:10,  1.01s/it, loss=1.3602, batch_acc=0.5938, running_acc=0.5384, grad=6.2247]Training epoch 4:  57%|█████▋    | 93/163 [01:46<01:10,  1.01s/it, loss=1.7991, batch_acc=0.4688, running_acc=0.5376, grad=7.7704]Training epoch 4:  58%|█████▊    | 94/163 [01:47<01:07,  1.03it/s, loss=1.7991, batch_acc=0.4688, running_acc=0.5376, grad=7.7704]Training epoch 4:  58%|█████▊    | 94/163 [01:47<01:07,  1.03it/s, loss=1.4649, batch_acc=0.5938, running_acc=0.5382, grad=7.6850]Training epoch 4:  58%|█████▊    | 95/163 [01:49<01:22,  1.21s/it, loss=1.4649, batch_acc=0.5938, running_acc=0.5382, grad=7.6850]Training epoch 4:  58%|█████▊    | 95/163 [01:49<01:22,  1.21s/it, loss=1.2870, batch_acc=0.5625, running_acc=0.5385, grad=6.4127]Training epoch 4:  59%|█████▉    | 96/163 [01:49<01:14,  1.11s/it, loss=1.2870, batch_acc=0.5625, running_acc=0.5385, grad=6.4127]Training epoch 4:  59%|█████▉    | 96/163 [01:49<01:14,  1.11s/it, loss=1.3423, batch_acc=0.6250, running_acc=0.5394, grad=7.6608]Training epoch 4:  60%|█████▉    | 97/163 [01:50<01:08,  1.04s/it, loss=1.3423, batch_acc=0.6250, running_acc=0.5394, grad=7.6608]Training epoch 4:  60%|█████▉    | 97/163 [01:50<01:08,  1.04s/it, loss=1.8507, batch_acc=0.5000, running_acc=0.5390, grad=7.2498]Training epoch 4:  60%|██████    | 98/163 [01:51<01:04,  1.01it/s, loss=1.8507, batch_acc=0.5000, running_acc=0.5390, grad=7.2498]Training epoch 4:  60%|██████    | 98/163 [01:51<01:04,  1.01it/s, loss=1.1165, batch_acc=0.5312, running_acc=0.5389, grad=6.7348]Training epoch 4:  61%|██████    | 99/163 [01:53<01:23,  1.31s/it, loss=1.1165, batch_acc=0.5312, running_acc=0.5389, grad=6.7348]Training epoch 4:  61%|██████    | 99/163 [01:53<01:23,  1.31s/it, loss=1.4308, batch_acc=0.6562, running_acc=0.5401, grad=6.2199]Training epoch 4:  61%|██████▏   | 100/163 [01:54<01:14,  1.18s/it, loss=1.4308, batch_acc=0.6562, running_acc=0.5401, grad=6.2199]Training epoch 4:  61%|██████▏   | 100/163 [01:54<01:14,  1.18s/it, loss=1.3669, batch_acc=0.5938, running_acc=0.5406, grad=7.0494]Training epoch 4:  62%|██████▏   | 101/163 [01:55<01:07,  1.09s/it, loss=1.3669, batch_acc=0.5938, running_acc=0.5406, grad=7.0494]Training epoch 4:  62%|██████▏   | 101/163 [01:55<01:07,  1.09s/it, loss=1.7069, batch_acc=0.5312, running_acc=0.5405, grad=6.4362]Training epoch 4:  63%|██████▎   | 102/163 [01:56<01:02,  1.03s/it, loss=1.7069, batch_acc=0.5312, running_acc=0.5405, grad=6.4362]Training epoch 4:  63%|██████▎   | 102/163 [01:56<01:02,  1.03s/it, loss=1.5276, batch_acc=0.5000, running_acc=0.5401, grad=6.7007]Training epoch 4:  63%|██████▎   | 103/163 [01:58<01:14,  1.24s/it, loss=1.5276, batch_acc=0.5000, running_acc=0.5401, grad=6.7007]Training epoch 4:  63%|██████▎   | 103/163 [01:58<01:14,  1.24s/it, loss=1.0977, batch_acc=0.6562, running_acc=0.5413, grad=4.9548]Training epoch 4:  64%|██████▍   | 104/163 [01:59<01:06,  1.13s/it, loss=1.0977, batch_acc=0.6562, running_acc=0.5413, grad=4.9548]Training epoch 4:  64%|██████▍   | 104/163 [01:59<01:06,  1.13s/it, loss=1.2826, batch_acc=0.6875, running_acc=0.5427, grad=5.5222]Training epoch 4:  64%|██████▍   | 105/163 [01:59<01:01,  1.05s/it, loss=1.2826, batch_acc=0.6875, running_acc=0.5427, grad=5.5222]Training epoch 4:  64%|██████▍   | 105/163 [01:59<01:01,  1.05s/it, loss=0.9930, batch_acc=0.7188, running_acc=0.5443, grad=5.0130]Training epoch 4:  65%|██████▌   | 106/163 [02:00<00:57,  1.00s/it, loss=0.9930, batch_acc=0.7188, running_acc=0.5443, grad=5.0130]Training epoch 4:  65%|██████▌   | 106/163 [02:00<00:57,  1.00s/it, loss=1.6080, batch_acc=0.5312, running_acc=0.5442, grad=7.3029]Training epoch 4:  66%|██████▌   | 107/163 [02:02<01:04,  1.16s/it, loss=1.6080, batch_acc=0.5312, running_acc=0.5442, grad=7.3029]Training epoch 4:  66%|██████▌   | 107/163 [02:02<01:04,  1.16s/it, loss=1.3113, batch_acc=0.6562, running_acc=0.5453, grad=7.2059]Training epoch 4:  66%|██████▋   | 108/163 [02:03<00:59,  1.08s/it, loss=1.3113, batch_acc=0.6562, running_acc=0.5453, grad=7.2059]Training epoch 4:  66%|██████▋   | 108/163 [02:03<00:59,  1.08s/it, loss=1.4495, batch_acc=0.5938, running_acc=0.5457, grad=7.1882]Training epoch 4:  67%|██████▋   | 109/163 [02:04<00:54,  1.02s/it, loss=1.4495, batch_acc=0.5938, running_acc=0.5457, grad=7.1882]Training epoch 4:  67%|██████▋   | 109/163 [02:04<00:54,  1.02s/it, loss=1.7743, batch_acc=0.4688, running_acc=0.5450, grad=8.3890]Training epoch 4:  67%|██████▋   | 110/163 [02:04<00:51,  1.03it/s, loss=1.7743, batch_acc=0.4688, running_acc=0.5450, grad=8.3890]Training epoch 4:  67%|██████▋   | 110/163 [02:04<00:51,  1.03it/s, loss=1.1537, batch_acc=0.6562, running_acc=0.5460, grad=6.9523]Training epoch 4:  68%|██████▊   | 111/163 [02:07<01:08,  1.33s/it, loss=1.1537, batch_acc=0.6562, running_acc=0.5460, grad=6.9523]Training epoch 4:  68%|██████▊   | 111/163 [02:07<01:08,  1.33s/it, loss=1.2460, batch_acc=0.5938, running_acc=0.5465, grad=7.2475]Training epoch 4:  69%|██████▊   | 112/163 [02:07<01:00,  1.19s/it, loss=1.2460, batch_acc=0.5938, running_acc=0.5465, grad=7.2475]Training epoch 4:  69%|██████▊   | 112/163 [02:07<01:00,  1.19s/it, loss=1.5377, batch_acc=0.5312, running_acc=0.5463, grad=8.7275]Training epoch 4:  69%|██████▉   | 113/163 [02:08<00:54,  1.10s/it, loss=1.5377, batch_acc=0.5312, running_acc=0.5463, grad=8.7275]Training epoch 4:  69%|██████▉   | 113/163 [02:08<00:54,  1.10s/it, loss=1.2122, batch_acc=0.6250, running_acc=0.5470, grad=7.3036]Training epoch 4:  70%|██████▉   | 114/163 [02:09<00:50,  1.03s/it, loss=1.2122, batch_acc=0.6250, running_acc=0.5470, grad=7.3036]Training epoch 4:  70%|██████▉   | 114/163 [02:09<00:50,  1.03s/it, loss=1.6654, batch_acc=0.4688, running_acc=0.5463, grad=7.2325]Training epoch 4:  71%|███████   | 115/163 [02:12<01:09,  1.45s/it, loss=1.6654, batch_acc=0.4688, running_acc=0.5463, grad=7.2325]Training epoch 4:  71%|███████   | 115/163 [02:12<01:09,  1.45s/it, loss=1.3292, batch_acc=0.6250, running_acc=0.5470, grad=8.4854]Training epoch 4:  71%|███████   | 116/163 [02:13<01:00,  1.28s/it, loss=1.3292, batch_acc=0.6250, running_acc=0.5470, grad=8.4854]Training epoch 4:  71%|███████   | 116/163 [02:13<01:00,  1.28s/it, loss=1.4934, batch_acc=0.5625, running_acc=0.5471, grad=7.6166]Training epoch 4:  72%|███████▏  | 117/163 [02:13<00:53,  1.16s/it, loss=1.4934, batch_acc=0.5625, running_acc=0.5471, grad=7.6166]Training epoch 4:  72%|███████▏  | 117/163 [02:13<00:53,  1.16s/it, loss=1.7354, batch_acc=0.4688, running_acc=0.5465, grad=8.9108]Training epoch 4:  72%|███████▏  | 118/163 [02:14<00:48,  1.07s/it, loss=1.7354, batch_acc=0.4688, running_acc=0.5465, grad=8.9108]Training epoch 4:  72%|███████▏  | 118/163 [02:14<00:48,  1.07s/it, loss=1.3502, batch_acc=0.5000, running_acc=0.5461, grad=6.8115]Training epoch 4:  73%|███████▎  | 119/163 [02:16<00:54,  1.24s/it, loss=1.3502, batch_acc=0.5000, running_acc=0.5461, grad=6.8115]Training epoch 4:  73%|███████▎  | 119/163 [02:16<00:54,  1.24s/it, loss=1.3377, batch_acc=0.5625, running_acc=0.5462, grad=5.6805]Training epoch 4:  74%|███████▎  | 120/163 [02:17<00:48,  1.13s/it, loss=1.3377, batch_acc=0.5625, running_acc=0.5462, grad=5.6805]Training epoch 4:  74%|███████▎  | 120/163 [02:17<00:48,  1.13s/it, loss=1.4374, batch_acc=0.6875, running_acc=0.5474, grad=5.0611]Training epoch 4:  74%|███████▍  | 121/163 [02:18<00:44,  1.05s/it, loss=1.4374, batch_acc=0.6875, running_acc=0.5474, grad=5.0611]Training epoch 4:  74%|███████▍  | 121/163 [02:18<00:44,  1.05s/it, loss=1.6251, batch_acc=0.5312, running_acc=0.5473, grad=8.2469]Training epoch 4:  75%|███████▍  | 122/163 [02:19<00:41,  1.00s/it, loss=1.6251, batch_acc=0.5312, running_acc=0.5473, grad=8.2469]Training epoch 4:  75%|███████▍  | 122/163 [02:19<00:41,  1.00s/it, loss=1.6309, batch_acc=0.5000, running_acc=0.5469, grad=9.0368]Training epoch 4:  75%|███████▌  | 123/163 [02:21<00:53,  1.35s/it, loss=1.6309, batch_acc=0.5000, running_acc=0.5469, grad=9.0368]Training epoch 4:  75%|███████▌  | 123/163 [02:21<00:53,  1.35s/it, loss=1.6341, batch_acc=0.4375, running_acc=0.5460, grad=8.0535]Training epoch 4:  76%|███████▌  | 124/163 [02:22<00:47,  1.21s/it, loss=1.6341, batch_acc=0.4375, running_acc=0.5460, grad=8.0535]Training epoch 4:  76%|███████▌  | 124/163 [02:22<00:47,  1.21s/it, loss=1.4515, batch_acc=0.4688, running_acc=0.5454, grad=6.8733]Training epoch 4:  77%|███████▋  | 125/163 [02:22<00:42,  1.11s/it, loss=1.4515, batch_acc=0.4688, running_acc=0.5454, grad=6.8733]Training epoch 4:  77%|███████▋  | 125/163 [02:22<00:42,  1.11s/it, loss=1.4499, batch_acc=0.5000, running_acc=0.5450, grad=7.0596]Training epoch 4:  77%|███████▋  | 126/163 [02:23<00:38,  1.04s/it, loss=1.4499, batch_acc=0.5000, running_acc=0.5450, grad=7.0596]Training epoch 4:  77%|███████▋  | 126/163 [02:23<00:38,  1.04s/it, loss=1.6282, batch_acc=0.5938, running_acc=0.5454, grad=10.9549]Training epoch 4:  78%|███████▊  | 127/163 [02:25<00:41,  1.16s/it, loss=1.6282, batch_acc=0.5938, running_acc=0.5454, grad=10.9549]Training epoch 4:  78%|███████▊  | 127/163 [02:25<00:41,  1.16s/it, loss=1.2543, batch_acc=0.6250, running_acc=0.5460, grad=6.7064] Training epoch 4:  79%|███████▊  | 128/163 [02:26<00:37,  1.07s/it, loss=1.2543, batch_acc=0.6250, running_acc=0.5460, grad=6.7064]Training epoch 4:  79%|███████▊  | 128/163 [02:26<00:37,  1.07s/it, loss=1.2222, batch_acc=0.5625, running_acc=0.5461, grad=6.8396]Training epoch 4:  79%|███████▉  | 129/163 [02:27<00:34,  1.02s/it, loss=1.2222, batch_acc=0.5625, running_acc=0.5461, grad=6.8396]Training epoch 4:  79%|███████▉  | 129/163 [02:27<00:34,  1.02s/it, loss=1.3196, batch_acc=0.5312, running_acc=0.5460, grad=8.3010]Training epoch 4:  80%|███████▉  | 130/163 [02:27<00:32,  1.03it/s, loss=1.3196, batch_acc=0.5312, running_acc=0.5460, grad=8.3010]Training epoch 4:  80%|███████▉  | 130/163 [02:27<00:32,  1.03it/s, loss=1.4845, batch_acc=0.5938, running_acc=0.5464, grad=7.4313]Training epoch 4:  80%|████████  | 131/163 [02:29<00:35,  1.12s/it, loss=1.4845, batch_acc=0.5938, running_acc=0.5464, grad=7.4313]Training epoch 4:  80%|████████  | 131/163 [02:29<00:35,  1.12s/it, loss=1.7063, batch_acc=0.5625, running_acc=0.5465, grad=8.4714]Training epoch 4:  81%|████████  | 132/163 [02:30<00:32,  1.05s/it, loss=1.7063, batch_acc=0.5625, running_acc=0.5465, grad=8.4714]Training epoch 4:  81%|████████  | 132/163 [02:30<00:32,  1.05s/it, loss=1.5261, batch_acc=0.4688, running_acc=0.5459, grad=7.6642]Training epoch 4:  82%|████████▏ | 133/163 [02:31<00:29,  1.00it/s, loss=1.5261, batch_acc=0.4688, running_acc=0.5459, grad=7.6642]Training epoch 4:  82%|████████▏ | 133/163 [02:31<00:29,  1.00it/s, loss=1.5686, batch_acc=0.5625, running_acc=0.5461, grad=8.4911]Training epoch 4:  82%|████████▏ | 134/163 [02:31<00:27,  1.04it/s, loss=1.5686, batch_acc=0.5625, running_acc=0.5461, grad=8.4911]Training epoch 4:  82%|████████▏ | 134/163 [02:31<00:27,  1.04it/s, loss=1.2988, batch_acc=0.5625, running_acc=0.5462, grad=5.7501]Training epoch 4:  83%|████████▎ | 135/163 [02:33<00:29,  1.06s/it, loss=1.2988, batch_acc=0.5625, running_acc=0.5462, grad=5.7501]Training epoch 4:  83%|████████▎ | 135/163 [02:33<00:29,  1.06s/it, loss=1.7341, batch_acc=0.4688, running_acc=0.5456, grad=10.9956]Training epoch 4:  83%|████████▎ | 136/163 [02:34<00:27,  1.00s/it, loss=1.7341, batch_acc=0.4688, running_acc=0.5456, grad=10.9956]Training epoch 4:  83%|████████▎ | 136/163 [02:34<00:27,  1.00s/it, loss=1.4446, batch_acc=0.6562, running_acc=0.5464, grad=6.7725] Training epoch 4:  84%|████████▍ | 137/163 [02:35<00:25,  1.03it/s, loss=1.4446, batch_acc=0.6562, running_acc=0.5464, grad=6.7725]Training epoch 4:  84%|████████▍ | 137/163 [02:35<00:25,  1.03it/s, loss=1.5119, batch_acc=0.5625, running_acc=0.5465, grad=8.5230]Training epoch 4:  85%|████████▍ | 138/163 [02:35<00:23,  1.06it/s, loss=1.5119, batch_acc=0.5625, running_acc=0.5465, grad=8.5230]Training epoch 4:  85%|████████▍ | 138/163 [02:35<00:23,  1.06it/s, loss=1.0597, batch_acc=0.6562, running_acc=0.5473, grad=6.9592]Training epoch 4:  85%|████████▌ | 139/163 [02:37<00:24,  1.02s/it, loss=1.0597, batch_acc=0.6562, running_acc=0.5473, grad=6.9592]Training epoch 4:  85%|████████▌ | 139/163 [02:37<00:24,  1.02s/it, loss=1.5203, batch_acc=0.5625, running_acc=0.5474, grad=7.3275]Training epoch 4:  86%|████████▌ | 140/163 [02:37<00:22,  1.02it/s, loss=1.5203, batch_acc=0.5625, running_acc=0.5474, grad=7.3275]Training epoch 4:  86%|████████▌ | 140/163 [02:37<00:22,  1.02it/s, loss=1.8922, batch_acc=0.3438, running_acc=0.5460, grad=9.0073]Training epoch 4:  87%|████████▋ | 141/163 [02:38<00:20,  1.06it/s, loss=1.8922, batch_acc=0.3438, running_acc=0.5460, grad=9.0073]Training epoch 4:  87%|████████▋ | 141/163 [02:38<00:20,  1.06it/s, loss=1.6287, batch_acc=0.5938, running_acc=0.5463, grad=6.5197]Training epoch 4:  87%|████████▋ | 142/163 [02:39<00:19,  1.08it/s, loss=1.6287, batch_acc=0.5938, running_acc=0.5463, grad=6.5197]Training epoch 4:  87%|████████▋ | 142/163 [02:39<00:19,  1.08it/s, loss=1.3630, batch_acc=0.6562, running_acc=0.5471, grad=6.9618]Training epoch 4:  88%|████████▊ | 143/163 [02:41<00:23,  1.17s/it, loss=1.3630, batch_acc=0.6562, running_acc=0.5471, grad=6.9618]Training epoch 4:  88%|████████▊ | 143/163 [02:41<00:23,  1.17s/it, loss=1.6335, batch_acc=0.4375, running_acc=0.5463, grad=7.7870]Training epoch 4:  88%|████████▊ | 144/163 [02:42<00:20,  1.08s/it, loss=1.6335, batch_acc=0.4375, running_acc=0.5463, grad=7.7870]Training epoch 4:  88%|████████▊ | 144/163 [02:42<00:20,  1.08s/it, loss=1.4053, batch_acc=0.5625, running_acc=0.5464, grad=9.2596]Training epoch 4:  89%|████████▉ | 145/163 [02:43<00:18,  1.02s/it, loss=1.4053, batch_acc=0.5625, running_acc=0.5464, grad=9.2596]Training epoch 4:  89%|████████▉ | 145/163 [02:43<00:18,  1.02s/it, loss=1.4995, batch_acc=0.5000, running_acc=0.5461, grad=9.3059]Training epoch 4:  90%|████████▉ | 146/163 [02:44<00:16,  1.02it/s, loss=1.4995, batch_acc=0.5000, running_acc=0.5461, grad=9.3059]Training epoch 4:  90%|████████▉ | 146/163 [02:44<00:16,  1.02it/s, loss=1.4596, batch_acc=0.6250, running_acc=0.5467, grad=6.5536]Training epoch 4:  90%|█████████ | 147/163 [02:45<00:17,  1.09s/it, loss=1.4596, batch_acc=0.6250, running_acc=0.5467, grad=6.5536]Training epoch 4:  90%|█████████ | 147/163 [02:45<00:17,  1.09s/it, loss=1.3836, batch_acc=0.5625, running_acc=0.5468, grad=7.0531]Training epoch 4:  91%|█████████ | 148/163 [02:46<00:15,  1.03s/it, loss=1.3836, batch_acc=0.5625, running_acc=0.5468, grad=7.0531]Training epoch 4:  91%|█████████ | 148/163 [02:46<00:15,  1.03s/it, loss=1.6383, batch_acc=0.5312, running_acc=0.5467, grad=6.8048]Training epoch 4:  91%|█████████▏| 149/163 [02:47<00:13,  1.02it/s, loss=1.6383, batch_acc=0.5312, running_acc=0.5467, grad=6.8048]Training epoch 4:  91%|█████████▏| 149/163 [02:47<00:13,  1.02it/s, loss=1.3473, batch_acc=0.6250, running_acc=0.5472, grad=7.8471]Training epoch 4:  92%|█████████▏| 150/163 [02:48<00:12,  1.05it/s, loss=1.3473, batch_acc=0.6250, running_acc=0.5472, grad=7.8471]Training epoch 4:  92%|█████████▏| 150/163 [02:48<00:12,  1.05it/s, loss=1.1311, batch_acc=0.6250, running_acc=0.5477, grad=8.7955]Training epoch 4:  93%|█████████▎| 151/163 [02:49<00:12,  1.08s/it, loss=1.1311, batch_acc=0.6250, running_acc=0.5477, grad=8.7955]Training epoch 4:  93%|█████████▎| 151/163 [02:49<00:12,  1.08s/it, loss=1.1295, batch_acc=0.6250, running_acc=0.5482, grad=6.7982]Training epoch 4:  93%|█████████▎| 152/163 [02:50<00:11,  1.03s/it, loss=1.1295, batch_acc=0.6250, running_acc=0.5482, grad=6.7982]Training epoch 4:  93%|█████████▎| 152/163 [02:50<00:11,  1.03s/it, loss=1.7018, batch_acc=0.5312, running_acc=0.5481, grad=7.6279]Training epoch 4:  94%|█████████▍| 153/163 [02:51<00:09,  1.02it/s, loss=1.7018, batch_acc=0.5312, running_acc=0.5481, grad=7.6279]Training epoch 4:  94%|█████████▍| 153/163 [02:51<00:09,  1.02it/s, loss=1.3896, batch_acc=0.5625, running_acc=0.5482, grad=11.7694]Training epoch 4:  94%|█████████▍| 154/163 [02:52<00:08,  1.05it/s, loss=1.3896, batch_acc=0.5625, running_acc=0.5482, grad=11.7694]Training epoch 4:  94%|█████████▍| 154/163 [02:52<00:08,  1.05it/s, loss=1.4982, batch_acc=0.6250, running_acc=0.5487, grad=9.3660] Training epoch 4:  95%|█████████▌| 155/163 [02:53<00:08,  1.08s/it, loss=1.4982, batch_acc=0.6250, running_acc=0.5487, grad=9.3660]Training epoch 4:  95%|█████████▌| 155/163 [02:53<00:08,  1.08s/it, loss=1.7572, batch_acc=0.4688, running_acc=0.5482, grad=8.5988]Training epoch 4:  96%|█████████▌| 156/163 [02:54<00:08,  1.16s/it, loss=1.7572, batch_acc=0.4688, running_acc=0.5482, grad=8.5988]Training epoch 4:  96%|█████████▌| 156/163 [02:54<00:08,  1.16s/it, loss=1.8924, batch_acc=0.4375, running_acc=0.5475, grad=9.1565]Training epoch 4:  96%|█████████▋| 157/163 [02:55<00:06,  1.08s/it, loss=1.8924, batch_acc=0.4375, running_acc=0.5475, grad=9.1565]Training epoch 4:  96%|█████████▋| 157/163 [02:55<00:06,  1.08s/it, loss=1.5713, batch_acc=0.5000, running_acc=0.5472, grad=7.1661]Training epoch 4:  97%|█████████▋| 158/163 [02:56<00:05,  1.04s/it, loss=1.5713, batch_acc=0.5000, running_acc=0.5472, grad=7.1661]Training epoch 4:  97%|█████████▋| 158/163 [02:56<00:05,  1.04s/it, loss=1.2921, batch_acc=0.6875, running_acc=0.5481, grad=9.3054]Training epoch 4:  98%|█████████▊| 159/163 [02:58<00:04,  1.12s/it, loss=1.2921, batch_acc=0.6875, running_acc=0.5481, grad=9.3054]Training epoch 4:  98%|█████████▊| 159/163 [02:58<00:04,  1.12s/it, loss=1.7464, batch_acc=0.4375, running_acc=0.5474, grad=7.7301]Training epoch 4:  98%|█████████▊| 160/163 [02:58<00:03,  1.07s/it, loss=1.7464, batch_acc=0.4375, running_acc=0.5474, grad=7.7301]Training epoch 4:  98%|█████████▊| 160/163 [02:58<00:03,  1.07s/it, loss=1.1381, batch_acc=0.5938, running_acc=0.5477, grad=6.8178]Training epoch 4:  99%|█████████▉| 161/163 [02:59<00:02,  1.01s/it, loss=1.1381, batch_acc=0.5938, running_acc=0.5477, grad=6.8178]Training epoch 4:  99%|█████████▉| 161/163 [02:59<00:02,  1.01s/it, loss=1.2763, batch_acc=0.6250, running_acc=0.5481, grad=5.7297]Training epoch 4:  99%|█████████▉| 162/163 [03:00<00:00,  1.03it/s, loss=1.2763, batch_acc=0.6250, running_acc=0.5481, grad=5.7297]Training epoch 4:  99%|█████████▉| 162/163 [03:00<00:00,  1.03it/s, loss=1.4594, batch_acc=0.5938, running_acc=0.5484, grad=7.3082]Training epoch 4: 100%|██████████| 163/163 [03:01<00:00,  1.15it/s, loss=1.4594, batch_acc=0.5938, running_acc=0.5484, grad=7.3082]Training epoch 4: 100%|██████████| 163/163 [03:01<00:00,  1.15it/s, loss=1.6503, batch_acc=0.6190, running_acc=0.5487, grad=8.2738]Training epoch 4: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=1.6503, batch_acc=0.6190, running_acc=0.5487, grad=8.2738]
Evaluation epoch 4:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 4:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it]Evaluation epoch 4:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it, loss=0.9726, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 4:   7%|▋         | 2/28 [00:05<00:57,  2.23s/it, loss=0.9726, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 4:   7%|▋         | 2/28 [00:05<00:57,  2.23s/it, loss=1.1161, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 4:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=1.1161, batch_acc=0.7500, running_acc=0.7344]Evaluation epoch 4:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.9000, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 4:  14%|█▍        | 4/28 [00:09<00:59,  2.50s/it, loss=0.9000, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 4:  14%|█▍        | 4/28 [00:09<00:59,  2.50s/it, loss=1.8982, batch_acc=0.4062, running_acc=0.6641]Evaluation epoch 4:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=1.8982, batch_acc=0.4062, running_acc=0.6641]Evaluation epoch 4:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=2.3108, batch_acc=0.3125, running_acc=0.5938]Evaluation epoch 4:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=2.3108, batch_acc=0.3125, running_acc=0.5938]Evaluation epoch 4:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=1.6578, batch_acc=0.5000, running_acc=0.5781]Evaluation epoch 4:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=1.6578, batch_acc=0.5000, running_acc=0.5781]Evaluation epoch 4:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=1.5116, batch_acc=0.6250, running_acc=0.5848]Evaluation epoch 4:  29%|██▊       | 8/28 [00:14<00:34,  1.70s/it, loss=1.5116, batch_acc=0.6250, running_acc=0.5848]Evaluation epoch 4:  29%|██▊       | 8/28 [00:14<00:34,  1.70s/it, loss=1.7982, batch_acc=0.4375, running_acc=0.5664]Evaluation epoch 4:  32%|███▏      | 9/28 [00:14<00:27,  1.43s/it, loss=1.7982, batch_acc=0.4375, running_acc=0.5664]Evaluation epoch 4:  32%|███▏      | 9/28 [00:14<00:27,  1.43s/it, loss=2.1365, batch_acc=0.4062, running_acc=0.5486]Evaluation epoch 4:  36%|███▌      | 10/28 [00:15<00:19,  1.07s/it, loss=2.1365, batch_acc=0.4062, running_acc=0.5486]Evaluation epoch 4:  36%|███▌      | 10/28 [00:15<00:19,  1.07s/it, loss=0.7182, batch_acc=0.8750, running_acc=0.5813]Evaluation epoch 4:  39%|███▉      | 11/28 [00:15<00:13,  1.21it/s, loss=0.7182, batch_acc=0.8750, running_acc=0.5813]Evaluation epoch 4:  39%|███▉      | 11/28 [00:15<00:13,  1.21it/s, loss=1.4717, batch_acc=0.5938, running_acc=0.5824]Evaluation epoch 4:  43%|████▎     | 12/28 [00:20<00:33,  2.07s/it, loss=1.4717, batch_acc=0.5938, running_acc=0.5824]Evaluation epoch 4:  43%|████▎     | 12/28 [00:20<00:33,  2.07s/it, loss=1.2860, batch_acc=0.6562, running_acc=0.5885]Evaluation epoch 4:  46%|████▋     | 13/28 [00:20<00:22,  1.52s/it, loss=1.2860, batch_acc=0.6562, running_acc=0.5885]Evaluation epoch 4:  46%|████▋     | 13/28 [00:20<00:22,  1.52s/it, loss=1.1573, batch_acc=0.7500, running_acc=0.6010]Evaluation epoch 4:  50%|█████     | 14/28 [00:20<00:16,  1.14s/it, loss=1.1573, batch_acc=0.7500, running_acc=0.6010]Evaluation epoch 4:  50%|█████     | 14/28 [00:20<00:16,  1.14s/it, loss=1.6788, batch_acc=0.5938, running_acc=0.6004]Evaluation epoch 4:  54%|█████▎    | 15/28 [00:21<00:11,  1.14it/s, loss=1.6788, batch_acc=0.5938, running_acc=0.6004]Evaluation epoch 4:  54%|█████▎    | 15/28 [00:21<00:11,  1.14it/s, loss=2.7830, batch_acc=0.2188, running_acc=0.5750]Evaluation epoch 4:  57%|█████▋    | 16/28 [00:23<00:17,  1.47s/it, loss=2.7830, batch_acc=0.2188, running_acc=0.5750]Evaluation epoch 4:  57%|█████▋    | 16/28 [00:23<00:17,  1.47s/it, loss=1.9429, batch_acc=0.4375, running_acc=0.5664]Evaluation epoch 4:  61%|██████    | 17/28 [00:24<00:12,  1.10s/it, loss=1.9429, batch_acc=0.4375, running_acc=0.5664]Evaluation epoch 4:  61%|██████    | 17/28 [00:24<00:12,  1.10s/it, loss=1.4026, batch_acc=0.4375, running_acc=0.5588]Evaluation epoch 4:  64%|██████▍   | 18/28 [00:24<00:08,  1.17it/s, loss=1.4026, batch_acc=0.4375, running_acc=0.5588]Evaluation epoch 4:  64%|██████▍   | 18/28 [00:24<00:08,  1.17it/s, loss=1.4711, batch_acc=0.5312, running_acc=0.5573]Evaluation epoch 4:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=1.4711, batch_acc=0.5312, running_acc=0.5573]Evaluation epoch 4:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=1.4022, batch_acc=0.4375, running_acc=0.5510]Evaluation epoch 4:  71%|███████▏  | 20/28 [00:27<00:10,  1.32s/it, loss=1.4022, batch_acc=0.4375, running_acc=0.5510]Evaluation epoch 4:  71%|███████▏  | 20/28 [00:27<00:10,  1.32s/it, loss=1.8195, batch_acc=0.4688, running_acc=0.5469]Evaluation epoch 4:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=1.8195, batch_acc=0.4688, running_acc=0.5469]Evaluation epoch 4:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=1.5002, batch_acc=0.6250, running_acc=0.5506]Evaluation epoch 4:  79%|███████▊  | 22/28 [00:28<00:04,  1.28it/s, loss=1.5002, batch_acc=0.6250, running_acc=0.5506]Evaluation epoch 4:  79%|███████▊  | 22/28 [00:28<00:04,  1.28it/s, loss=1.9241, batch_acc=0.5000, running_acc=0.5483]Evaluation epoch 4:  82%|████████▏ | 23/28 [00:28<00:03,  1.60it/s, loss=1.9241, batch_acc=0.5000, running_acc=0.5483]Evaluation epoch 4:  82%|████████▏ | 23/28 [00:28<00:03,  1.60it/s, loss=1.9226, batch_acc=0.3438, running_acc=0.5394]Evaluation epoch 4:  86%|████████▌ | 24/28 [00:33<00:08,  2.08s/it, loss=1.9226, batch_acc=0.3438, running_acc=0.5394]Evaluation epoch 4:  86%|████████▌ | 24/28 [00:33<00:08,  2.08s/it, loss=0.9537, batch_acc=0.7812, running_acc=0.5495]Evaluation epoch 4:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.9537, batch_acc=0.7812, running_acc=0.5495]Evaluation epoch 4:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.8831, batch_acc=0.7500, running_acc=0.5575]Evaluation epoch 4:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.8831, batch_acc=0.7500, running_acc=0.5575]Evaluation epoch 4:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.5949, batch_acc=0.5312, running_acc=0.5565]Evaluation epoch 4:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=1.5949, batch_acc=0.5312, running_acc=0.5565]Evaluation epoch 4:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=1.8878, batch_acc=0.4375, running_acc=0.5521]Evaluation epoch 4: 100%|██████████| 28/28 [00:34<00:00,  1.13it/s, loss=1.2625, batch_acc=0.6667, running_acc=0.5525]Evaluation epoch 4: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.2625, batch_acc=0.6667, running_acc=0.5525]
Training epoch 5:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 5:   1%|          | 1/163 [00:06<17:04,  6.32s/it]Training epoch 5:   1%|          | 1/163 [00:06<17:04,  6.32s/it, loss=1.0055, batch_acc=0.7188, running_acc=0.7188, grad=5.9626]Training epoch 5:   1%|          | 2/163 [00:07<08:22,  3.12s/it, loss=1.0055, batch_acc=0.7188, running_acc=0.7188, grad=5.9626]Training epoch 5:   1%|          | 2/163 [00:07<08:22,  3.12s/it, loss=1.2556, batch_acc=0.6250, running_acc=0.6719, grad=6.2292]Training epoch 5:   2%|▏         | 3/163 [00:08<05:35,  2.10s/it, loss=1.2556, batch_acc=0.6250, running_acc=0.6719, grad=6.2292]Training epoch 5:   2%|▏         | 3/163 [00:08<05:35,  2.10s/it, loss=1.2930, batch_acc=0.5000, running_acc=0.6146, grad=6.3861]Training epoch 5:   2%|▏         | 4/163 [00:09<05:06,  1.93s/it, loss=1.2930, batch_acc=0.5000, running_acc=0.6146, grad=6.3861]Training epoch 5:   2%|▏         | 4/163 [00:09<05:06,  1.93s/it, loss=1.0055, batch_acc=0.7500, running_acc=0.6484, grad=5.7093]Training epoch 5:   3%|▎         | 5/163 [00:10<04:04,  1.55s/it, loss=1.0055, batch_acc=0.7500, running_acc=0.6484, grad=5.7093]Training epoch 5:   3%|▎         | 5/163 [00:10<04:04,  1.55s/it, loss=1.4443, batch_acc=0.5938, running_acc=0.6375, grad=6.1477]Training epoch 5:   4%|▎         | 6/163 [00:11<03:27,  1.32s/it, loss=1.4443, batch_acc=0.5938, running_acc=0.6375, grad=6.1477]Training epoch 5:   4%|▎         | 6/163 [00:11<03:27,  1.32s/it, loss=1.1296, batch_acc=0.6562, running_acc=0.6406, grad=5.6818]Training epoch 5:   4%|▍         | 7/163 [00:12<03:03,  1.18s/it, loss=1.1296, batch_acc=0.6562, running_acc=0.6406, grad=5.6818]Training epoch 5:   4%|▍         | 7/163 [00:12<03:03,  1.18s/it, loss=1.3509, batch_acc=0.6250, running_acc=0.6384, grad=6.1052]Training epoch 5:   5%|▍         | 8/163 [00:14<03:34,  1.38s/it, loss=1.3509, batch_acc=0.6250, running_acc=0.6384, grad=6.1052]Training epoch 5:   5%|▍         | 8/163 [00:14<03:34,  1.38s/it, loss=1.6429, batch_acc=0.5312, running_acc=0.6250, grad=6.2853]Training epoch 5:   6%|▌         | 9/163 [00:15<03:08,  1.22s/it, loss=1.6429, batch_acc=0.5312, running_acc=0.6250, grad=6.2853]Training epoch 5:   6%|▌         | 9/163 [00:15<03:08,  1.22s/it, loss=1.4566, batch_acc=0.5312, running_acc=0.6146, grad=9.0854]Training epoch 5:   6%|▌         | 10/163 [00:15<02:50,  1.12s/it, loss=1.4566, batch_acc=0.5312, running_acc=0.6146, grad=9.0854]Training epoch 5:   6%|▌         | 10/163 [00:15<02:50,  1.12s/it, loss=1.3620, batch_acc=0.5625, running_acc=0.6094, grad=9.0886]Training epoch 5:   7%|▋         | 11/163 [00:16<02:38,  1.04s/it, loss=1.3620, batch_acc=0.5625, running_acc=0.6094, grad=9.0886]Training epoch 5:   7%|▋         | 11/163 [00:16<02:38,  1.04s/it, loss=1.5223, batch_acc=0.6250, running_acc=0.6108, grad=8.0202]Training epoch 5:   7%|▋         | 12/163 [00:18<03:05,  1.23s/it, loss=1.5223, batch_acc=0.6250, running_acc=0.6108, grad=8.0202]Training epoch 5:   7%|▋         | 12/163 [00:18<03:05,  1.23s/it, loss=1.3762, batch_acc=0.5938, running_acc=0.6094, grad=6.8162]Training epoch 5:   8%|▊         | 13/163 [00:19<02:48,  1.12s/it, loss=1.3762, batch_acc=0.5938, running_acc=0.6094, grad=6.8162]Training epoch 5:   8%|▊         | 13/163 [00:19<02:48,  1.12s/it, loss=1.4943, batch_acc=0.4688, running_acc=0.5986, grad=10.3439]Training epoch 5:   9%|▊         | 14/163 [00:20<02:36,  1.05s/it, loss=1.4943, batch_acc=0.4688, running_acc=0.5986, grad=10.3439]Training epoch 5:   9%|▊         | 14/163 [00:20<02:36,  1.05s/it, loss=1.2835, batch_acc=0.6562, running_acc=0.6027, grad=7.7515] Training epoch 5:   9%|▉         | 15/163 [00:21<02:27,  1.00it/s, loss=1.2835, batch_acc=0.6562, running_acc=0.6027, grad=7.7515]Training epoch 5:   9%|▉         | 15/163 [00:21<02:27,  1.00it/s, loss=1.2438, batch_acc=0.7188, running_acc=0.6104, grad=6.9800]Training epoch 5:  10%|▉         | 16/163 [00:23<03:26,  1.41s/it, loss=1.2438, batch_acc=0.7188, running_acc=0.6104, grad=6.9800]Training epoch 5:  10%|▉         | 16/163 [00:23<03:26,  1.41s/it, loss=1.0307, batch_acc=0.6875, running_acc=0.6152, grad=6.0546]Training epoch 5:  10%|█         | 17/163 [00:24<03:02,  1.25s/it, loss=1.0307, batch_acc=0.6875, running_acc=0.6152, grad=6.0546]Training epoch 5:  10%|█         | 17/163 [00:24<03:02,  1.25s/it, loss=0.9841, batch_acc=0.7500, running_acc=0.6232, grad=7.6111]Training epoch 5:  11%|█         | 18/163 [00:25<02:44,  1.14s/it, loss=0.9841, batch_acc=0.7500, running_acc=0.6232, grad=7.6111]Training epoch 5:  11%|█         | 18/163 [00:25<02:44,  1.14s/it, loss=1.0507, batch_acc=0.6875, running_acc=0.6267, grad=5.7915]Training epoch 5:  12%|█▏        | 19/163 [00:26<02:32,  1.06s/it, loss=1.0507, batch_acc=0.6875, running_acc=0.6267, grad=5.7915]Training epoch 5:  12%|█▏        | 19/163 [00:26<02:32,  1.06s/it, loss=1.4015, batch_acc=0.5625, running_acc=0.6234, grad=7.1071]Training epoch 5:  12%|█▏        | 20/163 [00:27<03:07,  1.31s/it, loss=1.4015, batch_acc=0.5625, running_acc=0.6234, grad=7.1071]Training epoch 5:  12%|█▏        | 20/163 [00:27<03:07,  1.31s/it, loss=1.4483, batch_acc=0.6875, running_acc=0.6266, grad=7.8892]Training epoch 5:  13%|█▎        | 21/163 [00:28<02:47,  1.18s/it, loss=1.4483, batch_acc=0.6875, running_acc=0.6266, grad=7.8892]Training epoch 5:  13%|█▎        | 21/163 [00:28<02:47,  1.18s/it, loss=1.3842, batch_acc=0.6250, running_acc=0.6265, grad=8.4753]Training epoch 5:  13%|█▎        | 22/163 [00:29<02:33,  1.09s/it, loss=1.3842, batch_acc=0.6250, running_acc=0.6265, grad=8.4753]Training epoch 5:  13%|█▎        | 22/163 [00:29<02:33,  1.09s/it, loss=1.1561, batch_acc=0.6562, running_acc=0.6278, grad=7.0241]Training epoch 5:  14%|█▍        | 23/163 [00:30<02:23,  1.02s/it, loss=1.1561, batch_acc=0.6562, running_acc=0.6278, grad=7.0241]Training epoch 5:  14%|█▍        | 23/163 [00:30<02:23,  1.02s/it, loss=1.5823, batch_acc=0.5938, running_acc=0.6264, grad=12.5325]Training epoch 5:  15%|█▍        | 24/163 [00:32<02:48,  1.21s/it, loss=1.5823, batch_acc=0.5938, running_acc=0.6264, grad=12.5325]Training epoch 5:  15%|█▍        | 24/163 [00:32<02:48,  1.21s/it, loss=1.0501, batch_acc=0.7500, running_acc=0.6315, grad=6.2875] Training epoch 5:  15%|█▌        | 25/163 [00:33<02:33,  1.11s/it, loss=1.0501, batch_acc=0.7500, running_acc=0.6315, grad=6.2875]Training epoch 5:  15%|█▌        | 25/163 [00:33<02:33,  1.11s/it, loss=1.3325, batch_acc=0.7188, running_acc=0.6350, grad=7.3009]Training epoch 5:  16%|█▌        | 26/163 [00:34<02:22,  1.04s/it, loss=1.3325, batch_acc=0.7188, running_acc=0.6350, grad=7.3009]Training epoch 5:  16%|█▌        | 26/163 [00:34<02:22,  1.04s/it, loss=1.2346, batch_acc=0.6562, running_acc=0.6358, grad=9.1004]Training epoch 5:  17%|█▋        | 27/163 [00:34<02:14,  1.01it/s, loss=1.2346, batch_acc=0.6562, running_acc=0.6358, grad=9.1004]Training epoch 5:  17%|█▋        | 27/163 [00:34<02:14,  1.01it/s, loss=1.0347, batch_acc=0.7500, running_acc=0.6400, grad=6.8807]Training epoch 5:  17%|█▋        | 28/163 [00:36<02:46,  1.23s/it, loss=1.0347, batch_acc=0.7500, running_acc=0.6400, grad=6.8807]Training epoch 5:  17%|█▋        | 28/163 [00:36<02:46,  1.23s/it, loss=1.4404, batch_acc=0.4688, running_acc=0.6339, grad=10.8567]Training epoch 5:  18%|█▊        | 29/163 [00:37<02:30,  1.12s/it, loss=1.4404, batch_acc=0.4688, running_acc=0.6339, grad=10.8567]Training epoch 5:  18%|█▊        | 29/163 [00:37<02:30,  1.12s/it, loss=1.2711, batch_acc=0.5000, running_acc=0.6293, grad=7.6568] Training epoch 5:  18%|█▊        | 30/163 [00:38<02:19,  1.05s/it, loss=1.2711, batch_acc=0.5000, running_acc=0.6293, grad=7.6568]Training epoch 5:  18%|█▊        | 30/163 [00:38<02:19,  1.05s/it, loss=1.1298, batch_acc=0.7500, running_acc=0.6333, grad=6.2057]Training epoch 5:  19%|█▉        | 31/163 [00:39<02:11,  1.00it/s, loss=1.1298, batch_acc=0.7500, running_acc=0.6333, grad=6.2057]Training epoch 5:  19%|█▉        | 31/163 [00:39<02:11,  1.00it/s, loss=1.6198, batch_acc=0.5938, running_acc=0.6321, grad=7.3797]Training epoch 5:  20%|█▉        | 32/163 [00:40<02:33,  1.17s/it, loss=1.6198, batch_acc=0.5938, running_acc=0.6321, grad=7.3797]Training epoch 5:  20%|█▉        | 32/163 [00:40<02:33,  1.17s/it, loss=0.8558, batch_acc=0.8438, running_acc=0.6387, grad=5.8085]Training epoch 5:  20%|██        | 33/163 [00:41<02:20,  1.08s/it, loss=0.8558, batch_acc=0.8438, running_acc=0.6387, grad=5.8085]Training epoch 5:  20%|██        | 33/163 [00:41<02:20,  1.08s/it, loss=1.0771, batch_acc=0.6875, running_acc=0.6402, grad=7.0343]Training epoch 5:  21%|██        | 34/163 [00:42<02:11,  1.02s/it, loss=1.0771, batch_acc=0.6875, running_acc=0.6402, grad=7.0343]Training epoch 5:  21%|██        | 34/163 [00:42<02:11,  1.02s/it, loss=1.0843, batch_acc=0.6562, running_acc=0.6406, grad=7.2999]Training epoch 5:  21%|██▏       | 35/163 [00:43<02:05,  1.02it/s, loss=1.0843, batch_acc=0.6562, running_acc=0.6406, grad=7.2999]Training epoch 5:  21%|██▏       | 35/163 [00:43<02:05,  1.02it/s, loss=1.1063, batch_acc=0.6875, running_acc=0.6420, grad=5.6610]Training epoch 5:  22%|██▏       | 36/163 [00:45<02:24,  1.14s/it, loss=1.1063, batch_acc=0.6875, running_acc=0.6420, grad=5.6610]Training epoch 5:  22%|██▏       | 36/163 [00:45<02:24,  1.14s/it, loss=1.2467, batch_acc=0.7188, running_acc=0.6441, grad=6.5046]Training epoch 5:  23%|██▎       | 37/163 [00:45<02:13,  1.06s/it, loss=1.2467, batch_acc=0.7188, running_acc=0.6441, grad=6.5046]Training epoch 5:  23%|██▎       | 37/163 [00:45<02:13,  1.06s/it, loss=1.1918, batch_acc=0.6875, running_acc=0.6453, grad=6.0548]Training epoch 5:  23%|██▎       | 38/163 [00:46<02:05,  1.01s/it, loss=1.1918, batch_acc=0.6875, running_acc=0.6453, grad=6.0548]Training epoch 5:  23%|██▎       | 38/163 [00:46<02:05,  1.01s/it, loss=1.1395, batch_acc=0.6562, running_acc=0.6456, grad=7.2312]Training epoch 5:  24%|██▍       | 39/163 [00:47<01:59,  1.03it/s, loss=1.1395, batch_acc=0.6562, running_acc=0.6456, grad=7.2312]Training epoch 5:  24%|██▍       | 39/163 [00:47<01:59,  1.03it/s, loss=0.9629, batch_acc=0.8125, running_acc=0.6498, grad=6.4075]Training epoch 5:  25%|██▍       | 40/163 [00:49<02:33,  1.25s/it, loss=0.9629, batch_acc=0.8125, running_acc=0.6498, grad=6.4075]Training epoch 5:  25%|██▍       | 40/163 [00:49<02:33,  1.25s/it, loss=1.2923, batch_acc=0.6250, running_acc=0.6492, grad=8.9280]Training epoch 5:  25%|██▌       | 41/163 [00:50<02:19,  1.14s/it, loss=1.2923, batch_acc=0.6250, running_acc=0.6492, grad=8.9280]Training epoch 5:  25%|██▌       | 41/163 [00:50<02:19,  1.14s/it, loss=0.8827, batch_acc=0.6875, running_acc=0.6502, grad=4.5167]Training epoch 5:  26%|██▌       | 42/163 [00:51<02:08,  1.06s/it, loss=0.8827, batch_acc=0.6875, running_acc=0.6502, grad=4.5167]Training epoch 5:  26%|██▌       | 42/163 [00:51<02:08,  1.06s/it, loss=1.0158, batch_acc=0.6250, running_acc=0.6496, grad=7.0184]Training epoch 5:  26%|██▋       | 43/163 [00:52<02:00,  1.01s/it, loss=1.0158, batch_acc=0.6250, running_acc=0.6496, grad=7.0184]Training epoch 5:  26%|██▋       | 43/163 [00:52<02:00,  1.01s/it, loss=1.0659, batch_acc=0.6250, running_acc=0.6490, grad=7.0920]Training epoch 5:  27%|██▋       | 44/163 [00:54<02:28,  1.25s/it, loss=1.0659, batch_acc=0.6250, running_acc=0.6490, grad=7.0920]Training epoch 5:  27%|██▋       | 44/163 [00:54<02:28,  1.25s/it, loss=1.5258, batch_acc=0.5312, running_acc=0.6463, grad=8.1590]Training epoch 5:  28%|██▊       | 45/163 [00:54<02:13,  1.13s/it, loss=1.5258, batch_acc=0.5312, running_acc=0.6463, grad=8.1590]Training epoch 5:  28%|██▊       | 45/163 [00:54<02:13,  1.13s/it, loss=1.0136, batch_acc=0.6562, running_acc=0.6465, grad=8.2737]Training epoch 5:  28%|██▊       | 46/163 [00:55<02:03,  1.06s/it, loss=1.0136, batch_acc=0.6562, running_acc=0.6465, grad=8.2737]Training epoch 5:  28%|██▊       | 46/163 [00:55<02:03,  1.06s/it, loss=1.2877, batch_acc=0.5938, running_acc=0.6454, grad=9.8823]Training epoch 5:  29%|██▉       | 47/163 [00:56<01:56,  1.00s/it, loss=1.2877, batch_acc=0.5938, running_acc=0.6454, grad=9.8823]Training epoch 5:  29%|██▉       | 47/163 [00:56<01:56,  1.00s/it, loss=1.4672, batch_acc=0.6250, running_acc=0.6449, grad=9.2989]Training epoch 5:  29%|██▉       | 48/163 [00:57<02:03,  1.08s/it, loss=1.4672, batch_acc=0.6250, running_acc=0.6449, grad=9.2989]Training epoch 5:  29%|██▉       | 48/163 [00:57<02:03,  1.08s/it, loss=0.9640, batch_acc=0.7500, running_acc=0.6471, grad=6.5520]Training epoch 5:  30%|███       | 49/163 [00:58<01:55,  1.02s/it, loss=0.9640, batch_acc=0.7500, running_acc=0.6471, grad=6.5520]Training epoch 5:  30%|███       | 49/163 [00:58<01:55,  1.02s/it, loss=1.2624, batch_acc=0.6250, running_acc=0.6467, grad=6.5211]Training epoch 5:  31%|███       | 50/163 [00:59<01:50,  1.03it/s, loss=1.2624, batch_acc=0.6250, running_acc=0.6467, grad=6.5211]Training epoch 5:  31%|███       | 50/163 [00:59<01:50,  1.03it/s, loss=1.4353, batch_acc=0.6562, running_acc=0.6469, grad=7.5380]Training epoch 5:  31%|███▏      | 51/163 [01:00<01:45,  1.06it/s, loss=1.4353, batch_acc=0.6562, running_acc=0.6469, grad=7.5380]Training epoch 5:  31%|███▏      | 51/163 [01:00<01:45,  1.06it/s, loss=1.0724, batch_acc=0.7188, running_acc=0.6483, grad=7.8927]Training epoch 5:  32%|███▏      | 52/163 [01:02<02:06,  1.14s/it, loss=1.0724, batch_acc=0.7188, running_acc=0.6483, grad=7.8927]Training epoch 5:  32%|███▏      | 52/163 [01:02<02:06,  1.14s/it, loss=1.3750, batch_acc=0.6250, running_acc=0.6478, grad=7.5684]Training epoch 5:  33%|███▎      | 53/163 [01:03<01:57,  1.06s/it, loss=1.3750, batch_acc=0.6250, running_acc=0.6478, grad=7.5684]Training epoch 5:  33%|███▎      | 53/163 [01:03<01:57,  1.06s/it, loss=1.2729, batch_acc=0.6562, running_acc=0.6480, grad=6.4127]Training epoch 5:  33%|███▎      | 54/163 [01:03<01:49,  1.01s/it, loss=1.2729, batch_acc=0.6562, running_acc=0.6480, grad=6.4127]Training epoch 5:  33%|███▎      | 54/163 [01:03<01:49,  1.01s/it, loss=1.0481, batch_acc=0.6875, running_acc=0.6487, grad=6.4552]Training epoch 5:  34%|███▎      | 55/163 [01:04<01:44,  1.03it/s, loss=1.0481, batch_acc=0.6875, running_acc=0.6487, grad=6.4552]Training epoch 5:  34%|███▎      | 55/163 [01:04<01:44,  1.03it/s, loss=1.2678, batch_acc=0.6875, running_acc=0.6494, grad=6.7252]Training epoch 5:  34%|███▍      | 56/163 [01:06<02:12,  1.24s/it, loss=1.2678, batch_acc=0.6875, running_acc=0.6494, grad=6.7252]Training epoch 5:  34%|███▍      | 56/163 [01:06<02:12,  1.24s/it, loss=1.1139, batch_acc=0.6562, running_acc=0.6496, grad=9.9604]Training epoch 5:  35%|███▍      | 57/163 [01:07<01:59,  1.13s/it, loss=1.1139, batch_acc=0.6562, running_acc=0.6496, grad=9.9604]Training epoch 5:  35%|███▍      | 57/163 [01:07<01:59,  1.13s/it, loss=1.3012, batch_acc=0.6562, running_acc=0.6497, grad=7.8043]Training epoch 5:  36%|███▌      | 58/163 [01:08<01:50,  1.05s/it, loss=1.3012, batch_acc=0.6562, running_acc=0.6497, grad=7.8043]Training epoch 5:  36%|███▌      | 58/163 [01:08<01:50,  1.05s/it, loss=0.9671, batch_acc=0.7500, running_acc=0.6514, grad=7.0026]Training epoch 5:  36%|███▌      | 59/163 [01:09<01:44,  1.00s/it, loss=0.9671, batch_acc=0.7500, running_acc=0.6514, grad=7.0026]Training epoch 5:  36%|███▌      | 59/163 [01:09<01:44,  1.00s/it, loss=1.0409, batch_acc=0.8125, running_acc=0.6541, grad=6.4496]Training epoch 5:  37%|███▋      | 60/163 [01:10<01:57,  1.14s/it, loss=1.0409, batch_acc=0.8125, running_acc=0.6541, grad=6.4496]Training epoch 5:  37%|███▋      | 60/163 [01:10<01:57,  1.14s/it, loss=0.8100, batch_acc=0.7812, running_acc=0.6562, grad=5.6562]Training epoch 5:  37%|███▋      | 61/163 [01:11<01:48,  1.06s/it, loss=0.8100, batch_acc=0.7812, running_acc=0.6562, grad=5.6562]Training epoch 5:  37%|███▋      | 61/163 [01:11<01:48,  1.06s/it, loss=0.8984, batch_acc=0.7188, running_acc=0.6573, grad=7.4139]Training epoch 5:  38%|███▊      | 62/163 [01:12<01:41,  1.01s/it, loss=0.8984, batch_acc=0.7188, running_acc=0.6573, grad=7.4139]Training epoch 5:  38%|███▊      | 62/163 [01:12<01:41,  1.01s/it, loss=1.0704, batch_acc=0.6562, running_acc=0.6573, grad=9.9262]Training epoch 5:  39%|███▊      | 63/163 [01:13<01:36,  1.03it/s, loss=1.0704, batch_acc=0.6562, running_acc=0.6573, grad=9.9262]Training epoch 5:  39%|███▊      | 63/163 [01:13<01:36,  1.03it/s, loss=1.3392, batch_acc=0.5938, running_acc=0.6562, grad=9.4890]Training epoch 5:  39%|███▉      | 64/163 [01:14<01:52,  1.13s/it, loss=1.3392, batch_acc=0.5938, running_acc=0.6562, grad=9.4890]Training epoch 5:  39%|███▉      | 64/163 [01:14<01:52,  1.13s/it, loss=1.0005, batch_acc=0.7188, running_acc=0.6572, grad=9.5200]Training epoch 5:  40%|███▉      | 65/163 [01:15<01:43,  1.06s/it, loss=1.0005, batch_acc=0.7188, running_acc=0.6572, grad=9.5200]Training epoch 5:  40%|███▉      | 65/163 [01:15<01:43,  1.06s/it, loss=1.0422, batch_acc=0.6562, running_acc=0.6572, grad=7.5615]Training epoch 5:  40%|████      | 66/163 [01:16<01:37,  1.00s/it, loss=1.0422, batch_acc=0.6562, running_acc=0.6572, grad=7.5615]Training epoch 5:  40%|████      | 66/163 [01:16<01:37,  1.00s/it, loss=0.9848, batch_acc=0.7500, running_acc=0.6586, grad=6.7847]Training epoch 5:  41%|████      | 67/163 [01:17<01:32,  1.04it/s, loss=0.9848, batch_acc=0.7500, running_acc=0.6586, grad=6.7847]Training epoch 5:  41%|████      | 67/163 [01:17<01:32,  1.04it/s, loss=1.1794, batch_acc=0.6250, running_acc=0.6581, grad=6.2825]Training epoch 5:  42%|████▏     | 68/163 [01:19<01:48,  1.15s/it, loss=1.1794, batch_acc=0.6250, running_acc=0.6581, grad=6.2825]Training epoch 5:  42%|████▏     | 68/163 [01:19<01:48,  1.15s/it, loss=1.1105, batch_acc=0.7188, running_acc=0.6590, grad=5.5000]Training epoch 5:  42%|████▏     | 69/163 [01:19<01:40,  1.07s/it, loss=1.1105, batch_acc=0.7188, running_acc=0.6590, grad=5.5000]Training epoch 5:  42%|████▏     | 69/163 [01:19<01:40,  1.07s/it, loss=1.3041, batch_acc=0.5938, running_acc=0.6581, grad=8.1572]Training epoch 5:  43%|████▎     | 70/163 [01:20<01:33,  1.01s/it, loss=1.3041, batch_acc=0.5938, running_acc=0.6581, grad=8.1572]Training epoch 5:  43%|████▎     | 70/163 [01:20<01:33,  1.01s/it, loss=1.3744, batch_acc=0.6562, running_acc=0.6580, grad=7.2725]Training epoch 5:  44%|████▎     | 71/163 [01:21<01:29,  1.03it/s, loss=1.3744, batch_acc=0.6562, running_acc=0.6580, grad=7.2725]Training epoch 5:  44%|████▎     | 71/163 [01:21<01:29,  1.03it/s, loss=0.7312, batch_acc=0.8125, running_acc=0.6602, grad=5.1231]Training epoch 5:  44%|████▍     | 72/163 [01:23<01:37,  1.07s/it, loss=0.7312, batch_acc=0.8125, running_acc=0.6602, grad=5.1231]Training epoch 5:  44%|████▍     | 72/163 [01:23<01:37,  1.07s/it, loss=1.1292, batch_acc=0.6250, running_acc=0.6597, grad=9.4429]Training epoch 5:  45%|████▍     | 73/163 [01:23<01:30,  1.01s/it, loss=1.1292, batch_acc=0.6250, running_acc=0.6597, grad=9.4429]Training epoch 5:  45%|████▍     | 73/163 [01:23<01:30,  1.01s/it, loss=0.9725, batch_acc=0.8125, running_acc=0.6618, grad=6.0993]Training epoch 5:  45%|████▌     | 74/163 [01:24<01:26,  1.03it/s, loss=0.9725, batch_acc=0.8125, running_acc=0.6618, grad=6.0993]Training epoch 5:  45%|████▌     | 74/163 [01:24<01:26,  1.03it/s, loss=1.1028, batch_acc=0.7188, running_acc=0.6626, grad=7.1576]Training epoch 5:  46%|████▌     | 75/163 [01:25<01:22,  1.06it/s, loss=1.1028, batch_acc=0.7188, running_acc=0.6626, grad=7.1576]Training epoch 5:  46%|████▌     | 75/163 [01:25<01:22,  1.06it/s, loss=1.4478, batch_acc=0.5312, running_acc=0.6608, grad=9.0725]Training epoch 5:  47%|████▋     | 76/163 [01:27<01:34,  1.09s/it, loss=1.4478, batch_acc=0.5312, running_acc=0.6608, grad=9.0725]Training epoch 5:  47%|████▋     | 76/163 [01:27<01:34,  1.09s/it, loss=1.5553, batch_acc=0.5625, running_acc=0.6595, grad=8.5193]Training epoch 5:  47%|████▋     | 77/163 [01:27<01:28,  1.03s/it, loss=1.5553, batch_acc=0.5625, running_acc=0.6595, grad=8.5193]Training epoch 5:  47%|████▋     | 77/163 [01:27<01:28,  1.03s/it, loss=1.2194, batch_acc=0.6250, running_acc=0.6591, grad=8.5320]Training epoch 5:  48%|████▊     | 78/163 [01:28<01:23,  1.02it/s, loss=1.2194, batch_acc=0.6250, running_acc=0.6591, grad=8.5320]Training epoch 5:  48%|████▊     | 78/163 [01:28<01:23,  1.02it/s, loss=1.1288, batch_acc=0.7188, running_acc=0.6599, grad=7.2554]Training epoch 5:  48%|████▊     | 79/163 [01:29<01:19,  1.05it/s, loss=1.1288, batch_acc=0.7188, running_acc=0.6599, grad=7.2554]Training epoch 5:  48%|████▊     | 79/163 [01:29<01:19,  1.05it/s, loss=1.4585, batch_acc=0.6250, running_acc=0.6594, grad=8.1889]Training epoch 5:  49%|████▉     | 80/163 [01:31<01:31,  1.10s/it, loss=1.4585, batch_acc=0.6250, running_acc=0.6594, grad=8.1889]Training epoch 5:  49%|████▉     | 80/163 [01:31<01:31,  1.10s/it, loss=1.1673, batch_acc=0.7188, running_acc=0.6602, grad=6.3025]Training epoch 5:  50%|████▉     | 81/163 [01:32<01:24,  1.03s/it, loss=1.1673, batch_acc=0.7188, running_acc=0.6602, grad=6.3025]Training epoch 5:  50%|████▉     | 81/163 [01:32<01:24,  1.03s/it, loss=1.4805, batch_acc=0.6562, running_acc=0.6601, grad=7.1924]Training epoch 5:  50%|█████     | 82/163 [01:32<01:19,  1.01it/s, loss=1.4805, batch_acc=0.6562, running_acc=0.6601, grad=7.1924]Training epoch 5:  50%|█████     | 82/163 [01:32<01:19,  1.01it/s, loss=1.4731, batch_acc=0.4688, running_acc=0.6578, grad=6.6755]Training epoch 5:  51%|█████     | 83/163 [01:33<01:16,  1.05it/s, loss=1.4731, batch_acc=0.4688, running_acc=0.6578, grad=6.6755]Training epoch 5:  51%|█████     | 83/163 [01:33<01:16,  1.05it/s, loss=0.9637, batch_acc=0.7500, running_acc=0.6589, grad=7.6815]Training epoch 5:  52%|█████▏    | 84/163 [01:35<01:31,  1.15s/it, loss=0.9637, batch_acc=0.7500, running_acc=0.6589, grad=7.6815]Training epoch 5:  52%|█████▏    | 84/163 [01:35<01:31,  1.15s/it, loss=1.0016, batch_acc=0.6250, running_acc=0.6585, grad=8.2580]Training epoch 5:  52%|█████▏    | 85/163 [01:36<01:23,  1.07s/it, loss=1.0016, batch_acc=0.6250, running_acc=0.6585, grad=8.2580]Training epoch 5:  52%|█████▏    | 85/163 [01:36<01:23,  1.07s/it, loss=0.9056, batch_acc=0.7812, running_acc=0.6599, grad=5.7026]Training epoch 5:  53%|█████▎    | 86/163 [01:37<01:18,  1.01s/it, loss=0.9056, batch_acc=0.7812, running_acc=0.6599, grad=5.7026]Training epoch 5:  53%|█████▎    | 86/163 [01:37<01:18,  1.01s/it, loss=1.1719, batch_acc=0.6250, running_acc=0.6595, grad=6.3060]Training epoch 5:  53%|█████▎    | 87/163 [01:38<01:13,  1.03it/s, loss=1.1719, batch_acc=0.6250, running_acc=0.6595, grad=6.3060]Training epoch 5:  53%|█████▎    | 87/163 [01:38<01:13,  1.03it/s, loss=1.0136, batch_acc=0.7500, running_acc=0.6606, grad=5.3230]Training epoch 5:  54%|█████▍    | 88/163 [01:39<01:21,  1.09s/it, loss=1.0136, batch_acc=0.7500, running_acc=0.6606, grad=5.3230]Training epoch 5:  54%|█████▍    | 88/163 [01:39<01:21,  1.09s/it, loss=1.4002, batch_acc=0.6562, running_acc=0.6605, grad=10.2923]Training epoch 5:  55%|█████▍    | 89/163 [01:40<01:15,  1.02s/it, loss=1.4002, batch_acc=0.6562, running_acc=0.6605, grad=10.2923]Training epoch 5:  55%|█████▍    | 89/163 [01:40<01:15,  1.02s/it, loss=0.8459, batch_acc=0.7188, running_acc=0.6612, grad=6.2662] Training epoch 5:  55%|█████▌    | 90/163 [01:41<01:11,  1.02it/s, loss=0.8459, batch_acc=0.7188, running_acc=0.6612, grad=6.2662]Training epoch 5:  55%|█████▌    | 90/163 [01:41<01:11,  1.02it/s, loss=1.1019, batch_acc=0.7500, running_acc=0.6622, grad=7.0664]Training epoch 5:  56%|█████▌    | 91/163 [01:42<01:08,  1.05it/s, loss=1.1019, batch_acc=0.7500, running_acc=0.6622, grad=7.0664]Training epoch 5:  56%|█████▌    | 91/163 [01:42<01:08,  1.05it/s, loss=0.9698, batch_acc=0.6562, running_acc=0.6621, grad=7.3476]Training epoch 5:  56%|█████▋    | 92/163 [01:43<01:12,  1.02s/it, loss=0.9698, batch_acc=0.6562, running_acc=0.6621, grad=7.3476]Training epoch 5:  56%|█████▋    | 92/163 [01:43<01:12,  1.02s/it, loss=1.0615, batch_acc=0.7812, running_acc=0.6634, grad=6.5987]Training epoch 5:  57%|█████▋    | 93/163 [01:44<01:08,  1.03it/s, loss=1.0615, batch_acc=0.7812, running_acc=0.6634, grad=6.5987]Training epoch 5:  57%|█████▋    | 93/163 [01:44<01:08,  1.03it/s, loss=0.9968, batch_acc=0.6875, running_acc=0.6636, grad=8.2183]Training epoch 5:  58%|█████▊    | 94/163 [01:45<01:11,  1.03s/it, loss=0.9968, batch_acc=0.6875, running_acc=0.6636, grad=8.2183]Training epoch 5:  58%|█████▊    | 94/163 [01:45<01:11,  1.03s/it, loss=1.2878, batch_acc=0.6250, running_acc=0.6632, grad=8.8082]Training epoch 5:  58%|█████▊    | 95/163 [01:46<01:07,  1.01it/s, loss=1.2878, batch_acc=0.6250, running_acc=0.6632, grad=8.8082]Training epoch 5:  58%|█████▊    | 95/163 [01:46<01:07,  1.01it/s, loss=1.1814, batch_acc=0.6875, running_acc=0.6635, grad=9.1556]Training epoch 5:  59%|█████▉    | 96/163 [01:47<01:21,  1.22s/it, loss=1.1814, batch_acc=0.6875, running_acc=0.6635, grad=9.1556]Training epoch 5:  59%|█████▉    | 96/163 [01:47<01:21,  1.22s/it, loss=1.0577, batch_acc=0.6875, running_acc=0.6637, grad=7.2070]Training epoch 5:  60%|█████▉    | 97/163 [01:48<01:13,  1.11s/it, loss=1.0577, batch_acc=0.6875, running_acc=0.6637, grad=7.2070]Training epoch 5:  60%|█████▉    | 97/163 [01:48<01:13,  1.11s/it, loss=1.0944, batch_acc=0.7188, running_acc=0.6643, grad=7.7005]Training epoch 5:  60%|██████    | 98/163 [01:49<01:07,  1.04s/it, loss=1.0944, batch_acc=0.7188, running_acc=0.6643, grad=7.7005]Training epoch 5:  60%|██████    | 98/163 [01:49<01:07,  1.04s/it, loss=1.2741, batch_acc=0.6875, running_acc=0.6645, grad=6.5637]Training epoch 5:  61%|██████    | 99/163 [01:50<01:03,  1.01it/s, loss=1.2741, batch_acc=0.6875, running_acc=0.6645, grad=6.5637]Training epoch 5:  61%|██████    | 99/163 [01:50<01:03,  1.01it/s, loss=1.1284, batch_acc=0.6562, running_acc=0.6645, grad=9.3351]Training epoch 5:  61%|██████▏   | 100/163 [01:52<01:14,  1.19s/it, loss=1.1284, batch_acc=0.6562, running_acc=0.6645, grad=9.3351]Training epoch 5:  61%|██████▏   | 100/163 [01:52<01:14,  1.19s/it, loss=1.2168, batch_acc=0.6875, running_acc=0.6647, grad=8.7421]Training epoch 5:  62%|██████▏   | 101/163 [01:53<01:07,  1.09s/it, loss=1.2168, batch_acc=0.6875, running_acc=0.6647, grad=8.7421]Training epoch 5:  62%|██████▏   | 101/163 [01:53<01:07,  1.09s/it, loss=1.0635, batch_acc=0.7188, running_acc=0.6652, grad=7.4007]Training epoch 5:  63%|██████▎   | 102/163 [01:53<01:02,  1.03s/it, loss=1.0635, batch_acc=0.7188, running_acc=0.6652, grad=7.4007]Training epoch 5:  63%|██████▎   | 102/163 [01:53<01:02,  1.03s/it, loss=1.1728, batch_acc=0.5938, running_acc=0.6645, grad=8.6851]Training epoch 5:  63%|██████▎   | 103/163 [01:54<00:58,  1.02it/s, loss=1.1728, batch_acc=0.5938, running_acc=0.6645, grad=8.6851]Training epoch 5:  63%|██████▎   | 103/163 [01:54<00:58,  1.02it/s, loss=0.8939, batch_acc=0.7812, running_acc=0.6657, grad=6.5111]Training epoch 5:  64%|██████▍   | 104/163 [01:56<01:17,  1.31s/it, loss=0.8939, batch_acc=0.7812, running_acc=0.6657, grad=6.5111]Training epoch 5:  64%|██████▍   | 104/163 [01:56<01:17,  1.31s/it, loss=1.3045, batch_acc=0.6562, running_acc=0.6656, grad=6.8115]Training epoch 5:  64%|██████▍   | 105/163 [01:57<01:08,  1.18s/it, loss=1.3045, batch_acc=0.6562, running_acc=0.6656, grad=6.8115]Training epoch 5:  64%|██████▍   | 105/163 [01:57<01:08,  1.18s/it, loss=0.9482, batch_acc=0.8125, running_acc=0.6670, grad=8.3153]Training epoch 5:  65%|██████▌   | 106/163 [01:58<01:01,  1.09s/it, loss=0.9482, batch_acc=0.8125, running_acc=0.6670, grad=8.3153]Training epoch 5:  65%|██████▌   | 106/163 [01:58<01:01,  1.09s/it, loss=1.2890, batch_acc=0.5938, running_acc=0.6663, grad=8.8850]Training epoch 5:  66%|██████▌   | 107/163 [01:59<00:57,  1.02s/it, loss=1.2890, batch_acc=0.5938, running_acc=0.6663, grad=8.8850]Training epoch 5:  66%|██████▌   | 107/163 [01:59<00:57,  1.02s/it, loss=1.1083, batch_acc=0.5938, running_acc=0.6656, grad=5.6054]Training epoch 5:  66%|██████▋   | 108/163 [02:00<01:01,  1.12s/it, loss=1.1083, batch_acc=0.5938, running_acc=0.6656, grad=5.6054]Training epoch 5:  66%|██████▋   | 108/163 [02:00<01:01,  1.12s/it, loss=1.3571, batch_acc=0.6562, running_acc=0.6655, grad=7.6093]Training epoch 5:  67%|██████▋   | 109/163 [02:01<00:56,  1.05s/it, loss=1.3571, batch_acc=0.6562, running_acc=0.6655, grad=7.6093]Training epoch 5:  67%|██████▋   | 109/163 [02:01<00:56,  1.05s/it, loss=1.2317, batch_acc=0.5938, running_acc=0.6649, grad=8.5410]Training epoch 5:  67%|██████▋   | 110/163 [02:02<00:52,  1.00it/s, loss=1.2317, batch_acc=0.5938, running_acc=0.6649, grad=8.5410]Training epoch 5:  67%|██████▋   | 110/163 [02:02<00:52,  1.00it/s, loss=1.0438, batch_acc=0.6875, running_acc=0.6651, grad=8.6200]Training epoch 5:  68%|██████▊   | 111/163 [02:03<00:49,  1.04it/s, loss=1.0438, batch_acc=0.6875, running_acc=0.6651, grad=8.6200]Training epoch 5:  68%|██████▊   | 111/163 [02:03<00:49,  1.04it/s, loss=0.9561, batch_acc=0.7812, running_acc=0.6661, grad=7.1475]Training epoch 5:  69%|██████▊   | 112/163 [02:04<00:54,  1.06s/it, loss=0.9561, batch_acc=0.7812, running_acc=0.6661, grad=7.1475]Training epoch 5:  69%|██████▊   | 112/163 [02:04<00:54,  1.06s/it, loss=1.1374, batch_acc=0.6875, running_acc=0.6663, grad=9.2566]Training epoch 5:  69%|██████▉   | 113/163 [02:05<00:50,  1.01s/it, loss=1.1374, batch_acc=0.6875, running_acc=0.6663, grad=9.2566]Training epoch 5:  69%|██████▉   | 113/163 [02:05<00:50,  1.01s/it, loss=0.9553, batch_acc=0.7188, running_acc=0.6668, grad=7.2405]Training epoch 5:  70%|██████▉   | 114/163 [02:06<00:51,  1.05s/it, loss=0.9553, batch_acc=0.7188, running_acc=0.6668, grad=7.2405]Training epoch 5:  70%|██████▉   | 114/163 [02:06<00:51,  1.05s/it, loss=1.2873, batch_acc=0.6562, running_acc=0.6667, grad=8.9539]Training epoch 5:  71%|███████   | 115/163 [02:07<00:47,  1.00it/s, loss=1.2873, batch_acc=0.6562, running_acc=0.6667, grad=8.9539]Training epoch 5:  71%|███████   | 115/163 [02:07<00:47,  1.00it/s, loss=1.1029, batch_acc=0.6250, running_acc=0.6663, grad=6.1574]Training epoch 5:  71%|███████   | 116/163 [02:09<00:53,  1.15s/it, loss=1.1029, batch_acc=0.6250, running_acc=0.6663, grad=6.1574]Training epoch 5:  71%|███████   | 116/163 [02:09<00:53,  1.15s/it, loss=0.9885, batch_acc=0.5938, running_acc=0.6657, grad=7.5897]Training epoch 5:  72%|███████▏  | 117/163 [02:10<00:48,  1.06s/it, loss=0.9885, batch_acc=0.5938, running_acc=0.6657, grad=7.5897]Training epoch 5:  72%|███████▏  | 117/163 [02:10<00:48,  1.06s/it, loss=1.0590, batch_acc=0.7188, running_acc=0.6661, grad=6.8818]Training epoch 5:  72%|███████▏  | 118/163 [02:10<00:45,  1.01s/it, loss=1.0590, batch_acc=0.7188, running_acc=0.6661, grad=6.8818]Training epoch 5:  72%|███████▏  | 118/163 [02:10<00:45,  1.01s/it, loss=1.0212, batch_acc=0.6875, running_acc=0.6663, grad=6.7031]Training epoch 5:  73%|███████▎  | 119/163 [02:11<00:42,  1.03it/s, loss=1.0212, batch_acc=0.6875, running_acc=0.6663, grad=6.7031]Training epoch 5:  73%|███████▎  | 119/163 [02:11<00:42,  1.03it/s, loss=0.8613, batch_acc=0.7500, running_acc=0.6670, grad=6.7744]Training epoch 5:  74%|███████▎  | 120/163 [02:13<00:47,  1.09s/it, loss=0.8613, batch_acc=0.7500, running_acc=0.6670, grad=6.7744]Training epoch 5:  74%|███████▎  | 120/163 [02:13<00:47,  1.09s/it, loss=1.4657, batch_acc=0.5312, running_acc=0.6659, grad=8.4980]Training epoch 5:  74%|███████▍  | 121/163 [02:14<00:43,  1.03s/it, loss=1.4657, batch_acc=0.5312, running_acc=0.6659, grad=8.4980]Training epoch 5:  74%|███████▍  | 121/163 [02:14<00:43,  1.03s/it, loss=1.1061, batch_acc=0.6562, running_acc=0.6658, grad=6.8430]Training epoch 5:  75%|███████▍  | 122/163 [02:14<00:40,  1.00it/s, loss=1.1061, batch_acc=0.6562, running_acc=0.6658, grad=6.8430]Training epoch 5:  75%|███████▍  | 122/163 [02:14<00:40,  1.00it/s, loss=1.1522, batch_acc=0.6875, running_acc=0.6660, grad=7.8371]Training epoch 5:  75%|███████▌  | 123/163 [02:15<00:38,  1.04it/s, loss=1.1522, batch_acc=0.6875, running_acc=0.6660, grad=7.8371]Training epoch 5:  75%|███████▌  | 123/163 [02:15<00:38,  1.04it/s, loss=1.0904, batch_acc=0.6562, running_acc=0.6659, grad=7.1556]Training epoch 5:  76%|███████▌  | 124/163 [02:17<00:45,  1.17s/it, loss=1.0904, batch_acc=0.6562, running_acc=0.6659, grad=7.1556]Training epoch 5:  76%|███████▌  | 124/163 [02:17<00:45,  1.17s/it, loss=0.9360, batch_acc=0.8125, running_acc=0.6671, grad=5.7147]Training epoch 5:  77%|███████▋  | 125/163 [02:18<00:41,  1.08s/it, loss=0.9360, batch_acc=0.8125, running_acc=0.6671, grad=5.7147]Training epoch 5:  77%|███████▋  | 125/163 [02:18<00:41,  1.08s/it, loss=1.3624, batch_acc=0.5938, running_acc=0.6665, grad=8.9345]Training epoch 5:  77%|███████▋  | 126/163 [02:19<00:37,  1.02s/it, loss=1.3624, batch_acc=0.5938, running_acc=0.6665, grad=8.9345]Training epoch 5:  77%|███████▋  | 126/163 [02:19<00:37,  1.02s/it, loss=1.3691, batch_acc=0.6562, running_acc=0.6664, grad=10.4926]Training epoch 5:  78%|███████▊  | 127/163 [02:20<00:35,  1.02it/s, loss=1.3691, batch_acc=0.6562, running_acc=0.6664, grad=10.4926]Training epoch 5:  78%|███████▊  | 127/163 [02:20<00:35,  1.02it/s, loss=1.7230, batch_acc=0.5625, running_acc=0.6656, grad=10.2110]Training epoch 5:  79%|███████▊  | 128/163 [02:21<00:37,  1.06s/it, loss=1.7230, batch_acc=0.5625, running_acc=0.6656, grad=10.2110]Training epoch 5:  79%|███████▊  | 128/163 [02:21<00:37,  1.06s/it, loss=1.3019, batch_acc=0.5938, running_acc=0.6650, grad=9.1639] Training epoch 5:  79%|███████▉  | 129/163 [02:22<00:34,  1.01s/it, loss=1.3019, batch_acc=0.5938, running_acc=0.6650, grad=9.1639]Training epoch 5:  79%|███████▉  | 129/163 [02:22<00:34,  1.01s/it, loss=1.2001, batch_acc=0.6250, running_acc=0.6647, grad=8.0505]Training epoch 5:  80%|███████▉  | 130/163 [02:23<00:31,  1.03it/s, loss=1.2001, batch_acc=0.6250, running_acc=0.6647, grad=8.0505]Training epoch 5:  80%|███████▉  | 130/163 [02:23<00:31,  1.03it/s, loss=1.3551, batch_acc=0.6562, running_acc=0.6647, grad=7.6146]Training epoch 5:  80%|████████  | 131/163 [02:24<00:30,  1.06it/s, loss=1.3551, batch_acc=0.6562, running_acc=0.6647, grad=7.6146]Training epoch 5:  80%|████████  | 131/163 [02:24<00:30,  1.06it/s, loss=1.1906, batch_acc=0.6875, running_acc=0.6648, grad=7.8129]Training epoch 5:  81%|████████  | 132/163 [02:24<00:28,  1.07it/s, loss=1.1906, batch_acc=0.6875, running_acc=0.6648, grad=7.8129]Training epoch 5:  81%|████████  | 132/163 [02:24<00:28,  1.07it/s, loss=1.2857, batch_acc=0.5000, running_acc=0.6636, grad=8.1223]Training epoch 5:  82%|████████▏ | 133/163 [02:25<00:27,  1.09it/s, loss=1.2857, batch_acc=0.5000, running_acc=0.6636, grad=8.1223]Training epoch 5:  82%|████████▏ | 133/163 [02:25<00:27,  1.09it/s, loss=1.4960, batch_acc=0.5625, running_acc=0.6628, grad=10.6841]Training epoch 5:  82%|████████▏ | 134/163 [02:27<00:28,  1.00it/s, loss=1.4960, batch_acc=0.5625, running_acc=0.6628, grad=10.6841]Training epoch 5:  82%|████████▏ | 134/163 [02:27<00:28,  1.00it/s, loss=1.4477, batch_acc=0.6250, running_acc=0.6625, grad=7.3069] Training epoch 5:  83%|████████▎ | 135/163 [02:27<00:26,  1.04it/s, loss=1.4477, batch_acc=0.6250, running_acc=0.6625, grad=7.3069]Training epoch 5:  83%|████████▎ | 135/163 [02:27<00:26,  1.04it/s, loss=1.0752, batch_acc=0.6562, running_acc=0.6625, grad=8.9164]Training epoch 5:  83%|████████▎ | 136/163 [02:29<00:27,  1.03s/it, loss=1.0752, batch_acc=0.6562, running_acc=0.6625, grad=8.9164]Training epoch 5:  83%|████████▎ | 136/163 [02:29<00:27,  1.03s/it, loss=0.8962, batch_acc=0.7812, running_acc=0.6634, grad=6.1300]Training epoch 5:  84%|████████▍ | 137/163 [02:29<00:25,  1.01it/s, loss=0.8962, batch_acc=0.7812, running_acc=0.6634, grad=6.1300]Training epoch 5:  84%|████████▍ | 137/163 [02:29<00:25,  1.01it/s, loss=1.3343, batch_acc=0.6562, running_acc=0.6633, grad=7.0658]Training epoch 5:  85%|████████▍ | 138/163 [02:31<00:27,  1.08s/it, loss=1.3343, batch_acc=0.6562, running_acc=0.6633, grad=7.0658]Training epoch 5:  85%|████████▍ | 138/163 [02:31<00:27,  1.08s/it, loss=1.2081, batch_acc=0.5625, running_acc=0.6626, grad=13.1913]Training epoch 5:  85%|████████▌ | 139/163 [02:32<00:24,  1.02s/it, loss=1.2081, batch_acc=0.5625, running_acc=0.6626, grad=13.1913]Training epoch 5:  85%|████████▌ | 139/163 [02:32<00:24,  1.02s/it, loss=0.9644, batch_acc=0.7500, running_acc=0.6632, grad=8.0645] Training epoch 5:  86%|████████▌ | 140/163 [02:33<00:26,  1.14s/it, loss=0.9644, batch_acc=0.7500, running_acc=0.6632, grad=8.0645]Training epoch 5:  86%|████████▌ | 140/163 [02:33<00:26,  1.14s/it, loss=1.5188, batch_acc=0.5000, running_acc=0.6621, grad=9.4080]Training epoch 5:  87%|████████▋ | 141/163 [02:34<00:23,  1.06s/it, loss=1.5188, batch_acc=0.5000, running_acc=0.6621, grad=9.4080]Training epoch 5:  87%|████████▋ | 141/163 [02:34<00:23,  1.06s/it, loss=1.2336, batch_acc=0.5938, running_acc=0.6616, grad=8.9502]Training epoch 5:  87%|████████▋ | 142/163 [02:35<00:23,  1.10s/it, loss=1.2336, batch_acc=0.5938, running_acc=0.6616, grad=8.9502]Training epoch 5:  87%|████████▋ | 142/163 [02:35<00:23,  1.10s/it, loss=1.1602, batch_acc=0.7188, running_acc=0.6620, grad=6.2970]Training epoch 5:  88%|████████▊ | 143/163 [02:36<00:20,  1.04s/it, loss=1.1602, batch_acc=0.7188, running_acc=0.6620, grad=6.2970]Training epoch 5:  88%|████████▊ | 143/163 [02:36<00:20,  1.04s/it, loss=1.3856, batch_acc=0.5938, running_acc=0.6615, grad=8.9579]Training epoch 5:  88%|████████▊ | 144/163 [02:37<00:19,  1.01s/it, loss=1.3856, batch_acc=0.5938, running_acc=0.6615, grad=8.9579]Training epoch 5:  88%|████████▊ | 144/163 [02:37<00:19,  1.01s/it, loss=1.1464, batch_acc=0.5938, running_acc=0.6610, grad=8.7342]Training epoch 5:  89%|████████▉ | 145/163 [02:38<00:17,  1.03it/s, loss=1.1464, batch_acc=0.5938, running_acc=0.6610, grad=8.7342]Training epoch 5:  89%|████████▉ | 145/163 [02:38<00:17,  1.03it/s, loss=1.1563, batch_acc=0.5938, running_acc=0.6606, grad=7.7529]Training epoch 5:  90%|████████▉ | 146/163 [02:39<00:18,  1.09s/it, loss=1.1563, batch_acc=0.5938, running_acc=0.6606, grad=7.7529]Training epoch 5:  90%|████████▉ | 146/163 [02:39<00:18,  1.09s/it, loss=1.1395, batch_acc=0.6562, running_acc=0.6605, grad=9.0062]Training epoch 5:  90%|█████████ | 147/163 [02:40<00:16,  1.02s/it, loss=1.1395, batch_acc=0.6562, running_acc=0.6605, grad=9.0062]Training epoch 5:  90%|█████████ | 147/163 [02:40<00:16,  1.02s/it, loss=1.2811, batch_acc=0.6250, running_acc=0.6603, grad=9.4564]Training epoch 5:  91%|█████████ | 148/163 [02:41<00:14,  1.02it/s, loss=1.2811, batch_acc=0.6250, running_acc=0.6603, grad=9.4564]Training epoch 5:  91%|█████████ | 148/163 [02:41<00:14,  1.02it/s, loss=0.9373, batch_acc=0.7188, running_acc=0.6607, grad=5.4998]Training epoch 5:  91%|█████████▏| 149/163 [02:42<00:13,  1.05it/s, loss=0.9373, batch_acc=0.7188, running_acc=0.6607, grad=5.4998]Training epoch 5:  91%|█████████▏| 149/163 [02:42<00:13,  1.05it/s, loss=1.0755, batch_acc=0.6250, running_acc=0.6604, grad=7.9981]Training epoch 5:  92%|█████████▏| 150/163 [02:43<00:12,  1.00it/s, loss=1.0755, batch_acc=0.6250, running_acc=0.6604, grad=7.9981]Training epoch 5:  92%|█████████▏| 150/163 [02:43<00:12,  1.00it/s, loss=1.0562, batch_acc=0.6875, running_acc=0.6606, grad=7.0556]Training epoch 5:  93%|█████████▎| 151/163 [02:44<00:11,  1.04it/s, loss=1.0562, batch_acc=0.6875, running_acc=0.6606, grad=7.0556]Training epoch 5:  93%|█████████▎| 151/163 [02:44<00:11,  1.04it/s, loss=1.1801, batch_acc=0.6250, running_acc=0.6604, grad=7.4425]Training epoch 5:  93%|█████████▎| 152/163 [02:45<00:12,  1.10s/it, loss=1.1801, batch_acc=0.6250, running_acc=0.6604, grad=7.4425]Training epoch 5:  93%|█████████▎| 152/163 [02:45<00:12,  1.10s/it, loss=1.1273, batch_acc=0.7188, running_acc=0.6608, grad=8.5910]Training epoch 5:  94%|█████████▍| 153/163 [02:46<00:10,  1.04s/it, loss=1.1273, batch_acc=0.7188, running_acc=0.6608, grad=8.5910]Training epoch 5:  94%|█████████▍| 153/163 [02:46<00:10,  1.04s/it, loss=0.9440, batch_acc=0.6875, running_acc=0.6609, grad=8.6622]Training epoch 5:  94%|█████████▍| 154/163 [02:48<00:11,  1.23s/it, loss=0.9440, batch_acc=0.6875, running_acc=0.6609, grad=8.6622]Training epoch 5:  94%|█████████▍| 154/163 [02:48<00:11,  1.23s/it, loss=0.8638, batch_acc=0.6562, running_acc=0.6609, grad=6.8001]Training epoch 5:  95%|█████████▌| 155/163 [02:49<00:09,  1.13s/it, loss=0.8638, batch_acc=0.6562, running_acc=0.6609, grad=6.8001]Training epoch 5:  95%|█████████▌| 155/163 [02:49<00:09,  1.13s/it, loss=1.1612, batch_acc=0.5625, running_acc=0.6603, grad=10.0907]Training epoch 5:  96%|█████████▌| 156/163 [02:50<00:07,  1.05s/it, loss=1.1612, batch_acc=0.5625, running_acc=0.6603, grad=10.0907]Training epoch 5:  96%|█████████▌| 156/163 [02:50<00:07,  1.05s/it, loss=1.5216, batch_acc=0.4688, running_acc=0.6591, grad=8.4605] Training epoch 5:  96%|█████████▋| 157/163 [02:50<00:05,  1.00it/s, loss=1.5216, batch_acc=0.4688, running_acc=0.6591, grad=8.4605]Training epoch 5:  96%|█████████▋| 157/163 [02:50<00:05,  1.00it/s, loss=1.2327, batch_acc=0.6250, running_acc=0.6588, grad=9.8503]Training epoch 5:  97%|█████████▋| 158/163 [02:53<00:06,  1.32s/it, loss=1.2327, batch_acc=0.6250, running_acc=0.6588, grad=9.8503]Training epoch 5:  97%|█████████▋| 158/163 [02:53<00:06,  1.32s/it, loss=0.8018, batch_acc=0.7500, running_acc=0.6594, grad=6.3763]Training epoch 5:  98%|█████████▊| 159/163 [02:53<00:04,  1.19s/it, loss=0.8018, batch_acc=0.7500, running_acc=0.6594, grad=6.3763]Training epoch 5:  98%|█████████▊| 159/163 [02:53<00:04,  1.19s/it, loss=1.0083, batch_acc=0.6562, running_acc=0.6594, grad=7.0517]Training epoch 5:  98%|█████████▊| 160/163 [02:54<00:03,  1.10s/it, loss=1.0083, batch_acc=0.6562, running_acc=0.6594, grad=7.0517]Training epoch 5:  98%|█████████▊| 160/163 [02:54<00:03,  1.10s/it, loss=1.2493, batch_acc=0.6250, running_acc=0.6592, grad=7.5246]Training epoch 5:  99%|█████████▉| 161/163 [02:55<00:02,  1.03s/it, loss=1.2493, batch_acc=0.6250, running_acc=0.6592, grad=7.5246]Training epoch 5:  99%|█████████▉| 161/163 [02:55<00:02,  1.03s/it, loss=1.1665, batch_acc=0.6562, running_acc=0.6592, grad=9.5655]Training epoch 5:  99%|█████████▉| 162/163 [02:56<00:00,  1.01it/s, loss=1.1665, batch_acc=0.6562, running_acc=0.6592, grad=9.5655]Training epoch 5:  99%|█████████▉| 162/163 [02:56<00:00,  1.01it/s, loss=1.3053, batch_acc=0.6562, running_acc=0.6591, grad=12.1318]Training epoch 5: 100%|██████████| 163/163 [02:57<00:00,  1.13it/s, loss=1.3053, batch_acc=0.6562, running_acc=0.6591, grad=12.1318]Training epoch 5: 100%|██████████| 163/163 [02:57<00:00,  1.13it/s, loss=1.3701, batch_acc=0.5238, running_acc=0.6586, grad=10.7075]Training epoch 5: 100%|██████████| 163/163 [02:57<00:00,  1.09s/it, loss=1.3701, batch_acc=0.5238, running_acc=0.6586, grad=10.7075]
Evaluation epoch 5:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 5:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it]Evaluation epoch 5:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it, loss=0.9629, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 5:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.9629, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 5:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.7692, batch_acc=0.7812, running_acc=0.7344]Evaluation epoch 5:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.7692, batch_acc=0.7812, running_acc=0.7344]Evaluation epoch 5:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.6137, batch_acc=0.8750, running_acc=0.7812]Evaluation epoch 5:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=0.6137, batch_acc=0.8750, running_acc=0.7812]Evaluation epoch 5:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=1.7269, batch_acc=0.4062, running_acc=0.6875]Evaluation epoch 5:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.7269, batch_acc=0.4062, running_acc=0.6875]Evaluation epoch 5:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=2.6317, batch_acc=0.3438, running_acc=0.6188]Evaluation epoch 5:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=2.6317, batch_acc=0.3438, running_acc=0.6188]Evaluation epoch 5:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.3198, batch_acc=0.5938, running_acc=0.6146]Evaluation epoch 5:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=1.3198, batch_acc=0.5938, running_acc=0.6146]Evaluation epoch 5:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=1.4941, batch_acc=0.5625, running_acc=0.6071]Evaluation epoch 5:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=1.4941, batch_acc=0.5625, running_acc=0.6071]Evaluation epoch 5:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=1.3414, batch_acc=0.4688, running_acc=0.5898]Evaluation epoch 5:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=1.3414, batch_acc=0.4688, running_acc=0.5898]Evaluation epoch 5:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=1.4632, batch_acc=0.6562, running_acc=0.5972]Evaluation epoch 5:  36%|███▌      | 10/28 [00:14<00:18,  1.01s/it, loss=1.4632, batch_acc=0.6562, running_acc=0.5972]Evaluation epoch 5:  36%|███▌      | 10/28 [00:14<00:18,  1.01s/it, loss=0.5581, batch_acc=0.8438, running_acc=0.6219]Evaluation epoch 5:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=0.5581, batch_acc=0.8438, running_acc=0.6219]Evaluation epoch 5:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=1.2029, batch_acc=0.6562, running_acc=0.6250]Evaluation epoch 5:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=1.2029, batch_acc=0.6562, running_acc=0.6250]Evaluation epoch 5:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=1.4320, batch_acc=0.4375, running_acc=0.6094]Evaluation epoch 5:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=1.4320, batch_acc=0.4375, running_acc=0.6094]Evaluation epoch 5:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=0.7395, batch_acc=0.8125, running_acc=0.6250]Evaluation epoch 5:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=0.7395, batch_acc=0.8125, running_acc=0.6250]Evaluation epoch 5:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=1.5390, batch_acc=0.6562, running_acc=0.6272]Evaluation epoch 5:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=1.5390, batch_acc=0.6562, running_acc=0.6272]Evaluation epoch 5:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=2.4096, batch_acc=0.3750, running_acc=0.6104]Evaluation epoch 5:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=2.4096, batch_acc=0.3750, running_acc=0.6104]Evaluation epoch 5:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=1.8085, batch_acc=0.4375, running_acc=0.5996]Evaluation epoch 5:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=1.8085, batch_acc=0.4375, running_acc=0.5996]Evaluation epoch 5:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=1.3279, batch_acc=0.4375, running_acc=0.5901]Evaluation epoch 5:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=1.3279, batch_acc=0.4375, running_acc=0.5901]Evaluation epoch 5:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.9860, batch_acc=0.5938, running_acc=0.5903]Evaluation epoch 5:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=0.9860, batch_acc=0.5938, running_acc=0.5903]Evaluation epoch 5:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=1.2020, batch_acc=0.6562, running_acc=0.5938]Evaluation epoch 5:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=1.2020, batch_acc=0.6562, running_acc=0.5938]Evaluation epoch 5:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=1.0460, batch_acc=0.7812, running_acc=0.6031]Evaluation epoch 5:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=1.0460, batch_acc=0.7812, running_acc=0.6031]Evaluation epoch 5:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=1.6772, batch_acc=0.5312, running_acc=0.5997]Evaluation epoch 5:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=1.6772, batch_acc=0.5312, running_acc=0.5997]Evaluation epoch 5:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=1.4742, batch_acc=0.5625, running_acc=0.5980]Evaluation epoch 5:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.4742, batch_acc=0.5625, running_acc=0.5980]Evaluation epoch 5:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.2779, batch_acc=0.6875, running_acc=0.6019]Evaluation epoch 5:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=1.2779, batch_acc=0.6875, running_acc=0.6019]Evaluation epoch 5:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=0.3776, batch_acc=0.9375, running_acc=0.6159]Evaluation epoch 5:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.3776, batch_acc=0.9375, running_acc=0.6159]Evaluation epoch 5:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=1.3369, batch_acc=0.5625, running_acc=0.6138]Evaluation epoch 5:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.3369, batch_acc=0.5625, running_acc=0.6138]Evaluation epoch 5:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.7248, batch_acc=0.5625, running_acc=0.6118]Evaluation epoch 5:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=1.7248, batch_acc=0.5625, running_acc=0.6118]Evaluation epoch 5:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=2.1646, batch_acc=0.2812, running_acc=0.5995]Evaluation epoch 5: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.5474, batch_acc=0.3333, running_acc=0.5986]Evaluation epoch 5: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=1.5474, batch_acc=0.3333, running_acc=0.5986]
Training epoch 6:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 6:   1%|          | 1/163 [00:05<15:14,  5.64s/it]Training epoch 6:   1%|          | 1/163 [00:05<15:14,  5.64s/it, loss=0.9662, batch_acc=0.6875, running_acc=0.6875, grad=6.5194]Training epoch 6:   1%|          | 2/163 [00:06<07:37,  2.84s/it, loss=0.9662, batch_acc=0.6875, running_acc=0.6875, grad=6.5194]Training epoch 6:   1%|          | 2/163 [00:06<07:37,  2.84s/it, loss=0.9336, batch_acc=0.7812, running_acc=0.7344, grad=8.5714]Training epoch 6:   2%|▏         | 3/163 [00:07<05:11,  1.95s/it, loss=0.9336, batch_acc=0.7812, running_acc=0.7344, grad=8.5714]Training epoch 6:   2%|▏         | 3/163 [00:07<05:11,  1.95s/it, loss=0.7961, batch_acc=0.7500, running_acc=0.7396, grad=5.9374]Training epoch 6:   2%|▏         | 4/163 [00:09<05:32,  2.09s/it, loss=0.7961, batch_acc=0.7500, running_acc=0.7396, grad=5.9374]Training epoch 6:   2%|▏         | 4/163 [00:09<05:32,  2.09s/it, loss=1.0463, batch_acc=0.7188, running_acc=0.7344, grad=6.6892]Training epoch 6:   3%|▎         | 5/163 [00:10<04:21,  1.65s/it, loss=1.0463, batch_acc=0.7188, running_acc=0.7344, grad=6.6892]Training epoch 6:   3%|▎         | 5/163 [00:10<04:21,  1.65s/it, loss=0.7014, batch_acc=0.8125, running_acc=0.7500, grad=7.6562]Training epoch 6:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=0.7014, batch_acc=0.8125, running_acc=0.7500, grad=7.6562]Training epoch 6:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=0.8721, batch_acc=0.7188, running_acc=0.7448, grad=6.5708]Training epoch 6:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=0.8721, batch_acc=0.7188, running_acc=0.7448, grad=6.5708]Training epoch 6:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=0.9206, batch_acc=0.7500, running_acc=0.7455, grad=8.1290]Training epoch 6:   5%|▍         | 8/163 [00:14<03:51,  1.50s/it, loss=0.9206, batch_acc=0.7500, running_acc=0.7455, grad=8.1290]Training epoch 6:   5%|▍         | 8/163 [00:14<03:51,  1.50s/it, loss=1.1508, batch_acc=0.7188, running_acc=0.7422, grad=8.0995]Training epoch 6:   6%|▌         | 9/163 [00:15<03:20,  1.30s/it, loss=1.1508, batch_acc=0.7188, running_acc=0.7422, grad=8.0995]Training epoch 6:   6%|▌         | 9/163 [00:15<03:20,  1.30s/it, loss=0.9436, batch_acc=0.7188, running_acc=0.7396, grad=8.9510]Training epoch 6:   6%|▌         | 10/163 [00:16<02:59,  1.17s/it, loss=0.9436, batch_acc=0.7188, running_acc=0.7396, grad=8.9510]Training epoch 6:   6%|▌         | 10/163 [00:16<02:59,  1.17s/it, loss=0.7287, batch_acc=0.8125, running_acc=0.7469, grad=5.5666]Training epoch 6:   7%|▋         | 11/163 [00:17<02:44,  1.08s/it, loss=0.7287, batch_acc=0.8125, running_acc=0.7469, grad=5.5666]Training epoch 6:   7%|▋         | 11/163 [00:17<02:44,  1.08s/it, loss=1.1114, batch_acc=0.6250, running_acc=0.7358, grad=6.4641]Training epoch 6:   7%|▋         | 12/163 [00:19<03:29,  1.39s/it, loss=1.1114, batch_acc=0.6250, running_acc=0.7358, grad=6.4641]Training epoch 6:   7%|▋         | 12/163 [00:19<03:29,  1.39s/it, loss=1.0896, batch_acc=0.6250, running_acc=0.7266, grad=7.7626]Training epoch 6:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=1.0896, batch_acc=0.6250, running_acc=0.7266, grad=7.7626]Training epoch 6:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.8532, batch_acc=0.8125, running_acc=0.7332, grad=5.9782]Training epoch 6:   9%|▊         | 14/163 [00:20<02:47,  1.13s/it, loss=0.8532, batch_acc=0.8125, running_acc=0.7332, grad=5.9782]Training epoch 6:   9%|▊         | 14/163 [00:20<02:47,  1.13s/it, loss=1.2983, batch_acc=0.5938, running_acc=0.7232, grad=8.7034]Training epoch 6:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=1.2983, batch_acc=0.5938, running_acc=0.7232, grad=8.7034]Training epoch 6:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.8351, batch_acc=0.7500, running_acc=0.7250, grad=6.5590]Training epoch 6:  10%|▉         | 16/163 [00:23<03:11,  1.31s/it, loss=0.8351, batch_acc=0.7500, running_acc=0.7250, grad=6.5590]Training epoch 6:  10%|▉         | 16/163 [00:23<03:11,  1.31s/it, loss=0.7570, batch_acc=0.8125, running_acc=0.7305, grad=4.8322]Training epoch 6:  10%|█         | 17/163 [00:24<02:51,  1.18s/it, loss=0.7570, batch_acc=0.8125, running_acc=0.7305, grad=4.8322]Training epoch 6:  10%|█         | 17/163 [00:24<02:51,  1.18s/it, loss=0.7131, batch_acc=0.8125, running_acc=0.7353, grad=6.0710]Training epoch 6:  11%|█         | 18/163 [00:25<02:37,  1.09s/it, loss=0.7131, batch_acc=0.8125, running_acc=0.7353, grad=6.0710]Training epoch 6:  11%|█         | 18/163 [00:25<02:37,  1.09s/it, loss=0.8570, batch_acc=0.7188, running_acc=0.7344, grad=6.2730]Training epoch 6:  12%|█▏        | 19/163 [00:26<02:27,  1.03s/it, loss=0.8570, batch_acc=0.7188, running_acc=0.7344, grad=6.2730]Training epoch 6:  12%|█▏        | 19/163 [00:26<02:27,  1.03s/it, loss=0.6882, batch_acc=0.8750, running_acc=0.7418, grad=6.3932]Training epoch 6:  12%|█▏        | 20/163 [00:27<02:53,  1.21s/it, loss=0.6882, batch_acc=0.8750, running_acc=0.7418, grad=6.3932]Training epoch 6:  12%|█▏        | 20/163 [00:27<02:53,  1.21s/it, loss=0.8301, batch_acc=0.8125, running_acc=0.7453, grad=7.3728]Training epoch 6:  13%|█▎        | 21/163 [00:28<02:38,  1.11s/it, loss=0.8301, batch_acc=0.8125, running_acc=0.7453, grad=7.3728]Training epoch 6:  13%|█▎        | 21/163 [00:28<02:38,  1.11s/it, loss=0.9090, batch_acc=0.7500, running_acc=0.7455, grad=4.7162]Training epoch 6:  13%|█▎        | 22/163 [00:29<02:32,  1.08s/it, loss=0.9090, batch_acc=0.7500, running_acc=0.7455, grad=4.7162]Training epoch 6:  13%|█▎        | 22/163 [00:29<02:32,  1.08s/it, loss=0.9420, batch_acc=0.6875, running_acc=0.7429, grad=7.2469]Training epoch 6:  14%|█▍        | 23/163 [00:30<02:22,  1.02s/it, loss=0.9420, batch_acc=0.6875, running_acc=0.7429, grad=7.2469]Training epoch 6:  14%|█▍        | 23/163 [00:30<02:22,  1.02s/it, loss=0.7502, batch_acc=0.8750, running_acc=0.7486, grad=5.1574]Training epoch 6:  15%|█▍        | 24/163 [00:32<02:44,  1.19s/it, loss=0.7502, batch_acc=0.8750, running_acc=0.7486, grad=5.1574]Training epoch 6:  15%|█▍        | 24/163 [00:32<02:44,  1.19s/it, loss=0.7277, batch_acc=0.8438, running_acc=0.7526, grad=5.7724]Training epoch 6:  15%|█▌        | 25/163 [00:33<02:31,  1.09s/it, loss=0.7277, batch_acc=0.8438, running_acc=0.7526, grad=5.7724]Training epoch 6:  15%|█▌        | 25/163 [00:33<02:31,  1.09s/it, loss=0.6596, batch_acc=0.8438, running_acc=0.7562, grad=6.0433]Training epoch 6:  16%|█▌        | 26/163 [00:34<02:41,  1.18s/it, loss=0.6596, batch_acc=0.8438, running_acc=0.7562, grad=6.0433]Training epoch 6:  16%|█▌        | 26/163 [00:34<02:41,  1.18s/it, loss=0.8029, batch_acc=0.7812, running_acc=0.7572, grad=7.2780]Training epoch 6:  17%|█▋        | 27/163 [00:35<02:27,  1.09s/it, loss=0.8029, batch_acc=0.7812, running_acc=0.7572, grad=7.2780]Training epoch 6:  17%|█▋        | 27/163 [00:35<02:27,  1.09s/it, loss=0.7664, batch_acc=0.7188, running_acc=0.7558, grad=5.2017]Training epoch 6:  17%|█▋        | 28/163 [00:36<02:37,  1.16s/it, loss=0.7664, batch_acc=0.7188, running_acc=0.7558, grad=5.2017]Training epoch 6:  17%|█▋        | 28/163 [00:36<02:37,  1.16s/it, loss=1.1647, batch_acc=0.6562, running_acc=0.7522, grad=9.3225]Training epoch 6:  18%|█▊        | 29/163 [00:37<02:24,  1.08s/it, loss=1.1647, batch_acc=0.6562, running_acc=0.7522, grad=9.3225]Training epoch 6:  18%|█▊        | 29/163 [00:37<02:24,  1.08s/it, loss=0.7837, batch_acc=0.7500, running_acc=0.7522, grad=5.9758]Training epoch 6:  18%|█▊        | 30/163 [00:39<02:34,  1.16s/it, loss=0.7837, batch_acc=0.7500, running_acc=0.7522, grad=5.9758]Training epoch 6:  18%|█▊        | 30/163 [00:39<02:34,  1.16s/it, loss=0.8303, batch_acc=0.8125, running_acc=0.7542, grad=6.1433]Training epoch 6:  19%|█▉        | 31/163 [00:39<02:22,  1.08s/it, loss=0.8303, batch_acc=0.8125, running_acc=0.7542, grad=6.1433]Training epoch 6:  19%|█▉        | 31/163 [00:39<02:22,  1.08s/it, loss=1.0523, batch_acc=0.7188, running_acc=0.7530, grad=6.1782]Training epoch 6:  20%|█▉        | 32/163 [00:40<02:13,  1.02s/it, loss=1.0523, batch_acc=0.7188, running_acc=0.7530, grad=6.1782]Training epoch 6:  20%|█▉        | 32/163 [00:40<02:13,  1.02s/it, loss=0.6082, batch_acc=0.8750, running_acc=0.7568, grad=5.6414]Training epoch 6:  20%|██        | 33/163 [00:41<02:07,  1.02it/s, loss=0.6082, batch_acc=0.8750, running_acc=0.7568, grad=5.6414]Training epoch 6:  20%|██        | 33/163 [00:41<02:07,  1.02it/s, loss=0.8326, batch_acc=0.7188, running_acc=0.7557, grad=11.3235]Training epoch 6:  21%|██        | 34/163 [00:43<02:39,  1.24s/it, loss=0.8326, batch_acc=0.7188, running_acc=0.7557, grad=11.3235]Training epoch 6:  21%|██        | 34/163 [00:43<02:39,  1.24s/it, loss=0.9426, batch_acc=0.6250, running_acc=0.7518, grad=7.2097] Training epoch 6:  21%|██▏       | 35/163 [00:44<02:24,  1.13s/it, loss=0.9426, batch_acc=0.6250, running_acc=0.7518, grad=7.2097]Training epoch 6:  21%|██▏       | 35/163 [00:44<02:24,  1.13s/it, loss=1.2183, batch_acc=0.6562, running_acc=0.7491, grad=9.2189]Training epoch 6:  22%|██▏       | 36/163 [00:45<02:13,  1.05s/it, loss=1.2183, batch_acc=0.6562, running_acc=0.7491, grad=9.2189]Training epoch 6:  22%|██▏       | 36/163 [00:45<02:13,  1.05s/it, loss=0.9085, batch_acc=0.7500, running_acc=0.7491, grad=8.4782]Training epoch 6:  23%|██▎       | 37/163 [00:46<02:10,  1.04s/it, loss=0.9085, batch_acc=0.7500, running_acc=0.7491, grad=8.4782]Training epoch 6:  23%|██▎       | 37/163 [00:46<02:10,  1.04s/it, loss=1.1678, batch_acc=0.7188, running_acc=0.7483, grad=5.6423]Training epoch 6:  23%|██▎       | 38/163 [00:47<02:32,  1.22s/it, loss=1.1678, batch_acc=0.7188, running_acc=0.7483, grad=5.6423]Training epoch 6:  23%|██▎       | 38/163 [00:47<02:32,  1.22s/it, loss=0.5014, batch_acc=0.8750, running_acc=0.7516, grad=5.3629]Training epoch 6:  24%|██▍       | 39/163 [00:48<02:18,  1.12s/it, loss=0.5014, batch_acc=0.8750, running_acc=0.7516, grad=5.3629]Training epoch 6:  24%|██▍       | 39/163 [00:48<02:18,  1.12s/it, loss=0.9099, batch_acc=0.7812, running_acc=0.7524, grad=8.4474]Training epoch 6:  25%|██▍       | 40/163 [00:49<02:08,  1.05s/it, loss=0.9099, batch_acc=0.7812, running_acc=0.7524, grad=8.4474]Training epoch 6:  25%|██▍       | 40/163 [00:49<02:08,  1.05s/it, loss=1.1662, batch_acc=0.6562, running_acc=0.7500, grad=8.9378]Training epoch 6:  25%|██▌       | 41/163 [00:50<02:01,  1.00it/s, loss=1.1662, batch_acc=0.6562, running_acc=0.7500, grad=8.9378]Training epoch 6:  25%|██▌       | 41/163 [00:50<02:01,  1.00it/s, loss=0.9110, batch_acc=0.7500, running_acc=0.7500, grad=7.4746]Training epoch 6:  26%|██▌       | 42/163 [00:52<02:23,  1.19s/it, loss=0.9110, batch_acc=0.7500, running_acc=0.7500, grad=7.4746]Training epoch 6:  26%|██▌       | 42/163 [00:52<02:23,  1.19s/it, loss=0.8813, batch_acc=0.7500, running_acc=0.7500, grad=6.9927]Training epoch 6:  26%|██▋       | 43/163 [00:53<02:11,  1.10s/it, loss=0.8813, batch_acc=0.7500, running_acc=0.7500, grad=6.9927]Training epoch 6:  26%|██▋       | 43/163 [00:53<02:11,  1.10s/it, loss=0.8366, batch_acc=0.7188, running_acc=0.7493, grad=7.4066]Training epoch 6:  27%|██▋       | 44/163 [00:53<02:02,  1.03s/it, loss=0.8366, batch_acc=0.7188, running_acc=0.7493, grad=7.4066]Training epoch 6:  27%|██▋       | 44/163 [00:53<02:02,  1.03s/it, loss=1.1229, batch_acc=0.6875, running_acc=0.7479, grad=8.9826]Training epoch 6:  28%|██▊       | 45/163 [00:54<01:56,  1.01it/s, loss=1.1229, batch_acc=0.6875, running_acc=0.7479, grad=8.9826]Training epoch 6:  28%|██▊       | 45/163 [00:54<01:56,  1.01it/s, loss=1.3901, batch_acc=0.5625, running_acc=0.7438, grad=12.5901]Training epoch 6:  28%|██▊       | 46/163 [00:56<02:26,  1.25s/it, loss=1.3901, batch_acc=0.5625, running_acc=0.7438, grad=12.5901]Training epoch 6:  28%|██▊       | 46/163 [00:56<02:26,  1.25s/it, loss=1.0782, batch_acc=0.6562, running_acc=0.7418, grad=7.6506] Training epoch 6:  29%|██▉       | 47/163 [00:57<02:12,  1.14s/it, loss=1.0782, batch_acc=0.6562, running_acc=0.7418, grad=7.6506]Training epoch 6:  29%|██▉       | 47/163 [00:57<02:12,  1.14s/it, loss=1.1905, batch_acc=0.7500, running_acc=0.7420, grad=10.1022]Training epoch 6:  29%|██▉       | 48/163 [00:58<02:02,  1.06s/it, loss=1.1905, batch_acc=0.7500, running_acc=0.7420, grad=10.1022]Training epoch 6:  29%|██▉       | 48/163 [00:58<02:02,  1.06s/it, loss=1.3813, batch_acc=0.5312, running_acc=0.7376, grad=9.6943] Training epoch 6:  30%|███       | 49/163 [00:59<01:54,  1.01s/it, loss=1.3813, batch_acc=0.5312, running_acc=0.7376, grad=9.6943]Training epoch 6:  30%|███       | 49/163 [00:59<01:54,  1.01s/it, loss=0.8078, batch_acc=0.7812, running_acc=0.7385, grad=10.1996]Training epoch 6:  31%|███       | 50/163 [01:01<02:25,  1.29s/it, loss=0.8078, batch_acc=0.7812, running_acc=0.7385, grad=10.1996]Training epoch 6:  31%|███       | 50/163 [01:01<02:25,  1.29s/it, loss=0.7583, batch_acc=0.8125, running_acc=0.7400, grad=7.5394] Training epoch 6:  31%|███▏      | 51/163 [01:02<02:10,  1.16s/it, loss=0.7583, batch_acc=0.8125, running_acc=0.7400, grad=7.5394]Training epoch 6:  31%|███▏      | 51/163 [01:02<02:10,  1.16s/it, loss=0.9986, batch_acc=0.6875, running_acc=0.7390, grad=8.2637]Training epoch 6:  32%|███▏      | 52/163 [01:03<01:59,  1.08s/it, loss=0.9986, batch_acc=0.6875, running_acc=0.7390, grad=8.2637]Training epoch 6:  32%|███▏      | 52/163 [01:03<01:59,  1.08s/it, loss=1.0480, batch_acc=0.6562, running_acc=0.7374, grad=9.4648]Training epoch 6:  33%|███▎      | 53/163 [01:03<01:52,  1.02s/it, loss=1.0480, batch_acc=0.6562, running_acc=0.7374, grad=9.4648]Training epoch 6:  33%|███▎      | 53/163 [01:03<01:52,  1.02s/it, loss=1.0065, batch_acc=0.5938, running_acc=0.7347, grad=10.5683]Training epoch 6:  33%|███▎      | 54/163 [01:06<02:29,  1.37s/it, loss=1.0065, batch_acc=0.5938, running_acc=0.7347, grad=10.5683]Training epoch 6:  33%|███▎      | 54/163 [01:06<02:29,  1.37s/it, loss=0.7792, batch_acc=0.6875, running_acc=0.7338, grad=7.0697] Training epoch 6:  34%|███▎      | 55/163 [01:06<02:12,  1.22s/it, loss=0.7792, batch_acc=0.6875, running_acc=0.7338, grad=7.0697]Training epoch 6:  34%|███▎      | 55/163 [01:06<02:12,  1.22s/it, loss=0.7255, batch_acc=0.8125, running_acc=0.7352, grad=6.5398]Training epoch 6:  34%|███▍      | 56/163 [01:07<01:59,  1.12s/it, loss=0.7255, batch_acc=0.8125, running_acc=0.7352, grad=6.5398]Training epoch 6:  34%|███▍      | 56/163 [01:07<01:59,  1.12s/it, loss=1.0406, batch_acc=0.7500, running_acc=0.7355, grad=7.6387]Training epoch 6:  35%|███▍      | 57/163 [01:08<01:51,  1.05s/it, loss=1.0406, batch_acc=0.7500, running_acc=0.7355, grad=7.6387]Training epoch 6:  35%|███▍      | 57/163 [01:08<01:51,  1.05s/it, loss=0.8809, batch_acc=0.7188, running_acc=0.7352, grad=7.8637]Training epoch 6:  36%|███▌      | 58/163 [01:10<02:07,  1.21s/it, loss=0.8809, batch_acc=0.7188, running_acc=0.7352, grad=7.8637]Training epoch 6:  36%|███▌      | 58/163 [01:10<02:07,  1.21s/it, loss=1.0076, batch_acc=0.7188, running_acc=0.7349, grad=6.5854]Training epoch 6:  36%|███▌      | 59/163 [01:11<01:55,  1.11s/it, loss=1.0076, batch_acc=0.7188, running_acc=0.7349, grad=6.5854]Training epoch 6:  36%|███▌      | 59/163 [01:11<01:55,  1.11s/it, loss=0.8760, batch_acc=0.7500, running_acc=0.7352, grad=6.0187]Training epoch 6:  37%|███▋      | 60/163 [01:12<01:47,  1.04s/it, loss=0.8760, batch_acc=0.7500, running_acc=0.7352, grad=6.0187]Training epoch 6:  37%|███▋      | 60/163 [01:12<01:47,  1.04s/it, loss=1.1851, batch_acc=0.6562, running_acc=0.7339, grad=7.1094]Training epoch 6:  37%|███▋      | 61/163 [01:12<01:41,  1.01it/s, loss=1.1851, batch_acc=0.6562, running_acc=0.7339, grad=7.1094]Training epoch 6:  37%|███▋      | 61/163 [01:12<01:41,  1.01it/s, loss=0.6365, batch_acc=0.8438, running_acc=0.7357, grad=6.3997]Training epoch 6:  38%|███▊      | 62/163 [01:14<01:57,  1.17s/it, loss=0.6365, batch_acc=0.8438, running_acc=0.7357, grad=6.3997]Training epoch 6:  38%|███▊      | 62/163 [01:14<01:57,  1.17s/it, loss=0.7703, batch_acc=0.7812, running_acc=0.7364, grad=5.9662]Training epoch 6:  39%|███▊      | 63/163 [01:15<01:48,  1.08s/it, loss=0.7703, batch_acc=0.7812, running_acc=0.7364, grad=5.9662]Training epoch 6:  39%|███▊      | 63/163 [01:15<01:48,  1.08s/it, loss=1.0311, batch_acc=0.6562, running_acc=0.7351, grad=8.3076]Training epoch 6:  39%|███▉      | 64/163 [01:16<01:41,  1.02s/it, loss=1.0311, batch_acc=0.6562, running_acc=0.7351, grad=8.3076]Training epoch 6:  39%|███▉      | 64/163 [01:16<01:41,  1.02s/it, loss=1.0762, batch_acc=0.8125, running_acc=0.7363, grad=6.1387]Training epoch 6:  40%|███▉      | 65/163 [01:17<01:35,  1.02it/s, loss=1.0762, batch_acc=0.8125, running_acc=0.7363, grad=6.1387]Training epoch 6:  40%|███▉      | 65/163 [01:17<01:35,  1.02it/s, loss=1.0368, batch_acc=0.6875, running_acc=0.7356, grad=7.5327]Training epoch 6:  40%|████      | 66/163 [01:19<01:59,  1.23s/it, loss=1.0368, batch_acc=0.6875, running_acc=0.7356, grad=7.5327]Training epoch 6:  40%|████      | 66/163 [01:19<01:59,  1.23s/it, loss=1.1128, batch_acc=0.7188, running_acc=0.7353, grad=7.8314]Training epoch 6:  41%|████      | 67/163 [01:19<01:47,  1.12s/it, loss=1.1128, batch_acc=0.7188, running_acc=0.7353, grad=7.8314]Training epoch 6:  41%|████      | 67/163 [01:19<01:47,  1.12s/it, loss=0.5733, batch_acc=0.8750, running_acc=0.7374, grad=4.3724]Training epoch 6:  42%|████▏     | 68/163 [01:20<01:39,  1.05s/it, loss=0.5733, batch_acc=0.8750, running_acc=0.7374, grad=4.3724]Training epoch 6:  42%|████▏     | 68/163 [01:20<01:39,  1.05s/it, loss=0.9386, batch_acc=0.7500, running_acc=0.7376, grad=6.4122]Training epoch 6:  42%|████▏     | 69/163 [01:21<01:33,  1.00it/s, loss=0.9386, batch_acc=0.7500, running_acc=0.7376, grad=6.4122]Training epoch 6:  42%|████▏     | 69/163 [01:21<01:33,  1.00it/s, loss=0.8365, batch_acc=0.7500, running_acc=0.7378, grad=6.3396]Training epoch 6:  43%|████▎     | 70/163 [01:23<02:00,  1.29s/it, loss=0.8365, batch_acc=0.7500, running_acc=0.7378, grad=6.3396]Training epoch 6:  43%|████▎     | 70/163 [01:23<02:00,  1.29s/it, loss=0.8955, batch_acc=0.7812, running_acc=0.7384, grad=6.2408]Training epoch 6:  44%|████▎     | 71/163 [01:24<01:47,  1.17s/it, loss=0.8955, batch_acc=0.7812, running_acc=0.7384, grad=6.2408]Training epoch 6:  44%|████▎     | 71/163 [01:24<01:47,  1.17s/it, loss=0.7088, batch_acc=0.7812, running_acc=0.7390, grad=7.2528]Training epoch 6:  44%|████▍     | 72/163 [01:25<01:38,  1.08s/it, loss=0.7088, batch_acc=0.7812, running_acc=0.7390, grad=7.2528]Training epoch 6:  44%|████▍     | 72/163 [01:25<01:38,  1.08s/it, loss=0.7961, batch_acc=0.7500, running_acc=0.7391, grad=8.3162]Training epoch 6:  45%|████▍     | 73/163 [01:26<01:31,  1.02s/it, loss=0.7961, batch_acc=0.7500, running_acc=0.7391, grad=8.3162]Training epoch 6:  45%|████▍     | 73/163 [01:26<01:31,  1.02s/it, loss=0.6125, batch_acc=0.8438, running_acc=0.7406, grad=4.9049]Training epoch 6:  45%|████▌     | 74/163 [01:27<01:47,  1.21s/it, loss=0.6125, batch_acc=0.8438, running_acc=0.7406, grad=4.9049]Training epoch 6:  45%|████▌     | 74/163 [01:27<01:47,  1.21s/it, loss=1.1442, batch_acc=0.6250, running_acc=0.7390, grad=7.5174]Training epoch 6:  46%|████▌     | 75/163 [01:28<01:37,  1.11s/it, loss=1.1442, batch_acc=0.6250, running_acc=0.7390, grad=7.5174]Training epoch 6:  46%|████▌     | 75/163 [01:28<01:37,  1.11s/it, loss=0.9606, batch_acc=0.6875, running_acc=0.7383, grad=7.2089]Training epoch 6:  47%|████▋     | 76/163 [01:29<01:30,  1.04s/it, loss=0.9606, batch_acc=0.6875, running_acc=0.7383, grad=7.2089]Training epoch 6:  47%|████▋     | 76/163 [01:29<01:30,  1.04s/it, loss=0.8806, batch_acc=0.6562, running_acc=0.7373, grad=7.6515]Training epoch 6:  47%|████▋     | 77/163 [01:30<01:25,  1.01it/s, loss=0.8806, batch_acc=0.6562, running_acc=0.7373, grad=7.6515]Training epoch 6:  47%|████▋     | 77/163 [01:30<01:25,  1.01it/s, loss=0.7129, batch_acc=0.7500, running_acc=0.7374, grad=7.4466]Training epoch 6:  48%|████▊     | 78/163 [01:32<01:36,  1.13s/it, loss=0.7129, batch_acc=0.7500, running_acc=0.7374, grad=7.4466]Training epoch 6:  48%|████▊     | 78/163 [01:32<01:36,  1.13s/it, loss=1.4131, batch_acc=0.5625, running_acc=0.7352, grad=8.7281]Training epoch 6:  48%|████▊     | 79/163 [01:32<01:28,  1.06s/it, loss=1.4131, batch_acc=0.5625, running_acc=0.7352, grad=8.7281]Training epoch 6:  48%|████▊     | 79/163 [01:32<01:28,  1.06s/it, loss=0.8040, batch_acc=0.7812, running_acc=0.7358, grad=8.3431]Training epoch 6:  49%|████▉     | 80/163 [01:33<01:23,  1.00s/it, loss=0.8040, batch_acc=0.7812, running_acc=0.7358, grad=8.3431]Training epoch 6:  49%|████▉     | 80/163 [01:33<01:23,  1.00s/it, loss=1.0041, batch_acc=0.7188, running_acc=0.7355, grad=7.3900]Training epoch 6:  50%|████▉     | 81/163 [01:34<01:19,  1.03it/s, loss=1.0041, batch_acc=0.7188, running_acc=0.7355, grad=7.3900]Training epoch 6:  50%|████▉     | 81/163 [01:34<01:19,  1.03it/s, loss=0.8141, batch_acc=0.7500, running_acc=0.7357, grad=5.8964]Training epoch 6:  50%|█████     | 82/163 [01:36<01:41,  1.25s/it, loss=0.8141, batch_acc=0.7500, running_acc=0.7357, grad=5.8964]Training epoch 6:  50%|█████     | 82/163 [01:36<01:41,  1.25s/it, loss=1.0711, batch_acc=0.6562, running_acc=0.7348, grad=7.8912]Training epoch 6:  51%|█████     | 83/163 [01:37<01:31,  1.14s/it, loss=1.0711, batch_acc=0.6562, running_acc=0.7348, grad=7.8912]Training epoch 6:  51%|█████     | 83/163 [01:37<01:31,  1.14s/it, loss=0.9864, batch_acc=0.7188, running_acc=0.7346, grad=9.3251]Training epoch 6:  52%|█████▏    | 84/163 [01:38<01:23,  1.06s/it, loss=0.9864, batch_acc=0.7188, running_acc=0.7346, grad=9.3251]Training epoch 6:  52%|█████▏    | 84/163 [01:38<01:23,  1.06s/it, loss=1.1150, batch_acc=0.6875, running_acc=0.7340, grad=8.5996]Training epoch 6:  52%|█████▏    | 85/163 [01:39<01:18,  1.01s/it, loss=1.1150, batch_acc=0.6875, running_acc=0.7340, grad=8.5996]Training epoch 6:  52%|█████▏    | 85/163 [01:39<01:18,  1.01s/it, loss=1.0556, batch_acc=0.7500, running_acc=0.7342, grad=8.1566]Training epoch 6:  53%|█████▎    | 86/163 [01:41<01:36,  1.26s/it, loss=1.0556, batch_acc=0.7500, running_acc=0.7342, grad=8.1566]Training epoch 6:  53%|█████▎    | 86/163 [01:41<01:36,  1.26s/it, loss=0.8447, batch_acc=0.7500, running_acc=0.7344, grad=7.7766]Training epoch 6:  53%|█████▎    | 87/163 [01:41<01:27,  1.15s/it, loss=0.8447, batch_acc=0.7500, running_acc=0.7344, grad=7.7766]Training epoch 6:  53%|█████▎    | 87/163 [01:41<01:27,  1.15s/it, loss=0.7940, batch_acc=0.8438, running_acc=0.7356, grad=6.9635]Training epoch 6:  54%|█████▍    | 88/163 [01:42<01:19,  1.07s/it, loss=0.7940, batch_acc=0.8438, running_acc=0.7356, grad=6.9635]Training epoch 6:  54%|█████▍    | 88/163 [01:42<01:19,  1.07s/it, loss=0.8117, batch_acc=0.7188, running_acc=0.7354, grad=7.4782]Training epoch 6:  55%|█████▍    | 89/163 [01:43<01:14,  1.01s/it, loss=0.8117, batch_acc=0.7188, running_acc=0.7354, grad=7.4782]Training epoch 6:  55%|█████▍    | 89/163 [01:43<01:14,  1.01s/it, loss=1.2141, batch_acc=0.5938, running_acc=0.7338, grad=13.6878]Training epoch 6:  55%|█████▌    | 90/163 [01:45<01:21,  1.12s/it, loss=1.2141, batch_acc=0.5938, running_acc=0.7338, grad=13.6878]Training epoch 6:  55%|█████▌    | 90/163 [01:45<01:21,  1.12s/it, loss=1.0837, batch_acc=0.7188, running_acc=0.7337, grad=8.9979] Training epoch 6:  56%|█████▌    | 91/163 [01:45<01:15,  1.05s/it, loss=1.0837, batch_acc=0.7188, running_acc=0.7337, grad=8.9979]Training epoch 6:  56%|█████▌    | 91/163 [01:45<01:15,  1.05s/it, loss=0.6325, batch_acc=0.7812, running_acc=0.7342, grad=6.6063]Training epoch 6:  56%|█████▋    | 92/163 [01:46<01:10,  1.00it/s, loss=0.6325, batch_acc=0.7812, running_acc=0.7342, grad=6.6063]Training epoch 6:  56%|█████▋    | 92/163 [01:46<01:10,  1.00it/s, loss=0.6748, batch_acc=0.8125, running_acc=0.7351, grad=6.7929]Training epoch 6:  57%|█████▋    | 93/163 [01:47<01:07,  1.04it/s, loss=0.6748, batch_acc=0.8125, running_acc=0.7351, grad=6.7929]Training epoch 6:  57%|█████▋    | 93/163 [01:47<01:07,  1.04it/s, loss=1.1997, batch_acc=0.5938, running_acc=0.7335, grad=7.9265]Training epoch 6:  58%|█████▊    | 94/163 [01:49<01:25,  1.25s/it, loss=1.1997, batch_acc=0.5938, running_acc=0.7335, grad=7.9265]Training epoch 6:  58%|█████▊    | 94/163 [01:49<01:25,  1.25s/it, loss=0.7458, batch_acc=0.8438, running_acc=0.7347, grad=7.5616]Training epoch 6:  58%|█████▊    | 95/163 [01:50<01:17,  1.14s/it, loss=0.7458, batch_acc=0.8438, running_acc=0.7347, grad=7.5616]Training epoch 6:  58%|█████▊    | 95/163 [01:50<01:17,  1.14s/it, loss=0.6368, batch_acc=0.7500, running_acc=0.7349, grad=6.5317]Training epoch 6:  59%|█████▉    | 96/163 [01:51<01:10,  1.06s/it, loss=0.6368, batch_acc=0.7500, running_acc=0.7349, grad=6.5317]Training epoch 6:  59%|█████▉    | 96/163 [01:51<01:10,  1.06s/it, loss=1.4423, batch_acc=0.7500, running_acc=0.7350, grad=7.0702]Training epoch 6:  60%|█████▉    | 97/163 [01:52<01:06,  1.00s/it, loss=1.4423, batch_acc=0.7500, running_acc=0.7350, grad=7.0702]Training epoch 6:  60%|█████▉    | 97/163 [01:52<01:06,  1.00s/it, loss=0.8503, batch_acc=0.7500, running_acc=0.7352, grad=7.7199]Training epoch 6:  60%|██████    | 98/163 [01:53<01:04,  1.01it/s, loss=0.8503, batch_acc=0.7500, running_acc=0.7352, grad=7.7199]Training epoch 6:  60%|██████    | 98/163 [01:53<01:04,  1.01it/s, loss=1.0954, batch_acc=0.6250, running_acc=0.7341, grad=11.7680]Training epoch 6:  61%|██████    | 99/163 [01:54<01:01,  1.04it/s, loss=1.0954, batch_acc=0.6250, running_acc=0.7341, grad=11.7680]Training epoch 6:  61%|██████    | 99/163 [01:54<01:01,  1.04it/s, loss=1.2392, batch_acc=0.6250, running_acc=0.7330, grad=8.2311] Training epoch 6:  61%|██████▏   | 100/163 [01:54<00:58,  1.07it/s, loss=1.2392, batch_acc=0.6250, running_acc=0.7330, grad=8.2311]Training epoch 6:  61%|██████▏   | 100/163 [01:54<00:58,  1.07it/s, loss=0.8980, batch_acc=0.6562, running_acc=0.7322, grad=9.0595]Training epoch 6:  62%|██████▏   | 101/163 [01:55<00:56,  1.09it/s, loss=0.8980, batch_acc=0.6562, running_acc=0.7322, grad=9.0595]Training epoch 6:  62%|██████▏   | 101/163 [01:55<00:56,  1.09it/s, loss=0.7034, batch_acc=0.7500, running_acc=0.7324, grad=4.9801]Training epoch 6:  63%|██████▎   | 102/163 [01:58<01:19,  1.30s/it, loss=0.7034, batch_acc=0.7500, running_acc=0.7324, grad=4.9801]Training epoch 6:  63%|██████▎   | 102/163 [01:58<01:19,  1.30s/it, loss=0.8021, batch_acc=0.8125, running_acc=0.7331, grad=6.8176]Training epoch 6:  63%|██████▎   | 103/163 [01:58<01:10,  1.17s/it, loss=0.8021, batch_acc=0.8125, running_acc=0.7331, grad=6.8176]Training epoch 6:  63%|██████▎   | 103/163 [01:58<01:10,  1.17s/it, loss=0.6733, batch_acc=0.8125, running_acc=0.7339, grad=7.1202]Training epoch 6:  64%|██████▍   | 104/163 [01:59<01:03,  1.08s/it, loss=0.6733, batch_acc=0.8125, running_acc=0.7339, grad=7.1202]Training epoch 6:  64%|██████▍   | 104/163 [01:59<01:03,  1.08s/it, loss=1.4455, batch_acc=0.6562, running_acc=0.7332, grad=9.8131]Training epoch 6:  64%|██████▍   | 105/163 [02:00<00:59,  1.02s/it, loss=1.4455, batch_acc=0.6562, running_acc=0.7332, grad=9.8131]Training epoch 6:  64%|██████▍   | 105/163 [02:00<00:59,  1.02s/it, loss=0.5609, batch_acc=0.8750, running_acc=0.7345, grad=4.8885]Training epoch 6:  65%|██████▌   | 106/163 [02:02<01:03,  1.12s/it, loss=0.5609, batch_acc=0.8750, running_acc=0.7345, grad=4.8885]Training epoch 6:  65%|██████▌   | 106/163 [02:02<01:03,  1.12s/it, loss=1.0706, batch_acc=0.6562, running_acc=0.7338, grad=8.0661]Training epoch 6:  66%|██████▌   | 107/163 [02:02<00:58,  1.05s/it, loss=1.0706, batch_acc=0.6562, running_acc=0.7338, grad=8.0661]Training epoch 6:  66%|██████▌   | 107/163 [02:02<00:58,  1.05s/it, loss=0.8705, batch_acc=0.7812, running_acc=0.7342, grad=6.5653]Training epoch 6:  66%|██████▋   | 108/163 [02:03<00:54,  1.00it/s, loss=0.8705, batch_acc=0.7812, running_acc=0.7342, grad=6.5653]Training epoch 6:  66%|██████▋   | 108/163 [02:03<00:54,  1.00it/s, loss=0.8116, batch_acc=0.7812, running_acc=0.7347, grad=6.5408]Training epoch 6:  67%|██████▋   | 109/163 [02:04<00:51,  1.04it/s, loss=0.8116, batch_acc=0.7812, running_acc=0.7347, grad=6.5408]Training epoch 6:  67%|██████▋   | 109/163 [02:04<00:51,  1.04it/s, loss=0.5485, batch_acc=0.8125, running_acc=0.7354, grad=5.3772]Training epoch 6:  67%|██████▋   | 110/163 [02:06<01:00,  1.14s/it, loss=0.5485, batch_acc=0.8125, running_acc=0.7354, grad=5.3772]Training epoch 6:  67%|██████▋   | 110/163 [02:06<01:00,  1.14s/it, loss=0.9165, batch_acc=0.6562, running_acc=0.7347, grad=7.3421]Training epoch 6:  68%|██████▊   | 111/163 [02:07<00:55,  1.06s/it, loss=0.9165, batch_acc=0.6562, running_acc=0.7347, grad=7.3421]Training epoch 6:  68%|██████▊   | 111/163 [02:07<00:55,  1.06s/it, loss=1.1279, batch_acc=0.6250, running_acc=0.7337, grad=8.3437]Training epoch 6:  69%|██████▊   | 112/163 [02:07<00:51,  1.01s/it, loss=1.1279, batch_acc=0.6250, running_acc=0.7337, grad=8.3437]Training epoch 6:  69%|██████▊   | 112/163 [02:07<00:51,  1.01s/it, loss=1.4234, batch_acc=0.5938, running_acc=0.7324, grad=10.2023]Training epoch 6:  69%|██████▉   | 113/163 [02:08<00:48,  1.03it/s, loss=1.4234, batch_acc=0.5938, running_acc=0.7324, grad=10.2023]Training epoch 6:  69%|██████▉   | 113/163 [02:08<00:48,  1.03it/s, loss=0.9634, batch_acc=0.7188, running_acc=0.7323, grad=7.2941] Training epoch 6:  70%|██████▉   | 114/163 [02:10<01:00,  1.23s/it, loss=0.9634, batch_acc=0.7188, running_acc=0.7323, grad=7.2941]Training epoch 6:  70%|██████▉   | 114/163 [02:10<01:00,  1.23s/it, loss=0.7894, batch_acc=0.7812, running_acc=0.7327, grad=10.8568]Training epoch 6:  71%|███████   | 115/163 [02:11<00:54,  1.13s/it, loss=0.7894, batch_acc=0.7812, running_acc=0.7327, grad=10.8568]Training epoch 6:  71%|███████   | 115/163 [02:11<00:54,  1.13s/it, loss=1.0110, batch_acc=0.8125, running_acc=0.7334, grad=9.8475] Training epoch 6:  71%|███████   | 116/163 [02:12<00:49,  1.05s/it, loss=1.0110, batch_acc=0.8125, running_acc=0.7334, grad=9.8475]Training epoch 6:  71%|███████   | 116/163 [02:12<00:49,  1.05s/it, loss=0.9388, batch_acc=0.7812, running_acc=0.7338, grad=10.5996]Training epoch 6:  72%|███████▏  | 117/163 [02:13<00:45,  1.00it/s, loss=0.9388, batch_acc=0.7812, running_acc=0.7338, grad=10.5996]Training epoch 6:  72%|███████▏  | 117/163 [02:13<00:45,  1.00it/s, loss=0.7056, batch_acc=0.7812, running_acc=0.7342, grad=6.7538] Training epoch 6:  72%|███████▏  | 118/163 [02:14<00:48,  1.09s/it, loss=0.7056, batch_acc=0.7812, running_acc=0.7342, grad=6.7538]Training epoch 6:  72%|███████▏  | 118/163 [02:14<00:48,  1.09s/it, loss=0.9615, batch_acc=0.6875, running_acc=0.7338, grad=6.6877]Training epoch 6:  73%|███████▎  | 119/163 [02:15<00:45,  1.02s/it, loss=0.9615, batch_acc=0.6875, running_acc=0.7338, grad=6.6877]Training epoch 6:  73%|███████▎  | 119/163 [02:15<00:45,  1.02s/it, loss=0.9441, batch_acc=0.7500, running_acc=0.7340, grad=6.5130]Training epoch 6:  74%|███████▎  | 120/163 [02:16<00:42,  1.02it/s, loss=0.9441, batch_acc=0.7500, running_acc=0.7340, grad=6.5130]Training epoch 6:  74%|███████▎  | 120/163 [02:16<00:42,  1.02it/s, loss=0.7397, batch_acc=0.7500, running_acc=0.7341, grad=8.5076]Training epoch 6:  74%|███████▍  | 121/163 [02:17<00:39,  1.05it/s, loss=0.7397, batch_acc=0.7500, running_acc=0.7341, grad=8.5076]Training epoch 6:  74%|███████▍  | 121/163 [02:17<00:39,  1.05it/s, loss=0.7185, batch_acc=0.7812, running_acc=0.7345, grad=8.7796]Training epoch 6:  75%|███████▍  | 122/163 [02:18<00:46,  1.14s/it, loss=0.7185, batch_acc=0.7812, running_acc=0.7345, grad=8.7796]Training epoch 6:  75%|███████▍  | 122/163 [02:18<00:46,  1.14s/it, loss=0.6770, batch_acc=0.8125, running_acc=0.7351, grad=7.2324]Training epoch 6:  75%|███████▌  | 123/163 [02:19<00:42,  1.06s/it, loss=0.6770, batch_acc=0.8125, running_acc=0.7351, grad=7.2324]Training epoch 6:  75%|███████▌  | 123/163 [02:19<00:42,  1.06s/it, loss=0.9130, batch_acc=0.6875, running_acc=0.7348, grad=6.7427]Training epoch 6:  76%|███████▌  | 124/163 [02:20<00:39,  1.01s/it, loss=0.9130, batch_acc=0.6875, running_acc=0.7348, grad=6.7427]Training epoch 6:  76%|███████▌  | 124/163 [02:20<00:39,  1.01s/it, loss=0.6714, batch_acc=0.8438, running_acc=0.7356, grad=6.1644]Training epoch 6:  77%|███████▋  | 125/163 [02:21<00:36,  1.03it/s, loss=0.6714, batch_acc=0.8438, running_acc=0.7356, grad=6.1644]Training epoch 6:  77%|███████▋  | 125/163 [02:21<00:36,  1.03it/s, loss=0.6014, batch_acc=0.9062, running_acc=0.7370, grad=4.8856]Training epoch 6:  77%|███████▋  | 126/163 [02:23<00:46,  1.26s/it, loss=0.6014, batch_acc=0.9062, running_acc=0.7370, grad=4.8856]Training epoch 6:  77%|███████▋  | 126/163 [02:23<00:46,  1.26s/it, loss=1.2134, batch_acc=0.6562, running_acc=0.7364, grad=9.0018]Training epoch 6:  78%|███████▊  | 127/163 [02:24<00:41,  1.15s/it, loss=1.2134, batch_acc=0.6562, running_acc=0.7364, grad=9.0018]Training epoch 6:  78%|███████▊  | 127/163 [02:24<00:41,  1.15s/it, loss=0.7440, batch_acc=0.8438, running_acc=0.7372, grad=7.6906]Training epoch 6:  79%|███████▊  | 128/163 [02:25<00:37,  1.07s/it, loss=0.7440, batch_acc=0.8438, running_acc=0.7372, grad=7.6906]Training epoch 6:  79%|███████▊  | 128/163 [02:25<00:37,  1.07s/it, loss=1.1472, batch_acc=0.6875, running_acc=0.7368, grad=9.8557]Training epoch 6:  79%|███████▉  | 129/163 [02:26<00:34,  1.01s/it, loss=1.1472, batch_acc=0.6875, running_acc=0.7368, grad=9.8557]Training epoch 6:  79%|███████▉  | 129/163 [02:26<00:34,  1.01s/it, loss=0.9454, batch_acc=0.7188, running_acc=0.7367, grad=7.9989]Training epoch 6:  80%|███████▉  | 130/163 [02:28<00:43,  1.32s/it, loss=0.9454, batch_acc=0.7188, running_acc=0.7367, grad=7.9989]Training epoch 6:  80%|███████▉  | 130/163 [02:28<00:43,  1.32s/it, loss=0.7232, batch_acc=0.8125, running_acc=0.7373, grad=8.0615]Training epoch 6:  80%|████████  | 131/163 [02:28<00:37,  1.19s/it, loss=0.7232, batch_acc=0.8125, running_acc=0.7373, grad=8.0615]Training epoch 6:  80%|████████  | 131/163 [02:28<00:37,  1.19s/it, loss=0.9195, batch_acc=0.7812, running_acc=0.7376, grad=6.4287]Training epoch 6:  81%|████████  | 132/163 [02:29<00:33,  1.09s/it, loss=0.9195, batch_acc=0.7812, running_acc=0.7376, grad=6.4287]Training epoch 6:  81%|████████  | 132/163 [02:29<00:33,  1.09s/it, loss=0.7153, batch_acc=0.8750, running_acc=0.7386, grad=6.3325]Training epoch 6:  82%|████████▏ | 133/163 [02:30<00:30,  1.03s/it, loss=0.7153, batch_acc=0.8750, running_acc=0.7386, grad=6.3325]Training epoch 6:  82%|████████▏ | 133/163 [02:30<00:30,  1.03s/it, loss=0.7153, batch_acc=0.8438, running_acc=0.7394, grad=7.2446]Training epoch 6:  82%|████████▏ | 134/163 [02:32<00:39,  1.35s/it, loss=0.7153, batch_acc=0.8438, running_acc=0.7394, grad=7.2446]Training epoch 6:  82%|████████▏ | 134/163 [02:32<00:39,  1.35s/it, loss=1.0627, batch_acc=0.6875, running_acc=0.7390, grad=8.1414]Training epoch 6:  83%|████████▎ | 135/163 [02:33<00:33,  1.21s/it, loss=1.0627, batch_acc=0.6875, running_acc=0.7390, grad=8.1414]Training epoch 6:  83%|████████▎ | 135/163 [02:33<00:33,  1.21s/it, loss=1.0511, batch_acc=0.6875, running_acc=0.7387, grad=10.5434]Training epoch 6:  83%|████████▎ | 136/163 [02:34<00:29,  1.11s/it, loss=1.0511, batch_acc=0.6875, running_acc=0.7387, grad=10.5434]Training epoch 6:  83%|████████▎ | 136/163 [02:34<00:29,  1.11s/it, loss=0.9621, batch_acc=0.6250, running_acc=0.7378, grad=6.9686] Training epoch 6:  84%|████████▍ | 137/163 [02:35<00:27,  1.04s/it, loss=0.9621, batch_acc=0.6250, running_acc=0.7378, grad=6.9686]Training epoch 6:  84%|████████▍ | 137/163 [02:35<00:27,  1.04s/it, loss=1.0719, batch_acc=0.6562, running_acc=0.7372, grad=9.1931]Training epoch 6:  85%|████████▍ | 138/163 [02:37<00:32,  1.31s/it, loss=1.0719, batch_acc=0.6562, running_acc=0.7372, grad=9.1931]Training epoch 6:  85%|████████▍ | 138/163 [02:37<00:32,  1.31s/it, loss=0.6278, batch_acc=0.8125, running_acc=0.7378, grad=6.7241]Training epoch 6:  85%|████████▌ | 139/163 [02:38<00:28,  1.18s/it, loss=0.6278, batch_acc=0.8125, running_acc=0.7378, grad=6.7241]Training epoch 6:  85%|████████▌ | 139/163 [02:38<00:28,  1.18s/it, loss=0.4733, batch_acc=0.8750, running_acc=0.7388, grad=6.2985]Training epoch 6:  86%|████████▌ | 140/163 [02:39<00:25,  1.09s/it, loss=0.4733, batch_acc=0.8750, running_acc=0.7388, grad=6.2985]Training epoch 6:  86%|████████▌ | 140/163 [02:39<00:25,  1.09s/it, loss=0.6965, batch_acc=0.7812, running_acc=0.7391, grad=8.8139]Training epoch 6:  87%|████████▋ | 141/163 [02:40<00:22,  1.03s/it, loss=0.6965, batch_acc=0.7812, running_acc=0.7391, grad=8.8139]Training epoch 6:  87%|████████▋ | 141/163 [02:40<00:22,  1.03s/it, loss=0.8813, batch_acc=0.7188, running_acc=0.7389, grad=10.5612]Training epoch 6:  87%|████████▋ | 142/163 [02:42<00:28,  1.38s/it, loss=0.8813, batch_acc=0.7188, running_acc=0.7389, grad=10.5612]Training epoch 6:  87%|████████▋ | 142/163 [02:42<00:28,  1.38s/it, loss=1.2074, batch_acc=0.7188, running_acc=0.7388, grad=10.5887]Training epoch 6:  88%|████████▊ | 143/163 [02:43<00:24,  1.23s/it, loss=1.2074, batch_acc=0.7188, running_acc=0.7388, grad=10.5887]Training epoch 6:  88%|████████▊ | 143/163 [02:43<00:24,  1.23s/it, loss=0.9012, batch_acc=0.7188, running_acc=0.7386, grad=8.0708] Training epoch 6:  88%|████████▊ | 144/163 [02:43<00:21,  1.12s/it, loss=0.9012, batch_acc=0.7188, running_acc=0.7386, grad=8.0708]Training epoch 6:  88%|████████▊ | 144/163 [02:43<00:21,  1.12s/it, loss=0.7409, batch_acc=0.8125, running_acc=0.7391, grad=6.6101]Training epoch 6:  89%|████████▉ | 145/163 [02:44<00:18,  1.05s/it, loss=0.7409, batch_acc=0.8125, running_acc=0.7391, grad=6.6101]Training epoch 6:  89%|████████▉ | 145/163 [02:44<00:18,  1.05s/it, loss=0.4664, batch_acc=0.9375, running_acc=0.7405, grad=5.4630]Training epoch 6:  90%|████████▉ | 146/163 [02:46<00:20,  1.21s/it, loss=0.4664, batch_acc=0.9375, running_acc=0.7405, grad=5.4630]Training epoch 6:  90%|████████▉ | 146/163 [02:46<00:20,  1.21s/it, loss=0.6801, batch_acc=0.7812, running_acc=0.7408, grad=5.8606]Training epoch 6:  90%|█████████ | 147/163 [02:47<00:17,  1.11s/it, loss=0.6801, batch_acc=0.7812, running_acc=0.7408, grad=5.8606]Training epoch 6:  90%|█████████ | 147/163 [02:47<00:17,  1.11s/it, loss=0.7605, batch_acc=0.7812, running_acc=0.7411, grad=6.6231]Training epoch 6:  91%|█████████ | 148/163 [02:48<00:15,  1.04s/it, loss=0.7605, batch_acc=0.7812, running_acc=0.7411, grad=6.6231]Training epoch 6:  91%|█████████ | 148/163 [02:48<00:15,  1.04s/it, loss=1.1321, batch_acc=0.5938, running_acc=0.7401, grad=9.1700]Training epoch 6:  91%|█████████▏| 149/163 [02:49<00:13,  1.01it/s, loss=1.1321, batch_acc=0.5938, running_acc=0.7401, grad=9.1700]Training epoch 6:  91%|█████████▏| 149/163 [02:49<00:13,  1.01it/s, loss=0.6147, batch_acc=0.8438, running_acc=0.7408, grad=5.4755]Training epoch 6:  92%|█████████▏| 150/163 [02:50<00:14,  1.14s/it, loss=0.6147, batch_acc=0.8438, running_acc=0.7408, grad=5.4755]Training epoch 6:  92%|█████████▏| 150/163 [02:50<00:14,  1.14s/it, loss=1.0369, batch_acc=0.6875, running_acc=0.7404, grad=8.4181]Training epoch 6:  93%|█████████▎| 151/163 [02:51<00:12,  1.06s/it, loss=1.0369, batch_acc=0.6875, running_acc=0.7404, grad=8.4181]Training epoch 6:  93%|█████████▎| 151/163 [02:51<00:12,  1.06s/it, loss=0.8279, batch_acc=0.8438, running_acc=0.7411, grad=9.1184]Training epoch 6:  93%|█████████▎| 152/163 [02:52<00:11,  1.00s/it, loss=0.8279, batch_acc=0.8438, running_acc=0.7411, grad=9.1184]Training epoch 6:  93%|█████████▎| 152/163 [02:52<00:11,  1.00s/it, loss=1.2910, batch_acc=0.6875, running_acc=0.7407, grad=7.6487]Training epoch 6:  94%|█████████▍| 153/163 [02:53<00:09,  1.03it/s, loss=1.2910, batch_acc=0.6875, running_acc=0.7407, grad=7.6487]Training epoch 6:  94%|█████████▍| 153/163 [02:53<00:09,  1.03it/s, loss=1.0137, batch_acc=0.7812, running_acc=0.7410, grad=9.1086]Training epoch 6:  94%|█████████▍| 154/163 [02:55<00:11,  1.26s/it, loss=1.0137, batch_acc=0.7812, running_acc=0.7410, grad=9.1086]Training epoch 6:  94%|█████████▍| 154/163 [02:55<00:11,  1.26s/it, loss=0.7336, batch_acc=0.8125, running_acc=0.7415, grad=9.1968]Training epoch 6:  95%|█████████▌| 155/163 [02:56<00:09,  1.14s/it, loss=0.7336, batch_acc=0.8125, running_acc=0.7415, grad=9.1968]Training epoch 6:  95%|█████████▌| 155/163 [02:56<00:09,  1.14s/it, loss=0.6403, batch_acc=0.9062, running_acc=0.7425, grad=5.6766]Training epoch 6:  96%|█████████▌| 156/163 [02:56<00:07,  1.06s/it, loss=0.6403, batch_acc=0.9062, running_acc=0.7425, grad=5.6766]Training epoch 6:  96%|█████████▌| 156/163 [02:56<00:07,  1.06s/it, loss=0.9297, batch_acc=0.7188, running_acc=0.7424, grad=7.1416]Training epoch 6:  96%|█████████▋| 157/163 [02:57<00:06,  1.01s/it, loss=0.9297, batch_acc=0.7188, running_acc=0.7424, grad=7.1416]Training epoch 6:  96%|█████████▋| 157/163 [02:57<00:06,  1.01s/it, loss=1.0907, batch_acc=0.7500, running_acc=0.7424, grad=9.1178]Training epoch 6:  97%|█████████▋| 158/163 [02:59<00:06,  1.25s/it, loss=1.0907, batch_acc=0.7500, running_acc=0.7424, grad=9.1178]Training epoch 6:  97%|█████████▋| 158/163 [02:59<00:06,  1.25s/it, loss=0.8670, batch_acc=0.6562, running_acc=0.7419, grad=6.3605]Training epoch 6:  98%|█████████▊| 159/163 [03:00<00:04,  1.14s/it, loss=0.8670, batch_acc=0.6562, running_acc=0.7419, grad=6.3605]Training epoch 6:  98%|█████████▊| 159/163 [03:00<00:04,  1.14s/it, loss=1.0351, batch_acc=0.5938, running_acc=0.7410, grad=8.8435]Training epoch 6:  98%|█████████▊| 160/163 [03:01<00:03,  1.06s/it, loss=1.0351, batch_acc=0.5938, running_acc=0.7410, grad=8.8435]Training epoch 6:  98%|█████████▊| 160/163 [03:01<00:03,  1.06s/it, loss=1.1774, batch_acc=0.6875, running_acc=0.7406, grad=7.3363]Training epoch 6:  99%|█████████▉| 161/163 [03:02<00:02,  1.01s/it, loss=1.1774, batch_acc=0.6875, running_acc=0.7406, grad=7.3363]Training epoch 6:  99%|█████████▉| 161/163 [03:02<00:02,  1.01s/it, loss=0.7703, batch_acc=0.8438, running_acc=0.7413, grad=7.4249]Training epoch 6:  99%|█████████▉| 162/163 [03:03<00:00,  1.03it/s, loss=0.7703, batch_acc=0.8438, running_acc=0.7413, grad=7.4249]Training epoch 6:  99%|█████████▉| 162/163 [03:03<00:00,  1.03it/s, loss=1.0029, batch_acc=0.5625, running_acc=0.7402, grad=9.0075]Training epoch 6: 100%|██████████| 163/163 [03:03<00:00,  1.15it/s, loss=1.0029, batch_acc=0.5625, running_acc=0.7402, grad=9.0075]Training epoch 6: 100%|██████████| 163/163 [03:03<00:00,  1.15it/s, loss=0.8417, batch_acc=0.8095, running_acc=0.7404, grad=9.0295]Training epoch 6: 100%|██████████| 163/163 [03:03<00:00,  1.13s/it, loss=0.8417, batch_acc=0.8095, running_acc=0.7404, grad=9.0295]
Evaluation epoch 6:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 6:   4%|▎         | 1/28 [00:05<02:16,  5.06s/it]Evaluation epoch 6:   4%|▎         | 1/28 [00:05<02:16,  5.06s/it, loss=1.0162, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 6:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=1.0162, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 6:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=0.7754, batch_acc=0.7812, running_acc=0.7031]Evaluation epoch 6:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.7754, batch_acc=0.7812, running_acc=0.7031]Evaluation epoch 6:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=1.1577, batch_acc=0.7188, running_acc=0.7083]Evaluation epoch 6:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=1.1577, batch_acc=0.7188, running_acc=0.7083]Evaluation epoch 6:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=1.8282, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 6:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.8282, batch_acc=0.5000, running_acc=0.6562]Evaluation epoch 6:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=2.3641, batch_acc=0.2500, running_acc=0.5750]Evaluation epoch 6:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=2.3641, batch_acc=0.2500, running_acc=0.5750]Evaluation epoch 6:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.1663, batch_acc=0.5938, running_acc=0.5781]Evaluation epoch 6:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=1.1663, batch_acc=0.5938, running_acc=0.5781]Evaluation epoch 6:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.8649, batch_acc=0.8438, running_acc=0.6161]Evaluation epoch 6:  29%|██▊       | 8/28 [00:14<00:33,  1.66s/it, loss=0.8649, batch_acc=0.8438, running_acc=0.6161]Evaluation epoch 6:  29%|██▊       | 8/28 [00:14<00:33,  1.66s/it, loss=0.7093, batch_acc=0.7812, running_acc=0.6367]Evaluation epoch 6:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=0.7093, batch_acc=0.7812, running_acc=0.6367]Evaluation epoch 6:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=1.2941, batch_acc=0.6250, running_acc=0.6354]Evaluation epoch 6:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=1.2941, batch_acc=0.6250, running_acc=0.6354]Evaluation epoch 6:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.9846, batch_acc=0.7500, running_acc=0.6469]Evaluation epoch 6:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=0.9846, batch_acc=0.7500, running_acc=0.6469]Evaluation epoch 6:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=1.5614, batch_acc=0.5938, running_acc=0.6420]Evaluation epoch 6:  43%|████▎     | 12/28 [00:20<00:34,  2.19s/it, loss=1.5614, batch_acc=0.5938, running_acc=0.6420]Evaluation epoch 6:  43%|████▎     | 12/28 [00:20<00:34,  2.19s/it, loss=1.1078, batch_acc=0.6562, running_acc=0.6432]Evaluation epoch 6:  46%|████▋     | 13/28 [00:20<00:24,  1.60s/it, loss=1.1078, batch_acc=0.6562, running_acc=0.6432]Evaluation epoch 6:  46%|████▋     | 13/28 [00:20<00:24,  1.60s/it, loss=1.2117, batch_acc=0.6875, running_acc=0.6466]Evaluation epoch 6:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=1.2117, batch_acc=0.6875, running_acc=0.6466]Evaluation epoch 6:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=1.6916, batch_acc=0.5000, running_acc=0.6362]Evaluation epoch 6:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=1.6916, batch_acc=0.5000, running_acc=0.6362]Evaluation epoch 6:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=1.7469, batch_acc=0.5625, running_acc=0.6312]Evaluation epoch 6:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=1.7469, batch_acc=0.5625, running_acc=0.6312]Evaluation epoch 6:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=1.2062, batch_acc=0.5938, running_acc=0.6289]Evaluation epoch 6:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=1.2062, batch_acc=0.5938, running_acc=0.6289]Evaluation epoch 6:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=0.8521, batch_acc=0.8125, running_acc=0.6397]Evaluation epoch 6:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.8521, batch_acc=0.8125, running_acc=0.6397]Evaluation epoch 6:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=1.0907, batch_acc=0.7188, running_acc=0.6441]Evaluation epoch 6:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=1.0907, batch_acc=0.7188, running_acc=0.6441]Evaluation epoch 6:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=1.5553, batch_acc=0.4375, running_acc=0.6332]Evaluation epoch 6:  71%|███████▏  | 20/28 [00:27<00:10,  1.36s/it, loss=1.5553, batch_acc=0.4375, running_acc=0.6332]Evaluation epoch 6:  71%|███████▏  | 20/28 [00:27<00:10,  1.36s/it, loss=1.1636, batch_acc=0.5312, running_acc=0.6281]Evaluation epoch 6:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=1.1636, batch_acc=0.5312, running_acc=0.6281]Evaluation epoch 6:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=1.4162, batch_acc=0.6250, running_acc=0.6280]Evaluation epoch 6:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=1.4162, batch_acc=0.6250, running_acc=0.6280]Evaluation epoch 6:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=1.5775, batch_acc=0.4688, running_acc=0.6207]Evaluation epoch 6:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=1.5775, batch_acc=0.4688, running_acc=0.6207]Evaluation epoch 6:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=1.6770, batch_acc=0.4375, running_acc=0.6128]Evaluation epoch 6:  86%|████████▌ | 24/28 [00:33<00:08,  2.03s/it, loss=1.6770, batch_acc=0.4375, running_acc=0.6128]Evaluation epoch 6:  86%|████████▌ | 24/28 [00:33<00:08,  2.03s/it, loss=1.1137, batch_acc=0.5938, running_acc=0.6120]Evaluation epoch 6:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=1.1137, batch_acc=0.5938, running_acc=0.6120]Evaluation epoch 6:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=1.0171, batch_acc=0.6250, running_acc=0.6125]Evaluation epoch 6:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=1.0171, batch_acc=0.6250, running_acc=0.6125]Evaluation epoch 6:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=1.3305, batch_acc=0.6250, running_acc=0.6130]Evaluation epoch 6:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=1.3305, batch_acc=0.6250, running_acc=0.6130]Evaluation epoch 6:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=1.5828, batch_acc=0.5312, running_acc=0.6100]Evaluation epoch 6: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=0.1886, batch_acc=1.0000, running_acc=0.6113]Evaluation epoch 6: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=0.1886, batch_acc=1.0000, running_acc=0.6113]
Training epoch 7:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 7:   1%|          | 1/163 [00:06<17:23,  6.44s/it]Training epoch 7:   1%|          | 1/163 [00:06<17:23,  6.44s/it, loss=0.8683, batch_acc=0.8438, running_acc=0.8438, grad=10.6442]Training epoch 7:   1%|          | 2/163 [00:07<08:30,  3.17s/it, loss=0.8683, batch_acc=0.8438, running_acc=0.8438, grad=10.6442]Training epoch 7:   1%|          | 2/163 [00:07<08:30,  3.17s/it, loss=0.9015, batch_acc=0.8125, running_acc=0.8281, grad=7.7537] Training epoch 7:   2%|▏         | 3/163 [00:08<05:39,  2.12s/it, loss=0.9015, batch_acc=0.8125, running_acc=0.8281, grad=7.7537]Training epoch 7:   2%|▏         | 3/163 [00:08<05:39,  2.12s/it, loss=0.9503, batch_acc=0.7188, running_acc=0.7917, grad=7.8146]Training epoch 7:   2%|▏         | 4/163 [00:11<06:38,  2.51s/it, loss=0.9503, batch_acc=0.7188, running_acc=0.7917, grad=7.8146]Training epoch 7:   2%|▏         | 4/163 [00:11<06:38,  2.51s/it, loss=0.6430, batch_acc=0.6875, running_acc=0.7656, grad=8.2350]Training epoch 7:   3%|▎         | 5/163 [00:12<05:03,  1.92s/it, loss=0.6430, batch_acc=0.6875, running_acc=0.7656, grad=8.2350]Training epoch 7:   3%|▎         | 5/163 [00:12<05:03,  1.92s/it, loss=0.7294, batch_acc=0.7500, running_acc=0.7625, grad=6.6353]Training epoch 7:   4%|▎         | 6/163 [00:13<04:06,  1.57s/it, loss=0.7294, batch_acc=0.7500, running_acc=0.7625, grad=6.6353]Training epoch 7:   4%|▎         | 6/163 [00:13<04:06,  1.57s/it, loss=1.1289, batch_acc=0.7500, running_acc=0.7604, grad=7.3572]Training epoch 7:   4%|▍         | 7/163 [00:13<03:29,  1.34s/it, loss=1.1289, batch_acc=0.7500, running_acc=0.7604, grad=7.3572]Training epoch 7:   4%|▍         | 7/163 [00:13<03:29,  1.34s/it, loss=0.5657, batch_acc=0.9375, running_acc=0.7857, grad=4.9141]Training epoch 7:   5%|▍         | 8/163 [00:15<03:35,  1.39s/it, loss=0.5657, batch_acc=0.9375, running_acc=0.7857, grad=4.9141]Training epoch 7:   5%|▍         | 8/163 [00:15<03:35,  1.39s/it, loss=0.4468, batch_acc=0.9062, running_acc=0.8008, grad=4.7052]Training epoch 7:   6%|▌         | 9/163 [00:16<03:09,  1.23s/it, loss=0.4468, batch_acc=0.9062, running_acc=0.8008, grad=4.7052]Training epoch 7:   6%|▌         | 9/163 [00:16<03:09,  1.23s/it, loss=0.8605, batch_acc=0.7812, running_acc=0.7986, grad=7.4040]Training epoch 7:   6%|▌         | 10/163 [00:17<02:51,  1.12s/it, loss=0.8605, batch_acc=0.7812, running_acc=0.7986, grad=7.4040]Training epoch 7:   6%|▌         | 10/163 [00:17<02:51,  1.12s/it, loss=0.6528, batch_acc=0.7500, running_acc=0.7937, grad=6.4479]Training epoch 7:   7%|▋         | 11/163 [00:18<02:39,  1.05s/it, loss=0.6528, batch_acc=0.7500, running_acc=0.7937, grad=6.4479]Training epoch 7:   7%|▋         | 11/163 [00:18<02:39,  1.05s/it, loss=0.6532, batch_acc=0.8750, running_acc=0.8011, grad=6.4564]Training epoch 7:   7%|▋         | 12/163 [00:19<03:06,  1.24s/it, loss=0.6532, batch_acc=0.8750, running_acc=0.8011, grad=6.4564]Training epoch 7:   7%|▋         | 12/163 [00:19<03:06,  1.24s/it, loss=0.6928, batch_acc=0.7500, running_acc=0.7969, grad=5.8864]Training epoch 7:   8%|▊         | 13/163 [00:20<02:49,  1.13s/it, loss=0.6928, batch_acc=0.7500, running_acc=0.7969, grad=5.8864]Training epoch 7:   8%|▊         | 13/163 [00:20<02:49,  1.13s/it, loss=0.8962, batch_acc=0.7500, running_acc=0.7933, grad=12.5942]Training epoch 7:   9%|▊         | 14/163 [00:21<02:37,  1.05s/it, loss=0.8962, batch_acc=0.7500, running_acc=0.7933, grad=12.5942]Training epoch 7:   9%|▊         | 14/163 [00:21<02:37,  1.05s/it, loss=0.7385, batch_acc=0.8125, running_acc=0.7946, grad=8.6110] Training epoch 7:   9%|▉         | 15/163 [00:22<02:28,  1.00s/it, loss=0.7385, batch_acc=0.8125, running_acc=0.7946, grad=8.6110]Training epoch 7:   9%|▉         | 15/163 [00:22<02:28,  1.00s/it, loss=0.5809, batch_acc=0.8125, running_acc=0.7958, grad=7.4909]Training epoch 7:  10%|▉         | 16/163 [00:23<02:48,  1.15s/it, loss=0.5809, batch_acc=0.8125, running_acc=0.7958, grad=7.4909]Training epoch 7:  10%|▉         | 16/163 [00:23<02:48,  1.15s/it, loss=0.5755, batch_acc=0.8750, running_acc=0.8008, grad=6.5599]Training epoch 7:  10%|█         | 17/163 [00:24<02:35,  1.07s/it, loss=0.5755, batch_acc=0.8750, running_acc=0.8008, grad=6.5599]Training epoch 7:  10%|█         | 17/163 [00:24<02:35,  1.07s/it, loss=0.8658, batch_acc=0.6562, running_acc=0.7923, grad=6.9194]Training epoch 7:  11%|█         | 18/163 [00:25<02:26,  1.01s/it, loss=0.8658, batch_acc=0.6562, running_acc=0.7923, grad=6.9194]Training epoch 7:  11%|█         | 18/163 [00:25<02:26,  1.01s/it, loss=0.8416, batch_acc=0.7812, running_acc=0.7917, grad=6.7644]Training epoch 7:  12%|█▏        | 19/163 [00:26<02:23,  1.00it/s, loss=0.8416, batch_acc=0.7812, running_acc=0.7917, grad=6.7644]Training epoch 7:  12%|█▏        | 19/163 [00:26<02:23,  1.00it/s, loss=0.6931, batch_acc=0.8438, running_acc=0.7944, grad=6.1629]Training epoch 7:  12%|█▏        | 20/163 [00:27<02:38,  1.11s/it, loss=0.6931, batch_acc=0.8438, running_acc=0.7944, grad=6.1629]Training epoch 7:  12%|█▏        | 20/163 [00:27<02:38,  1.11s/it, loss=0.5655, batch_acc=0.8438, running_acc=0.7969, grad=5.7123]Training epoch 7:  13%|█▎        | 21/163 [00:28<02:27,  1.04s/it, loss=0.5655, batch_acc=0.8438, running_acc=0.7969, grad=5.7123]Training epoch 7:  13%|█▎        | 21/163 [00:28<02:27,  1.04s/it, loss=0.6441, batch_acc=0.7812, running_acc=0.7961, grad=7.5714]Training epoch 7:  13%|█▎        | 22/163 [00:29<02:20,  1.01it/s, loss=0.6441, batch_acc=0.7812, running_acc=0.7961, grad=7.5714]Training epoch 7:  13%|█▎        | 22/163 [00:29<02:20,  1.01it/s, loss=1.0376, batch_acc=0.5312, running_acc=0.7841, grad=8.3770]Training epoch 7:  14%|█▍        | 23/163 [00:30<02:14,  1.04it/s, loss=1.0376, batch_acc=0.5312, running_acc=0.7841, grad=8.3770]Training epoch 7:  14%|█▍        | 23/163 [00:30<02:14,  1.04it/s, loss=0.4681, batch_acc=0.9062, running_acc=0.7894, grad=6.5425]Training epoch 7:  15%|█▍        | 24/163 [00:31<02:26,  1.06s/it, loss=0.4681, batch_acc=0.9062, running_acc=0.7894, grad=6.5425]Training epoch 7:  15%|█▍        | 24/163 [00:31<02:26,  1.06s/it, loss=0.9147, batch_acc=0.6875, running_acc=0.7852, grad=7.5512]Training epoch 7:  15%|█▌        | 25/163 [00:32<02:18,  1.00s/it, loss=0.9147, batch_acc=0.6875, running_acc=0.7852, grad=7.5512]Training epoch 7:  15%|█▌        | 25/163 [00:32<02:18,  1.00s/it, loss=0.5008, batch_acc=0.8438, running_acc=0.7875, grad=6.0749]Training epoch 7:  16%|█▌        | 26/163 [00:33<02:12,  1.03it/s, loss=0.5008, batch_acc=0.8438, running_acc=0.7875, grad=6.0749]Training epoch 7:  16%|█▌        | 26/163 [00:33<02:12,  1.03it/s, loss=0.6631, batch_acc=0.8438, running_acc=0.7897, grad=7.6973]Training epoch 7:  17%|█▋        | 27/163 [00:34<02:07,  1.06it/s, loss=0.6631, batch_acc=0.8438, running_acc=0.7897, grad=7.6973]Training epoch 7:  17%|█▋        | 27/163 [00:34<02:07,  1.06it/s, loss=0.4345, batch_acc=0.9062, running_acc=0.7940, grad=4.4004]Training epoch 7:  17%|█▋        | 28/163 [00:35<02:14,  1.01it/s, loss=0.4345, batch_acc=0.9062, running_acc=0.7940, grad=4.4004]Training epoch 7:  17%|█▋        | 28/163 [00:35<02:14,  1.01it/s, loss=0.3935, batch_acc=0.9688, running_acc=0.8002, grad=5.0079]Training epoch 7:  18%|█▊        | 29/163 [00:36<02:08,  1.04it/s, loss=0.3935, batch_acc=0.9688, running_acc=0.8002, grad=5.0079]Training epoch 7:  18%|█▊        | 29/163 [00:36<02:08,  1.04it/s, loss=0.6056, batch_acc=0.8125, running_acc=0.8006, grad=6.1755]Training epoch 7:  18%|█▊        | 30/163 [00:37<02:04,  1.07it/s, loss=0.6056, batch_acc=0.8125, running_acc=0.8006, grad=6.1755]Training epoch 7:  18%|█▊        | 30/163 [00:37<02:04,  1.07it/s, loss=0.8895, batch_acc=0.7500, running_acc=0.7990, grad=8.0930]Training epoch 7:  19%|█▉        | 31/163 [00:38<02:01,  1.09it/s, loss=0.8895, batch_acc=0.7500, running_acc=0.7990, grad=8.0930]Training epoch 7:  19%|█▉        | 31/163 [00:38<02:01,  1.09it/s, loss=0.6335, batch_acc=0.8125, running_acc=0.7994, grad=6.2181]Training epoch 7:  20%|█▉        | 32/163 [00:40<02:35,  1.18s/it, loss=0.6335, batch_acc=0.8125, running_acc=0.7994, grad=6.2181]Training epoch 7:  20%|█▉        | 32/163 [00:40<02:35,  1.18s/it, loss=0.5750, batch_acc=0.8750, running_acc=0.8018, grad=6.9723]Training epoch 7:  20%|██        | 33/163 [00:40<02:22,  1.09s/it, loss=0.5750, batch_acc=0.8750, running_acc=0.8018, grad=6.9723]Training epoch 7:  20%|██        | 33/163 [00:40<02:22,  1.09s/it, loss=0.7199, batch_acc=0.7812, running_acc=0.8011, grad=5.7848]Training epoch 7:  21%|██        | 34/163 [00:41<02:12,  1.03s/it, loss=0.7199, batch_acc=0.7812, running_acc=0.8011, grad=5.7848]Training epoch 7:  21%|██        | 34/163 [00:41<02:12,  1.03s/it, loss=0.5014, batch_acc=0.9688, running_acc=0.8061, grad=5.3941]Training epoch 7:  21%|██▏       | 35/163 [00:42<02:06,  1.02it/s, loss=0.5014, batch_acc=0.9688, running_acc=0.8061, grad=5.3941]Training epoch 7:  21%|██▏       | 35/163 [00:42<02:06,  1.02it/s, loss=0.5800, batch_acc=0.7500, running_acc=0.8045, grad=6.1205]Training epoch 7:  22%|██▏       | 36/163 [00:44<02:19,  1.09s/it, loss=0.5800, batch_acc=0.7500, running_acc=0.8045, grad=6.1205]Training epoch 7:  22%|██▏       | 36/163 [00:44<02:19,  1.09s/it, loss=0.5976, batch_acc=0.8125, running_acc=0.8047, grad=7.0935]Training epoch 7:  23%|██▎       | 37/163 [00:44<02:09,  1.03s/it, loss=0.5976, batch_acc=0.8125, running_acc=0.8047, grad=7.0935]Training epoch 7:  23%|██▎       | 37/163 [00:44<02:09,  1.03s/it, loss=0.4036, batch_acc=0.9375, running_acc=0.8083, grad=4.3365]Training epoch 7:  23%|██▎       | 38/163 [00:45<02:03,  1.01it/s, loss=0.4036, batch_acc=0.9375, running_acc=0.8083, grad=4.3365]Training epoch 7:  23%|██▎       | 38/163 [00:45<02:03,  1.01it/s, loss=0.7745, batch_acc=0.7500, running_acc=0.8067, grad=8.4451]Training epoch 7:  24%|██▍       | 39/163 [00:46<01:58,  1.05it/s, loss=0.7745, batch_acc=0.7500, running_acc=0.8067, grad=8.4451]Training epoch 7:  24%|██▍       | 39/163 [00:46<01:58,  1.05it/s, loss=0.5687, batch_acc=0.8438, running_acc=0.8077, grad=4.3437]Training epoch 7:  25%|██▍       | 40/163 [00:48<02:14,  1.10s/it, loss=0.5687, batch_acc=0.8438, running_acc=0.8077, grad=4.3437]Training epoch 7:  25%|██▍       | 40/163 [00:48<02:14,  1.10s/it, loss=0.7001, batch_acc=0.7500, running_acc=0.8063, grad=5.5141]Training epoch 7:  25%|██▌       | 41/163 [00:49<02:05,  1.03s/it, loss=0.7001, batch_acc=0.7500, running_acc=0.8063, grad=5.5141]Training epoch 7:  25%|██▌       | 41/163 [00:49<02:05,  1.03s/it, loss=0.7236, batch_acc=0.7500, running_acc=0.8049, grad=7.4642]Training epoch 7:  26%|██▌       | 42/163 [00:49<01:59,  1.01it/s, loss=0.7236, batch_acc=0.7500, running_acc=0.8049, grad=7.4642]Training epoch 7:  26%|██▌       | 42/163 [00:49<01:59,  1.01it/s, loss=0.7886, batch_acc=0.7812, running_acc=0.8043, grad=9.6165]Training epoch 7:  26%|██▋       | 43/163 [00:50<01:54,  1.05it/s, loss=0.7886, batch_acc=0.7812, running_acc=0.8043, grad=9.6165]Training epoch 7:  26%|██▋       | 43/163 [00:50<01:54,  1.05it/s, loss=0.9360, batch_acc=0.7812, running_acc=0.8038, grad=7.6371]Training epoch 7:  27%|██▋       | 44/163 [00:51<01:54,  1.04it/s, loss=0.9360, batch_acc=0.7812, running_acc=0.8038, grad=7.6371]Training epoch 7:  27%|██▋       | 44/163 [00:51<01:54,  1.04it/s, loss=0.6840, batch_acc=0.8750, running_acc=0.8054, grad=5.8338]Training epoch 7:  28%|██▊       | 45/163 [00:52<01:50,  1.07it/s, loss=0.6840, batch_acc=0.8750, running_acc=0.8054, grad=5.8338]Training epoch 7:  28%|██▊       | 45/163 [00:52<01:50,  1.07it/s, loss=0.8411, batch_acc=0.8125, running_acc=0.8056, grad=10.6153]Training epoch 7:  28%|██▊       | 46/163 [00:53<01:47,  1.09it/s, loss=0.8411, batch_acc=0.8125, running_acc=0.8056, grad=10.6153]Training epoch 7:  28%|██▊       | 46/163 [00:53<01:47,  1.09it/s, loss=0.6404, batch_acc=0.8438, running_acc=0.8064, grad=8.9344] Training epoch 7:  29%|██▉       | 47/163 [00:54<01:45,  1.10it/s, loss=0.6404, batch_acc=0.8438, running_acc=0.8064, grad=8.9344]Training epoch 7:  29%|██▉       | 47/163 [00:54<01:45,  1.10it/s, loss=0.6768, batch_acc=0.7500, running_acc=0.8052, grad=7.4490]Training epoch 7:  29%|██▉       | 48/163 [00:55<02:05,  1.09s/it, loss=0.6768, batch_acc=0.7500, running_acc=0.8052, grad=7.4490]Training epoch 7:  29%|██▉       | 48/163 [00:55<02:05,  1.09s/it, loss=0.7592, batch_acc=0.6875, running_acc=0.8027, grad=7.2153]Training epoch 7:  30%|███       | 49/163 [00:56<01:57,  1.03s/it, loss=0.7592, batch_acc=0.6875, running_acc=0.8027, grad=7.2153]Training epoch 7:  30%|███       | 49/163 [00:56<01:57,  1.03s/it, loss=0.6586, batch_acc=0.8125, running_acc=0.8029, grad=6.2045]Training epoch 7:  31%|███       | 50/163 [00:57<01:51,  1.02it/s, loss=0.6586, batch_acc=0.8125, running_acc=0.8029, grad=6.2045]Training epoch 7:  31%|███       | 50/163 [00:57<01:51,  1.02it/s, loss=0.6733, batch_acc=0.7500, running_acc=0.8019, grad=7.6402]Training epoch 7:  31%|███▏      | 51/163 [00:58<01:46,  1.05it/s, loss=0.6733, batch_acc=0.7500, running_acc=0.8019, grad=7.6402]Training epoch 7:  31%|███▏      | 51/163 [00:58<01:46,  1.05it/s, loss=1.1426, batch_acc=0.6875, running_acc=0.7996, grad=11.7191]Training epoch 7:  32%|███▏      | 52/163 [00:59<01:50,  1.00it/s, loss=1.1426, batch_acc=0.6875, running_acc=0.7996, grad=11.7191]Training epoch 7:  32%|███▏      | 52/163 [00:59<01:50,  1.00it/s, loss=0.9499, batch_acc=0.6250, running_acc=0.7963, grad=12.1821]Training epoch 7:  33%|███▎      | 53/163 [01:00<01:45,  1.04it/s, loss=0.9499, batch_acc=0.6250, running_acc=0.7963, grad=12.1821]Training epoch 7:  33%|███▎      | 53/163 [01:00<01:45,  1.04it/s, loss=0.9663, batch_acc=0.7500, running_acc=0.7954, grad=7.1632] Training epoch 7:  33%|███▎      | 54/163 [01:01<01:42,  1.07it/s, loss=0.9663, batch_acc=0.7500, running_acc=0.7954, grad=7.1632]Training epoch 7:  33%|███▎      | 54/163 [01:01<01:42,  1.07it/s, loss=0.6254, batch_acc=0.7812, running_acc=0.7951, grad=6.8445]Training epoch 7:  34%|███▎      | 55/163 [01:02<01:39,  1.09it/s, loss=0.6254, batch_acc=0.7812, running_acc=0.7951, grad=6.8445]Training epoch 7:  34%|███▎      | 55/163 [01:02<01:39,  1.09it/s, loss=0.7710, batch_acc=0.7812, running_acc=0.7949, grad=6.0766]Training epoch 7:  34%|███▍      | 56/163 [01:03<01:50,  1.03s/it, loss=0.7710, batch_acc=0.7812, running_acc=0.7949, grad=6.0766]Training epoch 7:  34%|███▍      | 56/163 [01:03<01:50,  1.03s/it, loss=0.9529, batch_acc=0.6875, running_acc=0.7930, grad=8.2035]Training epoch 7:  35%|███▍      | 57/163 [01:04<01:44,  1.01it/s, loss=0.9529, batch_acc=0.6875, running_acc=0.7930, grad=8.2035]Training epoch 7:  35%|███▍      | 57/163 [01:04<01:44,  1.01it/s, loss=0.6593, batch_acc=0.7812, running_acc=0.7928, grad=9.5982]Training epoch 7:  36%|███▌      | 58/163 [01:05<01:40,  1.05it/s, loss=0.6593, batch_acc=0.7812, running_acc=0.7928, grad=9.5982]Training epoch 7:  36%|███▌      | 58/163 [01:05<01:40,  1.05it/s, loss=0.5502, batch_acc=0.8125, running_acc=0.7931, grad=7.2414]Training epoch 7:  36%|███▌      | 59/163 [01:06<01:36,  1.07it/s, loss=0.5502, batch_acc=0.8125, running_acc=0.7931, grad=7.2414]Training epoch 7:  36%|███▌      | 59/163 [01:06<01:36,  1.07it/s, loss=0.6920, batch_acc=0.7812, running_acc=0.7929, grad=7.4343]Training epoch 7:  37%|███▋      | 60/163 [01:07<01:40,  1.02it/s, loss=0.6920, batch_acc=0.7812, running_acc=0.7929, grad=7.4343]Training epoch 7:  37%|███▋      | 60/163 [01:07<01:40,  1.02it/s, loss=0.6102, batch_acc=0.7812, running_acc=0.7927, grad=7.7808]Training epoch 7:  37%|███▋      | 61/163 [01:08<01:36,  1.05it/s, loss=0.6102, batch_acc=0.7812, running_acc=0.7927, grad=7.7808]Training epoch 7:  37%|███▋      | 61/163 [01:08<01:36,  1.05it/s, loss=0.5296, batch_acc=0.8438, running_acc=0.7935, grad=5.3784]Training epoch 7:  38%|███▊      | 62/163 [01:09<01:35,  1.06it/s, loss=0.5296, batch_acc=0.8438, running_acc=0.7935, grad=5.3784]Training epoch 7:  38%|███▊      | 62/163 [01:09<01:35,  1.06it/s, loss=0.3920, batch_acc=0.8750, running_acc=0.7949, grad=5.4228]Training epoch 7:  39%|███▊      | 63/163 [01:10<01:32,  1.08it/s, loss=0.3920, batch_acc=0.8750, running_acc=0.7949, grad=5.4228]Training epoch 7:  39%|███▊      | 63/163 [01:10<01:32,  1.08it/s, loss=0.8346, batch_acc=0.8125, running_acc=0.7951, grad=7.3133]Training epoch 7:  39%|███▉      | 64/163 [01:11<01:54,  1.15s/it, loss=0.8346, batch_acc=0.8125, running_acc=0.7951, grad=7.3133]Training epoch 7:  39%|███▉      | 64/163 [01:11<01:54,  1.15s/it, loss=0.5951, batch_acc=0.8125, running_acc=0.7954, grad=9.2724]Training epoch 7:  40%|███▉      | 65/163 [01:12<01:45,  1.07s/it, loss=0.5951, batch_acc=0.8125, running_acc=0.7954, grad=9.2724]Training epoch 7:  40%|███▉      | 65/163 [01:12<01:45,  1.07s/it, loss=0.9662, batch_acc=0.7188, running_acc=0.7942, grad=8.4023]Training epoch 7:  40%|████      | 66/163 [01:13<01:38,  1.02s/it, loss=0.9662, batch_acc=0.7188, running_acc=0.7942, grad=8.4023]Training epoch 7:  40%|████      | 66/163 [01:13<01:38,  1.02s/it, loss=0.8458, batch_acc=0.7500, running_acc=0.7936, grad=7.1131]Training epoch 7:  41%|████      | 67/163 [01:14<01:33,  1.03it/s, loss=0.8458, batch_acc=0.7500, running_acc=0.7936, grad=7.1131]Training epoch 7:  41%|████      | 67/163 [01:14<01:33,  1.03it/s, loss=0.5324, batch_acc=0.8750, running_acc=0.7948, grad=4.9220]Training epoch 7:  42%|████▏     | 68/163 [01:15<01:50,  1.16s/it, loss=0.5324, batch_acc=0.8750, running_acc=0.7948, grad=4.9220]Training epoch 7:  42%|████▏     | 68/163 [01:15<01:50,  1.16s/it, loss=0.6599, batch_acc=0.7500, running_acc=0.7941, grad=6.2174]Training epoch 7:  42%|████▏     | 69/163 [01:16<01:41,  1.08s/it, loss=0.6599, batch_acc=0.7500, running_acc=0.7941, grad=6.2174]Training epoch 7:  42%|████▏     | 69/163 [01:16<01:41,  1.08s/it, loss=0.8446, batch_acc=0.7188, running_acc=0.7930, grad=10.8029]Training epoch 7:  43%|████▎     | 70/163 [01:17<01:34,  1.02s/it, loss=0.8446, batch_acc=0.7188, running_acc=0.7930, grad=10.8029]Training epoch 7:  43%|████▎     | 70/163 [01:17<01:34,  1.02s/it, loss=0.7127, batch_acc=0.7812, running_acc=0.7929, grad=10.0409]Training epoch 7:  44%|████▎     | 71/163 [01:18<01:29,  1.02it/s, loss=0.7127, batch_acc=0.7812, running_acc=0.7929, grad=10.0409]Training epoch 7:  44%|████▎     | 71/163 [01:18<01:29,  1.02it/s, loss=0.7820, batch_acc=0.7188, running_acc=0.7918, grad=9.0377] Training epoch 7:  44%|████▍     | 72/163 [01:19<01:38,  1.08s/it, loss=0.7820, batch_acc=0.7188, running_acc=0.7918, grad=9.0377]Training epoch 7:  44%|████▍     | 72/163 [01:19<01:38,  1.08s/it, loss=0.7911, batch_acc=0.8125, running_acc=0.7921, grad=8.3969]Training epoch 7:  45%|████▍     | 73/163 [01:20<01:31,  1.02s/it, loss=0.7911, batch_acc=0.8125, running_acc=0.7921, grad=8.3969]Training epoch 7:  45%|████▍     | 73/163 [01:20<01:31,  1.02s/it, loss=0.7720, batch_acc=0.6562, running_acc=0.7902, grad=8.3257]Training epoch 7:  45%|████▌     | 74/163 [01:21<01:27,  1.02it/s, loss=0.7720, batch_acc=0.6562, running_acc=0.7902, grad=8.3257]Training epoch 7:  45%|████▌     | 74/163 [01:21<01:27,  1.02it/s, loss=0.6375, batch_acc=0.8438, running_acc=0.7910, grad=5.2103]Training epoch 7:  46%|████▌     | 75/163 [01:22<01:23,  1.05it/s, loss=0.6375, batch_acc=0.8438, running_acc=0.7910, grad=5.2103]Training epoch 7:  46%|████▌     | 75/163 [01:22<01:23,  1.05it/s, loss=0.7578, batch_acc=0.7188, running_acc=0.7900, grad=6.2009]Training epoch 7:  47%|████▋     | 76/163 [01:23<01:31,  1.06s/it, loss=0.7578, batch_acc=0.7188, running_acc=0.7900, grad=6.2009]Training epoch 7:  47%|████▋     | 76/163 [01:23<01:31,  1.06s/it, loss=0.6908, batch_acc=0.8438, running_acc=0.7907, grad=6.8811]Training epoch 7:  47%|████▋     | 77/163 [01:24<01:26,  1.00s/it, loss=0.6908, batch_acc=0.8438, running_acc=0.7907, grad=6.8811]Training epoch 7:  47%|████▋     | 77/163 [01:24<01:26,  1.00s/it, loss=0.8501, batch_acc=0.7500, running_acc=0.7902, grad=9.4383]Training epoch 7:  48%|████▊     | 78/163 [01:25<01:22,  1.03it/s, loss=0.8501, batch_acc=0.7500, running_acc=0.7902, grad=9.4383]Training epoch 7:  48%|████▊     | 78/163 [01:25<01:22,  1.03it/s, loss=0.7891, batch_acc=0.7188, running_acc=0.7893, grad=7.8340]Training epoch 7:  48%|████▊     | 79/163 [01:26<01:19,  1.06it/s, loss=0.7891, batch_acc=0.7188, running_acc=0.7893, grad=7.8340]Training epoch 7:  48%|████▊     | 79/163 [01:26<01:19,  1.06it/s, loss=0.8672, batch_acc=0.6875, running_acc=0.7880, grad=7.1227]Training epoch 7:  49%|████▉     | 80/163 [01:28<01:37,  1.17s/it, loss=0.8672, batch_acc=0.6875, running_acc=0.7880, grad=7.1227]Training epoch 7:  49%|████▉     | 80/163 [01:28<01:37,  1.17s/it, loss=0.7470, batch_acc=0.7812, running_acc=0.7879, grad=7.4319]Training epoch 7:  50%|████▉     | 81/163 [01:29<01:29,  1.09s/it, loss=0.7470, batch_acc=0.7812, running_acc=0.7879, grad=7.4319]Training epoch 7:  50%|████▉     | 81/163 [01:29<01:29,  1.09s/it, loss=0.7349, batch_acc=0.8125, running_acc=0.7882, grad=6.5991]Training epoch 7:  50%|█████     | 82/163 [01:30<01:28,  1.10s/it, loss=0.7349, batch_acc=0.8125, running_acc=0.7882, grad=6.5991]Training epoch 7:  50%|█████     | 82/163 [01:30<01:28,  1.10s/it, loss=0.5100, batch_acc=0.8125, running_acc=0.7885, grad=6.4521]Training epoch 7:  51%|█████     | 83/163 [01:31<01:22,  1.03s/it, loss=0.5100, batch_acc=0.8125, running_acc=0.7885, grad=6.4521]Training epoch 7:  51%|█████     | 83/163 [01:31<01:22,  1.03s/it, loss=0.6883, batch_acc=0.6875, running_acc=0.7873, grad=9.3618]Training epoch 7:  52%|█████▏    | 84/163 [01:32<01:35,  1.21s/it, loss=0.6883, batch_acc=0.6875, running_acc=0.7873, grad=9.3618]Training epoch 7:  52%|█████▏    | 84/163 [01:32<01:35,  1.21s/it, loss=0.6384, batch_acc=0.7500, running_acc=0.7868, grad=6.9218]Training epoch 7:  52%|█████▏    | 85/163 [01:33<01:28,  1.13s/it, loss=0.6384, batch_acc=0.7500, running_acc=0.7868, grad=6.9218]Training epoch 7:  52%|█████▏    | 85/163 [01:33<01:28,  1.13s/it, loss=0.3800, batch_acc=0.9062, running_acc=0.7882, grad=3.7272]Training epoch 7:  53%|█████▎    | 86/163 [01:35<01:38,  1.29s/it, loss=0.3800, batch_acc=0.9062, running_acc=0.7882, grad=3.7272]Training epoch 7:  53%|█████▎    | 86/163 [01:35<01:38,  1.29s/it, loss=0.4902, batch_acc=0.8750, running_acc=0.7892, grad=5.4440]Training epoch 7:  53%|█████▎    | 87/163 [01:36<01:28,  1.16s/it, loss=0.4902, batch_acc=0.8750, running_acc=0.7892, grad=5.4440]Training epoch 7:  53%|█████▎    | 87/163 [01:36<01:28,  1.16s/it, loss=0.7301, batch_acc=0.7812, running_acc=0.7892, grad=7.3644]Training epoch 7:  54%|█████▍    | 88/163 [01:37<01:38,  1.31s/it, loss=0.7301, batch_acc=0.7812, running_acc=0.7892, grad=7.3644]Training epoch 7:  54%|█████▍    | 88/163 [01:37<01:38,  1.31s/it, loss=0.5213, batch_acc=0.7812, running_acc=0.7891, grad=6.2199]Training epoch 7:  55%|█████▍    | 89/163 [01:38<01:27,  1.18s/it, loss=0.5213, batch_acc=0.7812, running_acc=0.7891, grad=6.2199]Training epoch 7:  55%|█████▍    | 89/163 [01:38<01:27,  1.18s/it, loss=0.6311, batch_acc=0.8750, running_acc=0.7900, grad=6.5268]Training epoch 7:  55%|█████▌    | 90/163 [01:40<01:46,  1.46s/it, loss=0.6311, batch_acc=0.8750, running_acc=0.7900, grad=6.5268]Training epoch 7:  55%|█████▌    | 90/163 [01:40<01:46,  1.46s/it, loss=0.5423, batch_acc=0.8438, running_acc=0.7906, grad=6.0642]Training epoch 7:  56%|█████▌    | 91/163 [01:41<01:32,  1.28s/it, loss=0.5423, batch_acc=0.8438, running_acc=0.7906, grad=6.0642]Training epoch 7:  56%|█████▌    | 91/163 [01:41<01:32,  1.28s/it, loss=0.7144, batch_acc=0.7500, running_acc=0.7902, grad=6.6963]Training epoch 7:  56%|█████▋    | 92/163 [01:42<01:23,  1.18s/it, loss=0.7144, batch_acc=0.7500, running_acc=0.7902, grad=6.6963]Training epoch 7:  56%|█████▋    | 92/163 [01:42<01:23,  1.18s/it, loss=0.7501, batch_acc=0.7812, running_acc=0.7901, grad=6.7995]Training epoch 7:  57%|█████▋    | 93/163 [01:43<01:17,  1.11s/it, loss=0.7501, batch_acc=0.7812, running_acc=0.7901, grad=6.7995]Training epoch 7:  57%|█████▋    | 93/163 [01:43<01:17,  1.11s/it, loss=0.5875, batch_acc=0.9062, running_acc=0.7913, grad=6.2642]Training epoch 7:  58%|█████▊    | 94/163 [01:45<01:27,  1.27s/it, loss=0.5875, batch_acc=0.9062, running_acc=0.7913, grad=6.2642]Training epoch 7:  58%|█████▊    | 94/163 [01:45<01:27,  1.27s/it, loss=0.4876, batch_acc=0.9062, running_acc=0.7926, grad=4.9425]Training epoch 7:  58%|█████▊    | 95/163 [01:46<01:18,  1.15s/it, loss=0.4876, batch_acc=0.9062, running_acc=0.7926, grad=4.9425]Training epoch 7:  58%|█████▊    | 95/163 [01:46<01:18,  1.15s/it, loss=0.4954, batch_acc=0.8438, running_acc=0.7931, grad=5.6800]Training epoch 7:  59%|█████▉    | 96/163 [01:47<01:11,  1.07s/it, loss=0.4954, batch_acc=0.8438, running_acc=0.7931, grad=5.6800]Training epoch 7:  59%|█████▉    | 96/163 [01:47<01:11,  1.07s/it, loss=0.5105, batch_acc=0.8125, running_acc=0.7933, grad=8.2675]Training epoch 7:  60%|█████▉    | 97/163 [01:47<01:06,  1.01s/it, loss=0.5105, batch_acc=0.8125, running_acc=0.7933, grad=8.2675]Training epoch 7:  60%|█████▉    | 97/163 [01:47<01:06,  1.01s/it, loss=0.5200, batch_acc=0.8438, running_acc=0.7938, grad=9.4913]Training epoch 7:  60%|██████    | 98/163 [01:49<01:20,  1.24s/it, loss=0.5200, batch_acc=0.8438, running_acc=0.7938, grad=9.4913]Training epoch 7:  60%|██████    | 98/163 [01:49<01:20,  1.24s/it, loss=0.7254, batch_acc=0.7812, running_acc=0.7937, grad=8.5325]Training epoch 7:  61%|██████    | 99/163 [01:50<01:12,  1.13s/it, loss=0.7254, batch_acc=0.7812, running_acc=0.7937, grad=8.5325]Training epoch 7:  61%|██████    | 99/163 [01:50<01:12,  1.13s/it, loss=0.5544, batch_acc=0.8750, running_acc=0.7945, grad=5.5733]Training epoch 7:  61%|██████▏   | 100/163 [01:51<01:06,  1.06s/it, loss=0.5544, batch_acc=0.8750, running_acc=0.7945, grad=5.5733]Training epoch 7:  61%|██████▏   | 100/163 [01:51<01:06,  1.06s/it, loss=0.5600, batch_acc=0.8438, running_acc=0.7950, grad=5.9549]Training epoch 7:  62%|██████▏   | 101/163 [01:52<01:02,  1.00s/it, loss=0.5600, batch_acc=0.8438, running_acc=0.7950, grad=5.9549]Training epoch 7:  62%|██████▏   | 101/163 [01:52<01:02,  1.00s/it, loss=0.8779, batch_acc=0.7188, running_acc=0.7942, grad=7.4740]Training epoch 7:  63%|██████▎   | 102/163 [01:53<01:08,  1.13s/it, loss=0.8779, batch_acc=0.7188, running_acc=0.7942, grad=7.4740]Training epoch 7:  63%|██████▎   | 102/163 [01:53<01:08,  1.13s/it, loss=0.8144, batch_acc=0.7500, running_acc=0.7938, grad=10.0224]Training epoch 7:  63%|██████▎   | 103/163 [01:54<01:03,  1.05s/it, loss=0.8144, batch_acc=0.7500, running_acc=0.7938, grad=10.0224]Training epoch 7:  63%|██████▎   | 103/163 [01:54<01:03,  1.05s/it, loss=0.6589, batch_acc=0.7812, running_acc=0.7937, grad=8.7317] Training epoch 7:  64%|██████▍   | 104/163 [01:55<00:59,  1.00s/it, loss=0.6589, batch_acc=0.7812, running_acc=0.7937, grad=8.7317]Training epoch 7:  64%|██████▍   | 104/163 [01:55<00:59,  1.00s/it, loss=0.7170, batch_acc=0.8125, running_acc=0.7939, grad=8.0877]Training epoch 7:  64%|██████▍   | 105/163 [01:56<00:55,  1.04it/s, loss=0.7170, batch_acc=0.8125, running_acc=0.7939, grad=8.0877]Training epoch 7:  64%|██████▍   | 105/163 [01:56<00:55,  1.04it/s, loss=0.9937, batch_acc=0.5938, running_acc=0.7920, grad=11.7679]Training epoch 7:  65%|██████▌   | 106/163 [01:57<01:03,  1.12s/it, loss=0.9937, batch_acc=0.5938, running_acc=0.7920, grad=11.7679]Training epoch 7:  65%|██████▌   | 106/163 [01:57<01:03,  1.12s/it, loss=1.2016, batch_acc=0.6562, running_acc=0.7907, grad=11.9711]Training epoch 7:  66%|██████▌   | 107/163 [01:58<00:58,  1.05s/it, loss=1.2016, batch_acc=0.6562, running_acc=0.7907, grad=11.9711]Training epoch 7:  66%|██████▌   | 107/163 [01:58<00:58,  1.05s/it, loss=0.7786, batch_acc=0.7812, running_acc=0.7906, grad=9.2534] Training epoch 7:  66%|██████▋   | 108/163 [01:59<00:54,  1.00it/s, loss=0.7786, batch_acc=0.7812, running_acc=0.7906, grad=9.2534]Training epoch 7:  66%|██████▋   | 108/163 [01:59<00:54,  1.00it/s, loss=0.7891, batch_acc=0.7500, running_acc=0.7902, grad=6.9843]Training epoch 7:  67%|██████▋   | 109/163 [02:00<00:51,  1.04it/s, loss=0.7891, batch_acc=0.7500, running_acc=0.7902, grad=6.9843]Training epoch 7:  67%|██████▋   | 109/163 [02:00<00:51,  1.04it/s, loss=0.6285, batch_acc=0.8125, running_acc=0.7904, grad=7.5682]Training epoch 7:  67%|██████▋   | 110/163 [02:01<00:57,  1.08s/it, loss=0.6285, batch_acc=0.8125, running_acc=0.7904, grad=7.5682]Training epoch 7:  67%|██████▋   | 110/163 [02:01<00:57,  1.08s/it, loss=0.6180, batch_acc=0.8125, running_acc=0.7906, grad=7.6825]Training epoch 7:  68%|██████▊   | 111/163 [02:02<00:53,  1.02s/it, loss=0.6180, batch_acc=0.8125, running_acc=0.7906, grad=7.6825]Training epoch 7:  68%|██████▊   | 111/163 [02:02<00:53,  1.02s/it, loss=0.7547, batch_acc=0.8438, running_acc=0.7911, grad=8.0024]Training epoch 7:  69%|██████▊   | 112/163 [02:03<00:50,  1.02it/s, loss=0.7547, batch_acc=0.8438, running_acc=0.7911, grad=8.0024]Training epoch 7:  69%|██████▊   | 112/163 [02:03<00:50,  1.02it/s, loss=0.4427, batch_acc=0.8750, running_acc=0.7919, grad=5.6593]Training epoch 7:  69%|██████▉   | 113/163 [02:04<00:48,  1.04it/s, loss=0.4427, batch_acc=0.8750, running_acc=0.7919, grad=5.6593]Training epoch 7:  69%|██████▉   | 113/163 [02:04<00:48,  1.04it/s, loss=0.5975, batch_acc=0.8125, running_acc=0.7920, grad=6.3019]Training epoch 7:  70%|██████▉   | 114/163 [02:06<00:56,  1.16s/it, loss=0.5975, batch_acc=0.8125, running_acc=0.7920, grad=6.3019]Training epoch 7:  70%|██████▉   | 114/163 [02:06<00:56,  1.16s/it, loss=0.6729, batch_acc=0.7812, running_acc=0.7919, grad=8.1761]Training epoch 7:  71%|███████   | 115/163 [02:07<00:51,  1.08s/it, loss=0.6729, batch_acc=0.7812, running_acc=0.7919, grad=8.1761]Training epoch 7:  71%|███████   | 115/163 [02:07<00:51,  1.08s/it, loss=0.8966, batch_acc=0.7188, running_acc=0.7913, grad=6.6409]Training epoch 7:  71%|███████   | 116/163 [02:07<00:47,  1.02s/it, loss=0.8966, batch_acc=0.7188, running_acc=0.7913, grad=6.6409]Training epoch 7:  71%|███████   | 116/163 [02:07<00:47,  1.02s/it, loss=0.6312, batch_acc=0.8750, running_acc=0.7920, grad=6.8409]Training epoch 7:  72%|███████▏  | 117/163 [02:08<00:44,  1.02it/s, loss=0.6312, batch_acc=0.8750, running_acc=0.7920, grad=6.8409]Training epoch 7:  72%|███████▏  | 117/163 [02:08<00:44,  1.02it/s, loss=0.5095, batch_acc=0.8438, running_acc=0.7925, grad=6.4450]Training epoch 7:  72%|███████▏  | 118/163 [02:11<01:02,  1.38s/it, loss=0.5095, batch_acc=0.8438, running_acc=0.7925, grad=6.4450]Training epoch 7:  72%|███████▏  | 118/163 [02:11<01:02,  1.38s/it, loss=1.0127, batch_acc=0.7188, running_acc=0.7918, grad=7.9458]Training epoch 7:  73%|███████▎  | 119/163 [02:11<00:54,  1.23s/it, loss=1.0127, batch_acc=0.7188, running_acc=0.7918, grad=7.9458]Training epoch 7:  73%|███████▎  | 119/163 [02:11<00:54,  1.23s/it, loss=0.5022, batch_acc=0.8750, running_acc=0.7925, grad=5.8304]Training epoch 7:  74%|███████▎  | 120/163 [02:12<00:48,  1.12s/it, loss=0.5022, batch_acc=0.8750, running_acc=0.7925, grad=5.8304]Training epoch 7:  74%|███████▎  | 120/163 [02:12<00:48,  1.12s/it, loss=0.6718, batch_acc=0.7812, running_acc=0.7924, grad=7.9324]Training epoch 7:  74%|███████▍  | 121/163 [02:13<00:44,  1.05s/it, loss=0.6718, batch_acc=0.7812, running_acc=0.7924, grad=7.9324]Training epoch 7:  74%|███████▍  | 121/163 [02:13<00:44,  1.05s/it, loss=0.8059, batch_acc=0.7812, running_acc=0.7924, grad=7.9027]Training epoch 7:  75%|███████▍  | 122/163 [02:14<00:43,  1.06s/it, loss=0.8059, batch_acc=0.7812, running_acc=0.7924, grad=7.9027]Training epoch 7:  75%|███████▍  | 122/163 [02:14<00:43,  1.06s/it, loss=1.3389, batch_acc=0.5000, running_acc=0.7900, grad=11.2365]Training epoch 7:  75%|███████▌  | 123/163 [02:15<00:40,  1.01s/it, loss=1.3389, batch_acc=0.5000, running_acc=0.7900, grad=11.2365]Training epoch 7:  75%|███████▌  | 123/163 [02:15<00:40,  1.01s/it, loss=0.6213, batch_acc=0.8750, running_acc=0.7907, grad=4.0385] Training epoch 7:  76%|███████▌  | 124/163 [02:16<00:37,  1.03it/s, loss=0.6213, batch_acc=0.8750, running_acc=0.7907, grad=4.0385]Training epoch 7:  76%|███████▌  | 124/163 [02:16<00:37,  1.03it/s, loss=1.0706, batch_acc=0.6875, running_acc=0.7898, grad=6.7494]Training epoch 7:  77%|███████▋  | 125/163 [02:17<00:35,  1.06it/s, loss=1.0706, batch_acc=0.6875, running_acc=0.7898, grad=6.7494]Training epoch 7:  77%|███████▋  | 125/163 [02:17<00:35,  1.06it/s, loss=0.8656, batch_acc=0.7188, running_acc=0.7893, grad=7.7802]Training epoch 7:  77%|███████▋  | 126/163 [02:19<00:41,  1.13s/it, loss=0.8656, batch_acc=0.7188, running_acc=0.7893, grad=7.7802]Training epoch 7:  77%|███████▋  | 126/163 [02:19<00:41,  1.13s/it, loss=0.9235, batch_acc=0.7188, running_acc=0.7887, grad=7.8300]Training epoch 7:  78%|███████▊  | 127/163 [02:19<00:38,  1.06s/it, loss=0.9235, batch_acc=0.7188, running_acc=0.7887, grad=7.8300]Training epoch 7:  78%|███████▊  | 127/163 [02:19<00:38,  1.06s/it, loss=0.5367, batch_acc=0.8438, running_acc=0.7891, grad=5.9865]Training epoch 7:  79%|███████▊  | 128/163 [02:20<00:35,  1.00s/it, loss=0.5367, batch_acc=0.8438, running_acc=0.7891, grad=5.9865]Training epoch 7:  79%|███████▊  | 128/163 [02:20<00:35,  1.00s/it, loss=0.8278, batch_acc=0.8125, running_acc=0.7893, grad=7.7468]Training epoch 7:  79%|███████▉  | 129/163 [02:21<00:32,  1.04it/s, loss=0.8278, batch_acc=0.8125, running_acc=0.7893, grad=7.7468]Training epoch 7:  79%|███████▉  | 129/163 [02:21<00:32,  1.04it/s, loss=0.6562, batch_acc=0.7812, running_acc=0.7892, grad=7.1503]Training epoch 7:  80%|███████▉  | 130/163 [02:23<00:42,  1.27s/it, loss=0.6562, batch_acc=0.7812, running_acc=0.7892, grad=7.1503]Training epoch 7:  80%|███████▉  | 130/163 [02:23<00:42,  1.27s/it, loss=0.9802, batch_acc=0.6562, running_acc=0.7882, grad=8.4040]Training epoch 7:  80%|████████  | 131/163 [02:24<00:36,  1.15s/it, loss=0.9802, batch_acc=0.6562, running_acc=0.7882, grad=8.4040]Training epoch 7:  80%|████████  | 131/163 [02:24<00:36,  1.15s/it, loss=0.5787, batch_acc=0.7812, running_acc=0.7882, grad=5.6186]Training epoch 7:  81%|████████  | 132/163 [02:25<00:33,  1.07s/it, loss=0.5787, batch_acc=0.7812, running_acc=0.7882, grad=5.6186]Training epoch 7:  81%|████████  | 132/163 [02:25<00:33,  1.07s/it, loss=0.7241, batch_acc=0.7812, running_acc=0.7881, grad=6.7701]Training epoch 7:  82%|████████▏ | 133/163 [02:26<00:30,  1.02s/it, loss=0.7241, batch_acc=0.7812, running_acc=0.7881, grad=6.7701]Training epoch 7:  82%|████████▏ | 133/163 [02:26<00:30,  1.02s/it, loss=0.9140, batch_acc=0.7812, running_acc=0.7881, grad=6.8638]Training epoch 7:  82%|████████▏ | 134/163 [02:27<00:32,  1.11s/it, loss=0.9140, batch_acc=0.7812, running_acc=0.7881, grad=6.8638]Training epoch 7:  82%|████████▏ | 134/163 [02:27<00:32,  1.11s/it, loss=0.7020, batch_acc=0.8125, running_acc=0.7882, grad=7.1698]Training epoch 7:  83%|████████▎ | 135/163 [02:28<00:29,  1.04s/it, loss=0.7020, batch_acc=0.8125, running_acc=0.7882, grad=7.1698]Training epoch 7:  83%|████████▎ | 135/163 [02:28<00:29,  1.04s/it, loss=0.7285, batch_acc=0.8125, running_acc=0.7884, grad=9.6744]Training epoch 7:  83%|████████▎ | 136/163 [02:29<00:26,  1.01it/s, loss=0.7285, batch_acc=0.8125, running_acc=0.7884, grad=9.6744]Training epoch 7:  83%|████████▎ | 136/163 [02:29<00:26,  1.01it/s, loss=0.9630, batch_acc=0.7500, running_acc=0.7881, grad=8.9298]Training epoch 7:  84%|████████▍ | 137/163 [02:30<00:24,  1.04it/s, loss=0.9630, batch_acc=0.7500, running_acc=0.7881, grad=8.9298]Training epoch 7:  84%|████████▍ | 137/163 [02:30<00:24,  1.04it/s, loss=0.8953, batch_acc=0.8438, running_acc=0.7885, grad=9.7709]Training epoch 7:  85%|████████▍ | 138/163 [02:31<00:24,  1.04it/s, loss=0.8953, batch_acc=0.8438, running_acc=0.7885, grad=9.7709]Training epoch 7:  85%|████████▍ | 138/163 [02:31<00:24,  1.04it/s, loss=0.8448, batch_acc=0.6875, running_acc=0.7878, grad=7.7912]Training epoch 7:  85%|████████▌ | 139/163 [02:32<00:22,  1.07it/s, loss=0.8448, batch_acc=0.6875, running_acc=0.7878, grad=7.7912]Training epoch 7:  85%|████████▌ | 139/163 [02:32<00:22,  1.07it/s, loss=0.7020, batch_acc=0.7812, running_acc=0.7878, grad=8.3734]Training epoch 7:  86%|████████▌ | 140/163 [02:33<00:21,  1.09it/s, loss=0.7020, batch_acc=0.7812, running_acc=0.7878, grad=8.3734]Training epoch 7:  86%|████████▌ | 140/163 [02:33<00:21,  1.09it/s, loss=0.6200, batch_acc=0.8438, running_acc=0.7882, grad=6.7337]Training epoch 7:  87%|████████▋ | 141/163 [02:33<00:19,  1.10it/s, loss=0.6200, batch_acc=0.8438, running_acc=0.7882, grad=6.7337]Training epoch 7:  87%|████████▋ | 141/163 [02:33<00:19,  1.10it/s, loss=0.6386, batch_acc=0.7500, running_acc=0.7879, grad=6.8444]Training epoch 7:  87%|████████▋ | 142/163 [02:35<00:22,  1.07s/it, loss=0.6386, batch_acc=0.7500, running_acc=0.7879, grad=6.8444]Training epoch 7:  87%|████████▋ | 142/163 [02:35<00:22,  1.07s/it, loss=0.5595, batch_acc=0.7812, running_acc=0.7879, grad=6.7135]Training epoch 7:  88%|████████▊ | 143/163 [02:36<00:20,  1.01s/it, loss=0.5595, batch_acc=0.7812, running_acc=0.7879, grad=6.7135]Training epoch 7:  88%|████████▊ | 143/163 [02:36<00:20,  1.01s/it, loss=0.6603, batch_acc=0.7812, running_acc=0.7878, grad=7.7257]Training epoch 7:  88%|████████▊ | 144/163 [02:37<00:18,  1.03it/s, loss=0.6603, batch_acc=0.7812, running_acc=0.7878, grad=7.7257]Training epoch 7:  88%|████████▊ | 144/163 [02:37<00:18,  1.03it/s, loss=0.5148, batch_acc=0.8750, running_acc=0.7884, grad=5.6429]Training epoch 7:  89%|████████▉ | 145/163 [02:37<00:17,  1.06it/s, loss=0.5148, batch_acc=0.8750, running_acc=0.7884, grad=5.6429]Training epoch 7:  89%|████████▉ | 145/163 [02:37<00:17,  1.06it/s, loss=0.7067, batch_acc=0.7812, running_acc=0.7884, grad=9.6769]Training epoch 7:  90%|████████▉ | 146/163 [02:39<00:17,  1.02s/it, loss=0.7067, batch_acc=0.7812, running_acc=0.7884, grad=9.6769]Training epoch 7:  90%|████████▉ | 146/163 [02:39<00:17,  1.02s/it, loss=0.9370, batch_acc=0.7188, running_acc=0.7879, grad=8.4993]Training epoch 7:  90%|█████████ | 147/163 [02:40<00:15,  1.02it/s, loss=0.9370, batch_acc=0.7188, running_acc=0.7879, grad=8.4993]Training epoch 7:  90%|█████████ | 147/163 [02:40<00:15,  1.02it/s, loss=0.6781, batch_acc=0.8125, running_acc=0.7881, grad=5.8254]Training epoch 7:  91%|█████████ | 148/163 [02:40<00:14,  1.05it/s, loss=0.6781, batch_acc=0.8125, running_acc=0.7881, grad=5.8254]Training epoch 7:  91%|█████████ | 148/163 [02:40<00:14,  1.05it/s, loss=0.6758, batch_acc=0.7812, running_acc=0.7880, grad=7.0555]Training epoch 7:  91%|█████████▏| 149/163 [02:41<00:13,  1.08it/s, loss=0.6758, batch_acc=0.7812, running_acc=0.7880, grad=7.0555]Training epoch 7:  91%|█████████▏| 149/163 [02:41<00:13,  1.08it/s, loss=0.4764, batch_acc=0.8750, running_acc=0.7886, grad=5.3247]Training epoch 7:  92%|█████████▏| 150/163 [02:43<00:15,  1.21s/it, loss=0.4764, batch_acc=0.8750, running_acc=0.7886, grad=5.3247]Training epoch 7:  92%|█████████▏| 150/163 [02:43<00:15,  1.21s/it, loss=0.6764, batch_acc=0.7812, running_acc=0.7885, grad=7.1590]Training epoch 7:  93%|█████████▎| 151/163 [02:44<00:13,  1.11s/it, loss=0.6764, batch_acc=0.7812, running_acc=0.7885, grad=7.1590]Training epoch 7:  93%|█████████▎| 151/163 [02:44<00:13,  1.11s/it, loss=0.6514, batch_acc=0.8125, running_acc=0.7887, grad=7.5179]Training epoch 7:  93%|█████████▎| 152/163 [02:45<00:11,  1.04s/it, loss=0.6514, batch_acc=0.8125, running_acc=0.7887, grad=7.5179]Training epoch 7:  93%|█████████▎| 152/163 [02:45<00:11,  1.04s/it, loss=1.1783, batch_acc=0.6562, running_acc=0.7878, grad=11.0325]Training epoch 7:  94%|█████████▍| 153/163 [02:46<00:09,  1.01it/s, loss=1.1783, batch_acc=0.6562, running_acc=0.7878, grad=11.0325]Training epoch 7:  94%|█████████▍| 153/163 [02:46<00:09,  1.01it/s, loss=0.3656, batch_acc=0.9688, running_acc=0.7890, grad=4.9828] Training epoch 7:  94%|█████████▍| 154/163 [02:48<00:11,  1.24s/it, loss=0.3656, batch_acc=0.9688, running_acc=0.7890, grad=4.9828]Training epoch 7:  94%|█████████▍| 154/163 [02:48<00:11,  1.24s/it, loss=0.6888, batch_acc=0.8125, running_acc=0.7892, grad=5.5889]Training epoch 7:  95%|█████████▌| 155/163 [02:49<00:09,  1.13s/it, loss=0.6888, batch_acc=0.8125, running_acc=0.7892, grad=5.5889]Training epoch 7:  95%|█████████▌| 155/163 [02:49<00:09,  1.13s/it, loss=0.6584, batch_acc=0.8750, running_acc=0.7897, grad=5.7293]Training epoch 7:  96%|█████████▌| 156/163 [02:49<00:07,  1.06s/it, loss=0.6584, batch_acc=0.8750, running_acc=0.7897, grad=5.7293]Training epoch 7:  96%|█████████▌| 156/163 [02:49<00:07,  1.06s/it, loss=0.7128, batch_acc=0.8125, running_acc=0.7899, grad=7.4632]Training epoch 7:  96%|█████████▋| 157/163 [02:50<00:06,  1.00s/it, loss=0.7128, batch_acc=0.8125, running_acc=0.7899, grad=7.4632]Training epoch 7:  96%|█████████▋| 157/163 [02:50<00:06,  1.00s/it, loss=0.7851, batch_acc=0.7500, running_acc=0.7896, grad=7.4767]Training epoch 7:  97%|█████████▋| 158/163 [02:52<00:06,  1.23s/it, loss=0.7851, batch_acc=0.7500, running_acc=0.7896, grad=7.4767]Training epoch 7:  97%|█████████▋| 158/163 [02:52<00:06,  1.23s/it, loss=0.6250, batch_acc=0.7812, running_acc=0.7896, grad=5.5514]Training epoch 7:  98%|█████████▊| 159/163 [02:53<00:04,  1.12s/it, loss=0.6250, batch_acc=0.7812, running_acc=0.7896, grad=5.5514]Training epoch 7:  98%|█████████▊| 159/163 [02:53<00:04,  1.12s/it, loss=0.4866, batch_acc=0.8438, running_acc=0.7899, grad=5.9192]Training epoch 7:  98%|█████████▊| 160/163 [02:54<00:03,  1.05s/it, loss=0.4866, batch_acc=0.8438, running_acc=0.7899, grad=5.9192]Training epoch 7:  98%|█████████▊| 160/163 [02:54<00:03,  1.05s/it, loss=0.5635, batch_acc=0.8438, running_acc=0.7902, grad=6.3853]Training epoch 7:  99%|█████████▉| 161/163 [02:55<00:01,  1.00it/s, loss=0.5635, batch_acc=0.8438, running_acc=0.7902, grad=6.3853]Training epoch 7:  99%|█████████▉| 161/163 [02:55<00:01,  1.00it/s, loss=0.7709, batch_acc=0.7500, running_acc=0.7900, grad=6.7428]Training epoch 7:  99%|█████████▉| 162/163 [02:56<00:00,  1.04it/s, loss=0.7709, batch_acc=0.7500, running_acc=0.7900, grad=6.7428]Training epoch 7:  99%|█████████▉| 162/163 [02:56<00:00,  1.04it/s, loss=0.4888, batch_acc=0.9062, running_acc=0.7907, grad=5.9291]Training epoch 7: 100%|██████████| 163/163 [02:56<00:00,  1.16it/s, loss=0.4888, batch_acc=0.9062, running_acc=0.7907, grad=5.9291]Training epoch 7: 100%|██████████| 163/163 [02:56<00:00,  1.16it/s, loss=0.4280, batch_acc=0.9048, running_acc=0.7912, grad=6.6860]Training epoch 7: 100%|██████████| 163/163 [02:56<00:00,  1.08s/it, loss=0.4280, batch_acc=0.9048, running_acc=0.7912, grad=6.6860]
Evaluation epoch 7:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 7:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it]Evaluation epoch 7:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it, loss=1.1701, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 7:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=1.1701, batch_acc=0.6250, running_acc=0.6250]Evaluation epoch 7:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=0.4591, batch_acc=0.9062, running_acc=0.7656]Evaluation epoch 7:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.4591, batch_acc=0.9062, running_acc=0.7656]Evaluation epoch 7:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=1.2463, batch_acc=0.6562, running_acc=0.7292]Evaluation epoch 7:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=1.2463, batch_acc=0.6562, running_acc=0.7292]Evaluation epoch 7:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=1.5055, batch_acc=0.5312, running_acc=0.6797]Evaluation epoch 7:  18%|█▊        | 5/28 [00:10<00:38,  1.66s/it, loss=1.5055, batch_acc=0.5312, running_acc=0.6797]Evaluation epoch 7:  18%|█▊        | 5/28 [00:10<00:38,  1.66s/it, loss=1.3679, batch_acc=0.6562, running_acc=0.6750]Evaluation epoch 7:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=1.3679, batch_acc=0.6562, running_acc=0.6750]Evaluation epoch 7:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=0.7651, batch_acc=0.8125, running_acc=0.6979]Evaluation epoch 7:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.7651, batch_acc=0.8125, running_acc=0.6979]Evaluation epoch 7:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=1.0961, batch_acc=0.7188, running_acc=0.7009]Evaluation epoch 7:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=1.0961, batch_acc=0.7188, running_acc=0.7009]Evaluation epoch 7:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.7781, batch_acc=0.7500, running_acc=0.7070]Evaluation epoch 7:  32%|███▏      | 9/28 [00:14<00:25,  1.33s/it, loss=0.7781, batch_acc=0.7500, running_acc=0.7070]Evaluation epoch 7:  32%|███▏      | 9/28 [00:14<00:25,  1.33s/it, loss=1.0321, batch_acc=0.7188, running_acc=0.7083]Evaluation epoch 7:  36%|███▌      | 10/28 [00:14<00:17,  1.00it/s, loss=1.0321, batch_acc=0.7188, running_acc=0.7083]Evaluation epoch 7:  36%|███▌      | 10/28 [00:14<00:17,  1.00it/s, loss=0.4720, batch_acc=0.9062, running_acc=0.7281]Evaluation epoch 7:  39%|███▉      | 11/28 [00:15<00:13,  1.29it/s, loss=0.4720, batch_acc=0.9062, running_acc=0.7281]Evaluation epoch 7:  39%|███▉      | 11/28 [00:15<00:13,  1.29it/s, loss=0.8254, batch_acc=0.6875, running_acc=0.7244]Evaluation epoch 7:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=0.8254, batch_acc=0.6875, running_acc=0.7244]Evaluation epoch 7:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=0.8443, batch_acc=0.7812, running_acc=0.7292]Evaluation epoch 7:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=0.8443, batch_acc=0.7812, running_acc=0.7292]Evaluation epoch 7:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=1.1209, batch_acc=0.8125, running_acc=0.7356]Evaluation epoch 7:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=1.1209, batch_acc=0.8125, running_acc=0.7356]Evaluation epoch 7:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=2.1460, batch_acc=0.5000, running_acc=0.7188]Evaluation epoch 7:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=2.1460, batch_acc=0.5000, running_acc=0.7188]Evaluation epoch 7:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.7650, batch_acc=0.5312, running_acc=0.7063]Evaluation epoch 7:  57%|█████▋    | 16/28 [00:24<00:18,  1.53s/it, loss=1.7650, batch_acc=0.5312, running_acc=0.7063]Evaluation epoch 7:  57%|█████▋    | 16/28 [00:24<00:18,  1.53s/it, loss=1.0766, batch_acc=0.7188, running_acc=0.7070]Evaluation epoch 7:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=1.0766, batch_acc=0.7188, running_acc=0.7070]Evaluation epoch 7:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.5821, batch_acc=0.8438, running_acc=0.7151]Evaluation epoch 7:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.5821, batch_acc=0.8438, running_acc=0.7151]Evaluation epoch 7:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.9789, batch_acc=0.7812, running_acc=0.7188]Evaluation epoch 7:  68%|██████▊   | 19/28 [00:24<00:06,  1.44it/s, loss=0.9789, batch_acc=0.7812, running_acc=0.7188]Evaluation epoch 7:  68%|██████▊   | 19/28 [00:24<00:06,  1.44it/s, loss=1.3228, batch_acc=0.4375, running_acc=0.7039]Evaluation epoch 7:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=1.3228, batch_acc=0.4375, running_acc=0.7039]Evaluation epoch 7:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=0.9981, batch_acc=0.5938, running_acc=0.6984]Evaluation epoch 7:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.9981, batch_acc=0.5938, running_acc=0.6984]Evaluation epoch 7:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.8257, batch_acc=0.8125, running_acc=0.7039]Evaluation epoch 7:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.8257, batch_acc=0.8125, running_acc=0.7039]Evaluation epoch 7:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=1.1929, batch_acc=0.6562, running_acc=0.7017]Evaluation epoch 7:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.1929, batch_acc=0.6562, running_acc=0.7017]Evaluation epoch 7:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.4973, batch_acc=0.4688, running_acc=0.6916]Evaluation epoch 7:  86%|████████▌ | 24/28 [00:34<00:08,  2.08s/it, loss=1.4973, batch_acc=0.4688, running_acc=0.6916]Evaluation epoch 7:  86%|████████▌ | 24/28 [00:34<00:08,  2.08s/it, loss=0.4841, batch_acc=0.8750, running_acc=0.6992]Evaluation epoch 7:  89%|████████▉ | 25/28 [00:34<00:04,  1.54s/it, loss=0.4841, batch_acc=0.8750, running_acc=0.6992]Evaluation epoch 7:  89%|████████▉ | 25/28 [00:34<00:04,  1.54s/it, loss=0.7046, batch_acc=0.7500, running_acc=0.7013]Evaluation epoch 7:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.7046, batch_acc=0.7500, running_acc=0.7013]Evaluation epoch 7:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.3133, batch_acc=0.5938, running_acc=0.6971]Evaluation epoch 7:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=1.3133, batch_acc=0.5938, running_acc=0.6971]Evaluation epoch 7:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=1.1359, batch_acc=0.6562, running_acc=0.6956]Evaluation epoch 7: 100%|██████████| 28/28 [00:34<00:00,  1.13it/s, loss=0.9632, batch_acc=0.6667, running_acc=0.6955]Evaluation epoch 7: 100%|██████████| 28/28 [00:34<00:00,  1.25s/it, loss=0.9632, batch_acc=0.6667, running_acc=0.6955]
Training epoch 8:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 8:   1%|          | 1/163 [00:05<14:24,  5.34s/it]Training epoch 8:   1%|          | 1/163 [00:05<14:24,  5.34s/it, loss=0.6136, batch_acc=0.7812, running_acc=0.7812, grad=6.6850]Training epoch 8:   1%|          | 2/163 [00:06<07:17,  2.72s/it, loss=0.6136, batch_acc=0.7812, running_acc=0.7812, grad=6.6850]Training epoch 8:   1%|          | 2/163 [00:06<07:17,  2.72s/it, loss=0.6227, batch_acc=0.8438, running_acc=0.8125, grad=7.6937]Training epoch 8:   2%|▏         | 3/163 [00:07<05:00,  1.88s/it, loss=0.6227, batch_acc=0.8438, running_acc=0.8125, grad=7.6937]Training epoch 8:   2%|▏         | 3/163 [00:07<05:00,  1.88s/it, loss=0.6228, batch_acc=0.8438, running_acc=0.8229, grad=5.4318]Training epoch 8:   2%|▏         | 4/163 [00:09<06:02,  2.28s/it, loss=0.6228, batch_acc=0.8438, running_acc=0.8229, grad=5.4318]Training epoch 8:   2%|▏         | 4/163 [00:09<06:02,  2.28s/it, loss=0.5615, batch_acc=0.8438, running_acc=0.8281, grad=5.5075]Training epoch 8:   3%|▎         | 5/163 [00:10<04:40,  1.77s/it, loss=0.5615, batch_acc=0.8438, running_acc=0.8281, grad=5.5075]Training epoch 8:   3%|▎         | 5/163 [00:10<04:40,  1.77s/it, loss=0.4241, batch_acc=0.9062, running_acc=0.8438, grad=5.2484]Training epoch 8:   4%|▎         | 6/163 [00:11<03:56,  1.50s/it, loss=0.4241, batch_acc=0.9062, running_acc=0.8438, grad=5.2484]Training epoch 8:   4%|▎         | 6/163 [00:11<03:56,  1.50s/it, loss=0.5835, batch_acc=0.8125, running_acc=0.8385, grad=6.9695]Training epoch 8:   4%|▍         | 7/163 [00:12<03:22,  1.30s/it, loss=0.5835, batch_acc=0.8125, running_acc=0.8385, grad=6.9695]Training epoch 8:   4%|▍         | 7/163 [00:12<03:22,  1.30s/it, loss=0.5518, batch_acc=0.8438, running_acc=0.8393, grad=6.2714]Training epoch 8:   5%|▍         | 8/163 [00:14<03:37,  1.40s/it, loss=0.5518, batch_acc=0.8438, running_acc=0.8393, grad=6.2714]Training epoch 8:   5%|▍         | 8/163 [00:14<03:37,  1.40s/it, loss=0.4804, batch_acc=0.8750, running_acc=0.8438, grad=7.4571]Training epoch 8:   6%|▌         | 9/163 [00:15<03:10,  1.24s/it, loss=0.4804, batch_acc=0.8750, running_acc=0.8438, grad=7.4571]Training epoch 8:   6%|▌         | 9/163 [00:15<03:10,  1.24s/it, loss=0.9015, batch_acc=0.7812, running_acc=0.8368, grad=7.1611]Training epoch 8:   6%|▌         | 10/163 [00:16<02:52,  1.13s/it, loss=0.9015, batch_acc=0.7812, running_acc=0.8368, grad=7.1611]Training epoch 8:   6%|▌         | 10/163 [00:16<02:52,  1.13s/it, loss=0.5836, batch_acc=0.8125, running_acc=0.8344, grad=7.0455]Training epoch 8:   7%|▋         | 11/163 [00:16<02:39,  1.05s/it, loss=0.5836, batch_acc=0.8125, running_acc=0.8344, grad=7.0455]Training epoch 8:   7%|▋         | 11/163 [00:16<02:39,  1.05s/it, loss=0.3624, batch_acc=0.9688, running_acc=0.8466, grad=4.9565]Training epoch 8:   7%|▋         | 12/163 [00:18<02:48,  1.12s/it, loss=0.3624, batch_acc=0.9688, running_acc=0.8466, grad=4.9565]Training epoch 8:   7%|▋         | 12/163 [00:18<02:48,  1.12s/it, loss=0.6146, batch_acc=0.8438, running_acc=0.8464, grad=6.5202]Training epoch 8:   8%|▊         | 13/163 [00:19<02:36,  1.04s/it, loss=0.6146, batch_acc=0.8438, running_acc=0.8464, grad=6.5202]Training epoch 8:   8%|▊         | 13/163 [00:19<02:36,  1.04s/it, loss=0.4782, batch_acc=0.9062, running_acc=0.8510, grad=7.2752]Training epoch 8:   9%|▊         | 14/163 [00:20<02:28,  1.01it/s, loss=0.4782, batch_acc=0.9062, running_acc=0.8510, grad=7.2752]Training epoch 8:   9%|▊         | 14/163 [00:20<02:28,  1.01it/s, loss=0.4082, batch_acc=0.9062, running_acc=0.8549, grad=4.8216]Training epoch 8:   9%|▉         | 15/163 [00:20<02:22,  1.04it/s, loss=0.4082, batch_acc=0.9062, running_acc=0.8549, grad=4.8216]Training epoch 8:   9%|▉         | 15/163 [00:20<02:22,  1.04it/s, loss=0.4968, batch_acc=0.8438, running_acc=0.8542, grad=7.3119]Training epoch 8:  10%|▉         | 16/163 [00:22<02:57,  1.21s/it, loss=0.4968, batch_acc=0.8438, running_acc=0.8542, grad=7.3119]Training epoch 8:  10%|▉         | 16/163 [00:22<02:57,  1.21s/it, loss=0.3631, batch_acc=0.9062, running_acc=0.8574, grad=8.0333]Training epoch 8:  10%|█         | 17/163 [00:23<02:42,  1.11s/it, loss=0.3631, batch_acc=0.9062, running_acc=0.8574, grad=8.0333]Training epoch 8:  10%|█         | 17/163 [00:23<02:42,  1.11s/it, loss=0.5250, batch_acc=0.8750, running_acc=0.8585, grad=9.2021]Training epoch 8:  11%|█         | 18/163 [00:24<02:31,  1.04s/it, loss=0.5250, batch_acc=0.8750, running_acc=0.8585, grad=9.2021]Training epoch 8:  11%|█         | 18/163 [00:24<02:31,  1.04s/it, loss=0.4433, batch_acc=0.9062, running_acc=0.8611, grad=5.2289]Training epoch 8:  12%|█▏        | 19/163 [00:25<02:22,  1.01it/s, loss=0.4433, batch_acc=0.9062, running_acc=0.8611, grad=5.2289]Training epoch 8:  12%|█▏        | 19/163 [00:25<02:22,  1.01it/s, loss=0.6110, batch_acc=0.8750, running_acc=0.8618, grad=7.3035]Training epoch 8:  12%|█▏        | 20/163 [00:26<02:33,  1.07s/it, loss=0.6110, batch_acc=0.8750, running_acc=0.8618, grad=7.3035]Training epoch 8:  12%|█▏        | 20/163 [00:26<02:33,  1.07s/it, loss=0.6374, batch_acc=0.8125, running_acc=0.8594, grad=6.2930]Training epoch 8:  13%|█▎        | 21/163 [00:27<02:26,  1.03s/it, loss=0.6374, batch_acc=0.8125, running_acc=0.8594, grad=6.2930]Training epoch 8:  13%|█▎        | 21/163 [00:27<02:26,  1.03s/it, loss=0.3265, batch_acc=0.9688, running_acc=0.8646, grad=5.1291]Training epoch 8:  13%|█▎        | 22/163 [00:28<02:23,  1.01s/it, loss=0.3265, batch_acc=0.9688, running_acc=0.8646, grad=5.1291]Training epoch 8:  13%|█▎        | 22/163 [00:28<02:23,  1.01s/it, loss=0.7570, batch_acc=0.7500, running_acc=0.8594, grad=5.7674]Training epoch 8:  14%|█▍        | 23/163 [00:29<02:16,  1.03it/s, loss=0.7570, batch_acc=0.7500, running_acc=0.8594, grad=5.7674]Training epoch 8:  14%|█▍        | 23/163 [00:29<02:16,  1.03it/s, loss=0.5759, batch_acc=0.8750, running_acc=0.8601, grad=5.5550]Training epoch 8:  15%|█▍        | 24/163 [00:31<02:43,  1.18s/it, loss=0.5759, batch_acc=0.8750, running_acc=0.8601, grad=5.5550]Training epoch 8:  15%|█▍        | 24/163 [00:31<02:43,  1.18s/it, loss=0.5672, batch_acc=0.8750, running_acc=0.8607, grad=5.5204]Training epoch 8:  15%|█▌        | 25/163 [00:31<02:30,  1.09s/it, loss=0.5672, batch_acc=0.8750, running_acc=0.8607, grad=5.5204]Training epoch 8:  15%|█▌        | 25/163 [00:31<02:30,  1.09s/it, loss=0.4852, batch_acc=0.8438, running_acc=0.8600, grad=6.3745]Training epoch 8:  16%|█▌        | 26/163 [00:32<02:20,  1.03s/it, loss=0.4852, batch_acc=0.8438, running_acc=0.8600, grad=6.3745]Training epoch 8:  16%|█▌        | 26/163 [00:32<02:20,  1.03s/it, loss=0.5623, batch_acc=0.8125, running_acc=0.8582, grad=9.2179]Training epoch 8:  17%|█▋        | 27/163 [00:33<02:13,  1.02it/s, loss=0.5623, batch_acc=0.8125, running_acc=0.8582, grad=9.2179]Training epoch 8:  17%|█▋        | 27/163 [00:33<02:13,  1.02it/s, loss=0.6397, batch_acc=0.8125, running_acc=0.8565, grad=5.8595]Training epoch 8:  17%|█▋        | 28/163 [00:35<02:38,  1.17s/it, loss=0.6397, batch_acc=0.8125, running_acc=0.8565, grad=5.8595]Training epoch 8:  17%|█▋        | 28/163 [00:35<02:38,  1.17s/it, loss=0.6085, batch_acc=0.7812, running_acc=0.8538, grad=7.4844]Training epoch 8:  18%|█▊        | 29/163 [00:36<02:34,  1.15s/it, loss=0.6085, batch_acc=0.7812, running_acc=0.8538, grad=7.4844]Training epoch 8:  18%|█▊        | 29/163 [00:36<02:34,  1.15s/it, loss=0.4612, batch_acc=0.8750, running_acc=0.8545, grad=5.3572]Training epoch 8:  18%|█▊        | 30/163 [00:37<02:22,  1.07s/it, loss=0.4612, batch_acc=0.8750, running_acc=0.8545, grad=5.3572]Training epoch 8:  18%|█▊        | 30/163 [00:37<02:22,  1.07s/it, loss=0.5367, batch_acc=0.7500, running_acc=0.8510, grad=5.6669]Training epoch 8:  19%|█▉        | 31/163 [00:38<02:13,  1.01s/it, loss=0.5367, batch_acc=0.7500, running_acc=0.8510, grad=5.6669]Training epoch 8:  19%|█▉        | 31/163 [00:38<02:13,  1.01s/it, loss=0.5027, batch_acc=0.8438, running_acc=0.8508, grad=5.7277]Training epoch 8:  20%|█▉        | 32/163 [00:39<02:35,  1.19s/it, loss=0.5027, batch_acc=0.8438, running_acc=0.8508, grad=5.7277]Training epoch 8:  20%|█▉        | 32/163 [00:39<02:35,  1.19s/it, loss=0.7258, batch_acc=0.7500, running_acc=0.8477, grad=7.7516]Training epoch 8:  20%|██        | 33/163 [00:40<02:23,  1.11s/it, loss=0.7258, batch_acc=0.7500, running_acc=0.8477, grad=7.7516]Training epoch 8:  20%|██        | 33/163 [00:40<02:23,  1.11s/it, loss=0.6380, batch_acc=0.8438, running_acc=0.8475, grad=7.2447]Training epoch 8:  21%|██        | 34/163 [00:41<02:13,  1.04s/it, loss=0.6380, batch_acc=0.8438, running_acc=0.8475, grad=7.2447]Training epoch 8:  21%|██        | 34/163 [00:41<02:13,  1.04s/it, loss=0.4577, batch_acc=0.9062, running_acc=0.8493, grad=4.2660]Training epoch 8:  21%|██▏       | 35/163 [00:42<02:06,  1.01it/s, loss=0.4577, batch_acc=0.9062, running_acc=0.8493, grad=4.2660]Training epoch 8:  21%|██▏       | 35/163 [00:42<02:06,  1.01it/s, loss=0.4642, batch_acc=0.8750, running_acc=0.8500, grad=6.3024]Training epoch 8:  22%|██▏       | 36/163 [00:43<02:13,  1.05s/it, loss=0.4642, batch_acc=0.8750, running_acc=0.8500, grad=6.3024]Training epoch 8:  22%|██▏       | 36/163 [00:43<02:13,  1.05s/it, loss=0.4350, batch_acc=0.9375, running_acc=0.8524, grad=6.3884]Training epoch 8:  23%|██▎       | 37/163 [00:44<02:20,  1.12s/it, loss=0.4350, batch_acc=0.9375, running_acc=0.8524, grad=6.3884]Training epoch 8:  23%|██▎       | 37/163 [00:44<02:20,  1.12s/it, loss=0.4551, batch_acc=0.8750, running_acc=0.8530, grad=5.9699]Training epoch 8:  23%|██▎       | 38/163 [00:45<02:10,  1.05s/it, loss=0.4551, batch_acc=0.8750, running_acc=0.8530, grad=5.9699]Training epoch 8:  23%|██▎       | 38/163 [00:45<02:10,  1.05s/it, loss=0.3890, batch_acc=0.9062, running_acc=0.8544, grad=4.2938]Training epoch 8:  24%|██▍       | 39/163 [00:46<02:03,  1.00it/s, loss=0.3890, batch_acc=0.9062, running_acc=0.8544, grad=4.2938]Training epoch 8:  24%|██▍       | 39/163 [00:46<02:03,  1.00it/s, loss=0.6706, batch_acc=0.8750, running_acc=0.8550, grad=7.8922]Training epoch 8:  25%|██▍       | 40/163 [00:47<02:07,  1.04s/it, loss=0.6706, batch_acc=0.8750, running_acc=0.8550, grad=7.8922]Training epoch 8:  25%|██▍       | 40/163 [00:47<02:07,  1.04s/it, loss=0.4193, batch_acc=0.8438, running_acc=0.8547, grad=5.6702]Training epoch 8:  25%|██▌       | 41/163 [00:49<02:37,  1.29s/it, loss=0.4193, batch_acc=0.8438, running_acc=0.8547, grad=5.6702]Training epoch 8:  25%|██▌       | 41/163 [00:49<02:37,  1.29s/it, loss=0.5989, batch_acc=0.8750, running_acc=0.8552, grad=5.4356]Training epoch 8:  26%|██▌       | 42/163 [00:50<02:21,  1.17s/it, loss=0.5989, batch_acc=0.8750, running_acc=0.8552, grad=5.4356]Training epoch 8:  26%|██▌       | 42/163 [00:50<02:21,  1.17s/it, loss=0.4331, batch_acc=0.8438, running_acc=0.8549, grad=6.9931]Training epoch 8:  26%|██▋       | 43/163 [00:51<02:09,  1.08s/it, loss=0.4331, batch_acc=0.8438, running_acc=0.8549, grad=6.9931]Training epoch 8:  26%|██▋       | 43/163 [00:51<02:09,  1.08s/it, loss=0.4870, batch_acc=0.8438, running_acc=0.8547, grad=4.8876]Training epoch 8:  27%|██▋       | 44/163 [00:52<02:01,  1.02s/it, loss=0.4870, batch_acc=0.8438, running_acc=0.8547, grad=4.8876]Training epoch 8:  27%|██▋       | 44/163 [00:52<02:01,  1.02s/it, loss=0.5505, batch_acc=0.8125, running_acc=0.8537, grad=6.6874]Training epoch 8:  28%|██▊       | 45/163 [00:53<02:08,  1.09s/it, loss=0.5505, batch_acc=0.8125, running_acc=0.8537, grad=6.6874]Training epoch 8:  28%|██▊       | 45/163 [00:53<02:08,  1.09s/it, loss=0.4539, batch_acc=0.8438, running_acc=0.8535, grad=5.2847]Training epoch 8:  28%|██▊       | 46/163 [00:54<02:00,  1.03s/it, loss=0.4539, batch_acc=0.8438, running_acc=0.8535, grad=5.2847]Training epoch 8:  28%|██▊       | 46/163 [00:54<02:00,  1.03s/it, loss=0.6626, batch_acc=0.7500, running_acc=0.8512, grad=6.9728]Training epoch 8:  29%|██▉       | 47/163 [00:55<01:53,  1.02it/s, loss=0.6626, batch_acc=0.7500, running_acc=0.8512, grad=6.9728]Training epoch 8:  29%|██▉       | 47/163 [00:55<01:53,  1.02it/s, loss=0.4057, batch_acc=0.8750, running_acc=0.8517, grad=4.7837]Training epoch 8:  29%|██▉       | 48/163 [00:56<01:49,  1.05it/s, loss=0.4057, batch_acc=0.8750, running_acc=0.8517, grad=4.7837]Training epoch 8:  29%|██▉       | 48/163 [00:56<01:49,  1.05it/s, loss=0.3390, batch_acc=0.8750, running_acc=0.8522, grad=5.4297]Training epoch 8:  30%|███       | 49/163 [00:58<02:22,  1.25s/it, loss=0.3390, batch_acc=0.8750, running_acc=0.8522, grad=5.4297]Training epoch 8:  30%|███       | 49/163 [00:58<02:22,  1.25s/it, loss=0.3295, batch_acc=0.9375, running_acc=0.8540, grad=5.2351]Training epoch 8:  31%|███       | 50/163 [00:58<02:08,  1.14s/it, loss=0.3295, batch_acc=0.9375, running_acc=0.8540, grad=5.2351]Training epoch 8:  31%|███       | 50/163 [00:58<02:08,  1.14s/it, loss=0.4831, batch_acc=0.7812, running_acc=0.8525, grad=5.4896]Training epoch 8:  31%|███▏      | 51/163 [00:59<01:58,  1.06s/it, loss=0.4831, batch_acc=0.7812, running_acc=0.8525, grad=5.4896]Training epoch 8:  31%|███▏      | 51/163 [00:59<01:58,  1.06s/it, loss=0.5626, batch_acc=0.8438, running_acc=0.8523, grad=6.0739]Training epoch 8:  32%|███▏      | 52/163 [01:00<01:51,  1.01s/it, loss=0.5626, batch_acc=0.8438, running_acc=0.8523, grad=6.0739]Training epoch 8:  32%|███▏      | 52/163 [01:00<01:51,  1.01s/it, loss=0.4508, batch_acc=0.8750, running_acc=0.8528, grad=4.5301]Training epoch 8:  33%|███▎      | 53/163 [01:03<02:38,  1.44s/it, loss=0.4508, batch_acc=0.8750, running_acc=0.8528, grad=4.5301]Training epoch 8:  33%|███▎      | 53/163 [01:03<02:38,  1.44s/it, loss=0.4746, batch_acc=0.9062, running_acc=0.8538, grad=7.8502]Training epoch 8:  33%|███▎      | 54/163 [01:04<02:18,  1.27s/it, loss=0.4746, batch_acc=0.9062, running_acc=0.8538, grad=7.8502]Training epoch 8:  33%|███▎      | 54/163 [01:04<02:18,  1.27s/it, loss=0.6437, batch_acc=0.8438, running_acc=0.8536, grad=6.9622]Training epoch 8:  34%|███▎      | 55/163 [01:04<02:04,  1.15s/it, loss=0.6437, batch_acc=0.8438, running_acc=0.8536, grad=6.9622]Training epoch 8:  34%|███▎      | 55/163 [01:04<02:04,  1.15s/it, loss=0.8539, batch_acc=0.7500, running_acc=0.8517, grad=8.4184]Training epoch 8:  34%|███▍      | 56/163 [01:05<01:54,  1.07s/it, loss=0.8539, batch_acc=0.7500, running_acc=0.8517, grad=8.4184]Training epoch 8:  34%|███▍      | 56/163 [01:05<01:54,  1.07s/it, loss=0.7828, batch_acc=0.7812, running_acc=0.8504, grad=7.6006]Training epoch 8:  35%|███▍      | 57/163 [01:07<02:04,  1.17s/it, loss=0.7828, batch_acc=0.7812, running_acc=0.8504, grad=7.6006]Training epoch 8:  35%|███▍      | 57/163 [01:07<02:04,  1.17s/it, loss=0.5160, batch_acc=0.8438, running_acc=0.8503, grad=6.4219]Training epoch 8:  36%|███▌      | 58/163 [01:08<01:53,  1.08s/it, loss=0.5160, batch_acc=0.8438, running_acc=0.8503, grad=6.4219]Training epoch 8:  36%|███▌      | 58/163 [01:08<01:53,  1.08s/it, loss=0.5006, batch_acc=0.8438, running_acc=0.8502, grad=4.8014]Training epoch 8:  36%|███▌      | 59/163 [01:08<01:46,  1.02s/it, loss=0.5006, batch_acc=0.8438, running_acc=0.8502, grad=4.8014]Training epoch 8:  36%|███▌      | 59/163 [01:08<01:46,  1.02s/it, loss=0.5202, batch_acc=0.8750, running_acc=0.8506, grad=4.8559]Training epoch 8:  37%|███▋      | 60/163 [01:09<01:40,  1.02it/s, loss=0.5202, batch_acc=0.8750, running_acc=0.8506, grad=4.8559]Training epoch 8:  37%|███▋      | 60/163 [01:09<01:40,  1.02it/s, loss=0.8233, batch_acc=0.7812, running_acc=0.8495, grad=9.8625]Training epoch 8:  37%|███▋      | 61/163 [01:11<01:55,  1.13s/it, loss=0.8233, batch_acc=0.7812, running_acc=0.8495, grad=9.8625]Training epoch 8:  37%|███▋      | 61/163 [01:11<01:55,  1.13s/it, loss=0.6445, batch_acc=0.8125, running_acc=0.8489, grad=7.1030]Training epoch 8:  38%|███▊      | 62/163 [01:12<01:46,  1.06s/it, loss=0.6445, batch_acc=0.8125, running_acc=0.8489, grad=7.1030]Training epoch 8:  38%|███▊      | 62/163 [01:12<01:46,  1.06s/it, loss=0.5640, batch_acc=0.8750, running_acc=0.8493, grad=8.4198]Training epoch 8:  39%|███▊      | 63/163 [01:13<01:40,  1.00s/it, loss=0.5640, batch_acc=0.8750, running_acc=0.8493, grad=8.4198]Training epoch 8:  39%|███▊      | 63/163 [01:13<01:40,  1.00s/it, loss=0.6049, batch_acc=0.8438, running_acc=0.8492, grad=5.4790]Training epoch 8:  39%|███▉      | 64/163 [01:13<01:35,  1.04it/s, loss=0.6049, batch_acc=0.8438, running_acc=0.8492, grad=5.4790]Training epoch 8:  39%|███▉      | 64/163 [01:13<01:35,  1.04it/s, loss=0.4992, batch_acc=0.9375, running_acc=0.8506, grad=5.6765]Training epoch 8:  40%|███▉      | 65/163 [01:15<01:45,  1.08s/it, loss=0.4992, batch_acc=0.9375, running_acc=0.8506, grad=5.6765]Training epoch 8:  40%|███▉      | 65/163 [01:15<01:45,  1.08s/it, loss=0.4840, batch_acc=0.8125, running_acc=0.8500, grad=7.1649]Training epoch 8:  40%|████      | 66/163 [01:16<01:38,  1.02s/it, loss=0.4840, batch_acc=0.8125, running_acc=0.8500, grad=7.1649]Training epoch 8:  40%|████      | 66/163 [01:16<01:38,  1.02s/it, loss=0.4992, batch_acc=0.8750, running_acc=0.8504, grad=5.2795]Training epoch 8:  41%|████      | 67/163 [01:17<01:33,  1.02it/s, loss=0.4992, batch_acc=0.8750, running_acc=0.8504, grad=5.2795]Training epoch 8:  41%|████      | 67/163 [01:17<01:33,  1.02it/s, loss=0.3650, batch_acc=0.9062, running_acc=0.8512, grad=6.3332]Training epoch 8:  42%|████▏     | 68/163 [01:17<01:30,  1.05it/s, loss=0.3650, batch_acc=0.9062, running_acc=0.8512, grad=6.3332]Training epoch 8:  42%|████▏     | 68/163 [01:17<01:30,  1.05it/s, loss=0.4448, batch_acc=0.8125, running_acc=0.8506, grad=6.0163]Training epoch 8:  42%|████▏     | 69/163 [01:19<01:42,  1.10s/it, loss=0.4448, batch_acc=0.8125, running_acc=0.8506, grad=6.0163]Training epoch 8:  42%|████▏     | 69/163 [01:19<01:42,  1.10s/it, loss=0.4202, batch_acc=0.9062, running_acc=0.8514, grad=6.4274]Training epoch 8:  43%|████▎     | 70/163 [01:21<01:56,  1.26s/it, loss=0.4202, batch_acc=0.9062, running_acc=0.8514, grad=6.4274]Training epoch 8:  43%|████▎     | 70/163 [01:21<01:56,  1.26s/it, loss=0.3630, batch_acc=0.9375, running_acc=0.8527, grad=6.0185]Training epoch 8:  44%|████▎     | 71/163 [01:21<01:45,  1.14s/it, loss=0.3630, batch_acc=0.9375, running_acc=0.8527, grad=6.0185]Training epoch 8:  44%|████▎     | 71/163 [01:21<01:45,  1.14s/it, loss=0.6235, batch_acc=0.7500, running_acc=0.8512, grad=7.6147]Training epoch 8:  44%|████▍     | 72/163 [01:22<01:36,  1.06s/it, loss=0.6235, batch_acc=0.7500, running_acc=0.8512, grad=7.6147]Training epoch 8:  44%|████▍     | 72/163 [01:22<01:36,  1.06s/it, loss=0.3855, batch_acc=0.8750, running_acc=0.8516, grad=5.6583]Training epoch 8:  45%|████▍     | 73/163 [01:23<01:38,  1.10s/it, loss=0.3855, batch_acc=0.8750, running_acc=0.8516, grad=5.6583]Training epoch 8:  45%|████▍     | 73/163 [01:23<01:38,  1.10s/it, loss=0.7743, batch_acc=0.7812, running_acc=0.8506, grad=10.8764]Training epoch 8:  45%|████▌     | 74/163 [01:25<01:57,  1.32s/it, loss=0.7743, batch_acc=0.7812, running_acc=0.8506, grad=10.8764]Training epoch 8:  45%|████▌     | 74/163 [01:25<01:57,  1.32s/it, loss=0.5627, batch_acc=0.8750, running_acc=0.8509, grad=8.2275] Training epoch 8:  46%|████▌     | 75/163 [01:26<01:44,  1.19s/it, loss=0.5627, batch_acc=0.8750, running_acc=0.8509, grad=8.2275]Training epoch 8:  46%|████▌     | 75/163 [01:26<01:44,  1.19s/it, loss=0.4954, batch_acc=0.8750, running_acc=0.8512, grad=5.2720]Training epoch 8:  47%|████▋     | 76/163 [01:27<01:35,  1.10s/it, loss=0.4954, batch_acc=0.8750, running_acc=0.8512, grad=5.2720]Training epoch 8:  47%|████▋     | 76/163 [01:27<01:35,  1.10s/it, loss=0.7090, batch_acc=0.8125, running_acc=0.8507, grad=8.9515]Training epoch 8:  47%|████▋     | 77/163 [01:28<01:34,  1.10s/it, loss=0.7090, batch_acc=0.8125, running_acc=0.8507, grad=8.9515]Training epoch 8:  47%|████▋     | 77/163 [01:28<01:34,  1.10s/it, loss=0.6509, batch_acc=0.7812, running_acc=0.8498, grad=7.7822]Training epoch 8:  48%|████▊     | 78/163 [01:30<02:00,  1.42s/it, loss=0.6509, batch_acc=0.7812, running_acc=0.8498, grad=7.7822]Training epoch 8:  48%|████▊     | 78/163 [01:30<02:00,  1.42s/it, loss=0.4752, batch_acc=0.8750, running_acc=0.8502, grad=6.7548]Training epoch 8:  48%|████▊     | 79/163 [01:31<01:45,  1.26s/it, loss=0.4752, batch_acc=0.8750, running_acc=0.8502, grad=6.7548]Training epoch 8:  48%|████▊     | 79/163 [01:31<01:45,  1.26s/it, loss=0.4478, batch_acc=0.9062, running_acc=0.8509, grad=5.4984]Training epoch 8:  49%|████▉     | 80/163 [01:32<01:34,  1.14s/it, loss=0.4478, batch_acc=0.9062, running_acc=0.8509, grad=5.4984]Training epoch 8:  49%|████▉     | 80/163 [01:32<01:34,  1.14s/it, loss=0.3140, batch_acc=0.9375, running_acc=0.8520, grad=3.6255]Training epoch 8:  50%|████▉     | 81/163 [01:33<01:27,  1.06s/it, loss=0.3140, batch_acc=0.9375, running_acc=0.8520, grad=3.6255]Training epoch 8:  50%|████▉     | 81/163 [01:33<01:27,  1.06s/it, loss=0.6325, batch_acc=0.8125, running_acc=0.8515, grad=6.1854]Training epoch 8:  50%|█████     | 82/163 [01:35<01:44,  1.29s/it, loss=0.6325, batch_acc=0.8125, running_acc=0.8515, grad=6.1854]Training epoch 8:  50%|█████     | 82/163 [01:35<01:44,  1.29s/it, loss=0.7136, batch_acc=0.7500, running_acc=0.8502, grad=7.9014]Training epoch 8:  51%|█████     | 83/163 [01:36<01:33,  1.17s/it, loss=0.7136, batch_acc=0.7500, running_acc=0.8502, grad=7.9014]Training epoch 8:  51%|█████     | 83/163 [01:36<01:33,  1.17s/it, loss=0.4144, batch_acc=0.8750, running_acc=0.8505, grad=4.9791]Training epoch 8:  52%|█████▏    | 84/163 [01:37<01:25,  1.08s/it, loss=0.4144, batch_acc=0.8750, running_acc=0.8505, grad=4.9791]Training epoch 8:  52%|█████▏    | 84/163 [01:37<01:25,  1.08s/it, loss=0.4842, batch_acc=0.8750, running_acc=0.8508, grad=5.3602]Training epoch 8:  52%|█████▏    | 85/163 [01:38<01:21,  1.04s/it, loss=0.4842, batch_acc=0.8750, running_acc=0.8508, grad=5.3602]Training epoch 8:  52%|█████▏    | 85/163 [01:38<01:21,  1.04s/it, loss=0.6095, batch_acc=0.8125, running_acc=0.8504, grad=8.0598]Training epoch 8:  53%|█████▎    | 86/163 [01:39<01:28,  1.15s/it, loss=0.6095, batch_acc=0.8125, running_acc=0.8504, grad=8.0598]Training epoch 8:  53%|█████▎    | 86/163 [01:39<01:28,  1.15s/it, loss=0.4331, batch_acc=0.8750, running_acc=0.8507, grad=6.8627]Training epoch 8:  53%|█████▎    | 87/163 [01:40<01:21,  1.07s/it, loss=0.4331, batch_acc=0.8750, running_acc=0.8507, grad=6.8627]Training epoch 8:  53%|█████▎    | 87/163 [01:40<01:21,  1.07s/it, loss=0.4562, batch_acc=0.9062, running_acc=0.8513, grad=6.1772]Training epoch 8:  54%|█████▍    | 88/163 [01:41<01:15,  1.01s/it, loss=0.4562, batch_acc=0.9062, running_acc=0.8513, grad=6.1772]Training epoch 8:  54%|█████▍    | 88/163 [01:41<01:15,  1.01s/it, loss=0.3739, batch_acc=0.9062, running_acc=0.8519, grad=4.9478]Training epoch 8:  55%|█████▍    | 89/163 [01:42<01:14,  1.01s/it, loss=0.3739, batch_acc=0.9062, running_acc=0.8519, grad=4.9478]Training epoch 8:  55%|█████▍    | 89/163 [01:42<01:14,  1.01s/it, loss=0.3797, batch_acc=0.9062, running_acc=0.8525, grad=4.2654]Training epoch 8:  55%|█████▌    | 90/163 [01:43<01:30,  1.25s/it, loss=0.3797, batch_acc=0.9062, running_acc=0.8525, grad=4.2654]Training epoch 8:  55%|█████▌    | 90/163 [01:43<01:30,  1.25s/it, loss=0.6082, batch_acc=0.8438, running_acc=0.8524, grad=8.5110]Training epoch 8:  56%|█████▌    | 91/163 [01:44<01:21,  1.14s/it, loss=0.6082, batch_acc=0.8438, running_acc=0.8524, grad=8.5110]Training epoch 8:  56%|█████▌    | 91/163 [01:44<01:21,  1.14s/it, loss=0.5297, batch_acc=0.7812, running_acc=0.8516, grad=6.5460]Training epoch 8:  56%|█████▋    | 92/163 [01:45<01:15,  1.06s/it, loss=0.5297, batch_acc=0.7812, running_acc=0.8516, grad=6.5460]Training epoch 8:  56%|█████▋    | 92/163 [01:45<01:15,  1.06s/it, loss=0.4385, batch_acc=0.8750, running_acc=0.8519, grad=5.7030]Training epoch 8:  57%|█████▋    | 93/163 [01:46<01:16,  1.09s/it, loss=0.4385, batch_acc=0.8750, running_acc=0.8519, grad=5.7030]Training epoch 8:  57%|█████▋    | 93/163 [01:46<01:16,  1.09s/it, loss=0.6164, batch_acc=0.8125, running_acc=0.8515, grad=6.7292]Training epoch 8:  58%|█████▊    | 94/163 [01:47<01:11,  1.04s/it, loss=0.6164, batch_acc=0.8125, running_acc=0.8515, grad=6.7292]Training epoch 8:  58%|█████▊    | 94/163 [01:47<01:11,  1.04s/it, loss=0.3200, batch_acc=0.9062, running_acc=0.8521, grad=5.8977]Training epoch 8:  58%|█████▊    | 95/163 [01:48<01:07,  1.01it/s, loss=0.3200, batch_acc=0.9062, running_acc=0.8521, grad=5.8977]Training epoch 8:  58%|█████▊    | 95/163 [01:48<01:07,  1.01it/s, loss=0.9571, batch_acc=0.7812, running_acc=0.8513, grad=11.3829]Training epoch 8:  59%|█████▉    | 96/163 [01:49<01:04,  1.04it/s, loss=0.9571, batch_acc=0.7812, running_acc=0.8513, grad=11.3829]Training epoch 8:  59%|█████▉    | 96/163 [01:49<01:04,  1.04it/s, loss=0.5440, batch_acc=0.8750, running_acc=0.8516, grad=13.2276]Training epoch 8:  60%|█████▉    | 97/163 [01:50<01:10,  1.06s/it, loss=0.5440, batch_acc=0.8750, running_acc=0.8516, grad=13.2276]Training epoch 8:  60%|█████▉    | 97/163 [01:50<01:10,  1.06s/it, loss=0.6737, batch_acc=0.6875, running_acc=0.8499, grad=13.0569]Training epoch 8:  60%|██████    | 98/163 [01:51<01:07,  1.04s/it, loss=0.6737, batch_acc=0.6875, running_acc=0.8499, grad=13.0569]Training epoch 8:  60%|██████    | 98/163 [01:51<01:07,  1.04s/it, loss=0.3740, batch_acc=0.9062, running_acc=0.8504, grad=4.0061] Training epoch 8:  61%|██████    | 99/163 [01:52<01:03,  1.01it/s, loss=0.3740, batch_acc=0.9062, running_acc=0.8504, grad=4.0061]Training epoch 8:  61%|██████    | 99/163 [01:52<01:03,  1.01it/s, loss=0.6963, batch_acc=0.7812, running_acc=0.8497, grad=6.7824]Training epoch 8:  61%|██████▏   | 100/163 [01:53<01:00,  1.04it/s, loss=0.6963, batch_acc=0.7812, running_acc=0.8497, grad=6.7824]Training epoch 8:  61%|██████▏   | 100/163 [01:53<01:00,  1.04it/s, loss=0.5743, batch_acc=0.8750, running_acc=0.8500, grad=6.9616]Training epoch 8:  62%|██████▏   | 101/163 [01:55<01:19,  1.28s/it, loss=0.5743, batch_acc=0.8750, running_acc=0.8500, grad=6.9616]Training epoch 8:  62%|██████▏   | 101/163 [01:55<01:19,  1.28s/it, loss=0.2290, batch_acc=0.9688, running_acc=0.8512, grad=4.1505]Training epoch 8:  63%|██████▎   | 102/163 [01:56<01:10,  1.16s/it, loss=0.2290, batch_acc=0.9688, running_acc=0.8512, grad=4.1505]Training epoch 8:  63%|██████▎   | 102/163 [01:56<01:10,  1.16s/it, loss=0.5609, batch_acc=0.8438, running_acc=0.8511, grad=6.5442]Training epoch 8:  63%|██████▎   | 103/163 [01:57<01:04,  1.07s/it, loss=0.5609, batch_acc=0.8438, running_acc=0.8511, grad=6.5442]Training epoch 8:  63%|██████▎   | 103/163 [01:57<01:04,  1.07s/it, loss=0.5942, batch_acc=0.8438, running_acc=0.8510, grad=8.3807]Training epoch 8:  64%|██████▍   | 104/163 [01:58<00:59,  1.02s/it, loss=0.5942, batch_acc=0.8438, running_acc=0.8510, grad=8.3807]Training epoch 8:  64%|██████▍   | 104/163 [01:58<00:59,  1.02s/it, loss=0.4763, batch_acc=0.9375, running_acc=0.8519, grad=5.0321]Training epoch 8:  64%|██████▍   | 105/163 [01:59<01:04,  1.11s/it, loss=0.4763, batch_acc=0.9375, running_acc=0.8519, grad=5.0321]Training epoch 8:  64%|██████▍   | 105/163 [01:59<01:04,  1.11s/it, loss=0.8449, batch_acc=0.6875, running_acc=0.8503, grad=7.5195]Training epoch 8:  65%|██████▌   | 106/163 [02:00<00:59,  1.04s/it, loss=0.8449, batch_acc=0.6875, running_acc=0.8503, grad=7.5195]Training epoch 8:  65%|██████▌   | 106/163 [02:00<00:59,  1.04s/it, loss=0.4312, batch_acc=0.9375, running_acc=0.8511, grad=5.4711]Training epoch 8:  66%|██████▌   | 107/163 [02:01<00:55,  1.01it/s, loss=0.4312, batch_acc=0.9375, running_acc=0.8511, grad=5.4711]Training epoch 8:  66%|██████▌   | 107/163 [02:01<00:55,  1.01it/s, loss=0.4264, batch_acc=0.8750, running_acc=0.8513, grad=6.1191]Training epoch 8:  66%|██████▋   | 108/163 [02:02<00:52,  1.04it/s, loss=0.4264, batch_acc=0.8750, running_acc=0.8513, grad=6.1191]Training epoch 8:  66%|██████▋   | 108/163 [02:02<00:52,  1.04it/s, loss=0.6565, batch_acc=0.8125, running_acc=0.8510, grad=6.4128]Training epoch 8:  67%|██████▋   | 109/163 [02:03<01:01,  1.15s/it, loss=0.6565, batch_acc=0.8125, running_acc=0.8510, grad=6.4128]Training epoch 8:  67%|██████▋   | 109/163 [02:03<01:01,  1.15s/it, loss=0.8141, batch_acc=0.7812, running_acc=0.8503, grad=6.7500]Training epoch 8:  67%|██████▋   | 110/163 [02:05<01:06,  1.25s/it, loss=0.8141, batch_acc=0.7812, running_acc=0.8503, grad=6.7500]Training epoch 8:  67%|██████▋   | 110/163 [02:05<01:06,  1.25s/it, loss=0.4569, batch_acc=0.8750, running_acc=0.8506, grad=6.6652]Training epoch 8:  68%|██████▊   | 111/163 [02:06<00:59,  1.14s/it, loss=0.4569, batch_acc=0.8750, running_acc=0.8506, grad=6.6652]Training epoch 8:  68%|██████▊   | 111/163 [02:06<00:59,  1.14s/it, loss=0.4412, batch_acc=0.8750, running_acc=0.8508, grad=8.1155]Training epoch 8:  69%|██████▊   | 112/163 [02:07<00:54,  1.06s/it, loss=0.4412, batch_acc=0.8750, running_acc=0.8508, grad=8.1155]Training epoch 8:  69%|██████▊   | 112/163 [02:07<00:54,  1.06s/it, loss=0.3186, batch_acc=0.9062, running_acc=0.8513, grad=3.9695]Training epoch 8:  69%|██████▉   | 113/163 [02:07<00:50,  1.01s/it, loss=0.3186, batch_acc=0.9062, running_acc=0.8513, grad=3.9695]Training epoch 8:  69%|██████▉   | 113/163 [02:07<00:50,  1.01s/it, loss=0.4684, batch_acc=0.9062, running_acc=0.8518, grad=4.7575]Training epoch 8:  70%|██████▉   | 114/163 [02:09<00:54,  1.11s/it, loss=0.4684, batch_acc=0.9062, running_acc=0.8518, grad=4.7575]Training epoch 8:  70%|██████▉   | 114/163 [02:09<00:54,  1.11s/it, loss=0.4261, batch_acc=0.9062, running_acc=0.8522, grad=6.3264]Training epoch 8:  71%|███████   | 115/163 [02:10<00:49,  1.04s/it, loss=0.4261, batch_acc=0.9062, running_acc=0.8522, grad=6.3264]Training epoch 8:  71%|███████   | 115/163 [02:10<00:49,  1.04s/it, loss=0.2604, batch_acc=0.9688, running_acc=0.8533, grad=4.5629]Training epoch 8:  71%|███████   | 116/163 [02:11<00:46,  1.01it/s, loss=0.2604, batch_acc=0.9688, running_acc=0.8533, grad=4.5629]Training epoch 8:  71%|███████   | 116/163 [02:11<00:46,  1.01it/s, loss=0.3156, batch_acc=0.9375, running_acc=0.8540, grad=4.9330]Training epoch 8:  72%|███████▏  | 117/163 [02:12<00:51,  1.11s/it, loss=0.3156, batch_acc=0.9375, running_acc=0.8540, grad=4.9330]Training epoch 8:  72%|███████▏  | 117/163 [02:12<00:51,  1.11s/it, loss=0.3981, batch_acc=0.9062, running_acc=0.8544, grad=5.0321]Training epoch 8:  72%|███████▏  | 118/163 [02:13<00:50,  1.12s/it, loss=0.3981, batch_acc=0.9062, running_acc=0.8544, grad=5.0321]Training epoch 8:  72%|███████▏  | 118/163 [02:13<00:50,  1.12s/it, loss=0.3639, batch_acc=0.9375, running_acc=0.8551, grad=7.6216]Training epoch 8:  73%|███████▎  | 119/163 [02:14<00:45,  1.05s/it, loss=0.3639, batch_acc=0.9375, running_acc=0.8551, grad=7.6216]Training epoch 8:  73%|███████▎  | 119/163 [02:14<00:45,  1.05s/it, loss=0.7267, batch_acc=0.7500, running_acc=0.8543, grad=10.6571]Training epoch 8:  74%|███████▎  | 120/163 [02:15<00:42,  1.00it/s, loss=0.7267, batch_acc=0.7500, running_acc=0.8543, grad=10.6571]Training epoch 8:  74%|███████▎  | 120/163 [02:15<00:42,  1.00it/s, loss=0.5598, batch_acc=0.8125, running_acc=0.8539, grad=7.6137] Training epoch 8:  74%|███████▍  | 121/163 [02:16<00:46,  1.10s/it, loss=0.5598, batch_acc=0.8125, running_acc=0.8539, grad=7.6137]Training epoch 8:  74%|███████▍  | 121/163 [02:16<00:46,  1.10s/it, loss=0.5429, batch_acc=0.8125, running_acc=0.8536, grad=9.0540]Training epoch 8:  75%|███████▍  | 122/163 [02:17<00:43,  1.06s/it, loss=0.5429, batch_acc=0.8125, running_acc=0.8536, grad=9.0540]Training epoch 8:  75%|███████▍  | 122/163 [02:17<00:43,  1.06s/it, loss=0.7623, batch_acc=0.8125, running_acc=0.8532, grad=7.4906]Training epoch 8:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.7623, batch_acc=0.8125, running_acc=0.8532, grad=7.4906]Training epoch 8:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.5121, batch_acc=0.9062, running_acc=0.8537, grad=5.5369]Training epoch 8:  76%|███████▌  | 124/163 [02:19<00:37,  1.03it/s, loss=0.5121, batch_acc=0.9062, running_acc=0.8537, grad=5.5369]Training epoch 8:  76%|███████▌  | 124/163 [02:19<00:37,  1.03it/s, loss=0.7564, batch_acc=0.6875, running_acc=0.8523, grad=10.0576]Training epoch 8:  77%|███████▋  | 125/163 [02:21<00:45,  1.19s/it, loss=0.7564, batch_acc=0.6875, running_acc=0.8523, grad=10.0576]Training epoch 8:  77%|███████▋  | 125/163 [02:21<00:45,  1.19s/it, loss=0.3536, batch_acc=0.9375, running_acc=0.8530, grad=7.6375] Training epoch 8:  77%|███████▋  | 126/163 [02:22<00:40,  1.11s/it, loss=0.3536, batch_acc=0.9375, running_acc=0.8530, grad=7.6375]Training epoch 8:  77%|███████▋  | 126/163 [02:22<00:40,  1.11s/it, loss=0.3918, batch_acc=0.9375, running_acc=0.8537, grad=8.8693]Training epoch 8:  78%|███████▊  | 127/163 [02:22<00:37,  1.04s/it, loss=0.3918, batch_acc=0.9375, running_acc=0.8537, grad=8.8693]Training epoch 8:  78%|███████▊  | 127/163 [02:22<00:37,  1.04s/it, loss=0.5653, batch_acc=0.8125, running_acc=0.8533, grad=8.0662]Training epoch 8:  79%|███████▊  | 128/163 [02:23<00:34,  1.01it/s, loss=0.5653, batch_acc=0.8125, running_acc=0.8533, grad=8.0662]Training epoch 8:  79%|███████▊  | 128/163 [02:23<00:34,  1.01it/s, loss=0.3901, batch_acc=0.9062, running_acc=0.8538, grad=3.9057]Training epoch 8:  79%|███████▉  | 129/163 [02:25<00:39,  1.17s/it, loss=0.3901, batch_acc=0.9062, running_acc=0.8538, grad=3.9057]Training epoch 8:  79%|███████▉  | 129/163 [02:25<00:39,  1.17s/it, loss=0.7072, batch_acc=0.7812, running_acc=0.8532, grad=6.9941]Training epoch 8:  80%|███████▉  | 130/163 [02:26<00:36,  1.10s/it, loss=0.7072, batch_acc=0.7812, running_acc=0.8532, grad=6.9941]Training epoch 8:  80%|███████▉  | 130/163 [02:26<00:36,  1.10s/it, loss=0.3116, batch_acc=0.9375, running_acc=0.8538, grad=4.3450]Training epoch 8:  80%|████████  | 131/163 [02:27<00:33,  1.03s/it, loss=0.3116, batch_acc=0.9375, running_acc=0.8538, grad=4.3450]Training epoch 8:  80%|████████  | 131/163 [02:27<00:33,  1.03s/it, loss=0.4640, batch_acc=0.9062, running_acc=0.8542, grad=6.7259]Training epoch 8:  81%|████████  | 132/163 [02:28<00:30,  1.01it/s, loss=0.4640, batch_acc=0.9062, running_acc=0.8542, grad=6.7259]Training epoch 8:  81%|████████  | 132/163 [02:28<00:30,  1.01it/s, loss=0.5255, batch_acc=0.8438, running_acc=0.8542, grad=8.5476]Training epoch 8:  82%|████████▏ | 133/163 [02:29<00:34,  1.14s/it, loss=0.5255, batch_acc=0.8438, running_acc=0.8542, grad=8.5476]Training epoch 8:  82%|████████▏ | 133/163 [02:29<00:34,  1.14s/it, loss=0.5119, batch_acc=0.8750, running_acc=0.8543, grad=6.0603]Training epoch 8:  82%|████████▏ | 134/163 [02:30<00:34,  1.19s/it, loss=0.5119, batch_acc=0.8750, running_acc=0.8543, grad=6.0603]Training epoch 8:  82%|████████▏ | 134/163 [02:30<00:34,  1.19s/it, loss=0.5676, batch_acc=0.8125, running_acc=0.8540, grad=6.8379]Training epoch 8:  83%|████████▎ | 135/163 [02:31<00:30,  1.10s/it, loss=0.5676, batch_acc=0.8125, running_acc=0.8540, grad=6.8379]Training epoch 8:  83%|████████▎ | 135/163 [02:31<00:30,  1.10s/it, loss=0.4377, batch_acc=0.9062, running_acc=0.8544, grad=5.9741]Training epoch 8:  83%|████████▎ | 136/163 [02:32<00:27,  1.03s/it, loss=0.4377, batch_acc=0.9062, running_acc=0.8544, grad=5.9741]Training epoch 8:  83%|████████▎ | 136/163 [02:32<00:27,  1.03s/it, loss=0.3115, batch_acc=0.9375, running_acc=0.8550, grad=4.8975]Training epoch 8:  84%|████████▍ | 137/163 [02:34<00:31,  1.20s/it, loss=0.3115, batch_acc=0.9375, running_acc=0.8550, grad=4.8975]Training epoch 8:  84%|████████▍ | 137/163 [02:34<00:31,  1.20s/it, loss=0.5496, batch_acc=0.8438, running_acc=0.8549, grad=6.7530]Training epoch 8:  85%|████████▍ | 138/163 [02:35<00:29,  1.17s/it, loss=0.5496, batch_acc=0.8438, running_acc=0.8549, grad=6.7530]Training epoch 8:  85%|████████▍ | 138/163 [02:35<00:29,  1.17s/it, loss=0.5688, batch_acc=0.8125, running_acc=0.8546, grad=7.9606]Training epoch 8:  85%|████████▌ | 139/163 [02:36<00:25,  1.08s/it, loss=0.5688, batch_acc=0.8125, running_acc=0.8546, grad=7.9606]Training epoch 8:  85%|████████▌ | 139/163 [02:36<00:25,  1.08s/it, loss=0.5868, batch_acc=0.8438, running_acc=0.8545, grad=6.4890]Training epoch 8:  86%|████████▌ | 140/163 [02:37<00:23,  1.02s/it, loss=0.5868, batch_acc=0.8438, running_acc=0.8545, grad=6.4890]Training epoch 8:  86%|████████▌ | 140/163 [02:37<00:23,  1.02s/it, loss=0.4472, batch_acc=0.8750, running_acc=0.8547, grad=4.8958]Training epoch 8:  87%|████████▋ | 141/163 [02:38<00:23,  1.05s/it, loss=0.4472, batch_acc=0.8750, running_acc=0.8547, grad=4.8958]Training epoch 8:  87%|████████▋ | 141/163 [02:38<00:23,  1.05s/it, loss=0.2663, batch_acc=0.9375, running_acc=0.8553, grad=3.9672]Training epoch 8:  87%|████████▋ | 142/163 [02:40<00:27,  1.29s/it, loss=0.2663, batch_acc=0.9375, running_acc=0.8553, grad=3.9672]Training epoch 8:  87%|████████▋ | 142/163 [02:40<00:27,  1.29s/it, loss=0.7665, batch_acc=0.6875, running_acc=0.8541, grad=8.9529]Training epoch 8:  88%|████████▊ | 143/163 [02:40<00:23,  1.17s/it, loss=0.7665, batch_acc=0.6875, running_acc=0.8541, grad=8.9529]Training epoch 8:  88%|████████▊ | 143/163 [02:40<00:23,  1.17s/it, loss=0.4763, batch_acc=0.8750, running_acc=0.8542, grad=6.4328]Training epoch 8:  88%|████████▊ | 144/163 [02:41<00:20,  1.08s/it, loss=0.4763, batch_acc=0.8750, running_acc=0.8542, grad=6.4328]Training epoch 8:  88%|████████▊ | 144/163 [02:41<00:20,  1.08s/it, loss=0.5421, batch_acc=0.9062, running_acc=0.8546, grad=6.1693]Training epoch 8:  89%|████████▉ | 145/163 [02:42<00:18,  1.02s/it, loss=0.5421, batch_acc=0.9062, running_acc=0.8546, grad=6.1693]Training epoch 8:  89%|████████▉ | 145/163 [02:42<00:18,  1.02s/it, loss=0.4936, batch_acc=0.8125, running_acc=0.8543, grad=4.7349]Training epoch 8:  90%|████████▉ | 146/163 [02:44<00:19,  1.17s/it, loss=0.4936, batch_acc=0.8125, running_acc=0.8543, grad=4.7349]Training epoch 8:  90%|████████▉ | 146/163 [02:44<00:19,  1.17s/it, loss=0.5229, batch_acc=0.8125, running_acc=0.8540, grad=6.3665]Training epoch 8:  90%|█████████ | 147/163 [02:45<00:17,  1.08s/it, loss=0.5229, batch_acc=0.8125, running_acc=0.8540, grad=6.3665]Training epoch 8:  90%|█████████ | 147/163 [02:45<00:17,  1.08s/it, loss=0.3982, batch_acc=0.8438, running_acc=0.8540, grad=6.2304]Training epoch 8:  91%|█████████ | 148/163 [02:46<00:15,  1.02s/it, loss=0.3982, batch_acc=0.8438, running_acc=0.8540, grad=6.2304]Training epoch 8:  91%|█████████ | 148/163 [02:46<00:15,  1.02s/it, loss=0.2531, batch_acc=0.9375, running_acc=0.8545, grad=5.0514]Training epoch 8:  91%|█████████▏| 149/163 [02:47<00:15,  1.12s/it, loss=0.2531, batch_acc=0.9375, running_acc=0.8545, grad=5.0514]Training epoch 8:  91%|█████████▏| 149/163 [02:47<00:15,  1.12s/it, loss=0.5922, batch_acc=0.8438, running_acc=0.8544, grad=6.5524]Training epoch 8:  92%|█████████▏| 150/163 [02:48<00:15,  1.16s/it, loss=0.5922, batch_acc=0.8438, running_acc=0.8544, grad=6.5524]Training epoch 8:  92%|█████████▏| 150/163 [02:48<00:15,  1.16s/it, loss=0.3671, batch_acc=0.9062, running_acc=0.8548, grad=5.3518]Training epoch 8:  93%|█████████▎| 151/163 [02:49<00:12,  1.07s/it, loss=0.3671, batch_acc=0.9062, running_acc=0.8548, grad=5.3518]Training epoch 8:  93%|█████████▎| 151/163 [02:49<00:12,  1.07s/it, loss=0.3517, batch_acc=0.8750, running_acc=0.8549, grad=4.9658]Training epoch 8:  93%|█████████▎| 152/163 [02:50<00:11,  1.02s/it, loss=0.3517, batch_acc=0.8750, running_acc=0.8549, grad=4.9658]Training epoch 8:  93%|█████████▎| 152/163 [02:50<00:11,  1.02s/it, loss=0.8056, batch_acc=0.7500, running_acc=0.8542, grad=7.7901]Training epoch 8:  94%|█████████▍| 153/163 [02:51<00:11,  1.13s/it, loss=0.8056, batch_acc=0.7500, running_acc=0.8542, grad=7.7901]Training epoch 8:  94%|█████████▍| 153/163 [02:51<00:11,  1.13s/it, loss=0.5568, batch_acc=0.8125, running_acc=0.8540, grad=7.1044]Training epoch 8:  94%|█████████▍| 154/163 [02:52<00:09,  1.05s/it, loss=0.5568, batch_acc=0.8125, running_acc=0.8540, grad=7.1044]Training epoch 8:  94%|█████████▍| 154/163 [02:52<00:09,  1.05s/it, loss=0.4364, batch_acc=0.8750, running_acc=0.8541, grad=7.8835]Training epoch 8:  95%|█████████▌| 155/163 [02:53<00:08,  1.00s/it, loss=0.4364, batch_acc=0.8750, running_acc=0.8541, grad=7.8835]Training epoch 8:  95%|█████████▌| 155/163 [02:53<00:08,  1.00s/it, loss=0.8054, batch_acc=0.7500, running_acc=0.8534, grad=9.5082]Training epoch 8:  96%|█████████▌| 156/163 [02:54<00:06,  1.04it/s, loss=0.8054, batch_acc=0.7500, running_acc=0.8534, grad=9.5082]Training epoch 8:  96%|█████████▌| 156/163 [02:54<00:06,  1.04it/s, loss=0.2945, batch_acc=1.0000, running_acc=0.8544, grad=5.4041]Training epoch 8:  96%|█████████▋| 157/163 [02:56<00:07,  1.21s/it, loss=0.2945, batch_acc=1.0000, running_acc=0.8544, grad=5.4041]Training epoch 8:  96%|█████████▋| 157/163 [02:56<00:07,  1.21s/it, loss=0.7732, batch_acc=0.7500, running_acc=0.8537, grad=8.8499]Training epoch 8:  97%|█████████▋| 158/163 [02:57<00:05,  1.11s/it, loss=0.7732, batch_acc=0.7500, running_acc=0.8537, grad=8.8499]Training epoch 8:  97%|█████████▋| 158/163 [02:57<00:05,  1.11s/it, loss=0.3950, batch_acc=0.9062, running_acc=0.8540, grad=5.3184]Training epoch 8:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=0.3950, batch_acc=0.9062, running_acc=0.8540, grad=5.3184]Training epoch 8:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=0.4684, batch_acc=0.8125, running_acc=0.8538, grad=5.4960]Training epoch 8:  98%|█████████▊| 160/163 [02:58<00:02,  1.01it/s, loss=0.4684, batch_acc=0.8125, running_acc=0.8538, grad=5.4960]Training epoch 8:  98%|█████████▊| 160/163 [02:58<00:02,  1.01it/s, loss=0.7697, batch_acc=0.6875, running_acc=0.8527, grad=7.4433]Training epoch 8:  99%|█████████▉| 161/163 [03:00<00:02,  1.24s/it, loss=0.7697, batch_acc=0.6875, running_acc=0.8527, grad=7.4433]Training epoch 8:  99%|█████████▉| 161/163 [03:00<00:02,  1.24s/it, loss=0.6347, batch_acc=0.8125, running_acc=0.8525, grad=7.1399]Training epoch 8:  99%|█████████▉| 162/163 [03:01<00:01,  1.13s/it, loss=0.6347, batch_acc=0.8125, running_acc=0.8525, grad=7.1399]Training epoch 8:  99%|█████████▉| 162/163 [03:01<00:01,  1.13s/it, loss=0.4384, batch_acc=0.8750, running_acc=0.8526, grad=5.9969]Training epoch 8: 100%|██████████| 163/163 [03:02<00:00,  1.02it/s, loss=0.4384, batch_acc=0.8750, running_acc=0.8526, grad=5.9969]Training epoch 8: 100%|██████████| 163/163 [03:02<00:00,  1.02it/s, loss=0.4264, batch_acc=0.9048, running_acc=0.8528, grad=7.6577]Training epoch 8: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.4264, batch_acc=0.9048, running_acc=0.8528, grad=7.6577]
Evaluation epoch 8:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 8:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it]Evaluation epoch 8:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it, loss=0.4890, batch_acc=0.7812, running_acc=0.7812]Evaluation epoch 8:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.4890, batch_acc=0.7812, running_acc=0.7812]Evaluation epoch 8:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.2804, batch_acc=0.9688, running_acc=0.8750]Evaluation epoch 8:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.2804, batch_acc=0.9688, running_acc=0.8750]Evaluation epoch 8:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.3712, batch_acc=0.9062, running_acc=0.8854]Evaluation epoch 8:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=0.3712, batch_acc=0.9062, running_acc=0.8854]Evaluation epoch 8:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=0.9872, batch_acc=0.6562, running_acc=0.8281]Evaluation epoch 8:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=0.9872, batch_acc=0.6562, running_acc=0.8281]Evaluation epoch 8:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.2807, batch_acc=0.6562, running_acc=0.7937]Evaluation epoch 8:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.2807, batch_acc=0.6562, running_acc=0.7937]Evaluation epoch 8:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=0.9177, batch_acc=0.7188, running_acc=0.7812]Evaluation epoch 8:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.9177, batch_acc=0.7188, running_acc=0.7812]Evaluation epoch 8:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=1.2837, batch_acc=0.5938, running_acc=0.7545]Evaluation epoch 8:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=1.2837, batch_acc=0.5938, running_acc=0.7545]Evaluation epoch 8:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=1.1984, batch_acc=0.5625, running_acc=0.7305]Evaluation epoch 8:  32%|███▏      | 9/28 [00:14<00:25,  1.33s/it, loss=1.1984, batch_acc=0.5625, running_acc=0.7305]Evaluation epoch 8:  32%|███▏      | 9/28 [00:14<00:25,  1.33s/it, loss=0.8270, batch_acc=0.7188, running_acc=0.7292]Evaluation epoch 8:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.8270, batch_acc=0.7188, running_acc=0.7292]Evaluation epoch 8:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.4918, batch_acc=0.9062, running_acc=0.7469]Evaluation epoch 8:  39%|███▉      | 11/28 [00:15<00:13,  1.29it/s, loss=0.4918, batch_acc=0.9062, running_acc=0.7469]Evaluation epoch 8:  39%|███▉      | 11/28 [00:15<00:13,  1.29it/s, loss=0.8786, batch_acc=0.7188, running_acc=0.7443]Evaluation epoch 8:  43%|████▎     | 12/28 [00:20<00:34,  2.14s/it, loss=0.8786, batch_acc=0.7188, running_acc=0.7443]Evaluation epoch 8:  43%|████▎     | 12/28 [00:20<00:34,  2.14s/it, loss=1.3844, batch_acc=0.5625, running_acc=0.7292]Evaluation epoch 8:  46%|████▋     | 13/28 [00:20<00:23,  1.57s/it, loss=1.3844, batch_acc=0.5625, running_acc=0.7292]Evaluation epoch 8:  46%|████▋     | 13/28 [00:20<00:23,  1.57s/it, loss=0.4879, batch_acc=0.8438, running_acc=0.7380]Evaluation epoch 8:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.4879, batch_acc=0.8438, running_acc=0.7380]Evaluation epoch 8:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=1.6333, batch_acc=0.6250, running_acc=0.7299]Evaluation epoch 8:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=1.6333, batch_acc=0.6250, running_acc=0.7299]Evaluation epoch 8:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=1.5655, batch_acc=0.5312, running_acc=0.7167]Evaluation epoch 8:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=1.5655, batch_acc=0.5312, running_acc=0.7167]Evaluation epoch 8:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=1.1566, batch_acc=0.6250, running_acc=0.7109]Evaluation epoch 8:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=1.1566, batch_acc=0.6250, running_acc=0.7109]Evaluation epoch 8:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.7950, batch_acc=0.6250, running_acc=0.7059]Evaluation epoch 8:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.7950, batch_acc=0.6250, running_acc=0.7059]Evaluation epoch 8:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.7398, batch_acc=0.8125, running_acc=0.7118]Evaluation epoch 8:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.7398, batch_acc=0.8125, running_acc=0.7118]Evaluation epoch 8:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=1.3495, batch_acc=0.6250, running_acc=0.7072]Evaluation epoch 8:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=1.3495, batch_acc=0.6250, running_acc=0.7072]Evaluation epoch 8:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.4844, batch_acc=0.9062, running_acc=0.7172]Evaluation epoch 8:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=0.4844, batch_acc=0.9062, running_acc=0.7172]Evaluation epoch 8:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=1.2007, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 8:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=1.2007, batch_acc=0.7500, running_acc=0.7188]Evaluation epoch 8:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=1.1408, batch_acc=0.6562, running_acc=0.7159]Evaluation epoch 8:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=1.1408, batch_acc=0.6562, running_acc=0.7159]Evaluation epoch 8:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=1.5595, batch_acc=0.4062, running_acc=0.7024]Evaluation epoch 8:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=1.5595, batch_acc=0.4062, running_acc=0.7024]Evaluation epoch 8:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=0.3609, batch_acc=0.8750, running_acc=0.7096]Evaluation epoch 8:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.3609, batch_acc=0.8750, running_acc=0.7096]Evaluation epoch 8:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.5374, batch_acc=0.8438, running_acc=0.7150]Evaluation epoch 8:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.5374, batch_acc=0.8438, running_acc=0.7150]Evaluation epoch 8:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=1.0034, batch_acc=0.6250, running_acc=0.7115]Evaluation epoch 8:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=1.0034, batch_acc=0.6250, running_acc=0.7115]Evaluation epoch 8:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=1.0322, batch_acc=0.6562, running_acc=0.7095]Evaluation epoch 8: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=0.9148, batch_acc=0.3333, running_acc=0.7082]Evaluation epoch 8: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=0.9148, batch_acc=0.3333, running_acc=0.7082]
Training epoch 9:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 9:   1%|          | 1/163 [00:05<15:32,  5.76s/it]Training epoch 9:   1%|          | 1/163 [00:05<15:32,  5.76s/it, loss=0.3431, batch_acc=0.8750, running_acc=0.8750, grad=6.8737]Training epoch 9:   1%|          | 2/163 [00:06<07:45,  2.89s/it, loss=0.3431, batch_acc=0.8750, running_acc=0.8750, grad=6.8737]Training epoch 9:   1%|          | 2/163 [00:06<07:45,  2.89s/it, loss=0.2304, batch_acc=0.9375, running_acc=0.9062, grad=5.5979]Training epoch 9:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=0.2304, batch_acc=0.9375, running_acc=0.9062, grad=5.5979]Training epoch 9:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=0.1645, batch_acc=0.9688, running_acc=0.9271, grad=3.4182]Training epoch 9:   2%|▏         | 4/163 [00:09<05:36,  2.11s/it, loss=0.1645, batch_acc=0.9688, running_acc=0.9271, grad=3.4182]Training epoch 9:   2%|▏         | 4/163 [00:09<05:36,  2.11s/it, loss=0.4066, batch_acc=0.8438, running_acc=0.9062, grad=5.4422]Training epoch 9:   3%|▎         | 5/163 [00:10<04:23,  1.67s/it, loss=0.4066, batch_acc=0.8438, running_acc=0.9062, grad=5.4422]Training epoch 9:   3%|▎         | 5/163 [00:10<04:23,  1.67s/it, loss=0.4223, batch_acc=0.8750, running_acc=0.9000, grad=5.6861]Training epoch 9:   4%|▎         | 6/163 [00:11<03:39,  1.40s/it, loss=0.4223, batch_acc=0.8750, running_acc=0.9000, grad=5.6861]Training epoch 9:   4%|▎         | 6/163 [00:11<03:39,  1.40s/it, loss=0.5049, batch_acc=0.8750, running_acc=0.8958, grad=5.3341]Training epoch 9:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=0.5049, batch_acc=0.8750, running_acc=0.8958, grad=5.3341]Training epoch 9:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=0.3870, batch_acc=0.8750, running_acc=0.8929, grad=9.9134]Training epoch 9:   5%|▍         | 8/163 [00:14<03:34,  1.38s/it, loss=0.3870, batch_acc=0.8750, running_acc=0.8929, grad=9.9134]Training epoch 9:   5%|▍         | 8/163 [00:14<03:34,  1.38s/it, loss=0.2784, batch_acc=0.9688, running_acc=0.9023, grad=4.3029]Training epoch 9:   6%|▌         | 9/163 [00:15<03:08,  1.22s/it, loss=0.2784, batch_acc=0.9688, running_acc=0.9023, grad=4.3029]Training epoch 9:   6%|▌         | 9/163 [00:15<03:08,  1.22s/it, loss=0.2808, batch_acc=0.9375, running_acc=0.9062, grad=6.0888]Training epoch 9:   6%|▌         | 10/163 [00:15<02:51,  1.12s/it, loss=0.2808, batch_acc=0.9375, running_acc=0.9062, grad=6.0888]Training epoch 9:   6%|▌         | 10/163 [00:15<02:51,  1.12s/it, loss=0.3413, batch_acc=0.8750, running_acc=0.9031, grad=4.6893]Training epoch 9:   7%|▋         | 11/163 [00:16<02:41,  1.06s/it, loss=0.3413, batch_acc=0.8750, running_acc=0.9031, grad=4.6893]Training epoch 9:   7%|▋         | 11/163 [00:16<02:41,  1.06s/it, loss=0.6389, batch_acc=0.8438, running_acc=0.8977, grad=6.8290]Training epoch 9:   7%|▋         | 12/163 [00:18<03:21,  1.34s/it, loss=0.6389, batch_acc=0.8438, running_acc=0.8977, grad=6.8290]Training epoch 9:   7%|▋         | 12/163 [00:18<03:21,  1.34s/it, loss=0.4324, batch_acc=0.9062, running_acc=0.8984, grad=6.4716]Training epoch 9:   8%|▊         | 13/163 [00:19<02:59,  1.20s/it, loss=0.4324, batch_acc=0.9062, running_acc=0.8984, grad=6.4716]Training epoch 9:   8%|▊         | 13/163 [00:19<02:59,  1.20s/it, loss=0.2863, batch_acc=0.9375, running_acc=0.9014, grad=4.7229]Training epoch 9:   9%|▊         | 14/163 [00:20<02:44,  1.10s/it, loss=0.2863, batch_acc=0.9375, running_acc=0.9014, grad=4.7229]Training epoch 9:   9%|▊         | 14/163 [00:20<02:44,  1.10s/it, loss=0.3262, batch_acc=0.9688, running_acc=0.9062, grad=4.9797]Training epoch 9:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=0.3262, batch_acc=0.9688, running_acc=0.9062, grad=4.9797]Training epoch 9:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=0.3069, batch_acc=0.9375, running_acc=0.9083, grad=4.4494]Training epoch 9:  10%|▉         | 16/163 [00:22<02:51,  1.17s/it, loss=0.3069, batch_acc=0.9375, running_acc=0.9083, grad=4.4494]Training epoch 9:  10%|▉         | 16/163 [00:22<02:51,  1.17s/it, loss=0.2282, batch_acc=0.9688, running_acc=0.9121, grad=3.8449]Training epoch 9:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=0.2282, batch_acc=0.9688, running_acc=0.9121, grad=3.8449]Training epoch 9:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=0.4470, batch_acc=0.8125, running_acc=0.9062, grad=4.6668]Training epoch 9:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=0.4470, batch_acc=0.8125, running_acc=0.9062, grad=4.6668]Training epoch 9:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=0.2670, batch_acc=0.9062, running_acc=0.9062, grad=4.2692]Training epoch 9:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=0.2670, batch_acc=0.9062, running_acc=0.9062, grad=4.2692]Training epoch 9:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=0.3710, batch_acc=0.8750, running_acc=0.9046, grad=5.2160]Training epoch 9:  12%|█▏        | 20/163 [00:27<02:54,  1.22s/it, loss=0.3710, batch_acc=0.8750, running_acc=0.9046, grad=5.2160]Training epoch 9:  12%|█▏        | 20/163 [00:27<02:54,  1.22s/it, loss=0.2845, batch_acc=0.9375, running_acc=0.9062, grad=3.5478]Training epoch 9:  13%|█▎        | 21/163 [00:28<02:38,  1.11s/it, loss=0.2845, batch_acc=0.9375, running_acc=0.9062, grad=3.5478]Training epoch 9:  13%|█▎        | 21/163 [00:28<02:38,  1.11s/it, loss=0.4182, batch_acc=0.8438, running_acc=0.9033, grad=5.4123]Training epoch 9:  13%|█▎        | 22/163 [00:29<02:27,  1.05s/it, loss=0.4182, batch_acc=0.8438, running_acc=0.9033, grad=5.4123]Training epoch 9:  13%|█▎        | 22/163 [00:29<02:27,  1.05s/it, loss=0.3809, batch_acc=0.8750, running_acc=0.9020, grad=5.1180]Training epoch 9:  14%|█▍        | 23/163 [00:30<02:19,  1.01it/s, loss=0.3809, batch_acc=0.8750, running_acc=0.9020, grad=5.1180]Training epoch 9:  14%|█▍        | 23/163 [00:30<02:19,  1.01it/s, loss=0.3687, batch_acc=0.8750, running_acc=0.9008, grad=6.0484]Training epoch 9:  15%|█▍        | 24/163 [00:31<02:54,  1.26s/it, loss=0.3687, batch_acc=0.8750, running_acc=0.9008, grad=6.0484]Training epoch 9:  15%|█▍        | 24/163 [00:31<02:54,  1.26s/it, loss=0.4823, batch_acc=0.9062, running_acc=0.9010, grad=7.5711]Training epoch 9:  15%|█▌        | 25/163 [00:32<02:37,  1.14s/it, loss=0.4823, batch_acc=0.9062, running_acc=0.9010, grad=7.5711]Training epoch 9:  15%|█▌        | 25/163 [00:32<02:37,  1.14s/it, loss=0.2609, batch_acc=0.9375, running_acc=0.9025, grad=4.5550]Training epoch 9:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.2609, batch_acc=0.9375, running_acc=0.9025, grad=4.5550]Training epoch 9:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.5431, batch_acc=0.8125, running_acc=0.8990, grad=6.8682]Training epoch 9:  17%|█▋        | 27/163 [00:34<02:17,  1.01s/it, loss=0.5431, batch_acc=0.8125, running_acc=0.8990, grad=6.8682]Training epoch 9:  17%|█▋        | 27/163 [00:34<02:17,  1.01s/it, loss=0.6881, batch_acc=0.8125, running_acc=0.8958, grad=7.4593]Training epoch 9:  17%|█▋        | 28/163 [00:36<03:01,  1.35s/it, loss=0.6881, batch_acc=0.8125, running_acc=0.8958, grad=7.4593]Training epoch 9:  17%|█▋        | 28/163 [00:36<03:01,  1.35s/it, loss=0.5821, batch_acc=0.7812, running_acc=0.8917, grad=6.4836]Training epoch 9:  18%|█▊        | 29/163 [00:37<02:41,  1.20s/it, loss=0.5821, batch_acc=0.7812, running_acc=0.8917, grad=6.4836]Training epoch 9:  18%|█▊        | 29/163 [00:37<02:41,  1.20s/it, loss=0.2071, batch_acc=0.9688, running_acc=0.8944, grad=3.3036]Training epoch 9:  18%|█▊        | 30/163 [00:38<02:27,  1.11s/it, loss=0.2071, batch_acc=0.9688, running_acc=0.8944, grad=3.3036]Training epoch 9:  18%|█▊        | 30/163 [00:38<02:27,  1.11s/it, loss=0.3386, batch_acc=0.8750, running_acc=0.8938, grad=5.5075]Training epoch 9:  19%|█▉        | 31/163 [00:39<02:16,  1.04s/it, loss=0.3386, batch_acc=0.8750, running_acc=0.8938, grad=5.5075]Training epoch 9:  19%|█▉        | 31/163 [00:39<02:16,  1.04s/it, loss=0.4075, batch_acc=0.8438, running_acc=0.8921, grad=6.1790]Training epoch 9:  20%|█▉        | 32/163 [00:41<02:44,  1.25s/it, loss=0.4075, batch_acc=0.8438, running_acc=0.8921, grad=6.1790]Training epoch 9:  20%|█▉        | 32/163 [00:41<02:44,  1.25s/it, loss=0.2930, batch_acc=0.9375, running_acc=0.8936, grad=4.3249]Training epoch 9:  20%|██        | 33/163 [00:41<02:28,  1.14s/it, loss=0.2930, batch_acc=0.9375, running_acc=0.8936, grad=4.3249]Training epoch 9:  20%|██        | 33/163 [00:41<02:28,  1.14s/it, loss=0.4138, batch_acc=0.8438, running_acc=0.8920, grad=6.9439]Training epoch 9:  21%|██        | 34/163 [00:42<02:17,  1.06s/it, loss=0.4138, batch_acc=0.8438, running_acc=0.8920, grad=6.9439]Training epoch 9:  21%|██        | 34/163 [00:42<02:17,  1.06s/it, loss=0.4081, batch_acc=0.9375, running_acc=0.8934, grad=5.9203]Training epoch 9:  21%|██▏       | 35/163 [00:43<02:08,  1.01s/it, loss=0.4081, batch_acc=0.9375, running_acc=0.8934, grad=5.9203]Training epoch 9:  21%|██▏       | 35/163 [00:43<02:08,  1.01s/it, loss=0.5088, batch_acc=0.9062, running_acc=0.8938, grad=6.3168]Training epoch 9:  22%|██▏       | 36/163 [00:45<02:37,  1.24s/it, loss=0.5088, batch_acc=0.9062, running_acc=0.8938, grad=6.3168]Training epoch 9:  22%|██▏       | 36/163 [00:45<02:37,  1.24s/it, loss=0.4004, batch_acc=0.9062, running_acc=0.8941, grad=7.0657]Training epoch 9:  23%|██▎       | 37/163 [00:46<02:22,  1.13s/it, loss=0.4004, batch_acc=0.9062, running_acc=0.8941, grad=7.0657]Training epoch 9:  23%|██▎       | 37/163 [00:46<02:22,  1.13s/it, loss=0.5555, batch_acc=0.8438, running_acc=0.8927, grad=8.0569]Training epoch 9:  23%|██▎       | 38/163 [00:47<02:11,  1.06s/it, loss=0.5555, batch_acc=0.8438, running_acc=0.8927, grad=8.0569]Training epoch 9:  23%|██▎       | 38/163 [00:47<02:11,  1.06s/it, loss=0.3989, batch_acc=0.9062, running_acc=0.8931, grad=5.3910]Training epoch 9:  24%|██▍       | 39/163 [00:48<02:04,  1.00s/it, loss=0.3989, batch_acc=0.9062, running_acc=0.8931, grad=5.3910]Training epoch 9:  24%|██▍       | 39/163 [00:48<02:04,  1.00s/it, loss=0.4754, batch_acc=0.8125, running_acc=0.8910, grad=7.3925]Training epoch 9:  25%|██▍       | 40/163 [00:49<02:17,  1.12s/it, loss=0.4754, batch_acc=0.8125, running_acc=0.8910, grad=7.3925]Training epoch 9:  25%|██▍       | 40/163 [00:49<02:17,  1.12s/it, loss=0.3993, batch_acc=0.8438, running_acc=0.8898, grad=7.1215]Training epoch 9:  25%|██▌       | 41/163 [00:50<02:07,  1.05s/it, loss=0.3993, batch_acc=0.8438, running_acc=0.8898, grad=7.1215]Training epoch 9:  25%|██▌       | 41/163 [00:50<02:07,  1.05s/it, loss=0.4757, batch_acc=0.8438, running_acc=0.8887, grad=6.7617]Training epoch 9:  26%|██▌       | 42/163 [00:51<02:00,  1.00it/s, loss=0.4757, batch_acc=0.8438, running_acc=0.8887, grad=6.7617]Training epoch 9:  26%|██▌       | 42/163 [00:51<02:00,  1.00it/s, loss=0.3283, batch_acc=0.9688, running_acc=0.8906, grad=4.4406]Training epoch 9:  26%|██▋       | 43/163 [00:52<01:55,  1.04it/s, loss=0.3283, batch_acc=0.9688, running_acc=0.8906, grad=4.4406]Training epoch 9:  26%|██▋       | 43/163 [00:52<01:55,  1.04it/s, loss=0.5787, batch_acc=0.8125, running_acc=0.8888, grad=8.6644]Training epoch 9:  27%|██▋       | 44/163 [00:53<02:24,  1.21s/it, loss=0.5787, batch_acc=0.8125, running_acc=0.8888, grad=8.6644]Training epoch 9:  27%|██▋       | 44/163 [00:53<02:24,  1.21s/it, loss=0.2663, batch_acc=0.9375, running_acc=0.8899, grad=5.7669]Training epoch 9:  28%|██▊       | 45/163 [00:54<02:11,  1.11s/it, loss=0.2663, batch_acc=0.9375, running_acc=0.8899, grad=5.7669]Training epoch 9:  28%|██▊       | 45/163 [00:54<02:11,  1.11s/it, loss=0.5594, batch_acc=0.8438, running_acc=0.8889, grad=6.8007]Training epoch 9:  28%|██▊       | 46/163 [00:55<02:02,  1.04s/it, loss=0.5594, batch_acc=0.8438, running_acc=0.8889, grad=6.8007]Training epoch 9:  28%|██▊       | 46/163 [00:55<02:02,  1.04s/it, loss=0.4778, batch_acc=0.8750, running_acc=0.8886, grad=5.7796]Training epoch 9:  29%|██▉       | 47/163 [00:56<01:55,  1.01it/s, loss=0.4778, batch_acc=0.8750, running_acc=0.8886, grad=5.7796]Training epoch 9:  29%|██▉       | 47/163 [00:56<01:55,  1.01it/s, loss=0.3212, batch_acc=0.9375, running_acc=0.8896, grad=4.3072]Training epoch 9:  29%|██▉       | 48/163 [00:58<02:12,  1.15s/it, loss=0.3212, batch_acc=0.9375, running_acc=0.8896, grad=4.3072]Training epoch 9:  29%|██▉       | 48/163 [00:58<02:12,  1.15s/it, loss=0.3602, batch_acc=0.9062, running_acc=0.8900, grad=4.4869]Training epoch 9:  30%|███       | 49/163 [00:58<02:01,  1.07s/it, loss=0.3602, batch_acc=0.9062, running_acc=0.8900, grad=4.4869]Training epoch 9:  30%|███       | 49/163 [00:58<02:01,  1.07s/it, loss=0.6389, batch_acc=0.7188, running_acc=0.8865, grad=7.9905]Training epoch 9:  31%|███       | 50/163 [00:59<01:54,  1.01s/it, loss=0.6389, batch_acc=0.7188, running_acc=0.8865, grad=7.9905]Training epoch 9:  31%|███       | 50/163 [00:59<01:54,  1.01s/it, loss=0.3128, batch_acc=0.9062, running_acc=0.8869, grad=4.6163]Training epoch 9:  31%|███▏      | 51/163 [01:00<01:48,  1.03it/s, loss=0.3128, batch_acc=0.9062, running_acc=0.8869, grad=4.6163]Training epoch 9:  31%|███▏      | 51/163 [01:00<01:48,  1.03it/s, loss=0.3580, batch_acc=0.9375, running_acc=0.8879, grad=5.7383]Training epoch 9:  32%|███▏      | 52/163 [01:02<02:20,  1.27s/it, loss=0.3580, batch_acc=0.9375, running_acc=0.8879, grad=5.7383]Training epoch 9:  32%|███▏      | 52/163 [01:02<02:20,  1.27s/it, loss=0.5561, batch_acc=0.8125, running_acc=0.8864, grad=8.0413]Training epoch 9:  33%|███▎      | 53/163 [01:03<02:06,  1.15s/it, loss=0.5561, batch_acc=0.8125, running_acc=0.8864, grad=8.0413]Training epoch 9:  33%|███▎      | 53/163 [01:03<02:06,  1.15s/it, loss=0.4111, batch_acc=0.8125, running_acc=0.8850, grad=6.4176]Training epoch 9:  33%|███▎      | 54/163 [01:04<01:56,  1.07s/it, loss=0.4111, batch_acc=0.8125, running_acc=0.8850, grad=6.4176]Training epoch 9:  33%|███▎      | 54/163 [01:04<01:56,  1.07s/it, loss=0.6147, batch_acc=0.7500, running_acc=0.8825, grad=10.6458]Training epoch 9:  34%|███▎      | 55/163 [01:05<01:49,  1.01s/it, loss=0.6147, batch_acc=0.7500, running_acc=0.8825, grad=10.6458]Training epoch 9:  34%|███▎      | 55/163 [01:05<01:49,  1.01s/it, loss=0.4523, batch_acc=0.8438, running_acc=0.8818, grad=6.1031] Training epoch 9:  34%|███▍      | 56/163 [01:07<02:15,  1.26s/it, loss=0.4523, batch_acc=0.8438, running_acc=0.8818, grad=6.1031]Training epoch 9:  34%|███▍      | 56/163 [01:07<02:15,  1.26s/it, loss=0.3103, batch_acc=0.9062, running_acc=0.8823, grad=6.1159]Training epoch 9:  35%|███▍      | 57/163 [01:08<02:01,  1.15s/it, loss=0.3103, batch_acc=0.9062, running_acc=0.8823, grad=6.1159]Training epoch 9:  35%|███▍      | 57/163 [01:08<02:01,  1.15s/it, loss=0.3523, batch_acc=0.8438, running_acc=0.8816, grad=6.8293]Training epoch 9:  36%|███▌      | 58/163 [01:08<01:51,  1.07s/it, loss=0.3523, batch_acc=0.8438, running_acc=0.8816, grad=6.8293]Training epoch 9:  36%|███▌      | 58/163 [01:08<01:51,  1.07s/it, loss=0.4741, batch_acc=0.8438, running_acc=0.8809, grad=8.2321]Training epoch 9:  36%|███▌      | 59/163 [01:09<01:44,  1.01s/it, loss=0.4741, batch_acc=0.8438, running_acc=0.8809, grad=8.2321]Training epoch 9:  36%|███▌      | 59/163 [01:09<01:44,  1.01s/it, loss=0.4025, batch_acc=0.8125, running_acc=0.8798, grad=5.0688]Training epoch 9:  37%|███▋      | 60/163 [01:11<01:57,  1.14s/it, loss=0.4025, batch_acc=0.8125, running_acc=0.8798, grad=5.0688]Training epoch 9:  37%|███▋      | 60/163 [01:11<01:57,  1.14s/it, loss=0.3629, batch_acc=0.9062, running_acc=0.8802, grad=6.2014]Training epoch 9:  37%|███▋      | 61/163 [01:12<01:48,  1.06s/it, loss=0.3629, batch_acc=0.9062, running_acc=0.8802, grad=6.2014]Training epoch 9:  37%|███▋      | 61/163 [01:12<01:48,  1.06s/it, loss=0.3134, batch_acc=0.8438, running_acc=0.8796, grad=4.5640]Training epoch 9:  38%|███▊      | 62/163 [01:12<01:41,  1.01s/it, loss=0.3134, batch_acc=0.8438, running_acc=0.8796, grad=4.5640]Training epoch 9:  38%|███▊      | 62/163 [01:12<01:41,  1.01s/it, loss=0.5393, batch_acc=0.8750, running_acc=0.8795, grad=7.5148]Training epoch 9:  39%|███▊      | 63/163 [01:13<01:39,  1.01it/s, loss=0.5393, batch_acc=0.8750, running_acc=0.8795, grad=7.5148]Training epoch 9:  39%|███▊      | 63/163 [01:13<01:39,  1.01it/s, loss=0.5051, batch_acc=0.8750, running_acc=0.8795, grad=7.3742]Training epoch 9:  39%|███▉      | 64/163 [01:15<01:55,  1.17s/it, loss=0.5051, batch_acc=0.8750, running_acc=0.8795, grad=7.3742]Training epoch 9:  39%|███▉      | 64/163 [01:15<01:55,  1.17s/it, loss=0.5432, batch_acc=0.8438, running_acc=0.8789, grad=7.0084]Training epoch 9:  40%|███▉      | 65/163 [01:16<01:46,  1.08s/it, loss=0.5432, batch_acc=0.8438, running_acc=0.8789, grad=7.0084]Training epoch 9:  40%|███▉      | 65/163 [01:16<01:46,  1.08s/it, loss=0.4465, batch_acc=0.9062, running_acc=0.8793, grad=6.4353]Training epoch 9:  40%|████      | 66/163 [01:17<01:39,  1.02s/it, loss=0.4465, batch_acc=0.9062, running_acc=0.8793, grad=6.4353]Training epoch 9:  40%|████      | 66/163 [01:17<01:39,  1.02s/it, loss=0.2975, batch_acc=0.9375, running_acc=0.8802, grad=4.0924]Training epoch 9:  41%|████      | 67/163 [01:18<01:33,  1.02it/s, loss=0.2975, batch_acc=0.9375, running_acc=0.8802, grad=4.0924]Training epoch 9:  41%|████      | 67/163 [01:18<01:33,  1.02it/s, loss=0.3339, batch_acc=0.9062, running_acc=0.8806, grad=6.1804]Training epoch 9:  42%|████▏     | 68/163 [01:19<01:44,  1.10s/it, loss=0.3339, batch_acc=0.9062, running_acc=0.8806, grad=6.1804]Training epoch 9:  42%|████▏     | 68/163 [01:19<01:44,  1.10s/it, loss=0.3854, batch_acc=0.8750, running_acc=0.8805, grad=4.8396]Training epoch 9:  42%|████▏     | 69/163 [01:20<01:37,  1.03s/it, loss=0.3854, batch_acc=0.8750, running_acc=0.8805, grad=4.8396]Training epoch 9:  42%|████▏     | 69/163 [01:20<01:37,  1.03s/it, loss=0.3627, batch_acc=0.8750, running_acc=0.8804, grad=5.5647]Training epoch 9:  43%|████▎     | 70/163 [01:21<01:31,  1.01it/s, loss=0.3627, batch_acc=0.8750, running_acc=0.8804, grad=5.5647]Training epoch 9:  43%|████▎     | 70/163 [01:21<01:31,  1.01it/s, loss=0.4395, batch_acc=0.8750, running_acc=0.8804, grad=4.9828]Training epoch 9:  44%|████▎     | 71/163 [01:22<01:29,  1.03it/s, loss=0.4395, batch_acc=0.8750, running_acc=0.8804, grad=4.9828]Training epoch 9:  44%|████▎     | 71/163 [01:22<01:29,  1.03it/s, loss=0.2998, batch_acc=0.9375, running_acc=0.8812, grad=4.7368]Training epoch 9:  44%|████▍     | 72/163 [01:24<01:55,  1.27s/it, loss=0.2998, batch_acc=0.9375, running_acc=0.8812, grad=4.7368]Training epoch 9:  44%|████▍     | 72/163 [01:24<01:55,  1.27s/it, loss=0.4393, batch_acc=0.8125, running_acc=0.8802, grad=6.5976]Training epoch 9:  45%|████▍     | 73/163 [01:25<01:44,  1.16s/it, loss=0.4393, batch_acc=0.8125, running_acc=0.8802, grad=6.5976]Training epoch 9:  45%|████▍     | 73/163 [01:25<01:44,  1.16s/it, loss=0.6251, batch_acc=0.8438, running_acc=0.8797, grad=7.3024]Training epoch 9:  45%|████▌     | 74/163 [01:25<01:35,  1.07s/it, loss=0.6251, batch_acc=0.8438, running_acc=0.8797, grad=7.3024]Training epoch 9:  45%|████▌     | 74/163 [01:25<01:35,  1.07s/it, loss=0.3097, batch_acc=0.9375, running_acc=0.8805, grad=5.4970]Training epoch 9:  46%|████▌     | 75/163 [01:26<01:30,  1.03s/it, loss=0.3097, batch_acc=0.9375, running_acc=0.8805, grad=5.4970]Training epoch 9:  46%|████▌     | 75/163 [01:26<01:30,  1.03s/it, loss=0.3515, batch_acc=0.9062, running_acc=0.8808, grad=4.5576]Training epoch 9:  47%|████▋     | 76/163 [01:27<01:29,  1.03s/it, loss=0.3515, batch_acc=0.9062, running_acc=0.8808, grad=4.5576]Training epoch 9:  47%|████▋     | 76/163 [01:27<01:29,  1.03s/it, loss=0.7238, batch_acc=0.6875, running_acc=0.8783, grad=10.7961]Training epoch 9:  47%|████▋     | 77/163 [01:28<01:24,  1.02it/s, loss=0.7238, batch_acc=0.6875, running_acc=0.8783, grad=10.7961]Training epoch 9:  47%|████▋     | 77/163 [01:28<01:24,  1.02it/s, loss=0.4936, batch_acc=0.8438, running_acc=0.8778, grad=10.7577]Training epoch 9:  48%|████▊     | 78/163 [01:29<01:20,  1.05it/s, loss=0.4936, batch_acc=0.8438, running_acc=0.8778, grad=10.7577]Training epoch 9:  48%|████▊     | 78/163 [01:29<01:20,  1.05it/s, loss=0.3003, batch_acc=0.9062, running_acc=0.8782, grad=6.7236] Training epoch 9:  48%|████▊     | 79/163 [01:30<01:18,  1.07it/s, loss=0.3003, batch_acc=0.9062, running_acc=0.8782, grad=6.7236]Training epoch 9:  48%|████▊     | 79/163 [01:30<01:18,  1.07it/s, loss=0.6974, batch_acc=0.7812, running_acc=0.8770, grad=11.3970]Training epoch 9:  49%|████▉     | 80/163 [01:32<01:30,  1.09s/it, loss=0.6974, batch_acc=0.7812, running_acc=0.8770, grad=11.3970]Training epoch 9:  49%|████▉     | 80/163 [01:32<01:30,  1.09s/it, loss=0.3846, batch_acc=0.8750, running_acc=0.8770, grad=4.6928] Training epoch 9:  50%|████▉     | 81/163 [01:32<01:24,  1.03s/it, loss=0.3846, batch_acc=0.8750, running_acc=0.8770, grad=4.6928]Training epoch 9:  50%|████▉     | 81/163 [01:32<01:24,  1.03s/it, loss=0.1974, batch_acc=0.9688, running_acc=0.8781, grad=3.4216]Training epoch 9:  50%|█████     | 82/163 [01:33<01:19,  1.02it/s, loss=0.1974, batch_acc=0.9688, running_acc=0.8781, grad=3.4216]Training epoch 9:  50%|█████     | 82/163 [01:33<01:19,  1.02it/s, loss=0.2127, batch_acc=0.9688, running_acc=0.8792, grad=3.0269]Training epoch 9:  51%|█████     | 83/163 [01:34<01:16,  1.05it/s, loss=0.2127, batch_acc=0.9688, running_acc=0.8792, grad=3.0269]Training epoch 9:  51%|█████     | 83/163 [01:34<01:16,  1.05it/s, loss=0.4074, batch_acc=0.9062, running_acc=0.8795, grad=5.4848]Training epoch 9:  52%|█████▏    | 84/163 [01:36<01:28,  1.12s/it, loss=0.4074, batch_acc=0.9062, running_acc=0.8795, grad=5.4848]Training epoch 9:  52%|█████▏    | 84/163 [01:36<01:28,  1.12s/it, loss=0.3908, batch_acc=0.8750, running_acc=0.8795, grad=6.2600]Training epoch 9:  52%|█████▏    | 85/163 [01:37<01:21,  1.05s/it, loss=0.3908, batch_acc=0.8750, running_acc=0.8795, grad=6.2600]Training epoch 9:  52%|█████▏    | 85/163 [01:37<01:21,  1.05s/it, loss=0.5495, batch_acc=0.8438, running_acc=0.8790, grad=7.5067]Training epoch 9:  53%|█████▎    | 86/163 [01:37<01:16,  1.00it/s, loss=0.5495, batch_acc=0.8438, running_acc=0.8790, grad=7.5067]Training epoch 9:  53%|█████▎    | 86/163 [01:37<01:16,  1.00it/s, loss=0.3901, batch_acc=0.8750, running_acc=0.8790, grad=6.7675]Training epoch 9:  53%|█████▎    | 87/163 [01:38<01:13,  1.03it/s, loss=0.3901, batch_acc=0.8750, running_acc=0.8790, grad=6.7675]Training epoch 9:  53%|█████▎    | 87/163 [01:38<01:13,  1.03it/s, loss=0.6141, batch_acc=0.8438, running_acc=0.8786, grad=6.4782]Training epoch 9:  54%|█████▍    | 88/163 [01:40<01:33,  1.25s/it, loss=0.6141, batch_acc=0.8438, running_acc=0.8786, grad=6.4782]Training epoch 9:  54%|█████▍    | 88/163 [01:40<01:33,  1.25s/it, loss=0.4798, batch_acc=0.8438, running_acc=0.8782, grad=9.5735]Training epoch 9:  55%|█████▍    | 89/163 [01:41<01:24,  1.14s/it, loss=0.4798, batch_acc=0.8438, running_acc=0.8782, grad=9.5735]Training epoch 9:  55%|█████▍    | 89/163 [01:41<01:24,  1.14s/it, loss=0.2894, batch_acc=0.8750, running_acc=0.8782, grad=4.4209]Training epoch 9:  55%|█████▌    | 90/163 [01:42<01:17,  1.06s/it, loss=0.2894, batch_acc=0.8750, running_acc=0.8782, grad=4.4209]Training epoch 9:  55%|█████▌    | 90/163 [01:42<01:17,  1.06s/it, loss=0.3174, batch_acc=0.8750, running_acc=0.8781, grad=5.3148]Training epoch 9:  56%|█████▌    | 91/163 [01:43<01:14,  1.04s/it, loss=0.3174, batch_acc=0.8750, running_acc=0.8781, grad=5.3148]Training epoch 9:  56%|█████▌    | 91/163 [01:43<01:14,  1.04s/it, loss=0.3341, batch_acc=0.9062, running_acc=0.8784, grad=7.0455]Training epoch 9:  56%|█████▋    | 92/163 [01:44<01:16,  1.08s/it, loss=0.3341, batch_acc=0.9062, running_acc=0.8784, grad=7.0455]Training epoch 9:  56%|█████▋    | 92/163 [01:44<01:16,  1.08s/it, loss=0.3290, batch_acc=0.8750, running_acc=0.8784, grad=6.0437]Training epoch 9:  57%|█████▋    | 93/163 [01:45<01:11,  1.02s/it, loss=0.3290, batch_acc=0.8750, running_acc=0.8784, grad=6.0437]Training epoch 9:  57%|█████▋    | 93/163 [01:45<01:11,  1.02s/it, loss=0.3661, batch_acc=0.8750, running_acc=0.8784, grad=6.1765]Training epoch 9:  58%|█████▊    | 94/163 [01:46<01:07,  1.02it/s, loss=0.3661, batch_acc=0.8750, running_acc=0.8784, grad=6.1765]Training epoch 9:  58%|█████▊    | 94/163 [01:46<01:07,  1.02it/s, loss=0.2856, batch_acc=0.9688, running_acc=0.8793, grad=4.2261]Training epoch 9:  58%|█████▊    | 95/163 [01:47<01:04,  1.05it/s, loss=0.2856, batch_acc=0.9688, running_acc=0.8793, grad=4.2261]Training epoch 9:  58%|█████▊    | 95/163 [01:47<01:04,  1.05it/s, loss=0.3951, batch_acc=0.9062, running_acc=0.8796, grad=6.6581]Training epoch 9:  59%|█████▉    | 96/163 [01:49<01:22,  1.23s/it, loss=0.3951, batch_acc=0.9062, running_acc=0.8796, grad=6.6581]Training epoch 9:  59%|█████▉    | 96/163 [01:49<01:22,  1.23s/it, loss=0.4774, batch_acc=0.8750, running_acc=0.8796, grad=7.5169]Training epoch 9:  60%|█████▉    | 97/163 [01:50<01:14,  1.13s/it, loss=0.4774, batch_acc=0.8750, running_acc=0.8796, grad=7.5169]Training epoch 9:  60%|█████▉    | 97/163 [01:50<01:14,  1.13s/it, loss=0.3650, batch_acc=0.9375, running_acc=0.8802, grad=6.0576]Training epoch 9:  60%|██████    | 98/163 [01:50<01:08,  1.05s/it, loss=0.3650, batch_acc=0.9375, running_acc=0.8802, grad=6.0576]Training epoch 9:  60%|██████    | 98/163 [01:50<01:08,  1.05s/it, loss=0.3535, batch_acc=0.9062, running_acc=0.8804, grad=5.7698]Training epoch 9:  61%|██████    | 99/163 [01:51<01:05,  1.03s/it, loss=0.3535, batch_acc=0.9062, running_acc=0.8804, grad=5.7698]Training epoch 9:  61%|██████    | 99/163 [01:51<01:05,  1.03s/it, loss=0.2194, batch_acc=0.9375, running_acc=0.8810, grad=3.7123]Training epoch 9:  61%|██████▏   | 100/163 [01:52<01:03,  1.01s/it, loss=0.2194, batch_acc=0.9375, running_acc=0.8810, grad=3.7123]Training epoch 9:  61%|██████▏   | 100/163 [01:52<01:03,  1.01s/it, loss=0.4629, batch_acc=0.8438, running_acc=0.8806, grad=4.9629]Training epoch 9:  62%|██████▏   | 101/163 [01:53<01:00,  1.03it/s, loss=0.4629, batch_acc=0.8438, running_acc=0.8806, grad=4.9629]Training epoch 9:  62%|██████▏   | 101/163 [01:53<01:00,  1.03it/s, loss=0.3393, batch_acc=0.9062, running_acc=0.8809, grad=5.2956]Training epoch 9:  63%|██████▎   | 102/163 [01:54<00:57,  1.06it/s, loss=0.3393, batch_acc=0.9062, running_acc=0.8809, grad=5.2956]Training epoch 9:  63%|██████▎   | 102/163 [01:54<00:57,  1.06it/s, loss=0.4347, batch_acc=0.8438, running_acc=0.8805, grad=5.3321]Training epoch 9:  63%|██████▎   | 103/163 [01:55<00:59,  1.01it/s, loss=0.4347, batch_acc=0.8438, running_acc=0.8805, grad=5.3321]Training epoch 9:  63%|██████▎   | 103/163 [01:55<00:59,  1.01it/s, loss=0.6190, batch_acc=0.7812, running_acc=0.8796, grad=10.3522]Training epoch 9:  64%|██████▍   | 104/163 [01:56<00:59,  1.00s/it, loss=0.6190, batch_acc=0.7812, running_acc=0.8796, grad=10.3522]Training epoch 9:  64%|██████▍   | 104/163 [01:56<00:59,  1.00s/it, loss=0.3412, batch_acc=0.9375, running_acc=0.8801, grad=5.6972] Training epoch 9:  64%|██████▍   | 105/163 [01:57<00:55,  1.04it/s, loss=0.3412, batch_acc=0.9375, running_acc=0.8801, grad=5.6972]Training epoch 9:  64%|██████▍   | 105/163 [01:57<00:55,  1.04it/s, loss=0.4110, batch_acc=0.8750, running_acc=0.8801, grad=7.1280]Training epoch 9:  65%|██████▌   | 106/163 [01:58<00:53,  1.07it/s, loss=0.4110, batch_acc=0.8750, running_acc=0.8801, grad=7.1280]Training epoch 9:  65%|██████▌   | 106/163 [01:58<00:53,  1.07it/s, loss=0.3022, batch_acc=0.9062, running_acc=0.8803, grad=8.9603]Training epoch 9:  66%|██████▌   | 107/163 [02:00<01:02,  1.11s/it, loss=0.3022, batch_acc=0.9062, running_acc=0.8803, grad=8.9603]Training epoch 9:  66%|██████▌   | 107/163 [02:00<01:02,  1.11s/it, loss=0.4555, batch_acc=0.7812, running_acc=0.8794, grad=7.4194]Training epoch 9:  66%|██████▋   | 108/163 [02:00<00:57,  1.05s/it, loss=0.4555, batch_acc=0.7812, running_acc=0.8794, grad=7.4194]Training epoch 9:  66%|██████▋   | 108/163 [02:00<00:57,  1.05s/it, loss=0.2583, batch_acc=1.0000, running_acc=0.8805, grad=4.4980]Training epoch 9:  67%|██████▋   | 109/163 [02:01<00:53,  1.00it/s, loss=0.2583, batch_acc=1.0000, running_acc=0.8805, grad=4.4980]Training epoch 9:  67%|██████▋   | 109/163 [02:01<00:53,  1.00it/s, loss=0.4402, batch_acc=0.8750, running_acc=0.8804, grad=6.7520]Training epoch 9:  67%|██████▋   | 110/163 [02:02<00:51,  1.04it/s, loss=0.4402, batch_acc=0.8750, running_acc=0.8804, grad=6.7520]Training epoch 9:  67%|██████▋   | 110/163 [02:02<00:51,  1.04it/s, loss=0.3687, batch_acc=0.9062, running_acc=0.8807, grad=5.3375]Training epoch 9:  68%|██████▊   | 111/163 [02:04<01:03,  1.22s/it, loss=0.3687, batch_acc=0.9062, running_acc=0.8807, grad=5.3375]Training epoch 9:  68%|██████▊   | 111/163 [02:04<01:03,  1.22s/it, loss=0.3641, batch_acc=0.8750, running_acc=0.8806, grad=7.3422]Training epoch 9:  69%|██████▊   | 112/163 [02:05<00:59,  1.16s/it, loss=0.3641, batch_acc=0.8750, running_acc=0.8806, grad=7.3422]Training epoch 9:  69%|██████▊   | 112/163 [02:05<00:59,  1.16s/it, loss=0.5097, batch_acc=0.8438, running_acc=0.8803, grad=6.3331]Training epoch 9:  69%|██████▉   | 113/163 [02:06<00:53,  1.08s/it, loss=0.5097, batch_acc=0.8438, running_acc=0.8803, grad=6.3331]Training epoch 9:  69%|██████▉   | 113/163 [02:06<00:53,  1.08s/it, loss=0.4314, batch_acc=0.9062, running_acc=0.8805, grad=6.5508]Training epoch 9:  70%|██████▉   | 114/163 [02:07<00:49,  1.02s/it, loss=0.4314, batch_acc=0.9062, running_acc=0.8805, grad=6.5508]Training epoch 9:  70%|██████▉   | 114/163 [02:07<00:49,  1.02s/it, loss=0.5635, batch_acc=0.8125, running_acc=0.8799, grad=6.9715]Training epoch 9:  71%|███████   | 115/163 [02:08<00:50,  1.06s/it, loss=0.5635, batch_acc=0.8125, running_acc=0.8799, grad=6.9715]Training epoch 9:  71%|███████   | 115/163 [02:08<00:50,  1.06s/it, loss=0.4464, batch_acc=0.8750, running_acc=0.8799, grad=7.9318]Training epoch 9:  71%|███████   | 116/163 [02:09<00:55,  1.18s/it, loss=0.4464, batch_acc=0.8750, running_acc=0.8799, grad=7.9318]Training epoch 9:  71%|███████   | 116/163 [02:09<00:55,  1.18s/it, loss=0.2691, batch_acc=0.9375, running_acc=0.8804, grad=4.3912]Training epoch 9:  72%|███████▏  | 117/163 [02:10<00:50,  1.09s/it, loss=0.2691, batch_acc=0.9375, running_acc=0.8804, grad=4.3912]Training epoch 9:  72%|███████▏  | 117/163 [02:10<00:50,  1.09s/it, loss=0.2095, batch_acc=0.9688, running_acc=0.8811, grad=5.4699]Training epoch 9:  72%|███████▏  | 118/163 [02:11<00:46,  1.03s/it, loss=0.2095, batch_acc=0.9688, running_acc=0.8811, grad=5.4699]Training epoch 9:  72%|███████▏  | 118/163 [02:11<00:46,  1.03s/it, loss=0.3839, batch_acc=0.9688, running_acc=0.8819, grad=5.6490]Training epoch 9:  73%|███████▎  | 119/163 [02:12<00:44,  1.01s/it, loss=0.3839, batch_acc=0.9688, running_acc=0.8819, grad=5.6490]Training epoch 9:  73%|███████▎  | 119/163 [02:12<00:44,  1.01s/it, loss=0.2335, batch_acc=0.9375, running_acc=0.8824, grad=5.2421]Training epoch 9:  74%|███████▎  | 120/163 [02:14<00:50,  1.18s/it, loss=0.2335, batch_acc=0.9375, running_acc=0.8824, grad=5.2421]Training epoch 9:  74%|███████▎  | 120/163 [02:14<00:50,  1.18s/it, loss=0.3459, batch_acc=0.9062, running_acc=0.8826, grad=6.5594]Training epoch 9:  74%|███████▍  | 121/163 [02:15<00:45,  1.09s/it, loss=0.3459, batch_acc=0.9062, running_acc=0.8826, grad=6.5594]Training epoch 9:  74%|███████▍  | 121/163 [02:15<00:45,  1.09s/it, loss=0.3086, batch_acc=0.9375, running_acc=0.8830, grad=4.8716]Training epoch 9:  75%|███████▍  | 122/163 [02:15<00:41,  1.02s/it, loss=0.3086, batch_acc=0.9375, running_acc=0.8830, grad=4.8716]Training epoch 9:  75%|███████▍  | 122/163 [02:15<00:41,  1.02s/it, loss=0.3709, batch_acc=0.8438, running_acc=0.8827, grad=5.9358]Training epoch 9:  75%|███████▌  | 123/163 [02:16<00:39,  1.02it/s, loss=0.3709, batch_acc=0.8438, running_acc=0.8827, grad=5.9358]Training epoch 9:  75%|███████▌  | 123/163 [02:16<00:39,  1.02it/s, loss=0.5489, batch_acc=0.7812, running_acc=0.8819, grad=10.0115]Training epoch 9:  76%|███████▌  | 124/163 [02:18<00:47,  1.22s/it, loss=0.5489, batch_acc=0.7812, running_acc=0.8819, grad=10.0115]Training epoch 9:  76%|███████▌  | 124/163 [02:18<00:47,  1.22s/it, loss=0.6697, batch_acc=0.7500, running_acc=0.8808, grad=7.4287] Training epoch 9:  77%|███████▋  | 125/163 [02:19<00:42,  1.12s/it, loss=0.6697, batch_acc=0.7500, running_acc=0.8808, grad=7.4287]Training epoch 9:  77%|███████▋  | 125/163 [02:19<00:42,  1.12s/it, loss=0.3559, batch_acc=0.8750, running_acc=0.8808, grad=5.3430]Training epoch 9:  77%|███████▋  | 126/163 [02:20<00:38,  1.05s/it, loss=0.3559, batch_acc=0.8750, running_acc=0.8808, grad=5.3430]Training epoch 9:  77%|███████▋  | 126/163 [02:20<00:38,  1.05s/it, loss=0.3358, batch_acc=0.8750, running_acc=0.8807, grad=4.2072]Training epoch 9:  78%|███████▊  | 127/163 [02:21<00:39,  1.11s/it, loss=0.3358, batch_acc=0.8750, running_acc=0.8807, grad=4.2072]Training epoch 9:  78%|███████▊  | 127/163 [02:21<00:39,  1.11s/it, loss=0.1992, batch_acc=0.9375, running_acc=0.8812, grad=2.8002]Training epoch 9:  79%|███████▊  | 128/163 [02:22<00:41,  1.18s/it, loss=0.1992, batch_acc=0.9375, running_acc=0.8812, grad=2.8002]Training epoch 9:  79%|███████▊  | 128/163 [02:22<00:41,  1.18s/it, loss=0.3885, batch_acc=0.9062, running_acc=0.8813, grad=8.0173]Training epoch 9:  79%|███████▉  | 129/163 [02:23<00:36,  1.09s/it, loss=0.3885, batch_acc=0.9062, running_acc=0.8813, grad=8.0173]Training epoch 9:  79%|███████▉  | 129/163 [02:23<00:36,  1.09s/it, loss=0.4381, batch_acc=0.8750, running_acc=0.8813, grad=8.6698]Training epoch 9:  80%|███████▉  | 130/163 [02:24<00:33,  1.03s/it, loss=0.4381, batch_acc=0.8750, running_acc=0.8813, grad=8.6698]Training epoch 9:  80%|███████▉  | 130/163 [02:24<00:33,  1.03s/it, loss=0.3109, batch_acc=0.9688, running_acc=0.8820, grad=6.2395]Training epoch 9:  80%|████████  | 131/163 [02:25<00:31,  1.01it/s, loss=0.3109, batch_acc=0.9688, running_acc=0.8820, grad=6.2395]Training epoch 9:  80%|████████  | 131/163 [02:25<00:31,  1.01it/s, loss=0.2803, batch_acc=0.8750, running_acc=0.8819, grad=3.6591]Training epoch 9:  81%|████████  | 132/163 [02:27<00:40,  1.32s/it, loss=0.2803, batch_acc=0.8750, running_acc=0.8819, grad=3.6591]Training epoch 9:  81%|████████  | 132/163 [02:27<00:40,  1.32s/it, loss=0.4013, batch_acc=0.8438, running_acc=0.8816, grad=6.1873]Training epoch 9:  82%|████████▏ | 133/163 [02:28<00:35,  1.18s/it, loss=0.4013, batch_acc=0.8438, running_acc=0.8816, grad=6.1873]Training epoch 9:  82%|████████▏ | 133/163 [02:28<00:35,  1.18s/it, loss=0.4320, batch_acc=0.8438, running_acc=0.8813, grad=6.5977]Training epoch 9:  82%|████████▏ | 134/163 [02:29<00:31,  1.09s/it, loss=0.4320, batch_acc=0.8438, running_acc=0.8813, grad=6.5977]Training epoch 9:  82%|████████▏ | 134/163 [02:29<00:31,  1.09s/it, loss=0.4442, batch_acc=0.9062, running_acc=0.8815, grad=7.4599]Training epoch 9:  83%|████████▎ | 135/163 [02:30<00:28,  1.03s/it, loss=0.4442, batch_acc=0.9062, running_acc=0.8815, grad=7.4599]Training epoch 9:  83%|████████▎ | 135/163 [02:30<00:28,  1.03s/it, loss=0.5394, batch_acc=0.8438, running_acc=0.8812, grad=7.4748]Training epoch 9:  83%|████████▎ | 136/163 [02:32<00:35,  1.30s/it, loss=0.5394, batch_acc=0.8438, running_acc=0.8812, grad=7.4748]Training epoch 9:  83%|████████▎ | 136/163 [02:32<00:35,  1.30s/it, loss=0.3763, batch_acc=0.8438, running_acc=0.8810, grad=6.9356]Training epoch 9:  84%|████████▍ | 137/163 [02:33<00:30,  1.17s/it, loss=0.3763, batch_acc=0.8438, running_acc=0.8810, grad=6.9356]Training epoch 9:  84%|████████▍ | 137/163 [02:33<00:30,  1.17s/it, loss=0.3179, batch_acc=0.8750, running_acc=0.8809, grad=5.7466]Training epoch 9:  85%|████████▍ | 138/163 [02:34<00:27,  1.09s/it, loss=0.3179, batch_acc=0.8750, running_acc=0.8809, grad=5.7466]Training epoch 9:  85%|████████▍ | 138/163 [02:34<00:27,  1.09s/it, loss=0.3577, batch_acc=0.9062, running_acc=0.8811, grad=5.6628]Training epoch 9:  85%|████████▌ | 139/163 [02:34<00:24,  1.02s/it, loss=0.3577, batch_acc=0.9062, running_acc=0.8811, grad=5.6628]Training epoch 9:  85%|████████▌ | 139/163 [02:34<00:24,  1.02s/it, loss=0.2935, batch_acc=0.9062, running_acc=0.8813, grad=4.6710]Training epoch 9:  86%|████████▌ | 140/163 [02:36<00:30,  1.33s/it, loss=0.2935, batch_acc=0.9062, running_acc=0.8813, grad=4.6710]Training epoch 9:  86%|████████▌ | 140/163 [02:36<00:30,  1.33s/it, loss=0.4998, batch_acc=0.8125, running_acc=0.8808, grad=7.0521]Training epoch 9:  87%|████████▋ | 141/163 [02:37<00:26,  1.19s/it, loss=0.4998, batch_acc=0.8125, running_acc=0.8808, grad=7.0521]Training epoch 9:  87%|████████▋ | 141/163 [02:37<00:26,  1.19s/it, loss=0.3738, batch_acc=0.9375, running_acc=0.8812, grad=6.7048]Training epoch 9:  87%|████████▋ | 142/163 [02:38<00:23,  1.10s/it, loss=0.3738, batch_acc=0.9375, running_acc=0.8812, grad=6.7048]Training epoch 9:  87%|████████▋ | 142/163 [02:38<00:23,  1.10s/it, loss=0.5139, batch_acc=0.9062, running_acc=0.8814, grad=6.3605]Training epoch 9:  88%|████████▊ | 143/163 [02:39<00:20,  1.03s/it, loss=0.5139, batch_acc=0.9062, running_acc=0.8814, grad=6.3605]Training epoch 9:  88%|████████▊ | 143/163 [02:39<00:20,  1.03s/it, loss=0.3888, batch_acc=0.9062, running_acc=0.8816, grad=5.6791]Training epoch 9:  88%|████████▊ | 144/163 [02:41<00:23,  1.23s/it, loss=0.3888, batch_acc=0.9062, running_acc=0.8816, grad=5.6791]Training epoch 9:  88%|████████▊ | 144/163 [02:41<00:23,  1.23s/it, loss=0.6007, batch_acc=0.8438, running_acc=0.8813, grad=6.6831]Training epoch 9:  89%|████████▉ | 145/163 [02:42<00:20,  1.13s/it, loss=0.6007, batch_acc=0.8438, running_acc=0.8813, grad=6.6831]Training epoch 9:  89%|████████▉ | 145/163 [02:42<00:20,  1.13s/it, loss=0.3432, batch_acc=0.8750, running_acc=0.8812, grad=4.9720]Training epoch 9:  90%|████████▉ | 146/163 [02:43<00:17,  1.05s/it, loss=0.3432, batch_acc=0.8750, running_acc=0.8812, grad=4.9720]Training epoch 9:  90%|████████▉ | 146/163 [02:43<00:17,  1.05s/it, loss=0.6351, batch_acc=0.7500, running_acc=0.8804, grad=8.5255]Training epoch 9:  90%|█████████ | 147/163 [02:44<00:16,  1.01s/it, loss=0.6351, batch_acc=0.7500, running_acc=0.8804, grad=8.5255]Training epoch 9:  90%|█████████ | 147/163 [02:44<00:16,  1.01s/it, loss=0.3649, batch_acc=0.8750, running_acc=0.8803, grad=6.3848]Training epoch 9:  91%|█████████ | 148/163 [02:45<00:19,  1.31s/it, loss=0.3649, batch_acc=0.8750, running_acc=0.8803, grad=6.3848]Training epoch 9:  91%|█████████ | 148/163 [02:45<00:19,  1.31s/it, loss=0.3902, batch_acc=0.9062, running_acc=0.8805, grad=6.6319]Training epoch 9:  91%|█████████▏| 149/163 [02:46<00:16,  1.18s/it, loss=0.3902, batch_acc=0.9062, running_acc=0.8805, grad=6.6319]Training epoch 9:  91%|█████████▏| 149/163 [02:46<00:16,  1.18s/it, loss=0.5621, batch_acc=0.8438, running_acc=0.8802, grad=9.3767]Training epoch 9:  92%|█████████▏| 150/163 [02:47<00:14,  1.09s/it, loss=0.5621, batch_acc=0.8438, running_acc=0.8802, grad=9.3767]Training epoch 9:  92%|█████████▏| 150/163 [02:47<00:14,  1.09s/it, loss=0.4991, batch_acc=0.8125, running_acc=0.8798, grad=6.2142]Training epoch 9:  93%|█████████▎| 151/163 [02:48<00:12,  1.04s/it, loss=0.4991, batch_acc=0.8125, running_acc=0.8798, grad=6.2142]Training epoch 9:  93%|█████████▎| 151/163 [02:48<00:12,  1.04s/it, loss=0.3330, batch_acc=0.9062, running_acc=0.8800, grad=6.1756]Training epoch 9:  93%|█████████▎| 152/163 [02:50<00:14,  1.28s/it, loss=0.3330, batch_acc=0.9062, running_acc=0.8800, grad=6.1756]Training epoch 9:  93%|█████████▎| 152/163 [02:50<00:14,  1.28s/it, loss=0.3958, batch_acc=0.9062, running_acc=0.8801, grad=6.0199]Training epoch 9:  94%|█████████▍| 153/163 [02:51<00:11,  1.16s/it, loss=0.3958, batch_acc=0.9062, running_acc=0.8801, grad=6.0199]Training epoch 9:  94%|█████████▍| 153/163 [02:51<00:11,  1.16s/it, loss=0.4838, batch_acc=0.8438, running_acc=0.8799, grad=9.4747]Training epoch 9:  94%|█████████▍| 154/163 [02:52<00:09,  1.08s/it, loss=0.4838, batch_acc=0.8438, running_acc=0.8799, grad=9.4747]Training epoch 9:  94%|█████████▍| 154/163 [02:52<00:09,  1.08s/it, loss=0.4773, batch_acc=0.8750, running_acc=0.8799, grad=10.5972]Training epoch 9:  95%|█████████▌| 155/163 [02:53<00:08,  1.03s/it, loss=0.4773, batch_acc=0.8750, running_acc=0.8799, grad=10.5972]Training epoch 9:  95%|█████████▌| 155/163 [02:53<00:08,  1.03s/it, loss=0.2600, batch_acc=1.0000, running_acc=0.8806, grad=6.7124] Training epoch 9:  96%|█████████▌| 156/163 [02:55<00:09,  1.34s/it, loss=0.2600, batch_acc=1.0000, running_acc=0.8806, grad=6.7124]Training epoch 9:  96%|█████████▌| 156/163 [02:55<00:09,  1.34s/it, loss=0.3997, batch_acc=0.8438, running_acc=0.8804, grad=8.3988]Training epoch 9:  96%|█████████▋| 157/163 [02:56<00:07,  1.20s/it, loss=0.3997, batch_acc=0.8438, running_acc=0.8804, grad=8.3988]Training epoch 9:  96%|█████████▋| 157/163 [02:56<00:07,  1.20s/it, loss=0.3886, batch_acc=0.9062, running_acc=0.8806, grad=5.2756]Training epoch 9:  97%|█████████▋| 158/163 [02:57<00:05,  1.10s/it, loss=0.3886, batch_acc=0.9062, running_acc=0.8806, grad=5.2756]Training epoch 9:  97%|█████████▋| 158/163 [02:57<00:05,  1.10s/it, loss=0.4045, batch_acc=0.8750, running_acc=0.8805, grad=6.3969]Training epoch 9:  98%|█████████▊| 159/163 [02:57<00:04,  1.03s/it, loss=0.4045, batch_acc=0.8750, running_acc=0.8805, grad=6.3969]Training epoch 9:  98%|█████████▊| 159/163 [02:57<00:04,  1.03s/it, loss=0.2249, batch_acc=1.0000, running_acc=0.8813, grad=4.1450]Training epoch 9:  98%|█████████▊| 160/163 [02:59<00:03,  1.27s/it, loss=0.2249, batch_acc=1.0000, running_acc=0.8813, grad=4.1450]Training epoch 9:  98%|█████████▊| 160/163 [02:59<00:03,  1.27s/it, loss=0.2487, batch_acc=0.8750, running_acc=0.8812, grad=4.7678]Training epoch 9:  99%|█████████▉| 161/163 [03:00<00:02,  1.15s/it, loss=0.2487, batch_acc=0.8750, running_acc=0.8812, grad=4.7678]Training epoch 9:  99%|█████████▉| 161/163 [03:00<00:02,  1.15s/it, loss=0.6521, batch_acc=0.7812, running_acc=0.8806, grad=8.6434]Training epoch 9:  99%|█████████▉| 162/163 [03:01<00:01,  1.07s/it, loss=0.6521, batch_acc=0.7812, running_acc=0.8806, grad=8.6434]Training epoch 9:  99%|█████████▉| 162/163 [03:01<00:01,  1.07s/it, loss=0.3521, batch_acc=0.8125, running_acc=0.8802, grad=6.2927]Training epoch 9: 100%|██████████| 163/163 [03:02<00:00,  1.07it/s, loss=0.3521, batch_acc=0.8125, running_acc=0.8802, grad=6.2927]Training epoch 9: 100%|██████████| 163/163 [03:02<00:00,  1.07it/s, loss=0.3550, batch_acc=0.9048, running_acc=0.8803, grad=7.8129]Training epoch 9: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.3550, batch_acc=0.9048, running_acc=0.8803, grad=7.8129]
Evaluation epoch 9:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 9:   4%|▎         | 1/28 [00:05<02:23,  5.30s/it]Evaluation epoch 9:   4%|▎         | 1/28 [00:05<02:23,  5.30s/it, loss=0.4887, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 9:   7%|▋         | 2/28 [00:05<01:00,  2.34s/it, loss=0.4887, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 9:   7%|▋         | 2/28 [00:05<01:00,  2.34s/it, loss=1.1563, batch_acc=0.6250, running_acc=0.7656]Evaluation epoch 9:  11%|█         | 3/28 [00:05<00:34,  1.39s/it, loss=1.1563, batch_acc=0.6250, running_acc=0.7656]Evaluation epoch 9:  11%|█         | 3/28 [00:05<00:34,  1.39s/it, loss=0.5325, batch_acc=0.8438, running_acc=0.7917]Evaluation epoch 9:  14%|█▍        | 4/28 [00:10<01:03,  2.63s/it, loss=0.5325, batch_acc=0.8438, running_acc=0.7917]Evaluation epoch 9:  14%|█▍        | 4/28 [00:10<01:03,  2.63s/it, loss=0.7784, batch_acc=0.7812, running_acc=0.7891]Evaluation epoch 9:  18%|█▊        | 5/28 [00:10<00:40,  1.78s/it, loss=0.7784, batch_acc=0.7812, running_acc=0.7891]Evaluation epoch 9:  18%|█▊        | 5/28 [00:10<00:40,  1.78s/it, loss=1.6951, batch_acc=0.6250, running_acc=0.7562]Evaluation epoch 9:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=1.6951, batch_acc=0.6250, running_acc=0.7562]Evaluation epoch 9:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=1.6489, batch_acc=0.4688, running_acc=0.7083]Evaluation epoch 9:  25%|██▌       | 7/28 [00:11<00:19,  1.07it/s, loss=1.6489, batch_acc=0.4688, running_acc=0.7083]Evaluation epoch 9:  25%|██▌       | 7/28 [00:11<00:19,  1.07it/s, loss=0.8430, batch_acc=0.7188, running_acc=0.7098]Evaluation epoch 9:  29%|██▊       | 8/28 [00:14<00:33,  1.67s/it, loss=0.8430, batch_acc=0.7188, running_acc=0.7098]Evaluation epoch 9:  29%|██▊       | 8/28 [00:14<00:33,  1.67s/it, loss=0.8926, batch_acc=0.8438, running_acc=0.7266]Evaluation epoch 9:  32%|███▏      | 9/28 [00:14<00:23,  1.23s/it, loss=0.8926, batch_acc=0.8438, running_acc=0.7266]Evaluation epoch 9:  32%|███▏      | 9/28 [00:14<00:23,  1.23s/it, loss=0.7458, batch_acc=0.8125, running_acc=0.7361]Evaluation epoch 9:  36%|███▌      | 10/28 [00:14<00:16,  1.07it/s, loss=0.7458, batch_acc=0.8125, running_acc=0.7361]Evaluation epoch 9:  36%|███▌      | 10/28 [00:14<00:16,  1.07it/s, loss=0.5262, batch_acc=0.8750, running_acc=0.7500]Evaluation epoch 9:  39%|███▉      | 11/28 [00:15<00:12,  1.38it/s, loss=0.5262, batch_acc=0.8750, running_acc=0.7500]Evaluation epoch 9:  39%|███▉      | 11/28 [00:15<00:12,  1.38it/s, loss=0.6289, batch_acc=0.8750, running_acc=0.7614]Evaluation epoch 9:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=0.6289, batch_acc=0.8750, running_acc=0.7614]Evaluation epoch 9:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=0.8829, batch_acc=0.7812, running_acc=0.7630]Evaluation epoch 9:  46%|████▋     | 13/28 [00:21<00:24,  1.61s/it, loss=0.8829, batch_acc=0.7812, running_acc=0.7630]Evaluation epoch 9:  46%|████▋     | 13/28 [00:21<00:24,  1.61s/it, loss=1.1543, batch_acc=0.7500, running_acc=0.7620]Evaluation epoch 9:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=1.1543, batch_acc=0.7500, running_acc=0.7620]Evaluation epoch 9:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=1.0375, batch_acc=0.7500, running_acc=0.7612]Evaluation epoch 9:  54%|█████▎    | 15/28 [00:21<00:11,  1.08it/s, loss=1.0375, batch_acc=0.7500, running_acc=0.7612]Evaluation epoch 9:  54%|█████▎    | 15/28 [00:21<00:11,  1.08it/s, loss=1.8079, batch_acc=0.5000, running_acc=0.7438]Evaluation epoch 9:  57%|█████▋    | 16/28 [00:24<00:17,  1.46s/it, loss=1.8079, batch_acc=0.5000, running_acc=0.7438]Evaluation epoch 9:  57%|█████▋    | 16/28 [00:24<00:17,  1.46s/it, loss=0.9827, batch_acc=0.5625, running_acc=0.7324]Evaluation epoch 9:  61%|██████    | 17/28 [00:24<00:12,  1.10s/it, loss=0.9827, batch_acc=0.5625, running_acc=0.7324]Evaluation epoch 9:  61%|██████    | 17/28 [00:24<00:12,  1.10s/it, loss=0.6843, batch_acc=0.7188, running_acc=0.7316]Evaluation epoch 9:  64%|██████▍   | 18/28 [00:24<00:08,  1.18it/s, loss=0.6843, batch_acc=0.7188, running_acc=0.7316]Evaluation epoch 9:  64%|██████▍   | 18/28 [00:24<00:08,  1.18it/s, loss=0.7879, batch_acc=0.8438, running_acc=0.7378]Evaluation epoch 9:  68%|██████▊   | 19/28 [00:25<00:06,  1.49it/s, loss=0.7879, batch_acc=0.8438, running_acc=0.7378]Evaluation epoch 9:  68%|██████▊   | 19/28 [00:25<00:06,  1.49it/s, loss=1.3355, batch_acc=0.6250, running_acc=0.7319]Evaluation epoch 9:  71%|███████▏  | 20/28 [00:27<00:09,  1.23s/it, loss=1.3355, batch_acc=0.6250, running_acc=0.7319]Evaluation epoch 9:  71%|███████▏  | 20/28 [00:27<00:09,  1.23s/it, loss=0.5123, batch_acc=0.7500, running_acc=0.7328]Evaluation epoch 9:  75%|███████▌  | 21/28 [00:27<00:06,  1.07it/s, loss=0.5123, batch_acc=0.7500, running_acc=0.7328]Evaluation epoch 9:  75%|███████▌  | 21/28 [00:27<00:06,  1.07it/s, loss=0.8741, batch_acc=0.7812, running_acc=0.7351]Evaluation epoch 9:  79%|███████▊  | 22/28 [00:28<00:04,  1.36it/s, loss=0.8741, batch_acc=0.7812, running_acc=0.7351]Evaluation epoch 9:  79%|███████▊  | 22/28 [00:28<00:04,  1.36it/s, loss=1.0088, batch_acc=0.7500, running_acc=0.7358]Evaluation epoch 9:  82%|████████▏ | 23/28 [00:28<00:02,  1.69it/s, loss=1.0088, batch_acc=0.7500, running_acc=0.7358]Evaluation epoch 9:  82%|████████▏ | 23/28 [00:28<00:02,  1.69it/s, loss=1.5804, batch_acc=0.4062, running_acc=0.7215]Evaluation epoch 9:  86%|████████▌ | 24/28 [00:33<00:07,  1.94s/it, loss=1.5804, batch_acc=0.4062, running_acc=0.7215]Evaluation epoch 9:  86%|████████▌ | 24/28 [00:33<00:07,  1.94s/it, loss=0.5427, batch_acc=0.8125, running_acc=0.7253]Evaluation epoch 9:  89%|████████▉ | 25/28 [00:33<00:04,  1.43s/it, loss=0.5427, batch_acc=0.8125, running_acc=0.7253]Evaluation epoch 9:  89%|████████▉ | 25/28 [00:33<00:04,  1.43s/it, loss=0.5626, batch_acc=0.8125, running_acc=0.7288]Evaluation epoch 9:  93%|█████████▎| 26/28 [00:33<00:02,  1.08s/it, loss=0.5626, batch_acc=0.8125, running_acc=0.7288]Evaluation epoch 9:  93%|█████████▎| 26/28 [00:33<00:02,  1.08s/it, loss=1.4450, batch_acc=0.5625, running_acc=0.7224]Evaluation epoch 9:  96%|█████████▋| 27/28 [00:34<00:00,  1.20it/s, loss=1.4450, batch_acc=0.5625, running_acc=0.7224]Evaluation epoch 9:  96%|█████████▋| 27/28 [00:34<00:00,  1.20it/s, loss=1.6594, batch_acc=0.5000, running_acc=0.7141]Evaluation epoch 9: 100%|██████████| 28/28 [00:34<00:00,  1.20it/s, loss=1.2434, batch_acc=0.6667, running_acc=0.7140]Evaluation epoch 9: 100%|██████████| 28/28 [00:34<00:00,  1.22s/it, loss=1.2434, batch_acc=0.6667, running_acc=0.7140]
Training epoch 10:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 10:   1%|          | 1/163 [00:05<14:40,  5.44s/it]Training epoch 10:   1%|          | 1/163 [00:05<14:40,  5.44s/it, loss=0.3799, batch_acc=0.9062, running_acc=0.9062, grad=6.8194]Training epoch 10:   1%|          | 2/163 [00:06<07:23,  2.76s/it, loss=0.3799, batch_acc=0.9062, running_acc=0.9062, grad=6.8194]Training epoch 10:   1%|          | 2/163 [00:06<07:23,  2.76s/it, loss=0.4296, batch_acc=0.8125, running_acc=0.8594, grad=6.2933]Training epoch 10:   2%|▏         | 3/163 [00:07<05:04,  1.90s/it, loss=0.4296, batch_acc=0.8125, running_acc=0.8594, grad=6.2933]Training epoch 10:   2%|▏         | 3/163 [00:07<05:04,  1.90s/it, loss=0.2987, batch_acc=0.8438, running_acc=0.8542, grad=4.7451]Training epoch 10:   2%|▏         | 4/163 [00:09<05:32,  2.09s/it, loss=0.2987, batch_acc=0.8438, running_acc=0.8542, grad=4.7451]Training epoch 10:   2%|▏         | 4/163 [00:09<05:32,  2.09s/it, loss=0.3323, batch_acc=0.9062, running_acc=0.8672, grad=4.0402]Training epoch 10:   3%|▎         | 5/163 [00:10<04:21,  1.66s/it, loss=0.3323, batch_acc=0.9062, running_acc=0.8672, grad=4.0402]Training epoch 10:   3%|▎         | 5/163 [00:10<04:21,  1.66s/it, loss=0.2813, batch_acc=0.9375, running_acc=0.8812, grad=4.4924]Training epoch 10:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=0.2813, batch_acc=0.9375, running_acc=0.8812, grad=4.4924]Training epoch 10:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=0.1299, batch_acc=0.9688, running_acc=0.8958, grad=2.9894]Training epoch 10:   4%|▍         | 7/163 [00:12<03:10,  1.22s/it, loss=0.1299, batch_acc=0.9688, running_acc=0.8958, grad=2.9894]Training epoch 10:   4%|▍         | 7/163 [00:12<03:10,  1.22s/it, loss=0.2099, batch_acc=0.9375, running_acc=0.9018, grad=5.4404]Training epoch 10:   5%|▍         | 8/163 [00:13<03:26,  1.33s/it, loss=0.2099, batch_acc=0.9375, running_acc=0.9018, grad=5.4404]Training epoch 10:   5%|▍         | 8/163 [00:13<03:26,  1.33s/it, loss=0.2791, batch_acc=0.8750, running_acc=0.8984, grad=4.9468]Training epoch 10:   6%|▌         | 9/163 [00:14<03:03,  1.19s/it, loss=0.2791, batch_acc=0.8750, running_acc=0.8984, grad=4.9468]Training epoch 10:   6%|▌         | 9/163 [00:14<03:03,  1.19s/it, loss=0.3927, batch_acc=0.9062, running_acc=0.8993, grad=6.4616]Training epoch 10:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=0.3927, batch_acc=0.9062, running_acc=0.8993, grad=6.4616]Training epoch 10:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=0.4359, batch_acc=0.8438, running_acc=0.8938, grad=5.0441]Training epoch 10:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=0.4359, batch_acc=0.8438, running_acc=0.8938, grad=5.0441]Training epoch 10:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=0.2466, batch_acc=0.9062, running_acc=0.8949, grad=5.5386]Training epoch 10:   7%|▋         | 12/163 [00:18<03:02,  1.21s/it, loss=0.2466, batch_acc=0.9062, running_acc=0.8949, grad=5.5386]Training epoch 10:   7%|▋         | 12/163 [00:18<03:02,  1.21s/it, loss=0.1826, batch_acc=0.9375, running_acc=0.8984, grad=2.8939]Training epoch 10:   8%|▊         | 13/163 [00:18<02:46,  1.11s/it, loss=0.1826, batch_acc=0.9375, running_acc=0.8984, grad=2.8939]Training epoch 10:   8%|▊         | 13/163 [00:18<02:46,  1.11s/it, loss=0.2465, batch_acc=1.0000, running_acc=0.9062, grad=4.3984]Training epoch 10:   9%|▊         | 14/163 [00:19<02:34,  1.04s/it, loss=0.2465, batch_acc=1.0000, running_acc=0.9062, grad=4.3984]Training epoch 10:   9%|▊         | 14/163 [00:19<02:34,  1.04s/it, loss=0.2372, batch_acc=0.9062, running_acc=0.9062, grad=5.1957]Training epoch 10:   9%|▉         | 15/163 [00:20<02:26,  1.01it/s, loss=0.2372, batch_acc=0.9062, running_acc=0.9062, grad=5.1957]Training epoch 10:   9%|▉         | 15/163 [00:20<02:26,  1.01it/s, loss=0.2372, batch_acc=0.9375, running_acc=0.9083, grad=4.8234]Training epoch 10:  10%|▉         | 16/163 [00:22<03:10,  1.30s/it, loss=0.2372, batch_acc=0.9375, running_acc=0.9083, grad=4.8234]Training epoch 10:  10%|▉         | 16/163 [00:22<03:10,  1.30s/it, loss=0.2564, batch_acc=0.9062, running_acc=0.9082, grad=5.0138]Training epoch 10:  10%|█         | 17/163 [00:23<02:50,  1.17s/it, loss=0.2564, batch_acc=0.9062, running_acc=0.9082, grad=5.0138]Training epoch 10:  10%|█         | 17/163 [00:23<02:50,  1.17s/it, loss=0.2503, batch_acc=0.9375, running_acc=0.9099, grad=6.7379]Training epoch 10:  11%|█         | 18/163 [00:24<02:37,  1.08s/it, loss=0.2503, batch_acc=0.9375, running_acc=0.9099, grad=6.7379]Training epoch 10:  11%|█         | 18/163 [00:24<02:37,  1.08s/it, loss=0.2679, batch_acc=0.9062, running_acc=0.9097, grad=5.0111]Training epoch 10:  12%|█▏        | 19/163 [00:25<02:30,  1.04s/it, loss=0.2679, batch_acc=0.9062, running_acc=0.9097, grad=5.0111]Training epoch 10:  12%|█▏        | 19/163 [00:25<02:30,  1.04s/it, loss=0.2354, batch_acc=0.9375, running_acc=0.9112, grad=3.4006]Training epoch 10:  12%|█▏        | 20/163 [00:26<02:49,  1.19s/it, loss=0.2354, batch_acc=0.9375, running_acc=0.9112, grad=3.4006]Training epoch 10:  12%|█▏        | 20/163 [00:26<02:49,  1.19s/it, loss=0.1992, batch_acc=1.0000, running_acc=0.9156, grad=6.9269]Training epoch 10:  13%|█▎        | 21/163 [00:27<02:35,  1.09s/it, loss=0.1992, batch_acc=1.0000, running_acc=0.9156, grad=6.9269]Training epoch 10:  13%|█▎        | 21/163 [00:27<02:35,  1.09s/it, loss=0.4848, batch_acc=0.8438, running_acc=0.9122, grad=6.9546]Training epoch 10:  13%|█▎        | 22/163 [00:28<02:24,  1.03s/it, loss=0.4848, batch_acc=0.8438, running_acc=0.9122, grad=6.9546]Training epoch 10:  13%|█▎        | 22/163 [00:28<02:24,  1.03s/it, loss=0.3132, batch_acc=0.9375, running_acc=0.9134, grad=8.0836]Training epoch 10:  14%|█▍        | 23/163 [00:29<02:17,  1.02it/s, loss=0.3132, batch_acc=0.9375, running_acc=0.9134, grad=8.0836]Training epoch 10:  14%|█▍        | 23/163 [00:29<02:17,  1.02it/s, loss=0.3189, batch_acc=0.8750, running_acc=0.9117, grad=5.4243]Training epoch 10:  15%|█▍        | 24/163 [00:31<02:46,  1.20s/it, loss=0.3189, batch_acc=0.8750, running_acc=0.9117, grad=5.4243]Training epoch 10:  15%|█▍        | 24/163 [00:31<02:46,  1.20s/it, loss=0.4582, batch_acc=0.8125, running_acc=0.9076, grad=5.7776]Training epoch 10:  15%|█▌        | 25/163 [00:32<02:32,  1.10s/it, loss=0.4582, batch_acc=0.8125, running_acc=0.9076, grad=5.7776]Training epoch 10:  15%|█▌        | 25/163 [00:32<02:32,  1.10s/it, loss=0.2147, batch_acc=0.9062, running_acc=0.9075, grad=4.7144]Training epoch 10:  16%|█▌        | 26/163 [00:33<02:21,  1.04s/it, loss=0.2147, batch_acc=0.9062, running_acc=0.9075, grad=4.7144]Training epoch 10:  16%|█▌        | 26/163 [00:33<02:21,  1.04s/it, loss=0.3465, batch_acc=0.8750, running_acc=0.9062, grad=5.1119]Training epoch 10:  17%|█▋        | 27/163 [00:33<02:14,  1.01it/s, loss=0.3465, batch_acc=0.8750, running_acc=0.9062, grad=5.1119]Training epoch 10:  17%|█▋        | 27/163 [00:33<02:14,  1.01it/s, loss=0.2111, batch_acc=0.9688, running_acc=0.9086, grad=3.8291]Training epoch 10:  17%|█▋        | 28/163 [00:35<02:31,  1.12s/it, loss=0.2111, batch_acc=0.9688, running_acc=0.9086, grad=3.8291]Training epoch 10:  17%|█▋        | 28/163 [00:35<02:31,  1.12s/it, loss=0.2595, batch_acc=0.9062, running_acc=0.9085, grad=5.6171]Training epoch 10:  18%|█▊        | 29/163 [00:36<02:20,  1.05s/it, loss=0.2595, batch_acc=0.9062, running_acc=0.9085, grad=5.6171]Training epoch 10:  18%|█▊        | 29/163 [00:36<02:20,  1.05s/it, loss=0.3200, batch_acc=0.9062, running_acc=0.9084, grad=5.9622]Training epoch 10:  18%|█▊        | 30/163 [00:37<02:12,  1.00it/s, loss=0.3200, batch_acc=0.9062, running_acc=0.9084, grad=5.9622]Training epoch 10:  18%|█▊        | 30/163 [00:37<02:12,  1.00it/s, loss=0.1903, batch_acc=0.9375, running_acc=0.9094, grad=4.5226]Training epoch 10:  19%|█▉        | 31/163 [00:37<02:06,  1.04it/s, loss=0.1903, batch_acc=0.9375, running_acc=0.9094, grad=4.5226]Training epoch 10:  19%|█▉        | 31/163 [00:37<02:06,  1.04it/s, loss=0.3471, batch_acc=0.9062, running_acc=0.9093, grad=4.7336]Training epoch 10:  20%|█▉        | 32/163 [00:39<02:24,  1.10s/it, loss=0.3471, batch_acc=0.9062, running_acc=0.9093, grad=4.7336]Training epoch 10:  20%|█▉        | 32/163 [00:39<02:24,  1.10s/it, loss=0.2638, batch_acc=0.8750, running_acc=0.9082, grad=4.6073]Training epoch 10:  20%|██        | 33/163 [00:40<02:14,  1.03s/it, loss=0.2638, batch_acc=0.8750, running_acc=0.9082, grad=4.6073]Training epoch 10:  20%|██        | 33/163 [00:40<02:14,  1.03s/it, loss=0.2969, batch_acc=0.9375, running_acc=0.9091, grad=5.4503]Training epoch 10:  21%|██        | 34/163 [00:41<02:07,  1.01it/s, loss=0.2969, batch_acc=0.9375, running_acc=0.9091, grad=5.4503]Training epoch 10:  21%|██        | 34/163 [00:41<02:07,  1.01it/s, loss=0.3018, batch_acc=0.8750, running_acc=0.9081, grad=6.9778]Training epoch 10:  21%|██▏       | 35/163 [00:42<02:02,  1.05it/s, loss=0.3018, batch_acc=0.8750, running_acc=0.9081, grad=6.9778]Training epoch 10:  21%|██▏       | 35/163 [00:42<02:02,  1.05it/s, loss=0.5380, batch_acc=0.8438, running_acc=0.9062, grad=6.4761]Training epoch 10:  22%|██▏       | 36/163 [00:43<02:10,  1.03s/it, loss=0.5380, batch_acc=0.8438, running_acc=0.9062, grad=6.4761]Training epoch 10:  22%|██▏       | 36/163 [00:43<02:10,  1.03s/it, loss=0.4125, batch_acc=0.8750, running_acc=0.9054, grad=7.6940]Training epoch 10:  23%|██▎       | 37/163 [00:44<02:03,  1.02it/s, loss=0.4125, batch_acc=0.8750, running_acc=0.9054, grad=7.6940]Training epoch 10:  23%|██▎       | 37/163 [00:44<02:03,  1.02it/s, loss=0.4909, batch_acc=0.8750, running_acc=0.9046, grad=9.0675]Training epoch 10:  23%|██▎       | 38/163 [00:44<01:58,  1.05it/s, loss=0.4909, batch_acc=0.8750, running_acc=0.9046, grad=9.0675]Training epoch 10:  23%|██▎       | 38/163 [00:44<01:58,  1.05it/s, loss=0.4152, batch_acc=0.7812, running_acc=0.9013, grad=5.8614]Training epoch 10:  24%|██▍       | 39/163 [00:45<01:55,  1.07it/s, loss=0.4152, batch_acc=0.7812, running_acc=0.9013, grad=5.8614]Training epoch 10:  24%|██▍       | 39/163 [00:45<01:55,  1.07it/s, loss=0.3608, batch_acc=0.9062, running_acc=0.9014, grad=5.1217]Training epoch 10:  25%|██▍       | 40/163 [00:48<02:41,  1.32s/it, loss=0.3608, batch_acc=0.9062, running_acc=0.9014, grad=5.1217]Training epoch 10:  25%|██▍       | 40/163 [00:48<02:41,  1.32s/it, loss=0.2947, batch_acc=0.9375, running_acc=0.9023, grad=5.4934]Training epoch 10:  25%|██▌       | 41/163 [00:48<02:24,  1.18s/it, loss=0.2947, batch_acc=0.9375, running_acc=0.9023, grad=5.4934]Training epoch 10:  25%|██▌       | 41/163 [00:48<02:24,  1.18s/it, loss=0.3427, batch_acc=0.9688, running_acc=0.9040, grad=6.3218]Training epoch 10:  26%|██▌       | 42/163 [00:49<02:12,  1.09s/it, loss=0.3427, batch_acc=0.9688, running_acc=0.9040, grad=6.3218]Training epoch 10:  26%|██▌       | 42/163 [00:49<02:12,  1.09s/it, loss=0.3122, batch_acc=0.9062, running_acc=0.9040, grad=7.2764]Training epoch 10:  26%|██▋       | 43/163 [00:50<02:04,  1.04s/it, loss=0.3122, batch_acc=0.9062, running_acc=0.9040, grad=7.2764]Training epoch 10:  26%|██▋       | 43/163 [00:50<02:04,  1.04s/it, loss=0.4265, batch_acc=0.8438, running_acc=0.9026, grad=7.2681]Training epoch 10:  27%|██▋       | 44/163 [00:52<02:15,  1.14s/it, loss=0.4265, batch_acc=0.8438, running_acc=0.9026, grad=7.2681]Training epoch 10:  27%|██▋       | 44/163 [00:52<02:15,  1.14s/it, loss=0.2528, batch_acc=0.9375, running_acc=0.9034, grad=4.3347]Training epoch 10:  28%|██▊       | 45/163 [00:52<02:05,  1.06s/it, loss=0.2528, batch_acc=0.9375, running_acc=0.9034, grad=4.3347]Training epoch 10:  28%|██▊       | 45/163 [00:52<02:05,  1.06s/it, loss=0.2875, batch_acc=0.9062, running_acc=0.9035, grad=6.1634]Training epoch 10:  28%|██▊       | 46/163 [00:53<01:57,  1.01s/it, loss=0.2875, batch_acc=0.9062, running_acc=0.9035, grad=6.1634]Training epoch 10:  28%|██▊       | 46/163 [00:53<01:57,  1.01s/it, loss=0.2247, batch_acc=0.9375, running_acc=0.9042, grad=3.3486]Training epoch 10:  29%|██▉       | 47/163 [00:54<01:52,  1.03it/s, loss=0.2247, batch_acc=0.9375, running_acc=0.9042, grad=3.3486]Training epoch 10:  29%|██▉       | 47/163 [00:54<01:52,  1.03it/s, loss=0.3626, batch_acc=0.9062, running_acc=0.9043, grad=6.0216]Training epoch 10:  29%|██▉       | 48/163 [00:56<02:02,  1.07s/it, loss=0.3626, batch_acc=0.9062, running_acc=0.9043, grad=6.0216]Training epoch 10:  29%|██▉       | 48/163 [00:56<02:02,  1.07s/it, loss=0.2958, batch_acc=0.9375, running_acc=0.9049, grad=4.5341]Training epoch 10:  30%|███       | 49/163 [00:56<01:55,  1.01s/it, loss=0.2958, batch_acc=0.9375, running_acc=0.9049, grad=4.5341]Training epoch 10:  30%|███       | 49/163 [00:56<01:55,  1.01s/it, loss=0.3887, batch_acc=0.8438, running_acc=0.9037, grad=5.2478]Training epoch 10:  31%|███       | 50/163 [00:57<01:49,  1.03it/s, loss=0.3887, batch_acc=0.8438, running_acc=0.9037, grad=5.2478]Training epoch 10:  31%|███       | 50/163 [00:57<01:49,  1.03it/s, loss=0.3015, batch_acc=0.9062, running_acc=0.9038, grad=4.1696]Training epoch 10:  31%|███▏      | 51/163 [00:58<01:45,  1.06it/s, loss=0.3015, batch_acc=0.9062, running_acc=0.9038, grad=4.1696]Training epoch 10:  31%|███▏      | 51/163 [00:58<01:45,  1.06it/s, loss=0.1740, batch_acc=0.9375, running_acc=0.9044, grad=2.5774]Training epoch 10:  32%|███▏      | 52/163 [01:00<02:06,  1.14s/it, loss=0.1740, batch_acc=0.9375, running_acc=0.9044, grad=2.5774]Training epoch 10:  32%|███▏      | 52/163 [01:00<02:06,  1.14s/it, loss=0.5278, batch_acc=0.7500, running_acc=0.9014, grad=9.6205]Training epoch 10:  33%|███▎      | 53/163 [01:01<01:56,  1.06s/it, loss=0.5278, batch_acc=0.7500, running_acc=0.9014, grad=9.6205]Training epoch 10:  33%|███▎      | 53/163 [01:01<01:56,  1.06s/it, loss=0.3090, batch_acc=0.9062, running_acc=0.9015, grad=5.4109]Training epoch 10:  33%|███▎      | 54/163 [01:02<01:49,  1.00s/it, loss=0.3090, batch_acc=0.9062, running_acc=0.9015, grad=5.4109]Training epoch 10:  33%|███▎      | 54/163 [01:02<01:49,  1.00s/it, loss=0.4603, batch_acc=0.9062, running_acc=0.9016, grad=5.4616]Training epoch 10:  34%|███▎      | 55/163 [01:02<01:44,  1.03it/s, loss=0.4603, batch_acc=0.9062, running_acc=0.9016, grad=5.4616]Training epoch 10:  34%|███▎      | 55/163 [01:02<01:44,  1.03it/s, loss=0.2317, batch_acc=0.9375, running_acc=0.9023, grad=3.6954]Training epoch 10:  34%|███▍      | 56/163 [01:04<02:11,  1.23s/it, loss=0.2317, batch_acc=0.9375, running_acc=0.9023, grad=3.6954]Training epoch 10:  34%|███▍      | 56/163 [01:04<02:11,  1.23s/it, loss=0.2083, batch_acc=0.9688, running_acc=0.9035, grad=3.7231]Training epoch 10:  35%|███▍      | 57/163 [01:05<01:59,  1.13s/it, loss=0.2083, batch_acc=0.9688, running_acc=0.9035, grad=3.7231]Training epoch 10:  35%|███▍      | 57/163 [01:05<01:59,  1.13s/it, loss=0.1900, batch_acc=0.9375, running_acc=0.9041, grad=4.0739]Training epoch 10:  36%|███▌      | 58/163 [01:06<01:50,  1.05s/it, loss=0.1900, batch_acc=0.9375, running_acc=0.9041, grad=4.0739]Training epoch 10:  36%|███▌      | 58/163 [01:06<01:50,  1.05s/it, loss=0.4307, batch_acc=0.8750, running_acc=0.9036, grad=5.8932]Training epoch 10:  36%|███▌      | 59/163 [01:07<01:43,  1.00it/s, loss=0.4307, batch_acc=0.8750, running_acc=0.9036, grad=5.8932]Training epoch 10:  36%|███▌      | 59/163 [01:07<01:43,  1.00it/s, loss=0.3154, batch_acc=0.8750, running_acc=0.9031, grad=5.0414]Training epoch 10:  37%|███▋      | 60/163 [01:08<01:53,  1.10s/it, loss=0.3154, batch_acc=0.8750, running_acc=0.9031, grad=5.0414]Training epoch 10:  37%|███▋      | 60/163 [01:08<01:53,  1.10s/it, loss=0.3763, batch_acc=0.9375, running_acc=0.9036, grad=7.7144]Training epoch 10:  37%|███▋      | 61/163 [01:09<01:45,  1.04s/it, loss=0.3763, batch_acc=0.9375, running_acc=0.9036, grad=7.7144]Training epoch 10:  37%|███▋      | 61/163 [01:09<01:45,  1.04s/it, loss=0.1028, batch_acc=0.9688, running_acc=0.9047, grad=1.6442]Training epoch 10:  38%|███▊      | 62/163 [01:10<01:39,  1.01it/s, loss=0.1028, batch_acc=0.9688, running_acc=0.9047, grad=1.6442]Training epoch 10:  38%|███▊      | 62/163 [01:10<01:39,  1.01it/s, loss=0.3862, batch_acc=0.8750, running_acc=0.9042, grad=6.6835]Training epoch 10:  39%|███▊      | 63/163 [01:11<01:35,  1.05it/s, loss=0.3862, batch_acc=0.8750, running_acc=0.9042, grad=6.6835]Training epoch 10:  39%|███▊      | 63/163 [01:11<01:35,  1.05it/s, loss=0.4232, batch_acc=0.7812, running_acc=0.9023, grad=6.3778]Training epoch 10:  39%|███▉      | 64/163 [01:13<02:04,  1.26s/it, loss=0.4232, batch_acc=0.7812, running_acc=0.9023, grad=6.3778]Training epoch 10:  39%|███▉      | 64/163 [01:13<02:04,  1.26s/it, loss=0.4749, batch_acc=0.9062, running_acc=0.9023, grad=6.0998]Training epoch 10:  40%|███▉      | 65/163 [01:14<01:52,  1.14s/it, loss=0.4749, batch_acc=0.9062, running_acc=0.9023, grad=6.0998]Training epoch 10:  40%|███▉      | 65/163 [01:14<01:52,  1.14s/it, loss=0.3012, batch_acc=0.9375, running_acc=0.9029, grad=5.4191]Training epoch 10:  40%|████      | 66/163 [01:15<01:43,  1.07s/it, loss=0.3012, batch_acc=0.9375, running_acc=0.9029, grad=5.4191]Training epoch 10:  40%|████      | 66/163 [01:15<01:43,  1.07s/it, loss=0.1878, batch_acc=0.9688, running_acc=0.9039, grad=2.9813]Training epoch 10:  41%|████      | 67/163 [01:15<01:36,  1.01s/it, loss=0.1878, batch_acc=0.9688, running_acc=0.9039, grad=2.9813]Training epoch 10:  41%|████      | 67/163 [01:15<01:36,  1.01s/it, loss=0.2342, batch_acc=0.9375, running_acc=0.9044, grad=4.5927]Training epoch 10:  42%|████▏     | 68/163 [01:17<01:37,  1.02s/it, loss=0.2342, batch_acc=0.9375, running_acc=0.9044, grad=4.5927]Training epoch 10:  42%|████▏     | 68/163 [01:17<01:37,  1.02s/it, loss=0.2202, batch_acc=0.9688, running_acc=0.9053, grad=4.2472]Training epoch 10:  42%|████▏     | 69/163 [01:17<01:32,  1.02it/s, loss=0.2202, batch_acc=0.9688, running_acc=0.9053, grad=4.2472]Training epoch 10:  42%|████▏     | 69/163 [01:17<01:32,  1.02it/s, loss=0.3444, batch_acc=0.8438, running_acc=0.9044, grad=5.8178]Training epoch 10:  43%|████▎     | 70/163 [01:18<01:28,  1.05it/s, loss=0.3444, batch_acc=0.8438, running_acc=0.9044, grad=5.8178]Training epoch 10:  43%|████▎     | 70/163 [01:18<01:28,  1.05it/s, loss=0.2461, batch_acc=0.9062, running_acc=0.9045, grad=4.4527]Training epoch 10:  44%|████▎     | 71/163 [01:19<01:25,  1.08it/s, loss=0.2461, batch_acc=0.9062, running_acc=0.9045, grad=4.4527]Training epoch 10:  44%|████▎     | 71/163 [01:19<01:25,  1.08it/s, loss=0.2420, batch_acc=0.9062, running_acc=0.9045, grad=4.0577]Training epoch 10:  44%|████▍     | 72/163 [01:21<02:01,  1.33s/it, loss=0.2420, batch_acc=0.9062, running_acc=0.9045, grad=4.0577]Training epoch 10:  44%|████▍     | 72/163 [01:21<02:01,  1.33s/it, loss=0.2942, batch_acc=0.9062, running_acc=0.9045, grad=6.3729]Training epoch 10:  45%|████▍     | 73/163 [01:22<01:47,  1.20s/it, loss=0.2942, batch_acc=0.9062, running_acc=0.9045, grad=6.3729]Training epoch 10:  45%|████▍     | 73/163 [01:22<01:47,  1.20s/it, loss=0.2242, batch_acc=0.9375, running_acc=0.9050, grad=4.5590]Training epoch 10:  45%|████▌     | 74/163 [01:23<01:37,  1.10s/it, loss=0.2242, batch_acc=0.9375, running_acc=0.9050, grad=4.5590]Training epoch 10:  45%|████▌     | 74/163 [01:23<01:37,  1.10s/it, loss=0.2841, batch_acc=0.9375, running_acc=0.9054, grad=4.7677]Training epoch 10:  46%|████▌     | 75/163 [01:24<01:30,  1.03s/it, loss=0.2841, batch_acc=0.9375, running_acc=0.9054, grad=4.7677]Training epoch 10:  46%|████▌     | 75/163 [01:24<01:30,  1.03s/it, loss=0.2305, batch_acc=0.9062, running_acc=0.9054, grad=3.7629]Training epoch 10:  47%|████▋     | 76/163 [01:26<01:54,  1.32s/it, loss=0.2305, batch_acc=0.9062, running_acc=0.9054, grad=3.7629]Training epoch 10:  47%|████▋     | 76/163 [01:26<01:54,  1.32s/it, loss=0.3632, batch_acc=0.9062, running_acc=0.9054, grad=6.7518]Training epoch 10:  47%|████▋     | 77/163 [01:27<01:41,  1.18s/it, loss=0.3632, batch_acc=0.9062, running_acc=0.9054, grad=6.7518]Training epoch 10:  47%|████▋     | 77/163 [01:27<01:41,  1.18s/it, loss=0.2910, batch_acc=0.9375, running_acc=0.9058, grad=4.3851]Training epoch 10:  48%|████▊     | 78/163 [01:28<01:32,  1.09s/it, loss=0.2910, batch_acc=0.9375, running_acc=0.9058, grad=4.3851]Training epoch 10:  48%|████▊     | 78/163 [01:28<01:32,  1.09s/it, loss=0.3111, batch_acc=0.9375, running_acc=0.9062, grad=7.7749]Training epoch 10:  48%|████▊     | 79/163 [01:29<01:26,  1.03s/it, loss=0.3111, batch_acc=0.9375, running_acc=0.9062, grad=7.7749]Training epoch 10:  48%|████▊     | 79/163 [01:29<01:26,  1.03s/it, loss=0.4331, batch_acc=0.8438, running_acc=0.9055, grad=6.5044]Training epoch 10:  49%|████▉     | 80/163 [01:30<01:40,  1.21s/it, loss=0.4331, batch_acc=0.8438, running_acc=0.9055, grad=6.5044]Training epoch 10:  49%|████▉     | 80/163 [01:30<01:40,  1.21s/it, loss=0.2788, batch_acc=0.9375, running_acc=0.9059, grad=5.4130]Training epoch 10:  50%|████▉     | 81/163 [01:31<01:31,  1.11s/it, loss=0.2788, batch_acc=0.9375, running_acc=0.9059, grad=5.4130]Training epoch 10:  50%|████▉     | 81/163 [01:31<01:31,  1.11s/it, loss=0.4207, batch_acc=0.8750, running_acc=0.9055, grad=6.3982]Training epoch 10:  50%|█████     | 82/163 [01:32<01:24,  1.04s/it, loss=0.4207, batch_acc=0.8750, running_acc=0.9055, grad=6.3982]Training epoch 10:  50%|█████     | 82/163 [01:32<01:24,  1.04s/it, loss=0.2598, batch_acc=0.9375, running_acc=0.9059, grad=7.1600]Training epoch 10:  51%|█████     | 83/163 [01:33<01:19,  1.01it/s, loss=0.2598, batch_acc=0.9375, running_acc=0.9059, grad=7.1600]Training epoch 10:  51%|█████     | 83/163 [01:33<01:19,  1.01it/s, loss=0.1993, batch_acc=0.9688, running_acc=0.9066, grad=5.3105]Training epoch 10:  52%|█████▏    | 84/163 [01:34<01:30,  1.15s/it, loss=0.1993, batch_acc=0.9688, running_acc=0.9066, grad=5.3105]Training epoch 10:  52%|█████▏    | 84/163 [01:34<01:30,  1.15s/it, loss=0.3269, batch_acc=0.9375, running_acc=0.9070, grad=6.8213]Training epoch 10:  52%|█████▏    | 85/163 [01:35<01:23,  1.06s/it, loss=0.3269, batch_acc=0.9375, running_acc=0.9070, grad=6.8213]Training epoch 10:  52%|█████▏    | 85/163 [01:35<01:23,  1.06s/it, loss=0.3359, batch_acc=0.8750, running_acc=0.9066, grad=6.8728]Training epoch 10:  53%|█████▎    | 86/163 [01:36<01:17,  1.01s/it, loss=0.3359, batch_acc=0.8750, running_acc=0.9066, grad=6.8728]Training epoch 10:  53%|█████▎    | 86/163 [01:36<01:17,  1.01s/it, loss=0.2890, batch_acc=0.8750, running_acc=0.9062, grad=4.3366]Training epoch 10:  53%|█████▎    | 87/163 [01:37<01:13,  1.03it/s, loss=0.2890, batch_acc=0.8750, running_acc=0.9062, grad=4.3366]Training epoch 10:  53%|█████▎    | 87/163 [01:37<01:13,  1.03it/s, loss=0.2674, batch_acc=0.9688, running_acc=0.9070, grad=5.2300]Training epoch 10:  54%|█████▍    | 88/163 [01:39<01:34,  1.26s/it, loss=0.2674, batch_acc=0.9688, running_acc=0.9070, grad=5.2300]Training epoch 10:  54%|█████▍    | 88/163 [01:39<01:34,  1.26s/it, loss=0.3872, batch_acc=0.9375, running_acc=0.9073, grad=5.6179]Training epoch 10:  55%|█████▍    | 89/163 [01:40<01:24,  1.14s/it, loss=0.3872, batch_acc=0.9375, running_acc=0.9073, grad=5.6179]Training epoch 10:  55%|█████▍    | 89/163 [01:40<01:24,  1.14s/it, loss=0.1645, batch_acc=0.9688, running_acc=0.9080, grad=4.6885]Training epoch 10:  55%|█████▌    | 90/163 [01:41<01:17,  1.06s/it, loss=0.1645, batch_acc=0.9688, running_acc=0.9080, grad=4.6885]Training epoch 10:  55%|█████▌    | 90/163 [01:41<01:17,  1.06s/it, loss=0.2217, batch_acc=0.9062, running_acc=0.9080, grad=3.6234]Training epoch 10:  56%|█████▌    | 91/163 [01:42<01:12,  1.01s/it, loss=0.2217, batch_acc=0.9062, running_acc=0.9080, grad=3.6234]Training epoch 10:  56%|█████▌    | 91/163 [01:42<01:12,  1.01s/it, loss=0.3177, batch_acc=0.9062, running_acc=0.9080, grad=5.0194]Training epoch 10:  56%|█████▋    | 92/163 [01:43<01:25,  1.20s/it, loss=0.3177, batch_acc=0.9062, running_acc=0.9080, grad=5.0194]Training epoch 10:  56%|█████▋    | 92/163 [01:43<01:25,  1.20s/it, loss=0.3718, batch_acc=0.8750, running_acc=0.9076, grad=5.3070]Training epoch 10:  57%|█████▋    | 93/163 [01:44<01:17,  1.10s/it, loss=0.3718, batch_acc=0.8750, running_acc=0.9076, grad=5.3070]Training epoch 10:  57%|█████▋    | 93/163 [01:44<01:17,  1.10s/it, loss=0.3173, batch_acc=0.9062, running_acc=0.9076, grad=5.7617]Training epoch 10:  58%|█████▊    | 94/163 [01:45<01:11,  1.04s/it, loss=0.3173, batch_acc=0.9062, running_acc=0.9076, grad=5.7617]Training epoch 10:  58%|█████▊    | 94/163 [01:45<01:11,  1.04s/it, loss=0.4265, batch_acc=0.8750, running_acc=0.9072, grad=6.7472]Training epoch 10:  58%|█████▊    | 95/163 [01:46<01:07,  1.01it/s, loss=0.4265, batch_acc=0.8750, running_acc=0.9072, grad=6.7472]Training epoch 10:  58%|█████▊    | 95/163 [01:46<01:07,  1.01it/s, loss=0.2121, batch_acc=0.9688, running_acc=0.9079, grad=5.0065]Training epoch 10:  59%|█████▉    | 96/163 [01:47<01:15,  1.12s/it, loss=0.2121, batch_acc=0.9688, running_acc=0.9079, grad=5.0065]Training epoch 10:  59%|█████▉    | 96/163 [01:47<01:15,  1.12s/it, loss=0.3928, batch_acc=0.8750, running_acc=0.9076, grad=7.7314]Training epoch 10:  60%|█████▉    | 97/163 [01:48<01:09,  1.05s/it, loss=0.3928, batch_acc=0.8750, running_acc=0.9076, grad=7.7314]Training epoch 10:  60%|█████▉    | 97/163 [01:48<01:09,  1.05s/it, loss=0.2486, batch_acc=0.9688, running_acc=0.9082, grad=4.7235]Training epoch 10:  60%|██████    | 98/163 [01:49<01:04,  1.00it/s, loss=0.2486, batch_acc=0.9688, running_acc=0.9082, grad=4.7235]Training epoch 10:  60%|██████    | 98/163 [01:49<01:04,  1.00it/s, loss=0.3327, batch_acc=0.8438, running_acc=0.9075, grad=7.6104]Training epoch 10:  61%|██████    | 99/163 [01:50<01:01,  1.04it/s, loss=0.3327, batch_acc=0.8438, running_acc=0.9075, grad=7.6104]Training epoch 10:  61%|██████    | 99/163 [01:50<01:01,  1.04it/s, loss=0.2893, batch_acc=0.9062, running_acc=0.9075, grad=5.5112]Training epoch 10:  61%|██████▏   | 100/163 [01:52<01:15,  1.20s/it, loss=0.2893, batch_acc=0.9062, running_acc=0.9075, grad=5.5112]Training epoch 10:  61%|██████▏   | 100/163 [01:52<01:15,  1.20s/it, loss=0.2383, batch_acc=0.9688, running_acc=0.9081, grad=5.3721]Training epoch 10:  62%|██████▏   | 101/163 [01:53<01:08,  1.10s/it, loss=0.2383, batch_acc=0.9688, running_acc=0.9081, grad=5.3721]Training epoch 10:  62%|██████▏   | 101/163 [01:53<01:08,  1.10s/it, loss=0.2702, batch_acc=0.8750, running_acc=0.9078, grad=4.9263]Training epoch 10:  63%|██████▎   | 102/163 [01:54<01:03,  1.03s/it, loss=0.2702, batch_acc=0.8750, running_acc=0.9078, grad=4.9263]Training epoch 10:  63%|██████▎   | 102/163 [01:54<01:03,  1.03s/it, loss=0.4366, batch_acc=0.9062, running_acc=0.9078, grad=6.4934]Training epoch 10:  63%|██████▎   | 103/163 [01:54<00:59,  1.01it/s, loss=0.4366, batch_acc=0.9062, running_acc=0.9078, grad=6.4934]Training epoch 10:  63%|██████▎   | 103/163 [01:54<00:59,  1.01it/s, loss=0.2901, batch_acc=0.9062, running_acc=0.9078, grad=3.9762]Training epoch 10:  64%|██████▍   | 104/163 [01:56<01:15,  1.28s/it, loss=0.2901, batch_acc=0.9062, running_acc=0.9078, grad=3.9762]Training epoch 10:  64%|██████▍   | 104/163 [01:56<01:15,  1.28s/it, loss=0.3046, batch_acc=0.9062, running_acc=0.9078, grad=6.7644]Training epoch 10:  64%|██████▍   | 105/163 [01:57<01:07,  1.16s/it, loss=0.3046, batch_acc=0.9062, running_acc=0.9078, grad=6.7644]Training epoch 10:  64%|██████▍   | 105/163 [01:57<01:07,  1.16s/it, loss=0.2141, batch_acc=0.9375, running_acc=0.9080, grad=4.8032]Training epoch 10:  65%|██████▌   | 106/163 [01:58<01:01,  1.07s/it, loss=0.2141, batch_acc=0.9375, running_acc=0.9080, grad=4.8032]Training epoch 10:  65%|██████▌   | 106/163 [01:58<01:01,  1.07s/it, loss=0.3377, batch_acc=0.9375, running_acc=0.9083, grad=7.1576]Training epoch 10:  66%|██████▌   | 107/163 [01:59<00:56,  1.01s/it, loss=0.3377, batch_acc=0.9375, running_acc=0.9083, grad=7.1576]Training epoch 10:  66%|██████▌   | 107/163 [01:59<00:56,  1.01s/it, loss=0.1979, batch_acc=0.9688, running_acc=0.9089, grad=4.6388]Training epoch 10:  66%|██████▋   | 108/163 [02:00<01:01,  1.12s/it, loss=0.1979, batch_acc=0.9688, running_acc=0.9089, grad=4.6388]Training epoch 10:  66%|██████▋   | 108/163 [02:00<01:01,  1.12s/it, loss=0.5355, batch_acc=0.7812, running_acc=0.9077, grad=6.6189]Training epoch 10:  67%|██████▋   | 109/163 [02:01<00:56,  1.05s/it, loss=0.5355, batch_acc=0.7812, running_acc=0.9077, grad=6.6189]Training epoch 10:  67%|██████▋   | 109/163 [02:01<00:56,  1.05s/it, loss=0.4754, batch_acc=0.8125, running_acc=0.9068, grad=7.3142]Training epoch 10:  67%|██████▋   | 110/163 [02:02<00:52,  1.00it/s, loss=0.4754, batch_acc=0.8125, running_acc=0.9068, grad=7.3142]Training epoch 10:  67%|██████▋   | 110/163 [02:02<00:52,  1.00it/s, loss=0.2423, batch_acc=0.9375, running_acc=0.9071, grad=4.6626]Training epoch 10:  68%|██████▊   | 111/163 [02:03<00:50,  1.04it/s, loss=0.2423, batch_acc=0.9375, running_acc=0.9071, grad=4.6626]Training epoch 10:  68%|██████▊   | 111/163 [02:03<00:50,  1.04it/s, loss=0.2205, batch_acc=0.9688, running_acc=0.9077, grad=5.9168]Training epoch 10:  69%|██████▊   | 112/163 [02:05<00:59,  1.16s/it, loss=0.2205, batch_acc=0.9688, running_acc=0.9077, grad=5.9168]Training epoch 10:  69%|██████▊   | 112/163 [02:05<00:59,  1.16s/it, loss=0.1737, batch_acc=0.9688, running_acc=0.9082, grad=4.5978]Training epoch 10:  69%|██████▉   | 113/163 [02:05<00:53,  1.08s/it, loss=0.1737, batch_acc=0.9688, running_acc=0.9082, grad=4.5978]Training epoch 10:  69%|██████▉   | 113/163 [02:05<00:53,  1.08s/it, loss=0.1431, batch_acc=0.9688, running_acc=0.9087, grad=4.6332]Training epoch 10:  70%|██████▉   | 114/163 [02:06<00:49,  1.02s/it, loss=0.1431, batch_acc=0.9688, running_acc=0.9087, grad=4.6332]Training epoch 10:  70%|██████▉   | 114/163 [02:06<00:49,  1.02s/it, loss=0.1819, batch_acc=0.9688, running_acc=0.9093, grad=4.1434]Training epoch 10:  71%|███████   | 115/163 [02:07<00:46,  1.03it/s, loss=0.1819, batch_acc=0.9688, running_acc=0.9093, grad=4.1434]Training epoch 10:  71%|███████   | 115/163 [02:07<00:46,  1.03it/s, loss=0.2445, batch_acc=0.9375, running_acc=0.9095, grad=5.8668]Training epoch 10:  71%|███████   | 116/163 [02:09<00:50,  1.08s/it, loss=0.2445, batch_acc=0.9375, running_acc=0.9095, grad=5.8668]Training epoch 10:  71%|███████   | 116/163 [02:09<00:50,  1.08s/it, loss=0.2188, batch_acc=0.9375, running_acc=0.9098, grad=5.9793]Training epoch 10:  72%|███████▏  | 117/163 [02:09<00:46,  1.02s/it, loss=0.2188, batch_acc=0.9375, running_acc=0.9098, grad=5.9793]Training epoch 10:  72%|███████▏  | 117/163 [02:09<00:46,  1.02s/it, loss=0.3505, batch_acc=0.9375, running_acc=0.9100, grad=4.5970]Training epoch 10:  72%|███████▏  | 118/163 [02:10<00:44,  1.02it/s, loss=0.3505, batch_acc=0.9375, running_acc=0.9100, grad=4.5970]Training epoch 10:  72%|███████▏  | 118/163 [02:10<00:44,  1.02it/s, loss=0.2618, batch_acc=0.9375, running_acc=0.9102, grad=4.5132]Training epoch 10:  73%|███████▎  | 119/163 [02:11<00:41,  1.06it/s, loss=0.2618, batch_acc=0.9375, running_acc=0.9102, grad=4.5132]Training epoch 10:  73%|███████▎  | 119/163 [02:11<00:41,  1.06it/s, loss=0.2721, batch_acc=0.9375, running_acc=0.9105, grad=5.1415]Training epoch 10:  74%|███████▎  | 120/163 [02:13<00:54,  1.27s/it, loss=0.2721, batch_acc=0.9375, running_acc=0.9105, grad=5.1415]Training epoch 10:  74%|███████▎  | 120/163 [02:13<00:54,  1.27s/it, loss=0.3637, batch_acc=0.9062, running_acc=0.9104, grad=5.2115]Training epoch 10:  74%|███████▍  | 121/163 [02:14<00:48,  1.15s/it, loss=0.3637, batch_acc=0.9062, running_acc=0.9104, grad=5.2115]Training epoch 10:  74%|███████▍  | 121/163 [02:14<00:48,  1.15s/it, loss=0.1665, batch_acc=1.0000, running_acc=0.9112, grad=4.5265]Training epoch 10:  75%|███████▍  | 122/163 [02:15<00:43,  1.07s/it, loss=0.1665, batch_acc=1.0000, running_acc=0.9112, grad=4.5265]Training epoch 10:  75%|███████▍  | 122/163 [02:15<00:43,  1.07s/it, loss=0.1214, batch_acc=0.9688, running_acc=0.9116, grad=2.8271]Training epoch 10:  75%|███████▌  | 123/163 [02:16<00:40,  1.01s/it, loss=0.1214, batch_acc=0.9688, running_acc=0.9116, grad=2.8271]Training epoch 10:  75%|███████▌  | 123/163 [02:16<00:40,  1.01s/it, loss=0.2738, batch_acc=0.9062, running_acc=0.9116, grad=5.5743]Training epoch 10:  76%|███████▌  | 124/163 [02:18<00:49,  1.27s/it, loss=0.2738, batch_acc=0.9062, running_acc=0.9116, grad=5.5743]Training epoch 10:  76%|███████▌  | 124/163 [02:18<00:49,  1.27s/it, loss=0.3074, batch_acc=0.9375, running_acc=0.9118, grad=4.5965]Training epoch 10:  77%|███████▋  | 125/163 [02:19<00:43,  1.16s/it, loss=0.3074, batch_acc=0.9375, running_acc=0.9118, grad=4.5965]Training epoch 10:  77%|███████▋  | 125/163 [02:19<00:43,  1.16s/it, loss=0.2892, batch_acc=0.9375, running_acc=0.9120, grad=4.6541]Training epoch 10:  77%|███████▋  | 126/163 [02:20<00:39,  1.07s/it, loss=0.2892, batch_acc=0.9375, running_acc=0.9120, grad=4.6541]Training epoch 10:  77%|███████▋  | 126/163 [02:20<00:39,  1.07s/it, loss=0.4587, batch_acc=0.8125, running_acc=0.9112, grad=10.0296]Training epoch 10:  78%|███████▊  | 127/163 [02:20<00:36,  1.01s/it, loss=0.4587, batch_acc=0.8125, running_acc=0.9112, grad=10.0296]Training epoch 10:  78%|███████▊  | 127/163 [02:20<00:36,  1.01s/it, loss=0.4033, batch_acc=0.9375, running_acc=0.9114, grad=7.0979] Training epoch 10:  79%|███████▊  | 128/163 [02:22<00:45,  1.30s/it, loss=0.4033, batch_acc=0.9375, running_acc=0.9114, grad=7.0979]Training epoch 10:  79%|███████▊  | 128/163 [02:22<00:45,  1.30s/it, loss=0.2718, batch_acc=0.9375, running_acc=0.9116, grad=5.1844]Training epoch 10:  79%|███████▉  | 129/163 [02:23<00:39,  1.17s/it, loss=0.2718, batch_acc=0.9375, running_acc=0.9116, grad=5.1844]Training epoch 10:  79%|███████▉  | 129/163 [02:23<00:39,  1.17s/it, loss=0.5369, batch_acc=0.8750, running_acc=0.9113, grad=6.2699]Training epoch 10:  80%|███████▉  | 130/163 [02:24<00:35,  1.09s/it, loss=0.5369, batch_acc=0.8750, running_acc=0.9113, grad=6.2699]Training epoch 10:  80%|███████▉  | 130/163 [02:24<00:35,  1.09s/it, loss=0.3240, batch_acc=0.8750, running_acc=0.9111, grad=4.9755]Training epoch 10:  80%|████████  | 131/163 [02:25<00:32,  1.02s/it, loss=0.3240, batch_acc=0.8750, running_acc=0.9111, grad=4.9755]Training epoch 10:  80%|████████  | 131/163 [02:25<00:32,  1.02s/it, loss=0.3094, batch_acc=0.9375, running_acc=0.9113, grad=4.8534]Training epoch 10:  81%|████████  | 132/163 [02:27<00:39,  1.27s/it, loss=0.3094, batch_acc=0.9375, running_acc=0.9113, grad=4.8534]Training epoch 10:  81%|████████  | 132/163 [02:27<00:39,  1.27s/it, loss=0.2487, batch_acc=0.9062, running_acc=0.9112, grad=5.7742]Training epoch 10:  82%|████████▏ | 133/163 [02:28<00:34,  1.15s/it, loss=0.2487, batch_acc=0.9062, running_acc=0.9112, grad=5.7742]Training epoch 10:  82%|████████▏ | 133/163 [02:28<00:34,  1.15s/it, loss=0.4090, batch_acc=0.8750, running_acc=0.9109, grad=7.6321]Training epoch 10:  82%|████████▏ | 134/163 [02:29<00:31,  1.07s/it, loss=0.4090, batch_acc=0.8750, running_acc=0.9109, grad=7.6321]Training epoch 10:  82%|████████▏ | 134/163 [02:29<00:31,  1.07s/it, loss=0.3278, batch_acc=0.8438, running_acc=0.9104, grad=9.7747]Training epoch 10:  83%|████████▎ | 135/163 [02:29<00:28,  1.01s/it, loss=0.3278, batch_acc=0.8438, running_acc=0.9104, grad=9.7747]Training epoch 10:  83%|████████▎ | 135/163 [02:29<00:28,  1.01s/it, loss=0.2664, batch_acc=0.9375, running_acc=0.9106, grad=4.1056]Training epoch 10:  83%|████████▎ | 136/163 [02:31<00:31,  1.17s/it, loss=0.2664, batch_acc=0.9375, running_acc=0.9106, grad=4.1056]Training epoch 10:  83%|████████▎ | 136/163 [02:31<00:31,  1.17s/it, loss=0.4579, batch_acc=0.8125, running_acc=0.9099, grad=6.0469]Training epoch 10:  84%|████████▍ | 137/163 [02:32<00:28,  1.08s/it, loss=0.4579, batch_acc=0.8125, running_acc=0.9099, grad=6.0469]Training epoch 10:  84%|████████▍ | 137/163 [02:32<00:28,  1.08s/it, loss=0.5078, batch_acc=0.8438, running_acc=0.9094, grad=9.9659]Training epoch 10:  85%|████████▍ | 138/163 [02:33<00:25,  1.02s/it, loss=0.5078, batch_acc=0.8438, running_acc=0.9094, grad=9.9659]Training epoch 10:  85%|████████▍ | 138/163 [02:33<00:25,  1.02s/it, loss=0.2949, batch_acc=0.9375, running_acc=0.9096, grad=7.1880]Training epoch 10:  85%|████████▌ | 139/163 [02:34<00:23,  1.02it/s, loss=0.2949, batch_acc=0.9375, running_acc=0.9096, grad=7.1880]Training epoch 10:  85%|████████▌ | 139/163 [02:34<00:23,  1.02it/s, loss=0.5777, batch_acc=0.8125, running_acc=0.9089, grad=9.9118]Training epoch 10:  86%|████████▌ | 140/163 [02:36<00:32,  1.40s/it, loss=0.5777, batch_acc=0.8125, running_acc=0.9089, grad=9.9118]Training epoch 10:  86%|████████▌ | 140/163 [02:36<00:32,  1.40s/it, loss=0.3790, batch_acc=0.9062, running_acc=0.9089, grad=5.4535]Training epoch 10:  87%|████████▋ | 141/163 [02:37<00:27,  1.24s/it, loss=0.3790, batch_acc=0.9062, running_acc=0.9089, grad=5.4535]Training epoch 10:  87%|████████▋ | 141/163 [02:37<00:27,  1.24s/it, loss=0.2834, batch_acc=0.9062, running_acc=0.9089, grad=5.7515]Training epoch 10:  87%|████████▋ | 142/163 [02:38<00:23,  1.13s/it, loss=0.2834, batch_acc=0.9062, running_acc=0.9089, grad=5.7515]Training epoch 10:  87%|████████▋ | 142/163 [02:38<00:23,  1.13s/it, loss=0.2637, batch_acc=0.9062, running_acc=0.9089, grad=4.9294]Training epoch 10:  88%|████████▊ | 143/163 [02:39<00:21,  1.06s/it, loss=0.2637, batch_acc=0.9062, running_acc=0.9089, grad=4.9294]Training epoch 10:  88%|████████▊ | 143/163 [02:39<00:21,  1.06s/it, loss=0.2818, batch_acc=0.9688, running_acc=0.9093, grad=7.0582]Training epoch 10:  88%|████████▊ | 144/163 [02:41<00:25,  1.34s/it, loss=0.2818, batch_acc=0.9688, running_acc=0.9093, grad=7.0582]Training epoch 10:  88%|████████▊ | 144/163 [02:41<00:25,  1.34s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9099, grad=3.2669]Training epoch 10:  89%|████████▉ | 145/163 [02:42<00:21,  1.20s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9099, grad=3.2669]Training epoch 10:  89%|████████▉ | 145/163 [02:42<00:21,  1.20s/it, loss=0.2190, batch_acc=0.9688, running_acc=0.9103, grad=3.9850]Training epoch 10:  90%|████████▉ | 146/163 [02:42<00:18,  1.10s/it, loss=0.2190, batch_acc=0.9688, running_acc=0.9103, grad=3.9850]Training epoch 10:  90%|████████▉ | 146/163 [02:42<00:18,  1.10s/it, loss=0.4013, batch_acc=0.8125, running_acc=0.9097, grad=7.7184]Training epoch 10:  90%|█████████ | 147/163 [02:43<00:16,  1.03s/it, loss=0.4013, batch_acc=0.8125, running_acc=0.9097, grad=7.7184]Training epoch 10:  90%|█████████ | 147/163 [02:43<00:16,  1.03s/it, loss=0.1344, batch_acc=1.0000, running_acc=0.9103, grad=3.3297]Training epoch 10:  91%|█████████ | 148/163 [02:45<00:19,  1.29s/it, loss=0.1344, batch_acc=1.0000, running_acc=0.9103, grad=3.3297]Training epoch 10:  91%|█████████ | 148/163 [02:45<00:19,  1.29s/it, loss=0.2971, batch_acc=0.9062, running_acc=0.9103, grad=5.7280]Training epoch 10:  91%|█████████▏| 149/163 [02:46<00:16,  1.17s/it, loss=0.2971, batch_acc=0.9062, running_acc=0.9103, grad=5.7280]Training epoch 10:  91%|█████████▏| 149/163 [02:46<00:16,  1.17s/it, loss=0.3133, batch_acc=0.9062, running_acc=0.9102, grad=6.7385]Training epoch 10:  92%|█████████▏| 150/163 [02:47<00:14,  1.08s/it, loss=0.3133, batch_acc=0.9062, running_acc=0.9102, grad=6.7385]Training epoch 10:  92%|█████████▏| 150/163 [02:47<00:14,  1.08s/it, loss=0.4993, batch_acc=0.8750, running_acc=0.9100, grad=6.6865]Training epoch 10:  93%|█████████▎| 151/163 [02:48<00:12,  1.02s/it, loss=0.4993, batch_acc=0.8750, running_acc=0.9100, grad=6.6865]Training epoch 10:  93%|█████████▎| 151/163 [02:48<00:12,  1.02s/it, loss=0.2131, batch_acc=0.9375, running_acc=0.9102, grad=3.8606]Training epoch 10:  93%|█████████▎| 152/163 [02:49<00:12,  1.13s/it, loss=0.2131, batch_acc=0.9375, running_acc=0.9102, grad=3.8606]Training epoch 10:  93%|█████████▎| 152/163 [02:49<00:12,  1.13s/it, loss=0.1838, batch_acc=0.9375, running_acc=0.9104, grad=3.5032]Training epoch 10:  94%|█████████▍| 153/163 [02:50<00:10,  1.05s/it, loss=0.1838, batch_acc=0.9375, running_acc=0.9104, grad=3.5032]Training epoch 10:  94%|█████████▍| 153/163 [02:50<00:10,  1.05s/it, loss=0.3206, batch_acc=0.9062, running_acc=0.9103, grad=5.0751]Training epoch 10:  94%|█████████▍| 154/163 [02:51<00:09,  1.00s/it, loss=0.3206, batch_acc=0.9062, running_acc=0.9103, grad=5.0751]Training epoch 10:  94%|█████████▍| 154/163 [02:51<00:09,  1.00s/it, loss=0.3033, batch_acc=0.8750, running_acc=0.9101, grad=5.1560]Training epoch 10:  95%|█████████▌| 155/163 [02:52<00:07,  1.04it/s, loss=0.3033, batch_acc=0.8750, running_acc=0.9101, grad=5.1560]Training epoch 10:  95%|█████████▌| 155/163 [02:52<00:07,  1.04it/s, loss=0.2847, batch_acc=0.9062, running_acc=0.9101, grad=7.1657]Training epoch 10:  96%|█████████▌| 156/163 [02:54<00:09,  1.35s/it, loss=0.2847, batch_acc=0.9062, running_acc=0.9101, grad=7.1657]Training epoch 10:  96%|█████████▌| 156/163 [02:54<00:09,  1.35s/it, loss=0.5673, batch_acc=0.9062, running_acc=0.9101, grad=7.3119]Training epoch 10:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=0.5673, batch_acc=0.9062, running_acc=0.9101, grad=7.3119]Training epoch 10:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=0.3604, batch_acc=0.8438, running_acc=0.9096, grad=5.8493]Training epoch 10:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=0.3604, batch_acc=0.8438, running_acc=0.9096, grad=5.8493]Training epoch 10:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=0.3083, batch_acc=0.8750, running_acc=0.9094, grad=6.4409]Training epoch 10:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=0.3083, batch_acc=0.8750, running_acc=0.9094, grad=6.4409]Training epoch 10:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=0.2716, batch_acc=0.9062, running_acc=0.9094, grad=4.9800]Training epoch 10:  98%|█████████▊| 160/163 [02:58<00:03,  1.23s/it, loss=0.2716, batch_acc=0.9062, running_acc=0.9094, grad=4.9800]Training epoch 10:  98%|█████████▊| 160/163 [02:58<00:03,  1.23s/it, loss=0.2770, batch_acc=0.9062, running_acc=0.9094, grad=4.6895]Training epoch 10:  99%|█████████▉| 161/163 [02:59<00:02,  1.12s/it, loss=0.2770, batch_acc=0.9062, running_acc=0.9094, grad=4.6895]Training epoch 10:  99%|█████████▉| 161/163 [02:59<00:02,  1.12s/it, loss=0.2115, batch_acc=0.9688, running_acc=0.9097, grad=5.0041]Training epoch 10:  99%|█████████▉| 162/163 [03:00<00:01,  1.05s/it, loss=0.2115, batch_acc=0.9688, running_acc=0.9097, grad=5.0041]Training epoch 10:  99%|█████████▉| 162/163 [03:00<00:01,  1.05s/it, loss=0.5610, batch_acc=0.7812, running_acc=0.9090, grad=9.7734]Training epoch 10: 100%|██████████| 163/163 [03:01<00:00,  1.08it/s, loss=0.5610, batch_acc=0.7812, running_acc=0.9090, grad=9.7734]Training epoch 10: 100%|██████████| 163/163 [03:01<00:00,  1.08it/s, loss=0.2511, batch_acc=0.9524, running_acc=0.9091, grad=5.4843]Training epoch 10: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=0.2511, batch_acc=0.9524, running_acc=0.9091, grad=5.4843]
Evaluation epoch 10:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 10:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it]Evaluation epoch 10:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it, loss=0.4916, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 10:   7%|▋         | 2/28 [00:05<00:58,  2.23s/it, loss=0.4916, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 10:   7%|▋         | 2/28 [00:05<00:58,  2.23s/it, loss=0.3674, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 10:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.3674, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 10:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=1.2866, batch_acc=0.5938, running_acc=0.8021]Evaluation epoch 10:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=1.2866, batch_acc=0.5938, running_acc=0.8021]Evaluation epoch 10:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.8301, batch_acc=0.7188, running_acc=0.7812]Evaluation epoch 10:  18%|█▊        | 5/28 [00:10<00:38,  1.67s/it, loss=0.8301, batch_acc=0.7188, running_acc=0.7812]Evaluation epoch 10:  18%|█▊        | 5/28 [00:10<00:38,  1.67s/it, loss=1.7677, batch_acc=0.5625, running_acc=0.7375]Evaluation epoch 10:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=1.7677, batch_acc=0.5625, running_acc=0.7375]Evaluation epoch 10:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=0.7852, batch_acc=0.7812, running_acc=0.7448]Evaluation epoch 10:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.7852, batch_acc=0.7812, running_acc=0.7448]Evaluation epoch 10:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=1.1322, batch_acc=0.7500, running_acc=0.7455]Evaluation epoch 10:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=1.1322, batch_acc=0.7500, running_acc=0.7455]Evaluation epoch 10:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.9596, batch_acc=0.6875, running_acc=0.7383]Evaluation epoch 10:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.9596, batch_acc=0.6875, running_acc=0.7383]Evaluation epoch 10:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.8934, batch_acc=0.7188, running_acc=0.7361]Evaluation epoch 10:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.8934, batch_acc=0.7188, running_acc=0.7361]Evaluation epoch 10:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.5674, batch_acc=0.8750, running_acc=0.7500]Evaluation epoch 10:  39%|███▉      | 11/28 [00:14<00:12,  1.33it/s, loss=0.5674, batch_acc=0.8750, running_acc=0.7500]Evaluation epoch 10:  39%|███▉      | 11/28 [00:14<00:12,  1.33it/s, loss=0.6387, batch_acc=0.8438, running_acc=0.7585]Evaluation epoch 10:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=0.6387, batch_acc=0.8438, running_acc=0.7585]Evaluation epoch 10:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=1.2626, batch_acc=0.6562, running_acc=0.7500]Evaluation epoch 10:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=1.2626, batch_acc=0.6562, running_acc=0.7500]Evaluation epoch 10:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=0.5170, batch_acc=0.8750, running_acc=0.7596]Evaluation epoch 10:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=0.5170, batch_acc=0.8750, running_acc=0.7596]Evaluation epoch 10:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=1.2829, batch_acc=0.7188, running_acc=0.7567]Evaluation epoch 10:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.2829, batch_acc=0.7188, running_acc=0.7567]Evaluation epoch 10:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.3654, batch_acc=0.5312, running_acc=0.7417]Evaluation epoch 10:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=1.3654, batch_acc=0.5312, running_acc=0.7417]Evaluation epoch 10:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=0.5145, batch_acc=0.8438, running_acc=0.7480]Evaluation epoch 10:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.5145, batch_acc=0.8438, running_acc=0.7480]Evaluation epoch 10:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.4559, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 10:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.4559, batch_acc=0.7812, running_acc=0.7500]Evaluation epoch 10:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.8438, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 10:  68%|██████▊   | 19/28 [00:24<00:06,  1.44it/s, loss=0.8438, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 10:  68%|██████▊   | 19/28 [00:24<00:06,  1.44it/s, loss=1.2998, batch_acc=0.5625, running_acc=0.7401]Evaluation epoch 10:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=1.2998, batch_acc=0.5625, running_acc=0.7401]Evaluation epoch 10:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=0.4335, batch_acc=0.7500, running_acc=0.7406]Evaluation epoch 10:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.4335, batch_acc=0.7500, running_acc=0.7406]Evaluation epoch 10:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=1.0250, batch_acc=0.7812, running_acc=0.7426]Evaluation epoch 10:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=1.0250, batch_acc=0.7812, running_acc=0.7426]Evaluation epoch 10:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.8336, batch_acc=0.7812, running_acc=0.7443]Evaluation epoch 10:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=0.8336, batch_acc=0.7812, running_acc=0.7443]Evaluation epoch 10:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.1926, batch_acc=0.6875, running_acc=0.7418]Evaluation epoch 10:  86%|████████▌ | 24/28 [00:34<00:08,  2.13s/it, loss=1.1926, batch_acc=0.6875, running_acc=0.7418]Evaluation epoch 10:  86%|████████▌ | 24/28 [00:34<00:08,  2.13s/it, loss=0.1596, batch_acc=0.9688, running_acc=0.7513]Evaluation epoch 10:  89%|████████▉ | 25/28 [00:34<00:04,  1.57s/it, loss=0.1596, batch_acc=0.9688, running_acc=0.7513]Evaluation epoch 10:  89%|████████▉ | 25/28 [00:34<00:04,  1.57s/it, loss=0.1440, batch_acc=0.9688, running_acc=0.7600]Evaluation epoch 10:  93%|█████████▎| 26/28 [00:34<00:02,  1.18s/it, loss=0.1440, batch_acc=0.9688, running_acc=0.7600]Evaluation epoch 10:  93%|█████████▎| 26/28 [00:34<00:02,  1.18s/it, loss=1.0824, batch_acc=0.6562, running_acc=0.7560]Evaluation epoch 10:  96%|█████████▋| 27/28 [00:34<00:00,  1.11it/s, loss=1.0824, batch_acc=0.6562, running_acc=0.7560]Evaluation epoch 10:  96%|█████████▋| 27/28 [00:34<00:00,  1.11it/s, loss=0.9415, batch_acc=0.6250, running_acc=0.7512]Evaluation epoch 10: 100%|██████████| 28/28 [00:35<00:00,  1.11it/s, loss=0.8522, batch_acc=0.6667, running_acc=0.7509]Evaluation epoch 10: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=0.8522, batch_acc=0.6667, running_acc=0.7509]
Training epoch 11:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 11:   1%|          | 1/163 [00:05<15:00,  5.56s/it]Training epoch 11:   1%|          | 1/163 [00:05<15:00,  5.56s/it, loss=0.2172, batch_acc=0.9062, running_acc=0.9062, grad=7.4885]Training epoch 11:   1%|          | 2/163 [00:06<07:32,  2.81s/it, loss=0.2172, batch_acc=0.9062, running_acc=0.9062, grad=7.4885]Training epoch 11:   1%|          | 2/163 [00:06<07:32,  2.81s/it, loss=0.3626, batch_acc=0.7812, running_acc=0.8438, grad=5.5952]Training epoch 11:   2%|▏         | 3/163 [00:07<05:08,  1.93s/it, loss=0.3626, batch_acc=0.7812, running_acc=0.8438, grad=5.5952]Training epoch 11:   2%|▏         | 3/163 [00:07<05:08,  1.93s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.8958, grad=2.4871]Training epoch 11:   2%|▏         | 4/163 [00:09<05:50,  2.20s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.8958, grad=2.4871]Training epoch 11:   2%|▏         | 4/163 [00:09<05:50,  2.20s/it, loss=0.3404, batch_acc=0.8438, running_acc=0.8828, grad=5.5694]Training epoch 11:   3%|▎         | 5/163 [00:10<04:32,  1.72s/it, loss=0.3404, batch_acc=0.8438, running_acc=0.8828, grad=5.5694]Training epoch 11:   3%|▎         | 5/163 [00:10<04:32,  1.72s/it, loss=0.1942, batch_acc=1.0000, running_acc=0.9062, grad=4.4435]Training epoch 11:   4%|▎         | 6/163 [00:11<03:45,  1.44s/it, loss=0.1942, batch_acc=1.0000, running_acc=0.9062, grad=4.4435]Training epoch 11:   4%|▎         | 6/163 [00:11<03:45,  1.44s/it, loss=0.2544, batch_acc=0.9062, running_acc=0.9062, grad=5.0048]Training epoch 11:   4%|▍         | 7/163 [00:12<03:15,  1.25s/it, loss=0.2544, batch_acc=0.9062, running_acc=0.9062, grad=5.0048]Training epoch 11:   4%|▍         | 7/163 [00:12<03:15,  1.25s/it, loss=0.3057, batch_acc=0.9062, running_acc=0.9062, grad=5.6007]Training epoch 11:   5%|▍         | 8/163 [00:14<03:44,  1.45s/it, loss=0.3057, batch_acc=0.9062, running_acc=0.9062, grad=5.6007]Training epoch 11:   5%|▍         | 8/163 [00:14<03:44,  1.45s/it, loss=0.2570, batch_acc=0.9688, running_acc=0.9141, grad=5.0658]Training epoch 11:   6%|▌         | 9/163 [00:15<03:15,  1.27s/it, loss=0.2570, batch_acc=0.9688, running_acc=0.9141, grad=5.0658]Training epoch 11:   6%|▌         | 9/163 [00:15<03:15,  1.27s/it, loss=0.1777, batch_acc=0.9688, running_acc=0.9201, grad=4.8288]Training epoch 11:   6%|▌         | 10/163 [00:16<02:55,  1.15s/it, loss=0.1777, batch_acc=0.9688, running_acc=0.9201, grad=4.8288]Training epoch 11:   6%|▌         | 10/163 [00:16<02:55,  1.15s/it, loss=0.3114, batch_acc=0.8125, running_acc=0.9094, grad=5.9062]Training epoch 11:   7%|▋         | 11/163 [00:17<02:41,  1.07s/it, loss=0.3114, batch_acc=0.8125, running_acc=0.9094, grad=5.9062]Training epoch 11:   7%|▋         | 11/163 [00:17<02:41,  1.07s/it, loss=0.2656, batch_acc=1.0000, running_acc=0.9176, grad=4.6110]Training epoch 11:   7%|▋         | 12/163 [00:18<02:57,  1.18s/it, loss=0.2656, batch_acc=1.0000, running_acc=0.9176, grad=4.6110]Training epoch 11:   7%|▋         | 12/163 [00:18<02:57,  1.18s/it, loss=0.2151, batch_acc=0.9688, running_acc=0.9219, grad=4.5772]Training epoch 11:   8%|▊         | 13/163 [00:19<02:42,  1.09s/it, loss=0.2151, batch_acc=0.9688, running_acc=0.9219, grad=4.5772]Training epoch 11:   8%|▊         | 13/163 [00:19<02:42,  1.09s/it, loss=0.1892, batch_acc=0.9688, running_acc=0.9255, grad=2.8893]Training epoch 11:   9%|▊         | 14/163 [00:20<02:37,  1.05s/it, loss=0.1892, batch_acc=0.9688, running_acc=0.9255, grad=2.8893]Training epoch 11:   9%|▊         | 14/163 [00:20<02:37,  1.05s/it, loss=0.1535, batch_acc=0.9375, running_acc=0.9263, grad=4.3011]Training epoch 11:   9%|▉         | 15/163 [00:21<02:28,  1.00s/it, loss=0.1535, batch_acc=0.9375, running_acc=0.9263, grad=4.3011]Training epoch 11:   9%|▉         | 15/163 [00:21<02:28,  1.00s/it, loss=0.1275, batch_acc=1.0000, running_acc=0.9313, grad=2.7066]Training epoch 11:  10%|▉         | 16/163 [00:22<02:58,  1.21s/it, loss=0.1275, batch_acc=1.0000, running_acc=0.9313, grad=2.7066]Training epoch 11:  10%|▉         | 16/163 [00:22<02:58,  1.21s/it, loss=0.2657, batch_acc=0.9062, running_acc=0.9297, grad=6.8964]Training epoch 11:  10%|█         | 17/163 [00:23<02:42,  1.11s/it, loss=0.2657, batch_acc=0.9062, running_acc=0.9297, grad=6.8964]Training epoch 11:  10%|█         | 17/163 [00:23<02:42,  1.11s/it, loss=0.1514, batch_acc=0.9375, running_acc=0.9301, grad=3.6184]Training epoch 11:  11%|█         | 18/163 [00:24<02:30,  1.04s/it, loss=0.1514, batch_acc=0.9375, running_acc=0.9301, grad=3.6184]Training epoch 11:  11%|█         | 18/163 [00:24<02:30,  1.04s/it, loss=0.2712, batch_acc=0.9062, running_acc=0.9288, grad=5.2706]Training epoch 11:  12%|█▏        | 19/163 [00:25<02:22,  1.01it/s, loss=0.2712, batch_acc=0.9062, running_acc=0.9288, grad=5.2706]Training epoch 11:  12%|█▏        | 19/163 [00:25<02:22,  1.01it/s, loss=0.2700, batch_acc=0.9375, running_acc=0.9293, grad=5.3717]Training epoch 11:  12%|█▏        | 20/163 [00:26<02:40,  1.12s/it, loss=0.2700, batch_acc=0.9375, running_acc=0.9293, grad=5.3717]Training epoch 11:  12%|█▏        | 20/163 [00:26<02:40,  1.12s/it, loss=0.1744, batch_acc=0.9375, running_acc=0.9297, grad=3.8531]Training epoch 11:  13%|█▎        | 21/163 [00:27<02:28,  1.05s/it, loss=0.1744, batch_acc=0.9375, running_acc=0.9297, grad=3.8531]Training epoch 11:  13%|█▎        | 21/163 [00:27<02:28,  1.05s/it, loss=0.1793, batch_acc=0.9375, running_acc=0.9301, grad=3.3969]Training epoch 11:  13%|█▎        | 22/163 [00:28<02:20,  1.00it/s, loss=0.1793, batch_acc=0.9375, running_acc=0.9301, grad=3.3969]Training epoch 11:  13%|█▎        | 22/163 [00:28<02:20,  1.00it/s, loss=0.4760, batch_acc=0.8750, running_acc=0.9276, grad=10.6306]Training epoch 11:  14%|█▍        | 23/163 [00:29<02:14,  1.04it/s, loss=0.4760, batch_acc=0.8750, running_acc=0.9276, grad=10.6306]Training epoch 11:  14%|█▍        | 23/163 [00:29<02:14,  1.04it/s, loss=0.2860, batch_acc=0.8750, running_acc=0.9253, grad=7.5312] Training epoch 11:  15%|█▍        | 24/163 [00:31<02:54,  1.26s/it, loss=0.2860, batch_acc=0.8750, running_acc=0.9253, grad=7.5312]Training epoch 11:  15%|█▍        | 24/163 [00:31<02:54,  1.26s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9284, grad=2.7462]Training epoch 11:  15%|█▌        | 25/163 [00:32<02:37,  1.14s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9284, grad=2.7462]Training epoch 11:  15%|█▌        | 25/163 [00:32<02:37,  1.14s/it, loss=0.1872, batch_acc=0.9688, running_acc=0.9300, grad=4.4779]Training epoch 11:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.1872, batch_acc=0.9688, running_acc=0.9300, grad=4.4779]Training epoch 11:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.1982, batch_acc=0.9375, running_acc=0.9303, grad=4.6293]Training epoch 11:  17%|█▋        | 27/163 [00:34<02:17,  1.01s/it, loss=0.1982, batch_acc=0.9375, running_acc=0.9303, grad=4.6293]Training epoch 11:  17%|█▋        | 27/163 [00:34<02:17,  1.01s/it, loss=0.2024, batch_acc=0.9375, running_acc=0.9306, grad=4.9156]Training epoch 11:  17%|█▋        | 28/163 [00:35<02:41,  1.20s/it, loss=0.2024, batch_acc=0.9375, running_acc=0.9306, grad=4.9156]Training epoch 11:  17%|█▋        | 28/163 [00:35<02:41,  1.20s/it, loss=0.2546, batch_acc=0.9688, running_acc=0.9319, grad=5.4248]Training epoch 11:  18%|█▊        | 29/163 [00:36<02:27,  1.10s/it, loss=0.2546, batch_acc=0.9688, running_acc=0.9319, grad=5.4248]Training epoch 11:  18%|█▊        | 29/163 [00:36<02:27,  1.10s/it, loss=0.1985, batch_acc=0.9688, running_acc=0.9332, grad=4.1627]Training epoch 11:  18%|█▊        | 30/163 [00:37<02:17,  1.03s/it, loss=0.1985, batch_acc=0.9688, running_acc=0.9332, grad=4.1627]Training epoch 11:  18%|█▊        | 30/163 [00:37<02:17,  1.03s/it, loss=0.1114, batch_acc=1.0000, running_acc=0.9354, grad=2.2863]Training epoch 11:  19%|█▉        | 31/163 [00:38<02:10,  1.01it/s, loss=0.1114, batch_acc=1.0000, running_acc=0.9354, grad=2.2863]Training epoch 11:  19%|█▉        | 31/163 [00:38<02:10,  1.01it/s, loss=0.1574, batch_acc=0.9062, running_acc=0.9345, grad=7.1432]Training epoch 11:  20%|█▉        | 32/163 [00:39<02:17,  1.05s/it, loss=0.1574, batch_acc=0.9062, running_acc=0.9345, grad=7.1432]Training epoch 11:  20%|█▉        | 32/163 [00:39<02:17,  1.05s/it, loss=0.3023, batch_acc=0.9062, running_acc=0.9336, grad=6.4523]Training epoch 11:  20%|██        | 33/163 [00:40<02:09,  1.00it/s, loss=0.3023, batch_acc=0.9062, running_acc=0.9336, grad=6.4523]Training epoch 11:  20%|██        | 33/163 [00:40<02:09,  1.00it/s, loss=0.2088, batch_acc=0.9375, running_acc=0.9337, grad=3.3372]Training epoch 11:  21%|██        | 34/163 [00:41<02:04,  1.04it/s, loss=0.2088, batch_acc=0.9375, running_acc=0.9337, grad=3.3372]Training epoch 11:  21%|██        | 34/163 [00:41<02:04,  1.04it/s, loss=0.1595, batch_acc=0.9688, running_acc=0.9347, grad=3.7251]Training epoch 11:  21%|██▏       | 35/163 [00:42<02:00,  1.07it/s, loss=0.1595, batch_acc=0.9688, running_acc=0.9347, grad=3.7251]Training epoch 11:  21%|██▏       | 35/163 [00:42<02:00,  1.07it/s, loss=0.3006, batch_acc=0.9375, running_acc=0.9348, grad=6.0153]Training epoch 11:  22%|██▏       | 36/163 [00:44<02:43,  1.29s/it, loss=0.3006, batch_acc=0.9375, running_acc=0.9348, grad=6.0153]Training epoch 11:  22%|██▏       | 36/163 [00:44<02:43,  1.29s/it, loss=0.3884, batch_acc=0.8750, running_acc=0.9332, grad=6.4856]Training epoch 11:  23%|██▎       | 37/163 [00:45<02:26,  1.16s/it, loss=0.3884, batch_acc=0.8750, running_acc=0.9332, grad=6.4856]Training epoch 11:  23%|██▎       | 37/163 [00:45<02:26,  1.16s/it, loss=0.1846, batch_acc=0.9375, running_acc=0.9333, grad=4.9660]Training epoch 11:  23%|██▎       | 38/163 [00:46<02:14,  1.08s/it, loss=0.1846, batch_acc=0.9375, running_acc=0.9333, grad=4.9660]Training epoch 11:  23%|██▎       | 38/163 [00:46<02:14,  1.08s/it, loss=0.1795, batch_acc=0.9062, running_acc=0.9326, grad=4.7690]Training epoch 11:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=0.1795, batch_acc=0.9062, running_acc=0.9326, grad=4.7690]Training epoch 11:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=0.4218, batch_acc=0.8750, running_acc=0.9311, grad=6.2511]Training epoch 11:  25%|██▍       | 40/163 [00:48<02:15,  1.10s/it, loss=0.4218, batch_acc=0.8750, running_acc=0.9311, grad=6.2511]Training epoch 11:  25%|██▍       | 40/163 [00:48<02:15,  1.10s/it, loss=0.2600, batch_acc=0.9375, running_acc=0.9313, grad=3.6967]Training epoch 11:  25%|██▌       | 41/163 [00:49<02:06,  1.03s/it, loss=0.2600, batch_acc=0.9375, running_acc=0.9313, grad=3.6967]Training epoch 11:  25%|██▌       | 41/163 [00:49<02:06,  1.03s/it, loss=0.1964, batch_acc=0.9375, running_acc=0.9314, grad=4.9996]Training epoch 11:  26%|██▌       | 42/163 [00:50<01:59,  1.01it/s, loss=0.1964, batch_acc=0.9375, running_acc=0.9314, grad=4.9996]Training epoch 11:  26%|██▌       | 42/163 [00:50<01:59,  1.01it/s, loss=0.2219, batch_acc=0.9375, running_acc=0.9315, grad=5.3796]Training epoch 11:  26%|██▋       | 43/163 [00:50<01:54,  1.05it/s, loss=0.2219, batch_acc=0.9375, running_acc=0.9315, grad=5.3796]Training epoch 11:  26%|██▋       | 43/163 [00:50<01:54,  1.05it/s, loss=0.2108, batch_acc=0.9688, running_acc=0.9324, grad=4.4468]Training epoch 11:  27%|██▋       | 44/163 [00:52<02:08,  1.08s/it, loss=0.2108, batch_acc=0.9688, running_acc=0.9324, grad=4.4468]Training epoch 11:  27%|██▋       | 44/163 [00:52<02:08,  1.08s/it, loss=0.1614, batch_acc=0.9688, running_acc=0.9332, grad=3.7922]Training epoch 11:  28%|██▊       | 45/163 [00:53<01:59,  1.02s/it, loss=0.1614, batch_acc=0.9688, running_acc=0.9332, grad=3.7922]Training epoch 11:  28%|██▊       | 45/163 [00:53<01:59,  1.02s/it, loss=0.2241, batch_acc=0.8750, running_acc=0.9319, grad=5.1269]Training epoch 11:  28%|██▊       | 46/163 [00:54<01:54,  1.03it/s, loss=0.2241, batch_acc=0.8750, running_acc=0.9319, grad=5.1269]Training epoch 11:  28%|██▊       | 46/163 [00:54<01:54,  1.03it/s, loss=0.1579, batch_acc=0.9375, running_acc=0.9321, grad=4.4131]Training epoch 11:  29%|██▉       | 47/163 [00:54<01:49,  1.06it/s, loss=0.1579, batch_acc=0.9375, running_acc=0.9321, grad=4.4131]Training epoch 11:  29%|██▉       | 47/163 [00:54<01:49,  1.06it/s, loss=0.1026, batch_acc=1.0000, running_acc=0.9335, grad=3.4745]Training epoch 11:  29%|██▉       | 48/163 [00:56<02:17,  1.20s/it, loss=0.1026, batch_acc=1.0000, running_acc=0.9335, grad=3.4745]Training epoch 11:  29%|██▉       | 48/163 [00:56<02:17,  1.20s/it, loss=0.4232, batch_acc=0.9375, running_acc=0.9336, grad=6.0671]Training epoch 11:  30%|███       | 49/163 [00:57<02:05,  1.10s/it, loss=0.4232, batch_acc=0.9375, running_acc=0.9336, grad=6.0671]Training epoch 11:  30%|███       | 49/163 [00:57<02:05,  1.10s/it, loss=0.2299, batch_acc=0.9375, running_acc=0.9337, grad=5.5149]Training epoch 11:  31%|███       | 50/163 [00:58<01:56,  1.03s/it, loss=0.2299, batch_acc=0.9375, running_acc=0.9337, grad=5.5149]Training epoch 11:  31%|███       | 50/163 [00:58<01:56,  1.03s/it, loss=0.2906, batch_acc=0.9062, running_acc=0.9331, grad=5.8756]Training epoch 11:  31%|███▏      | 51/163 [00:59<01:50,  1.01it/s, loss=0.2906, batch_acc=0.9062, running_acc=0.9331, grad=5.8756]Training epoch 11:  31%|███▏      | 51/163 [00:59<01:50,  1.01it/s, loss=0.2624, batch_acc=0.9062, running_acc=0.9326, grad=4.2673]Training epoch 11:  32%|███▏      | 52/163 [01:00<01:58,  1.07s/it, loss=0.2624, batch_acc=0.9062, running_acc=0.9326, grad=4.2673]Training epoch 11:  32%|███▏      | 52/163 [01:00<01:58,  1.07s/it, loss=0.1778, batch_acc=0.9688, running_acc=0.9333, grad=4.2428]Training epoch 11:  33%|███▎      | 53/163 [01:01<01:51,  1.01s/it, loss=0.1778, batch_acc=0.9688, running_acc=0.9333, grad=4.2428]Training epoch 11:  33%|███▎      | 53/163 [01:01<01:51,  1.01s/it, loss=0.1588, batch_acc=0.9375, running_acc=0.9334, grad=3.3707]Training epoch 11:  33%|███▎      | 54/163 [01:02<01:45,  1.03it/s, loss=0.1588, batch_acc=0.9375, running_acc=0.9334, grad=3.3707]Training epoch 11:  33%|███▎      | 54/163 [01:02<01:45,  1.03it/s, loss=0.2690, batch_acc=0.9375, running_acc=0.9334, grad=4.8811]Training epoch 11:  34%|███▎      | 55/163 [01:03<01:41,  1.06it/s, loss=0.2690, batch_acc=0.9375, running_acc=0.9334, grad=4.8811]Training epoch 11:  34%|███▎      | 55/163 [01:03<01:41,  1.06it/s, loss=0.1871, batch_acc=0.9688, running_acc=0.9341, grad=4.9972]Training epoch 11:  34%|███▍      | 56/163 [01:05<02:13,  1.25s/it, loss=0.1871, batch_acc=0.9688, running_acc=0.9341, grad=4.9972]Training epoch 11:  34%|███▍      | 56/163 [01:05<02:13,  1.25s/it, loss=0.1618, batch_acc=0.9375, running_acc=0.9342, grad=3.8607]Training epoch 11:  35%|███▍      | 57/163 [01:06<02:00,  1.14s/it, loss=0.1618, batch_acc=0.9375, running_acc=0.9342, grad=3.8607]Training epoch 11:  35%|███▍      | 57/163 [01:06<02:00,  1.14s/it, loss=0.1943, batch_acc=0.9688, running_acc=0.9348, grad=4.7710]Training epoch 11:  36%|███▌      | 58/163 [01:06<01:51,  1.06s/it, loss=0.1943, batch_acc=0.9688, running_acc=0.9348, grad=4.7710]Training epoch 11:  36%|███▌      | 58/163 [01:06<01:51,  1.06s/it, loss=0.1591, batch_acc=1.0000, running_acc=0.9359, grad=2.7547]Training epoch 11:  36%|███▌      | 59/163 [01:07<01:44,  1.01s/it, loss=0.1591, batch_acc=1.0000, running_acc=0.9359, grad=2.7547]Training epoch 11:  36%|███▌      | 59/163 [01:07<01:44,  1.01s/it, loss=0.1859, batch_acc=0.9375, running_acc=0.9359, grad=4.1805]Training epoch 11:  37%|███▋      | 60/163 [01:09<01:57,  1.14s/it, loss=0.1859, batch_acc=0.9375, running_acc=0.9359, grad=4.1805]Training epoch 11:  37%|███▋      | 60/163 [01:09<01:57,  1.14s/it, loss=0.2555, batch_acc=0.9062, running_acc=0.9354, grad=8.1437]Training epoch 11:  37%|███▋      | 61/163 [01:10<01:48,  1.06s/it, loss=0.2555, batch_acc=0.9062, running_acc=0.9354, grad=8.1437]Training epoch 11:  37%|███▋      | 61/163 [01:10<01:48,  1.06s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9365, grad=4.1033]Training epoch 11:  38%|███▊      | 62/163 [01:11<01:41,  1.00s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9365, grad=4.1033]Training epoch 11:  38%|███▊      | 62/163 [01:11<01:41,  1.00s/it, loss=0.2773, batch_acc=0.8750, running_acc=0.9355, grad=6.5698]Training epoch 11:  39%|███▊      | 63/163 [01:11<01:36,  1.03it/s, loss=0.2773, batch_acc=0.8750, running_acc=0.9355, grad=6.5698]Training epoch 11:  39%|███▊      | 63/163 [01:11<01:36,  1.03it/s, loss=0.2687, batch_acc=0.9375, running_acc=0.9355, grad=5.1965]Training epoch 11:  39%|███▉      | 64/163 [01:13<01:51,  1.13s/it, loss=0.2687, batch_acc=0.9375, running_acc=0.9355, grad=5.1965]Training epoch 11:  39%|███▉      | 64/163 [01:13<01:51,  1.13s/it, loss=0.2808, batch_acc=0.9375, running_acc=0.9355, grad=7.1282]Training epoch 11:  40%|███▉      | 65/163 [01:14<01:43,  1.05s/it, loss=0.2808, batch_acc=0.9375, running_acc=0.9355, grad=7.1282]Training epoch 11:  40%|███▉      | 65/163 [01:14<01:43,  1.05s/it, loss=0.1429, batch_acc=0.9375, running_acc=0.9356, grad=4.4835]Training epoch 11:  40%|████      | 66/163 [01:15<01:37,  1.00s/it, loss=0.1429, batch_acc=0.9375, running_acc=0.9356, grad=4.4835]Training epoch 11:  40%|████      | 66/163 [01:15<01:37,  1.00s/it, loss=0.1894, batch_acc=0.9375, running_acc=0.9356, grad=3.4619]Training epoch 11:  41%|████      | 67/163 [01:16<01:32,  1.04it/s, loss=0.1894, batch_acc=0.9375, running_acc=0.9356, grad=3.4619]Training epoch 11:  41%|████      | 67/163 [01:16<01:32,  1.04it/s, loss=0.3051, batch_acc=0.9375, running_acc=0.9356, grad=6.7268]Training epoch 11:  42%|████▏     | 68/163 [01:17<01:42,  1.08s/it, loss=0.3051, batch_acc=0.9375, running_acc=0.9356, grad=6.7268]Training epoch 11:  42%|████▏     | 68/163 [01:17<01:42,  1.08s/it, loss=0.1746, batch_acc=0.9688, running_acc=0.9361, grad=3.9296]Training epoch 11:  42%|████▏     | 69/163 [01:18<01:35,  1.02s/it, loss=0.1746, batch_acc=0.9688, running_acc=0.9361, grad=3.9296]Training epoch 11:  42%|████▏     | 69/163 [01:18<01:35,  1.02s/it, loss=0.2091, batch_acc=0.9688, running_acc=0.9366, grad=2.7676]Training epoch 11:  43%|████▎     | 70/163 [01:19<01:30,  1.02it/s, loss=0.2091, batch_acc=0.9688, running_acc=0.9366, grad=2.7676]Training epoch 11:  43%|████▎     | 70/163 [01:19<01:30,  1.02it/s, loss=0.1752, batch_acc=0.9688, running_acc=0.9371, grad=5.0599]Training epoch 11:  44%|████▎     | 71/163 [01:20<01:27,  1.06it/s, loss=0.1752, batch_acc=0.9688, running_acc=0.9371, grad=5.0599]Training epoch 11:  44%|████▎     | 71/163 [01:20<01:27,  1.06it/s, loss=0.1571, batch_acc=0.9688, running_acc=0.9375, grad=5.2880]Training epoch 11:  44%|████▍     | 72/163 [01:21<01:44,  1.15s/it, loss=0.1571, batch_acc=0.9688, running_acc=0.9375, grad=5.2880]Training epoch 11:  44%|████▍     | 72/163 [01:21<01:44,  1.15s/it, loss=0.1419, batch_acc=0.9688, running_acc=0.9379, grad=4.2391]Training epoch 11:  45%|████▍     | 73/163 [01:22<01:36,  1.07s/it, loss=0.1419, batch_acc=0.9688, running_acc=0.9379, grad=4.2391]Training epoch 11:  45%|████▍     | 73/163 [01:22<01:36,  1.07s/it, loss=0.2250, batch_acc=0.9375, running_acc=0.9379, grad=3.4560]Training epoch 11:  45%|████▌     | 74/163 [01:23<01:30,  1.01s/it, loss=0.2250, batch_acc=0.9375, running_acc=0.9379, grad=3.4560]Training epoch 11:  45%|████▌     | 74/163 [01:23<01:30,  1.01s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9383, grad=3.5136]Training epoch 11:  46%|████▌     | 75/163 [01:24<01:25,  1.03it/s, loss=0.1457, batch_acc=0.9688, running_acc=0.9383, grad=3.5136]Training epoch 11:  46%|████▌     | 75/163 [01:24<01:25,  1.03it/s, loss=0.1970, batch_acc=0.9375, running_acc=0.9383, grad=3.5537]Training epoch 11:  47%|████▋     | 76/163 [01:25<01:36,  1.11s/it, loss=0.1970, batch_acc=0.9375, running_acc=0.9383, grad=3.5537]Training epoch 11:  47%|████▋     | 76/163 [01:25<01:36,  1.11s/it, loss=0.2440, batch_acc=0.9375, running_acc=0.9383, grad=5.4345]Training epoch 11:  47%|████▋     | 77/163 [01:26<01:29,  1.04s/it, loss=0.2440, batch_acc=0.9375, running_acc=0.9383, grad=5.4345]Training epoch 11:  47%|████▋     | 77/163 [01:26<01:29,  1.04s/it, loss=0.2878, batch_acc=0.9062, running_acc=0.9379, grad=5.3598]Training epoch 11:  48%|████▊     | 78/163 [01:27<01:24,  1.01it/s, loss=0.2878, batch_acc=0.9062, running_acc=0.9379, grad=5.3598]Training epoch 11:  48%|████▊     | 78/163 [01:27<01:24,  1.01it/s, loss=0.3457, batch_acc=0.9062, running_acc=0.9375, grad=7.1041]Training epoch 11:  48%|████▊     | 79/163 [01:28<01:20,  1.04it/s, loss=0.3457, batch_acc=0.9062, running_acc=0.9375, grad=7.1041]Training epoch 11:  48%|████▊     | 79/163 [01:28<01:20,  1.04it/s, loss=0.2532, batch_acc=0.9062, running_acc=0.9371, grad=6.5299]Training epoch 11:  49%|████▉     | 80/163 [01:30<01:39,  1.19s/it, loss=0.2532, batch_acc=0.9062, running_acc=0.9371, grad=6.5299]Training epoch 11:  49%|████▉     | 80/163 [01:30<01:39,  1.19s/it, loss=0.1103, batch_acc=0.9688, running_acc=0.9375, grad=2.5020]Training epoch 11:  50%|████▉     | 81/163 [01:31<01:30,  1.10s/it, loss=0.1103, batch_acc=0.9688, running_acc=0.9375, grad=2.5020]Training epoch 11:  50%|████▉     | 81/163 [01:31<01:30,  1.10s/it, loss=0.2422, batch_acc=0.9062, running_acc=0.9371, grad=3.1058]Training epoch 11:  50%|█████     | 82/163 [01:32<01:26,  1.07s/it, loss=0.2422, batch_acc=0.9062, running_acc=0.9371, grad=3.1058]Training epoch 11:  50%|█████     | 82/163 [01:32<01:26,  1.07s/it, loss=0.3512, batch_acc=0.9062, running_acc=0.9367, grad=5.9250]Training epoch 11:  51%|█████     | 83/163 [01:32<01:20,  1.01s/it, loss=0.3512, batch_acc=0.9062, running_acc=0.9367, grad=5.9250]Training epoch 11:  51%|█████     | 83/163 [01:32<01:20,  1.01s/it, loss=0.5103, batch_acc=0.8125, running_acc=0.9352, grad=12.7574]Training epoch 11:  52%|█████▏    | 84/163 [01:34<01:31,  1.16s/it, loss=0.5103, batch_acc=0.8125, running_acc=0.9352, grad=12.7574]Training epoch 11:  52%|█████▏    | 84/163 [01:34<01:31,  1.16s/it, loss=0.2529, batch_acc=0.9375, running_acc=0.9353, grad=6.3922] Training epoch 11:  52%|█████▏    | 85/163 [01:35<01:23,  1.08s/it, loss=0.2529, batch_acc=0.9375, running_acc=0.9353, grad=6.3922]Training epoch 11:  52%|█████▏    | 85/163 [01:35<01:23,  1.08s/it, loss=0.3397, batch_acc=0.8750, running_acc=0.9346, grad=6.9360]Training epoch 11:  53%|█████▎    | 86/163 [01:36<01:18,  1.02s/it, loss=0.3397, batch_acc=0.8750, running_acc=0.9346, grad=6.9360]Training epoch 11:  53%|█████▎    | 86/163 [01:36<01:18,  1.02s/it, loss=0.4478, batch_acc=0.7812, running_acc=0.9328, grad=6.0104]Training epoch 11:  53%|█████▎    | 87/163 [01:37<01:14,  1.02it/s, loss=0.4478, batch_acc=0.7812, running_acc=0.9328, grad=6.0104]Training epoch 11:  53%|█████▎    | 87/163 [01:37<01:14,  1.02it/s, loss=0.2322, batch_acc=0.9062, running_acc=0.9325, grad=4.2515]Training epoch 11:  54%|█████▍    | 88/163 [01:38<01:34,  1.26s/it, loss=0.2322, batch_acc=0.9062, running_acc=0.9325, grad=4.2515]Training epoch 11:  54%|█████▍    | 88/163 [01:38<01:34,  1.26s/it, loss=0.1010, batch_acc=0.9688, running_acc=0.9329, grad=2.4896]Training epoch 11:  55%|█████▍    | 89/163 [01:39<01:24,  1.15s/it, loss=0.1010, batch_acc=0.9688, running_acc=0.9329, grad=2.4896]Training epoch 11:  55%|█████▍    | 89/163 [01:39<01:24,  1.15s/it, loss=0.4225, batch_acc=0.8750, running_acc=0.9322, grad=5.6375]Training epoch 11:  55%|█████▌    | 90/163 [01:40<01:20,  1.11s/it, loss=0.4225, batch_acc=0.8750, running_acc=0.9322, grad=5.6375]Training epoch 11:  55%|█████▌    | 90/163 [01:40<01:20,  1.11s/it, loss=0.2675, batch_acc=0.9062, running_acc=0.9319, grad=8.0673]Training epoch 11:  56%|█████▌    | 91/163 [01:41<01:14,  1.04s/it, loss=0.2675, batch_acc=0.9062, running_acc=0.9319, grad=8.0673]Training epoch 11:  56%|█████▌    | 91/163 [01:41<01:14,  1.04s/it, loss=0.2151, batch_acc=0.9688, running_acc=0.9323, grad=5.3858]Training epoch 11:  56%|█████▋    | 92/163 [01:43<01:29,  1.26s/it, loss=0.2151, batch_acc=0.9688, running_acc=0.9323, grad=5.3858]Training epoch 11:  56%|█████▋    | 92/163 [01:43<01:29,  1.26s/it, loss=0.2134, batch_acc=0.9375, running_acc=0.9324, grad=3.2862]Training epoch 11:  57%|█████▋    | 93/163 [01:44<01:20,  1.15s/it, loss=0.2134, batch_acc=0.9375, running_acc=0.9324, grad=3.2862]Training epoch 11:  57%|█████▋    | 93/163 [01:44<01:20,  1.15s/it, loss=0.2510, batch_acc=0.8750, running_acc=0.9318, grad=6.3158]Training epoch 11:  58%|█████▊    | 94/163 [01:45<01:14,  1.08s/it, loss=0.2510, batch_acc=0.8750, running_acc=0.9318, grad=6.3158]Training epoch 11:  58%|█████▊    | 94/163 [01:45<01:14,  1.08s/it, loss=0.1434, batch_acc=1.0000, running_acc=0.9325, grad=3.4225]Training epoch 11:  58%|█████▊    | 95/163 [01:46<01:09,  1.02s/it, loss=0.1434, batch_acc=1.0000, running_acc=0.9325, grad=3.4225]Training epoch 11:  58%|█████▊    | 95/163 [01:46<01:09,  1.02s/it, loss=0.0756, batch_acc=1.0000, running_acc=0.9332, grad=1.7330]Training epoch 11:  59%|█████▉    | 96/163 [01:47<01:17,  1.15s/it, loss=0.0756, batch_acc=1.0000, running_acc=0.9332, grad=1.7330]Training epoch 11:  59%|█████▉    | 96/163 [01:47<01:17,  1.15s/it, loss=0.3332, batch_acc=0.8438, running_acc=0.9323, grad=5.6976]Training epoch 11:  60%|█████▉    | 97/163 [01:48<01:10,  1.07s/it, loss=0.3332, batch_acc=0.8438, running_acc=0.9323, grad=5.6976]Training epoch 11:  60%|█████▉    | 97/163 [01:48<01:10,  1.07s/it, loss=0.2915, batch_acc=0.9062, running_acc=0.9320, grad=5.9068]Training epoch 11:  60%|██████    | 98/163 [01:49<01:08,  1.05s/it, loss=0.2915, batch_acc=0.9062, running_acc=0.9320, grad=5.9068]Training epoch 11:  60%|██████    | 98/163 [01:49<01:08,  1.05s/it, loss=0.2323, batch_acc=0.9688, running_acc=0.9324, grad=6.5130]Training epoch 11:  61%|██████    | 99/163 [01:50<01:04,  1.00s/it, loss=0.2323, batch_acc=0.9688, running_acc=0.9324, grad=6.5130]Training epoch 11:  61%|██████    | 99/163 [01:50<01:04,  1.00s/it, loss=0.1690, batch_acc=0.9375, running_acc=0.9324, grad=5.7757]Training epoch 11:  61%|██████▏   | 100/163 [01:51<01:09,  1.10s/it, loss=0.1690, batch_acc=0.9375, running_acc=0.9324, grad=5.7757]Training epoch 11:  61%|██████▏   | 100/163 [01:51<01:09,  1.10s/it, loss=0.2638, batch_acc=0.9375, running_acc=0.9325, grad=4.5459]Training epoch 11:  62%|██████▏   | 101/163 [01:52<01:04,  1.03s/it, loss=0.2638, batch_acc=0.9375, running_acc=0.9325, grad=4.5459]Training epoch 11:  62%|██████▏   | 101/163 [01:52<01:04,  1.03s/it, loss=0.3117, batch_acc=0.9062, running_acc=0.9322, grad=6.0112]Training epoch 11:  63%|██████▎   | 102/163 [01:53<01:08,  1.12s/it, loss=0.3117, batch_acc=0.9062, running_acc=0.9322, grad=6.0112]Training epoch 11:  63%|██████▎   | 102/163 [01:54<01:08,  1.12s/it, loss=0.2117, batch_acc=0.9688, running_acc=0.9326, grad=5.4320]Training epoch 11:  63%|██████▎   | 103/163 [01:54<01:02,  1.05s/it, loss=0.2117, batch_acc=0.9688, running_acc=0.9326, grad=5.4320]Training epoch 11:  63%|██████▎   | 103/163 [01:54<01:02,  1.05s/it, loss=0.1503, batch_acc=1.0000, running_acc=0.9333, grad=5.1811]Training epoch 11:  64%|██████▍   | 104/163 [01:56<01:08,  1.16s/it, loss=0.1503, batch_acc=1.0000, running_acc=0.9333, grad=5.1811]Training epoch 11:  64%|██████▍   | 104/163 [01:56<01:08,  1.16s/it, loss=0.2720, batch_acc=0.8750, running_acc=0.9327, grad=6.0207]Training epoch 11:  64%|██████▍   | 105/163 [01:57<01:02,  1.07s/it, loss=0.2720, batch_acc=0.8750, running_acc=0.9327, grad=6.0207]Training epoch 11:  64%|██████▍   | 105/163 [01:57<01:02,  1.07s/it, loss=0.1622, batch_acc=0.9375, running_acc=0.9327, grad=3.4247]Training epoch 11:  65%|██████▌   | 106/163 [01:58<00:59,  1.04s/it, loss=0.1622, batch_acc=0.9375, running_acc=0.9327, grad=3.4247]Training epoch 11:  65%|██████▌   | 106/163 [01:58<00:59,  1.04s/it, loss=0.1692, batch_acc=0.9375, running_acc=0.9328, grad=5.7931]Training epoch 11:  66%|██████▌   | 107/163 [01:59<00:55,  1.01it/s, loss=0.1692, batch_acc=0.9375, running_acc=0.9328, grad=5.7931]Training epoch 11:  66%|██████▌   | 107/163 [01:59<00:55,  1.01it/s, loss=0.2650, batch_acc=0.8750, running_acc=0.9322, grad=5.4479]Training epoch 11:  66%|██████▋   | 108/163 [02:00<01:02,  1.14s/it, loss=0.2650, batch_acc=0.8750, running_acc=0.9322, grad=5.4479]Training epoch 11:  66%|██████▋   | 108/163 [02:00<01:02,  1.14s/it, loss=0.3241, batch_acc=0.8750, running_acc=0.9317, grad=4.8430]Training epoch 11:  67%|██████▋   | 109/163 [02:01<00:57,  1.06s/it, loss=0.3241, batch_acc=0.8750, running_acc=0.9317, grad=4.8430]Training epoch 11:  67%|██████▋   | 109/163 [02:01<00:57,  1.06s/it, loss=0.1914, batch_acc=0.9375, running_acc=0.9318, grad=4.0400]Training epoch 11:  67%|██████▋   | 110/163 [02:02<00:54,  1.03s/it, loss=0.1914, batch_acc=0.9375, running_acc=0.9318, grad=4.0400]Training epoch 11:  67%|██████▋   | 110/163 [02:02<00:54,  1.03s/it, loss=0.2370, batch_acc=0.9375, running_acc=0.9318, grad=4.8696]Training epoch 11:  68%|██████▊   | 111/163 [02:03<00:51,  1.02it/s, loss=0.2370, batch_acc=0.9375, running_acc=0.9318, grad=4.8696]Training epoch 11:  68%|██████▊   | 111/163 [02:03<00:51,  1.02it/s, loss=0.3133, batch_acc=0.9062, running_acc=0.9316, grad=8.3633]Training epoch 11:  69%|██████▊   | 112/163 [02:04<00:55,  1.09s/it, loss=0.3133, batch_acc=0.9062, running_acc=0.9316, grad=8.3633]Training epoch 11:  69%|██████▊   | 112/163 [02:04<00:55,  1.09s/it, loss=0.1942, batch_acc=0.9688, running_acc=0.9319, grad=4.3886]Training epoch 11:  69%|██████▉   | 113/163 [02:05<00:51,  1.02s/it, loss=0.1942, batch_acc=0.9688, running_acc=0.9319, grad=4.3886]Training epoch 11:  69%|██████▉   | 113/163 [02:05<00:51,  1.02s/it, loss=0.3768, batch_acc=0.9375, running_acc=0.9320, grad=7.3017]Training epoch 11:  70%|██████▉   | 114/163 [02:06<00:48,  1.02it/s, loss=0.3768, batch_acc=0.9375, running_acc=0.9320, grad=7.3017]Training epoch 11:  70%|██████▉   | 114/163 [02:06<00:48,  1.02it/s, loss=0.3117, batch_acc=0.8750, running_acc=0.9315, grad=7.8806]Training epoch 11:  71%|███████   | 115/163 [02:07<00:45,  1.05it/s, loss=0.3117, batch_acc=0.8750, running_acc=0.9315, grad=7.8806]Training epoch 11:  71%|███████   | 115/163 [02:07<00:45,  1.05it/s, loss=0.2639, batch_acc=0.9062, running_acc=0.9313, grad=6.7630]Training epoch 11:  71%|███████   | 116/163 [02:08<00:53,  1.14s/it, loss=0.2639, batch_acc=0.9062, running_acc=0.9313, grad=6.7630]Training epoch 11:  71%|███████   | 116/163 [02:08<00:53,  1.14s/it, loss=0.2087, batch_acc=0.9688, running_acc=0.9316, grad=4.4535]Training epoch 11:  72%|███████▏  | 117/163 [02:09<00:48,  1.06s/it, loss=0.2087, batch_acc=0.9688, running_acc=0.9316, grad=4.4535]Training epoch 11:  72%|███████▏  | 117/163 [02:09<00:48,  1.06s/it, loss=0.2577, batch_acc=0.9688, running_acc=0.9319, grad=4.8571]Training epoch 11:  72%|███████▏  | 118/163 [02:11<00:52,  1.16s/it, loss=0.2577, batch_acc=0.9688, running_acc=0.9319, grad=4.8571]Training epoch 11:  72%|███████▏  | 118/163 [02:11<00:52,  1.16s/it, loss=0.1875, batch_acc=0.9688, running_acc=0.9322, grad=4.5866]Training epoch 11:  73%|███████▎  | 119/163 [02:11<00:47,  1.08s/it, loss=0.1875, batch_acc=0.9688, running_acc=0.9322, grad=4.5866]Training epoch 11:  73%|███████▎  | 119/163 [02:11<00:47,  1.08s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9328, grad=3.5769]Training epoch 11:  74%|███████▎  | 120/163 [02:13<00:52,  1.21s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9328, grad=3.5769]Training epoch 11:  74%|███████▎  | 120/163 [02:13<00:52,  1.21s/it, loss=0.1693, batch_acc=0.9688, running_acc=0.9331, grad=3.4717]Training epoch 11:  74%|███████▍  | 121/163 [02:14<00:46,  1.11s/it, loss=0.1693, batch_acc=0.9688, running_acc=0.9331, grad=3.4717]Training epoch 11:  74%|███████▍  | 121/163 [02:14<00:46,  1.11s/it, loss=0.2199, batch_acc=0.9062, running_acc=0.9329, grad=3.5469]Training epoch 11:  75%|███████▍  | 122/163 [02:15<00:44,  1.08s/it, loss=0.2199, batch_acc=0.9062, running_acc=0.9329, grad=3.5469]Training epoch 11:  75%|███████▍  | 122/163 [02:15<00:44,  1.08s/it, loss=0.2135, batch_acc=0.9375, running_acc=0.9329, grad=4.2813]Training epoch 11:  75%|███████▌  | 123/163 [02:16<00:40,  1.02s/it, loss=0.2135, batch_acc=0.9375, running_acc=0.9329, grad=4.2813]Training epoch 11:  75%|███████▌  | 123/163 [02:16<00:40,  1.02s/it, loss=0.3462, batch_acc=0.8750, running_acc=0.9324, grad=4.9596]Training epoch 11:  76%|███████▌  | 124/163 [02:17<00:45,  1.16s/it, loss=0.3462, batch_acc=0.8750, running_acc=0.9324, grad=4.9596]Training epoch 11:  76%|███████▌  | 124/163 [02:17<00:45,  1.16s/it, loss=0.2313, batch_acc=0.9375, running_acc=0.9325, grad=4.5266]Training epoch 11:  77%|███████▋  | 125/163 [02:18<00:40,  1.08s/it, loss=0.2313, batch_acc=0.9375, running_acc=0.9325, grad=4.5266]Training epoch 11:  77%|███████▋  | 125/163 [02:18<00:40,  1.08s/it, loss=0.1895, batch_acc=0.9062, running_acc=0.9323, grad=3.1974]Training epoch 11:  77%|███████▋  | 126/163 [02:19<00:39,  1.06s/it, loss=0.1895, batch_acc=0.9062, running_acc=0.9323, grad=3.1974]Training epoch 11:  77%|███████▋  | 126/163 [02:19<00:39,  1.06s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9325, grad=1.4440]Training epoch 11:  78%|███████▊  | 127/163 [02:20<00:36,  1.01s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9325, grad=1.4440]Training epoch 11:  78%|███████▊  | 127/163 [02:20<00:36,  1.01s/it, loss=0.1109, batch_acc=1.0000, running_acc=0.9331, grad=3.2428]Training epoch 11:  79%|███████▊  | 128/163 [02:22<00:42,  1.21s/it, loss=0.1109, batch_acc=1.0000, running_acc=0.9331, grad=3.2428]Training epoch 11:  79%|███████▊  | 128/163 [02:22<00:42,  1.21s/it, loss=0.3871, batch_acc=0.9062, running_acc=0.9329, grad=8.7212]Training epoch 11:  79%|███████▉  | 129/163 [02:23<00:37,  1.11s/it, loss=0.3871, batch_acc=0.9062, running_acc=0.9329, grad=8.7212]Training epoch 11:  79%|███████▉  | 129/163 [02:23<00:37,  1.11s/it, loss=0.1842, batch_acc=0.9688, running_acc=0.9331, grad=4.4952]Training epoch 11:  80%|███████▉  | 130/163 [02:24<00:36,  1.09s/it, loss=0.1842, batch_acc=0.9688, running_acc=0.9331, grad=4.4952]Training epoch 11:  80%|███████▉  | 130/163 [02:24<00:36,  1.09s/it, loss=0.1332, batch_acc=1.0000, running_acc=0.9337, grad=3.0105]Training epoch 11:  80%|████████  | 131/163 [02:24<00:32,  1.03s/it, loss=0.1332, batch_acc=1.0000, running_acc=0.9337, grad=3.0105]Training epoch 11:  80%|████████  | 131/163 [02:24<00:32,  1.03s/it, loss=0.2477, batch_acc=0.9375, running_acc=0.9337, grad=6.0965]Training epoch 11:  81%|████████  | 132/163 [02:26<00:33,  1.07s/it, loss=0.2477, batch_acc=0.9375, running_acc=0.9337, grad=6.0965]Training epoch 11:  81%|████████  | 132/163 [02:26<00:33,  1.07s/it, loss=0.2966, batch_acc=0.9062, running_acc=0.9335, grad=5.5889]Training epoch 11:  82%|████████▏ | 133/163 [02:27<00:30,  1.01s/it, loss=0.2966, batch_acc=0.9062, running_acc=0.9335, grad=5.5889]Training epoch 11:  82%|████████▏ | 133/163 [02:27<00:30,  1.01s/it, loss=0.2176, batch_acc=0.9375, running_acc=0.9335, grad=5.8711]Training epoch 11:  82%|████████▏ | 134/163 [02:28<00:30,  1.06s/it, loss=0.2176, batch_acc=0.9375, running_acc=0.9335, grad=5.8711]Training epoch 11:  82%|████████▏ | 134/163 [02:28<00:30,  1.06s/it, loss=0.2256, batch_acc=0.9062, running_acc=0.9333, grad=4.3950]Training epoch 11:  83%|████████▎ | 135/163 [02:29<00:28,  1.00s/it, loss=0.2256, batch_acc=0.9062, running_acc=0.9333, grad=4.3950]Training epoch 11:  83%|████████▎ | 135/163 [02:29<00:28,  1.00s/it, loss=0.2139, batch_acc=0.9062, running_acc=0.9331, grad=4.1038]Training epoch 11:  83%|████████▎ | 136/163 [02:30<00:32,  1.21s/it, loss=0.2139, batch_acc=0.9062, running_acc=0.9331, grad=4.1038]Training epoch 11:  83%|████████▎ | 136/163 [02:30<00:32,  1.21s/it, loss=0.3534, batch_acc=0.9062, running_acc=0.9329, grad=9.0359]Training epoch 11:  84%|████████▍ | 137/163 [02:31<00:28,  1.11s/it, loss=0.3534, batch_acc=0.9062, running_acc=0.9329, grad=9.0359]Training epoch 11:  84%|████████▍ | 137/163 [02:31<00:28,  1.11s/it, loss=0.2918, batch_acc=0.9062, running_acc=0.9327, grad=8.0846]Training epoch 11:  85%|████████▍ | 138/163 [02:32<00:28,  1.15s/it, loss=0.2918, batch_acc=0.9062, running_acc=0.9327, grad=8.0846]Training epoch 11:  85%|████████▍ | 138/163 [02:32<00:28,  1.15s/it, loss=0.2712, batch_acc=0.9062, running_acc=0.9325, grad=6.6269]Training epoch 11:  85%|████████▌ | 139/163 [02:33<00:25,  1.07s/it, loss=0.2712, batch_acc=0.9062, running_acc=0.9325, grad=6.6269]Training epoch 11:  85%|████████▌ | 139/163 [02:33<00:25,  1.07s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9328, grad=2.7083]Training epoch 11:  86%|████████▌ | 140/163 [02:34<00:25,  1.09s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9328, grad=2.7083]Training epoch 11:  86%|████████▌ | 140/163 [02:34<00:25,  1.09s/it, loss=0.2478, batch_acc=0.9062, running_acc=0.9326, grad=7.1585]Training epoch 11:  87%|████████▋ | 141/163 [02:35<00:22,  1.02s/it, loss=0.2478, batch_acc=0.9062, running_acc=0.9326, grad=7.1585]Training epoch 11:  87%|████████▋ | 141/163 [02:35<00:22,  1.02s/it, loss=0.2328, batch_acc=0.9688, running_acc=0.9328, grad=5.2972]Training epoch 11:  87%|████████▋ | 142/163 [02:36<00:20,  1.01it/s, loss=0.2328, batch_acc=0.9688, running_acc=0.9328, grad=5.2972]Training epoch 11:  87%|████████▋ | 142/163 [02:36<00:20,  1.01it/s, loss=0.2150, batch_acc=0.9062, running_acc=0.9327, grad=7.0436]Training epoch 11:  88%|████████▊ | 143/163 [02:37<00:19,  1.05it/s, loss=0.2150, batch_acc=0.9062, running_acc=0.9327, grad=7.0436]Training epoch 11:  88%|████████▊ | 143/163 [02:37<00:19,  1.05it/s, loss=0.1180, batch_acc=0.9688, running_acc=0.9329, grad=2.4614]Training epoch 11:  88%|████████▊ | 144/163 [02:39<00:23,  1.26s/it, loss=0.1180, batch_acc=0.9688, running_acc=0.9329, grad=2.4614]Training epoch 11:  88%|████████▊ | 144/163 [02:39<00:23,  1.26s/it, loss=0.4303, batch_acc=0.9062, running_acc=0.9327, grad=8.1098]Training epoch 11:  89%|████████▉ | 145/163 [02:40<00:20,  1.14s/it, loss=0.4303, batch_acc=0.9062, running_acc=0.9327, grad=8.1098]Training epoch 11:  89%|████████▉ | 145/163 [02:40<00:20,  1.14s/it, loss=0.5281, batch_acc=0.8438, running_acc=0.9321, grad=7.7613]Training epoch 11:  90%|████████▉ | 146/163 [02:41<00:18,  1.06s/it, loss=0.5281, batch_acc=0.8438, running_acc=0.9321, grad=7.7613]Training epoch 11:  90%|████████▉ | 146/163 [02:41<00:18,  1.06s/it, loss=0.2483, batch_acc=0.9062, running_acc=0.9319, grad=6.0649]Training epoch 11:  90%|█████████ | 147/163 [02:42<00:16,  1.01s/it, loss=0.2483, batch_acc=0.9062, running_acc=0.9319, grad=6.0649]Training epoch 11:  90%|█████████ | 147/163 [02:42<00:16,  1.01s/it, loss=0.2042, batch_acc=0.9375, running_acc=0.9320, grad=4.9862]Training epoch 11:  91%|█████████ | 148/163 [02:43<00:17,  1.15s/it, loss=0.2042, batch_acc=0.9375, running_acc=0.9320, grad=4.9862]Training epoch 11:  91%|█████████ | 148/163 [02:43<00:17,  1.15s/it, loss=0.1553, batch_acc=0.9375, running_acc=0.9320, grad=5.5023]Training epoch 11:  91%|█████████▏| 149/163 [02:44<00:14,  1.06s/it, loss=0.1553, batch_acc=0.9375, running_acc=0.9320, grad=5.5023]Training epoch 11:  91%|█████████▏| 149/163 [02:44<00:14,  1.06s/it, loss=0.3158, batch_acc=0.8750, running_acc=0.9316, grad=5.9488]Training epoch 11:  92%|█████████▏| 150/163 [02:45<00:13,  1.01s/it, loss=0.3158, batch_acc=0.8750, running_acc=0.9316, grad=5.9488]Training epoch 11:  92%|█████████▏| 150/163 [02:45<00:13,  1.01s/it, loss=0.0919, batch_acc=0.9688, running_acc=0.9319, grad=3.0322]Training epoch 11:  93%|█████████▎| 151/163 [02:46<00:11,  1.03it/s, loss=0.0919, batch_acc=0.9688, running_acc=0.9319, grad=3.0322]Training epoch 11:  93%|█████████▎| 151/163 [02:46<00:11,  1.03it/s, loss=0.2244, batch_acc=0.9375, running_acc=0.9319, grad=5.1245]Training epoch 11:  93%|█████████▎| 152/163 [02:47<00:13,  1.19s/it, loss=0.2244, batch_acc=0.9375, running_acc=0.9319, grad=5.1245]Training epoch 11:  93%|█████████▎| 152/163 [02:47<00:13,  1.19s/it, loss=0.1964, batch_acc=0.9375, running_acc=0.9319, grad=4.3311]Training epoch 11:  94%|█████████▍| 153/163 [02:48<00:10,  1.09s/it, loss=0.1964, batch_acc=0.9375, running_acc=0.9319, grad=4.3311]Training epoch 11:  94%|█████████▍| 153/163 [02:48<00:10,  1.09s/it, loss=0.3613, batch_acc=0.8125, running_acc=0.9312, grad=6.7302]Training epoch 11:  94%|█████████▍| 154/163 [02:49<00:09,  1.03s/it, loss=0.3613, batch_acc=0.8125, running_acc=0.9312, grad=6.7302]Training epoch 11:  94%|█████████▍| 154/163 [02:49<00:09,  1.03s/it, loss=0.1952, batch_acc=0.8750, running_acc=0.9308, grad=3.6028]Training epoch 11:  95%|█████████▌| 155/163 [02:50<00:07,  1.02it/s, loss=0.1952, batch_acc=0.8750, running_acc=0.9308, grad=3.6028]Training epoch 11:  95%|█████████▌| 155/163 [02:50<00:07,  1.02it/s, loss=0.2736, batch_acc=0.9062, running_acc=0.9306, grad=4.2435]Training epoch 11:  96%|█████████▌| 156/163 [02:52<00:08,  1.20s/it, loss=0.2736, batch_acc=0.9062, running_acc=0.9306, grad=4.2435]Training epoch 11:  96%|█████████▌| 156/163 [02:52<00:08,  1.20s/it, loss=0.2469, batch_acc=0.8750, running_acc=0.9303, grad=3.1275]Training epoch 11:  96%|█████████▋| 157/163 [02:53<00:06,  1.10s/it, loss=0.2469, batch_acc=0.8750, running_acc=0.9303, grad=3.1275]Training epoch 11:  96%|█████████▋| 157/163 [02:53<00:06,  1.10s/it, loss=0.3400, batch_acc=0.9062, running_acc=0.9301, grad=7.1587]Training epoch 11:  97%|█████████▋| 158/163 [02:54<00:05,  1.04s/it, loss=0.3400, batch_acc=0.9062, running_acc=0.9301, grad=7.1587]Training epoch 11:  97%|█████████▋| 158/163 [02:54<00:05,  1.04s/it, loss=0.3317, batch_acc=0.8750, running_acc=0.9298, grad=7.8819]Training epoch 11:  98%|█████████▊| 159/163 [02:54<00:03,  1.01it/s, loss=0.3317, batch_acc=0.8750, running_acc=0.9298, grad=7.8819]Training epoch 11:  98%|█████████▊| 159/163 [02:54<00:03,  1.01it/s, loss=0.2842, batch_acc=0.9375, running_acc=0.9298, grad=5.8089]Training epoch 11:  98%|█████████▊| 160/163 [02:55<00:02,  1.03it/s, loss=0.2842, batch_acc=0.9375, running_acc=0.9298, grad=5.8089]Training epoch 11:  98%|█████████▊| 160/163 [02:55<00:02,  1.03it/s, loss=0.6162, batch_acc=0.8750, running_acc=0.9295, grad=8.9763]Training epoch 11:  99%|█████████▉| 161/163 [02:56<00:01,  1.06it/s, loss=0.6162, batch_acc=0.8750, running_acc=0.9295, grad=8.9763]Training epoch 11:  99%|█████████▉| 161/163 [02:56<00:01,  1.06it/s, loss=0.3136, batch_acc=0.9062, running_acc=0.9293, grad=6.1612]Training epoch 11:  99%|█████████▉| 162/163 [02:57<00:00,  1.09it/s, loss=0.3136, batch_acc=0.9062, running_acc=0.9293, grad=6.1612]Training epoch 11:  99%|█████████▉| 162/163 [02:57<00:00,  1.09it/s, loss=0.1709, batch_acc=0.9375, running_acc=0.9294, grad=3.1353]Training epoch 11: 100%|██████████| 163/163 [02:58<00:00,  1.20it/s, loss=0.1709, batch_acc=0.9375, running_acc=0.9294, grad=3.1353]Training epoch 11: 100%|██████████| 163/163 [02:58<00:00,  1.20it/s, loss=0.1703, batch_acc=0.9524, running_acc=0.9295, grad=5.1033]Training epoch 11: 100%|██████████| 163/163 [02:58<00:00,  1.09s/it, loss=0.1703, batch_acc=0.9524, running_acc=0.9295, grad=5.1033]
Evaluation epoch 11:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 11:   4%|▎         | 1/28 [00:05<02:15,  5.00s/it]Evaluation epoch 11:   4%|▎         | 1/28 [00:05<02:15,  5.00s/it, loss=0.5019, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 11:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=0.5019, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 11:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=0.2853, batch_acc=0.8750, running_acc=0.8594]Evaluation epoch 11:  11%|█         | 3/28 [00:05<00:33,  1.32s/it, loss=0.2853, batch_acc=0.8750, running_acc=0.8594]Evaluation epoch 11:  11%|█         | 3/28 [00:05<00:33,  1.32s/it, loss=0.6616, batch_acc=0.7188, running_acc=0.8125]Evaluation epoch 11:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.6616, batch_acc=0.7188, running_acc=0.8125]Evaluation epoch 11:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=1.5524, batch_acc=0.5938, running_acc=0.7578]Evaluation epoch 11:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=1.5524, batch_acc=0.5938, running_acc=0.7578]Evaluation epoch 11:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=2.7926, batch_acc=0.4375, running_acc=0.6937]Evaluation epoch 11:  21%|██▏       | 6/28 [00:10<00:26,  1.18s/it, loss=2.7926, batch_acc=0.4375, running_acc=0.6937]Evaluation epoch 11:  21%|██▏       | 6/28 [00:10<00:26,  1.18s/it, loss=0.8190, batch_acc=0.7812, running_acc=0.7083]Evaluation epoch 11:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.8190, batch_acc=0.7812, running_acc=0.7083]Evaluation epoch 11:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.9586, batch_acc=0.7188, running_acc=0.7098]Evaluation epoch 11:  29%|██▊       | 8/28 [00:13<00:32,  1.61s/it, loss=0.9586, batch_acc=0.7188, running_acc=0.7098]Evaluation epoch 11:  29%|██▊       | 8/28 [00:13<00:32,  1.61s/it, loss=0.9350, batch_acc=0.6562, running_acc=0.7031]Evaluation epoch 11:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=0.9350, batch_acc=0.6562, running_acc=0.7031]Evaluation epoch 11:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=1.2704, batch_acc=0.6250, running_acc=0.6944]Evaluation epoch 11:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=1.2704, batch_acc=0.6250, running_acc=0.6944]Evaluation epoch 11:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.4105, batch_acc=0.8438, running_acc=0.7094]Evaluation epoch 11:  39%|███▉      | 11/28 [00:14<00:13,  1.27it/s, loss=0.4105, batch_acc=0.8438, running_acc=0.7094]Evaluation epoch 11:  39%|███▉      | 11/28 [00:14<00:13,  1.27it/s, loss=0.7046, batch_acc=0.8125, running_acc=0.7188]Evaluation epoch 11:  43%|████▎     | 12/28 [00:20<00:33,  2.09s/it, loss=0.7046, batch_acc=0.8125, running_acc=0.7188]Evaluation epoch 11:  43%|████▎     | 12/28 [00:20<00:33,  2.09s/it, loss=1.9476, batch_acc=0.4688, running_acc=0.6979]Evaluation epoch 11:  46%|████▋     | 13/28 [00:20<00:22,  1.53s/it, loss=1.9476, batch_acc=0.4688, running_acc=0.6979]Evaluation epoch 11:  46%|████▋     | 13/28 [00:20<00:22,  1.53s/it, loss=0.5404, batch_acc=0.8438, running_acc=0.7091]Evaluation epoch 11:  50%|█████     | 14/28 [00:20<00:16,  1.15s/it, loss=0.5404, batch_acc=0.8438, running_acc=0.7091]Evaluation epoch 11:  50%|█████     | 14/28 [00:20<00:16,  1.15s/it, loss=0.9985, batch_acc=0.8125, running_acc=0.7165]Evaluation epoch 11:  54%|█████▎    | 15/28 [00:20<00:11,  1.14it/s, loss=0.9985, batch_acc=0.8125, running_acc=0.7165]Evaluation epoch 11:  54%|█████▎    | 15/28 [00:20<00:11,  1.14it/s, loss=1.3553, batch_acc=0.6562, running_acc=0.7125]Evaluation epoch 11:  57%|█████▋    | 16/28 [00:23<00:18,  1.51s/it, loss=1.3553, batch_acc=0.6562, running_acc=0.7125]Evaluation epoch 11:  57%|█████▋    | 16/28 [00:23<00:18,  1.51s/it, loss=0.5864, batch_acc=0.8750, running_acc=0.7227]Evaluation epoch 11:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.5864, batch_acc=0.8750, running_acc=0.7227]Evaluation epoch 11:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.4859, batch_acc=0.9062, running_acc=0.7335]Evaluation epoch 11:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.4859, batch_acc=0.9062, running_acc=0.7335]Evaluation epoch 11:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=1.1072, batch_acc=0.7188, running_acc=0.7326]Evaluation epoch 11:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=1.1072, batch_acc=0.7188, running_acc=0.7326]Evaluation epoch 11:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.6786, batch_acc=0.6875, running_acc=0.7303]Evaluation epoch 11:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.6786, batch_acc=0.6875, running_acc=0.7303]Evaluation epoch 11:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.7866, batch_acc=0.5938, running_acc=0.7234]Evaluation epoch 11:  75%|███████▌  | 21/28 [00:27<00:07,  1.02s/it, loss=0.7866, batch_acc=0.5938, running_acc=0.7234]Evaluation epoch 11:  75%|███████▌  | 21/28 [00:27<00:07,  1.02s/it, loss=0.9016, batch_acc=0.8125, running_acc=0.7277]Evaluation epoch 11:  79%|███████▊  | 22/28 [00:27<00:04,  1.26it/s, loss=0.9016, batch_acc=0.8125, running_acc=0.7277]Evaluation epoch 11:  79%|███████▊  | 22/28 [00:27<00:04,  1.26it/s, loss=0.9594, batch_acc=0.6875, running_acc=0.7259]Evaluation epoch 11:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=0.9594, batch_acc=0.6875, running_acc=0.7259]Evaluation epoch 11:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=1.4686, batch_acc=0.5312, running_acc=0.7174]Evaluation epoch 11:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=1.4686, batch_acc=0.5312, running_acc=0.7174]Evaluation epoch 11:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=0.3430, batch_acc=0.9062, running_acc=0.7253]Evaluation epoch 11:  89%|████████▉ | 25/28 [00:33<00:04,  1.51s/it, loss=0.3430, batch_acc=0.9062, running_acc=0.7253]Evaluation epoch 11:  89%|████████▉ | 25/28 [00:33<00:04,  1.51s/it, loss=0.5038, batch_acc=0.8438, running_acc=0.7300]Evaluation epoch 11:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.5038, batch_acc=0.8438, running_acc=0.7300]Evaluation epoch 11:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.7396, batch_acc=0.8438, running_acc=0.7344]Evaluation epoch 11:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.7396, batch_acc=0.8438, running_acc=0.7344]Evaluation epoch 11:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=1.0729, batch_acc=0.7500, running_acc=0.7350]Evaluation epoch 11: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=0.8044, batch_acc=0.6667, running_acc=0.7347]Evaluation epoch 11: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=0.8044, batch_acc=0.6667, running_acc=0.7347]
Training epoch 12:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 12:   1%|          | 1/163 [00:05<15:50,  5.87s/it]Training epoch 12:   1%|          | 1/163 [00:05<15:50,  5.87s/it, loss=0.4163, batch_acc=0.8438, running_acc=0.8438, grad=6.9430]Training epoch 12:   1%|          | 2/163 [00:06<07:52,  2.93s/it, loss=0.4163, batch_acc=0.8438, running_acc=0.8438, grad=6.9430]Training epoch 12:   1%|          | 2/163 [00:06<07:52,  2.93s/it, loss=0.4357, batch_acc=0.8438, running_acc=0.8438, grad=10.5813]Training epoch 12:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=0.4357, batch_acc=0.8438, running_acc=0.8438, grad=10.5813]Training epoch 12:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=0.3825, batch_acc=0.8125, running_acc=0.8333, grad=6.5264] Training epoch 12:   2%|▏         | 4/163 [00:09<05:38,  2.13s/it, loss=0.3825, batch_acc=0.8125, running_acc=0.8333, grad=6.5264]Training epoch 12:   2%|▏         | 4/163 [00:09<05:38,  2.13s/it, loss=0.3674, batch_acc=0.8750, running_acc=0.8438, grad=8.5884]Training epoch 12:   3%|▎         | 5/163 [00:10<04:25,  1.68s/it, loss=0.3674, batch_acc=0.8750, running_acc=0.8438, grad=8.5884]Training epoch 12:   3%|▎         | 5/163 [00:10<04:25,  1.68s/it, loss=0.1980, batch_acc=0.9375, running_acc=0.8625, grad=5.0378]Training epoch 12:   4%|▎         | 6/163 [00:11<03:40,  1.41s/it, loss=0.1980, batch_acc=0.9375, running_acc=0.8625, grad=5.0378]Training epoch 12:   4%|▎         | 6/163 [00:11<03:40,  1.41s/it, loss=0.1384, batch_acc=1.0000, running_acc=0.8854, grad=3.8847]Training epoch 12:   4%|▍         | 7/163 [00:12<03:12,  1.23s/it, loss=0.1384, batch_acc=1.0000, running_acc=0.8854, grad=3.8847]Training epoch 12:   4%|▍         | 7/163 [00:12<03:12,  1.23s/it, loss=0.2428, batch_acc=0.9375, running_acc=0.8929, grad=4.9422]Training epoch 12:   5%|▍         | 8/163 [00:14<03:39,  1.42s/it, loss=0.2428, batch_acc=0.9375, running_acc=0.8929, grad=4.9422]Training epoch 12:   5%|▍         | 8/163 [00:14<03:39,  1.42s/it, loss=0.1179, batch_acc=0.9688, running_acc=0.9023, grad=2.4136]Training epoch 12:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.1179, batch_acc=0.9688, running_acc=0.9023, grad=2.4136]Training epoch 12:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.0906, batch_acc=1.0000, running_acc=0.9132, grad=2.2833]Training epoch 12:   6%|▌         | 10/163 [00:16<02:53,  1.13s/it, loss=0.0906, batch_acc=1.0000, running_acc=0.9132, grad=2.2833]Training epoch 12:   6%|▌         | 10/163 [00:16<02:53,  1.13s/it, loss=0.2148, batch_acc=0.9688, running_acc=0.9187, grad=4.9241]Training epoch 12:   7%|▋         | 11/163 [00:17<02:40,  1.06s/it, loss=0.2148, batch_acc=0.9688, running_acc=0.9187, grad=4.9241]Training epoch 12:   7%|▋         | 11/163 [00:17<02:40,  1.06s/it, loss=0.2026, batch_acc=0.9688, running_acc=0.9233, grad=6.2101]Training epoch 12:   7%|▋         | 12/163 [00:18<03:07,  1.24s/it, loss=0.2026, batch_acc=0.9688, running_acc=0.9233, grad=6.2101]Training epoch 12:   7%|▋         | 12/163 [00:18<03:07,  1.24s/it, loss=0.4642, batch_acc=0.8750, running_acc=0.9193, grad=9.0773]Training epoch 12:   8%|▊         | 13/163 [00:19<02:49,  1.13s/it, loss=0.4642, batch_acc=0.8750, running_acc=0.9193, grad=9.0773]Training epoch 12:   8%|▊         | 13/163 [00:19<02:49,  1.13s/it, loss=0.2187, batch_acc=0.9688, running_acc=0.9231, grad=5.5724]Training epoch 12:   9%|▊         | 14/163 [00:20<02:37,  1.06s/it, loss=0.2187, batch_acc=0.9688, running_acc=0.9231, grad=5.5724]Training epoch 12:   9%|▊         | 14/163 [00:20<02:37,  1.06s/it, loss=0.3364, batch_acc=0.8750, running_acc=0.9196, grad=4.7728]Training epoch 12:   9%|▉         | 15/163 [00:21<02:28,  1.00s/it, loss=0.3364, batch_acc=0.8750, running_acc=0.9196, grad=4.7728]Training epoch 12:   9%|▉         | 15/163 [00:21<02:28,  1.00s/it, loss=0.1881, batch_acc=0.9688, running_acc=0.9229, grad=4.5815]Training epoch 12:  10%|▉         | 16/163 [00:22<02:35,  1.06s/it, loss=0.1881, batch_acc=0.9688, running_acc=0.9229, grad=4.5815]Training epoch 12:  10%|▉         | 16/163 [00:22<02:35,  1.06s/it, loss=0.2795, batch_acc=0.9062, running_acc=0.9219, grad=5.6132]Training epoch 12:  10%|█         | 17/163 [00:23<02:26,  1.01s/it, loss=0.2795, batch_acc=0.9062, running_acc=0.9219, grad=5.6132]Training epoch 12:  10%|█         | 17/163 [00:23<02:26,  1.01s/it, loss=0.0581, batch_acc=1.0000, running_acc=0.9265, grad=1.3626]Training epoch 12:  11%|█         | 18/163 [00:24<02:20,  1.03it/s, loss=0.0581, batch_acc=1.0000, running_acc=0.9265, grad=1.3626]Training epoch 12:  11%|█         | 18/163 [00:24<02:20,  1.03it/s, loss=0.2351, batch_acc=0.9375, running_acc=0.9271, grad=5.0614]Training epoch 12:  12%|█▏        | 19/163 [00:25<02:15,  1.06it/s, loss=0.2351, batch_acc=0.9375, running_acc=0.9271, grad=5.0614]Training epoch 12:  12%|█▏        | 19/163 [00:25<02:15,  1.06it/s, loss=0.1680, batch_acc=0.9375, running_acc=0.9276, grad=2.9220]Training epoch 12:  12%|█▏        | 20/163 [00:26<02:30,  1.05s/it, loss=0.1680, batch_acc=0.9375, running_acc=0.9276, grad=2.9220]Training epoch 12:  12%|█▏        | 20/163 [00:26<02:30,  1.05s/it, loss=0.2733, batch_acc=0.8750, running_acc=0.9250, grad=4.6673]Training epoch 12:  13%|█▎        | 21/163 [00:27<02:21,  1.00it/s, loss=0.2733, batch_acc=0.8750, running_acc=0.9250, grad=4.6673]Training epoch 12:  13%|█▎        | 21/163 [00:27<02:21,  1.00it/s, loss=0.1579, batch_acc=0.9688, running_acc=0.9271, grad=5.6455]Training epoch 12:  13%|█▎        | 22/163 [00:28<02:15,  1.04it/s, loss=0.1579, batch_acc=0.9688, running_acc=0.9271, grad=5.6455]Training epoch 12:  13%|█▎        | 22/163 [00:28<02:15,  1.04it/s, loss=0.2326, batch_acc=0.9062, running_acc=0.9261, grad=5.5358]Training epoch 12:  14%|█▍        | 23/163 [00:29<02:11,  1.07it/s, loss=0.2326, batch_acc=0.9062, running_acc=0.9261, grad=5.5358]Training epoch 12:  14%|█▍        | 23/163 [00:29<02:11,  1.07it/s, loss=0.2968, batch_acc=0.9062, running_acc=0.9253, grad=5.7386]Training epoch 12:  15%|█▍        | 24/163 [00:30<02:30,  1.08s/it, loss=0.2968, batch_acc=0.9062, running_acc=0.9253, grad=5.7386]Training epoch 12:  15%|█▍        | 24/163 [00:30<02:30,  1.08s/it, loss=0.1409, batch_acc=0.9688, running_acc=0.9271, grad=1.8652]Training epoch 12:  15%|█▌        | 25/163 [00:31<02:20,  1.02s/it, loss=0.1409, batch_acc=0.9688, running_acc=0.9271, grad=1.8652]Training epoch 12:  15%|█▌        | 25/163 [00:31<02:20,  1.02s/it, loss=0.1463, batch_acc=0.9375, running_acc=0.9275, grad=3.8048]Training epoch 12:  16%|█▌        | 26/163 [00:32<02:13,  1.02it/s, loss=0.1463, batch_acc=0.9375, running_acc=0.9275, grad=3.8048]Training epoch 12:  16%|█▌        | 26/163 [00:32<02:13,  1.02it/s, loss=0.2061, batch_acc=0.9375, running_acc=0.9279, grad=4.4148]Training epoch 12:  17%|█▋        | 27/163 [00:33<02:08,  1.06it/s, loss=0.2061, batch_acc=0.9375, running_acc=0.9279, grad=4.4148]Training epoch 12:  17%|█▋        | 27/163 [00:33<02:08,  1.06it/s, loss=0.2033, batch_acc=0.9375, running_acc=0.9282, grad=4.8602]Training epoch 12:  17%|█▋        | 28/163 [00:34<02:28,  1.10s/it, loss=0.2033, batch_acc=0.9375, running_acc=0.9282, grad=4.8602]Training epoch 12:  17%|█▋        | 28/163 [00:34<02:28,  1.10s/it, loss=0.2170, batch_acc=0.9062, running_acc=0.9275, grad=5.1424]Training epoch 12:  18%|█▊        | 29/163 [00:35<02:18,  1.03s/it, loss=0.2170, batch_acc=0.9062, running_acc=0.9275, grad=5.1424]Training epoch 12:  18%|█▊        | 29/163 [00:35<02:18,  1.03s/it, loss=0.0642, batch_acc=1.0000, running_acc=0.9300, grad=1.9888]Training epoch 12:  18%|█▊        | 30/163 [00:36<02:11,  1.01it/s, loss=0.0642, batch_acc=1.0000, running_acc=0.9300, grad=1.9888]Training epoch 12:  18%|█▊        | 30/163 [00:36<02:11,  1.01it/s, loss=0.3354, batch_acc=0.8750, running_acc=0.9281, grad=4.7138]Training epoch 12:  19%|█▉        | 31/163 [00:37<02:06,  1.05it/s, loss=0.3354, batch_acc=0.8750, running_acc=0.9281, grad=4.7138]Training epoch 12:  19%|█▉        | 31/163 [00:37<02:06,  1.05it/s, loss=0.1250, batch_acc=0.9688, running_acc=0.9294, grad=4.4068]Training epoch 12:  20%|█▉        | 32/163 [00:39<02:43,  1.25s/it, loss=0.1250, batch_acc=0.9688, running_acc=0.9294, grad=4.4068]Training epoch 12:  20%|█▉        | 32/163 [00:39<02:43,  1.25s/it, loss=0.0915, batch_acc=1.0000, running_acc=0.9316, grad=2.1128]Training epoch 12:  20%|██        | 33/163 [00:40<02:28,  1.14s/it, loss=0.0915, batch_acc=1.0000, running_acc=0.9316, grad=2.1128]Training epoch 12:  20%|██        | 33/163 [00:40<02:28,  1.14s/it, loss=0.1809, batch_acc=0.9375, running_acc=0.9318, grad=4.4261]Training epoch 12:  21%|██        | 34/163 [00:40<02:16,  1.06s/it, loss=0.1809, batch_acc=0.9375, running_acc=0.9318, grad=4.4261]Training epoch 12:  21%|██        | 34/163 [00:40<02:16,  1.06s/it, loss=0.3843, batch_acc=0.9062, running_acc=0.9311, grad=6.0892]Training epoch 12:  21%|██▏       | 35/163 [00:41<02:08,  1.01s/it, loss=0.3843, batch_acc=0.9062, running_acc=0.9311, grad=6.0892]Training epoch 12:  21%|██▏       | 35/163 [00:41<02:08,  1.01s/it, loss=0.1796, batch_acc=0.9375, running_acc=0.9313, grad=5.7302]Training epoch 12:  22%|██▏       | 36/163 [00:42<02:04,  1.02it/s, loss=0.1796, batch_acc=0.9375, running_acc=0.9313, grad=5.7302]Training epoch 12:  22%|██▏       | 36/163 [00:42<02:04,  1.02it/s, loss=0.1179, batch_acc=1.0000, running_acc=0.9332, grad=3.6867]Training epoch 12:  23%|██▎       | 37/163 [00:43<01:59,  1.05it/s, loss=0.1179, batch_acc=1.0000, running_acc=0.9332, grad=3.6867]Training epoch 12:  23%|██▎       | 37/163 [00:43<01:59,  1.05it/s, loss=0.1869, batch_acc=0.9688, running_acc=0.9341, grad=6.9185]Training epoch 12:  23%|██▎       | 38/163 [00:44<01:58,  1.06it/s, loss=0.1869, batch_acc=0.9688, running_acc=0.9341, grad=6.9185]Training epoch 12:  23%|██▎       | 38/163 [00:44<01:58,  1.06it/s, loss=0.1304, batch_acc=0.9375, running_acc=0.9342, grad=3.1104]Training epoch 12:  24%|██▍       | 39/163 [00:45<01:54,  1.08it/s, loss=0.1304, batch_acc=0.9375, running_acc=0.9342, grad=3.1104]Training epoch 12:  24%|██▍       | 39/163 [00:45<01:54,  1.08it/s, loss=0.1667, batch_acc=0.9688, running_acc=0.9351, grad=4.6939]Training epoch 12:  25%|██▍       | 40/163 [00:46<02:12,  1.08s/it, loss=0.1667, batch_acc=0.9688, running_acc=0.9351, grad=4.6939]Training epoch 12:  25%|██▍       | 40/163 [00:46<02:12,  1.08s/it, loss=0.0961, batch_acc=0.9688, running_acc=0.9359, grad=2.8413]Training epoch 12:  25%|██▌       | 41/163 [00:47<02:04,  1.02s/it, loss=0.0961, batch_acc=0.9688, running_acc=0.9359, grad=2.8413]Training epoch 12:  25%|██▌       | 41/163 [00:47<02:04,  1.02s/it, loss=0.1251, batch_acc=0.9688, running_acc=0.9367, grad=3.1393]Training epoch 12:  26%|██▌       | 42/163 [00:48<01:58,  1.02it/s, loss=0.1251, batch_acc=0.9688, running_acc=0.9367, grad=3.1393]Training epoch 12:  26%|██▌       | 42/163 [00:48<01:58,  1.02it/s, loss=0.2895, batch_acc=0.8750, running_acc=0.9353, grad=5.6014]Training epoch 12:  26%|██▋       | 43/163 [00:49<01:53,  1.06it/s, loss=0.2895, batch_acc=0.8750, running_acc=0.9353, grad=5.6014]Training epoch 12:  26%|██▋       | 43/163 [00:49<01:53,  1.06it/s, loss=0.1795, batch_acc=0.9688, running_acc=0.9360, grad=5.7968]Training epoch 12:  27%|██▋       | 44/163 [00:51<02:15,  1.14s/it, loss=0.1795, batch_acc=0.9688, running_acc=0.9360, grad=5.7968]Training epoch 12:  27%|██▋       | 44/163 [00:51<02:15,  1.14s/it, loss=0.2048, batch_acc=0.9062, running_acc=0.9354, grad=4.5762]Training epoch 12:  28%|██▊       | 45/163 [00:51<02:05,  1.06s/it, loss=0.2048, batch_acc=0.9062, running_acc=0.9354, grad=4.5762]Training epoch 12:  28%|██▊       | 45/163 [00:51<02:05,  1.06s/it, loss=0.1868, batch_acc=0.9688, running_acc=0.9361, grad=4.3842]Training epoch 12:  28%|██▊       | 46/163 [00:52<02:01,  1.04s/it, loss=0.1868, batch_acc=0.9688, running_acc=0.9361, grad=4.3842]Training epoch 12:  28%|██▊       | 46/163 [00:52<02:01,  1.04s/it, loss=0.3011, batch_acc=0.8750, running_acc=0.9348, grad=6.7900]Training epoch 12:  29%|██▉       | 47/163 [00:53<01:55,  1.01it/s, loss=0.3011, batch_acc=0.8750, running_acc=0.9348, grad=6.7900]Training epoch 12:  29%|██▉       | 47/163 [00:53<01:55,  1.01it/s, loss=0.1073, batch_acc=1.0000, running_acc=0.9362, grad=3.3063]Training epoch 12:  29%|██▉       | 48/163 [00:54<01:50,  1.04it/s, loss=0.1073, batch_acc=1.0000, running_acc=0.9362, grad=3.3063]Training epoch 12:  29%|██▉       | 48/163 [00:54<01:50,  1.04it/s, loss=0.1178, batch_acc=0.9688, running_acc=0.9368, grad=2.4330]Training epoch 12:  30%|███       | 49/163 [00:55<01:46,  1.07it/s, loss=0.1178, batch_acc=0.9688, running_acc=0.9368, grad=2.4330]Training epoch 12:  30%|███       | 49/163 [00:55<01:46,  1.07it/s, loss=0.1774, batch_acc=0.9688, running_acc=0.9375, grad=5.0324]Training epoch 12:  31%|███       | 50/163 [00:57<02:10,  1.15s/it, loss=0.1774, batch_acc=0.9688, running_acc=0.9375, grad=5.0324]Training epoch 12:  31%|███       | 50/163 [00:57<02:10,  1.15s/it, loss=0.1770, batch_acc=0.9688, running_acc=0.9381, grad=5.8224]Training epoch 12:  31%|███▏      | 51/163 [00:58<02:00,  1.07s/it, loss=0.1770, batch_acc=0.9688, running_acc=0.9381, grad=5.8224]Training epoch 12:  31%|███▏      | 51/163 [00:58<02:00,  1.07s/it, loss=0.1108, batch_acc=0.9688, running_acc=0.9387, grad=3.6105]Training epoch 12:  32%|███▏      | 52/163 [00:59<01:52,  1.01s/it, loss=0.1108, batch_acc=0.9688, running_acc=0.9387, grad=3.6105]Training epoch 12:  32%|███▏      | 52/163 [00:59<01:52,  1.01s/it, loss=0.2410, batch_acc=0.9375, running_acc=0.9387, grad=6.6242]Training epoch 12:  33%|███▎      | 53/163 [00:59<01:47,  1.03it/s, loss=0.2410, batch_acc=0.9375, running_acc=0.9387, grad=6.6242]Training epoch 12:  33%|███▎      | 53/163 [00:59<01:47,  1.03it/s, loss=0.2073, batch_acc=0.9375, running_acc=0.9387, grad=4.5629]Training epoch 12:  33%|███▎      | 54/163 [01:01<02:14,  1.24s/it, loss=0.2073, batch_acc=0.9375, running_acc=0.9387, grad=4.5629]Training epoch 12:  33%|███▎      | 54/163 [01:01<02:14,  1.24s/it, loss=0.1651, batch_acc=1.0000, running_acc=0.9398, grad=4.4149]Training epoch 12:  34%|███▎      | 55/163 [01:02<02:01,  1.13s/it, loss=0.1651, batch_acc=1.0000, running_acc=0.9398, grad=4.4149]Training epoch 12:  34%|███▎      | 55/163 [01:02<02:01,  1.13s/it, loss=0.2571, batch_acc=0.9062, running_acc=0.9392, grad=5.4870]Training epoch 12:  34%|███▍      | 56/163 [01:03<01:52,  1.05s/it, loss=0.2571, batch_acc=0.9062, running_acc=0.9392, grad=5.4870]Training epoch 12:  34%|███▍      | 56/163 [01:03<01:52,  1.05s/it, loss=0.2875, batch_acc=0.9375, running_acc=0.9392, grad=6.6887]Training epoch 12:  35%|███▍      | 57/163 [01:04<01:48,  1.02s/it, loss=0.2875, batch_acc=0.9375, running_acc=0.9392, grad=6.6887]Training epoch 12:  35%|███▍      | 57/163 [01:04<01:48,  1.02s/it, loss=0.2623, batch_acc=0.9375, running_acc=0.9391, grad=6.1113]Training epoch 12:  36%|███▌      | 58/163 [01:05<01:55,  1.10s/it, loss=0.2623, batch_acc=0.9375, running_acc=0.9391, grad=6.1113]Training epoch 12:  36%|███▌      | 58/163 [01:05<01:55,  1.10s/it, loss=0.5594, batch_acc=0.7500, running_acc=0.9359, grad=10.9524]Training epoch 12:  36%|███▌      | 59/163 [01:06<01:47,  1.03s/it, loss=0.5594, batch_acc=0.7500, running_acc=0.9359, grad=10.9524]Training epoch 12:  36%|███▌      | 59/163 [01:06<01:47,  1.03s/it, loss=0.2254, batch_acc=0.9375, running_acc=0.9359, grad=7.1018] Training epoch 12:  37%|███▋      | 60/163 [01:07<01:41,  1.01it/s, loss=0.2254, batch_acc=0.9375, running_acc=0.9359, grad=7.1018]Training epoch 12:  37%|███▋      | 60/163 [01:07<01:41,  1.01it/s, loss=0.1920, batch_acc=0.9375, running_acc=0.9359, grad=4.8414]Training epoch 12:  37%|███▋      | 61/163 [01:08<01:37,  1.05it/s, loss=0.1920, batch_acc=0.9375, running_acc=0.9359, grad=4.8414]Training epoch 12:  37%|███▋      | 61/163 [01:08<01:37,  1.05it/s, loss=0.3287, batch_acc=0.9375, running_acc=0.9360, grad=6.0007]Training epoch 12:  38%|███▊      | 62/163 [01:09<01:50,  1.09s/it, loss=0.3287, batch_acc=0.9375, running_acc=0.9360, grad=6.0007]Training epoch 12:  38%|███▊      | 62/163 [01:09<01:50,  1.09s/it, loss=0.1926, batch_acc=0.9688, running_acc=0.9365, grad=3.7308]Training epoch 12:  39%|███▊      | 63/163 [01:10<01:42,  1.03s/it, loss=0.1926, batch_acc=0.9688, running_acc=0.9365, grad=3.7308]Training epoch 12:  39%|███▊      | 63/163 [01:10<01:42,  1.03s/it, loss=0.2790, batch_acc=0.9375, running_acc=0.9365, grad=8.0843]Training epoch 12:  39%|███▉      | 64/163 [01:11<01:37,  1.02it/s, loss=0.2790, batch_acc=0.9375, running_acc=0.9365, grad=8.0843]Training epoch 12:  39%|███▉      | 64/163 [01:11<01:37,  1.02it/s, loss=0.1247, batch_acc=0.9375, running_acc=0.9365, grad=1.6751]Training epoch 12:  40%|███▉      | 65/163 [01:12<01:33,  1.05it/s, loss=0.1247, batch_acc=0.9375, running_acc=0.9365, grad=1.6751]Training epoch 12:  40%|███▉      | 65/163 [01:12<01:33,  1.05it/s, loss=0.1453, batch_acc=0.9375, running_acc=0.9365, grad=3.5549]Training epoch 12:  40%|████      | 66/163 [01:13<01:42,  1.06s/it, loss=0.1453, batch_acc=0.9375, running_acc=0.9365, grad=3.5549]Training epoch 12:  40%|████      | 66/163 [01:13<01:42,  1.06s/it, loss=0.1400, batch_acc=0.9375, running_acc=0.9366, grad=4.6262]Training epoch 12:  41%|████      | 67/163 [01:14<01:36,  1.01s/it, loss=0.1400, batch_acc=0.9375, running_acc=0.9366, grad=4.6262]Training epoch 12:  41%|████      | 67/163 [01:14<01:36,  1.01s/it, loss=0.1957, batch_acc=0.9375, running_acc=0.9366, grad=5.9824]Training epoch 12:  42%|████▏     | 68/163 [01:15<01:33,  1.02it/s, loss=0.1957, batch_acc=0.9375, running_acc=0.9366, grad=5.9824]Training epoch 12:  42%|████▏     | 68/163 [01:15<01:33,  1.02it/s, loss=0.1811, batch_acc=0.9375, running_acc=0.9366, grad=4.3329]Training epoch 12:  42%|████▏     | 69/163 [01:16<01:30,  1.04it/s, loss=0.1811, batch_acc=0.9375, running_acc=0.9366, grad=4.3329]Training epoch 12:  42%|████▏     | 69/163 [01:16<01:30,  1.04it/s, loss=0.1139, batch_acc=0.9688, running_acc=0.9370, grad=2.7715]Training epoch 12:  43%|████▎     | 70/163 [01:17<01:34,  1.02s/it, loss=0.1139, batch_acc=0.9688, running_acc=0.9370, grad=2.7715]Training epoch 12:  43%|████▎     | 70/163 [01:17<01:34,  1.02s/it, loss=0.2572, batch_acc=0.9062, running_acc=0.9366, grad=6.6661]Training epoch 12:  44%|████▎     | 71/163 [01:18<01:29,  1.03it/s, loss=0.2572, batch_acc=0.9062, running_acc=0.9366, grad=6.6661]Training epoch 12:  44%|████▎     | 71/163 [01:18<01:29,  1.03it/s, loss=0.1754, batch_acc=0.9688, running_acc=0.9371, grad=4.4549]Training epoch 12:  44%|████▍     | 72/163 [01:19<01:26,  1.05it/s, loss=0.1754, batch_acc=0.9688, running_acc=0.9371, grad=4.4549]Training epoch 12:  44%|████▍     | 72/163 [01:19<01:26,  1.05it/s, loss=0.0734, batch_acc=1.0000, running_acc=0.9379, grad=2.6279]Training epoch 12:  45%|████▍     | 73/163 [01:20<01:30,  1.01s/it, loss=0.0734, batch_acc=1.0000, running_acc=0.9379, grad=2.6279]Training epoch 12:  45%|████▍     | 73/163 [01:20<01:30,  1.01s/it, loss=0.1804, batch_acc=0.9062, running_acc=0.9375, grad=2.2759]Training epoch 12:  45%|████▌     | 74/163 [01:21<01:35,  1.08s/it, loss=0.1804, batch_acc=0.9062, running_acc=0.9375, grad=2.2759]Training epoch 12:  45%|████▌     | 74/163 [01:21<01:35,  1.08s/it, loss=0.2062, batch_acc=0.9062, running_acc=0.9371, grad=4.9531]Training epoch 12:  46%|████▌     | 75/163 [01:22<01:29,  1.02s/it, loss=0.2062, batch_acc=0.9062, running_acc=0.9371, grad=4.9531]Training epoch 12:  46%|████▌     | 75/163 [01:22<01:29,  1.02s/it, loss=0.1783, batch_acc=0.9375, running_acc=0.9371, grad=4.7254]Training epoch 12:  47%|████▋     | 76/163 [01:23<01:24,  1.02it/s, loss=0.1783, batch_acc=0.9375, running_acc=0.9371, grad=4.7254]Training epoch 12:  47%|████▋     | 76/163 [01:23<01:24,  1.02it/s, loss=0.2156, batch_acc=0.9062, running_acc=0.9367, grad=4.0011]Training epoch 12:  47%|████▋     | 77/163 [01:24<01:32,  1.08s/it, loss=0.2156, batch_acc=0.9062, running_acc=0.9367, grad=4.0011]Training epoch 12:  47%|████▋     | 77/163 [01:24<01:32,  1.08s/it, loss=0.2318, batch_acc=0.9375, running_acc=0.9367, grad=5.7707]Training epoch 12:  48%|████▊     | 78/163 [01:26<01:41,  1.20s/it, loss=0.2318, batch_acc=0.9375, running_acc=0.9367, grad=5.7707]Training epoch 12:  48%|████▊     | 78/163 [01:26<01:41,  1.20s/it, loss=0.1562, batch_acc=0.9375, running_acc=0.9367, grad=4.1449]Training epoch 12:  48%|████▊     | 79/163 [01:27<01:32,  1.10s/it, loss=0.1562, batch_acc=0.9375, running_acc=0.9367, grad=4.1449]Training epoch 12:  48%|████▊     | 79/163 [01:27<01:32,  1.10s/it, loss=0.3630, batch_acc=0.8750, running_acc=0.9359, grad=8.3839]Training epoch 12:  49%|████▉     | 80/163 [01:28<01:25,  1.04s/it, loss=0.3630, batch_acc=0.8750, running_acc=0.9359, grad=8.3839]Training epoch 12:  49%|████▉     | 80/163 [01:28<01:25,  1.04s/it, loss=0.6039, batch_acc=0.8438, running_acc=0.9348, grad=7.4647]Training epoch 12:  50%|████▉     | 81/163 [01:29<01:22,  1.01s/it, loss=0.6039, batch_acc=0.8438, running_acc=0.9348, grad=7.4647]Training epoch 12:  50%|████▉     | 81/163 [01:29<01:22,  1.01s/it, loss=0.3644, batch_acc=0.8125, running_acc=0.9333, grad=9.0420]Training epoch 12:  50%|█████     | 82/163 [01:30<01:39,  1.23s/it, loss=0.3644, batch_acc=0.8125, running_acc=0.9333, grad=9.0420]Training epoch 12:  50%|█████     | 82/163 [01:30<01:39,  1.23s/it, loss=0.1075, batch_acc=0.9688, running_acc=0.9337, grad=3.7752]Training epoch 12:  51%|█████     | 83/163 [01:31<01:29,  1.12s/it, loss=0.1075, batch_acc=0.9688, running_acc=0.9337, grad=3.7752]Training epoch 12:  51%|█████     | 83/163 [01:31<01:29,  1.12s/it, loss=0.1413, batch_acc=0.9062, running_acc=0.9334, grad=3.5634]Training epoch 12:  52%|█████▏    | 84/163 [01:32<01:24,  1.07s/it, loss=0.1413, batch_acc=0.9062, running_acc=0.9334, grad=3.5634]Training epoch 12:  52%|█████▏    | 84/163 [01:32<01:24,  1.07s/it, loss=0.2462, batch_acc=0.9688, running_acc=0.9338, grad=7.3943]Training epoch 12:  52%|█████▏    | 85/163 [01:33<01:20,  1.04s/it, loss=0.2462, batch_acc=0.9688, running_acc=0.9338, grad=7.3943]Training epoch 12:  52%|█████▏    | 85/163 [01:33<01:20,  1.04s/it, loss=0.3090, batch_acc=0.9062, running_acc=0.9335, grad=6.4776]Training epoch 12:  53%|█████▎    | 86/163 [01:34<01:25,  1.11s/it, loss=0.3090, batch_acc=0.9062, running_acc=0.9335, grad=6.4776]Training epoch 12:  53%|█████▎    | 86/163 [01:34<01:25,  1.11s/it, loss=0.3446, batch_acc=0.8125, running_acc=0.9320, grad=5.8693]Training epoch 12:  53%|█████▎    | 87/163 [01:35<01:19,  1.04s/it, loss=0.3446, batch_acc=0.8125, running_acc=0.9320, grad=5.8693]Training epoch 12:  53%|█████▎    | 87/163 [01:35<01:19,  1.04s/it, loss=0.2010, batch_acc=0.9375, running_acc=0.9321, grad=5.3740]Training epoch 12:  54%|█████▍    | 88/163 [01:36<01:14,  1.01it/s, loss=0.2010, batch_acc=0.9375, running_acc=0.9321, grad=5.3740]Training epoch 12:  54%|█████▍    | 88/163 [01:36<01:14,  1.01it/s, loss=0.1672, batch_acc=0.9062, running_acc=0.9318, grad=6.6444]Training epoch 12:  55%|█████▍    | 89/163 [01:37<01:11,  1.03it/s, loss=0.1672, batch_acc=0.9062, running_acc=0.9318, grad=6.6444]Training epoch 12:  55%|█████▍    | 89/163 [01:37<01:11,  1.03it/s, loss=0.1188, batch_acc=1.0000, running_acc=0.9326, grad=3.3973]Training epoch 12:  55%|█████▌    | 90/163 [01:39<01:27,  1.20s/it, loss=0.1188, batch_acc=1.0000, running_acc=0.9326, grad=3.3973]Training epoch 12:  55%|█████▌    | 90/163 [01:39<01:27,  1.20s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9330, grad=3.7792]Training epoch 12:  56%|█████▌    | 91/163 [01:40<01:19,  1.10s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9330, grad=3.7792]Training epoch 12:  56%|█████▌    | 91/163 [01:40<01:19,  1.10s/it, loss=0.0958, batch_acc=1.0000, running_acc=0.9337, grad=3.0181]Training epoch 12:  56%|█████▋    | 92/163 [01:41<01:13,  1.04s/it, loss=0.0958, batch_acc=1.0000, running_acc=0.9337, grad=3.0181]Training epoch 12:  56%|█████▋    | 92/163 [01:41<01:13,  1.04s/it, loss=0.1447, batch_acc=0.9688, running_acc=0.9341, grad=3.1607]Training epoch 12:  57%|█████▋    | 93/163 [01:41<01:09,  1.01it/s, loss=0.1447, batch_acc=0.9688, running_acc=0.9341, grad=3.1607]Training epoch 12:  57%|█████▋    | 93/163 [01:41<01:09,  1.01it/s, loss=0.2473, batch_acc=0.9375, running_acc=0.9341, grad=4.8579]Training epoch 12:  58%|█████▊    | 94/163 [01:43<01:17,  1.12s/it, loss=0.2473, batch_acc=0.9375, running_acc=0.9341, grad=4.8579]Training epoch 12:  58%|█████▊    | 94/163 [01:43<01:17,  1.12s/it, loss=0.1738, batch_acc=0.9688, running_acc=0.9345, grad=3.0616]Training epoch 12:  58%|█████▊    | 95/163 [01:44<01:11,  1.05s/it, loss=0.1738, batch_acc=0.9688, running_acc=0.9345, grad=3.0616]Training epoch 12:  58%|█████▊    | 95/163 [01:44<01:11,  1.05s/it, loss=0.1224, batch_acc=0.9375, running_acc=0.9345, grad=2.2139]Training epoch 12:  59%|█████▉    | 96/163 [01:45<01:06,  1.00it/s, loss=0.1224, batch_acc=0.9375, running_acc=0.9345, grad=2.2139]Training epoch 12:  59%|█████▉    | 96/163 [01:45<01:06,  1.00it/s, loss=0.4123, batch_acc=0.8438, running_acc=0.9336, grad=7.3751]Training epoch 12:  60%|█████▉    | 97/163 [01:45<01:03,  1.04it/s, loss=0.4123, batch_acc=0.8438, running_acc=0.9336, grad=7.3751]Training epoch 12:  60%|█████▉    | 97/163 [01:45<01:03,  1.04it/s, loss=0.1862, batch_acc=0.9375, running_acc=0.9336, grad=5.6144]Training epoch 12:  60%|██████    | 98/163 [01:48<01:26,  1.33s/it, loss=0.1862, batch_acc=0.9375, running_acc=0.9336, grad=5.6144]Training epoch 12:  60%|██████    | 98/163 [01:48<01:26,  1.33s/it, loss=0.2975, batch_acc=0.8750, running_acc=0.9330, grad=5.9173]Training epoch 12:  61%|██████    | 99/163 [01:49<01:16,  1.20s/it, loss=0.2975, batch_acc=0.8750, running_acc=0.9330, grad=5.9173]Training epoch 12:  61%|██████    | 99/163 [01:49<01:16,  1.20s/it, loss=0.3292, batch_acc=0.9062, running_acc=0.9328, grad=7.9962]Training epoch 12:  61%|██████▏   | 100/163 [01:49<01:09,  1.10s/it, loss=0.3292, batch_acc=0.9062, running_acc=0.9328, grad=7.9962]Training epoch 12:  61%|██████▏   | 100/163 [01:49<01:09,  1.10s/it, loss=0.1540, batch_acc=0.9375, running_acc=0.9328, grad=3.2828]Training epoch 12:  62%|██████▏   | 101/163 [01:50<01:04,  1.04s/it, loss=0.1540, batch_acc=0.9375, running_acc=0.9328, grad=3.2828]Training epoch 12:  62%|██████▏   | 101/163 [01:50<01:04,  1.04s/it, loss=0.3796, batch_acc=0.9062, running_acc=0.9325, grad=7.7460]Training epoch 12:  63%|██████▎   | 102/163 [01:53<01:28,  1.44s/it, loss=0.3796, batch_acc=0.9062, running_acc=0.9325, grad=7.7460]Training epoch 12:  63%|██████▎   | 102/163 [01:53<01:28,  1.44s/it, loss=0.2571, batch_acc=0.8750, running_acc=0.9320, grad=4.7159]Training epoch 12:  63%|██████▎   | 103/163 [01:54<01:16,  1.27s/it, loss=0.2571, batch_acc=0.8750, running_acc=0.9320, grad=4.7159]Training epoch 12:  63%|██████▎   | 103/163 [01:54<01:16,  1.27s/it, loss=0.2628, batch_acc=0.8750, running_acc=0.9314, grad=5.6603]Training epoch 12:  64%|██████▍   | 104/163 [01:54<01:08,  1.16s/it, loss=0.2628, batch_acc=0.8750, running_acc=0.9314, grad=5.6603]Training epoch 12:  64%|██████▍   | 104/163 [01:54<01:08,  1.16s/it, loss=0.4729, batch_acc=0.8438, running_acc=0.9306, grad=9.0284]Training epoch 12:  64%|██████▍   | 105/163 [01:55<01:02,  1.07s/it, loss=0.4729, batch_acc=0.8438, running_acc=0.9306, grad=9.0284]Training epoch 12:  64%|██████▍   | 105/163 [01:55<01:02,  1.07s/it, loss=0.2904, batch_acc=0.8750, running_acc=0.9301, grad=4.3324]Training epoch 12:  65%|██████▌   | 106/163 [01:57<01:03,  1.11s/it, loss=0.2904, batch_acc=0.8750, running_acc=0.9301, grad=4.3324]Training epoch 12:  65%|██████▌   | 106/163 [01:57<01:03,  1.11s/it, loss=0.1779, batch_acc=0.9688, running_acc=0.9304, grad=4.3291]Training epoch 12:  66%|██████▌   | 107/163 [01:57<00:58,  1.04s/it, loss=0.1779, batch_acc=0.9688, running_acc=0.9304, grad=4.3291]Training epoch 12:  66%|██████▌   | 107/163 [01:57<00:58,  1.04s/it, loss=0.1694, batch_acc=0.9375, running_acc=0.9305, grad=2.7330]Training epoch 12:  66%|██████▋   | 108/163 [01:58<00:54,  1.01it/s, loss=0.1694, batch_acc=0.9375, running_acc=0.9305, grad=2.7330]Training epoch 12:  66%|██████▋   | 108/163 [01:58<00:54,  1.01it/s, loss=0.2587, batch_acc=0.9375, running_acc=0.9306, grad=6.6211]Training epoch 12:  67%|██████▋   | 109/163 [01:59<00:51,  1.04it/s, loss=0.2587, batch_acc=0.9375, running_acc=0.9306, grad=6.6211]Training epoch 12:  67%|██████▋   | 109/163 [01:59<00:51,  1.04it/s, loss=0.2093, batch_acc=0.9375, running_acc=0.9306, grad=5.8567]Training epoch 12:  67%|██████▋   | 110/163 [02:01<01:00,  1.14s/it, loss=0.2093, batch_acc=0.9375, running_acc=0.9306, grad=5.8567]Training epoch 12:  67%|██████▋   | 110/163 [02:01<01:00,  1.14s/it, loss=0.1570, batch_acc=0.9688, running_acc=0.9310, grad=2.4939]Training epoch 12:  68%|██████▊   | 111/163 [02:02<00:55,  1.06s/it, loss=0.1570, batch_acc=0.9688, running_acc=0.9310, grad=2.4939]Training epoch 12:  68%|██████▊   | 111/163 [02:02<00:55,  1.06s/it, loss=0.2571, batch_acc=0.9062, running_acc=0.9307, grad=5.1108]Training epoch 12:  69%|██████▊   | 112/163 [02:03<00:51,  1.01s/it, loss=0.2571, batch_acc=0.9062, running_acc=0.9307, grad=5.1108]Training epoch 12:  69%|██████▊   | 112/163 [02:03<00:51,  1.01s/it, loss=0.1324, batch_acc=1.0000, running_acc=0.9314, grad=3.0353]Training epoch 12:  69%|██████▉   | 113/163 [02:03<00:48,  1.03it/s, loss=0.1324, batch_acc=1.0000, running_acc=0.9314, grad=3.0353]Training epoch 12:  69%|██████▉   | 113/163 [02:03<00:48,  1.03it/s, loss=0.1822, batch_acc=0.9062, running_acc=0.9311, grad=5.3232]Training epoch 12:  70%|██████▉   | 114/163 [02:05<00:59,  1.21s/it, loss=0.1822, batch_acc=0.9062, running_acc=0.9311, grad=5.3232]Training epoch 12:  70%|██████▉   | 114/163 [02:05<00:59,  1.21s/it, loss=0.1451, batch_acc=0.9375, running_acc=0.9312, grad=2.4009]Training epoch 12:  71%|███████   | 115/163 [02:06<00:53,  1.11s/it, loss=0.1451, batch_acc=0.9375, running_acc=0.9312, grad=2.4009]Training epoch 12:  71%|███████   | 115/163 [02:06<00:53,  1.11s/it, loss=0.1522, batch_acc=0.9375, running_acc=0.9313, grad=4.3460]Training epoch 12:  71%|███████   | 116/163 [02:07<00:48,  1.04s/it, loss=0.1522, batch_acc=0.9375, running_acc=0.9313, grad=4.3460]Training epoch 12:  71%|███████   | 116/163 [02:07<00:48,  1.04s/it, loss=0.2864, batch_acc=0.9375, running_acc=0.9313, grad=4.5860]Training epoch 12:  72%|███████▏  | 117/163 [02:08<00:45,  1.01it/s, loss=0.2864, batch_acc=0.9375, running_acc=0.9313, grad=4.5860]Training epoch 12:  72%|███████▏  | 117/163 [02:08<00:45,  1.01it/s, loss=0.0894, batch_acc=0.9688, running_acc=0.9316, grad=1.8491]Training epoch 12:  72%|███████▏  | 118/163 [02:10<00:55,  1.22s/it, loss=0.0894, batch_acc=0.9688, running_acc=0.9316, grad=1.8491]Training epoch 12:  72%|███████▏  | 118/163 [02:10<00:55,  1.22s/it, loss=0.3009, batch_acc=0.8750, running_acc=0.9311, grad=5.5200]Training epoch 12:  73%|███████▎  | 119/163 [02:10<00:49,  1.12s/it, loss=0.3009, batch_acc=0.8750, running_acc=0.9311, grad=5.5200]Training epoch 12:  73%|███████▎  | 119/163 [02:10<00:49,  1.12s/it, loss=0.1485, batch_acc=0.9688, running_acc=0.9315, grad=3.3618]Training epoch 12:  74%|███████▎  | 120/163 [02:11<00:45,  1.05s/it, loss=0.1485, batch_acc=0.9688, running_acc=0.9315, grad=3.3618]Training epoch 12:  74%|███████▎  | 120/163 [02:11<00:45,  1.05s/it, loss=0.3326, batch_acc=0.8125, running_acc=0.9305, grad=4.7421]Training epoch 12:  74%|███████▍  | 121/163 [02:12<00:41,  1.00it/s, loss=0.3326, batch_acc=0.8125, running_acc=0.9305, grad=4.7421]Training epoch 12:  74%|███████▍  | 121/163 [02:12<00:41,  1.00it/s, loss=0.0852, batch_acc=0.9688, running_acc=0.9308, grad=1.8802]Training epoch 12:  75%|███████▍  | 122/163 [02:14<00:44,  1.09s/it, loss=0.0852, batch_acc=0.9688, running_acc=0.9308, grad=1.8802]Training epoch 12:  75%|███████▍  | 122/163 [02:14<00:44,  1.09s/it, loss=0.1146, batch_acc=1.0000, running_acc=0.9314, grad=3.1526]Training epoch 12:  75%|███████▌  | 123/163 [02:14<00:41,  1.03s/it, loss=0.1146, batch_acc=1.0000, running_acc=0.9314, grad=3.1526]Training epoch 12:  75%|███████▌  | 123/163 [02:14<00:41,  1.03s/it, loss=0.2176, batch_acc=0.9375, running_acc=0.9314, grad=5.2914]Training epoch 12:  76%|███████▌  | 124/163 [02:15<00:38,  1.02it/s, loss=0.2176, batch_acc=0.9375, running_acc=0.9314, grad=5.2914]Training epoch 12:  76%|███████▌  | 124/163 [02:15<00:38,  1.02it/s, loss=0.1317, batch_acc=0.9688, running_acc=0.9317, grad=3.6635]Training epoch 12:  77%|███████▋  | 125/163 [02:16<00:36,  1.05it/s, loss=0.1317, batch_acc=0.9688, running_acc=0.9317, grad=3.6635]Training epoch 12:  77%|███████▋  | 125/163 [02:16<00:36,  1.05it/s, loss=0.2704, batch_acc=0.9062, running_acc=0.9315, grad=5.2971]Training epoch 12:  77%|███████▋  | 126/163 [02:18<00:44,  1.20s/it, loss=0.2704, batch_acc=0.9062, running_acc=0.9315, grad=5.2971]Training epoch 12:  77%|███████▋  | 126/163 [02:18<00:44,  1.20s/it, loss=0.1158, batch_acc=0.9688, running_acc=0.9318, grad=3.5334]Training epoch 12:  78%|███████▊  | 127/163 [02:19<00:39,  1.11s/it, loss=0.1158, batch_acc=0.9688, running_acc=0.9318, grad=3.5334]Training epoch 12:  78%|███████▊  | 127/163 [02:19<00:39,  1.11s/it, loss=0.1863, batch_acc=0.9375, running_acc=0.9318, grad=4.3724]Training epoch 12:  79%|███████▊  | 128/163 [02:20<00:36,  1.04s/it, loss=0.1863, batch_acc=0.9375, running_acc=0.9318, grad=4.3724]Training epoch 12:  79%|███████▊  | 128/163 [02:20<00:36,  1.04s/it, loss=0.1971, batch_acc=0.9375, running_acc=0.9319, grad=3.3484]Training epoch 12:  79%|███████▉  | 129/163 [02:21<00:33,  1.01it/s, loss=0.1971, batch_acc=0.9375, running_acc=0.9319, grad=3.3484]Training epoch 12:  79%|███████▉  | 129/163 [02:21<00:33,  1.01it/s, loss=0.2872, batch_acc=0.9062, running_acc=0.9317, grad=5.9402]Training epoch 12:  80%|███████▉  | 130/163 [02:22<00:41,  1.26s/it, loss=0.2872, batch_acc=0.9062, running_acc=0.9317, grad=5.9402]Training epoch 12:  80%|███████▉  | 130/163 [02:22<00:41,  1.26s/it, loss=0.2399, batch_acc=0.9688, running_acc=0.9320, grad=5.6303]Training epoch 12:  80%|████████  | 131/163 [02:23<00:36,  1.15s/it, loss=0.2399, batch_acc=0.9688, running_acc=0.9320, grad=5.6303]Training epoch 12:  80%|████████  | 131/163 [02:23<00:36,  1.15s/it, loss=0.2218, batch_acc=0.9062, running_acc=0.9318, grad=4.1300]Training epoch 12:  81%|████████  | 132/163 [02:24<00:33,  1.07s/it, loss=0.2218, batch_acc=0.9062, running_acc=0.9318, grad=4.1300]Training epoch 12:  81%|████████  | 132/163 [02:24<00:33,  1.07s/it, loss=0.3005, batch_acc=0.9062, running_acc=0.9316, grad=6.5286]Training epoch 12:  82%|████████▏ | 133/163 [02:25<00:30,  1.01s/it, loss=0.3005, batch_acc=0.9062, running_acc=0.9316, grad=6.5286]Training epoch 12:  82%|████████▏ | 133/163 [02:25<00:30,  1.01s/it, loss=0.1955, batch_acc=0.9375, running_acc=0.9316, grad=4.1309]Training epoch 12:  82%|████████▏ | 134/163 [02:26<00:31,  1.08s/it, loss=0.1955, batch_acc=0.9375, running_acc=0.9316, grad=4.1309]Training epoch 12:  82%|████████▏ | 134/163 [02:26<00:31,  1.08s/it, loss=0.1308, batch_acc=0.9688, running_acc=0.9319, grad=3.4785]Training epoch 12:  83%|████████▎ | 135/163 [02:27<00:28,  1.02s/it, loss=0.1308, batch_acc=0.9688, running_acc=0.9319, grad=3.4785]Training epoch 12:  83%|████████▎ | 135/163 [02:27<00:28,  1.02s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9324, grad=1.7767]Training epoch 12:  83%|████████▎ | 136/163 [02:28<00:26,  1.02it/s, loss=0.1048, batch_acc=1.0000, running_acc=0.9324, grad=1.7767]Training epoch 12:  83%|████████▎ | 136/163 [02:28<00:26,  1.02it/s, loss=0.2009, batch_acc=0.9375, running_acc=0.9324, grad=5.5235]Training epoch 12:  84%|████████▍ | 137/163 [02:29<00:24,  1.05it/s, loss=0.2009, batch_acc=0.9375, running_acc=0.9324, grad=5.5235]Training epoch 12:  84%|████████▍ | 137/163 [02:29<00:24,  1.05it/s, loss=0.1336, batch_acc=1.0000, running_acc=0.9329, grad=3.4498]Training epoch 12:  85%|████████▍ | 138/163 [02:31<00:29,  1.20s/it, loss=0.1336, batch_acc=1.0000, running_acc=0.9329, grad=3.4498]Training epoch 12:  85%|████████▍ | 138/163 [02:31<00:29,  1.20s/it, loss=0.1372, batch_acc=0.9688, running_acc=0.9332, grad=2.8496]Training epoch 12:  85%|████████▌ | 139/163 [02:32<00:26,  1.10s/it, loss=0.1372, batch_acc=0.9688, running_acc=0.9332, grad=2.8496]Training epoch 12:  85%|████████▌ | 139/163 [02:32<00:26,  1.10s/it, loss=0.0876, batch_acc=0.9688, running_acc=0.9335, grad=2.6093]Training epoch 12:  86%|████████▌ | 140/163 [02:33<00:23,  1.04s/it, loss=0.0876, batch_acc=0.9688, running_acc=0.9335, grad=2.6093]Training epoch 12:  86%|████████▌ | 140/163 [02:33<00:23,  1.04s/it, loss=0.1671, batch_acc=0.9375, running_acc=0.9335, grad=2.7310]Training epoch 12:  87%|████████▋ | 141/163 [02:33<00:21,  1.01it/s, loss=0.1671, batch_acc=0.9375, running_acc=0.9335, grad=2.7310]Training epoch 12:  87%|████████▋ | 141/163 [02:33<00:21,  1.01it/s, loss=0.2704, batch_acc=0.9062, running_acc=0.9333, grad=5.2942]Training epoch 12:  87%|████████▋ | 142/163 [02:36<00:28,  1.35s/it, loss=0.2704, batch_acc=0.9062, running_acc=0.9333, grad=5.2942]Training epoch 12:  87%|████████▋ | 142/163 [02:36<00:28,  1.35s/it, loss=0.3504, batch_acc=0.9062, running_acc=0.9331, grad=6.2614]Training epoch 12:  88%|████████▊ | 143/163 [02:36<00:24,  1.21s/it, loss=0.3504, batch_acc=0.9062, running_acc=0.9331, grad=6.2614]Training epoch 12:  88%|████████▊ | 143/163 [02:36<00:24,  1.21s/it, loss=0.1088, batch_acc=0.9688, running_acc=0.9333, grad=3.3847]Training epoch 12:  88%|████████▊ | 144/163 [02:37<00:21,  1.11s/it, loss=0.1088, batch_acc=0.9688, running_acc=0.9333, grad=3.3847]Training epoch 12:  88%|████████▊ | 144/163 [02:37<00:21,  1.11s/it, loss=0.2449, batch_acc=0.9062, running_acc=0.9332, grad=5.6889]Training epoch 12:  89%|████████▉ | 145/163 [02:38<00:18,  1.04s/it, loss=0.2449, batch_acc=0.9062, running_acc=0.9332, grad=5.6889]Training epoch 12:  89%|████████▉ | 145/163 [02:38<00:18,  1.04s/it, loss=0.1546, batch_acc=0.9688, running_acc=0.9334, grad=6.0890]Training epoch 12:  90%|████████▉ | 146/163 [02:40<00:23,  1.36s/it, loss=0.1546, batch_acc=0.9688, running_acc=0.9334, grad=6.0890]Training epoch 12:  90%|████████▉ | 146/163 [02:40<00:23,  1.36s/it, loss=0.4357, batch_acc=0.7812, running_acc=0.9324, grad=8.5167]Training epoch 12:  90%|█████████ | 147/163 [02:41<00:19,  1.21s/it, loss=0.4357, batch_acc=0.7812, running_acc=0.9324, grad=8.5167]Training epoch 12:  90%|█████████ | 147/163 [02:41<00:19,  1.21s/it, loss=0.3263, batch_acc=0.8438, running_acc=0.9318, grad=6.1150]Training epoch 12:  91%|█████████ | 148/163 [02:42<00:16,  1.11s/it, loss=0.3263, batch_acc=0.8438, running_acc=0.9318, grad=6.1150]Training epoch 12:  91%|█████████ | 148/163 [02:42<00:16,  1.11s/it, loss=0.3172, batch_acc=0.9062, running_acc=0.9316, grad=4.9611]Training epoch 12:  91%|█████████▏| 149/163 [02:43<00:14,  1.04s/it, loss=0.3172, batch_acc=0.9062, running_acc=0.9316, grad=4.9611]Training epoch 12:  91%|█████████▏| 149/163 [02:43<00:14,  1.04s/it, loss=0.2620, batch_acc=0.9062, running_acc=0.9314, grad=8.1597]Training epoch 12:  92%|█████████▏| 150/163 [02:45<00:15,  1.21s/it, loss=0.2620, batch_acc=0.9062, running_acc=0.9314, grad=8.1597]Training epoch 12:  92%|█████████▏| 150/163 [02:45<00:15,  1.21s/it, loss=0.2160, batch_acc=0.9688, running_acc=0.9317, grad=4.9983]Training epoch 12:  93%|█████████▎| 151/163 [02:45<00:13,  1.11s/it, loss=0.2160, batch_acc=0.9688, running_acc=0.9317, grad=4.9983]Training epoch 12:  93%|█████████▎| 151/163 [02:45<00:13,  1.11s/it, loss=0.2041, batch_acc=0.9062, running_acc=0.9315, grad=6.6860]Training epoch 12:  93%|█████████▎| 152/163 [02:46<00:11,  1.04s/it, loss=0.2041, batch_acc=0.9062, running_acc=0.9315, grad=6.6860]Training epoch 12:  93%|█████████▎| 152/163 [02:46<00:11,  1.04s/it, loss=0.2257, batch_acc=0.9375, running_acc=0.9315, grad=6.7265]Training epoch 12:  94%|█████████▍| 153/163 [02:47<00:09,  1.01it/s, loss=0.2257, batch_acc=0.9375, running_acc=0.9315, grad=6.7265]Training epoch 12:  94%|█████████▍| 153/163 [02:47<00:09,  1.01it/s, loss=0.5015, batch_acc=0.8438, running_acc=0.9310, grad=9.8192]Training epoch 12:  94%|█████████▍| 154/163 [02:49<00:11,  1.30s/it, loss=0.5015, batch_acc=0.8438, running_acc=0.9310, grad=9.8192]Training epoch 12:  94%|█████████▍| 154/163 [02:49<00:11,  1.30s/it, loss=0.1013, batch_acc=1.0000, running_acc=0.9314, grad=3.2071]Training epoch 12:  95%|█████████▌| 155/163 [02:50<00:09,  1.17s/it, loss=0.1013, batch_acc=1.0000, running_acc=0.9314, grad=3.2071]Training epoch 12:  95%|█████████▌| 155/163 [02:50<00:09,  1.17s/it, loss=0.3119, batch_acc=0.9062, running_acc=0.9313, grad=10.3175]Training epoch 12:  96%|█████████▌| 156/163 [02:51<00:07,  1.08s/it, loss=0.3119, batch_acc=0.9062, running_acc=0.9313, grad=10.3175]Training epoch 12:  96%|█████████▌| 156/163 [02:51<00:07,  1.08s/it, loss=0.1655, batch_acc=1.0000, running_acc=0.9317, grad=4.3761] Training epoch 12:  96%|█████████▋| 157/163 [02:52<00:06,  1.02s/it, loss=0.1655, batch_acc=1.0000, running_acc=0.9317, grad=4.3761]Training epoch 12:  96%|█████████▋| 157/163 [02:52<00:06,  1.02s/it, loss=0.1248, batch_acc=1.0000, running_acc=0.9321, grad=4.5659]Training epoch 12:  97%|█████████▋| 158/163 [02:53<00:06,  1.20s/it, loss=0.1248, batch_acc=1.0000, running_acc=0.9321, grad=4.5659]Training epoch 12:  97%|█████████▋| 158/163 [02:53<00:06,  1.20s/it, loss=0.2022, batch_acc=0.9375, running_acc=0.9322, grad=4.6649]Training epoch 12:  98%|█████████▊| 159/163 [02:54<00:04,  1.11s/it, loss=0.2022, batch_acc=0.9375, running_acc=0.9322, grad=4.6649]Training epoch 12:  98%|█████████▊| 159/163 [02:54<00:04,  1.11s/it, loss=0.1420, batch_acc=0.9688, running_acc=0.9324, grad=3.6015]Training epoch 12:  98%|█████████▊| 160/163 [02:55<00:03,  1.04s/it, loss=0.1420, batch_acc=0.9688, running_acc=0.9324, grad=3.6015]Training epoch 12:  98%|█████████▊| 160/163 [02:55<00:03,  1.04s/it, loss=0.1585, batch_acc=0.9688, running_acc=0.9326, grad=4.4206]Training epoch 12:  99%|█████████▉| 161/163 [02:56<00:01,  1.01it/s, loss=0.1585, batch_acc=0.9688, running_acc=0.9326, grad=4.4206]Training epoch 12:  99%|█████████▉| 161/163 [02:56<00:01,  1.01it/s, loss=0.1403, batch_acc=0.9688, running_acc=0.9328, grad=3.9233]Training epoch 12:  99%|█████████▉| 162/163 [02:57<00:00,  1.04it/s, loss=0.1403, batch_acc=0.9688, running_acc=0.9328, grad=3.9233]Training epoch 12:  99%|█████████▉| 162/163 [02:57<00:00,  1.04it/s, loss=0.3289, batch_acc=0.9062, running_acc=0.9327, grad=6.0597]Training epoch 12: 100%|██████████| 163/163 [02:58<00:00,  1.16it/s, loss=0.3289, batch_acc=0.9062, running_acc=0.9327, grad=6.0597]Training epoch 12: 100%|██████████| 163/163 [02:58<00:00,  1.16it/s, loss=0.3152, batch_acc=0.9048, running_acc=0.9326, grad=8.3998]Training epoch 12: 100%|██████████| 163/163 [02:58<00:00,  1.09s/it, loss=0.3152, batch_acc=0.9048, running_acc=0.9326, grad=8.3998]
Evaluation epoch 12:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 12:   4%|▎         | 1/28 [00:05<02:17,  5.08s/it]Evaluation epoch 12:   4%|▎         | 1/28 [00:05<02:17,  5.08s/it, loss=0.5620, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 12:   7%|▋         | 2/28 [00:05<01:00,  2.32s/it, loss=0.5620, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 12:   7%|▋         | 2/28 [00:05<01:00,  2.32s/it, loss=0.2451, batch_acc=0.9375, running_acc=0.8750]Evaluation epoch 12:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=0.2451, batch_acc=0.9375, running_acc=0.8750]Evaluation epoch 12:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=0.7329, batch_acc=0.7812, running_acc=0.8438]Evaluation epoch 12:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.7329, batch_acc=0.7812, running_acc=0.8438]Evaluation epoch 12:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.5110, batch_acc=0.9062, running_acc=0.8594]Evaluation epoch 12:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=0.5110, batch_acc=0.9062, running_acc=0.8594]Evaluation epoch 12:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=1.9759, batch_acc=0.5312, running_acc=0.7937]Evaluation epoch 12:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.9759, batch_acc=0.5312, running_acc=0.7937]Evaluation epoch 12:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.4749, batch_acc=0.8750, running_acc=0.8073]Evaluation epoch 12:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.4749, batch_acc=0.8750, running_acc=0.8073]Evaluation epoch 12:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.8829, batch_acc=0.8125, running_acc=0.8080]Evaluation epoch 12:  29%|██▊       | 8/28 [00:14<00:34,  1.75s/it, loss=0.8829, batch_acc=0.8125, running_acc=0.8080]Evaluation epoch 12:  29%|██▊       | 8/28 [00:14<00:34,  1.75s/it, loss=1.2743, batch_acc=0.6250, running_acc=0.7852]Evaluation epoch 12:  32%|███▏      | 9/28 [00:14<00:24,  1.30s/it, loss=1.2743, batch_acc=0.6250, running_acc=0.7852]Evaluation epoch 12:  32%|███▏      | 9/28 [00:14<00:24,  1.30s/it, loss=0.9078, batch_acc=0.7500, running_acc=0.7812]Evaluation epoch 12:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.9078, batch_acc=0.7500, running_acc=0.7812]Evaluation epoch 12:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.3486, batch_acc=0.9375, running_acc=0.7969]Evaluation epoch 12:  39%|███▉      | 11/28 [00:15<00:12,  1.31it/s, loss=0.3486, batch_acc=0.9375, running_acc=0.7969]Evaluation epoch 12:  39%|███▉      | 11/28 [00:15<00:12,  1.31it/s, loss=0.4147, batch_acc=0.8750, running_acc=0.8040]Evaluation epoch 12:  43%|████▎     | 12/28 [00:20<00:36,  2.26s/it, loss=0.4147, batch_acc=0.8750, running_acc=0.8040]Evaluation epoch 12:  43%|████▎     | 12/28 [00:20<00:36,  2.26s/it, loss=0.8964, batch_acc=0.7188, running_acc=0.7969]Evaluation epoch 12:  46%|████▋     | 13/28 [00:21<00:24,  1.65s/it, loss=0.8964, batch_acc=0.7188, running_acc=0.7969]Evaluation epoch 12:  46%|████▋     | 13/28 [00:21<00:24,  1.65s/it, loss=0.2754, batch_acc=0.8750, running_acc=0.8029]Evaluation epoch 12:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=0.2754, batch_acc=0.8750, running_acc=0.8029]Evaluation epoch 12:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=1.1802, batch_acc=0.6875, running_acc=0.7946]Evaluation epoch 12:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.1802, batch_acc=0.6875, running_acc=0.7946]Evaluation epoch 12:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.5819, batch_acc=0.5625, running_acc=0.7792]Evaluation epoch 12:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=1.5819, batch_acc=0.5625, running_acc=0.7792]Evaluation epoch 12:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=0.6484, batch_acc=0.8750, running_acc=0.7852]Evaluation epoch 12:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.6484, batch_acc=0.8750, running_acc=0.7852]Evaluation epoch 12:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.4868, batch_acc=0.8750, running_acc=0.7904]Evaluation epoch 12:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.4868, batch_acc=0.8750, running_acc=0.7904]Evaluation epoch 12:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.6639, batch_acc=0.7500, running_acc=0.7882]Evaluation epoch 12:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=0.6639, batch_acc=0.7500, running_acc=0.7882]Evaluation epoch 12:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=1.0262, batch_acc=0.5938, running_acc=0.7780]Evaluation epoch 12:  71%|███████▏  | 20/28 [00:28<00:11,  1.38s/it, loss=1.0262, batch_acc=0.5938, running_acc=0.7780]Evaluation epoch 12:  71%|███████▏  | 20/28 [00:28<00:11,  1.38s/it, loss=0.6465, batch_acc=0.6875, running_acc=0.7734]Evaluation epoch 12:  75%|███████▌  | 21/28 [00:28<00:07,  1.05s/it, loss=0.6465, batch_acc=0.6875, running_acc=0.7734]Evaluation epoch 12:  75%|███████▌  | 21/28 [00:28<00:07,  1.05s/it, loss=0.8276, batch_acc=0.7812, running_acc=0.7738]Evaluation epoch 12:  79%|███████▊  | 22/28 [00:28<00:04,  1.23it/s, loss=0.8276, batch_acc=0.7812, running_acc=0.7738]Evaluation epoch 12:  79%|███████▊  | 22/28 [00:28<00:04,  1.23it/s, loss=0.9131, batch_acc=0.7500, running_acc=0.7727]Evaluation epoch 12:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=0.9131, batch_acc=0.7500, running_acc=0.7727]Evaluation epoch 12:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=1.0414, batch_acc=0.6875, running_acc=0.7690]Evaluation epoch 12:  86%|████████▌ | 24/28 [00:34<00:08,  2.01s/it, loss=1.0414, batch_acc=0.6875, running_acc=0.7690]Evaluation epoch 12:  86%|████████▌ | 24/28 [00:34<00:08,  2.01s/it, loss=0.3241, batch_acc=0.8438, running_acc=0.7721]Evaluation epoch 12:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.3241, batch_acc=0.8438, running_acc=0.7721]Evaluation epoch 12:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.0951, batch_acc=0.9688, running_acc=0.7800]Evaluation epoch 12:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.0951, batch_acc=0.9688, running_acc=0.7800]Evaluation epoch 12:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.8440, batch_acc=0.7500, running_acc=0.7788]Evaluation epoch 12:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.8440, batch_acc=0.7500, running_acc=0.7788]Evaluation epoch 12:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=1.0293, batch_acc=0.6875, running_acc=0.7755]Evaluation epoch 12: 100%|██████████| 28/28 [00:35<00:00,  1.16it/s, loss=0.3254, batch_acc=1.0000, running_acc=0.7762]Evaluation epoch 12: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=0.3254, batch_acc=1.0000, running_acc=0.7762]
Training epoch 13:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 13:   1%|          | 1/163 [00:05<15:48,  5.86s/it]Training epoch 13:   1%|          | 1/163 [00:05<15:48,  5.86s/it, loss=0.2122, batch_acc=0.8750, running_acc=0.8750, grad=3.3627]Training epoch 13:   1%|          | 2/163 [00:06<07:51,  2.93s/it, loss=0.2122, batch_acc=0.8750, running_acc=0.8750, grad=3.3627]Training epoch 13:   1%|          | 2/163 [00:06<07:51,  2.93s/it, loss=0.1786, batch_acc=0.9375, running_acc=0.9062, grad=3.4365]Training epoch 13:   2%|▏         | 3/163 [00:07<05:19,  2.00s/it, loss=0.1786, batch_acc=0.9375, running_acc=0.9062, grad=3.4365]Training epoch 13:   2%|▏         | 3/163 [00:07<05:19,  2.00s/it, loss=0.0500, batch_acc=1.0000, running_acc=0.9375, grad=0.9651]Training epoch 13:   2%|▏         | 4/163 [00:10<05:42,  2.15s/it, loss=0.0500, batch_acc=1.0000, running_acc=0.9375, grad=0.9651]Training epoch 13:   2%|▏         | 4/163 [00:10<05:42,  2.15s/it, loss=0.1659, batch_acc=1.0000, running_acc=0.9531, grad=4.6823]Training epoch 13:   3%|▎         | 5/163 [00:10<04:27,  1.69s/it, loss=0.1659, batch_acc=1.0000, running_acc=0.9531, grad=4.6823]Training epoch 13:   3%|▎         | 5/163 [00:10<04:27,  1.69s/it, loss=0.0731, batch_acc=0.9688, running_acc=0.9563, grad=1.1439]Training epoch 13:   4%|▎         | 6/163 [00:11<03:42,  1.42s/it, loss=0.0731, batch_acc=0.9688, running_acc=0.9563, grad=1.1439]Training epoch 13:   4%|▎         | 6/163 [00:11<03:42,  1.42s/it, loss=0.0678, batch_acc=0.9688, running_acc=0.9583, grad=1.1104]Training epoch 13:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=0.0678, batch_acc=0.9688, running_acc=0.9583, grad=1.1104]Training epoch 13:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=0.1311, batch_acc=0.9375, running_acc=0.9554, grad=2.6780]Training epoch 13:   5%|▍         | 8/163 [00:14<03:30,  1.36s/it, loss=0.1311, batch_acc=0.9375, running_acc=0.9554, grad=2.6780]Training epoch 13:   5%|▍         | 8/163 [00:14<03:30,  1.36s/it, loss=0.1618, batch_acc=0.9062, running_acc=0.9492, grad=6.4108]Training epoch 13:   6%|▌         | 9/163 [00:15<03:06,  1.21s/it, loss=0.1618, batch_acc=0.9062, running_acc=0.9492, grad=6.4108]Training epoch 13:   6%|▌         | 9/163 [00:15<03:06,  1.21s/it, loss=0.0697, batch_acc=1.0000, running_acc=0.9549, grad=1.4995]Training epoch 13:   6%|▌         | 10/163 [00:16<02:49,  1.11s/it, loss=0.0697, batch_acc=1.0000, running_acc=0.9549, grad=1.4995]Training epoch 13:   6%|▌         | 10/163 [00:16<02:49,  1.11s/it, loss=0.2950, batch_acc=0.9062, running_acc=0.9500, grad=7.1350]Training epoch 13:   7%|▋         | 11/163 [00:16<02:38,  1.04s/it, loss=0.2950, batch_acc=0.9062, running_acc=0.9500, grad=7.1350]Training epoch 13:   7%|▋         | 11/163 [00:16<02:38,  1.04s/it, loss=0.0810, batch_acc=1.0000, running_acc=0.9545, grad=2.8275]Training epoch 13:   7%|▋         | 12/163 [00:18<02:52,  1.15s/it, loss=0.0810, batch_acc=1.0000, running_acc=0.9545, grad=2.8275]Training epoch 13:   7%|▋         | 12/163 [00:18<02:52,  1.15s/it, loss=0.0538, batch_acc=1.0000, running_acc=0.9583, grad=1.8101]Training epoch 13:   8%|▊         | 13/163 [00:19<02:52,  1.15s/it, loss=0.0538, batch_acc=1.0000, running_acc=0.9583, grad=1.8101]Training epoch 13:   8%|▊         | 13/163 [00:19<02:52,  1.15s/it, loss=0.1248, batch_acc=0.9062, running_acc=0.9543, grad=4.5807]Training epoch 13:   9%|▊         | 14/163 [00:20<02:39,  1.07s/it, loss=0.1248, batch_acc=0.9062, running_acc=0.9543, grad=4.5807]Training epoch 13:   9%|▊         | 14/163 [00:20<02:39,  1.07s/it, loss=0.1279, batch_acc=1.0000, running_acc=0.9576, grad=4.5601]Training epoch 13:   9%|▉         | 15/163 [00:21<02:29,  1.01s/it, loss=0.1279, batch_acc=1.0000, running_acc=0.9576, grad=4.5601]Training epoch 13:   9%|▉         | 15/163 [00:21<02:29,  1.01s/it, loss=0.1321, batch_acc=0.9688, running_acc=0.9583, grad=3.8818]Training epoch 13:  10%|▉         | 16/163 [00:22<02:45,  1.13s/it, loss=0.1321, batch_acc=0.9688, running_acc=0.9583, grad=3.8818]Training epoch 13:  10%|▉         | 16/163 [00:22<02:45,  1.13s/it, loss=0.2189, batch_acc=0.9062, running_acc=0.9551, grad=4.6464]Training epoch 13:  10%|█         | 17/163 [00:24<03:06,  1.28s/it, loss=0.2189, batch_acc=0.9062, running_acc=0.9551, grad=4.6464]Training epoch 13:  10%|█         | 17/163 [00:24<03:06,  1.28s/it, loss=0.1711, batch_acc=0.9375, running_acc=0.9540, grad=3.2596]Training epoch 13:  11%|█         | 18/163 [00:25<02:48,  1.16s/it, loss=0.1711, batch_acc=0.9375, running_acc=0.9540, grad=3.2596]Training epoch 13:  11%|█         | 18/163 [00:25<02:48,  1.16s/it, loss=0.1257, batch_acc=0.9375, running_acc=0.9531, grad=3.1579]Training epoch 13:  12%|█▏        | 19/163 [00:26<02:34,  1.08s/it, loss=0.1257, batch_acc=0.9375, running_acc=0.9531, grad=3.1579]Training epoch 13:  12%|█▏        | 19/163 [00:26<02:34,  1.08s/it, loss=0.0505, batch_acc=1.0000, running_acc=0.9556, grad=1.6219]Training epoch 13:  12%|█▏        | 20/163 [00:27<02:33,  1.07s/it, loss=0.0505, batch_acc=1.0000, running_acc=0.9556, grad=1.6219]Training epoch 13:  12%|█▏        | 20/163 [00:27<02:33,  1.07s/it, loss=0.0993, batch_acc=0.9688, running_acc=0.9563, grad=2.0780]Training epoch 13:  13%|█▎        | 21/163 [00:29<03:15,  1.38s/it, loss=0.0993, batch_acc=0.9688, running_acc=0.9563, grad=2.0780]Training epoch 13:  13%|█▎        | 21/163 [00:29<03:15,  1.38s/it, loss=0.1472, batch_acc=0.9375, running_acc=0.9554, grad=3.8122]Training epoch 13:  13%|█▎        | 22/163 [00:30<02:53,  1.23s/it, loss=0.1472, batch_acc=0.9375, running_acc=0.9554, grad=3.8122]Training epoch 13:  13%|█▎        | 22/163 [00:30<02:53,  1.23s/it, loss=0.1005, batch_acc=0.9688, running_acc=0.9560, grad=3.8526]Training epoch 13:  14%|█▍        | 23/163 [00:30<02:37,  1.12s/it, loss=0.1005, batch_acc=0.9688, running_acc=0.9560, grad=3.8526]Training epoch 13:  14%|█▍        | 23/163 [00:30<02:37,  1.12s/it, loss=0.1548, batch_acc=0.9375, running_acc=0.9552, grad=2.1727]Training epoch 13:  15%|█▍        | 24/163 [00:31<02:25,  1.05s/it, loss=0.1548, batch_acc=0.9375, running_acc=0.9552, grad=2.1727]Training epoch 13:  15%|█▍        | 24/163 [00:31<02:25,  1.05s/it, loss=0.1458, batch_acc=0.9688, running_acc=0.9557, grad=5.0858]Training epoch 13:  15%|█▌        | 25/163 [00:33<03:06,  1.36s/it, loss=0.1458, batch_acc=0.9688, running_acc=0.9557, grad=5.0858]Training epoch 13:  15%|█▌        | 25/163 [00:33<03:06,  1.36s/it, loss=0.1260, batch_acc=0.9062, running_acc=0.9537, grad=1.8244]Training epoch 13:  16%|█▌        | 26/163 [00:34<02:46,  1.21s/it, loss=0.1260, batch_acc=0.9062, running_acc=0.9537, grad=1.8244]Training epoch 13:  16%|█▌        | 26/163 [00:34<02:46,  1.21s/it, loss=0.1027, batch_acc=0.9688, running_acc=0.9543, grad=3.4202]Training epoch 13:  17%|█▋        | 27/163 [00:35<02:31,  1.11s/it, loss=0.1027, batch_acc=0.9688, running_acc=0.9543, grad=3.4202]Training epoch 13:  17%|█▋        | 27/163 [00:35<02:31,  1.11s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9549, grad=5.9692]Training epoch 13:  17%|█▋        | 28/163 [00:36<02:20,  1.04s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9549, grad=5.9692]Training epoch 13:  17%|█▋        | 28/163 [00:36<02:20,  1.04s/it, loss=0.3424, batch_acc=0.8438, running_acc=0.9509, grad=5.5783]Training epoch 13:  18%|█▊        | 29/163 [00:37<02:29,  1.12s/it, loss=0.3424, batch_acc=0.8438, running_acc=0.9509, grad=5.5783]Training epoch 13:  18%|█▊        | 29/163 [00:37<02:29,  1.12s/it, loss=0.1775, batch_acc=0.9375, running_acc=0.9504, grad=4.8314]Training epoch 13:  18%|█▊        | 30/163 [00:38<02:19,  1.05s/it, loss=0.1775, batch_acc=0.9375, running_acc=0.9504, grad=4.8314]Training epoch 13:  18%|█▊        | 30/163 [00:38<02:19,  1.05s/it, loss=0.0910, batch_acc=0.9688, running_acc=0.9510, grad=3.9552]Training epoch 13:  19%|█▉        | 31/163 [00:39<02:11,  1.00it/s, loss=0.0910, batch_acc=0.9688, running_acc=0.9510, grad=3.9552]Training epoch 13:  19%|█▉        | 31/163 [00:39<02:11,  1.00it/s, loss=0.1493, batch_acc=1.0000, running_acc=0.9526, grad=4.4464]Training epoch 13:  20%|█▉        | 32/163 [00:40<02:25,  1.11s/it, loss=0.1493, batch_acc=1.0000, running_acc=0.9526, grad=4.4464]Training epoch 13:  20%|█▉        | 32/163 [00:40<02:25,  1.11s/it, loss=0.1190, batch_acc=0.9688, running_acc=0.9531, grad=2.2867]Training epoch 13:  20%|██        | 33/163 [00:42<02:29,  1.15s/it, loss=0.1190, batch_acc=0.9688, running_acc=0.9531, grad=2.2867]Training epoch 13:  20%|██        | 33/163 [00:42<02:29,  1.15s/it, loss=0.2188, batch_acc=0.9062, running_acc=0.9517, grad=3.9989]Training epoch 13:  21%|██        | 34/163 [00:43<02:17,  1.07s/it, loss=0.2188, batch_acc=0.9062, running_acc=0.9517, grad=3.9989]Training epoch 13:  21%|██        | 34/163 [00:43<02:17,  1.07s/it, loss=0.1192, batch_acc=0.9688, running_acc=0.9522, grad=4.4606]Training epoch 13:  21%|██▏       | 35/163 [00:43<02:09,  1.01s/it, loss=0.1192, batch_acc=0.9688, running_acc=0.9522, grad=4.4606]Training epoch 13:  21%|██▏       | 35/163 [00:43<02:09,  1.01s/it, loss=0.0957, batch_acc=0.9688, running_acc=0.9527, grad=2.7945]Training epoch 13:  22%|██▏       | 36/163 [00:45<02:27,  1.17s/it, loss=0.0957, batch_acc=0.9688, running_acc=0.9527, grad=2.7945]Training epoch 13:  22%|██▏       | 36/163 [00:45<02:27,  1.17s/it, loss=0.2376, batch_acc=0.9688, running_acc=0.9531, grad=5.9303]Training epoch 13:  23%|██▎       | 37/163 [00:46<02:36,  1.24s/it, loss=0.2376, batch_acc=0.9688, running_acc=0.9531, grad=5.9303]Training epoch 13:  23%|██▎       | 37/163 [00:46<02:36,  1.24s/it, loss=0.1463, batch_acc=0.9375, running_acc=0.9527, grad=4.7300]Training epoch 13:  23%|██▎       | 38/163 [00:47<02:21,  1.13s/it, loss=0.1463, batch_acc=0.9375, running_acc=0.9527, grad=4.7300]Training epoch 13:  23%|██▎       | 38/163 [00:47<02:21,  1.13s/it, loss=0.1211, batch_acc=0.9688, running_acc=0.9531, grad=4.8241]Training epoch 13:  24%|██▍       | 39/163 [00:48<02:11,  1.06s/it, loss=0.1211, batch_acc=0.9688, running_acc=0.9531, grad=4.8241]Training epoch 13:  24%|██▍       | 39/163 [00:48<02:11,  1.06s/it, loss=0.0878, batch_acc=0.9688, running_acc=0.9535, grad=1.5123]Training epoch 13:  25%|██▍       | 40/163 [00:49<02:09,  1.05s/it, loss=0.0878, batch_acc=0.9688, running_acc=0.9535, grad=1.5123]Training epoch 13:  25%|██▍       | 40/163 [00:49<02:09,  1.05s/it, loss=0.1416, batch_acc=0.9375, running_acc=0.9531, grad=3.3798]Training epoch 13:  25%|██▌       | 41/163 [00:51<02:39,  1.31s/it, loss=0.1416, batch_acc=0.9375, running_acc=0.9531, grad=3.3798]Training epoch 13:  25%|██▌       | 41/163 [00:51<02:39,  1.31s/it, loss=0.3106, batch_acc=0.8438, running_acc=0.9505, grad=6.9766]Training epoch 13:  26%|██▌       | 42/163 [00:52<02:22,  1.18s/it, loss=0.3106, batch_acc=0.8438, running_acc=0.9505, grad=6.9766]Training epoch 13:  26%|██▌       | 42/163 [00:52<02:22,  1.18s/it, loss=0.1663, batch_acc=0.9062, running_acc=0.9494, grad=3.2235]Training epoch 13:  26%|██▋       | 43/163 [00:53<02:10,  1.09s/it, loss=0.1663, batch_acc=0.9062, running_acc=0.9494, grad=3.2235]Training epoch 13:  26%|██▋       | 43/163 [00:53<02:10,  1.09s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9506, grad=1.6853]Training epoch 13:  27%|██▋       | 44/163 [00:54<02:11,  1.10s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9506, grad=1.6853]Training epoch 13:  27%|██▋       | 44/163 [00:54<02:11,  1.10s/it, loss=0.0851, batch_acc=0.9375, running_acc=0.9503, grad=1.1982]Training epoch 13:  28%|██▊       | 45/163 [00:56<02:25,  1.23s/it, loss=0.0851, batch_acc=0.9375, running_acc=0.9503, grad=1.1982]Training epoch 13:  28%|██▊       | 45/163 [00:56<02:25,  1.23s/it, loss=0.1868, batch_acc=0.9375, running_acc=0.9500, grad=4.1885]Training epoch 13:  28%|██▊       | 46/163 [00:56<02:11,  1.13s/it, loss=0.1868, batch_acc=0.9375, running_acc=0.9500, grad=4.1885]Training epoch 13:  28%|██▊       | 46/163 [00:56<02:11,  1.13s/it, loss=0.1271, batch_acc=0.9688, running_acc=0.9504, grad=4.3273]Training epoch 13:  29%|██▉       | 47/163 [00:57<02:01,  1.05s/it, loss=0.1271, batch_acc=0.9688, running_acc=0.9504, grad=4.3273]Training epoch 13:  29%|██▉       | 47/163 [00:57<02:01,  1.05s/it, loss=0.1284, batch_acc=0.9688, running_acc=0.9508, grad=4.5081]Training epoch 13:  29%|██▉       | 48/163 [00:59<02:10,  1.14s/it, loss=0.1284, batch_acc=0.9688, running_acc=0.9508, grad=4.5081]Training epoch 13:  29%|██▉       | 48/163 [00:59<02:10,  1.14s/it, loss=0.1528, batch_acc=0.9375, running_acc=0.9505, grad=2.9084]Training epoch 13:  30%|███       | 49/163 [01:00<02:27,  1.29s/it, loss=0.1528, batch_acc=0.9375, running_acc=0.9505, grad=2.9084]Training epoch 13:  30%|███       | 49/163 [01:00<02:27,  1.29s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9515, grad=3.3614]Training epoch 13:  31%|███       | 50/163 [01:01<02:11,  1.17s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9515, grad=3.3614]Training epoch 13:  31%|███       | 50/163 [01:01<02:11,  1.17s/it, loss=0.1371, batch_acc=0.9375, running_acc=0.9513, grad=4.4552]Training epoch 13:  31%|███▏      | 51/163 [01:02<02:00,  1.08s/it, loss=0.1371, batch_acc=0.9375, running_acc=0.9513, grad=4.4552]Training epoch 13:  31%|███▏      | 51/163 [01:02<02:00,  1.08s/it, loss=0.0923, batch_acc=0.9688, running_acc=0.9516, grad=1.9288]Training epoch 13:  32%|███▏      | 52/163 [01:03<01:53,  1.02s/it, loss=0.0923, batch_acc=0.9688, running_acc=0.9516, grad=1.9288]Training epoch 13:  32%|███▏      | 52/163 [01:03<01:53,  1.02s/it, loss=0.0729, batch_acc=1.0000, running_acc=0.9525, grad=2.3567]Training epoch 13:  33%|███▎      | 53/163 [01:04<02:00,  1.09s/it, loss=0.0729, batch_acc=1.0000, running_acc=0.9525, grad=2.3567]Training epoch 13:  33%|███▎      | 53/163 [01:04<02:00,  1.09s/it, loss=0.1169, batch_acc=1.0000, running_acc=0.9534, grad=3.8383]Training epoch 13:  33%|███▎      | 54/163 [01:05<01:52,  1.03s/it, loss=0.1169, batch_acc=1.0000, running_acc=0.9534, grad=3.8383]Training epoch 13:  33%|███▎      | 54/163 [01:05<01:52,  1.03s/it, loss=0.2045, batch_acc=0.9375, running_acc=0.9531, grad=7.5203]Training epoch 13:  34%|███▎      | 55/163 [01:06<01:46,  1.02it/s, loss=0.2045, batch_acc=0.9375, running_acc=0.9531, grad=7.5203]Training epoch 13:  34%|███▎      | 55/163 [01:06<01:46,  1.02it/s, loss=0.2499, batch_acc=0.9062, running_acc=0.9523, grad=6.9920]Training epoch 13:  34%|███▍      | 56/163 [01:07<01:58,  1.11s/it, loss=0.2499, batch_acc=0.9062, running_acc=0.9523, grad=6.9920]Training epoch 13:  34%|███▍      | 56/163 [01:07<01:58,  1.11s/it, loss=0.0768, batch_acc=1.0000, running_acc=0.9531, grad=2.2210]Training epoch 13:  35%|███▍      | 57/163 [01:08<01:50,  1.04s/it, loss=0.0768, batch_acc=1.0000, running_acc=0.9531, grad=2.2210]Training epoch 13:  35%|███▍      | 57/163 [01:08<01:50,  1.04s/it, loss=0.1362, batch_acc=0.9688, running_acc=0.9534, grad=4.5547]Training epoch 13:  36%|███▌      | 58/163 [01:09<01:44,  1.01it/s, loss=0.1362, batch_acc=0.9688, running_acc=0.9534, grad=4.5547]Training epoch 13:  36%|███▌      | 58/163 [01:09<01:44,  1.01it/s, loss=0.1680, batch_acc=0.9688, running_acc=0.9537, grad=5.5063]Training epoch 13:  36%|███▌      | 59/163 [01:10<01:39,  1.04it/s, loss=0.1680, batch_acc=0.9688, running_acc=0.9537, grad=5.5063]Training epoch 13:  36%|███▌      | 59/163 [01:10<01:39,  1.04it/s, loss=0.0404, batch_acc=1.0000, running_acc=0.9544, grad=1.6749]Training epoch 13:  37%|███▋      | 60/163 [01:12<02:17,  1.33s/it, loss=0.0404, batch_acc=1.0000, running_acc=0.9544, grad=1.6749]Training epoch 13:  37%|███▋      | 60/163 [01:12<02:17,  1.33s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9547, grad=3.0312]Training epoch 13:  37%|███▋      | 61/163 [01:13<02:01,  1.19s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9547, grad=3.0312]Training epoch 13:  37%|███▋      | 61/163 [01:13<02:01,  1.19s/it, loss=0.1402, batch_acc=1.0000, running_acc=0.9554, grad=4.7871]Training epoch 13:  38%|███▊      | 62/163 [01:14<01:51,  1.10s/it, loss=0.1402, batch_acc=1.0000, running_acc=0.9554, grad=4.7871]Training epoch 13:  38%|███▊      | 62/163 [01:14<01:51,  1.10s/it, loss=0.0789, batch_acc=1.0000, running_acc=0.9561, grad=2.6888]Training epoch 13:  39%|███▊      | 63/163 [01:15<01:43,  1.03s/it, loss=0.0789, batch_acc=1.0000, running_acc=0.9561, grad=2.6888]Training epoch 13:  39%|███▊      | 63/163 [01:15<01:43,  1.03s/it, loss=0.1575, batch_acc=0.9375, running_acc=0.9559, grad=5.9247]Training epoch 13:  39%|███▉      | 64/163 [01:16<01:46,  1.08s/it, loss=0.1575, batch_acc=0.9375, running_acc=0.9559, grad=5.9247]Training epoch 13:  39%|███▉      | 64/163 [01:16<01:46,  1.08s/it, loss=0.1022, batch_acc=1.0000, running_acc=0.9565, grad=3.7833]Training epoch 13:  40%|███▉      | 65/163 [01:17<01:39,  1.02s/it, loss=0.1022, batch_acc=1.0000, running_acc=0.9565, grad=3.7833]Training epoch 13:  40%|███▉      | 65/163 [01:17<01:39,  1.02s/it, loss=0.1807, batch_acc=0.9375, running_acc=0.9563, grad=4.2526]Training epoch 13:  40%|████      | 66/163 [01:18<01:34,  1.02it/s, loss=0.1807, batch_acc=0.9375, running_acc=0.9563, grad=4.2526]Training epoch 13:  40%|████      | 66/163 [01:18<01:34,  1.02it/s, loss=0.0579, batch_acc=1.0000, running_acc=0.9569, grad=1.8416]Training epoch 13:  41%|████      | 67/163 [01:19<01:30,  1.06it/s, loss=0.0579, batch_acc=1.0000, running_acc=0.9569, grad=1.8416]Training epoch 13:  41%|████      | 67/163 [01:19<01:30,  1.06it/s, loss=0.2247, batch_acc=0.9375, running_acc=0.9566, grad=4.8191]Training epoch 13:  42%|████▏     | 68/163 [01:21<01:59,  1.26s/it, loss=0.2247, batch_acc=0.9375, running_acc=0.9566, grad=4.8191]Training epoch 13:  42%|████▏     | 68/163 [01:21<01:59,  1.26s/it, loss=0.1403, batch_acc=0.9375, running_acc=0.9563, grad=4.1829]Training epoch 13:  42%|████▏     | 69/163 [01:21<01:47,  1.15s/it, loss=0.1403, batch_acc=0.9375, running_acc=0.9563, grad=4.1829]Training epoch 13:  42%|████▏     | 69/163 [01:21<01:47,  1.15s/it, loss=0.0444, batch_acc=1.0000, running_acc=0.9570, grad=1.9619]Training epoch 13:  43%|████▎     | 70/163 [01:22<01:39,  1.07s/it, loss=0.0444, batch_acc=1.0000, running_acc=0.9570, grad=1.9619]Training epoch 13:  43%|████▎     | 70/163 [01:22<01:39,  1.07s/it, loss=0.3517, batch_acc=0.8750, running_acc=0.9558, grad=8.6456]Training epoch 13:  44%|████▎     | 71/163 [01:23<01:32,  1.01s/it, loss=0.3517, batch_acc=0.8750, running_acc=0.9558, grad=8.6456]Training epoch 13:  44%|████▎     | 71/163 [01:23<01:32,  1.01s/it, loss=0.2318, batch_acc=0.9062, running_acc=0.9551, grad=4.0067]Training epoch 13:  44%|████▍     | 72/163 [01:25<01:44,  1.15s/it, loss=0.2318, batch_acc=0.9062, running_acc=0.9551, grad=4.0067]Training epoch 13:  44%|████▍     | 72/163 [01:25<01:44,  1.15s/it, loss=0.3021, batch_acc=0.8750, running_acc=0.9540, grad=7.6958]Training epoch 13:  45%|████▍     | 73/163 [01:26<01:36,  1.07s/it, loss=0.3021, batch_acc=0.8750, running_acc=0.9540, grad=7.6958]Training epoch 13:  45%|████▍     | 73/163 [01:26<01:36,  1.07s/it, loss=0.2603, batch_acc=0.8750, running_acc=0.9529, grad=6.5435]Training epoch 13:  45%|████▌     | 74/163 [01:26<01:30,  1.01s/it, loss=0.2603, batch_acc=0.8750, running_acc=0.9529, grad=6.5435]Training epoch 13:  45%|████▌     | 74/163 [01:26<01:30,  1.01s/it, loss=0.1133, batch_acc=0.9688, running_acc=0.9531, grad=2.3290]Training epoch 13:  46%|████▌     | 75/163 [01:27<01:25,  1.03it/s, loss=0.1133, batch_acc=0.9688, running_acc=0.9531, grad=2.3290]Training epoch 13:  46%|████▌     | 75/163 [01:27<01:25,  1.03it/s, loss=0.0922, batch_acc=0.9688, running_acc=0.9533, grad=2.7374]Training epoch 13:  47%|████▋     | 76/163 [01:29<01:43,  1.19s/it, loss=0.0922, batch_acc=0.9688, running_acc=0.9533, grad=2.7374]Training epoch 13:  47%|████▋     | 76/163 [01:29<01:43,  1.19s/it, loss=0.2165, batch_acc=0.9062, running_acc=0.9527, grad=5.4340]Training epoch 13:  47%|████▋     | 77/163 [01:30<01:34,  1.10s/it, loss=0.2165, batch_acc=0.9062, running_acc=0.9527, grad=5.4340]Training epoch 13:  47%|████▋     | 77/163 [01:30<01:34,  1.10s/it, loss=0.1401, batch_acc=0.9375, running_acc=0.9525, grad=3.7615]Training epoch 13:  48%|████▊     | 78/163 [01:31<01:27,  1.03s/it, loss=0.1401, batch_acc=0.9375, running_acc=0.9525, grad=3.7615]Training epoch 13:  48%|████▊     | 78/163 [01:31<01:27,  1.03s/it, loss=0.1009, batch_acc=1.0000, running_acc=0.9531, grad=3.5062]Training epoch 13:  48%|████▊     | 79/163 [01:32<01:22,  1.01it/s, loss=0.1009, batch_acc=1.0000, running_acc=0.9531, grad=3.5062]Training epoch 13:  48%|████▊     | 79/163 [01:32<01:22,  1.01it/s, loss=0.0685, batch_acc=1.0000, running_acc=0.9537, grad=2.3281]Training epoch 13:  49%|████▉     | 80/163 [01:33<01:35,  1.15s/it, loss=0.0685, batch_acc=1.0000, running_acc=0.9537, grad=2.3281]Training epoch 13:  49%|████▉     | 80/163 [01:33<01:35,  1.15s/it, loss=0.2203, batch_acc=0.9375, running_acc=0.9535, grad=7.4963]Training epoch 13:  50%|████▉     | 81/163 [01:34<01:27,  1.07s/it, loss=0.2203, batch_acc=0.9375, running_acc=0.9535, grad=7.4963]Training epoch 13:  50%|████▉     | 81/163 [01:34<01:27,  1.07s/it, loss=0.0614, batch_acc=0.9688, running_acc=0.9537, grad=1.6364]Training epoch 13:  50%|█████     | 82/163 [01:35<01:21,  1.01s/it, loss=0.0614, batch_acc=0.9688, running_acc=0.9537, grad=1.6364]Training epoch 13:  50%|█████     | 82/163 [01:35<01:21,  1.01s/it, loss=0.2195, batch_acc=0.9688, running_acc=0.9539, grad=5.0583]Training epoch 13:  51%|█████     | 83/163 [01:36<01:17,  1.03it/s, loss=0.2195, batch_acc=0.9688, running_acc=0.9539, grad=5.0583]Training epoch 13:  51%|█████     | 83/163 [01:36<01:17,  1.03it/s, loss=0.1882, batch_acc=0.9375, running_acc=0.9537, grad=5.7446]Training epoch 13:  52%|█████▏    | 84/163 [01:37<01:25,  1.08s/it, loss=0.1882, batch_acc=0.9375, running_acc=0.9537, grad=5.7446]Training epoch 13:  52%|█████▏    | 84/163 [01:37<01:25,  1.08s/it, loss=0.0900, batch_acc=1.0000, running_acc=0.9542, grad=2.1830]Training epoch 13:  52%|█████▏    | 85/163 [01:38<01:21,  1.04s/it, loss=0.0900, batch_acc=1.0000, running_acc=0.9542, grad=2.1830]Training epoch 13:  52%|█████▏    | 85/163 [01:38<01:21,  1.04s/it, loss=0.2908, batch_acc=0.9062, running_acc=0.9537, grad=6.2313]Training epoch 13:  53%|█████▎    | 86/163 [01:39<01:16,  1.01it/s, loss=0.2908, batch_acc=0.9062, running_acc=0.9537, grad=6.2313]Training epoch 13:  53%|█████▎    | 86/163 [01:39<01:16,  1.01it/s, loss=0.1959, batch_acc=0.9375, running_acc=0.9535, grad=5.2288]Training epoch 13:  53%|█████▎    | 87/163 [01:40<01:12,  1.04it/s, loss=0.1959, batch_acc=0.9375, running_acc=0.9535, grad=5.2288]Training epoch 13:  53%|█████▎    | 87/163 [01:40<01:12,  1.04it/s, loss=0.1457, batch_acc=0.9688, running_acc=0.9537, grad=4.0555]Training epoch 13:  54%|█████▍    | 88/163 [01:41<01:19,  1.06s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9537, grad=4.0555]Training epoch 13:  54%|█████▍    | 88/163 [01:41<01:19,  1.06s/it, loss=0.1636, batch_acc=0.9375, running_acc=0.9535, grad=4.0441]Training epoch 13:  55%|█████▍    | 89/163 [01:42<01:20,  1.09s/it, loss=0.1636, batch_acc=0.9375, running_acc=0.9535, grad=4.0441]Training epoch 13:  55%|█████▍    | 89/163 [01:42<01:20,  1.09s/it, loss=0.1088, batch_acc=0.9375, running_acc=0.9533, grad=2.1426]Training epoch 13:  55%|█████▌    | 90/163 [01:43<01:14,  1.03s/it, loss=0.1088, batch_acc=0.9375, running_acc=0.9533, grad=2.1426]Training epoch 13:  55%|█████▌    | 90/163 [01:43<01:14,  1.03s/it, loss=0.2543, batch_acc=0.9062, running_acc=0.9528, grad=7.0614]Training epoch 13:  56%|█████▌    | 91/163 [01:44<01:10,  1.02it/s, loss=0.2543, batch_acc=0.9062, running_acc=0.9528, grad=7.0614]Training epoch 13:  56%|█████▌    | 91/163 [01:44<01:10,  1.02it/s, loss=0.2762, batch_acc=0.9062, running_acc=0.9523, grad=7.3712]Training epoch 13:  56%|█████▋    | 92/163 [01:46<01:31,  1.28s/it, loss=0.2762, batch_acc=0.9062, running_acc=0.9523, grad=7.3712]Training epoch 13:  56%|█████▋    | 92/163 [01:46<01:31,  1.28s/it, loss=0.3697, batch_acc=0.9062, running_acc=0.9518, grad=7.2918]Training epoch 13:  57%|█████▋    | 93/163 [01:47<01:21,  1.16s/it, loss=0.3697, batch_acc=0.9062, running_acc=0.9518, grad=7.2918]Training epoch 13:  57%|█████▋    | 93/163 [01:47<01:21,  1.16s/it, loss=0.0489, batch_acc=1.0000, running_acc=0.9523, grad=1.5863]Training epoch 13:  58%|█████▊    | 94/163 [01:48<01:14,  1.08s/it, loss=0.0489, batch_acc=1.0000, running_acc=0.9523, grad=1.5863]Training epoch 13:  58%|█████▊    | 94/163 [01:48<01:14,  1.08s/it, loss=0.1015, batch_acc=0.9688, running_acc=0.9525, grad=3.2872]Training epoch 13:  58%|█████▊    | 95/163 [01:49<01:09,  1.02s/it, loss=0.1015, batch_acc=0.9688, running_acc=0.9525, grad=3.2872]Training epoch 13:  58%|█████▊    | 95/163 [01:49<01:09,  1.02s/it, loss=0.1796, batch_acc=0.9688, running_acc=0.9526, grad=5.6913]Training epoch 13:  59%|█████▉    | 96/163 [01:50<01:21,  1.21s/it, loss=0.1796, batch_acc=0.9688, running_acc=0.9526, grad=5.6913]Training epoch 13:  59%|█████▉    | 96/163 [01:50<01:21,  1.21s/it, loss=0.0907, batch_acc=1.0000, running_acc=0.9531, grad=3.1866]Training epoch 13:  60%|█████▉    | 97/163 [01:51<01:16,  1.17s/it, loss=0.0907, batch_acc=1.0000, running_acc=0.9531, grad=3.1866]Training epoch 13:  60%|█████▉    | 97/163 [01:51<01:16,  1.17s/it, loss=0.2396, batch_acc=0.9062, running_acc=0.9526, grad=6.6329]Training epoch 13:  60%|██████    | 98/163 [01:52<01:10,  1.08s/it, loss=0.2396, batch_acc=0.9062, running_acc=0.9526, grad=6.6329]Training epoch 13:  60%|██████    | 98/163 [01:52<01:10,  1.08s/it, loss=0.1783, batch_acc=0.9375, running_acc=0.9525, grad=6.4281]Training epoch 13:  61%|██████    | 99/163 [01:53<01:05,  1.02s/it, loss=0.1783, batch_acc=0.9375, running_acc=0.9525, grad=6.4281]Training epoch 13:  61%|██████    | 99/163 [01:53<01:05,  1.02s/it, loss=0.2894, batch_acc=0.9062, running_acc=0.9520, grad=9.8015]Training epoch 13:  61%|██████▏   | 100/163 [01:55<01:17,  1.23s/it, loss=0.2894, batch_acc=0.9062, running_acc=0.9520, grad=9.8015]Training epoch 13:  61%|██████▏   | 100/163 [01:55<01:17,  1.23s/it, loss=0.2531, batch_acc=0.9688, running_acc=0.9522, grad=6.7829]Training epoch 13:  62%|██████▏   | 101/163 [01:56<01:19,  1.27s/it, loss=0.2531, batch_acc=0.9688, running_acc=0.9522, grad=6.7829]Training epoch 13:  62%|██████▏   | 101/163 [01:56<01:19,  1.27s/it, loss=0.1405, batch_acc=0.9062, running_acc=0.9517, grad=1.7345]Training epoch 13:  63%|██████▎   | 102/163 [01:57<01:10,  1.16s/it, loss=0.1405, batch_acc=0.9062, running_acc=0.9517, grad=1.7345]Training epoch 13:  63%|██████▎   | 102/163 [01:57<01:10,  1.16s/it, loss=0.1612, batch_acc=0.9375, running_acc=0.9516, grad=3.0213]Training epoch 13:  63%|██████▎   | 103/163 [01:58<01:04,  1.07s/it, loss=0.1612, batch_acc=0.9375, running_acc=0.9516, grad=3.0213]Training epoch 13:  63%|██████▎   | 103/163 [01:58<01:04,  1.07s/it, loss=0.1204, batch_acc=0.9375, running_acc=0.9515, grad=2.1200]Training epoch 13:  64%|██████▍   | 104/163 [02:00<01:20,  1.36s/it, loss=0.1204, batch_acc=0.9375, running_acc=0.9515, grad=2.1200]Training epoch 13:  64%|██████▍   | 104/163 [02:00<01:20,  1.36s/it, loss=0.1554, batch_acc=0.9688, running_acc=0.9516, grad=3.2650]Training epoch 13:  64%|██████▍   | 105/163 [02:01<01:13,  1.27s/it, loss=0.1554, batch_acc=0.9688, running_acc=0.9516, grad=3.2650]Training epoch 13:  64%|██████▍   | 105/163 [02:01<01:13,  1.27s/it, loss=0.1638, batch_acc=0.9688, running_acc=0.9518, grad=4.7278]Training epoch 13:  65%|██████▌   | 106/163 [02:02<01:05,  1.15s/it, loss=0.1638, batch_acc=0.9688, running_acc=0.9518, grad=4.7278]Training epoch 13:  65%|██████▌   | 106/163 [02:02<01:05,  1.15s/it, loss=0.1087, batch_acc=0.9375, running_acc=0.9517, grad=2.9698]Training epoch 13:  66%|██████▌   | 107/163 [02:03<00:59,  1.07s/it, loss=0.1087, batch_acc=0.9375, running_acc=0.9517, grad=2.9698]Training epoch 13:  66%|██████▌   | 107/163 [02:03<00:59,  1.07s/it, loss=0.1276, batch_acc=0.9375, running_acc=0.9515, grad=3.3489]Training epoch 13:  66%|██████▋   | 108/163 [02:05<01:07,  1.23s/it, loss=0.1276, batch_acc=0.9375, running_acc=0.9515, grad=3.3489]Training epoch 13:  66%|██████▋   | 108/163 [02:05<01:07,  1.23s/it, loss=0.1977, batch_acc=0.9062, running_acc=0.9511, grad=3.9868]Training epoch 13:  67%|██████▋   | 109/163 [02:05<01:00,  1.13s/it, loss=0.1977, batch_acc=0.9062, running_acc=0.9511, grad=3.9868]Training epoch 13:  67%|██████▋   | 109/163 [02:05<01:00,  1.13s/it, loss=0.1524, batch_acc=0.9688, running_acc=0.9513, grad=5.4586]Training epoch 13:  67%|██████▋   | 110/163 [02:06<00:55,  1.05s/it, loss=0.1524, batch_acc=0.9688, running_acc=0.9513, grad=5.4586]Training epoch 13:  67%|██████▋   | 110/163 [02:06<00:55,  1.05s/it, loss=0.1751, batch_acc=0.9375, running_acc=0.9511, grad=2.7999]Training epoch 13:  68%|██████▊   | 111/163 [02:07<00:52,  1.00s/it, loss=0.1751, batch_acc=0.9375, running_acc=0.9511, grad=2.7999]Training epoch 13:  68%|██████▊   | 111/163 [02:07<00:52,  1.00s/it, loss=0.0899, batch_acc=0.9688, running_acc=0.9513, grad=3.8556]Training epoch 13:  69%|██████▊   | 112/163 [02:09<01:01,  1.20s/it, loss=0.0899, batch_acc=0.9688, running_acc=0.9513, grad=3.8556]Training epoch 13:  69%|██████▊   | 112/163 [02:09<01:01,  1.20s/it, loss=0.0955, batch_acc=1.0000, running_acc=0.9517, grad=3.9322]Training epoch 13:  69%|██████▉   | 113/163 [02:10<00:55,  1.11s/it, loss=0.0955, batch_acc=1.0000, running_acc=0.9517, grad=3.9322]Training epoch 13:  69%|██████▉   | 113/163 [02:10<00:55,  1.11s/it, loss=0.1487, batch_acc=0.9375, running_acc=0.9516, grad=5.2637]Training epoch 13:  70%|██████▉   | 114/163 [02:11<00:50,  1.04s/it, loss=0.1487, batch_acc=0.9375, running_acc=0.9516, grad=5.2637]Training epoch 13:  70%|██████▉   | 114/163 [02:11<00:50,  1.04s/it, loss=0.4799, batch_acc=0.8438, running_acc=0.9507, grad=8.7375]Training epoch 13:  71%|███████   | 115/163 [02:11<00:47,  1.01it/s, loss=0.4799, batch_acc=0.8438, running_acc=0.9507, grad=8.7375]Training epoch 13:  71%|███████   | 115/163 [02:11<00:47,  1.01it/s, loss=0.2108, batch_acc=0.9375, running_acc=0.9505, grad=4.7894]Training epoch 13:  71%|███████   | 116/163 [02:13<00:55,  1.17s/it, loss=0.2108, batch_acc=0.9375, running_acc=0.9505, grad=4.7894]Training epoch 13:  71%|███████   | 116/163 [02:13<00:55,  1.17s/it, loss=0.1643, batch_acc=0.9375, running_acc=0.9504, grad=4.8002]Training epoch 13:  72%|███████▏  | 117/163 [02:14<00:49,  1.09s/it, loss=0.1643, batch_acc=0.9375, running_acc=0.9504, grad=4.8002]Training epoch 13:  72%|███████▏  | 117/163 [02:14<00:49,  1.09s/it, loss=0.1611, batch_acc=0.9375, running_acc=0.9503, grad=3.9690]Training epoch 13:  72%|███████▏  | 118/163 [02:15<00:46,  1.02s/it, loss=0.1611, batch_acc=0.9375, running_acc=0.9503, grad=3.9690]Training epoch 13:  72%|███████▏  | 118/163 [02:15<00:46,  1.02s/it, loss=0.2682, batch_acc=0.9375, running_acc=0.9502, grad=4.2097]Training epoch 13:  73%|███████▎  | 119/163 [02:16<00:43,  1.02it/s, loss=0.2682, batch_acc=0.9375, running_acc=0.9502, grad=4.2097]Training epoch 13:  73%|███████▎  | 119/163 [02:16<00:43,  1.02it/s, loss=0.0920, batch_acc=1.0000, running_acc=0.9506, grad=3.3820]Training epoch 13:  74%|███████▎  | 120/163 [02:17<00:52,  1.21s/it, loss=0.0920, batch_acc=1.0000, running_acc=0.9506, grad=3.3820]Training epoch 13:  74%|███████▎  | 120/163 [02:17<00:52,  1.21s/it, loss=0.2830, batch_acc=0.9062, running_acc=0.9503, grad=7.0034]Training epoch 13:  74%|███████▍  | 121/163 [02:19<00:50,  1.20s/it, loss=0.2830, batch_acc=0.9062, running_acc=0.9503, grad=7.0034]Training epoch 13:  74%|███████▍  | 121/163 [02:19<00:50,  1.20s/it, loss=0.1952, batch_acc=0.9375, running_acc=0.9502, grad=5.2807]Training epoch 13:  75%|███████▍  | 122/163 [02:20<00:45,  1.10s/it, loss=0.1952, batch_acc=0.9375, running_acc=0.9502, grad=5.2807]Training epoch 13:  75%|███████▍  | 122/163 [02:20<00:45,  1.10s/it, loss=0.3377, batch_acc=0.8750, running_acc=0.9495, grad=6.5516]Training epoch 13:  75%|███████▌  | 123/163 [02:20<00:41,  1.03s/it, loss=0.3377, batch_acc=0.8750, running_acc=0.9495, grad=6.5516]Training epoch 13:  75%|███████▌  | 123/163 [02:20<00:41,  1.03s/it, loss=0.3804, batch_acc=0.9062, running_acc=0.9492, grad=6.8336]Training epoch 13:  76%|███████▌  | 124/163 [02:22<00:42,  1.09s/it, loss=0.3804, batch_acc=0.9062, running_acc=0.9492, grad=6.8336]Training epoch 13:  76%|███████▌  | 124/163 [02:22<00:42,  1.09s/it, loss=0.1315, batch_acc=0.9375, running_acc=0.9491, grad=3.3551]Training epoch 13:  77%|███████▋  | 125/163 [02:23<00:45,  1.19s/it, loss=0.1315, batch_acc=0.9375, running_acc=0.9491, grad=3.3551]Training epoch 13:  77%|███████▋  | 125/163 [02:23<00:45,  1.19s/it, loss=0.4049, batch_acc=0.9062, running_acc=0.9487, grad=7.0992]Training epoch 13:  77%|███████▋  | 126/163 [02:24<00:40,  1.10s/it, loss=0.4049, batch_acc=0.9062, running_acc=0.9487, grad=7.0992]Training epoch 13:  77%|███████▋  | 126/163 [02:24<00:40,  1.10s/it, loss=0.2506, batch_acc=0.8750, running_acc=0.9482, grad=6.8967]Training epoch 13:  78%|███████▊  | 127/163 [02:25<00:37,  1.03s/it, loss=0.2506, batch_acc=0.8750, running_acc=0.9482, grad=6.8967]Training epoch 13:  78%|███████▊  | 127/163 [02:25<00:37,  1.03s/it, loss=0.1237, batch_acc=1.0000, running_acc=0.9486, grad=4.1445]Training epoch 13:  79%|███████▊  | 128/163 [02:26<00:41,  1.20s/it, loss=0.1237, batch_acc=1.0000, running_acc=0.9486, grad=4.1445]Training epoch 13:  79%|███████▊  | 128/163 [02:26<00:41,  1.20s/it, loss=0.1236, batch_acc=0.9375, running_acc=0.9485, grad=5.7428]Training epoch 13:  79%|███████▉  | 129/163 [02:27<00:39,  1.16s/it, loss=0.1236, batch_acc=0.9375, running_acc=0.9485, grad=5.7428]Training epoch 13:  79%|███████▉  | 129/163 [02:27<00:39,  1.16s/it, loss=0.2083, batch_acc=0.9375, running_acc=0.9484, grad=6.6302]Training epoch 13:  80%|███████▉  | 130/163 [02:28<00:35,  1.08s/it, loss=0.2083, batch_acc=0.9375, running_acc=0.9484, grad=6.6302]Training epoch 13:  80%|███████▉  | 130/163 [02:28<00:35,  1.08s/it, loss=0.3881, batch_acc=0.8125, running_acc=0.9474, grad=10.4285]Training epoch 13:  80%|████████  | 131/163 [02:29<00:32,  1.02s/it, loss=0.3881, batch_acc=0.8125, running_acc=0.9474, grad=10.4285]Training epoch 13:  80%|████████  | 131/163 [02:29<00:32,  1.02s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9473, grad=4.7323] Training epoch 13:  81%|████████  | 132/163 [02:31<00:37,  1.21s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9473, grad=4.7323]Training epoch 13:  81%|████████  | 132/163 [02:31<00:37,  1.21s/it, loss=0.2609, batch_acc=0.9375, running_acc=0.9472, grad=4.6917]Training epoch 13:  82%|████████▏ | 133/163 [02:32<00:36,  1.21s/it, loss=0.2609, batch_acc=0.9375, running_acc=0.9472, grad=4.6917]Training epoch 13:  82%|████████▏ | 133/163 [02:32<00:36,  1.21s/it, loss=0.2110, batch_acc=0.9688, running_acc=0.9474, grad=4.8875]Training epoch 13:  82%|████████▏ | 134/163 [02:33<00:32,  1.11s/it, loss=0.2110, batch_acc=0.9688, running_acc=0.9474, grad=4.8875]Training epoch 13:  82%|████████▏ | 134/163 [02:33<00:32,  1.11s/it, loss=0.1382, batch_acc=0.9688, running_acc=0.9475, grad=5.2275]Training epoch 13:  83%|████████▎ | 135/163 [02:34<00:29,  1.04s/it, loss=0.1382, batch_acc=0.9688, running_acc=0.9475, grad=5.2275]Training epoch 13:  83%|████████▎ | 135/163 [02:34<00:29,  1.04s/it, loss=0.3979, batch_acc=0.9375, running_acc=0.9475, grad=6.6519]Training epoch 13:  83%|████████▎ | 136/163 [02:36<00:33,  1.25s/it, loss=0.3979, batch_acc=0.9375, running_acc=0.9475, grad=6.6519]Training epoch 13:  83%|████████▎ | 136/163 [02:36<00:33,  1.25s/it, loss=0.2624, batch_acc=0.8750, running_acc=0.9469, grad=5.0193]Training epoch 13:  84%|████████▍ | 137/163 [02:37<00:29,  1.15s/it, loss=0.2624, batch_acc=0.8750, running_acc=0.9469, grad=5.0193]Training epoch 13:  84%|████████▍ | 137/163 [02:37<00:29,  1.15s/it, loss=0.3607, batch_acc=0.8750, running_acc=0.9464, grad=10.0701]Training epoch 13:  85%|████████▍ | 138/163 [02:37<00:26,  1.07s/it, loss=0.3607, batch_acc=0.8750, running_acc=0.9464, grad=10.0701]Training epoch 13:  85%|████████▍ | 138/163 [02:37<00:26,  1.07s/it, loss=0.0994, batch_acc=0.9688, running_acc=0.9466, grad=3.5033] Training epoch 13:  85%|████████▌ | 139/163 [02:38<00:24,  1.01s/it, loss=0.0994, batch_acc=0.9688, running_acc=0.9466, grad=3.5033]Training epoch 13:  85%|████████▌ | 139/163 [02:38<00:24,  1.01s/it, loss=0.1509, batch_acc=0.9375, running_acc=0.9465, grad=2.7743]Training epoch 13:  86%|████████▌ | 140/163 [02:40<00:26,  1.16s/it, loss=0.1509, batch_acc=0.9375, running_acc=0.9465, grad=2.7743]Training epoch 13:  86%|████████▌ | 140/163 [02:40<00:26,  1.16s/it, loss=0.0963, batch_acc=1.0000, running_acc=0.9469, grad=2.9643]Training epoch 13:  87%|████████▋ | 141/163 [02:41<00:27,  1.25s/it, loss=0.0963, batch_acc=1.0000, running_acc=0.9469, grad=2.9643]Training epoch 13:  87%|████████▋ | 141/163 [02:41<00:27,  1.25s/it, loss=0.1981, batch_acc=0.9062, running_acc=0.9466, grad=5.4709]Training epoch 13:  87%|████████▋ | 142/163 [02:42<00:23,  1.14s/it, loss=0.1981, batch_acc=0.9062, running_acc=0.9466, grad=5.4709]Training epoch 13:  87%|████████▋ | 142/163 [02:42<00:23,  1.14s/it, loss=0.1094, batch_acc=1.0000, running_acc=0.9470, grad=3.4878]Training epoch 13:  88%|████████▊ | 143/163 [02:43<00:21,  1.06s/it, loss=0.1094, batch_acc=1.0000, running_acc=0.9470, grad=3.4878]Training epoch 13:  88%|████████▊ | 143/163 [02:43<00:21,  1.06s/it, loss=0.1688, batch_acc=0.9688, running_acc=0.9471, grad=4.6150]Training epoch 13:  88%|████████▊ | 144/163 [02:44<00:19,  1.02s/it, loss=0.1688, batch_acc=0.9688, running_acc=0.9471, grad=4.6150]Training epoch 13:  88%|████████▊ | 144/163 [02:44<00:19,  1.02s/it, loss=0.1968, batch_acc=0.9375, running_acc=0.9470, grad=6.0474]Training epoch 13:  89%|████████▉ | 145/163 [02:45<00:19,  1.10s/it, loss=0.1968, batch_acc=0.9375, running_acc=0.9470, grad=6.0474]Training epoch 13:  89%|████████▉ | 145/163 [02:45<00:19,  1.10s/it, loss=0.1105, batch_acc=0.9688, running_acc=0.9472, grad=3.2187]Training epoch 13:  90%|████████▉ | 146/163 [02:46<00:17,  1.03s/it, loss=0.1105, batch_acc=0.9688, running_acc=0.9472, grad=3.2187]Training epoch 13:  90%|████████▉ | 146/163 [02:46<00:17,  1.03s/it, loss=0.0775, batch_acc=0.9688, running_acc=0.9473, grad=6.0863]Training epoch 13:  90%|█████████ | 147/163 [02:47<00:15,  1.01it/s, loss=0.0775, batch_acc=0.9688, running_acc=0.9473, grad=6.0863]Training epoch 13:  90%|█████████ | 147/163 [02:47<00:15,  1.01it/s, loss=0.2833, batch_acc=0.9062, running_acc=0.9471, grad=6.1788]Training epoch 13:  91%|█████████ | 148/163 [02:48<00:17,  1.13s/it, loss=0.2833, batch_acc=0.9062, running_acc=0.9471, grad=6.1788]Training epoch 13:  91%|█████████ | 148/163 [02:48<00:17,  1.13s/it, loss=0.1774, batch_acc=0.9688, running_acc=0.9472, grad=6.7493]Training epoch 13:  91%|█████████▏| 149/163 [02:49<00:15,  1.09s/it, loss=0.1774, batch_acc=0.9688, running_acc=0.9472, grad=6.7493]Training epoch 13:  91%|█████████▏| 149/163 [02:49<00:15,  1.09s/it, loss=0.1005, batch_acc=0.9688, running_acc=0.9474, grad=3.0853]Training epoch 13:  92%|█████████▏| 150/163 [02:50<00:13,  1.02s/it, loss=0.1005, batch_acc=0.9688, running_acc=0.9474, grad=3.0853]Training epoch 13:  92%|█████████▏| 150/163 [02:50<00:13,  1.02s/it, loss=0.2162, batch_acc=0.9688, running_acc=0.9475, grad=4.2665]Training epoch 13:  93%|█████████▎| 151/163 [02:51<00:11,  1.02it/s, loss=0.2162, batch_acc=0.9688, running_acc=0.9475, grad=4.2665]Training epoch 13:  93%|█████████▎| 151/163 [02:51<00:11,  1.02it/s, loss=0.2276, batch_acc=0.8750, running_acc=0.9470, grad=4.4802]Training epoch 13:  93%|█████████▎| 152/163 [02:52<00:11,  1.08s/it, loss=0.2276, batch_acc=0.8750, running_acc=0.9470, grad=4.4802]Training epoch 13:  93%|█████████▎| 152/163 [02:52<00:11,  1.08s/it, loss=0.1735, batch_acc=1.0000, running_acc=0.9474, grad=4.7959]Training epoch 13:  94%|█████████▍| 153/163 [02:54<00:12,  1.22s/it, loss=0.1735, batch_acc=1.0000, running_acc=0.9474, grad=4.7959]Training epoch 13:  94%|█████████▍| 153/163 [02:54<00:12,  1.22s/it, loss=0.2284, batch_acc=0.9062, running_acc=0.9471, grad=4.7532]Training epoch 13:  94%|█████████▍| 154/163 [02:55<00:10,  1.12s/it, loss=0.2284, batch_acc=0.9062, running_acc=0.9471, grad=4.7532]Training epoch 13:  94%|█████████▍| 154/163 [02:55<00:10,  1.12s/it, loss=0.2518, batch_acc=0.9062, running_acc=0.9468, grad=5.6590]Training epoch 13:  95%|█████████▌| 155/163 [02:56<00:08,  1.05s/it, loss=0.2518, batch_acc=0.9062, running_acc=0.9468, grad=5.6590]Training epoch 13:  95%|█████████▌| 155/163 [02:56<00:08,  1.05s/it, loss=0.0576, batch_acc=1.0000, running_acc=0.9472, grad=1.3247]Training epoch 13:  96%|█████████▌| 156/163 [02:57<00:07,  1.03s/it, loss=0.0576, batch_acc=1.0000, running_acc=0.9472, grad=1.3247]Training epoch 13:  96%|█████████▌| 156/163 [02:57<00:07,  1.03s/it, loss=0.1634, batch_acc=0.9375, running_acc=0.9471, grad=5.4033]Training epoch 13:  96%|█████████▋| 157/163 [02:58<00:06,  1.12s/it, loss=0.1634, batch_acc=0.9375, running_acc=0.9471, grad=5.4033]Training epoch 13:  96%|█████████▋| 157/163 [02:58<00:06,  1.12s/it, loss=0.1833, batch_acc=0.8750, running_acc=0.9467, grad=3.3336]Training epoch 13:  97%|█████████▋| 158/163 [02:59<00:05,  1.05s/it, loss=0.1833, batch_acc=0.8750, running_acc=0.9467, grad=3.3336]Training epoch 13:  97%|█████████▋| 158/163 [02:59<00:05,  1.05s/it, loss=0.1390, batch_acc=0.9375, running_acc=0.9466, grad=4.3690]Training epoch 13:  98%|█████████▊| 159/163 [03:00<00:03,  1.01it/s, loss=0.1390, batch_acc=0.9375, running_acc=0.9466, grad=4.3690]Training epoch 13:  98%|█████████▊| 159/163 [03:00<00:03,  1.01it/s, loss=0.2253, batch_acc=0.9375, running_acc=0.9465, grad=10.0697]Training epoch 13:  98%|█████████▊| 160/163 [03:01<00:02,  1.04it/s, loss=0.2253, batch_acc=0.9375, running_acc=0.9465, grad=10.0697]Training epoch 13:  98%|█████████▊| 160/163 [03:01<00:02,  1.04it/s, loss=0.1412, batch_acc=0.9375, running_acc=0.9465, grad=2.9362] Training epoch 13:  99%|█████████▉| 161/163 [03:02<00:02,  1.04s/it, loss=0.1412, batch_acc=0.9375, running_acc=0.9465, grad=2.9362]Training epoch 13:  99%|█████████▉| 161/163 [03:02<00:02,  1.04s/it, loss=0.2210, batch_acc=0.8750, running_acc=0.9460, grad=4.6735]Training epoch 13:  99%|█████████▉| 162/163 [03:03<00:00,  1.01it/s, loss=0.2210, batch_acc=0.8750, running_acc=0.9460, grad=4.6735]Training epoch 13:  99%|█████████▉| 162/163 [03:03<00:00,  1.01it/s, loss=0.1713, batch_acc=0.9375, running_acc=0.9460, grad=5.5133]Training epoch 13: 100%|██████████| 163/163 [03:03<00:00,  1.13it/s, loss=0.1713, batch_acc=0.9375, running_acc=0.9460, grad=5.5133]Training epoch 13: 100%|██████████| 163/163 [03:03<00:00,  1.13it/s, loss=0.3219, batch_acc=0.8571, running_acc=0.9456, grad=9.0955]Training epoch 13: 100%|██████████| 163/163 [03:03<00:00,  1.13s/it, loss=0.3219, batch_acc=0.8571, running_acc=0.9456, grad=9.0955]
Evaluation epoch 13:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 13:   4%|▎         | 1/28 [00:04<02:11,  4.89s/it]Evaluation epoch 13:   4%|▎         | 1/28 [00:04<02:11,  4.89s/it, loss=0.4059, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 13:   7%|▋         | 2/28 [00:05<00:56,  2.17s/it, loss=0.4059, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 13:   7%|▋         | 2/28 [00:05<00:56,  2.17s/it, loss=0.1880, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 13:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.1880, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 13:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.7863, batch_acc=0.7812, running_acc=0.8646]Evaluation epoch 13:  14%|█▍        | 4/28 [00:09<01:01,  2.55s/it, loss=0.7863, batch_acc=0.7812, running_acc=0.8646]Evaluation epoch 13:  14%|█▍        | 4/28 [00:09<01:01,  2.55s/it, loss=0.7655, batch_acc=0.7500, running_acc=0.8359]Evaluation epoch 13:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=0.7655, batch_acc=0.7500, running_acc=0.8359]Evaluation epoch 13:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.8505, batch_acc=0.5625, running_acc=0.7812]Evaluation epoch 13:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.8505, batch_acc=0.5625, running_acc=0.7812]Evaluation epoch 13:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=0.6772, batch_acc=0.8125, running_acc=0.7865]Evaluation epoch 13:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.6772, batch_acc=0.8125, running_acc=0.7865]Evaluation epoch 13:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.0669, batch_acc=0.7188, running_acc=0.7768]Evaluation epoch 13:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=1.0669, batch_acc=0.7188, running_acc=0.7768]Evaluation epoch 13:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=1.2429, batch_acc=0.7188, running_acc=0.7695]Evaluation epoch 13:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=1.2429, batch_acc=0.7188, running_acc=0.7695]Evaluation epoch 13:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=1.1802, batch_acc=0.6875, running_acc=0.7604]Evaluation epoch 13:  36%|███▌      | 10/28 [00:14<00:16,  1.06it/s, loss=1.1802, batch_acc=0.6875, running_acc=0.7604]Evaluation epoch 13:  36%|███▌      | 10/28 [00:14<00:16,  1.06it/s, loss=0.5628, batch_acc=0.8438, running_acc=0.7688]Evaluation epoch 13:  39%|███▉      | 11/28 [00:14<00:12,  1.36it/s, loss=0.5628, batch_acc=0.8438, running_acc=0.7688]Evaluation epoch 13:  39%|███▉      | 11/28 [00:14<00:12,  1.36it/s, loss=0.5070, batch_acc=0.8438, running_acc=0.7756]Evaluation epoch 13:  43%|████▎     | 12/28 [00:20<00:35,  2.25s/it, loss=0.5070, batch_acc=0.8438, running_acc=0.7756]Evaluation epoch 13:  43%|████▎     | 12/28 [00:20<00:35,  2.25s/it, loss=0.8186, batch_acc=0.6562, running_acc=0.7656]Evaluation epoch 13:  46%|████▋     | 13/28 [00:20<00:24,  1.65s/it, loss=0.8186, batch_acc=0.6562, running_acc=0.7656]Evaluation epoch 13:  46%|████▋     | 13/28 [00:20<00:24,  1.65s/it, loss=0.6695, batch_acc=0.8750, running_acc=0.7740]Evaluation epoch 13:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=0.6695, batch_acc=0.8750, running_acc=0.7740]Evaluation epoch 13:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=1.1193, batch_acc=0.7812, running_acc=0.7746]Evaluation epoch 13:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.1193, batch_acc=0.7812, running_acc=0.7746]Evaluation epoch 13:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.3639, batch_acc=0.6875, running_acc=0.7688]Evaluation epoch 13:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.3639, batch_acc=0.6875, running_acc=0.7688]Evaluation epoch 13:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=0.4670, batch_acc=0.7188, running_acc=0.7656]Evaluation epoch 13:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.4670, batch_acc=0.7188, running_acc=0.7656]Evaluation epoch 13:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.3608, batch_acc=0.8438, running_acc=0.7702]Evaluation epoch 13:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.3608, batch_acc=0.8438, running_acc=0.7702]Evaluation epoch 13:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=1.1006, batch_acc=0.7500, running_acc=0.7691]Evaluation epoch 13:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=1.1006, batch_acc=0.7500, running_acc=0.7691]Evaluation epoch 13:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=1.0259, batch_acc=0.6875, running_acc=0.7648]Evaluation epoch 13:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=1.0259, batch_acc=0.6875, running_acc=0.7648]Evaluation epoch 13:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=0.5837, batch_acc=0.7188, running_acc=0.7625]Evaluation epoch 13:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=0.5837, batch_acc=0.7188, running_acc=0.7625]Evaluation epoch 13:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=1.1148, batch_acc=0.7500, running_acc=0.7619]Evaluation epoch 13:  79%|███████▊  | 22/28 [00:28<00:04,  1.28it/s, loss=1.1148, batch_acc=0.7500, running_acc=0.7619]Evaluation epoch 13:  79%|███████▊  | 22/28 [00:28<00:04,  1.28it/s, loss=0.9457, batch_acc=0.7188, running_acc=0.7599]Evaluation epoch 13:  82%|████████▏ | 23/28 [00:28<00:03,  1.60it/s, loss=0.9457, batch_acc=0.7188, running_acc=0.7599]Evaluation epoch 13:  82%|████████▏ | 23/28 [00:28<00:03,  1.60it/s, loss=1.2013, batch_acc=0.6875, running_acc=0.7568]Evaluation epoch 13:  86%|████████▌ | 24/28 [00:33<00:07,  1.97s/it, loss=1.2013, batch_acc=0.6875, running_acc=0.7568]Evaluation epoch 13:  86%|████████▌ | 24/28 [00:33<00:07,  1.97s/it, loss=0.2386, batch_acc=0.9375, running_acc=0.7643]Evaluation epoch 13:  89%|████████▉ | 25/28 [00:33<00:04,  1.46s/it, loss=0.2386, batch_acc=0.9375, running_acc=0.7643]Evaluation epoch 13:  89%|████████▉ | 25/28 [00:33<00:04,  1.46s/it, loss=0.2512, batch_acc=0.9375, running_acc=0.7712]Evaluation epoch 13:  93%|█████████▎| 26/28 [00:34<00:02,  1.10s/it, loss=0.2512, batch_acc=0.9375, running_acc=0.7712]Evaluation epoch 13:  93%|█████████▎| 26/28 [00:34<00:02,  1.10s/it, loss=0.2639, batch_acc=0.9375, running_acc=0.7776]Evaluation epoch 13:  96%|█████████▋| 27/28 [00:34<00:00,  1.18it/s, loss=0.2639, batch_acc=0.9375, running_acc=0.7776]Evaluation epoch 13:  96%|█████████▋| 27/28 [00:34<00:00,  1.18it/s, loss=0.7980, batch_acc=0.7812, running_acc=0.7778]Evaluation epoch 13: 100%|██████████| 28/28 [00:34<00:00,  1.18it/s, loss=0.0663, batch_acc=1.0000, running_acc=0.7785]Evaluation epoch 13: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=0.0663, batch_acc=1.0000, running_acc=0.7785]
Training epoch 14:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 14:   1%|          | 1/163 [00:05<15:59,  5.92s/it]Training epoch 14:   1%|          | 1/163 [00:05<15:59,  5.92s/it, loss=0.1564, batch_acc=0.9062, running_acc=0.9062, grad=5.5055]Training epoch 14:   1%|          | 2/163 [00:06<07:56,  2.96s/it, loss=0.1564, batch_acc=0.9062, running_acc=0.9062, grad=5.5055]Training epoch 14:   1%|          | 2/163 [00:06<07:56,  2.96s/it, loss=0.1635, batch_acc=0.9688, running_acc=0.9375, grad=5.4736]Training epoch 14:   2%|▏         | 3/163 [00:07<05:21,  2.01s/it, loss=0.1635, batch_acc=0.9688, running_acc=0.9375, grad=5.4736]Training epoch 14:   2%|▏         | 3/163 [00:07<05:21,  2.01s/it, loss=0.2374, batch_acc=0.9688, running_acc=0.9479, grad=4.4699]Training epoch 14:   2%|▏         | 4/163 [00:10<05:59,  2.26s/it, loss=0.2374, batch_acc=0.9688, running_acc=0.9479, grad=4.4699]Training epoch 14:   2%|▏         | 4/163 [00:10<05:59,  2.26s/it, loss=0.1314, batch_acc=0.9375, running_acc=0.9453, grad=3.8699]Training epoch 14:   3%|▎         | 5/163 [00:11<04:38,  1.76s/it, loss=0.1314, batch_acc=0.9375, running_acc=0.9453, grad=3.8699]Training epoch 14:   3%|▎         | 5/163 [00:11<04:38,  1.76s/it, loss=0.0762, batch_acc=1.0000, running_acc=0.9563, grad=1.8686]Training epoch 14:   4%|▎         | 6/163 [00:12<03:49,  1.46s/it, loss=0.0762, batch_acc=1.0000, running_acc=0.9563, grad=1.8686]Training epoch 14:   4%|▎         | 6/163 [00:12<03:49,  1.46s/it, loss=0.1196, batch_acc=0.9688, running_acc=0.9583, grad=3.5700]Training epoch 14:   4%|▍         | 7/163 [00:12<03:18,  1.27s/it, loss=0.1196, batch_acc=0.9688, running_acc=0.9583, grad=3.5700]Training epoch 14:   4%|▍         | 7/163 [00:12<03:18,  1.27s/it, loss=0.0838, batch_acc=0.9688, running_acc=0.9598, grad=3.3081]Training epoch 14:   5%|▍         | 8/163 [00:14<03:39,  1.42s/it, loss=0.0838, batch_acc=0.9688, running_acc=0.9598, grad=3.3081]Training epoch 14:   5%|▍         | 8/163 [00:14<03:39,  1.42s/it, loss=0.1879, batch_acc=0.8750, running_acc=0.9492, grad=6.0353]Training epoch 14:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.1879, batch_acc=0.8750, running_acc=0.9492, grad=6.0353]Training epoch 14:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.0843, batch_acc=0.9688, running_acc=0.9514, grad=2.3977]Training epoch 14:   6%|▌         | 10/163 [00:16<02:54,  1.14s/it, loss=0.0843, batch_acc=0.9688, running_acc=0.9514, grad=2.3977]Training epoch 14:   6%|▌         | 10/163 [00:16<02:54,  1.14s/it, loss=0.1227, batch_acc=0.9688, running_acc=0.9531, grad=3.8782]Training epoch 14:   7%|▋         | 11/163 [00:17<02:41,  1.06s/it, loss=0.1227, batch_acc=0.9688, running_acc=0.9531, grad=3.8782]Training epoch 14:   7%|▋         | 11/163 [00:17<02:41,  1.06s/it, loss=0.0980, batch_acc=0.9688, running_acc=0.9545, grad=3.3654]Training epoch 14:   7%|▋         | 12/163 [00:19<03:16,  1.30s/it, loss=0.0980, batch_acc=0.9688, running_acc=0.9545, grad=3.3654]Training epoch 14:   7%|▋         | 12/163 [00:19<03:16,  1.30s/it, loss=0.0624, batch_acc=1.0000, running_acc=0.9583, grad=2.1396]Training epoch 14:   8%|▊         | 13/163 [00:20<02:56,  1.17s/it, loss=0.0624, batch_acc=1.0000, running_acc=0.9583, grad=2.1396]Training epoch 14:   8%|▊         | 13/163 [00:20<02:56,  1.17s/it, loss=0.0945, batch_acc=0.9688, running_acc=0.9591, grad=2.6468]Training epoch 14:   9%|▊         | 14/163 [00:20<02:41,  1.08s/it, loss=0.0945, batch_acc=0.9688, running_acc=0.9591, grad=2.6468]Training epoch 14:   9%|▊         | 14/163 [00:20<02:41,  1.08s/it, loss=0.1253, batch_acc=1.0000, running_acc=0.9621, grad=4.4751]Training epoch 14:   9%|▉         | 15/163 [00:21<02:31,  1.02s/it, loss=0.1253, batch_acc=1.0000, running_acc=0.9621, grad=4.4751]Training epoch 14:   9%|▉         | 15/163 [00:21<02:31,  1.02s/it, loss=0.1008, batch_acc=1.0000, running_acc=0.9646, grad=3.7301]Training epoch 14:  10%|▉         | 16/163 [00:24<03:37,  1.48s/it, loss=0.1008, batch_acc=1.0000, running_acc=0.9646, grad=3.7301]Training epoch 14:  10%|▉         | 16/163 [00:24<03:37,  1.48s/it, loss=0.0813, batch_acc=1.0000, running_acc=0.9668, grad=2.1406]Training epoch 14:  10%|█         | 17/163 [00:25<03:10,  1.30s/it, loss=0.0813, batch_acc=1.0000, running_acc=0.9668, grad=2.1406]Training epoch 14:  10%|█         | 17/163 [00:25<03:10,  1.30s/it, loss=0.1532, batch_acc=0.9375, running_acc=0.9651, grad=4.8571]Training epoch 14:  11%|█         | 18/163 [00:26<02:50,  1.18s/it, loss=0.1532, batch_acc=0.9375, running_acc=0.9651, grad=4.8571]Training epoch 14:  11%|█         | 18/163 [00:26<02:50,  1.18s/it, loss=0.1285, batch_acc=0.9375, running_acc=0.9635, grad=3.5126]Training epoch 14:  12%|█▏        | 19/163 [00:27<02:36,  1.09s/it, loss=0.1285, batch_acc=0.9375, running_acc=0.9635, grad=3.5126]Training epoch 14:  12%|█▏        | 19/163 [00:27<02:36,  1.09s/it, loss=0.1134, batch_acc=0.9375, running_acc=0.9622, grad=4.3243]Training epoch 14:  12%|█▏        | 20/163 [00:29<03:38,  1.53s/it, loss=0.1134, batch_acc=0.9375, running_acc=0.9622, grad=4.3243]Training epoch 14:  12%|█▏        | 20/163 [00:29<03:38,  1.53s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9625, grad=4.8517]Training epoch 14:  13%|█▎        | 21/163 [00:30<03:09,  1.33s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9625, grad=4.8517]Training epoch 14:  13%|█▎        | 21/163 [00:30<03:09,  1.33s/it, loss=0.0959, batch_acc=0.9688, running_acc=0.9628, grad=2.5884]Training epoch 14:  13%|█▎        | 22/163 [00:31<02:48,  1.20s/it, loss=0.0959, batch_acc=0.9688, running_acc=0.9628, grad=2.5884]Training epoch 14:  13%|█▎        | 22/163 [00:31<02:48,  1.20s/it, loss=0.1032, batch_acc=0.9688, running_acc=0.9631, grad=5.4426]Training epoch 14:  14%|█▍        | 23/163 [00:32<02:34,  1.10s/it, loss=0.1032, batch_acc=0.9688, running_acc=0.9631, grad=5.4426]Training epoch 14:  14%|█▍        | 23/163 [00:32<02:34,  1.10s/it, loss=0.1188, batch_acc=1.0000, running_acc=0.9647, grad=3.8028]Training epoch 14:  15%|█▍        | 24/163 [00:33<02:53,  1.25s/it, loss=0.1188, batch_acc=1.0000, running_acc=0.9647, grad=3.8028]Training epoch 14:  15%|█▍        | 24/163 [00:33<02:53,  1.25s/it, loss=0.1252, batch_acc=0.9688, running_acc=0.9648, grad=3.4460]Training epoch 14:  15%|█▌        | 25/163 [00:34<02:36,  1.14s/it, loss=0.1252, batch_acc=0.9688, running_acc=0.9648, grad=3.4460]Training epoch 14:  15%|█▌        | 25/163 [00:34<02:36,  1.14s/it, loss=0.2515, batch_acc=0.9062, running_acc=0.9625, grad=6.7306]Training epoch 14:  16%|█▌        | 26/163 [00:35<02:25,  1.06s/it, loss=0.2515, batch_acc=0.9062, running_acc=0.9625, grad=6.7306]Training epoch 14:  16%|█▌        | 26/163 [00:35<02:25,  1.06s/it, loss=0.0880, batch_acc=0.9688, running_acc=0.9627, grad=1.7683]Training epoch 14:  17%|█▋        | 27/163 [00:36<02:16,  1.01s/it, loss=0.0880, batch_acc=0.9688, running_acc=0.9627, grad=1.7683]Training epoch 14:  17%|█▋        | 27/163 [00:36<02:16,  1.01s/it, loss=0.1869, batch_acc=0.9375, running_acc=0.9618, grad=5.6949]Training epoch 14:  17%|█▋        | 28/163 [00:38<02:43,  1.21s/it, loss=0.1869, batch_acc=0.9375, running_acc=0.9618, grad=5.6949]Training epoch 14:  17%|█▋        | 28/163 [00:38<02:43,  1.21s/it, loss=0.1819, batch_acc=0.8750, running_acc=0.9587, grad=7.5964]Training epoch 14:  18%|█▊        | 29/163 [00:39<02:28,  1.11s/it, loss=0.1819, batch_acc=0.8750, running_acc=0.9587, grad=7.5964]Training epoch 14:  18%|█▊        | 29/163 [00:39<02:28,  1.11s/it, loss=0.1213, batch_acc=0.9688, running_acc=0.9591, grad=3.8841]Training epoch 14:  18%|█▊        | 30/163 [00:39<02:18,  1.04s/it, loss=0.1213, batch_acc=0.9688, running_acc=0.9591, grad=3.8841]Training epoch 14:  18%|█▊        | 30/163 [00:39<02:18,  1.04s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9604, grad=3.4402]Training epoch 14:  19%|█▉        | 31/163 [00:40<02:11,  1.01it/s, loss=0.0831, batch_acc=1.0000, running_acc=0.9604, grad=3.4402]Training epoch 14:  19%|█▉        | 31/163 [00:40<02:11,  1.01it/s, loss=0.1270, batch_acc=0.9688, running_acc=0.9607, grad=3.3080]Training epoch 14:  20%|█▉        | 32/163 [00:42<02:39,  1.22s/it, loss=0.1270, batch_acc=0.9688, running_acc=0.9607, grad=3.3080]Training epoch 14:  20%|█▉        | 32/163 [00:42<02:39,  1.22s/it, loss=0.0606, batch_acc=1.0000, running_acc=0.9619, grad=1.7677]Training epoch 14:  20%|██        | 33/163 [00:43<02:24,  1.12s/it, loss=0.0606, batch_acc=1.0000, running_acc=0.9619, grad=1.7677]Training epoch 14:  20%|██        | 33/163 [00:43<02:24,  1.12s/it, loss=0.5248, batch_acc=0.8750, running_acc=0.9593, grad=14.1803]Training epoch 14:  21%|██        | 34/163 [00:44<02:14,  1.04s/it, loss=0.5248, batch_acc=0.8750, running_acc=0.9593, grad=14.1803]Training epoch 14:  21%|██        | 34/163 [00:44<02:14,  1.04s/it, loss=0.1562, batch_acc=0.9688, running_acc=0.9596, grad=4.0362] Training epoch 14:  21%|██▏       | 35/163 [00:45<02:07,  1.00it/s, loss=0.1562, batch_acc=0.9688, running_acc=0.9596, grad=4.0362]Training epoch 14:  21%|██▏       | 35/163 [00:45<02:07,  1.00it/s, loss=0.0636, batch_acc=1.0000, running_acc=0.9607, grad=1.6681]Training epoch 14:  22%|██▏       | 36/163 [00:46<02:36,  1.23s/it, loss=0.0636, batch_acc=1.0000, running_acc=0.9607, grad=1.6681]Training epoch 14:  22%|██▏       | 36/163 [00:46<02:36,  1.23s/it, loss=0.1313, batch_acc=0.9375, running_acc=0.9601, grad=4.9197]Training epoch 14:  23%|██▎       | 37/163 [00:47<02:22,  1.13s/it, loss=0.1313, batch_acc=0.9375, running_acc=0.9601, grad=4.9197]Training epoch 14:  23%|██▎       | 37/163 [00:47<02:22,  1.13s/it, loss=0.1105, batch_acc=0.9688, running_acc=0.9603, grad=3.2342]Training epoch 14:  23%|██▎       | 38/163 [00:48<02:11,  1.05s/it, loss=0.1105, batch_acc=0.9688, running_acc=0.9603, grad=3.2342]Training epoch 14:  23%|██▎       | 38/163 [00:48<02:11,  1.05s/it, loss=0.0721, batch_acc=0.9688, running_acc=0.9605, grad=3.5109]Training epoch 14:  24%|██▍       | 39/163 [00:49<02:04,  1.00s/it, loss=0.0721, batch_acc=0.9688, running_acc=0.9605, grad=3.5109]Training epoch 14:  24%|██▍       | 39/163 [00:49<02:04,  1.00s/it, loss=0.1439, batch_acc=0.9375, running_acc=0.9599, grad=4.5790]Training epoch 14:  25%|██▍       | 40/163 [00:51<02:18,  1.12s/it, loss=0.1439, batch_acc=0.9375, running_acc=0.9599, grad=4.5790]Training epoch 14:  25%|██▍       | 40/163 [00:51<02:18,  1.12s/it, loss=0.1224, batch_acc=0.9375, running_acc=0.9594, grad=5.6540]Training epoch 14:  25%|██▌       | 41/163 [00:51<02:08,  1.05s/it, loss=0.1224, batch_acc=0.9375, running_acc=0.9594, grad=5.6540]Training epoch 14:  25%|██▌       | 41/163 [00:51<02:08,  1.05s/it, loss=0.2509, batch_acc=0.9375, running_acc=0.9588, grad=6.4754]Training epoch 14:  26%|██▌       | 42/163 [00:52<02:00,  1.00it/s, loss=0.2509, batch_acc=0.9375, running_acc=0.9588, grad=6.4754]Training epoch 14:  26%|██▌       | 42/163 [00:52<02:00,  1.00it/s, loss=0.1961, batch_acc=0.9375, running_acc=0.9583, grad=8.0564]Training epoch 14:  26%|██▋       | 43/163 [00:53<01:55,  1.04it/s, loss=0.1961, batch_acc=0.9375, running_acc=0.9583, grad=8.0564]Training epoch 14:  26%|██▋       | 43/163 [00:53<01:55,  1.04it/s, loss=0.1488, batch_acc=0.9688, running_acc=0.9586, grad=4.4468]Training epoch 14:  27%|██▋       | 44/163 [00:55<02:43,  1.38s/it, loss=0.1488, batch_acc=0.9688, running_acc=0.9586, grad=4.4468]Training epoch 14:  27%|██▋       | 44/163 [00:55<02:43,  1.38s/it, loss=0.0816, batch_acc=1.0000, running_acc=0.9595, grad=2.7897]Training epoch 14:  28%|██▊       | 45/163 [00:56<02:24,  1.23s/it, loss=0.0816, batch_acc=1.0000, running_acc=0.9595, grad=2.7897]Training epoch 14:  28%|██▊       | 45/163 [00:56<02:24,  1.23s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9604, grad=4.6596]Training epoch 14:  28%|██▊       | 46/163 [00:57<02:11,  1.12s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9604, grad=4.6596]Training epoch 14:  28%|██▊       | 46/163 [00:57<02:11,  1.12s/it, loss=0.2930, batch_acc=0.8750, running_acc=0.9586, grad=5.3758]Training epoch 14:  29%|██▉       | 47/163 [00:58<02:01,  1.05s/it, loss=0.2930, batch_acc=0.8750, running_acc=0.9586, grad=5.3758]Training epoch 14:  29%|██▉       | 47/163 [00:58<02:01,  1.05s/it, loss=0.1147, batch_acc=0.9688, running_acc=0.9588, grad=1.8569]Training epoch 14:  29%|██▉       | 48/163 [01:00<02:43,  1.43s/it, loss=0.1147, batch_acc=0.9688, running_acc=0.9588, grad=1.8569]Training epoch 14:  29%|██▉       | 48/163 [01:00<02:43,  1.43s/it, loss=0.1168, batch_acc=0.9688, running_acc=0.9590, grad=4.1000]Training epoch 14:  30%|███       | 49/163 [01:01<02:23,  1.26s/it, loss=0.1168, batch_acc=0.9688, running_acc=0.9590, grad=4.1000]Training epoch 14:  30%|███       | 49/163 [01:01<02:23,  1.26s/it, loss=0.1990, batch_acc=0.9375, running_acc=0.9585, grad=4.6220]Training epoch 14:  31%|███       | 50/163 [01:02<02:09,  1.15s/it, loss=0.1990, batch_acc=0.9375, running_acc=0.9585, grad=4.6220]Training epoch 14:  31%|███       | 50/163 [01:02<02:09,  1.15s/it, loss=0.0786, batch_acc=1.0000, running_acc=0.9594, grad=3.9757]Training epoch 14:  31%|███▏      | 51/163 [01:03<01:59,  1.07s/it, loss=0.0786, batch_acc=1.0000, running_acc=0.9594, grad=3.9757]Training epoch 14:  31%|███▏      | 51/163 [01:03<01:59,  1.07s/it, loss=0.0667, batch_acc=1.0000, running_acc=0.9602, grad=4.0964]Training epoch 14:  32%|███▏      | 52/163 [01:05<02:38,  1.43s/it, loss=0.0667, batch_acc=1.0000, running_acc=0.9602, grad=4.0964]Training epoch 14:  32%|███▏      | 52/163 [01:05<02:38,  1.43s/it, loss=0.4318, batch_acc=0.8438, running_acc=0.9579, grad=11.2413]Training epoch 14:  33%|███▎      | 53/163 [01:06<02:18,  1.26s/it, loss=0.4318, batch_acc=0.8438, running_acc=0.9579, grad=11.2413]Training epoch 14:  33%|███▎      | 53/163 [01:06<02:18,  1.26s/it, loss=0.0404, batch_acc=1.0000, running_acc=0.9587, grad=1.1364] Training epoch 14:  33%|███▎      | 54/163 [01:07<02:05,  1.15s/it, loss=0.0404, batch_acc=1.0000, running_acc=0.9587, grad=1.1364]Training epoch 14:  33%|███▎      | 54/163 [01:07<02:05,  1.15s/it, loss=0.0793, batch_acc=0.9688, running_acc=0.9589, grad=1.7476]Training epoch 14:  34%|███▎      | 55/163 [01:08<01:55,  1.07s/it, loss=0.0793, batch_acc=0.9688, running_acc=0.9589, grad=1.7476]Training epoch 14:  34%|███▎      | 55/163 [01:08<01:55,  1.07s/it, loss=0.0956, batch_acc=0.9375, running_acc=0.9585, grad=5.8287]Training epoch 14:  34%|███▍      | 56/163 [01:11<02:45,  1.54s/it, loss=0.0956, batch_acc=0.9375, running_acc=0.9585, grad=5.8287]Training epoch 14:  34%|███▍      | 56/163 [01:11<02:45,  1.54s/it, loss=0.0649, batch_acc=1.0000, running_acc=0.9593, grad=2.0798]Training epoch 14:  35%|███▍      | 57/163 [01:12<02:22,  1.34s/it, loss=0.0649, batch_acc=1.0000, running_acc=0.9593, grad=2.0798]Training epoch 14:  35%|███▍      | 57/163 [01:12<02:22,  1.34s/it, loss=0.2438, batch_acc=0.9062, running_acc=0.9583, grad=6.8428]Training epoch 14:  36%|███▌      | 58/163 [01:12<02:06,  1.21s/it, loss=0.2438, batch_acc=0.9062, running_acc=0.9583, grad=6.8428]Training epoch 14:  36%|███▌      | 58/163 [01:12<02:06,  1.21s/it, loss=0.2310, batch_acc=0.9375, running_acc=0.9580, grad=5.0631]Training epoch 14:  36%|███▌      | 59/163 [01:13<01:55,  1.11s/it, loss=0.2310, batch_acc=0.9375, running_acc=0.9580, grad=5.0631]Training epoch 14:  36%|███▌      | 59/163 [01:13<01:55,  1.11s/it, loss=0.1635, batch_acc=0.9062, running_acc=0.9571, grad=5.6587]Training epoch 14:  37%|███▋      | 60/163 [01:15<02:17,  1.34s/it, loss=0.1635, batch_acc=0.9062, running_acc=0.9571, grad=5.6587]Training epoch 14:  37%|███▋      | 60/163 [01:15<02:17,  1.34s/it, loss=0.2218, batch_acc=0.8750, running_acc=0.9557, grad=3.6256]Training epoch 14:  37%|███▋      | 61/163 [01:16<02:02,  1.20s/it, loss=0.2218, batch_acc=0.8750, running_acc=0.9557, grad=3.6256]Training epoch 14:  37%|███▋      | 61/163 [01:16<02:02,  1.20s/it, loss=0.1352, batch_acc=0.9375, running_acc=0.9554, grad=4.0527]Training epoch 14:  38%|███▊      | 62/163 [01:17<01:51,  1.10s/it, loss=0.1352, batch_acc=0.9375, running_acc=0.9554, grad=4.0527]Training epoch 14:  38%|███▊      | 62/163 [01:17<01:51,  1.10s/it, loss=0.1159, batch_acc=0.9375, running_acc=0.9551, grad=3.2954]Training epoch 14:  39%|███▊      | 63/163 [01:18<01:43,  1.04s/it, loss=0.1159, batch_acc=0.9375, running_acc=0.9551, grad=3.2954]Training epoch 14:  39%|███▊      | 63/163 [01:18<01:43,  1.04s/it, loss=0.1531, batch_acc=0.9375, running_acc=0.9549, grad=5.7909]Training epoch 14:  39%|███▉      | 64/163 [01:19<01:57,  1.19s/it, loss=0.1531, batch_acc=0.9375, running_acc=0.9549, grad=5.7909]Training epoch 14:  39%|███▉      | 64/163 [01:19<01:57,  1.19s/it, loss=0.0797, batch_acc=1.0000, running_acc=0.9556, grad=2.8924]Training epoch 14:  40%|███▉      | 65/163 [01:20<01:47,  1.10s/it, loss=0.0797, batch_acc=1.0000, running_acc=0.9556, grad=2.8924]Training epoch 14:  40%|███▉      | 65/163 [01:20<01:47,  1.10s/it, loss=0.1452, batch_acc=0.9375, running_acc=0.9553, grad=3.0293]Training epoch 14:  40%|████      | 66/163 [01:21<01:40,  1.03s/it, loss=0.1452, batch_acc=0.9375, running_acc=0.9553, grad=3.0293]Training epoch 14:  40%|████      | 66/163 [01:21<01:40,  1.03s/it, loss=0.0708, batch_acc=1.0000, running_acc=0.9560, grad=3.1609]Training epoch 14:  41%|████      | 67/163 [01:22<01:34,  1.01it/s, loss=0.0708, batch_acc=1.0000, running_acc=0.9560, grad=3.1609]Training epoch 14:  41%|████      | 67/163 [01:22<01:34,  1.01it/s, loss=0.0965, batch_acc=0.9688, running_acc=0.9562, grad=3.9821]Training epoch 14:  42%|████▏     | 68/163 [01:24<01:54,  1.21s/it, loss=0.0965, batch_acc=0.9688, running_acc=0.9562, grad=3.9821]Training epoch 14:  42%|████▏     | 68/163 [01:24<01:54,  1.21s/it, loss=0.1184, batch_acc=0.9688, running_acc=0.9563, grad=4.8689]Training epoch 14:  42%|████▏     | 69/163 [01:25<01:47,  1.14s/it, loss=0.1184, batch_acc=0.9688, running_acc=0.9563, grad=4.8689]Training epoch 14:  42%|████▏     | 69/163 [01:25<01:47,  1.14s/it, loss=0.1074, batch_acc=0.9375, running_acc=0.9561, grad=1.9900]Training epoch 14:  43%|████▎     | 70/163 [01:26<01:38,  1.06s/it, loss=0.1074, batch_acc=0.9375, running_acc=0.9561, grad=1.9900]Training epoch 14:  43%|████▎     | 70/163 [01:26<01:38,  1.06s/it, loss=0.1812, batch_acc=0.9688, running_acc=0.9563, grad=4.0717]Training epoch 14:  44%|████▎     | 71/163 [01:26<01:32,  1.01s/it, loss=0.1812, batch_acc=0.9688, running_acc=0.9563, grad=4.0717]Training epoch 14:  44%|████▎     | 71/163 [01:26<01:32,  1.01s/it, loss=0.1161, batch_acc=0.9688, running_acc=0.9564, grad=3.0774]Training epoch 14:  44%|████▍     | 72/163 [01:28<01:59,  1.31s/it, loss=0.1161, batch_acc=0.9688, running_acc=0.9564, grad=3.0774]Training epoch 14:  44%|████▍     | 72/163 [01:28<01:59,  1.31s/it, loss=0.2177, batch_acc=0.9062, running_acc=0.9557, grad=4.8778]Training epoch 14:  45%|████▍     | 73/163 [01:29<01:46,  1.18s/it, loss=0.2177, batch_acc=0.9062, running_acc=0.9557, grad=4.8778]Training epoch 14:  45%|████▍     | 73/163 [01:29<01:46,  1.18s/it, loss=0.0750, batch_acc=1.0000, running_acc=0.9563, grad=2.6726][2025-12-08T12:38:04.443] error: *** JOB 682572 ON n0801 CANCELLED AT 2025-12-08T12:38:04 DUE to SIGNAL Terminated ***
