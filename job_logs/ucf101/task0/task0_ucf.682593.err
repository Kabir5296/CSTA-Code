Training epoch 0:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 0:   1%|          | 1/163 [00:06<16:57,  6.28s/it]Training epoch 0:   1%|          | 1/163 [00:06<16:57,  6.28s/it, loss=3.9124, batch_acc=0.0000, running_acc=0.0000, grad=7.7531]Training epoch 0:   1%|          | 2/163 [00:07<08:19,  3.10s/it, loss=3.9124, batch_acc=0.0000, running_acc=0.0000, grad=7.7531]Training epoch 0:   1%|          | 2/163 [00:07<08:19,  3.10s/it, loss=3.9773, batch_acc=0.0000, running_acc=0.0000, grad=7.7353]Training epoch 0:   2%|▏         | 3/163 [00:08<05:34,  2.09s/it, loss=3.9773, batch_acc=0.0000, running_acc=0.0000, grad=7.7353]Training epoch 0:   2%|▏         | 3/163 [00:08<05:34,  2.09s/it, loss=4.0521, batch_acc=0.0000, running_acc=0.0000, grad=7.1475]Training epoch 0:   2%|▏         | 4/163 [00:09<04:57,  1.87s/it, loss=4.0521, batch_acc=0.0000, running_acc=0.0000, grad=7.1475]Training epoch 0:   2%|▏         | 4/163 [00:09<04:57,  1.87s/it, loss=4.0147, batch_acc=0.0000, running_acc=0.0000, grad=7.6124]Training epoch 0:   3%|▎         | 5/163 [00:10<04:09,  1.58s/it, loss=4.0147, batch_acc=0.0000, running_acc=0.0000, grad=7.6124]Training epoch 0:   3%|▎         | 5/163 [00:10<04:09,  1.58s/it, loss=4.0540, batch_acc=0.0312, running_acc=0.0063, grad=6.9243]Training epoch 0:   4%|▎         | 6/163 [00:11<03:30,  1.34s/it, loss=4.0540, batch_acc=0.0312, running_acc=0.0063, grad=6.9243]Training epoch 0:   4%|▎         | 6/163 [00:11<03:30,  1.34s/it, loss=3.8663, batch_acc=0.0625, running_acc=0.0156, grad=6.3863]Training epoch 0:   4%|▍         | 7/163 [00:12<03:05,  1.19s/it, loss=3.8663, batch_acc=0.0625, running_acc=0.0156, grad=6.3863]Training epoch 0:   4%|▍         | 7/163 [00:12<03:05,  1.19s/it, loss=3.8601, batch_acc=0.1250, running_acc=0.0312, grad=6.8127]Training epoch 0:   5%|▍         | 8/163 [00:13<02:52,  1.11s/it, loss=3.8601, batch_acc=0.1250, running_acc=0.0312, grad=6.8127]Training epoch 0:   5%|▍         | 8/163 [00:13<02:52,  1.11s/it, loss=3.9814, batch_acc=0.0312, running_acc=0.0312, grad=6.9315]Training epoch 0:   6%|▌         | 9/163 [00:15<03:23,  1.32s/it, loss=3.9814, batch_acc=0.0312, running_acc=0.0312, grad=6.9315]Training epoch 0:   6%|▌         | 9/163 [00:15<03:23,  1.32s/it, loss=3.8799, batch_acc=0.0312, running_acc=0.0312, grad=7.7387]Training epoch 0:   6%|▌         | 10/163 [00:16<03:01,  1.18s/it, loss=3.8799, batch_acc=0.0312, running_acc=0.0312, grad=7.7387]Training epoch 0:   6%|▌         | 10/163 [00:16<03:01,  1.18s/it, loss=3.9638, batch_acc=0.0000, running_acc=0.0281, grad=7.2828]Training epoch 0:   7%|▋         | 11/163 [00:16<02:45,  1.09s/it, loss=3.9638, batch_acc=0.0000, running_acc=0.0281, grad=7.2828]Training epoch 0:   7%|▋         | 11/163 [00:16<02:45,  1.09s/it, loss=3.9616, batch_acc=0.0312, running_acc=0.0284, grad=6.3566]Training epoch 0:   7%|▋         | 12/163 [00:17<02:35,  1.03s/it, loss=3.9616, batch_acc=0.0312, running_acc=0.0284, grad=6.3566]Training epoch 0:   7%|▋         | 12/163 [00:17<02:35,  1.03s/it, loss=3.9690, batch_acc=0.0625, running_acc=0.0312, grad=7.0494]Training epoch 0:   8%|▊         | 13/163 [00:19<03:19,  1.33s/it, loss=3.9690, batch_acc=0.0625, running_acc=0.0312, grad=7.0494]Training epoch 0:   8%|▊         | 13/163 [00:19<03:19,  1.33s/it, loss=4.0158, batch_acc=0.0625, running_acc=0.0337, grad=7.1269]Training epoch 0:   9%|▊         | 14/163 [00:20<02:57,  1.19s/it, loss=4.0158, batch_acc=0.0625, running_acc=0.0337, grad=7.1269]Training epoch 0:   9%|▊         | 14/163 [00:20<02:57,  1.19s/it, loss=3.9893, batch_acc=0.0312, running_acc=0.0335, grad=6.5726]Training epoch 0:   9%|▉         | 15/163 [00:21<02:42,  1.10s/it, loss=3.9893, batch_acc=0.0312, running_acc=0.0335, grad=6.5726]Training epoch 0:   9%|▉         | 15/163 [00:21<02:42,  1.10s/it, loss=3.7899, batch_acc=0.0625, running_acc=0.0354, grad=7.3611]Training epoch 0:  10%|▉         | 16/163 [00:22<02:32,  1.04s/it, loss=3.7899, batch_acc=0.0625, running_acc=0.0354, grad=7.3611]Training epoch 0:  10%|▉         | 16/163 [00:22<02:32,  1.04s/it, loss=3.8711, batch_acc=0.0312, running_acc=0.0352, grad=7.4124]Training epoch 0:  10%|█         | 17/163 [00:23<02:46,  1.14s/it, loss=3.8711, batch_acc=0.0312, running_acc=0.0352, grad=7.4124]Training epoch 0:  10%|█         | 17/163 [00:23<02:46,  1.14s/it, loss=3.8254, batch_acc=0.0938, running_acc=0.0386, grad=7.3843]Training epoch 0:  11%|█         | 18/163 [00:24<02:34,  1.06s/it, loss=3.8254, batch_acc=0.0938, running_acc=0.0386, grad=7.3843]Training epoch 0:  11%|█         | 18/163 [00:24<02:34,  1.06s/it, loss=3.8496, batch_acc=0.0938, running_acc=0.0417, grad=6.3984]Training epoch 0:  12%|█▏        | 19/163 [00:25<02:25,  1.01s/it, loss=3.8496, batch_acc=0.0938, running_acc=0.0417, grad=6.3984]Training epoch 0:  12%|█▏        | 19/163 [00:25<02:25,  1.01s/it, loss=3.9968, batch_acc=0.0312, running_acc=0.0411, grad=6.9809]Training epoch 0:  12%|█▏        | 20/163 [00:26<02:25,  1.02s/it, loss=3.9968, batch_acc=0.0312, running_acc=0.0411, grad=6.9809]Training epoch 0:  12%|█▏        | 20/163 [00:26<02:25,  1.02s/it, loss=3.8191, batch_acc=0.0312, running_acc=0.0406, grad=7.2190]Training epoch 0:  13%|█▎        | 21/163 [00:28<02:52,  1.22s/it, loss=3.8191, batch_acc=0.0312, running_acc=0.0406, grad=7.2190]Training epoch 0:  13%|█▎        | 21/163 [00:28<02:52,  1.22s/it, loss=3.8279, batch_acc=0.0312, running_acc=0.0402, grad=5.8675]Training epoch 0:  13%|█▎        | 22/163 [00:29<02:37,  1.12s/it, loss=3.8279, batch_acc=0.0312, running_acc=0.0402, grad=5.8675]Training epoch 0:  13%|█▎        | 22/163 [00:29<02:37,  1.12s/it, loss=3.8284, batch_acc=0.0625, running_acc=0.0412, grad=7.1560]Training epoch 0:  14%|█▍        | 23/163 [00:30<02:26,  1.05s/it, loss=3.8284, batch_acc=0.0625, running_acc=0.0412, grad=7.1560]Training epoch 0:  14%|█▍        | 23/163 [00:30<02:26,  1.05s/it, loss=3.8486, batch_acc=0.0938, running_acc=0.0435, grad=6.5699]Training epoch 0:  15%|█▍        | 24/163 [00:31<02:26,  1.06s/it, loss=3.8486, batch_acc=0.0938, running_acc=0.0435, grad=6.5699]Training epoch 0:  15%|█▍        | 24/163 [00:31<02:26,  1.06s/it, loss=3.8784, batch_acc=0.1250, running_acc=0.0469, grad=7.0113]Training epoch 0:  15%|█▌        | 25/163 [00:32<02:50,  1.24s/it, loss=3.8784, batch_acc=0.1250, running_acc=0.0469, grad=7.0113]Training epoch 0:  15%|█▌        | 25/163 [00:32<02:50,  1.24s/it, loss=3.8764, batch_acc=0.0000, running_acc=0.0450, grad=7.0590]Training epoch 0:  16%|█▌        | 26/163 [00:33<02:35,  1.13s/it, loss=3.8764, batch_acc=0.0000, running_acc=0.0450, grad=7.0590]Training epoch 0:  16%|█▌        | 26/163 [00:33<02:35,  1.13s/it, loss=3.7943, batch_acc=0.0625, running_acc=0.0457, grad=6.0664]Training epoch 0:  17%|█▋        | 27/163 [00:34<02:23,  1.06s/it, loss=3.7943, batch_acc=0.0625, running_acc=0.0457, grad=6.0664]Training epoch 0:  17%|█▋        | 27/163 [00:34<02:23,  1.06s/it, loss=3.8651, batch_acc=0.0625, running_acc=0.0463, grad=7.1274]Training epoch 0:  17%|█▋        | 28/163 [00:35<02:18,  1.03s/it, loss=3.8651, batch_acc=0.0625, running_acc=0.0463, grad=7.1274]Training epoch 0:  17%|█▋        | 28/163 [00:35<02:18,  1.03s/it, loss=3.7930, batch_acc=0.0312, running_acc=0.0458, grad=7.7246]Training epoch 0:  18%|█▊        | 29/163 [00:37<02:47,  1.25s/it, loss=3.7930, batch_acc=0.0312, running_acc=0.0458, grad=7.7246]Training epoch 0:  18%|█▊        | 29/163 [00:37<02:47,  1.25s/it, loss=3.8008, batch_acc=0.1250, running_acc=0.0485, grad=8.2474]Training epoch 0:  18%|█▊        | 30/163 [00:38<02:31,  1.14s/it, loss=3.8008, batch_acc=0.1250, running_acc=0.0485, grad=8.2474]Training epoch 0:  18%|█▊        | 30/163 [00:38<02:31,  1.14s/it, loss=3.8008, batch_acc=0.0938, running_acc=0.0500, grad=7.1860]Training epoch 0:  19%|█▉        | 31/163 [00:39<02:20,  1.07s/it, loss=3.8008, batch_acc=0.0938, running_acc=0.0500, grad=7.1860]Training epoch 0:  19%|█▉        | 31/163 [00:39<02:20,  1.07s/it, loss=3.9291, batch_acc=0.0000, running_acc=0.0484, grad=6.4059]Training epoch 0:  20%|█▉        | 32/163 [00:40<02:19,  1.06s/it, loss=3.9291, batch_acc=0.0000, running_acc=0.0484, grad=6.4059]Training epoch 0:  20%|█▉        | 32/163 [00:40<02:19,  1.06s/it, loss=3.8858, batch_acc=0.0625, running_acc=0.0488, grad=7.0113]Training epoch 0:  20%|██        | 33/163 [00:41<02:25,  1.12s/it, loss=3.8858, batch_acc=0.0625, running_acc=0.0488, grad=7.0113]Training epoch 0:  20%|██        | 33/163 [00:41<02:25,  1.12s/it, loss=3.8447, batch_acc=0.0625, running_acc=0.0492, grad=5.8834]Training epoch 0:  21%|██        | 34/163 [00:42<02:15,  1.05s/it, loss=3.8447, batch_acc=0.0625, running_acc=0.0492, grad=5.8834]Training epoch 0:  21%|██        | 34/163 [00:42<02:15,  1.05s/it, loss=3.8124, batch_acc=0.0625, running_acc=0.0496, grad=6.5910]Training epoch 0:  21%|██▏       | 35/163 [00:43<02:07,  1.00it/s, loss=3.8124, batch_acc=0.0625, running_acc=0.0496, grad=6.5910]Training epoch 0:  21%|██▏       | 35/163 [00:43<02:07,  1.00it/s, loss=3.9277, batch_acc=0.0000, running_acc=0.0482, grad=8.6403]Training epoch 0:  22%|██▏       | 36/163 [00:44<02:28,  1.17s/it, loss=3.9277, batch_acc=0.0000, running_acc=0.0482, grad=8.6403]Training epoch 0:  22%|██▏       | 36/163 [00:44<02:28,  1.17s/it, loss=3.7563, batch_acc=0.0938, running_acc=0.0495, grad=5.9120]Training epoch 0:  23%|██▎       | 37/163 [00:45<02:19,  1.11s/it, loss=3.7563, batch_acc=0.0938, running_acc=0.0495, grad=5.9120]Training epoch 0:  23%|██▎       | 37/163 [00:45<02:19,  1.11s/it, loss=3.8503, batch_acc=0.0312, running_acc=0.0490, grad=5.9462]Training epoch 0:  23%|██▎       | 38/163 [00:46<02:10,  1.04s/it, loss=3.8503, batch_acc=0.0312, running_acc=0.0490, grad=5.9462]Training epoch 0:  23%|██▎       | 38/163 [00:46<02:10,  1.04s/it, loss=3.8700, batch_acc=0.0000, running_acc=0.0477, grad=6.3658]Training epoch 0:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=3.8700, batch_acc=0.0000, running_acc=0.0477, grad=6.3658]Training epoch 0:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=3.7255, batch_acc=0.0625, running_acc=0.0481, grad=7.2737]Training epoch 0:  25%|██▍       | 40/163 [00:48<02:19,  1.13s/it, loss=3.7255, batch_acc=0.0625, running_acc=0.0481, grad=7.2737]Training epoch 0:  25%|██▍       | 40/163 [00:48<02:19,  1.13s/it, loss=3.8714, batch_acc=0.0625, running_acc=0.0484, grad=6.8374]Training epoch 0:  25%|██▌       | 41/163 [00:50<02:22,  1.17s/it, loss=3.8714, batch_acc=0.0625, running_acc=0.0484, grad=6.8374]Training epoch 0:  25%|██▌       | 41/163 [00:50<02:22,  1.17s/it, loss=3.7480, batch_acc=0.0625, running_acc=0.0488, grad=6.9273]Training epoch 0:  26%|██▌       | 42/163 [00:51<02:14,  1.11s/it, loss=3.7480, batch_acc=0.0625, running_acc=0.0488, grad=6.9273]Training epoch 0:  26%|██▌       | 42/163 [00:51<02:14,  1.11s/it, loss=3.6966, batch_acc=0.0625, running_acc=0.0491, grad=6.3869]Training epoch 0:  26%|██▋       | 43/163 [00:52<02:05,  1.04s/it, loss=3.6966, batch_acc=0.0625, running_acc=0.0491, grad=6.3869]Training epoch 0:  26%|██▋       | 43/163 [00:52<02:05,  1.04s/it, loss=3.7149, batch_acc=0.0625, running_acc=0.0494, grad=6.9273]Training epoch 0:  27%|██▋       | 44/163 [00:53<02:30,  1.26s/it, loss=3.7149, batch_acc=0.0625, running_acc=0.0494, grad=6.9273]Training epoch 0:  27%|██▋       | 44/163 [00:53<02:30,  1.26s/it, loss=3.7511, batch_acc=0.1250, running_acc=0.0511, grad=6.2680]Training epoch 0:  28%|██▊       | 45/163 [00:54<02:15,  1.15s/it, loss=3.7511, batch_acc=0.1250, running_acc=0.0511, grad=6.2680]Training epoch 0:  28%|██▊       | 45/163 [00:54<02:15,  1.15s/it, loss=3.5129, batch_acc=0.2188, running_acc=0.0549, grad=6.8176]Training epoch 0:  28%|██▊       | 46/163 [00:55<02:08,  1.10s/it, loss=3.5129, batch_acc=0.2188, running_acc=0.0549, grad=6.8176]Training epoch 0:  28%|██▊       | 46/163 [00:55<02:08,  1.10s/it, loss=3.8288, batch_acc=0.0312, running_acc=0.0543, grad=7.8014]Training epoch 0:  29%|██▉       | 47/163 [00:56<02:00,  1.04s/it, loss=3.8288, batch_acc=0.0312, running_acc=0.0543, grad=7.8014]Training epoch 0:  29%|██▉       | 47/163 [00:56<02:00,  1.04s/it, loss=3.6477, batch_acc=0.0938, running_acc=0.0552, grad=5.7946]Training epoch 0:  29%|██▉       | 48/163 [00:57<01:59,  1.04s/it, loss=3.6477, batch_acc=0.0938, running_acc=0.0552, grad=5.7946]Training epoch 0:  29%|██▉       | 48/163 [00:57<01:59,  1.04s/it, loss=3.7731, batch_acc=0.0625, running_acc=0.0553, grad=6.1277]Training epoch 0:  30%|███       | 49/163 [00:59<02:09,  1.14s/it, loss=3.7731, batch_acc=0.0625, running_acc=0.0553, grad=6.1277]Training epoch 0:  30%|███       | 49/163 [00:59<02:09,  1.14s/it, loss=3.8049, batch_acc=0.0625, running_acc=0.0555, grad=7.1967]Training epoch 0:  31%|███       | 50/163 [00:59<01:59,  1.06s/it, loss=3.8049, batch_acc=0.0625, running_acc=0.0555, grad=7.1967]Training epoch 0:  31%|███       | 50/163 [00:59<01:59,  1.06s/it, loss=3.6562, batch_acc=0.1250, running_acc=0.0569, grad=6.5618]Training epoch 0:  31%|███▏      | 51/163 [01:00<01:52,  1.01s/it, loss=3.6562, batch_acc=0.1250, running_acc=0.0569, grad=6.5618]Training epoch 0:  31%|███▏      | 51/163 [01:00<01:52,  1.01s/it, loss=3.8340, batch_acc=0.0312, running_acc=0.0564, grad=6.6725]Training epoch 0:  32%|███▏      | 52/163 [01:01<01:50,  1.00it/s, loss=3.8340, batch_acc=0.0312, running_acc=0.0564, grad=6.6725]Training epoch 0:  32%|███▏      | 52/163 [01:01<01:50,  1.00it/s, loss=3.6844, batch_acc=0.0625, running_acc=0.0565, grad=6.7952]Training epoch 0:  33%|███▎      | 53/163 [01:03<02:07,  1.16s/it, loss=3.6844, batch_acc=0.0625, running_acc=0.0565, grad=6.7952]Training epoch 0:  33%|███▎      | 53/163 [01:03<02:07,  1.16s/it, loss=3.7690, batch_acc=0.0625, running_acc=0.0566, grad=6.4451]Training epoch 0:  33%|███▎      | 54/163 [01:04<01:57,  1.08s/it, loss=3.7690, batch_acc=0.0625, running_acc=0.0566, grad=6.4451]Training epoch 0:  33%|███▎      | 54/163 [01:04<01:57,  1.08s/it, loss=3.8238, batch_acc=0.0312, running_acc=0.0561, grad=5.8485]Training epoch 0:  34%|███▎      | 55/163 [01:05<01:49,  1.02s/it, loss=3.8238, batch_acc=0.0312, running_acc=0.0561, grad=5.8485]Training epoch 0:  34%|███▎      | 55/163 [01:05<01:49,  1.02s/it, loss=3.7763, batch_acc=0.1250, running_acc=0.0574, grad=5.4041]Training epoch 0:  34%|███▍      | 56/163 [01:06<01:47,  1.00s/it, loss=3.7763, batch_acc=0.1250, running_acc=0.0574, grad=5.4041]Training epoch 0:  34%|███▍      | 56/163 [01:06<01:47,  1.00s/it, loss=3.7914, batch_acc=0.0625, running_acc=0.0575, grad=6.4602]Training epoch 0:  35%|███▍      | 57/163 [01:07<01:51,  1.05s/it, loss=3.7914, batch_acc=0.0625, running_acc=0.0575, grad=6.4602]Training epoch 0:  35%|███▍      | 57/163 [01:07<01:51,  1.05s/it, loss=3.6941, batch_acc=0.0938, running_acc=0.0581, grad=6.8523]Training epoch 0:  36%|███▌      | 58/163 [01:08<01:45,  1.00s/it, loss=3.6941, batch_acc=0.0938, running_acc=0.0581, grad=6.8523]Training epoch 0:  36%|███▌      | 58/163 [01:08<01:45,  1.00s/it, loss=3.6904, batch_acc=0.0938, running_acc=0.0587, grad=6.7538]Training epoch 0:  36%|███▌      | 59/163 [01:08<01:40,  1.04it/s, loss=3.6904, batch_acc=0.0938, running_acc=0.0587, grad=6.7538]Training epoch 0:  36%|███▌      | 59/163 [01:08<01:40,  1.04it/s, loss=3.8423, batch_acc=0.0625, running_acc=0.0588, grad=7.3020]Training epoch 0:  37%|███▋      | 60/163 [01:09<01:36,  1.06it/s, loss=3.8423, batch_acc=0.0625, running_acc=0.0588, grad=7.3020]Training epoch 0:  37%|███▋      | 60/163 [01:09<01:36,  1.06it/s, loss=3.6986, batch_acc=0.0938, running_acc=0.0594, grad=6.7041]Training epoch 0:  37%|███▋      | 61/163 [01:11<02:05,  1.23s/it, loss=3.6986, batch_acc=0.0938, running_acc=0.0594, grad=6.7041]Training epoch 0:  37%|███▋      | 61/163 [01:11<02:05,  1.23s/it, loss=3.5141, batch_acc=0.1562, running_acc=0.0610, grad=5.8001]Training epoch 0:  38%|███▊      | 62/163 [01:12<01:53,  1.13s/it, loss=3.5141, batch_acc=0.1562, running_acc=0.0610, grad=5.8001]Training epoch 0:  38%|███▊      | 62/163 [01:12<01:53,  1.13s/it, loss=3.7167, batch_acc=0.1250, running_acc=0.0620, grad=5.8890]Training epoch 0:  39%|███▊      | 63/163 [01:13<01:45,  1.05s/it, loss=3.7167, batch_acc=0.1250, running_acc=0.0620, grad=5.8890]Training epoch 0:  39%|███▊      | 63/163 [01:13<01:45,  1.05s/it, loss=3.6599, batch_acc=0.1250, running_acc=0.0630, grad=7.2349]Training epoch 0:  39%|███▉      | 64/163 [01:14<01:39,  1.00s/it, loss=3.6599, batch_acc=0.1250, running_acc=0.0630, grad=7.2349]Training epoch 0:  39%|███▉      | 64/163 [01:14<01:39,  1.00s/it, loss=3.5695, batch_acc=0.1250, running_acc=0.0640, grad=6.7922]Training epoch 0:  40%|███▉      | 65/163 [01:15<01:40,  1.02s/it, loss=3.5695, batch_acc=0.1250, running_acc=0.0640, grad=6.7922]Training epoch 0:  40%|███▉      | 65/163 [01:15<01:40,  1.02s/it, loss=3.7920, batch_acc=0.0938, running_acc=0.0644, grad=7.0494]Training epoch 0:  40%|████      | 66/163 [01:16<01:34,  1.02it/s, loss=3.7920, batch_acc=0.0938, running_acc=0.0644, grad=7.0494]Training epoch 0:  40%|████      | 66/163 [01:16<01:34,  1.02it/s, loss=3.8123, batch_acc=0.0625, running_acc=0.0644, grad=7.3688]Training epoch 0:  41%|████      | 67/163 [01:17<01:31,  1.05it/s, loss=3.8123, batch_acc=0.0625, running_acc=0.0644, grad=7.3688]Training epoch 0:  41%|████      | 67/163 [01:17<01:31,  1.05it/s, loss=3.8665, batch_acc=0.0000, running_acc=0.0634, grad=6.8842]Training epoch 0:  42%|████▏     | 68/163 [01:18<01:45,  1.11s/it, loss=3.8665, batch_acc=0.0000, running_acc=0.0634, grad=6.8842]Training epoch 0:  42%|████▏     | 68/163 [01:18<01:45,  1.11s/it, loss=3.5190, batch_acc=0.1562, running_acc=0.0648, grad=6.3408]Training epoch 0:  42%|████▏     | 69/163 [01:20<01:52,  1.20s/it, loss=3.5190, batch_acc=0.1562, running_acc=0.0648, grad=6.3408]Training epoch 0:  42%|████▏     | 69/163 [01:20<01:52,  1.20s/it, loss=3.6668, batch_acc=0.0938, running_acc=0.0652, grad=6.9231]Training epoch 0:  43%|████▎     | 70/163 [01:21<01:45,  1.13s/it, loss=3.6668, batch_acc=0.0938, running_acc=0.0652, grad=6.9231]Training epoch 0:  43%|████▎     | 70/163 [01:21<01:45,  1.13s/it, loss=3.5909, batch_acc=0.1250, running_acc=0.0661, grad=6.1209]Training epoch 0:  44%|████▎     | 71/163 [01:21<01:37,  1.06s/it, loss=3.5909, batch_acc=0.1250, running_acc=0.0661, grad=6.1209]Training epoch 0:  44%|████▎     | 71/163 [01:21<01:37,  1.06s/it, loss=3.5335, batch_acc=0.1562, running_acc=0.0673, grad=6.3293]Training epoch 0:  44%|████▍     | 72/163 [01:23<01:42,  1.13s/it, loss=3.5335, batch_acc=0.1562, running_acc=0.0673, grad=6.3293]Training epoch 0:  44%|████▍     | 72/163 [01:23<01:42,  1.13s/it, loss=3.6641, batch_acc=0.0625, running_acc=0.0673, grad=6.9732]Training epoch 0:  45%|████▍     | 73/163 [01:24<01:43,  1.15s/it, loss=3.6641, batch_acc=0.0625, running_acc=0.0673, grad=6.9732]Training epoch 0:  45%|████▍     | 73/163 [01:24<01:43,  1.15s/it, loss=3.6330, batch_acc=0.1562, running_acc=0.0685, grad=6.4116]Training epoch 0:  45%|████▌     | 74/163 [01:25<01:36,  1.09s/it, loss=3.6330, batch_acc=0.1562, running_acc=0.0685, grad=6.4116]Training epoch 0:  45%|████▌     | 74/163 [01:25<01:36,  1.09s/it, loss=3.6410, batch_acc=0.0625, running_acc=0.0684, grad=6.0893]Training epoch 0:  46%|████▌     | 75/163 [01:26<01:30,  1.03s/it, loss=3.6410, batch_acc=0.0625, running_acc=0.0684, grad=6.0893]Training epoch 0:  46%|████▌     | 75/163 [01:26<01:30,  1.03s/it, loss=3.8578, batch_acc=0.0312, running_acc=0.0679, grad=7.5167]Training epoch 0:  47%|████▋     | 76/163 [01:27<01:39,  1.14s/it, loss=3.8578, batch_acc=0.0312, running_acc=0.0679, grad=7.5167]Training epoch 0:  47%|████▋     | 76/163 [01:27<01:39,  1.14s/it, loss=3.8304, batch_acc=0.0625, running_acc=0.0678, grad=6.2983]Training epoch 0:  47%|████▋     | 77/163 [01:29<01:46,  1.24s/it, loss=3.8304, batch_acc=0.0625, running_acc=0.0678, grad=6.2983]Training epoch 0:  47%|████▋     | 77/163 [01:29<01:46,  1.24s/it, loss=3.5923, batch_acc=0.1250, running_acc=0.0686, grad=7.3307]Training epoch 0:  48%|████▊     | 78/163 [01:30<01:36,  1.13s/it, loss=3.5923, batch_acc=0.1250, running_acc=0.0686, grad=7.3307]Training epoch 0:  48%|████▊     | 78/163 [01:30<01:36,  1.13s/it, loss=3.4561, batch_acc=0.1250, running_acc=0.0693, grad=6.2736]Training epoch 0:  48%|████▊     | 79/163 [01:30<01:28,  1.06s/it, loss=3.4561, batch_acc=0.1250, running_acc=0.0693, grad=6.2736]Training epoch 0:  48%|████▊     | 79/163 [01:30<01:28,  1.06s/it, loss=3.5326, batch_acc=0.0938, running_acc=0.0696, grad=6.7838]Training epoch 0:  49%|████▉     | 80/163 [01:31<01:24,  1.01s/it, loss=3.5326, batch_acc=0.0938, running_acc=0.0696, grad=6.7838]Training epoch 0:  49%|████▉     | 80/163 [01:31<01:24,  1.01s/it, loss=3.7590, batch_acc=0.0625, running_acc=0.0695, grad=7.6523]Training epoch 0:  50%|████▉     | 81/163 [01:33<01:27,  1.06s/it, loss=3.7590, batch_acc=0.0625, running_acc=0.0695, grad=7.6523]Training epoch 0:  50%|████▉     | 81/163 [01:33<01:27,  1.06s/it, loss=3.6671, batch_acc=0.0625, running_acc=0.0694, grad=6.6106]Training epoch 0:  50%|█████     | 82/163 [01:33<01:21,  1.01s/it, loss=3.6671, batch_acc=0.0625, running_acc=0.0694, grad=6.6106]Training epoch 0:  50%|█████     | 82/163 [01:33<01:21,  1.01s/it, loss=3.6115, batch_acc=0.0938, running_acc=0.0697, grad=6.4163]Training epoch 0:  51%|█████     | 83/163 [01:34<01:17,  1.03it/s, loss=3.6115, batch_acc=0.0938, running_acc=0.0697, grad=6.4163]Training epoch 0:  51%|█████     | 83/163 [01:34<01:17,  1.03it/s, loss=3.7177, batch_acc=0.0625, running_acc=0.0697, grad=8.4590]Training epoch 0:  52%|█████▏    | 84/163 [01:36<01:25,  1.08s/it, loss=3.7177, batch_acc=0.0625, running_acc=0.0697, grad=8.4590]Training epoch 0:  52%|█████▏    | 84/163 [01:36<01:25,  1.08s/it, loss=3.5576, batch_acc=0.1250, running_acc=0.0703, grad=7.0310]Training epoch 0:  52%|█████▏    | 85/163 [01:37<01:30,  1.16s/it, loss=3.5576, batch_acc=0.1250, running_acc=0.0703, grad=7.0310]Training epoch 0:  52%|█████▏    | 85/163 [01:37<01:30,  1.16s/it, loss=3.7265, batch_acc=0.0625, running_acc=0.0702, grad=7.7926]Training epoch 0:  53%|█████▎    | 86/163 [01:38<01:22,  1.08s/it, loss=3.7265, batch_acc=0.0625, running_acc=0.0702, grad=7.7926]Training epoch 0:  53%|█████▎    | 86/163 [01:38<01:22,  1.08s/it, loss=3.5217, batch_acc=0.0938, running_acc=0.0705, grad=6.3111]Training epoch 0:  53%|█████▎    | 87/163 [01:39<01:17,  1.02s/it, loss=3.5217, batch_acc=0.0938, running_acc=0.0705, grad=6.3111]Training epoch 0:  53%|█████▎    | 87/163 [01:39<01:17,  1.02s/it, loss=3.7628, batch_acc=0.0000, running_acc=0.0697, grad=7.7310]Training epoch 0:  54%|█████▍    | 88/163 [01:40<01:18,  1.05s/it, loss=3.7628, batch_acc=0.0000, running_acc=0.0697, grad=7.7310]Training epoch 0:  54%|█████▍    | 88/163 [01:40<01:18,  1.05s/it, loss=3.6218, batch_acc=0.0938, running_acc=0.0700, grad=7.0309]Training epoch 0:  55%|█████▍    | 89/163 [01:41<01:24,  1.15s/it, loss=3.6218, batch_acc=0.0938, running_acc=0.0700, grad=7.0309]Training epoch 0:  55%|█████▍    | 89/163 [01:41<01:24,  1.15s/it, loss=3.8271, batch_acc=0.0000, running_acc=0.0692, grad=6.1418]Training epoch 0:  55%|█████▌    | 90/163 [01:42<01:17,  1.07s/it, loss=3.8271, batch_acc=0.0000, running_acc=0.0692, grad=6.1418]Training epoch 0:  55%|█████▌    | 90/163 [01:42<01:17,  1.07s/it, loss=3.5268, batch_acc=0.1562, running_acc=0.0701, grad=6.7956]Training epoch 0:  56%|█████▌    | 91/163 [01:43<01:12,  1.01s/it, loss=3.5268, batch_acc=0.1562, running_acc=0.0701, grad=6.7956]Training epoch 0:  56%|█████▌    | 91/163 [01:43<01:12,  1.01s/it, loss=3.6147, batch_acc=0.1250, running_acc=0.0707, grad=6.1796]Training epoch 0:  56%|█████▋    | 92/163 [01:44<01:18,  1.11s/it, loss=3.6147, batch_acc=0.1250, running_acc=0.0707, grad=6.1796]Training epoch 0:  56%|█████▋    | 92/163 [01:44<01:18,  1.11s/it, loss=3.5864, batch_acc=0.1875, running_acc=0.0720, grad=6.1673]Training epoch 0:  57%|█████▋    | 93/163 [01:46<01:20,  1.15s/it, loss=3.5864, batch_acc=0.1875, running_acc=0.0720, grad=6.1673]Training epoch 0:  57%|█████▋    | 93/163 [01:46<01:20,  1.15s/it, loss=3.6505, batch_acc=0.0312, running_acc=0.0716, grad=7.1237]Training epoch 0:  58%|█████▊    | 94/163 [01:46<01:13,  1.07s/it, loss=3.6505, batch_acc=0.0312, running_acc=0.0716, grad=7.1237]Training epoch 0:  58%|█████▊    | 94/163 [01:46<01:13,  1.07s/it, loss=3.6353, batch_acc=0.0938, running_acc=0.0718, grad=6.0675]Training epoch 0:  58%|█████▊    | 95/163 [01:47<01:08,  1.01s/it, loss=3.6353, batch_acc=0.0938, running_acc=0.0718, grad=6.0675]Training epoch 0:  58%|█████▊    | 95/163 [01:47<01:08,  1.01s/it, loss=3.7338, batch_acc=0.1250, running_acc=0.0724, grad=6.9665]Training epoch 0:  59%|█████▉    | 96/163 [01:49<01:19,  1.18s/it, loss=3.7338, batch_acc=0.1250, running_acc=0.0724, grad=6.9665]Training epoch 0:  59%|█████▉    | 96/163 [01:49<01:19,  1.18s/it, loss=3.5373, batch_acc=0.0938, running_acc=0.0726, grad=7.2551]Training epoch 0:  60%|█████▉    | 97/163 [01:50<01:12,  1.09s/it, loss=3.5373, batch_acc=0.0938, running_acc=0.0726, grad=7.2551]Training epoch 0:  60%|█████▉    | 97/163 [01:50<01:12,  1.09s/it, loss=3.5643, batch_acc=0.0938, running_acc=0.0728, grad=7.2345]Training epoch 0:  60%|██████    | 98/163 [01:51<01:06,  1.03s/it, loss=3.5643, batch_acc=0.0938, running_acc=0.0728, grad=7.2345]Training epoch 0:  60%|██████    | 98/163 [01:51<01:06,  1.03s/it, loss=3.6545, batch_acc=0.0938, running_acc=0.0730, grad=7.1411]Training epoch 0:  61%|██████    | 99/163 [01:52<01:02,  1.02it/s, loss=3.6545, batch_acc=0.0938, running_acc=0.0730, grad=7.1411]Training epoch 0:  61%|██████    | 99/163 [01:52<01:02,  1.02it/s, loss=3.7532, batch_acc=0.0000, running_acc=0.0723, grad=6.7582]Training epoch 0:  61%|██████▏   | 100/163 [01:53<01:15,  1.19s/it, loss=3.7532, batch_acc=0.0000, running_acc=0.0723, grad=6.7582]Training epoch 0:  61%|██████▏   | 100/163 [01:53<01:15,  1.19s/it, loss=3.4666, batch_acc=0.1562, running_acc=0.0731, grad=7.7951]Training epoch 0:  62%|██████▏   | 101/163 [01:54<01:14,  1.21s/it, loss=3.4666, batch_acc=0.1562, running_acc=0.0731, grad=7.7951]Training epoch 0:  62%|██████▏   | 101/163 [01:54<01:14,  1.21s/it, loss=3.7496, batch_acc=0.0312, running_acc=0.0727, grad=8.1144]Training epoch 0:  63%|██████▎   | 102/163 [01:55<01:07,  1.11s/it, loss=3.7496, batch_acc=0.0312, running_acc=0.0727, grad=8.1144]Training epoch 0:  63%|██████▎   | 102/163 [01:55<01:07,  1.11s/it, loss=3.6740, batch_acc=0.0625, running_acc=0.0726, grad=7.2907]Training epoch 0:  63%|██████▎   | 103/163 [01:56<01:02,  1.04s/it, loss=3.6740, batch_acc=0.0625, running_acc=0.0726, grad=7.2907]Training epoch 0:  63%|██████▎   | 103/163 [01:56<01:02,  1.04s/it, loss=3.6224, batch_acc=0.0938, running_acc=0.0728, grad=6.6257]Training epoch 0:  64%|██████▍   | 104/163 [01:57<01:03,  1.07s/it, loss=3.6224, batch_acc=0.0938, running_acc=0.0728, grad=6.6257]Training epoch 0:  64%|██████▍   | 104/163 [01:57<01:03,  1.07s/it, loss=3.4807, batch_acc=0.1562, running_acc=0.0736, grad=6.3031]Training epoch 0:  64%|██████▍   | 105/163 [01:59<01:13,  1.26s/it, loss=3.4807, batch_acc=0.1562, running_acc=0.0736, grad=6.3031]Training epoch 0:  64%|██████▍   | 105/163 [01:59<01:13,  1.26s/it, loss=3.5195, batch_acc=0.1562, running_acc=0.0744, grad=6.2060]Training epoch 0:  65%|██████▌   | 106/163 [02:00<01:05,  1.15s/it, loss=3.5195, batch_acc=0.1562, running_acc=0.0744, grad=6.2060]Training epoch 0:  65%|██████▌   | 106/163 [02:00<01:05,  1.15s/it, loss=3.5703, batch_acc=0.1562, running_acc=0.0752, grad=7.1108]Training epoch 0:  66%|██████▌   | 107/163 [02:01<00:59,  1.07s/it, loss=3.5703, batch_acc=0.1562, running_acc=0.0752, grad=7.1108]Training epoch 0:  66%|██████▌   | 107/163 [02:01<00:59,  1.07s/it, loss=3.6599, batch_acc=0.0312, running_acc=0.0748, grad=7.4230]Training epoch 0:  66%|██████▋   | 108/163 [02:02<00:59,  1.08s/it, loss=3.6599, batch_acc=0.0312, running_acc=0.0748, grad=7.4230]Training epoch 0:  66%|██████▋   | 108/163 [02:02<00:59,  1.08s/it, loss=3.7759, batch_acc=0.0625, running_acc=0.0747, grad=7.6213]Training epoch 0:  67%|██████▋   | 109/163 [02:03<01:02,  1.16s/it, loss=3.7759, batch_acc=0.0625, running_acc=0.0747, grad=7.6213]Training epoch 0:  67%|██████▋   | 109/163 [02:03<01:02,  1.16s/it, loss=3.5906, batch_acc=0.0312, running_acc=0.0743, grad=6.1999]Training epoch 0:  67%|██████▋   | 110/163 [02:04<00:56,  1.07s/it, loss=3.5906, batch_acc=0.0312, running_acc=0.0743, grad=6.1999]Training epoch 0:  67%|██████▋   | 110/163 [02:04<00:56,  1.07s/it, loss=3.5520, batch_acc=0.1562, running_acc=0.0750, grad=6.7721]Training epoch 0:  68%|██████▊   | 111/163 [02:05<00:52,  1.02s/it, loss=3.5520, batch_acc=0.1562, running_acc=0.0750, grad=6.7721]Training epoch 0:  68%|██████▊   | 111/163 [02:05<00:52,  1.02s/it, loss=3.6272, batch_acc=0.0625, running_acc=0.0749, grad=7.3421]Training epoch 0:  69%|██████▊   | 112/163 [02:06<00:51,  1.01s/it, loss=3.6272, batch_acc=0.0625, running_acc=0.0749, grad=7.3421]Training epoch 0:  69%|██████▊   | 112/163 [02:06<00:51,  1.01s/it, loss=3.4596, batch_acc=0.1875, running_acc=0.0759, grad=8.1470]Training epoch 0:  69%|██████▉   | 113/163 [02:08<01:03,  1.27s/it, loss=3.4596, batch_acc=0.1875, running_acc=0.0759, grad=8.1470]Training epoch 0:  69%|██████▉   | 113/163 [02:08<01:03,  1.27s/it, loss=3.5739, batch_acc=0.1250, running_acc=0.0763, grad=6.8005]Training epoch 0:  70%|██████▉   | 114/163 [02:09<00:56,  1.15s/it, loss=3.5739, batch_acc=0.1250, running_acc=0.0763, grad=6.8005]Training epoch 0:  70%|██████▉   | 114/163 [02:09<00:56,  1.15s/it, loss=3.4007, batch_acc=0.0938, running_acc=0.0765, grad=6.3872]Training epoch 0:  71%|███████   | 115/163 [02:10<00:51,  1.07s/it, loss=3.4007, batch_acc=0.0938, running_acc=0.0765, grad=6.3872]Training epoch 0:  71%|███████   | 115/163 [02:10<00:51,  1.07s/it, loss=3.5996, batch_acc=0.0938, running_acc=0.0766, grad=7.0939]Training epoch 0:  71%|███████   | 116/163 [02:11<00:48,  1.04s/it, loss=3.5996, batch_acc=0.0938, running_acc=0.0766, grad=7.0939]Training epoch 0:  71%|███████   | 116/163 [02:11<00:48,  1.04s/it, loss=3.7195, batch_acc=0.0938, running_acc=0.0768, grad=7.5308]Training epoch 0:  72%|███████▏  | 117/163 [02:12<00:52,  1.15s/it, loss=3.7195, batch_acc=0.0938, running_acc=0.0768, grad=7.5308]Training epoch 0:  72%|███████▏  | 117/163 [02:12<00:52,  1.15s/it, loss=3.6763, batch_acc=0.0938, running_acc=0.0769, grad=7.1033]Training epoch 0:  72%|███████▏  | 118/163 [02:13<00:47,  1.07s/it, loss=3.6763, batch_acc=0.0938, running_acc=0.0769, grad=7.1033]Training epoch 0:  72%|███████▏  | 118/163 [02:13<00:47,  1.07s/it, loss=3.5499, batch_acc=0.1562, running_acc=0.0776, grad=6.8109]Training epoch 0:  73%|███████▎  | 119/163 [02:14<00:44,  1.01s/it, loss=3.5499, batch_acc=0.1562, running_acc=0.0776, grad=6.8109]Training epoch 0:  73%|███████▎  | 119/163 [02:14<00:44,  1.01s/it, loss=3.6271, batch_acc=0.0312, running_acc=0.0772, grad=6.6052]Training epoch 0:  74%|███████▎  | 120/163 [02:15<00:46,  1.08s/it, loss=3.6271, batch_acc=0.0312, running_acc=0.0772, grad=6.6052]Training epoch 0:  74%|███████▎  | 120/163 [02:15<00:46,  1.08s/it, loss=3.6101, batch_acc=0.0938, running_acc=0.0773, grad=7.8710]Training epoch 0:  74%|███████▍  | 121/163 [02:17<00:51,  1.23s/it, loss=3.6101, batch_acc=0.0938, running_acc=0.0773, grad=7.8710]Training epoch 0:  74%|███████▍  | 121/163 [02:17<00:51,  1.23s/it, loss=3.5623, batch_acc=0.0312, running_acc=0.0770, grad=7.3126]Training epoch 0:  75%|███████▍  | 122/163 [02:17<00:45,  1.12s/it, loss=3.5623, batch_acc=0.0312, running_acc=0.0770, grad=7.3126]Training epoch 0:  75%|███████▍  | 122/163 [02:17<00:45,  1.12s/it, loss=3.5089, batch_acc=0.1250, running_acc=0.0774, grad=7.1659]Training epoch 0:  75%|███████▌  | 123/163 [02:18<00:43,  1.08s/it, loss=3.5089, batch_acc=0.1250, running_acc=0.0774, grad=7.1659]Training epoch 0:  75%|███████▌  | 123/163 [02:18<00:43,  1.08s/it, loss=3.6101, batch_acc=0.0625, running_acc=0.0772, grad=6.9571]Training epoch 0:  76%|███████▌  | 124/163 [02:19<00:39,  1.02s/it, loss=3.6101, batch_acc=0.0625, running_acc=0.0772, grad=6.9571]Training epoch 0:  76%|███████▌  | 124/163 [02:19<00:39,  1.02s/it, loss=3.5224, batch_acc=0.0938, running_acc=0.0774, grad=6.2799]Training epoch 0:  77%|███████▋  | 125/163 [02:21<00:51,  1.35s/it, loss=3.5224, batch_acc=0.0938, running_acc=0.0774, grad=6.2799]Training epoch 0:  77%|███████▋  | 125/163 [02:21<00:51,  1.35s/it, loss=3.4590, batch_acc=0.1250, running_acc=0.0777, grad=7.0422]Training epoch 0:  77%|███████▋  | 126/163 [02:22<00:44,  1.21s/it, loss=3.4590, batch_acc=0.1250, running_acc=0.0777, grad=7.0422]Training epoch 0:  77%|███████▋  | 126/163 [02:22<00:44,  1.21s/it, loss=3.5541, batch_acc=0.1250, running_acc=0.0781, grad=6.4651]Training epoch 0:  78%|███████▊  | 127/163 [02:23<00:40,  1.11s/it, loss=3.5541, batch_acc=0.1250, running_acc=0.0781, grad=6.4651]Training epoch 0:  78%|███████▊  | 127/163 [02:23<00:40,  1.11s/it, loss=3.5544, batch_acc=0.1250, running_acc=0.0785, grad=7.3901]Training epoch 0:  79%|███████▊  | 128/163 [02:24<00:36,  1.04s/it, loss=3.5544, batch_acc=0.1250, running_acc=0.0785, grad=7.3901]Training epoch 0:  79%|███████▊  | 128/163 [02:24<00:36,  1.04s/it, loss=3.4197, batch_acc=0.1562, running_acc=0.0791, grad=7.9490]Training epoch 0:  79%|███████▉  | 129/163 [02:26<00:41,  1.24s/it, loss=3.4197, batch_acc=0.1562, running_acc=0.0791, grad=7.9490]Training epoch 0:  79%|███████▉  | 129/163 [02:26<00:41,  1.24s/it, loss=3.6109, batch_acc=0.1250, running_acc=0.0795, grad=6.9898]Training epoch 0:  80%|███████▉  | 130/163 [02:27<00:37,  1.13s/it, loss=3.6109, batch_acc=0.1250, running_acc=0.0795, grad=6.9898]Training epoch 0:  80%|███████▉  | 130/163 [02:27<00:37,  1.13s/it, loss=3.4753, batch_acc=0.0938, running_acc=0.0796, grad=6.7092]Training epoch 0:  80%|████████  | 131/163 [02:28<00:33,  1.05s/it, loss=3.4753, batch_acc=0.0938, running_acc=0.0796, grad=6.7092]Training epoch 0:  80%|████████  | 131/163 [02:28<00:33,  1.05s/it, loss=3.5188, batch_acc=0.0312, running_acc=0.0792, grad=6.3142]Training epoch 0:  81%|████████  | 132/163 [02:28<00:31,  1.00s/it, loss=3.5188, batch_acc=0.0312, running_acc=0.0792, grad=6.3142]Training epoch 0:  81%|████████  | 132/163 [02:28<00:31,  1.00s/it, loss=3.5888, batch_acc=0.1562, running_acc=0.0798, grad=7.2404]Training epoch 0:  82%|████████▏ | 133/163 [02:30<00:34,  1.16s/it, loss=3.5888, batch_acc=0.1562, running_acc=0.0798, grad=7.2404]Training epoch 0:  82%|████████▏ | 133/163 [02:30<00:34,  1.16s/it, loss=3.5841, batch_acc=0.1875, running_acc=0.0806, grad=9.3944]Training epoch 0:  82%|████████▏ | 134/163 [02:31<00:31,  1.08s/it, loss=3.5841, batch_acc=0.1875, running_acc=0.0806, grad=9.3944]Training epoch 0:  82%|████████▏ | 134/163 [02:31<00:31,  1.08s/it, loss=3.3634, batch_acc=0.1875, running_acc=0.0814, grad=6.3049]Training epoch 0:  83%|████████▎ | 135/163 [02:32<00:28,  1.02s/it, loss=3.3634, batch_acc=0.1875, running_acc=0.0814, grad=6.3049]Training epoch 0:  83%|████████▎ | 135/163 [02:32<00:28,  1.02s/it, loss=3.4529, batch_acc=0.1562, running_acc=0.0819, grad=7.4434]Training epoch 0:  83%|████████▎ | 136/163 [02:33<00:27,  1.00s/it, loss=3.4529, batch_acc=0.1562, running_acc=0.0819, grad=7.4434]Training epoch 0:  83%|████████▎ | 136/163 [02:33<00:27,  1.00s/it, loss=3.4654, batch_acc=0.1250, running_acc=0.0823, grad=6.5269]Training epoch 0:  84%|████████▍ | 137/163 [02:34<00:31,  1.23s/it, loss=3.4654, batch_acc=0.1250, running_acc=0.0823, grad=6.5269]Training epoch 0:  84%|████████▍ | 137/163 [02:34<00:31,  1.23s/it, loss=3.5056, batch_acc=0.1875, running_acc=0.0830, grad=7.9313]Training epoch 0:  85%|████████▍ | 138/163 [02:35<00:28,  1.12s/it, loss=3.5056, batch_acc=0.1875, running_acc=0.0830, grad=7.9313]Training epoch 0:  85%|████████▍ | 138/163 [02:35<00:28,  1.12s/it, loss=3.2819, batch_acc=0.1875, running_acc=0.0838, grad=7.7424]Training epoch 0:  85%|████████▌ | 139/163 [02:36<00:25,  1.05s/it, loss=3.2819, batch_acc=0.1875, running_acc=0.0838, grad=7.7424]Training epoch 0:  85%|████████▌ | 139/163 [02:36<00:25,  1.05s/it, loss=3.6221, batch_acc=0.0000, running_acc=0.0832, grad=7.4079]Training epoch 0:  86%|████████▌ | 140/163 [02:37<00:22,  1.00it/s, loss=3.6221, batch_acc=0.0000, running_acc=0.0832, grad=7.4079]Training epoch 0:  86%|████████▌ | 140/163 [02:37<00:22,  1.00it/s, loss=3.4861, batch_acc=0.0625, running_acc=0.0830, grad=7.4682]Training epoch 0:  87%|████████▋ | 141/163 [02:38<00:24,  1.11s/it, loss=3.4861, batch_acc=0.0625, running_acc=0.0830, grad=7.4682]Training epoch 0:  87%|████████▋ | 141/163 [02:38<00:24,  1.11s/it, loss=3.4667, batch_acc=0.0938, running_acc=0.0831, grad=7.0263]Training epoch 0:  87%|████████▋ | 142/163 [02:39<00:21,  1.04s/it, loss=3.4667, batch_acc=0.0938, running_acc=0.0831, grad=7.0263]Training epoch 0:  87%|████████▋ | 142/163 [02:39<00:21,  1.04s/it, loss=3.4541, batch_acc=0.0312, running_acc=0.0827, grad=6.7374]Training epoch 0:  88%|████████▊ | 143/163 [02:40<00:19,  1.01it/s, loss=3.4541, batch_acc=0.0312, running_acc=0.0827, grad=6.7374]Training epoch 0:  88%|████████▊ | 143/163 [02:40<00:19,  1.01it/s, loss=3.4483, batch_acc=0.0938, running_acc=0.0828, grad=6.6527]Training epoch 0:  88%|████████▊ | 144/163 [02:41<00:18,  1.04it/s, loss=3.4483, batch_acc=0.0938, running_acc=0.0828, grad=6.6527]Training epoch 0:  88%|████████▊ | 144/163 [02:41<00:18,  1.04it/s, loss=3.7122, batch_acc=0.0938, running_acc=0.0829, grad=8.2466]Training epoch 0:  89%|████████▉ | 145/163 [02:43<00:19,  1.10s/it, loss=3.7122, batch_acc=0.0938, running_acc=0.0829, grad=8.2466]Training epoch 0:  89%|████████▉ | 145/163 [02:43<00:19,  1.10s/it, loss=3.5318, batch_acc=0.1562, running_acc=0.0834, grad=9.8629]Training epoch 0:  90%|████████▉ | 146/163 [02:43<00:17,  1.03s/it, loss=3.5318, batch_acc=0.1562, running_acc=0.0834, grad=9.8629]Training epoch 0:  90%|████████▉ | 146/163 [02:43<00:17,  1.03s/it, loss=3.3630, batch_acc=0.0938, running_acc=0.0835, grad=7.7494]Training epoch 0:  90%|█████████ | 147/163 [02:44<00:15,  1.01it/s, loss=3.3630, batch_acc=0.0938, running_acc=0.0835, grad=7.7494]Training epoch 0:  90%|█████████ | 147/163 [02:44<00:15,  1.01it/s, loss=3.2206, batch_acc=0.2812, running_acc=0.0848, grad=6.6545]Training epoch 0:  91%|█████████ | 148/163 [02:45<00:15,  1.01s/it, loss=3.2206, batch_acc=0.2812, running_acc=0.0848, grad=6.6545]Training epoch 0:  91%|█████████ | 148/163 [02:45<00:15,  1.01s/it, loss=3.1717, batch_acc=0.2188, running_acc=0.0857, grad=7.3725]Training epoch 0:  91%|█████████▏| 149/163 [02:47<00:18,  1.29s/it, loss=3.1717, batch_acc=0.2188, running_acc=0.0857, grad=7.3725]Training epoch 0:  91%|█████████▏| 149/163 [02:47<00:18,  1.29s/it, loss=3.3078, batch_acc=0.1562, running_acc=0.0862, grad=6.9321]Training epoch 0:  92%|█████████▏| 150/163 [02:48<00:15,  1.16s/it, loss=3.3078, batch_acc=0.1562, running_acc=0.0862, grad=6.9321]Training epoch 0:  92%|█████████▏| 150/163 [02:48<00:15,  1.16s/it, loss=3.4752, batch_acc=0.1250, running_acc=0.0865, grad=8.9825]Training epoch 0:  93%|█████████▎| 151/163 [02:49<00:12,  1.08s/it, loss=3.4752, batch_acc=0.1250, running_acc=0.0865, grad=8.9825]Training epoch 0:  93%|█████████▎| 151/163 [02:49<00:12,  1.08s/it, loss=3.4141, batch_acc=0.1250, running_acc=0.0867, grad=7.2505]Training epoch 0:  93%|█████████▎| 152/163 [02:50<00:11,  1.04s/it, loss=3.4141, batch_acc=0.1250, running_acc=0.0867, grad=7.2505]Training epoch 0:  93%|█████████▎| 152/163 [02:50<00:11,  1.04s/it, loss=3.5078, batch_acc=0.0625, running_acc=0.0866, grad=6.7067]Training epoch 0:  94%|█████████▍| 153/163 [02:52<00:12,  1.28s/it, loss=3.5078, batch_acc=0.0625, running_acc=0.0866, grad=6.7067]Training epoch 0:  94%|█████████▍| 153/163 [02:52<00:12,  1.28s/it, loss=3.4808, batch_acc=0.1875, running_acc=0.0872, grad=8.4547]Training epoch 0:  94%|█████████▍| 154/163 [02:53<00:10,  1.16s/it, loss=3.4808, batch_acc=0.1875, running_acc=0.0872, grad=8.4547]Training epoch 0:  94%|█████████▍| 154/163 [02:53<00:10,  1.16s/it, loss=3.2291, batch_acc=0.1875, running_acc=0.0879, grad=7.0426]Training epoch 0:  95%|█████████▌| 155/163 [02:54<00:08,  1.08s/it, loss=3.2291, batch_acc=0.1875, running_acc=0.0879, grad=7.0426]Training epoch 0:  95%|█████████▌| 155/163 [02:54<00:08,  1.08s/it, loss=3.2656, batch_acc=0.1250, running_acc=0.0881, grad=7.6597]Training epoch 0:  96%|█████████▌| 156/163 [02:55<00:07,  1.05s/it, loss=3.2656, batch_acc=0.1250, running_acc=0.0881, grad=7.6597]Training epoch 0:  96%|█████████▌| 156/163 [02:55<00:07,  1.05s/it, loss=3.4187, batch_acc=0.0938, running_acc=0.0881, grad=6.6180]Training epoch 0:  96%|█████████▋| 157/163 [02:56<00:06,  1.12s/it, loss=3.4187, batch_acc=0.0938, running_acc=0.0881, grad=6.6180]Training epoch 0:  96%|█████████▋| 157/163 [02:56<00:06,  1.12s/it, loss=3.4546, batch_acc=0.0938, running_acc=0.0882, grad=7.1732]Training epoch 0:  97%|█████████▋| 158/163 [02:57<00:05,  1.05s/it, loss=3.4546, batch_acc=0.0938, running_acc=0.0882, grad=7.1732]Training epoch 0:  97%|█████████▋| 158/163 [02:57<00:05,  1.05s/it, loss=3.2379, batch_acc=0.0625, running_acc=0.0880, grad=7.1840]Training epoch 0:  98%|█████████▊| 159/163 [02:58<00:03,  1.00it/s, loss=3.2379, batch_acc=0.0625, running_acc=0.0880, grad=7.1840]Training epoch 0:  98%|█████████▊| 159/163 [02:58<00:03,  1.00it/s, loss=3.3131, batch_acc=0.1562, running_acc=0.0884, grad=7.9497]Training epoch 0:  98%|█████████▊| 160/163 [02:59<00:03,  1.03s/it, loss=3.3131, batch_acc=0.1562, running_acc=0.0884, grad=7.9497]Training epoch 0:  98%|█████████▊| 160/163 [02:59<00:03,  1.03s/it, loss=3.5003, batch_acc=0.0938, running_acc=0.0885, grad=8.2209]Training epoch 0:  99%|█████████▉| 161/163 [03:00<00:02,  1.10s/it, loss=3.5003, batch_acc=0.0938, running_acc=0.0885, grad=8.2209]Training epoch 0:  99%|█████████▉| 161/163 [03:00<00:02,  1.10s/it, loss=3.2793, batch_acc=0.2188, running_acc=0.0893, grad=8.0194]Training epoch 0:  99%|█████████▉| 162/163 [03:01<00:01,  1.04s/it, loss=3.2793, batch_acc=0.2188, running_acc=0.0893, grad=8.0194]Training epoch 0:  99%|█████████▉| 162/163 [03:01<00:01,  1.04s/it, loss=3.6344, batch_acc=0.0938, running_acc=0.0893, grad=6.6419]Training epoch 0: 100%|██████████| 163/163 [03:02<00:00,  1.09it/s, loss=3.6344, batch_acc=0.0938, running_acc=0.0893, grad=6.6419]Training epoch 0: 100%|██████████| 163/163 [03:02<00:00,  1.09it/s, loss=3.4790, batch_acc=0.0476, running_acc=0.0891, grad=9.6583]Training epoch 0: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=3.4790, batch_acc=0.0476, running_acc=0.0891, grad=9.6583]
Evaluation epoch 0:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 0:   4%|▎         | 1/28 [00:05<02:26,  5.41s/it]Evaluation epoch 0:   4%|▎         | 1/28 [00:05<02:26,  5.41s/it, loss=2.7736, batch_acc=0.3125, running_acc=0.3125]Evaluation epoch 0:   7%|▋         | 2/28 [00:05<01:01,  2.38s/it, loss=2.7736, batch_acc=0.3125, running_acc=0.3125]Evaluation epoch 0:   7%|▋         | 2/28 [00:05<01:01,  2.38s/it, loss=3.5845, batch_acc=0.0000, running_acc=0.1562]Evaluation epoch 0:  11%|█         | 3/28 [00:05<00:35,  1.42s/it, loss=3.5845, batch_acc=0.0000, running_acc=0.1562]Evaluation epoch 0:  11%|█         | 3/28 [00:05<00:35,  1.42s/it, loss=3.4977, batch_acc=0.0312, running_acc=0.1146]Evaluation epoch 0:  14%|█▍        | 4/28 [00:10<01:02,  2.62s/it, loss=3.4977, batch_acc=0.0312, running_acc=0.1146]Evaluation epoch 0:  14%|█▍        | 4/28 [00:10<01:02,  2.62s/it, loss=3.9429, batch_acc=0.0000, running_acc=0.0859]Evaluation epoch 0:  18%|█▊        | 5/28 [00:10<00:40,  1.77s/it, loss=3.9429, batch_acc=0.0000, running_acc=0.0859]Evaluation epoch 0:  18%|█▊        | 5/28 [00:10<00:40,  1.77s/it, loss=3.4991, batch_acc=0.0312, running_acc=0.0750]Evaluation epoch 0:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=3.4991, batch_acc=0.0312, running_acc=0.0750]Evaluation epoch 0:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=3.5569, batch_acc=0.0312, running_acc=0.0677]Evaluation epoch 0:  25%|██▌       | 7/28 [00:11<00:19,  1.07it/s, loss=3.5569, batch_acc=0.0312, running_acc=0.0677]Evaluation epoch 0:  25%|██▌       | 7/28 [00:11<00:19,  1.07it/s, loss=3.8415, batch_acc=0.0000, running_acc=0.0580]Evaluation epoch 0:  29%|██▊       | 8/28 [00:14<00:34,  1.73s/it, loss=3.8415, batch_acc=0.0000, running_acc=0.0580]Evaluation epoch 0:  29%|██▊       | 8/28 [00:14<00:34,  1.73s/it, loss=3.4813, batch_acc=0.0625, running_acc=0.0586]Evaluation epoch 0:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=3.4813, batch_acc=0.0625, running_acc=0.0586]Evaluation epoch 0:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=3.5103, batch_acc=0.1875, running_acc=0.0729]Evaluation epoch 0:  36%|███▌      | 10/28 [00:15<00:17,  1.04it/s, loss=3.5103, batch_acc=0.1875, running_acc=0.0729]Evaluation epoch 0:  36%|███▌      | 10/28 [00:15<00:17,  1.04it/s, loss=2.5020, batch_acc=0.6875, running_acc=0.1344]Evaluation epoch 0:  39%|███▉      | 11/28 [00:15<00:12,  1.34it/s, loss=2.5020, batch_acc=0.6875, running_acc=0.1344]Evaluation epoch 0:  39%|███▉      | 11/28 [00:15<00:12,  1.34it/s, loss=3.5402, batch_acc=0.0312, running_acc=0.1250]Evaluation epoch 0:  43%|████▎     | 12/28 [00:21<00:35,  2.24s/it, loss=3.5402, batch_acc=0.0312, running_acc=0.1250]Evaluation epoch 0:  43%|████▎     | 12/28 [00:21<00:35,  2.24s/it, loss=3.3531, batch_acc=0.0938, running_acc=0.1224]Evaluation epoch 0:  46%|████▋     | 13/28 [00:21<00:24,  1.64s/it, loss=3.3531, batch_acc=0.0938, running_acc=0.1224]Evaluation epoch 0:  46%|████▋     | 13/28 [00:21<00:24,  1.64s/it, loss=3.7896, batch_acc=0.0000, running_acc=0.1130]Evaluation epoch 0:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=3.7896, batch_acc=0.0000, running_acc=0.1130]Evaluation epoch 0:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=3.5832, batch_acc=0.0000, running_acc=0.1049]Evaluation epoch 0:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=3.5832, batch_acc=0.0000, running_acc=0.1049]Evaluation epoch 0:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=3.3908, batch_acc=0.0938, running_acc=0.1042]Evaluation epoch 0:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=3.3908, batch_acc=0.0938, running_acc=0.1042]Evaluation epoch 0:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=3.5842, batch_acc=0.3438, running_acc=0.1191]Evaluation epoch 0:  61%|██████    | 17/28 [00:25<00:12,  1.17s/it, loss=3.5842, batch_acc=0.3438, running_acc=0.1191]Evaluation epoch 0:  61%|██████    | 17/28 [00:25<00:12,  1.17s/it, loss=3.3622, batch_acc=0.2500, running_acc=0.1268]Evaluation epoch 0:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=3.3622, batch_acc=0.2500, running_acc=0.1268]Evaluation epoch 0:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=3.1765, batch_acc=0.1562, running_acc=0.1285]Evaluation epoch 0:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=3.1765, batch_acc=0.1562, running_acc=0.1285]Evaluation epoch 0:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=3.2634, batch_acc=0.0312, running_acc=0.1234]Evaluation epoch 0:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=3.2634, batch_acc=0.0312, running_acc=0.1234]Evaluation epoch 0:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=3.8716, batch_acc=0.0000, running_acc=0.1172]Evaluation epoch 0:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=3.8716, batch_acc=0.0000, running_acc=0.1172]Evaluation epoch 0:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=3.5833, batch_acc=0.0625, running_acc=0.1146]Evaluation epoch 0:  79%|███████▊  | 22/28 [00:29<00:04,  1.24it/s, loss=3.5833, batch_acc=0.0625, running_acc=0.1146]Evaluation epoch 0:  79%|███████▊  | 22/28 [00:29<00:04,  1.24it/s, loss=3.8264, batch_acc=0.0000, running_acc=0.1094]Evaluation epoch 0:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=3.8264, batch_acc=0.0000, running_acc=0.1094]Evaluation epoch 0:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=3.6533, batch_acc=0.0000, running_acc=0.1046]Evaluation epoch 0:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=3.6533, batch_acc=0.0000, running_acc=0.1046]Evaluation epoch 0:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=2.9385, batch_acc=0.2188, running_acc=0.1094]Evaluation epoch 0:  89%|████████▉ | 25/28 [00:35<00:04,  1.53s/it, loss=2.9385, batch_acc=0.2188, running_acc=0.1094]Evaluation epoch 0:  89%|████████▉ | 25/28 [00:35<00:04,  1.53s/it, loss=2.5004, batch_acc=0.4688, running_acc=0.1237]Evaluation epoch 0:  93%|█████████▎| 26/28 [00:35<00:02,  1.15s/it, loss=2.5004, batch_acc=0.4688, running_acc=0.1237]Evaluation epoch 0:  93%|█████████▎| 26/28 [00:35<00:02,  1.15s/it, loss=2.9503, batch_acc=0.2812, running_acc=0.1298]Evaluation epoch 0:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=2.9503, batch_acc=0.2812, running_acc=0.1298]Evaluation epoch 0:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=3.3637, batch_acc=0.0000, running_acc=0.1250]Evaluation epoch 0: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=3.0233, batch_acc=0.0000, running_acc=0.1246]Evaluation epoch 0: 100%|██████████| 28/28 [00:35<00:00,  1.27s/it, loss=3.0233, batch_acc=0.0000, running_acc=0.1246]
Training epoch 1:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 1:   1%|          | 1/163 [00:05<15:43,  5.82s/it]Training epoch 1:   1%|          | 1/163 [00:05<15:43,  5.82s/it, loss=3.2585, batch_acc=0.1250, running_acc=0.1250, grad=5.8398]Training epoch 1:   1%|          | 2/163 [00:06<07:50,  2.92s/it, loss=3.2585, batch_acc=0.1250, running_acc=0.1250, grad=5.8398]Training epoch 1:   1%|          | 2/163 [00:06<07:50,  2.92s/it, loss=3.6006, batch_acc=0.1250, running_acc=0.1250, grad=7.6225]Training epoch 1:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=3.6006, batch_acc=0.1250, running_acc=0.1250, grad=7.6225]Training epoch 1:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=3.3064, batch_acc=0.1562, running_acc=0.1354, grad=6.3921]Training epoch 1:   2%|▏         | 4/163 [00:10<06:39,  2.51s/it, loss=3.3064, batch_acc=0.1562, running_acc=0.1354, grad=6.3921]Training epoch 1:   2%|▏         | 4/163 [00:10<06:39,  2.51s/it, loss=3.5448, batch_acc=0.0938, running_acc=0.1250, grad=7.0777]Training epoch 1:   3%|▎         | 5/163 [00:11<05:03,  1.92s/it, loss=3.5448, batch_acc=0.0938, running_acc=0.1250, grad=7.0777]Training epoch 1:   3%|▎         | 5/163 [00:11<05:03,  1.92s/it, loss=3.5515, batch_acc=0.0938, running_acc=0.1187, grad=7.1040]Training epoch 1:   4%|▎         | 6/163 [00:12<04:06,  1.57s/it, loss=3.5515, batch_acc=0.0938, running_acc=0.1187, grad=7.1040]Training epoch 1:   4%|▎         | 6/163 [00:12<04:06,  1.57s/it, loss=3.3881, batch_acc=0.0625, running_acc=0.1094, grad=7.5424]Training epoch 1:   4%|▍         | 7/163 [00:13<03:29,  1.34s/it, loss=3.3881, batch_acc=0.0625, running_acc=0.1094, grad=7.5424]Training epoch 1:   4%|▍         | 7/163 [00:13<03:29,  1.34s/it, loss=3.3989, batch_acc=0.1250, running_acc=0.1116, grad=6.7982]Training epoch 1:   5%|▍         | 8/163 [00:15<04:14,  1.64s/it, loss=3.3989, batch_acc=0.1250, running_acc=0.1116, grad=6.7982]Training epoch 1:   5%|▍         | 8/163 [00:15<04:14,  1.64s/it, loss=3.3826, batch_acc=0.0938, running_acc=0.1094, grad=10.5178]Training epoch 1:   6%|▌         | 9/163 [00:16<03:36,  1.41s/it, loss=3.3826, batch_acc=0.0938, running_acc=0.1094, grad=10.5178]Training epoch 1:   6%|▌         | 9/163 [00:16<03:36,  1.41s/it, loss=3.3012, batch_acc=0.1250, running_acc=0.1111, grad=7.1172] Training epoch 1:   6%|▌         | 10/163 [00:17<03:10,  1.24s/it, loss=3.3012, batch_acc=0.1250, running_acc=0.1111, grad=7.1172]Training epoch 1:   6%|▌         | 10/163 [00:17<03:10,  1.24s/it, loss=3.1513, batch_acc=0.2188, running_acc=0.1219, grad=6.6790]Training epoch 1:   7%|▋         | 11/163 [00:18<02:52,  1.13s/it, loss=3.1513, batch_acc=0.2188, running_acc=0.1219, grad=6.6790]Training epoch 1:   7%|▋         | 11/163 [00:18<02:52,  1.13s/it, loss=3.4240, batch_acc=0.1250, running_acc=0.1222, grad=6.6125]Training epoch 1:   7%|▋         | 12/163 [00:20<03:17,  1.31s/it, loss=3.4240, batch_acc=0.1250, running_acc=0.1222, grad=6.6125]Training epoch 1:   7%|▋         | 12/163 [00:20<03:17,  1.31s/it, loss=3.6033, batch_acc=0.0938, running_acc=0.1198, grad=7.2187]Training epoch 1:   8%|▊         | 13/163 [00:21<02:56,  1.18s/it, loss=3.6033, batch_acc=0.0938, running_acc=0.1198, grad=7.2187]Training epoch 1:   8%|▊         | 13/163 [00:21<02:56,  1.18s/it, loss=3.2750, batch_acc=0.1562, running_acc=0.1226, grad=7.6179]Training epoch 1:   9%|▊         | 14/163 [00:21<02:42,  1.09s/it, loss=3.2750, batch_acc=0.1562, running_acc=0.1226, grad=7.6179]Training epoch 1:   9%|▊         | 14/163 [00:21<02:42,  1.09s/it, loss=3.2058, batch_acc=0.1875, running_acc=0.1272, grad=6.5054]Training epoch 1:   9%|▉         | 15/163 [00:22<02:31,  1.02s/it, loss=3.2058, batch_acc=0.1875, running_acc=0.1272, grad=6.5054]Training epoch 1:   9%|▉         | 15/163 [00:22<02:31,  1.02s/it, loss=3.5879, batch_acc=0.1250, running_acc=0.1271, grad=7.3271]Training epoch 1:  10%|▉         | 16/163 [00:24<03:09,  1.29s/it, loss=3.5879, batch_acc=0.1250, running_acc=0.1271, grad=7.3271]Training epoch 1:  10%|▉         | 16/163 [00:24<03:09,  1.29s/it, loss=3.4260, batch_acc=0.1250, running_acc=0.1270, grad=7.7091]Training epoch 1:  10%|█         | 17/163 [00:25<02:50,  1.17s/it, loss=3.4260, batch_acc=0.1250, running_acc=0.1270, grad=7.7091]Training epoch 1:  10%|█         | 17/163 [00:25<02:50,  1.17s/it, loss=3.3847, batch_acc=0.0938, running_acc=0.1250, grad=7.7770]Training epoch 1:  11%|█         | 18/163 [00:26<02:36,  1.08s/it, loss=3.3847, batch_acc=0.0938, running_acc=0.1250, grad=7.7770]Training epoch 1:  11%|█         | 18/163 [00:26<02:36,  1.08s/it, loss=3.1199, batch_acc=0.2188, running_acc=0.1302, grad=7.9132]Training epoch 1:  12%|█▏        | 19/163 [00:27<02:26,  1.02s/it, loss=3.1199, batch_acc=0.2188, running_acc=0.1302, grad=7.9132]Training epoch 1:  12%|█▏        | 19/163 [00:27<02:26,  1.02s/it, loss=3.2564, batch_acc=0.1250, running_acc=0.1299, grad=6.9155]Training epoch 1:  12%|█▏        | 20/163 [00:29<03:20,  1.40s/it, loss=3.2564, batch_acc=0.1250, running_acc=0.1299, grad=6.9155]Training epoch 1:  12%|█▏        | 20/163 [00:29<03:20,  1.40s/it, loss=3.4238, batch_acc=0.1250, running_acc=0.1297, grad=6.1422]Training epoch 1:  13%|█▎        | 21/163 [00:30<02:56,  1.24s/it, loss=3.4238, batch_acc=0.1250, running_acc=0.1297, grad=6.1422]Training epoch 1:  13%|█▎        | 21/163 [00:30<02:56,  1.24s/it, loss=3.1058, batch_acc=0.2812, running_acc=0.1369, grad=7.1151]Training epoch 1:  13%|█▎        | 22/163 [00:31<02:40,  1.13s/it, loss=3.1058, batch_acc=0.2812, running_acc=0.1369, grad=7.1151]Training epoch 1:  13%|█▎        | 22/163 [00:31<02:40,  1.13s/it, loss=3.4698, batch_acc=0.0938, running_acc=0.1349, grad=8.1971]Training epoch 1:  14%|█▍        | 23/163 [00:32<02:28,  1.06s/it, loss=3.4698, batch_acc=0.0938, running_acc=0.1349, grad=8.1971]Training epoch 1:  14%|█▍        | 23/163 [00:32<02:28,  1.06s/it, loss=3.4647, batch_acc=0.1562, running_acc=0.1359, grad=7.6893]Training epoch 1:  15%|█▍        | 24/163 [00:34<02:54,  1.26s/it, loss=3.4647, batch_acc=0.1562, running_acc=0.1359, grad=7.6893]Training epoch 1:  15%|█▍        | 24/163 [00:34<02:54,  1.26s/it, loss=3.3400, batch_acc=0.0938, running_acc=0.1341, grad=7.3326]Training epoch 1:  15%|█▌        | 25/163 [00:34<02:37,  1.14s/it, loss=3.3400, batch_acc=0.0938, running_acc=0.1341, grad=7.3326]Training epoch 1:  15%|█▌        | 25/163 [00:34<02:37,  1.14s/it, loss=3.3596, batch_acc=0.1875, running_acc=0.1363, grad=7.8530]Training epoch 1:  16%|█▌        | 26/163 [00:35<02:25,  1.06s/it, loss=3.3596, batch_acc=0.1875, running_acc=0.1363, grad=7.8530]Training epoch 1:  16%|█▌        | 26/163 [00:35<02:25,  1.06s/it, loss=3.6204, batch_acc=0.0625, running_acc=0.1334, grad=7.3801]Training epoch 1:  17%|█▋        | 27/163 [00:36<02:17,  1.01s/it, loss=3.6204, batch_acc=0.0625, running_acc=0.1334, grad=7.3801]Training epoch 1:  17%|█▋        | 27/163 [00:36<02:17,  1.01s/it, loss=3.4273, batch_acc=0.1562, running_acc=0.1343, grad=7.2606]Training epoch 1:  17%|█▋        | 28/163 [00:38<02:45,  1.23s/it, loss=3.4273, batch_acc=0.1562, running_acc=0.1343, grad=7.2606]Training epoch 1:  17%|█▋        | 28/163 [00:38<02:45,  1.23s/it, loss=3.1154, batch_acc=0.1875, running_acc=0.1362, grad=6.2600]Training epoch 1:  18%|█▊        | 29/163 [00:39<02:30,  1.12s/it, loss=3.1154, batch_acc=0.1875, running_acc=0.1362, grad=6.2600]Training epoch 1:  18%|█▊        | 29/163 [00:39<02:30,  1.12s/it, loss=3.4714, batch_acc=0.0625, running_acc=0.1336, grad=7.2928]Training epoch 1:  18%|█▊        | 30/163 [00:40<02:19,  1.05s/it, loss=3.4714, batch_acc=0.0625, running_acc=0.1336, grad=7.2928]Training epoch 1:  18%|█▊        | 30/163 [00:40<02:19,  1.05s/it, loss=3.3533, batch_acc=0.1562, running_acc=0.1344, grad=7.1594]Training epoch 1:  19%|█▉        | 31/163 [00:41<02:11,  1.00it/s, loss=3.3533, batch_acc=0.1562, running_acc=0.1344, grad=7.1594]Training epoch 1:  19%|█▉        | 31/163 [00:41<02:11,  1.00it/s, loss=3.0401, batch_acc=0.2188, running_acc=0.1371, grad=6.6000]Training epoch 1:  20%|█▉        | 32/163 [00:42<02:43,  1.25s/it, loss=3.0401, batch_acc=0.2188, running_acc=0.1371, grad=6.6000]Training epoch 1:  20%|█▉        | 32/163 [00:42<02:43,  1.25s/it, loss=3.0878, batch_acc=0.1562, running_acc=0.1377, grad=7.9760]Training epoch 1:  20%|██        | 33/163 [00:43<02:27,  1.14s/it, loss=3.0878, batch_acc=0.1562, running_acc=0.1377, grad=7.9760]Training epoch 1:  20%|██        | 33/163 [00:43<02:27,  1.14s/it, loss=3.4440, batch_acc=0.1562, running_acc=0.1383, grad=6.5195]Training epoch 1:  21%|██        | 34/163 [00:44<02:16,  1.06s/it, loss=3.4440, batch_acc=0.1562, running_acc=0.1383, grad=6.5195]Training epoch 1:  21%|██        | 34/163 [00:44<02:16,  1.06s/it, loss=3.2455, batch_acc=0.1250, running_acc=0.1379, grad=6.8493]Training epoch 1:  21%|██▏       | 35/163 [00:45<02:08,  1.00s/it, loss=3.2455, batch_acc=0.1250, running_acc=0.1379, grad=6.8493]Training epoch 1:  21%|██▏       | 35/163 [00:45<02:08,  1.00s/it, loss=3.4095, batch_acc=0.2188, running_acc=0.1402, grad=6.8077]Training epoch 1:  22%|██▏       | 36/163 [00:47<02:48,  1.32s/it, loss=3.4095, batch_acc=0.2188, running_acc=0.1402, grad=6.8077]Training epoch 1:  22%|██▏       | 36/163 [00:47<02:48,  1.32s/it, loss=3.2666, batch_acc=0.1562, running_acc=0.1406, grad=6.7589]Training epoch 1:  23%|██▎       | 37/163 [00:48<02:30,  1.19s/it, loss=3.2666, batch_acc=0.1562, running_acc=0.1406, grad=6.7589]Training epoch 1:  23%|██▎       | 37/163 [00:48<02:30,  1.19s/it, loss=3.2575, batch_acc=0.0938, running_acc=0.1394, grad=6.5198]Training epoch 1:  23%|██▎       | 38/163 [00:49<02:17,  1.10s/it, loss=3.2575, batch_acc=0.0938, running_acc=0.1394, grad=6.5198]Training epoch 1:  23%|██▎       | 38/163 [00:49<02:17,  1.10s/it, loss=2.9498, batch_acc=0.2188, running_acc=0.1414, grad=6.1468]Training epoch 1:  24%|██▍       | 39/163 [00:50<02:08,  1.03s/it, loss=2.9498, batch_acc=0.2188, running_acc=0.1414, grad=6.1468]Training epoch 1:  24%|██▍       | 39/163 [00:50<02:08,  1.03s/it, loss=3.3203, batch_acc=0.1250, running_acc=0.1410, grad=8.1029]Training epoch 1:  25%|██▍       | 40/163 [00:51<02:30,  1.22s/it, loss=3.3203, batch_acc=0.1250, running_acc=0.1410, grad=8.1029]Training epoch 1:  25%|██▍       | 40/163 [00:51<02:30,  1.22s/it, loss=3.2858, batch_acc=0.0938, running_acc=0.1398, grad=7.9238]Training epoch 1:  25%|██▌       | 41/163 [00:52<02:16,  1.12s/it, loss=3.2858, batch_acc=0.0938, running_acc=0.1398, grad=7.9238]Training epoch 1:  25%|██▌       | 41/163 [00:52<02:16,  1.12s/it, loss=3.3863, batch_acc=0.0938, running_acc=0.1387, grad=6.4638]Training epoch 1:  26%|██▌       | 42/163 [00:53<02:06,  1.05s/it, loss=3.3863, batch_acc=0.0938, running_acc=0.1387, grad=6.4638]Training epoch 1:  26%|██▌       | 42/163 [00:53<02:06,  1.05s/it, loss=3.3040, batch_acc=0.1250, running_acc=0.1384, grad=7.7775]Training epoch 1:  26%|██▋       | 43/163 [00:54<01:59,  1.00it/s, loss=3.3040, batch_acc=0.1250, running_acc=0.1384, grad=7.7775]Training epoch 1:  26%|██▋       | 43/163 [00:54<01:59,  1.00it/s, loss=3.4463, batch_acc=0.0625, running_acc=0.1366, grad=8.0549]Training epoch 1:  27%|██▋       | 44/163 [00:56<02:46,  1.40s/it, loss=3.4463, batch_acc=0.0625, running_acc=0.1366, grad=8.0549]Training epoch 1:  27%|██▋       | 44/163 [00:56<02:46,  1.40s/it, loss=3.4012, batch_acc=0.1250, running_acc=0.1364, grad=7.2114]Training epoch 1:  28%|██▊       | 45/163 [00:57<02:26,  1.24s/it, loss=3.4012, batch_acc=0.1250, running_acc=0.1364, grad=7.2114]Training epoch 1:  28%|██▊       | 45/163 [00:57<02:26,  1.24s/it, loss=3.5087, batch_acc=0.1250, running_acc=0.1361, grad=7.7044]Training epoch 1:  28%|██▊       | 46/163 [00:58<02:12,  1.13s/it, loss=3.5087, batch_acc=0.1250, running_acc=0.1361, grad=7.7044]Training epoch 1:  28%|██▊       | 46/163 [00:58<02:12,  1.13s/it, loss=3.0648, batch_acc=0.3125, running_acc=0.1399, grad=6.8346]Training epoch 1:  29%|██▉       | 47/163 [00:59<02:02,  1.06s/it, loss=3.0648, batch_acc=0.3125, running_acc=0.1399, grad=6.8346]Training epoch 1:  29%|██▉       | 47/163 [00:59<02:02,  1.06s/it, loss=3.3721, batch_acc=0.1562, running_acc=0.1403, grad=9.1394]Training epoch 1:  29%|██▉       | 48/163 [01:01<02:24,  1.26s/it, loss=3.3721, batch_acc=0.1562, running_acc=0.1403, grad=9.1394]Training epoch 1:  29%|██▉       | 48/163 [01:01<02:24,  1.26s/it, loss=3.3263, batch_acc=0.2500, running_acc=0.1426, grad=9.0205]Training epoch 1:  30%|███       | 49/163 [01:02<02:10,  1.15s/it, loss=3.3263, batch_acc=0.2500, running_acc=0.1426, grad=9.0205]Training epoch 1:  30%|███       | 49/163 [01:02<02:10,  1.15s/it, loss=3.5464, batch_acc=0.1562, running_acc=0.1429, grad=7.0930]Training epoch 1:  31%|███       | 50/163 [01:02<02:00,  1.07s/it, loss=3.5464, batch_acc=0.1562, running_acc=0.1429, grad=7.0930]Training epoch 1:  31%|███       | 50/163 [01:02<02:00,  1.07s/it, loss=3.2764, batch_acc=0.1562, running_acc=0.1431, grad=6.7868]Training epoch 1:  31%|███▏      | 51/163 [01:03<01:53,  1.01s/it, loss=3.2764, batch_acc=0.1562, running_acc=0.1431, grad=6.7868]Training epoch 1:  31%|███▏      | 51/163 [01:03<01:53,  1.01s/it, loss=3.2749, batch_acc=0.0938, running_acc=0.1422, grad=7.4127]Training epoch 1:  32%|███▏      | 52/163 [01:06<02:32,  1.38s/it, loss=3.2749, batch_acc=0.0938, running_acc=0.1422, grad=7.4127]Training epoch 1:  32%|███▏      | 52/163 [01:06<02:32,  1.38s/it, loss=3.2462, batch_acc=0.1250, running_acc=0.1418, grad=7.2685]Training epoch 1:  33%|███▎      | 53/163 [01:06<02:14,  1.23s/it, loss=3.2462, batch_acc=0.1250, running_acc=0.1418, grad=7.2685]Training epoch 1:  33%|███▎      | 53/163 [01:06<02:14,  1.23s/it, loss=3.1690, batch_acc=0.2500, running_acc=0.1439, grad=7.1525]Training epoch 1:  33%|███▎      | 54/163 [01:07<02:02,  1.12s/it, loss=3.1690, batch_acc=0.2500, running_acc=0.1439, grad=7.1525]Training epoch 1:  33%|███▎      | 54/163 [01:07<02:02,  1.12s/it, loss=3.2791, batch_acc=0.2188, running_acc=0.1453, grad=7.8998]Training epoch 1:  34%|███▎      | 55/163 [01:08<01:53,  1.05s/it, loss=3.2791, batch_acc=0.2188, running_acc=0.1453, grad=7.8998]Training epoch 1:  34%|███▎      | 55/163 [01:08<01:53,  1.05s/it, loss=3.5223, batch_acc=0.1250, running_acc=0.1449, grad=8.3074]Training epoch 1:  34%|███▍      | 56/163 [01:10<02:24,  1.35s/it, loss=3.5223, batch_acc=0.1250, running_acc=0.1449, grad=8.3074]Training epoch 1:  34%|███▍      | 56/163 [01:10<02:24,  1.35s/it, loss=3.1819, batch_acc=0.2812, running_acc=0.1473, grad=9.7030]Training epoch 1:  35%|███▍      | 57/163 [01:11<02:07,  1.21s/it, loss=3.1819, batch_acc=0.2812, running_acc=0.1473, grad=9.7030]Training epoch 1:  35%|███▍      | 57/163 [01:11<02:07,  1.21s/it, loss=3.2275, batch_acc=0.1562, running_acc=0.1475, grad=7.5427]Training epoch 1:  36%|███▌      | 58/163 [01:12<01:56,  1.11s/it, loss=3.2275, batch_acc=0.1562, running_acc=0.1475, grad=7.5427]Training epoch 1:  36%|███▌      | 58/163 [01:12<01:56,  1.11s/it, loss=3.3557, batch_acc=0.2188, running_acc=0.1487, grad=7.5871]Training epoch 1:  36%|███▌      | 59/163 [01:13<01:48,  1.04s/it, loss=3.3557, batch_acc=0.2188, running_acc=0.1487, grad=7.5871]Training epoch 1:  36%|███▌      | 59/163 [01:13<01:48,  1.04s/it, loss=3.3215, batch_acc=0.0938, running_acc=0.1478, grad=6.3524]Training epoch 1:  37%|███▋      | 60/163 [01:15<02:17,  1.34s/it, loss=3.3215, batch_acc=0.0938, running_acc=0.1478, grad=6.3524]Training epoch 1:  37%|███▋      | 60/163 [01:15<02:17,  1.34s/it, loss=3.1657, batch_acc=0.1875, running_acc=0.1484, grad=7.6419]Training epoch 1:  37%|███▋      | 61/163 [01:16<02:02,  1.20s/it, loss=3.1657, batch_acc=0.1875, running_acc=0.1484, grad=7.6419]Training epoch 1:  37%|███▋      | 61/163 [01:16<02:02,  1.20s/it, loss=3.6089, batch_acc=0.1562, running_acc=0.1486, grad=9.3448]Training epoch 1:  38%|███▊      | 62/163 [01:17<01:51,  1.10s/it, loss=3.6089, batch_acc=0.1562, running_acc=0.1486, grad=9.3448]Training epoch 1:  38%|███▊      | 62/163 [01:17<01:51,  1.10s/it, loss=3.3726, batch_acc=0.1875, running_acc=0.1492, grad=7.8202]Training epoch 1:  39%|███▊      | 63/163 [01:18<01:43,  1.04s/it, loss=3.3726, batch_acc=0.1875, running_acc=0.1492, grad=7.8202]Training epoch 1:  39%|███▊      | 63/163 [01:18<01:43,  1.04s/it, loss=3.5701, batch_acc=0.1250, running_acc=0.1488, grad=7.5204]Training epoch 1:  39%|███▉      | 64/163 [01:19<01:48,  1.10s/it, loss=3.5701, batch_acc=0.1250, running_acc=0.1488, grad=7.5204]Training epoch 1:  39%|███▉      | 64/163 [01:19<01:48,  1.10s/it, loss=3.6749, batch_acc=0.0938, running_acc=0.1479, grad=8.1711]Training epoch 1:  40%|███▉      | 65/163 [01:20<01:41,  1.03s/it, loss=3.6749, batch_acc=0.0938, running_acc=0.1479, grad=8.1711]Training epoch 1:  40%|███▉      | 65/163 [01:20<01:41,  1.03s/it, loss=3.2593, batch_acc=0.1875, running_acc=0.1486, grad=6.9367]Training epoch 1:  40%|████      | 66/163 [01:21<01:35,  1.01it/s, loss=3.2593, batch_acc=0.1875, running_acc=0.1486, grad=6.9367]Training epoch 1:  40%|████      | 66/163 [01:21<01:35,  1.01it/s, loss=3.1757, batch_acc=0.1875, running_acc=0.1491, grad=7.6952]Training epoch 1:  41%|████      | 67/163 [01:21<01:31,  1.05it/s, loss=3.1757, batch_acc=0.1875, running_acc=0.1491, grad=7.6952]Training epoch 1:  41%|████      | 67/163 [01:21<01:31,  1.05it/s, loss=3.2913, batch_acc=0.0625, running_acc=0.1479, grad=7.2205]Training epoch 1:  42%|████▏     | 68/163 [01:23<01:53,  1.19s/it, loss=3.2913, batch_acc=0.0625, running_acc=0.1479, grad=7.2205]Training epoch 1:  42%|████▏     | 68/163 [01:23<01:53,  1.19s/it, loss=3.3460, batch_acc=0.1250, running_acc=0.1475, grad=7.5810]Training epoch 1:  42%|████▏     | 69/163 [01:24<01:43,  1.10s/it, loss=3.3460, batch_acc=0.1250, running_acc=0.1475, grad=7.5810]Training epoch 1:  42%|████▏     | 69/163 [01:24<01:43,  1.10s/it, loss=3.3490, batch_acc=0.1875, running_acc=0.1481, grad=8.1593]Training epoch 1:  43%|████▎     | 70/163 [01:25<01:36,  1.03s/it, loss=3.3490, batch_acc=0.1875, running_acc=0.1481, grad=8.1593]Training epoch 1:  43%|████▎     | 70/163 [01:25<01:36,  1.03s/it, loss=3.5537, batch_acc=0.0625, running_acc=0.1469, grad=9.0088]Training epoch 1:  44%|████▎     | 71/163 [01:26<01:30,  1.01it/s, loss=3.5537, batch_acc=0.0625, running_acc=0.1469, grad=9.0088]Training epoch 1:  44%|████▎     | 71/163 [01:26<01:30,  1.01it/s, loss=3.2374, batch_acc=0.2188, running_acc=0.1479, grad=6.7911]Training epoch 1:  44%|████▍     | 72/163 [01:28<01:58,  1.30s/it, loss=3.2374, batch_acc=0.2188, running_acc=0.1479, grad=6.7911]Training epoch 1:  44%|████▍     | 72/163 [01:28<01:58,  1.30s/it, loss=3.3051, batch_acc=0.1250, running_acc=0.1476, grad=9.9015]Training epoch 1:  45%|████▍     | 73/163 [01:29<01:45,  1.18s/it, loss=3.3051, batch_acc=0.1250, running_acc=0.1476, grad=9.9015]Training epoch 1:  45%|████▍     | 73/163 [01:29<01:45,  1.18s/it, loss=3.3589, batch_acc=0.1250, running_acc=0.1473, grad=7.1345]Training epoch 1:  45%|████▌     | 74/163 [01:30<01:36,  1.09s/it, loss=3.3589, batch_acc=0.1250, running_acc=0.1473, grad=7.1345]Training epoch 1:  45%|████▌     | 74/163 [01:30<01:36,  1.09s/it, loss=3.0572, batch_acc=0.1562, running_acc=0.1474, grad=6.3166]Training epoch 1:  46%|████▌     | 75/163 [01:30<01:30,  1.03s/it, loss=3.0572, batch_acc=0.1562, running_acc=0.1474, grad=6.3166]Training epoch 1:  46%|████▌     | 75/163 [01:30<01:30,  1.03s/it, loss=3.1337, batch_acc=0.1875, running_acc=0.1479, grad=6.7522]Training epoch 1:  47%|████▋     | 76/163 [01:34<02:28,  1.71s/it, loss=3.1337, batch_acc=0.1875, running_acc=0.1479, grad=6.7522]Training epoch 1:  47%|████▋     | 76/163 [01:34<02:28,  1.71s/it, loss=3.3744, batch_acc=0.1562, running_acc=0.1480, grad=7.2069]Training epoch 1:  47%|████▋     | 77/163 [01:35<02:05,  1.46s/it, loss=3.3744, batch_acc=0.1562, running_acc=0.1480, grad=7.2069]Training epoch 1:  47%|████▋     | 77/163 [01:35<02:05,  1.46s/it, loss=3.2882, batch_acc=0.0938, running_acc=0.1473, grad=8.0843]Training epoch 1:  48%|████▊     | 78/163 [01:36<01:49,  1.29s/it, loss=3.2882, batch_acc=0.0938, running_acc=0.1473, grad=8.0843]Training epoch 1:  48%|████▊     | 78/163 [01:36<01:49,  1.29s/it, loss=3.3425, batch_acc=0.0312, running_acc=0.1458, grad=8.3920]Training epoch 1:  48%|████▊     | 79/163 [01:36<01:37,  1.17s/it, loss=3.3425, batch_acc=0.0312, running_acc=0.1458, grad=8.3920]Training epoch 1:  48%|████▊     | 79/163 [01:36<01:37,  1.17s/it, loss=3.3270, batch_acc=0.0938, running_acc=0.1452, grad=8.0590]Training epoch 1:  49%|████▉     | 80/163 [01:38<01:50,  1.34s/it, loss=3.3270, batch_acc=0.0938, running_acc=0.1452, grad=8.0590]Training epoch 1:  49%|████▉     | 80/163 [01:38<01:50,  1.34s/it, loss=3.2682, batch_acc=0.1875, running_acc=0.1457, grad=9.5031]Training epoch 1:  50%|████▉     | 81/163 [01:39<01:38,  1.20s/it, loss=3.2682, batch_acc=0.1875, running_acc=0.1457, grad=9.5031]Training epoch 1:  50%|████▉     | 81/163 [01:39<01:38,  1.20s/it, loss=3.3114, batch_acc=0.2500, running_acc=0.1470, grad=8.2756]Training epoch 1:  50%|█████     | 82/163 [01:40<01:29,  1.10s/it, loss=3.3114, batch_acc=0.2500, running_acc=0.1470, grad=8.2756]Training epoch 1:  50%|█████     | 82/163 [01:40<01:29,  1.10s/it, loss=2.9989, batch_acc=0.2188, running_acc=0.1479, grad=7.7916]Training epoch 1:  51%|█████     | 83/163 [01:41<01:22,  1.04s/it, loss=2.9989, batch_acc=0.2188, running_acc=0.1479, grad=7.7916]Training epoch 1:  51%|█████     | 83/163 [01:41<01:22,  1.04s/it, loss=3.0289, batch_acc=0.2812, running_acc=0.1495, grad=10.5912]Training epoch 1:  52%|█████▏    | 84/163 [01:43<01:55,  1.46s/it, loss=3.0289, batch_acc=0.2812, running_acc=0.1495, grad=10.5912]Training epoch 1:  52%|█████▏    | 84/163 [01:43<01:55,  1.46s/it, loss=3.2528, batch_acc=0.1250, running_acc=0.1492, grad=7.3396] Training epoch 1:  52%|█████▏    | 85/163 [01:44<01:40,  1.28s/it, loss=3.2528, batch_acc=0.1250, running_acc=0.1492, grad=7.3396]Training epoch 1:  52%|█████▏    | 85/163 [01:44<01:40,  1.28s/it, loss=3.4200, batch_acc=0.1562, running_acc=0.1493, grad=9.1780]Training epoch 1:  53%|█████▎    | 86/163 [01:45<01:29,  1.16s/it, loss=3.4200, batch_acc=0.1562, running_acc=0.1493, grad=9.1780]Training epoch 1:  53%|█████▎    | 86/163 [01:45<01:29,  1.16s/it, loss=3.3535, batch_acc=0.0625, running_acc=0.1483, grad=6.9329]Training epoch 1:  53%|█████▎    | 87/163 [01:46<01:21,  1.08s/it, loss=3.3535, batch_acc=0.0625, running_acc=0.1483, grad=6.9329]Training epoch 1:  53%|█████▎    | 87/163 [01:46<01:21,  1.08s/it, loss=3.3345, batch_acc=0.1562, running_acc=0.1483, grad=7.1875]Training epoch 1:  54%|█████▍    | 88/163 [01:47<01:27,  1.16s/it, loss=3.3345, batch_acc=0.1562, running_acc=0.1483, grad=7.1875]Training epoch 1:  54%|█████▍    | 88/163 [01:47<01:27,  1.16s/it, loss=3.3959, batch_acc=0.0625, running_acc=0.1474, grad=8.5863]Training epoch 1:  55%|█████▍    | 89/163 [01:48<01:19,  1.08s/it, loss=3.3959, batch_acc=0.0625, running_acc=0.1474, grad=8.5863]Training epoch 1:  55%|█████▍    | 89/163 [01:48<01:19,  1.08s/it, loss=3.4236, batch_acc=0.1562, running_acc=0.1475, grad=7.6732]Training epoch 1:  55%|█████▌    | 90/163 [01:49<01:14,  1.02s/it, loss=3.4236, batch_acc=0.1562, running_acc=0.1475, grad=7.6732]Training epoch 1:  55%|█████▌    | 90/163 [01:49<01:14,  1.02s/it, loss=3.0806, batch_acc=0.2188, running_acc=0.1483, grad=7.3178]Training epoch 1:  56%|█████▌    | 91/163 [01:50<01:10,  1.02it/s, loss=3.0806, batch_acc=0.2188, running_acc=0.1483, grad=7.3178]Training epoch 1:  56%|█████▌    | 91/163 [01:50<01:10,  1.02it/s, loss=3.2247, batch_acc=0.1562, running_acc=0.1484, grad=8.3808]Training epoch 1:  56%|█████▋    | 92/163 [01:51<01:21,  1.14s/it, loss=3.2247, batch_acc=0.1562, running_acc=0.1484, grad=8.3808]Training epoch 1:  56%|█████▋    | 92/163 [01:51<01:21,  1.14s/it, loss=3.4401, batch_acc=0.0312, running_acc=0.1471, grad=7.3232]Training epoch 1:  57%|█████▋    | 93/163 [01:52<01:14,  1.07s/it, loss=3.4401, batch_acc=0.0312, running_acc=0.1471, grad=7.3232]Training epoch 1:  57%|█████▋    | 93/163 [01:52<01:14,  1.07s/it, loss=3.2805, batch_acc=0.1875, running_acc=0.1475, grad=8.5086]Training epoch 1:  58%|█████▊    | 94/163 [01:53<01:09,  1.01s/it, loss=3.2805, batch_acc=0.1875, running_acc=0.1475, grad=8.5086]Training epoch 1:  58%|█████▊    | 94/163 [01:53<01:09,  1.01s/it, loss=3.0658, batch_acc=0.2812, running_acc=0.1489, grad=8.2115]Training epoch 1:  58%|█████▊    | 95/163 [01:54<01:06,  1.03it/s, loss=3.0658, batch_acc=0.2812, running_acc=0.1489, grad=8.2115]Training epoch 1:  58%|█████▊    | 95/163 [01:54<01:06,  1.03it/s, loss=3.2470, batch_acc=0.1875, running_acc=0.1493, grad=7.1374]Training epoch 1:  59%|█████▉    | 96/163 [01:56<01:25,  1.28s/it, loss=3.2470, batch_acc=0.1875, running_acc=0.1493, grad=7.1374]Training epoch 1:  59%|█████▉    | 96/163 [01:56<01:25,  1.28s/it, loss=3.1170, batch_acc=0.1875, running_acc=0.1497, grad=8.2537]Training epoch 1:  60%|█████▉    | 97/163 [01:57<01:16,  1.16s/it, loss=3.1170, batch_acc=0.1875, running_acc=0.1497, grad=8.2537]Training epoch 1:  60%|█████▉    | 97/163 [01:57<01:16,  1.16s/it, loss=3.2199, batch_acc=0.2188, running_acc=0.1505, grad=6.9290]Training epoch 1:  60%|██████    | 98/163 [01:58<01:09,  1.08s/it, loss=3.2199, batch_acc=0.2188, running_acc=0.1505, grad=6.9290]Training epoch 1:  60%|██████    | 98/163 [01:58<01:09,  1.08s/it, loss=3.2700, batch_acc=0.2188, running_acc=0.1511, grad=7.5278]Training epoch 1:  61%|██████    | 99/163 [01:59<01:05,  1.02s/it, loss=3.2700, batch_acc=0.2188, running_acc=0.1511, grad=7.5278]Training epoch 1:  61%|██████    | 99/163 [01:59<01:05,  1.02s/it, loss=3.1019, batch_acc=0.2188, running_acc=0.1518, grad=6.8959]Training epoch 1:  61%|██████▏   | 100/163 [02:00<01:12,  1.14s/it, loss=3.1019, batch_acc=0.2188, running_acc=0.1518, grad=6.8959]Training epoch 1:  61%|██████▏   | 100/163 [02:00<01:12,  1.14s/it, loss=3.2656, batch_acc=0.1875, running_acc=0.1522, grad=6.7914]Training epoch 1:  62%|██████▏   | 101/163 [02:01<01:06,  1.06s/it, loss=3.2656, batch_acc=0.1875, running_acc=0.1522, grad=6.7914]Training epoch 1:  62%|██████▏   | 101/163 [02:01<01:06,  1.06s/it, loss=3.3265, batch_acc=0.1562, running_acc=0.1522, grad=7.5726]Training epoch 1:  63%|██████▎   | 102/163 [02:02<01:01,  1.01s/it, loss=3.3265, batch_acc=0.1562, running_acc=0.1522, grad=7.5726]Training epoch 1:  63%|██████▎   | 102/163 [02:02<01:01,  1.01s/it, loss=3.4406, batch_acc=0.1562, running_acc=0.1523, grad=6.9397]Training epoch 1:  63%|██████▎   | 103/163 [02:03<00:58,  1.03it/s, loss=3.4406, batch_acc=0.1562, running_acc=0.1523, grad=6.9397]Training epoch 1:  63%|██████▎   | 103/163 [02:03<00:58,  1.03it/s, loss=3.0689, batch_acc=0.2812, running_acc=0.1535, grad=7.5642]Training epoch 1:  64%|██████▍   | 104/163 [02:04<00:59,  1.00s/it, loss=3.0689, batch_acc=0.2812, running_acc=0.1535, grad=7.5642]Training epoch 1:  64%|██████▍   | 104/163 [02:04<00:59,  1.00s/it, loss=3.3694, batch_acc=0.1875, running_acc=0.1538, grad=8.1365]Training epoch 1:  64%|██████▍   | 105/163 [02:05<00:56,  1.04it/s, loss=3.3694, batch_acc=0.1875, running_acc=0.1538, grad=8.1365]Training epoch 1:  64%|██████▍   | 105/163 [02:05<00:56,  1.04it/s, loss=3.5262, batch_acc=0.1250, running_acc=0.1536, grad=7.8244]Training epoch 1:  65%|██████▌   | 106/163 [02:06<00:53,  1.06it/s, loss=3.5262, batch_acc=0.1250, running_acc=0.1536, grad=7.8244]Training epoch 1:  65%|██████▌   | 106/163 [02:06<00:53,  1.06it/s, loss=3.3131, batch_acc=0.1250, running_acc=0.1533, grad=8.7645]Training epoch 1:  66%|██████▌   | 107/163 [02:07<00:51,  1.08it/s, loss=3.3131, batch_acc=0.1250, running_acc=0.1533, grad=8.7645]Training epoch 1:  66%|██████▌   | 107/163 [02:07<00:51,  1.08it/s, loss=3.3725, batch_acc=0.0938, running_acc=0.1527, grad=6.3904]Training epoch 1:  66%|██████▋   | 108/163 [02:08<00:55,  1.01s/it, loss=3.3725, batch_acc=0.0938, running_acc=0.1527, grad=6.3904]Training epoch 1:  66%|██████▋   | 108/163 [02:08<00:55,  1.01s/it, loss=3.3944, batch_acc=0.0625, running_acc=0.1519, grad=8.4690]Training epoch 1:  67%|██████▋   | 109/163 [02:09<00:52,  1.03it/s, loss=3.3944, batch_acc=0.0625, running_acc=0.1519, grad=8.4690]Training epoch 1:  67%|██████▋   | 109/163 [02:09<00:52,  1.03it/s, loss=3.2729, batch_acc=0.1562, running_acc=0.1519, grad=9.9962]Training epoch 1:  67%|██████▋   | 110/163 [02:10<00:50,  1.06it/s, loss=3.2729, batch_acc=0.1562, running_acc=0.1519, grad=9.9962]Training epoch 1:  67%|██████▋   | 110/163 [02:10<00:50,  1.06it/s, loss=2.8690, batch_acc=0.3125, running_acc=0.1534, grad=7.2885]Training epoch 1:  68%|██████▊   | 111/163 [02:10<00:48,  1.08it/s, loss=2.8690, batch_acc=0.3125, running_acc=0.1534, grad=7.2885]Training epoch 1:  68%|██████▊   | 111/163 [02:10<00:48,  1.08it/s, loss=3.1450, batch_acc=0.2188, running_acc=0.1540, grad=7.0443]Training epoch 1:  69%|██████▊   | 112/163 [02:12<00:53,  1.06s/it, loss=3.1450, batch_acc=0.2188, running_acc=0.1540, grad=7.0443]Training epoch 1:  69%|██████▊   | 112/163 [02:12<00:53,  1.06s/it, loss=3.3929, batch_acc=0.1250, running_acc=0.1537, grad=6.7717]Training epoch 1:  69%|██████▉   | 113/163 [02:13<00:50,  1.00s/it, loss=3.3929, batch_acc=0.1250, running_acc=0.1537, grad=6.7717]Training epoch 1:  69%|██████▉   | 113/163 [02:13<00:50,  1.00s/it, loss=3.2101, batch_acc=0.2188, running_acc=0.1543, grad=8.1679]Training epoch 1:  70%|██████▉   | 114/163 [02:14<00:47,  1.03it/s, loss=3.2101, batch_acc=0.2188, running_acc=0.1543, grad=8.1679]Training epoch 1:  70%|██████▉   | 114/163 [02:14<00:47,  1.03it/s, loss=3.3106, batch_acc=0.0938, running_acc=0.1538, grad=7.9406]Training epoch 1:  71%|███████   | 115/163 [02:14<00:45,  1.06it/s, loss=3.3106, batch_acc=0.0938, running_acc=0.1538, grad=7.9406]Training epoch 1:  71%|███████   | 115/163 [02:14<00:45,  1.06it/s, loss=3.4276, batch_acc=0.1250, running_acc=0.1535, grad=9.2659]Training epoch 1:  71%|███████   | 116/163 [02:15<00:45,  1.04it/s, loss=3.4276, batch_acc=0.1250, running_acc=0.1535, grad=9.2659]Training epoch 1:  71%|███████   | 116/163 [02:15<00:45,  1.04it/s, loss=3.3173, batch_acc=0.1562, running_acc=0.1536, grad=8.5051]Training epoch 1:  72%|███████▏  | 117/163 [02:16<00:43,  1.07it/s, loss=3.3173, batch_acc=0.1562, running_acc=0.1536, grad=8.5051]Training epoch 1:  72%|███████▏  | 117/163 [02:16<00:43,  1.07it/s, loss=3.1906, batch_acc=0.1562, running_acc=0.1536, grad=7.8677]Training epoch 1:  72%|███████▏  | 118/163 [02:17<00:41,  1.09it/s, loss=3.1906, batch_acc=0.1562, running_acc=0.1536, grad=7.8677]Training epoch 1:  72%|███████▏  | 118/163 [02:17<00:41,  1.09it/s, loss=3.2579, batch_acc=0.1875, running_acc=0.1539, grad=7.9391]Training epoch 1:  73%|███████▎  | 119/163 [02:18<00:39,  1.10it/s, loss=3.2579, batch_acc=0.1875, running_acc=0.1539, grad=7.9391]Training epoch 1:  73%|███████▎  | 119/163 [02:18<00:39,  1.10it/s, loss=3.0889, batch_acc=0.2500, running_acc=0.1547, grad=7.6635]Training epoch 1:  74%|███████▎  | 120/163 [02:19<00:42,  1.02it/s, loss=3.0889, batch_acc=0.2500, running_acc=0.1547, grad=7.6635]Training epoch 1:  74%|███████▎  | 120/163 [02:19<00:42,  1.02it/s, loss=3.2969, batch_acc=0.1562, running_acc=0.1547, grad=9.0894]Training epoch 1:  74%|███████▍  | 121/163 [02:20<00:39,  1.05it/s, loss=3.2969, batch_acc=0.1562, running_acc=0.1547, grad=9.0894]Training epoch 1:  74%|███████▍  | 121/163 [02:20<00:39,  1.05it/s, loss=3.1211, batch_acc=0.1875, running_acc=0.1550, grad=6.9037]Training epoch 1:  75%|███████▍  | 122/163 [02:21<00:38,  1.08it/s, loss=3.1211, batch_acc=0.1875, running_acc=0.1550, grad=6.9037]Training epoch 1:  75%|███████▍  | 122/163 [02:21<00:38,  1.08it/s, loss=3.0344, batch_acc=0.2188, running_acc=0.1555, grad=8.6573]Training epoch 1:  75%|███████▌  | 123/163 [02:22<00:36,  1.09it/s, loss=3.0344, batch_acc=0.2188, running_acc=0.1555, grad=8.6573]Training epoch 1:  75%|███████▌  | 123/163 [02:22<00:36,  1.09it/s, loss=3.3500, batch_acc=0.1250, running_acc=0.1552, grad=9.3510]Training epoch 1:  76%|███████▌  | 124/163 [02:24<00:48,  1.25s/it, loss=3.3500, batch_acc=0.1250, running_acc=0.1552, grad=9.3510]Training epoch 1:  76%|███████▌  | 124/163 [02:24<00:48,  1.25s/it, loss=3.1043, batch_acc=0.2188, running_acc=0.1557, grad=8.1448]Training epoch 1:  77%|███████▋  | 125/163 [02:25<00:43,  1.14s/it, loss=3.1043, batch_acc=0.2188, running_acc=0.1557, grad=8.1448]Training epoch 1:  77%|███████▋  | 125/163 [02:25<00:43,  1.14s/it, loss=3.1558, batch_acc=0.1875, running_acc=0.1560, grad=7.5404]Training epoch 1:  77%|███████▋  | 126/163 [02:26<00:39,  1.06s/it, loss=3.1558, batch_acc=0.1875, running_acc=0.1560, grad=7.5404]Training epoch 1:  77%|███████▋  | 126/163 [02:26<00:39,  1.06s/it, loss=3.1861, batch_acc=0.1875, running_acc=0.1562, grad=7.3122]Training epoch 1:  78%|███████▊  | 127/163 [02:26<00:36,  1.01s/it, loss=3.1861, batch_acc=0.1875, running_acc=0.1562, grad=7.3122]Training epoch 1:  78%|███████▊  | 127/163 [02:26<00:36,  1.01s/it, loss=3.1346, batch_acc=0.2812, running_acc=0.1572, grad=7.8400]Training epoch 1:  79%|███████▊  | 128/163 [02:29<00:46,  1.32s/it, loss=3.1346, batch_acc=0.2812, running_acc=0.1572, grad=7.8400]Training epoch 1:  79%|███████▊  | 128/163 [02:29<00:46,  1.32s/it, loss=3.0718, batch_acc=0.1875, running_acc=0.1575, grad=8.1638]Training epoch 1:  79%|███████▉  | 129/163 [02:29<00:40,  1.19s/it, loss=3.0718, batch_acc=0.1875, running_acc=0.1575, grad=8.1638]Training epoch 1:  79%|███████▉  | 129/163 [02:29<00:40,  1.19s/it, loss=3.3379, batch_acc=0.1875, running_acc=0.1577, grad=6.3780]Training epoch 1:  80%|███████▉  | 130/163 [02:30<00:36,  1.10s/it, loss=3.3379, batch_acc=0.1875, running_acc=0.1577, grad=6.3780]Training epoch 1:  80%|███████▉  | 130/163 [02:30<00:36,  1.10s/it, loss=3.3094, batch_acc=0.1875, running_acc=0.1579, grad=7.6269]Training epoch 1:  80%|████████  | 131/163 [02:31<00:32,  1.03s/it, loss=3.3094, batch_acc=0.1875, running_acc=0.1579, grad=7.6269]Training epoch 1:  80%|████████  | 131/163 [02:31<00:32,  1.03s/it, loss=3.2559, batch_acc=0.1562, running_acc=0.1579, grad=7.1627]Training epoch 1:  81%|████████  | 132/163 [02:32<00:31,  1.01s/it, loss=3.2559, batch_acc=0.1562, running_acc=0.1579, grad=7.1627]Training epoch 1:  81%|████████  | 132/163 [02:32<00:31,  1.01s/it, loss=3.3813, batch_acc=0.1562, running_acc=0.1579, grad=6.4740]Training epoch 1:  82%|████████▏ | 133/163 [02:33<00:29,  1.03it/s, loss=3.3813, batch_acc=0.1562, running_acc=0.1579, grad=6.4740]Training epoch 1:  82%|████████▏ | 133/163 [02:33<00:29,  1.03it/s, loss=3.3613, batch_acc=0.1250, running_acc=0.1577, grad=10.9299]Training epoch 1:  82%|████████▏ | 134/163 [02:34<00:27,  1.06it/s, loss=3.3613, batch_acc=0.1250, running_acc=0.1577, grad=10.9299]Training epoch 1:  82%|████████▏ | 134/163 [02:34<00:27,  1.06it/s, loss=3.0553, batch_acc=0.1562, running_acc=0.1576, grad=9.9270] Training epoch 1:  83%|████████▎ | 135/163 [02:35<00:26,  1.06it/s, loss=3.0553, batch_acc=0.1562, running_acc=0.1576, grad=9.9270]Training epoch 1:  83%|████████▎ | 135/163 [02:35<00:26,  1.06it/s, loss=2.8194, batch_acc=0.2812, running_acc=0.1586, grad=7.3144]Training epoch 1:  83%|████████▎ | 136/163 [02:36<00:27,  1.00s/it, loss=2.8194, batch_acc=0.2812, running_acc=0.1586, grad=7.3144]Training epoch 1:  83%|████████▎ | 136/163 [02:36<00:27,  1.00s/it, loss=3.1465, batch_acc=0.1562, running_acc=0.1585, grad=8.7696]Training epoch 1:  84%|████████▍ | 137/163 [02:37<00:25,  1.03it/s, loss=3.1465, batch_acc=0.1562, running_acc=0.1585, grad=8.7696]Training epoch 1:  84%|████████▍ | 137/163 [02:37<00:25,  1.03it/s, loss=3.0760, batch_acc=0.1562, running_acc=0.1585, grad=7.4233]Training epoch 1:  85%|████████▍ | 138/163 [02:38<00:23,  1.06it/s, loss=3.0760, batch_acc=0.1562, running_acc=0.1585, grad=7.4233]Training epoch 1:  85%|████████▍ | 138/163 [02:38<00:23,  1.06it/s, loss=3.0903, batch_acc=0.1875, running_acc=0.1587, grad=9.5818]Training epoch 1:  85%|████████▌ | 139/163 [02:39<00:22,  1.08it/s, loss=3.0903, batch_acc=0.1875, running_acc=0.1587, grad=9.5818]Training epoch 1:  85%|████████▌ | 139/163 [02:39<00:22,  1.08it/s, loss=3.1877, batch_acc=0.2812, running_acc=0.1596, grad=9.9836]Training epoch 1:  86%|████████▌ | 140/163 [02:40<00:24,  1.07s/it, loss=3.1877, batch_acc=0.2812, running_acc=0.1596, grad=9.9836]Training epoch 1:  86%|████████▌ | 140/163 [02:40<00:24,  1.07s/it, loss=2.9850, batch_acc=0.3125, running_acc=0.1607, grad=9.9721]Training epoch 1:  87%|████████▋ | 141/163 [02:41<00:23,  1.07s/it, loss=2.9850, batch_acc=0.3125, running_acc=0.1607, grad=9.9721]Training epoch 1:  87%|████████▋ | 141/163 [02:41<00:23,  1.07s/it, loss=3.1161, batch_acc=0.0938, running_acc=0.1602, grad=8.2144]Training epoch 1:  87%|████████▋ | 142/163 [02:42<00:21,  1.01s/it, loss=3.1161, batch_acc=0.0938, running_acc=0.1602, grad=8.2144]Training epoch 1:  87%|████████▋ | 142/163 [02:42<00:21,  1.01s/it, loss=3.3740, batch_acc=0.1562, running_acc=0.1602, grad=8.5910]Training epoch 1:  88%|████████▊ | 143/163 [02:43<00:19,  1.03it/s, loss=3.3740, batch_acc=0.1562, running_acc=0.1602, grad=8.5910]Training epoch 1:  88%|████████▊ | 143/163 [02:43<00:19,  1.03it/s, loss=3.2610, batch_acc=0.1250, running_acc=0.1600, grad=7.7125]Training epoch 1:  88%|████████▊ | 144/163 [02:45<00:22,  1.18s/it, loss=3.2610, batch_acc=0.1250, running_acc=0.1600, grad=7.7125]Training epoch 1:  88%|████████▊ | 144/163 [02:45<00:22,  1.18s/it, loss=3.6916, batch_acc=0.1562, running_acc=0.1599, grad=8.3806]Training epoch 1:  89%|████████▉ | 145/163 [02:45<00:20,  1.11s/it, loss=3.6916, batch_acc=0.1562, running_acc=0.1599, grad=8.3806]Training epoch 1:  89%|████████▉ | 145/163 [02:45<00:20,  1.11s/it, loss=3.2108, batch_acc=0.2188, running_acc=0.1603, grad=7.4328]Training epoch 1:  90%|████████▉ | 146/163 [02:46<00:17,  1.04s/it, loss=3.2108, batch_acc=0.2188, running_acc=0.1603, grad=7.4328]Training epoch 1:  90%|████████▉ | 146/163 [02:46<00:17,  1.04s/it, loss=2.8795, batch_acc=0.2188, running_acc=0.1607, grad=8.6963]Training epoch 1:  90%|█████████ | 147/163 [02:47<00:15,  1.01it/s, loss=2.8795, batch_acc=0.2188, running_acc=0.1607, grad=8.6963]Training epoch 1:  90%|█████████ | 147/163 [02:47<00:15,  1.01it/s, loss=3.1428, batch_acc=0.1875, running_acc=0.1609, grad=6.9680]Training epoch 1:  91%|█████████ | 148/163 [02:48<00:15,  1.06s/it, loss=3.1428, batch_acc=0.1875, running_acc=0.1609, grad=6.9680]Training epoch 1:  91%|█████████ | 148/163 [02:48<00:15,  1.06s/it, loss=2.9693, batch_acc=0.1875, running_acc=0.1611, grad=7.5766]Training epoch 1:  91%|█████████▏| 149/163 [02:49<00:14,  1.01s/it, loss=2.9693, batch_acc=0.1875, running_acc=0.1611, grad=7.5766]Training epoch 1:  91%|█████████▏| 149/163 [02:49<00:14,  1.01s/it, loss=3.3984, batch_acc=0.1562, running_acc=0.1611, grad=8.7509]Training epoch 1:  92%|█████████▏| 150/163 [02:50<00:12,  1.03it/s, loss=3.3984, batch_acc=0.1562, running_acc=0.1611, grad=8.7509]Training epoch 1:  92%|█████████▏| 150/163 [02:50<00:12,  1.03it/s, loss=3.2554, batch_acc=0.1875, running_acc=0.1613, grad=7.3277]Training epoch 1:  93%|█████████▎| 151/163 [02:51<00:11,  1.06it/s, loss=3.2554, batch_acc=0.1875, running_acc=0.1613, grad=7.3277]Training epoch 1:  93%|█████████▎| 151/163 [02:51<00:11,  1.06it/s, loss=3.0830, batch_acc=0.1250, running_acc=0.1610, grad=8.2255]Training epoch 1:  93%|█████████▎| 152/163 [02:52<00:10,  1.08it/s, loss=3.0830, batch_acc=0.1250, running_acc=0.1610, grad=8.2255]Training epoch 1:  93%|█████████▎| 152/163 [02:52<00:10,  1.08it/s, loss=3.3129, batch_acc=0.1562, running_acc=0.1610, grad=7.6551]Training epoch 1:  94%|█████████▍| 153/163 [02:54<00:11,  1.19s/it, loss=3.3129, batch_acc=0.1562, running_acc=0.1610, grad=7.6551]Training epoch 1:  94%|█████████▍| 153/163 [02:54<00:11,  1.19s/it, loss=3.0486, batch_acc=0.2188, running_acc=0.1614, grad=6.8215]Training epoch 1:  94%|█████████▍| 154/163 [02:55<00:09,  1.10s/it, loss=3.0486, batch_acc=0.2188, running_acc=0.1614, grad=6.8215]Training epoch 1:  94%|█████████▍| 154/163 [02:55<00:09,  1.10s/it, loss=3.1799, batch_acc=0.1875, running_acc=0.1615, grad=8.3465]Training epoch 1:  95%|█████████▌| 155/163 [02:56<00:08,  1.03s/it, loss=3.1799, batch_acc=0.1875, running_acc=0.1615, grad=8.3465]Training epoch 1:  95%|█████████▌| 155/163 [02:56<00:08,  1.03s/it, loss=3.1581, batch_acc=0.1875, running_acc=0.1617, grad=8.2641]Training epoch 1:  96%|█████████▌| 156/163 [02:56<00:06,  1.01it/s, loss=3.1581, batch_acc=0.1875, running_acc=0.1617, grad=8.2641]Training epoch 1:  96%|█████████▌| 156/163 [02:56<00:06,  1.01it/s, loss=3.2267, batch_acc=0.1562, running_acc=0.1617, grad=9.3061]Training epoch 1:  96%|█████████▋| 157/163 [02:58<00:07,  1.19s/it, loss=3.2267, batch_acc=0.1562, running_acc=0.1617, grad=9.3061]Training epoch 1:  96%|█████████▋| 157/163 [02:58<00:07,  1.19s/it, loss=3.0688, batch_acc=0.1875, running_acc=0.1618, grad=8.7396]Training epoch 1:  97%|█████████▋| 158/163 [02:59<00:05,  1.10s/it, loss=3.0688, batch_acc=0.1875, running_acc=0.1618, grad=8.7396]Training epoch 1:  97%|█████████▋| 158/163 [02:59<00:05,  1.10s/it, loss=3.0146, batch_acc=0.2188, running_acc=0.1622, grad=7.1261]Training epoch 1:  98%|█████████▊| 159/163 [03:00<00:04,  1.03s/it, loss=3.0146, batch_acc=0.2188, running_acc=0.1622, grad=7.1261]Training epoch 1:  98%|█████████▊| 159/163 [03:00<00:04,  1.03s/it, loss=3.3332, batch_acc=0.1875, running_acc=0.1623, grad=8.7614]Training epoch 1:  98%|█████████▊| 160/163 [03:01<00:02,  1.00it/s, loss=3.3332, batch_acc=0.1875, running_acc=0.1623, grad=8.7614]Training epoch 1:  98%|█████████▊| 160/163 [03:01<00:02,  1.00it/s, loss=3.2244, batch_acc=0.2500, running_acc=0.1629, grad=7.4024]Training epoch 1:  99%|█████████▉| 161/163 [03:02<00:02,  1.03s/it, loss=3.2244, batch_acc=0.2500, running_acc=0.1629, grad=7.4024]Training epoch 1:  99%|█████████▉| 161/163 [03:02<00:02,  1.03s/it, loss=2.9857, batch_acc=0.1562, running_acc=0.1628, grad=7.1061]Training epoch 1:  99%|█████████▉| 162/163 [03:03<00:00,  1.02it/s, loss=2.9857, batch_acc=0.1562, running_acc=0.1628, grad=7.1061]Training epoch 1:  99%|█████████▉| 162/163 [03:03<00:00,  1.02it/s, loss=3.2350, batch_acc=0.1875, running_acc=0.1630, grad=8.3331]Training epoch 1: 100%|██████████| 163/163 [03:03<00:00,  1.14it/s, loss=3.2350, batch_acc=0.1875, running_acc=0.1630, grad=8.3331]Training epoch 1: 100%|██████████| 163/163 [03:03<00:00,  1.14it/s, loss=3.0095, batch_acc=0.1905, running_acc=0.1631, grad=11.8408]Training epoch 1: 100%|██████████| 163/163 [03:03<00:00,  1.13s/it, loss=3.0095, batch_acc=0.1905, running_acc=0.1631, grad=11.8408]
Evaluation epoch 1:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 1:   4%|▎         | 1/28 [00:04<02:12,  4.92s/it]Evaluation epoch 1:   4%|▎         | 1/28 [00:04<02:12,  4.92s/it, loss=2.5068, batch_acc=0.1875, running_acc=0.1875]Evaluation epoch 1:   7%|▋         | 2/28 [00:05<00:57,  2.20s/it, loss=2.5068, batch_acc=0.1875, running_acc=0.1875]Evaluation epoch 1:   7%|▋         | 2/28 [00:05<00:57,  2.20s/it, loss=2.8430, batch_acc=0.3438, running_acc=0.2656]Evaluation epoch 1:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=2.8430, batch_acc=0.3438, running_acc=0.2656]Evaluation epoch 1:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=3.3498, batch_acc=0.0000, running_acc=0.1771]Evaluation epoch 1:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=3.3498, batch_acc=0.0000, running_acc=0.1771]Evaluation epoch 1:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=3.5938, batch_acc=0.0938, running_acc=0.1562]Evaluation epoch 1:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=3.5938, batch_acc=0.0938, running_acc=0.1562]Evaluation epoch 1:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=3.4034, batch_acc=0.0000, running_acc=0.1250]Evaluation epoch 1:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=3.4034, batch_acc=0.0000, running_acc=0.1250]Evaluation epoch 1:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=3.4326, batch_acc=0.2188, running_acc=0.1406]Evaluation epoch 1:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=3.4326, batch_acc=0.2188, running_acc=0.1406]Evaluation epoch 1:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=3.3988, batch_acc=0.0312, running_acc=0.1250]Evaluation epoch 1:  29%|██▊       | 8/28 [00:13<00:33,  1.70s/it, loss=3.3988, batch_acc=0.0312, running_acc=0.1250]Evaluation epoch 1:  29%|██▊       | 8/28 [00:13<00:33,  1.70s/it, loss=3.4062, batch_acc=0.0000, running_acc=0.1094]Evaluation epoch 1:  32%|███▏      | 9/28 [00:14<00:24,  1.31s/it, loss=3.4062, batch_acc=0.0000, running_acc=0.1094]Evaluation epoch 1:  32%|███▏      | 9/28 [00:14<00:24,  1.31s/it, loss=3.3942, batch_acc=0.1562, running_acc=0.1146]Evaluation epoch 1:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=3.3942, batch_acc=0.1562, running_acc=0.1146]Evaluation epoch 1:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=2.2135, batch_acc=0.6875, running_acc=0.1719]Evaluation epoch 1:  39%|███▉      | 11/28 [00:14<00:13,  1.31it/s, loss=2.2135, batch_acc=0.6875, running_acc=0.1719]Evaluation epoch 1:  39%|███▉      | 11/28 [00:14<00:13,  1.31it/s, loss=3.3684, batch_acc=0.0312, running_acc=0.1591]Evaluation epoch 1:  43%|████▎     | 12/28 [00:20<00:35,  2.25s/it, loss=3.3684, batch_acc=0.0312, running_acc=0.1591]Evaluation epoch 1:  43%|████▎     | 12/28 [00:20<00:35,  2.25s/it, loss=3.0808, batch_acc=0.3438, running_acc=0.1745]Evaluation epoch 1:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=3.0808, batch_acc=0.3438, running_acc=0.1745]Evaluation epoch 1:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=3.3457, batch_acc=0.1250, running_acc=0.1707]Evaluation epoch 1:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=3.3457, batch_acc=0.1250, running_acc=0.1707]Evaluation epoch 1:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=3.2820, batch_acc=0.1250, running_acc=0.1674]Evaluation epoch 1:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=3.2820, batch_acc=0.1250, running_acc=0.1674]Evaluation epoch 1:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=3.2857, batch_acc=0.3125, running_acc=0.1771]Evaluation epoch 1:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=3.2857, batch_acc=0.3125, running_acc=0.1771]Evaluation epoch 1:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=3.4799, batch_acc=0.3125, running_acc=0.1855]Evaluation epoch 1:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=3.4799, batch_acc=0.3125, running_acc=0.1855]Evaluation epoch 1:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=3.2248, batch_acc=0.2188, running_acc=0.1875]Evaluation epoch 1:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=3.2248, batch_acc=0.2188, running_acc=0.1875]Evaluation epoch 1:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=2.9053, batch_acc=0.1250, running_acc=0.1840]Evaluation epoch 1:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=2.9053, batch_acc=0.1250, running_acc=0.1840]Evaluation epoch 1:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=2.9289, batch_acc=0.0000, running_acc=0.1743]Evaluation epoch 1:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=2.9289, batch_acc=0.0000, running_acc=0.1743]Evaluation epoch 1:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=3.5643, batch_acc=0.0000, running_acc=0.1656]Evaluation epoch 1:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=3.5643, batch_acc=0.0000, running_acc=0.1656]Evaluation epoch 1:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=3.6952, batch_acc=0.0000, running_acc=0.1577]Evaluation epoch 1:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=3.6952, batch_acc=0.0000, running_acc=0.1577]Evaluation epoch 1:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=3.6207, batch_acc=0.0000, running_acc=0.1506]Evaluation epoch 1:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=3.6207, batch_acc=0.0000, running_acc=0.1506]Evaluation epoch 1:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=3.5501, batch_acc=0.0938, running_acc=0.1481]Evaluation epoch 1:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=3.5501, batch_acc=0.0938, running_acc=0.1481]Evaluation epoch 1:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=2.4437, batch_acc=0.5625, running_acc=0.1654]Evaluation epoch 1:  89%|████████▉ | 25/28 [00:34<00:04,  1.48s/it, loss=2.4437, batch_acc=0.5625, running_acc=0.1654]Evaluation epoch 1:  89%|████████▉ | 25/28 [00:34<00:04,  1.48s/it, loss=2.3223, batch_acc=0.4688, running_acc=0.1775]Evaluation epoch 1:  93%|█████████▎| 26/28 [00:34<00:02,  1.11s/it, loss=2.3223, batch_acc=0.4688, running_acc=0.1775]Evaluation epoch 1:  93%|█████████▎| 26/28 [00:34<00:02,  1.11s/it, loss=2.7077, batch_acc=0.4062, running_acc=0.1863]Evaluation epoch 1:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=2.7077, batch_acc=0.4062, running_acc=0.1863]Evaluation epoch 1:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=2.8949, batch_acc=0.0312, running_acc=0.1806]Evaluation epoch 1: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=2.5539, batch_acc=0.6667, running_acc=0.1822]Evaluation epoch 1: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=2.5539, batch_acc=0.6667, running_acc=0.1822]
Training epoch 2:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 2:   1%|          | 1/163 [00:05<15:11,  5.63s/it]Training epoch 2:   1%|          | 1/163 [00:05<15:11,  5.63s/it, loss=3.0312, batch_acc=0.2812, running_acc=0.2812, grad=7.2643]Training epoch 2:   1%|          | 2/163 [00:06<07:36,  2.83s/it, loss=3.0312, batch_acc=0.2812, running_acc=0.2812, grad=7.2643]Training epoch 2:   1%|          | 2/163 [00:06<07:36,  2.83s/it, loss=3.2759, batch_acc=0.1875, running_acc=0.2344, grad=8.0164]Training epoch 2:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=3.2759, batch_acc=0.1875, running_acc=0.2344, grad=8.0164]Training epoch 2:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=3.2052, batch_acc=0.1562, running_acc=0.2083, grad=7.9850]Training epoch 2:   2%|▏         | 4/163 [00:10<05:54,  2.23s/it, loss=3.2052, batch_acc=0.1562, running_acc=0.2083, grad=7.9850]Training epoch 2:   2%|▏         | 4/163 [00:10<05:54,  2.23s/it, loss=3.5083, batch_acc=0.0625, running_acc=0.1719, grad=9.7071]Training epoch 2:   3%|▎         | 5/163 [00:10<04:35,  1.74s/it, loss=3.5083, batch_acc=0.0625, running_acc=0.1719, grad=9.7071]Training epoch 2:   3%|▎         | 5/163 [00:10<04:35,  1.74s/it, loss=2.8942, batch_acc=0.2812, running_acc=0.1938, grad=7.2796]Training epoch 2:   4%|▎         | 6/163 [00:11<03:47,  1.45s/it, loss=2.8942, batch_acc=0.2812, running_acc=0.1938, grad=7.2796]Training epoch 2:   4%|▎         | 6/163 [00:11<03:47,  1.45s/it, loss=3.0840, batch_acc=0.2188, running_acc=0.1979, grad=7.6126]Training epoch 2:   4%|▍         | 7/163 [00:12<03:16,  1.26s/it, loss=3.0840, batch_acc=0.2188, running_acc=0.1979, grad=7.6126]Training epoch 2:   4%|▍         | 7/163 [00:12<03:16,  1.26s/it, loss=3.2368, batch_acc=0.0625, running_acc=0.1786, grad=11.1767]Training epoch 2:   5%|▍         | 8/163 [00:14<03:25,  1.32s/it, loss=3.2368, batch_acc=0.0625, running_acc=0.1786, grad=11.1767]Training epoch 2:   5%|▍         | 8/163 [00:14<03:25,  1.32s/it, loss=2.8307, batch_acc=0.2188, running_acc=0.1836, grad=6.5898] Training epoch 2:   6%|▌         | 9/163 [00:15<03:02,  1.18s/it, loss=2.8307, batch_acc=0.2188, running_acc=0.1836, grad=6.5898]Training epoch 2:   6%|▌         | 9/163 [00:15<03:02,  1.18s/it, loss=3.0021, batch_acc=0.2188, running_acc=0.1875, grad=8.4185]Training epoch 2:   6%|▌         | 10/163 [00:15<02:46,  1.09s/it, loss=3.0021, batch_acc=0.2188, running_acc=0.1875, grad=8.4185]Training epoch 2:   6%|▌         | 10/163 [00:15<02:46,  1.09s/it, loss=3.3196, batch_acc=0.0938, running_acc=0.1781, grad=7.4345]Training epoch 2:   7%|▋         | 11/163 [00:16<02:35,  1.03s/it, loss=3.3196, batch_acc=0.0938, running_acc=0.1781, grad=7.4345]Training epoch 2:   7%|▋         | 11/163 [00:16<02:35,  1.03s/it, loss=3.0856, batch_acc=0.1562, running_acc=0.1761, grad=8.8297]Training epoch 2:   7%|▋         | 12/163 [00:18<02:53,  1.15s/it, loss=3.0856, batch_acc=0.1562, running_acc=0.1761, grad=8.8297]Training epoch 2:   7%|▋         | 12/163 [00:18<02:53,  1.15s/it, loss=3.3584, batch_acc=0.1562, running_acc=0.1745, grad=8.5815]Training epoch 2:   8%|▊         | 13/163 [00:19<02:39,  1.07s/it, loss=3.3584, batch_acc=0.1562, running_acc=0.1745, grad=8.5815]Training epoch 2:   8%|▊         | 13/163 [00:19<02:39,  1.07s/it, loss=3.3463, batch_acc=0.1250, running_acc=0.1707, grad=8.3824]Training epoch 2:   9%|▊         | 14/163 [00:19<02:30,  1.01s/it, loss=3.3463, batch_acc=0.1250, running_acc=0.1707, grad=8.3824]Training epoch 2:   9%|▊         | 14/163 [00:19<02:30,  1.01s/it, loss=3.1526, batch_acc=0.2500, running_acc=0.1763, grad=9.4157]Training epoch 2:   9%|▉         | 15/163 [00:20<02:23,  1.03it/s, loss=3.1526, batch_acc=0.2500, running_acc=0.1763, grad=9.4157]Training epoch 2:   9%|▉         | 15/163 [00:20<02:23,  1.03it/s, loss=3.2507, batch_acc=0.1562, running_acc=0.1750, grad=7.9374]Training epoch 2:  10%|▉         | 16/163 [00:22<02:54,  1.19s/it, loss=3.2507, batch_acc=0.1562, running_acc=0.1750, grad=7.9374]Training epoch 2:  10%|▉         | 16/163 [00:22<02:54,  1.19s/it, loss=2.9975, batch_acc=0.1250, running_acc=0.1719, grad=8.0026]Training epoch 2:  10%|█         | 17/163 [00:23<02:48,  1.15s/it, loss=2.9975, batch_acc=0.1250, running_acc=0.1719, grad=8.0026]Training epoch 2:  10%|█         | 17/163 [00:23<02:48,  1.15s/it, loss=3.2147, batch_acc=0.1875, running_acc=0.1728, grad=7.5148]Training epoch 2:  11%|█         | 18/163 [00:24<02:35,  1.07s/it, loss=3.2147, batch_acc=0.1875, running_acc=0.1728, grad=7.5148]Training epoch 2:  11%|█         | 18/163 [00:24<02:35,  1.07s/it, loss=2.8385, batch_acc=0.1875, running_acc=0.1736, grad=8.0399]Training epoch 2:  12%|█▏        | 19/163 [00:25<02:25,  1.01s/it, loss=2.8385, batch_acc=0.1875, running_acc=0.1736, grad=8.0399]Training epoch 2:  12%|█▏        | 19/163 [00:25<02:25,  1.01s/it, loss=2.8391, batch_acc=0.2500, running_acc=0.1776, grad=11.1431]Training epoch 2:  12%|█▏        | 20/163 [00:26<02:22,  1.00it/s, loss=2.8391, batch_acc=0.2500, running_acc=0.1776, grad=11.1431]Training epoch 2:  12%|█▏        | 20/163 [00:26<02:22,  1.00it/s, loss=3.2897, batch_acc=0.0625, running_acc=0.1719, grad=7.8640] Training epoch 2:  13%|█▎        | 21/163 [00:27<02:17,  1.04it/s, loss=3.2897, batch_acc=0.0625, running_acc=0.1719, grad=7.8640]Training epoch 2:  13%|█▎        | 21/163 [00:27<02:17,  1.04it/s, loss=3.4046, batch_acc=0.0312, running_acc=0.1652, grad=8.2017]Training epoch 2:  13%|█▎        | 22/163 [00:28<02:32,  1.08s/it, loss=3.4046, batch_acc=0.0312, running_acc=0.1652, grad=8.2017]Training epoch 2:  13%|█▎        | 22/163 [00:28<02:32,  1.08s/it, loss=3.3507, batch_acc=0.0938, running_acc=0.1619, grad=8.6140]Training epoch 2:  14%|█▍        | 23/163 [00:29<02:23,  1.02s/it, loss=3.3507, batch_acc=0.0938, running_acc=0.1619, grad=8.6140]Training epoch 2:  14%|█▍        | 23/163 [00:29<02:23,  1.02s/it, loss=3.3168, batch_acc=0.0938, running_acc=0.1590, grad=6.7124]Training epoch 2:  15%|█▍        | 24/163 [00:30<02:41,  1.16s/it, loss=3.3168, batch_acc=0.0938, running_acc=0.1590, grad=6.7124]Training epoch 2:  15%|█▍        | 24/163 [00:30<02:41,  1.16s/it, loss=3.1124, batch_acc=0.1562, running_acc=0.1589, grad=7.3257]Training epoch 2:  15%|█▌        | 25/163 [00:31<02:28,  1.08s/it, loss=3.1124, batch_acc=0.1562, running_acc=0.1589, grad=7.3257]Training epoch 2:  15%|█▌        | 25/163 [00:31<02:28,  1.08s/it, loss=2.8992, batch_acc=0.2500, running_acc=0.1625, grad=7.4718]Training epoch 2:  16%|█▌        | 26/163 [00:32<02:25,  1.06s/it, loss=2.8992, batch_acc=0.2500, running_acc=0.1625, grad=7.4718]Training epoch 2:  16%|█▌        | 26/163 [00:32<02:25,  1.06s/it, loss=3.5144, batch_acc=0.0938, running_acc=0.1599, grad=9.1889]Training epoch 2:  17%|█▋        | 27/163 [00:33<02:17,  1.01s/it, loss=3.5144, batch_acc=0.0938, running_acc=0.1599, grad=9.1889]Training epoch 2:  17%|█▋        | 27/163 [00:33<02:17,  1.01s/it, loss=3.0980, batch_acc=0.1875, running_acc=0.1609, grad=7.2173]Training epoch 2:  17%|█▋        | 28/163 [00:34<02:15,  1.01s/it, loss=3.0980, batch_acc=0.1875, running_acc=0.1609, grad=7.2173]Training epoch 2:  17%|█▋        | 28/163 [00:34<02:15,  1.01s/it, loss=3.1249, batch_acc=0.2188, running_acc=0.1629, grad=8.1345]Training epoch 2:  18%|█▊        | 29/163 [00:35<02:15,  1.01s/it, loss=3.1249, batch_acc=0.2188, running_acc=0.1629, grad=8.1345]Training epoch 2:  18%|█▊        | 29/163 [00:35<02:15,  1.01s/it, loss=2.8824, batch_acc=0.2500, running_acc=0.1659, grad=10.4670]Training epoch 2:  18%|█▊        | 30/163 [00:37<02:45,  1.24s/it, loss=2.8824, batch_acc=0.2500, running_acc=0.1659, grad=10.4670]Training epoch 2:  18%|█▊        | 30/163 [00:37<02:45,  1.24s/it, loss=3.1339, batch_acc=0.1250, running_acc=0.1646, grad=8.9227] Training epoch 2:  19%|█▉        | 31/163 [00:38<02:29,  1.13s/it, loss=3.1339, batch_acc=0.1250, running_acc=0.1646, grad=8.9227]Training epoch 2:  19%|█▉        | 31/163 [00:38<02:29,  1.13s/it, loss=3.1184, batch_acc=0.1875, running_acc=0.1653, grad=7.9190]Training epoch 2:  20%|█▉        | 32/163 [00:39<02:19,  1.07s/it, loss=3.1184, batch_acc=0.1875, running_acc=0.1653, grad=7.9190]Training epoch 2:  20%|█▉        | 32/163 [00:39<02:19,  1.07s/it, loss=3.3114, batch_acc=0.1562, running_acc=0.1650, grad=8.7585]Training epoch 2:  20%|██        | 33/163 [00:40<02:11,  1.01s/it, loss=3.3114, batch_acc=0.1562, running_acc=0.1650, grad=8.7585]Training epoch 2:  20%|██        | 33/163 [00:40<02:11,  1.01s/it, loss=2.7912, batch_acc=0.3750, running_acc=0.1714, grad=8.3124]Training epoch 2:  21%|██        | 34/163 [00:42<02:51,  1.33s/it, loss=2.7912, batch_acc=0.3750, running_acc=0.1714, grad=8.3124]Training epoch 2:  21%|██        | 34/163 [00:42<02:51,  1.33s/it, loss=3.0351, batch_acc=0.1875, running_acc=0.1719, grad=8.5532]Training epoch 2:  21%|██▏       | 35/163 [00:43<02:32,  1.19s/it, loss=3.0351, batch_acc=0.1875, running_acc=0.1719, grad=8.5532]Training epoch 2:  21%|██▏       | 35/163 [00:43<02:32,  1.19s/it, loss=3.0604, batch_acc=0.2500, running_acc=0.1741, grad=8.8614]Training epoch 2:  22%|██▏       | 36/163 [00:44<02:19,  1.10s/it, loss=3.0604, batch_acc=0.2500, running_acc=0.1741, grad=8.8614]Training epoch 2:  22%|██▏       | 36/163 [00:44<02:19,  1.10s/it, loss=3.1131, batch_acc=0.1875, running_acc=0.1745, grad=8.0308]Training epoch 2:  23%|██▎       | 37/163 [00:44<02:10,  1.03s/it, loss=3.1131, batch_acc=0.1875, running_acc=0.1745, grad=8.0308]Training epoch 2:  23%|██▎       | 37/163 [00:44<02:10,  1.03s/it, loss=2.9120, batch_acc=0.2500, running_acc=0.1765, grad=8.8586]Training epoch 2:  23%|██▎       | 38/163 [00:46<02:36,  1.25s/it, loss=2.9120, batch_acc=0.2500, running_acc=0.1765, grad=8.8586]Training epoch 2:  23%|██▎       | 38/163 [00:46<02:36,  1.25s/it, loss=3.0937, batch_acc=0.1875, running_acc=0.1768, grad=9.1175]Training epoch 2:  24%|██▍       | 39/163 [00:47<02:21,  1.14s/it, loss=3.0937, batch_acc=0.1875, running_acc=0.1768, grad=9.1175]Training epoch 2:  24%|██▍       | 39/163 [00:47<02:21,  1.14s/it, loss=3.2639, batch_acc=0.1250, running_acc=0.1755, grad=8.0149]Training epoch 2:  25%|██▍       | 40/163 [00:48<02:10,  1.06s/it, loss=3.2639, batch_acc=0.1250, running_acc=0.1755, grad=8.0149]Training epoch 2:  25%|██▍       | 40/163 [00:48<02:10,  1.06s/it, loss=3.2112, batch_acc=0.2188, running_acc=0.1766, grad=8.0236]Training epoch 2:  25%|██▌       | 41/163 [00:49<02:03,  1.01s/it, loss=3.2112, batch_acc=0.2188, running_acc=0.1766, grad=8.0236]Training epoch 2:  25%|██▌       | 41/163 [00:49<02:03,  1.01s/it, loss=3.0268, batch_acc=0.2500, running_acc=0.1784, grad=7.9614]Training epoch 2:  26%|██▌       | 42/163 [00:51<02:34,  1.28s/it, loss=3.0268, batch_acc=0.2500, running_acc=0.1784, grad=7.9614]Training epoch 2:  26%|██▌       | 42/163 [00:51<02:34,  1.28s/it, loss=3.1127, batch_acc=0.1250, running_acc=0.1771, grad=8.2078]Training epoch 2:  26%|██▋       | 43/163 [00:52<02:19,  1.16s/it, loss=3.1127, batch_acc=0.1250, running_acc=0.1771, grad=8.2078]Training epoch 2:  26%|██▋       | 43/163 [00:52<02:19,  1.16s/it, loss=2.9428, batch_acc=0.2500, running_acc=0.1788, grad=8.0629]Training epoch 2:  27%|██▋       | 44/163 [00:53<02:08,  1.08s/it, loss=2.9428, batch_acc=0.2500, running_acc=0.1788, grad=8.0629]Training epoch 2:  27%|██▋       | 44/163 [00:53<02:08,  1.08s/it, loss=3.0773, batch_acc=0.1562, running_acc=0.1783, grad=7.0199]Training epoch 2:  28%|██▊       | 45/163 [00:53<02:01,  1.03s/it, loss=3.0773, batch_acc=0.1562, running_acc=0.1783, grad=7.0199]Training epoch 2:  28%|██▊       | 45/163 [00:53<02:01,  1.03s/it, loss=3.1050, batch_acc=0.1875, running_acc=0.1785, grad=8.8232]Training epoch 2:  28%|██▊       | 46/163 [00:55<02:23,  1.23s/it, loss=3.1050, batch_acc=0.1875, running_acc=0.1785, grad=8.8232]Training epoch 2:  28%|██▊       | 46/163 [00:55<02:23,  1.23s/it, loss=3.2510, batch_acc=0.1250, running_acc=0.1773, grad=7.5627]Training epoch 2:  29%|██▉       | 47/163 [00:56<02:10,  1.12s/it, loss=3.2510, batch_acc=0.1250, running_acc=0.1773, grad=7.5627]Training epoch 2:  29%|██▉       | 47/163 [00:56<02:10,  1.12s/it, loss=2.8807, batch_acc=0.2500, running_acc=0.1789, grad=8.1974]Training epoch 2:  29%|██▉       | 48/163 [00:57<02:00,  1.05s/it, loss=2.8807, batch_acc=0.2500, running_acc=0.1789, grad=8.1974]Training epoch 2:  29%|██▉       | 48/163 [00:57<02:00,  1.05s/it, loss=2.9625, batch_acc=0.3438, running_acc=0.1823, grad=6.0324]Training epoch 2:  30%|███       | 49/163 [00:58<01:56,  1.03s/it, loss=2.9625, batch_acc=0.3438, running_acc=0.1823, grad=6.0324]Training epoch 2:  30%|███       | 49/163 [00:58<01:56,  1.03s/it, loss=2.7061, batch_acc=0.2812, running_acc=0.1843, grad=8.4459]Training epoch 2:  31%|███       | 50/163 [01:00<02:26,  1.29s/it, loss=2.7061, batch_acc=0.2812, running_acc=0.1843, grad=8.4459]Training epoch 2:  31%|███       | 50/163 [01:00<02:26,  1.29s/it, loss=3.0665, batch_acc=0.2500, running_acc=0.1856, grad=7.8979]Training epoch 2:  31%|███▏      | 51/163 [01:01<02:10,  1.17s/it, loss=3.0665, batch_acc=0.2500, running_acc=0.1856, grad=7.8979]Training epoch 2:  31%|███▏      | 51/163 [01:01<02:10,  1.17s/it, loss=2.7779, batch_acc=0.2500, running_acc=0.1869, grad=9.2755]Training epoch 2:  32%|███▏      | 52/163 [01:02<02:00,  1.08s/it, loss=2.7779, batch_acc=0.2500, running_acc=0.1869, grad=9.2755]Training epoch 2:  32%|███▏      | 52/163 [01:02<02:00,  1.08s/it, loss=3.4312, batch_acc=0.0938, running_acc=0.1851, grad=8.3268]Training epoch 2:  33%|███▎      | 53/163 [01:02<01:52,  1.02s/it, loss=3.4312, batch_acc=0.0938, running_acc=0.1851, grad=8.3268]Training epoch 2:  33%|███▎      | 53/163 [01:02<01:52,  1.02s/it, loss=3.0483, batch_acc=0.1875, running_acc=0.1851, grad=8.5954]Training epoch 2:  33%|███▎      | 54/163 [01:04<02:16,  1.25s/it, loss=3.0483, batch_acc=0.1875, running_acc=0.1851, grad=8.5954]Training epoch 2:  33%|███▎      | 54/163 [01:04<02:16,  1.25s/it, loss=3.2046, batch_acc=0.1250, running_acc=0.1840, grad=9.8709]Training epoch 2:  34%|███▎      | 55/163 [01:05<02:03,  1.14s/it, loss=3.2046, batch_acc=0.1250, running_acc=0.1840, grad=9.8709]Training epoch 2:  34%|███▎      | 55/163 [01:05<02:03,  1.14s/it, loss=3.0275, batch_acc=0.1875, running_acc=0.1841, grad=10.0715]Training epoch 2:  34%|███▍      | 56/163 [01:06<01:53,  1.06s/it, loss=3.0275, batch_acc=0.1875, running_acc=0.1841, grad=10.0715]Training epoch 2:  34%|███▍      | 56/163 [01:06<01:53,  1.06s/it, loss=2.8812, batch_acc=0.2812, running_acc=0.1858, grad=7.2806] Training epoch 2:  35%|███▍      | 57/163 [01:07<01:46,  1.01s/it, loss=2.8812, batch_acc=0.2812, running_acc=0.1858, grad=7.2806]Training epoch 2:  35%|███▍      | 57/163 [01:07<01:46,  1.01s/it, loss=3.2065, batch_acc=0.1875, running_acc=0.1859, grad=9.2887]Training epoch 2:  36%|███▌      | 58/163 [01:08<02:04,  1.18s/it, loss=3.2065, batch_acc=0.1875, running_acc=0.1859, grad=9.2887]Training epoch 2:  36%|███▌      | 58/163 [01:08<02:04,  1.18s/it, loss=2.8974, batch_acc=0.2812, running_acc=0.1875, grad=8.3239]Training epoch 2:  36%|███▌      | 59/163 [01:09<01:53,  1.09s/it, loss=2.8974, batch_acc=0.2812, running_acc=0.1875, grad=8.3239]Training epoch 2:  36%|███▌      | 59/163 [01:09<01:53,  1.09s/it, loss=3.1842, batch_acc=0.2188, running_acc=0.1880, grad=12.5318]Training epoch 2:  37%|███▋      | 60/163 [01:10<01:45,  1.03s/it, loss=3.1842, batch_acc=0.2188, running_acc=0.1880, grad=12.5318]Training epoch 2:  37%|███▋      | 60/163 [01:10<01:45,  1.03s/it, loss=2.8100, batch_acc=0.1562, running_acc=0.1875, grad=10.2298]Training epoch 2:  37%|███▋      | 61/163 [01:11<01:40,  1.02it/s, loss=2.8100, batch_acc=0.1562, running_acc=0.1875, grad=10.2298]Training epoch 2:  37%|███▋      | 61/163 [01:11<01:40,  1.02it/s, loss=2.7416, batch_acc=0.4375, running_acc=0.1916, grad=8.9640] Training epoch 2:  38%|███▊      | 62/163 [01:13<02:00,  1.19s/it, loss=2.7416, batch_acc=0.4375, running_acc=0.1916, grad=8.9640]Training epoch 2:  38%|███▊      | 62/163 [01:13<02:00,  1.19s/it, loss=3.0719, batch_acc=0.1562, running_acc=0.1910, grad=13.2706]Training epoch 2:  39%|███▊      | 63/163 [01:14<01:49,  1.10s/it, loss=3.0719, batch_acc=0.1562, running_acc=0.1910, grad=13.2706]Training epoch 2:  39%|███▊      | 63/163 [01:14<01:49,  1.10s/it, loss=2.9838, batch_acc=0.1875, running_acc=0.1910, grad=11.6475]Training epoch 2:  39%|███▉      | 64/163 [01:15<01:42,  1.03s/it, loss=2.9838, batch_acc=0.1875, running_acc=0.1910, grad=11.6475]Training epoch 2:  39%|███▉      | 64/163 [01:15<01:42,  1.03s/it, loss=3.0964, batch_acc=0.1875, running_acc=0.1909, grad=9.1451] Training epoch 2:  40%|███▉      | 65/163 [01:15<01:36,  1.01it/s, loss=3.0964, batch_acc=0.1875, running_acc=0.1909, grad=9.1451]Training epoch 2:  40%|███▉      | 65/163 [01:15<01:36,  1.01it/s, loss=3.1387, batch_acc=0.2188, running_acc=0.1913, grad=8.7022]Training epoch 2:  40%|████      | 66/163 [01:17<01:47,  1.11s/it, loss=3.1387, batch_acc=0.2188, running_acc=0.1913, grad=8.7022]Training epoch 2:  40%|████      | 66/163 [01:17<01:47,  1.11s/it, loss=3.0281, batch_acc=0.2812, running_acc=0.1927, grad=8.1033]Training epoch 2:  41%|████      | 67/163 [01:18<01:40,  1.04s/it, loss=3.0281, batch_acc=0.2812, running_acc=0.1927, grad=8.1033]Training epoch 2:  41%|████      | 67/163 [01:18<01:40,  1.04s/it, loss=3.2298, batch_acc=0.1562, running_acc=0.1922, grad=9.7743]Training epoch 2:  42%|████▏     | 68/163 [01:19<01:34,  1.01it/s, loss=3.2298, batch_acc=0.1562, running_acc=0.1922, grad=9.7743]Training epoch 2:  42%|████▏     | 68/163 [01:19<01:34,  1.01it/s, loss=3.2564, batch_acc=0.1875, running_acc=0.1921, grad=9.1010]Training epoch 2:  42%|████▏     | 69/163 [01:19<01:30,  1.04it/s, loss=3.2564, batch_acc=0.1875, running_acc=0.1921, grad=9.1010]Training epoch 2:  42%|████▏     | 69/163 [01:19<01:30,  1.04it/s, loss=3.0114, batch_acc=0.2188, running_acc=0.1925, grad=8.3755]Training epoch 2:  43%|████▎     | 70/163 [01:20<01:26,  1.07it/s, loss=3.0114, batch_acc=0.2188, running_acc=0.1925, grad=8.3755]Training epoch 2:  43%|████▎     | 70/163 [01:20<01:26,  1.07it/s, loss=3.2890, batch_acc=0.1562, running_acc=0.1920, grad=8.7356]Training epoch 2:  44%|████▎     | 71/163 [01:21<01:24,  1.09it/s, loss=3.2890, batch_acc=0.1562, running_acc=0.1920, grad=8.7356]Training epoch 2:  44%|████▎     | 71/163 [01:21<01:24,  1.09it/s, loss=3.0124, batch_acc=0.2500, running_acc=0.1928, grad=8.0167]Training epoch 2:  44%|████▍     | 72/163 [01:22<01:22,  1.10it/s, loss=3.0124, batch_acc=0.2500, running_acc=0.1928, grad=8.0167]Training epoch 2:  44%|████▍     | 72/163 [01:22<01:22,  1.10it/s, loss=3.1474, batch_acc=0.2188, running_acc=0.1931, grad=7.7127]Training epoch 2:  45%|████▍     | 73/163 [01:23<01:20,  1.11it/s, loss=3.1474, batch_acc=0.2188, running_acc=0.1931, grad=7.7127]Training epoch 2:  45%|████▍     | 73/163 [01:23<01:20,  1.11it/s, loss=2.9549, batch_acc=0.1875, running_acc=0.1931, grad=7.4981]Training epoch 2:  45%|████▌     | 74/163 [01:25<01:40,  1.13s/it, loss=2.9549, batch_acc=0.1875, running_acc=0.1931, grad=7.4981]Training epoch 2:  45%|████▌     | 74/163 [01:25<01:40,  1.13s/it, loss=3.1420, batch_acc=0.1562, running_acc=0.1926, grad=9.8869]Training epoch 2:  46%|████▌     | 75/163 [01:25<01:32,  1.05s/it, loss=3.1420, batch_acc=0.1562, running_acc=0.1926, grad=9.8869]Training epoch 2:  46%|████▌     | 75/163 [01:25<01:32,  1.05s/it, loss=3.3857, batch_acc=0.0625, running_acc=0.1908, grad=9.2804]Training epoch 2:  47%|████▋     | 76/163 [01:26<01:27,  1.00s/it, loss=3.3857, batch_acc=0.0625, running_acc=0.1908, grad=9.2804]Training epoch 2:  47%|████▋     | 76/163 [01:26<01:27,  1.00s/it, loss=2.8154, batch_acc=0.3125, running_acc=0.1924, grad=6.7276]Training epoch 2:  47%|████▋     | 77/163 [01:27<01:22,  1.04it/s, loss=2.8154, batch_acc=0.3125, running_acc=0.1924, grad=6.7276]Training epoch 2:  47%|████▋     | 77/163 [01:27<01:22,  1.04it/s, loss=3.0103, batch_acc=0.2188, running_acc=0.1928, grad=12.1158]Training epoch 2:  48%|████▊     | 78/163 [01:29<01:32,  1.09s/it, loss=3.0103, batch_acc=0.2188, running_acc=0.1928, grad=12.1158]Training epoch 2:  48%|████▊     | 78/163 [01:29<01:32,  1.09s/it, loss=2.9157, batch_acc=0.2812, running_acc=0.1939, grad=9.3844] Training epoch 2:  48%|████▊     | 79/163 [01:30<01:26,  1.03s/it, loss=2.9157, batch_acc=0.2812, running_acc=0.1939, grad=9.3844]Training epoch 2:  48%|████▊     | 79/163 [01:30<01:26,  1.03s/it, loss=2.8244, batch_acc=0.2500, running_acc=0.1946, grad=10.3032]Training epoch 2:  49%|████▉     | 80/163 [01:30<01:21,  1.02it/s, loss=2.8244, batch_acc=0.2500, running_acc=0.1946, grad=10.3032]Training epoch 2:  49%|████▉     | 80/163 [01:30<01:21,  1.02it/s, loss=3.0003, batch_acc=0.2812, running_acc=0.1957, grad=8.9529] Training epoch 2:  50%|████▉     | 81/163 [01:31<01:17,  1.05it/s, loss=3.0003, batch_acc=0.2812, running_acc=0.1957, grad=8.9529]Training epoch 2:  50%|████▉     | 81/163 [01:31<01:17,  1.05it/s, loss=3.0387, batch_acc=0.2812, running_acc=0.1968, grad=10.7616]Training epoch 2:  50%|█████     | 82/163 [01:33<01:33,  1.16s/it, loss=3.0387, batch_acc=0.2812, running_acc=0.1968, grad=10.7616]Training epoch 2:  50%|█████     | 82/163 [01:33<01:33,  1.16s/it, loss=3.0463, batch_acc=0.1562, running_acc=0.1963, grad=9.2228] Training epoch 2:  51%|█████     | 83/163 [01:34<01:26,  1.08s/it, loss=3.0463, batch_acc=0.1562, running_acc=0.1963, grad=9.2228]Training epoch 2:  51%|█████     | 83/163 [01:34<01:26,  1.08s/it, loss=2.7461, batch_acc=0.3125, running_acc=0.1977, grad=9.4029]Training epoch 2:  52%|█████▏    | 84/163 [01:35<01:20,  1.02s/it, loss=2.7461, batch_acc=0.3125, running_acc=0.1977, grad=9.4029]Training epoch 2:  52%|█████▏    | 84/163 [01:35<01:20,  1.02s/it, loss=2.8317, batch_acc=0.3438, running_acc=0.1994, grad=7.4040]Training epoch 2:  52%|█████▏    | 85/163 [01:36<01:16,  1.02it/s, loss=2.8317, batch_acc=0.3438, running_acc=0.1994, grad=7.4040]Training epoch 2:  52%|█████▏    | 85/163 [01:36<01:16,  1.02it/s, loss=2.9804, batch_acc=0.2188, running_acc=0.1996, grad=8.5179]Training epoch 2:  53%|█████▎    | 86/163 [01:38<01:43,  1.35s/it, loss=2.9804, batch_acc=0.2188, running_acc=0.1996, grad=8.5179]Training epoch 2:  53%|█████▎    | 86/163 [01:38<01:43,  1.35s/it, loss=3.1380, batch_acc=0.1875, running_acc=0.1995, grad=8.8858]Training epoch 2:  53%|█████▎    | 87/163 [01:39<01:31,  1.21s/it, loss=3.1380, batch_acc=0.1875, running_acc=0.1995, grad=8.8858]Training epoch 2:  53%|█████▎    | 87/163 [01:39<01:31,  1.21s/it, loss=3.0078, batch_acc=0.2500, running_acc=0.2001, grad=11.7471]Training epoch 2:  54%|█████▍    | 88/163 [01:40<01:23,  1.11s/it, loss=3.0078, batch_acc=0.2500, running_acc=0.2001, grad=11.7471]Training epoch 2:  54%|█████▍    | 88/163 [01:40<01:23,  1.11s/it, loss=2.6981, batch_acc=0.2812, running_acc=0.2010, grad=8.7176] Training epoch 2:  55%|█████▍    | 89/163 [01:40<01:17,  1.04s/it, loss=2.6981, batch_acc=0.2812, running_acc=0.2010, grad=8.7176]Training epoch 2:  55%|█████▍    | 89/163 [01:40<01:17,  1.04s/it, loss=2.7720, batch_acc=0.2812, running_acc=0.2019, grad=9.6105]Training epoch 2:  55%|█████▌    | 90/163 [01:42<01:33,  1.28s/it, loss=2.7720, batch_acc=0.2812, running_acc=0.2019, grad=9.6105]Training epoch 2:  55%|█████▌    | 90/163 [01:42<01:33,  1.28s/it, loss=2.7153, batch_acc=0.4062, running_acc=0.2042, grad=9.1159]Training epoch 2:  56%|█████▌    | 91/163 [01:43<01:23,  1.16s/it, loss=2.7153, batch_acc=0.4062, running_acc=0.2042, grad=9.1159]Training epoch 2:  56%|█████▌    | 91/163 [01:43<01:23,  1.16s/it, loss=2.9668, batch_acc=0.2188, running_acc=0.2043, grad=8.7474]Training epoch 2:  56%|█████▋    | 92/163 [01:44<01:16,  1.07s/it, loss=2.9668, batch_acc=0.2188, running_acc=0.2043, grad=8.7474]Training epoch 2:  56%|█████▋    | 92/163 [01:44<01:16,  1.07s/it, loss=3.1861, batch_acc=0.1562, running_acc=0.2038, grad=8.3307]Training epoch 2:  57%|█████▋    | 93/163 [01:45<01:11,  1.01s/it, loss=3.1861, batch_acc=0.1562, running_acc=0.2038, grad=8.3307]Training epoch 2:  57%|█████▋    | 93/163 [01:45<01:11,  1.01s/it, loss=2.7364, batch_acc=0.3750, running_acc=0.2056, grad=8.0971]Training epoch 2:  58%|█████▊    | 94/163 [01:47<01:29,  1.30s/it, loss=2.7364, batch_acc=0.3750, running_acc=0.2056, grad=8.0971]Training epoch 2:  58%|█████▊    | 94/163 [01:47<01:29,  1.30s/it, loss=2.8165, batch_acc=0.2188, running_acc=0.2058, grad=10.9234]Training epoch 2:  58%|█████▊    | 95/163 [01:48<01:20,  1.18s/it, loss=2.8165, batch_acc=0.2188, running_acc=0.2058, grad=10.9234]Training epoch 2:  58%|█████▊    | 95/163 [01:48<01:20,  1.18s/it, loss=3.2011, batch_acc=0.1875, running_acc=0.2056, grad=9.5190] Training epoch 2:  59%|█████▉    | 96/163 [01:49<01:12,  1.09s/it, loss=3.2011, batch_acc=0.1875, running_acc=0.2056, grad=9.5190]Training epoch 2:  59%|█████▉    | 96/163 [01:49<01:12,  1.09s/it, loss=2.9124, batch_acc=0.2500, running_acc=0.2061, grad=9.3317]Training epoch 2:  60%|█████▉    | 97/163 [01:49<01:07,  1.03s/it, loss=2.9124, batch_acc=0.2500, running_acc=0.2061, grad=9.3317]Training epoch 2:  60%|█████▉    | 97/163 [01:49<01:07,  1.03s/it, loss=2.8398, batch_acc=0.3125, running_acc=0.2072, grad=11.2194]Training epoch 2:  60%|██████    | 98/163 [01:51<01:11,  1.09s/it, loss=2.8398, batch_acc=0.3125, running_acc=0.2072, grad=11.2194]Training epoch 2:  60%|██████    | 98/163 [01:51<01:11,  1.09s/it, loss=2.8291, batch_acc=0.3125, running_acc=0.2082, grad=7.8487] Training epoch 2:  61%|██████    | 99/163 [01:52<01:05,  1.03s/it, loss=2.8291, batch_acc=0.3125, running_acc=0.2082, grad=7.8487]Training epoch 2:  61%|██████    | 99/163 [01:52<01:05,  1.03s/it, loss=3.2956, batch_acc=0.2188, running_acc=0.2083, grad=8.3266]Training epoch 2:  61%|██████▏   | 100/163 [01:52<01:01,  1.02it/s, loss=3.2956, batch_acc=0.2188, running_acc=0.2083, grad=8.3266]Training epoch 2:  61%|██████▏   | 100/163 [01:52<01:01,  1.02it/s, loss=2.8960, batch_acc=0.2500, running_acc=0.2087, grad=9.4916]Training epoch 2:  62%|██████▏   | 101/163 [01:53<00:59,  1.05it/s, loss=2.8960, batch_acc=0.2500, running_acc=0.2087, grad=9.4916]Training epoch 2:  62%|██████▏   | 101/163 [01:53<00:59,  1.05it/s, loss=3.1596, batch_acc=0.2188, running_acc=0.2088, grad=10.7483]Training epoch 2:  63%|██████▎   | 102/163 [01:55<01:10,  1.16s/it, loss=3.1596, batch_acc=0.2188, running_acc=0.2088, grad=10.7483]Training epoch 2:  63%|██████▎   | 102/163 [01:55<01:10,  1.16s/it, loss=2.4923, batch_acc=0.3438, running_acc=0.2102, grad=10.9853]Training epoch 2:  63%|██████▎   | 103/163 [01:56<01:04,  1.08s/it, loss=2.4923, batch_acc=0.3438, running_acc=0.2102, grad=10.9853]Training epoch 2:  63%|██████▎   | 103/163 [01:56<01:04,  1.08s/it, loss=2.8011, batch_acc=0.3438, running_acc=0.2115, grad=10.0672]Training epoch 2:  64%|██████▍   | 104/163 [01:57<00:59,  1.02s/it, loss=2.8011, batch_acc=0.3438, running_acc=0.2115, grad=10.0672]Training epoch 2:  64%|██████▍   | 104/163 [01:57<00:59,  1.02s/it, loss=3.0269, batch_acc=0.2812, running_acc=0.2121, grad=8.8334] Training epoch 2:  64%|██████▍   | 105/163 [01:58<00:56,  1.03it/s, loss=3.0269, batch_acc=0.2812, running_acc=0.2121, grad=8.8334]Training epoch 2:  64%|██████▍   | 105/163 [01:58<00:56,  1.03it/s, loss=2.9543, batch_acc=0.2812, running_acc=0.2128, grad=10.1750]Training epoch 2:  65%|██████▌   | 106/163 [01:59<00:56,  1.01it/s, loss=2.9543, batch_acc=0.2812, running_acc=0.2128, grad=10.1750]Training epoch 2:  65%|██████▌   | 106/163 [01:59<00:56,  1.01it/s, loss=3.1247, batch_acc=0.1875, running_acc=0.2126, grad=10.0148]Training epoch 2:  66%|██████▌   | 107/163 [02:00<00:53,  1.04it/s, loss=3.1247, batch_acc=0.1875, running_acc=0.2126, grad=10.0148]Training epoch 2:  66%|██████▌   | 107/163 [02:00<00:53,  1.04it/s, loss=2.6620, batch_acc=0.3750, running_acc=0.2141, grad=9.0712] Training epoch 2:  66%|██████▋   | 108/163 [02:00<00:51,  1.07it/s, loss=2.6620, batch_acc=0.3750, running_acc=0.2141, grad=9.0712]Training epoch 2:  66%|██████▋   | 108/163 [02:00<00:51,  1.07it/s, loss=3.3215, batch_acc=0.1562, running_acc=0.2135, grad=9.7402]Training epoch 2:  67%|██████▋   | 109/163 [02:01<00:49,  1.09it/s, loss=3.3215, batch_acc=0.1562, running_acc=0.2135, grad=9.7402]Training epoch 2:  67%|██████▋   | 109/163 [02:01<00:49,  1.09it/s, loss=2.6842, batch_acc=0.2812, running_acc=0.2142, grad=10.4093]Training epoch 2:  67%|██████▋   | 110/163 [02:02<00:52,  1.01it/s, loss=2.6842, batch_acc=0.2812, running_acc=0.2142, grad=10.4093]Training epoch 2:  67%|██████▋   | 110/163 [02:02<00:52,  1.01it/s, loss=3.2271, batch_acc=0.1562, running_acc=0.2136, grad=10.0225]Training epoch 2:  68%|██████▊   | 111/163 [02:03<00:49,  1.04it/s, loss=3.2271, batch_acc=0.1562, running_acc=0.2136, grad=10.0225]Training epoch 2:  68%|██████▊   | 111/163 [02:03<00:49,  1.04it/s, loss=2.8284, batch_acc=0.2500, running_acc=0.2140, grad=7.9771] Training epoch 2:  69%|██████▊   | 112/163 [02:04<00:47,  1.07it/s, loss=2.8284, batch_acc=0.2500, running_acc=0.2140, grad=7.9771]Training epoch 2:  69%|██████▊   | 112/163 [02:04<00:47,  1.07it/s, loss=2.8249, batch_acc=0.3750, running_acc=0.2154, grad=9.2138]Training epoch 2:  69%|██████▉   | 113/163 [02:05<00:45,  1.09it/s, loss=2.8249, batch_acc=0.3750, running_acc=0.2154, grad=9.2138]Training epoch 2:  69%|██████▉   | 113/163 [02:05<00:45,  1.09it/s, loss=3.0702, batch_acc=0.1250, running_acc=0.2146, grad=12.9812]Training epoch 2:  70%|██████▉   | 114/163 [02:07<01:00,  1.23s/it, loss=3.0702, batch_acc=0.1250, running_acc=0.2146, grad=12.9812]Training epoch 2:  70%|██████▉   | 114/163 [02:07<01:00,  1.23s/it, loss=2.7802, batch_acc=0.3125, running_acc=0.2155, grad=10.9913]Training epoch 2:  71%|███████   | 115/163 [02:08<00:53,  1.12s/it, loss=2.7802, batch_acc=0.3125, running_acc=0.2155, grad=10.9913]Training epoch 2:  71%|███████   | 115/163 [02:08<00:53,  1.12s/it, loss=3.0948, batch_acc=0.3125, running_acc=0.2163, grad=10.7248]Training epoch 2:  71%|███████   | 116/163 [02:09<00:49,  1.05s/it, loss=3.0948, batch_acc=0.3125, running_acc=0.2163, grad=10.7248]Training epoch 2:  71%|███████   | 116/163 [02:09<00:49,  1.05s/it, loss=2.6221, batch_acc=0.2812, running_acc=0.2169, grad=7.8206] Training epoch 2:  72%|███████▏  | 117/163 [02:10<00:46,  1.00s/it, loss=2.6221, batch_acc=0.2812, running_acc=0.2169, grad=7.8206]Training epoch 2:  72%|███████▏  | 117/163 [02:10<00:46,  1.00s/it, loss=2.8018, batch_acc=0.3125, running_acc=0.2177, grad=7.7969]Training epoch 2:  72%|███████▏  | 118/163 [02:12<00:57,  1.28s/it, loss=2.8018, batch_acc=0.3125, running_acc=0.2177, grad=7.7969]Training epoch 2:  72%|███████▏  | 118/163 [02:12<00:57,  1.28s/it, loss=2.9420, batch_acc=0.0625, running_acc=0.2164, grad=9.9978]Training epoch 2:  73%|███████▎  | 119/163 [02:13<00:50,  1.16s/it, loss=2.9420, batch_acc=0.0625, running_acc=0.2164, grad=9.9978]Training epoch 2:  73%|███████▎  | 119/163 [02:13<00:50,  1.16s/it, loss=2.8447, batch_acc=0.2812, running_acc=0.2169, grad=9.5592]Training epoch 2:  74%|███████▎  | 120/163 [02:13<00:46,  1.07s/it, loss=2.8447, batch_acc=0.2812, running_acc=0.2169, grad=9.5592]Training epoch 2:  74%|███████▎  | 120/163 [02:13<00:46,  1.07s/it, loss=3.0653, batch_acc=0.2188, running_acc=0.2169, grad=9.2274]Training epoch 2:  74%|███████▍  | 121/163 [02:14<00:42,  1.02s/it, loss=3.0653, batch_acc=0.2188, running_acc=0.2169, grad=9.2274]Training epoch 2:  74%|███████▍  | 121/163 [02:14<00:42,  1.02s/it, loss=2.9567, batch_acc=0.2812, running_acc=0.2175, grad=10.4605]Training epoch 2:  75%|███████▍  | 122/163 [02:16<00:48,  1.19s/it, loss=2.9567, batch_acc=0.2812, running_acc=0.2175, grad=10.4605]Training epoch 2:  75%|███████▍  | 122/163 [02:16<00:48,  1.19s/it, loss=2.7411, batch_acc=0.3438, running_acc=0.2185, grad=9.1488] Training epoch 2:  75%|███████▌  | 123/163 [02:17<00:43,  1.10s/it, loss=2.7411, batch_acc=0.3438, running_acc=0.2185, grad=9.1488]Training epoch 2:  75%|███████▌  | 123/163 [02:17<00:43,  1.10s/it, loss=2.7685, batch_acc=0.3125, running_acc=0.2193, grad=9.9129]Training epoch 2:  76%|███████▌  | 124/163 [02:18<00:40,  1.03s/it, loss=2.7685, batch_acc=0.3125, running_acc=0.2193, grad=9.9129]Training epoch 2:  76%|███████▌  | 124/163 [02:18<00:40,  1.03s/it, loss=2.9424, batch_acc=0.2812, running_acc=0.2198, grad=9.0141]Training epoch 2:  77%|███████▋  | 125/163 [02:19<00:37,  1.01it/s, loss=2.9424, batch_acc=0.2812, running_acc=0.2198, grad=9.0141]Training epoch 2:  77%|███████▋  | 125/163 [02:19<00:37,  1.01it/s, loss=3.1442, batch_acc=0.1250, running_acc=0.2190, grad=8.3626]Training epoch 2:  77%|███████▋  | 126/163 [02:20<00:40,  1.11s/it, loss=3.1442, batch_acc=0.1250, running_acc=0.2190, grad=8.3626]Training epoch 2:  77%|███████▋  | 126/163 [02:20<00:40,  1.11s/it, loss=2.8478, batch_acc=0.3438, running_acc=0.2200, grad=12.7115]Training epoch 2:  78%|███████▊  | 127/163 [02:21<00:37,  1.04s/it, loss=2.8478, batch_acc=0.3438, running_acc=0.2200, grad=12.7115]Training epoch 2:  78%|███████▊  | 127/163 [02:21<00:37,  1.04s/it, loss=2.8200, batch_acc=0.3438, running_acc=0.2210, grad=7.5110] Training epoch 2:  79%|███████▊  | 128/163 [02:22<00:34,  1.01it/s, loss=2.8200, batch_acc=0.3438, running_acc=0.2210, grad=7.5110]Training epoch 2:  79%|███████▊  | 128/163 [02:22<00:34,  1.01it/s, loss=3.0142, batch_acc=0.1875, running_acc=0.2207, grad=10.0180]Training epoch 2:  79%|███████▉  | 129/163 [02:23<00:32,  1.05it/s, loss=3.0142, batch_acc=0.1875, running_acc=0.2207, grad=10.0180]Training epoch 2:  79%|███████▉  | 129/163 [02:23<00:32,  1.05it/s, loss=2.7261, batch_acc=0.3438, running_acc=0.2217, grad=9.6457] Training epoch 2:  80%|███████▉  | 130/163 [02:25<00:43,  1.32s/it, loss=2.7261, batch_acc=0.3438, running_acc=0.2217, grad=9.6457]Training epoch 2:  80%|███████▉  | 130/163 [02:25<00:43,  1.32s/it, loss=3.0596, batch_acc=0.2500, running_acc=0.2219, grad=9.3198]Training epoch 2:  80%|████████  | 131/163 [02:26<00:37,  1.19s/it, loss=3.0596, batch_acc=0.2500, running_acc=0.2219, grad=9.3198]Training epoch 2:  80%|████████  | 131/163 [02:26<00:37,  1.19s/it, loss=2.9296, batch_acc=0.2500, running_acc=0.2221, grad=16.3245]Training epoch 2:  81%|████████  | 132/163 [02:26<00:33,  1.10s/it, loss=2.9296, batch_acc=0.2500, running_acc=0.2221, grad=16.3245]Training epoch 2:  81%|████████  | 132/163 [02:26<00:33,  1.10s/it, loss=3.0146, batch_acc=0.3125, running_acc=0.2228, grad=6.9131] Training epoch 2:  82%|████████▏ | 133/163 [02:27<00:30,  1.03s/it, loss=3.0146, batch_acc=0.3125, running_acc=0.2228, grad=6.9131]Training epoch 2:  82%|████████▏ | 133/163 [02:27<00:30,  1.03s/it, loss=2.9646, batch_acc=0.2500, running_acc=0.2230, grad=11.5260]Training epoch 2:  82%|████████▏ | 134/163 [02:29<00:30,  1.07s/it, loss=2.9646, batch_acc=0.2500, running_acc=0.2230, grad=11.5260]Training epoch 2:  82%|████████▏ | 134/163 [02:29<00:30,  1.07s/it, loss=2.6481, batch_acc=0.3750, running_acc=0.2241, grad=8.6087] Training epoch 2:  83%|████████▎ | 135/163 [02:29<00:28,  1.01s/it, loss=2.6481, batch_acc=0.3750, running_acc=0.2241, grad=8.6087]Training epoch 2:  83%|████████▎ | 135/163 [02:29<00:28,  1.01s/it, loss=2.8869, batch_acc=0.3125, running_acc=0.2248, grad=9.6342]Training epoch 2:  83%|████████▎ | 136/163 [02:30<00:26,  1.03it/s, loss=2.8869, batch_acc=0.3125, running_acc=0.2248, grad=9.6342]Training epoch 2:  83%|████████▎ | 136/163 [02:30<00:26,  1.03it/s, loss=2.7688, batch_acc=0.2188, running_acc=0.2247, grad=9.5853]Training epoch 2:  84%|████████▍ | 137/163 [02:31<00:24,  1.06it/s, loss=2.7688, batch_acc=0.2188, running_acc=0.2247, grad=9.5853]Training epoch 2:  84%|████████▍ | 137/163 [02:31<00:24,  1.06it/s, loss=2.8947, batch_acc=0.1562, running_acc=0.2242, grad=8.7669]Training epoch 2:  85%|████████▍ | 138/163 [02:33<00:27,  1.08s/it, loss=2.8947, batch_acc=0.1562, running_acc=0.2242, grad=8.7669]Training epoch 2:  85%|████████▍ | 138/163 [02:33<00:27,  1.08s/it, loss=2.8923, batch_acc=0.2188, running_acc=0.2242, grad=10.0192]Training epoch 2:  85%|████████▌ | 139/163 [02:33<00:24,  1.02s/it, loss=2.8923, batch_acc=0.2188, running_acc=0.2242, grad=10.0192]Training epoch 2:  85%|████████▌ | 139/163 [02:33<00:24,  1.02s/it, loss=2.9923, batch_acc=0.2188, running_acc=0.2241, grad=10.1031]Training epoch 2:  86%|████████▌ | 140/163 [02:34<00:22,  1.02it/s, loss=2.9923, batch_acc=0.2188, running_acc=0.2241, grad=10.1031]Training epoch 2:  86%|████████▌ | 140/163 [02:34<00:22,  1.02it/s, loss=2.5969, batch_acc=0.2500, running_acc=0.2243, grad=8.8918] Training epoch 2:  87%|████████▋ | 141/163 [02:35<00:20,  1.05it/s, loss=2.5969, batch_acc=0.2500, running_acc=0.2243, grad=8.8918]Training epoch 2:  87%|████████▋ | 141/163 [02:35<00:20,  1.05it/s, loss=2.8784, batch_acc=0.1875, running_acc=0.2241, grad=9.8005]Training epoch 2:  87%|████████▋ | 142/163 [02:37<00:25,  1.20s/it, loss=2.8784, batch_acc=0.1875, running_acc=0.2241, grad=9.8005]Training epoch 2:  87%|████████▋ | 142/163 [02:37<00:25,  1.20s/it, loss=3.0525, batch_acc=0.2188, running_acc=0.2240, grad=8.5392]Training epoch 2:  88%|████████▊ | 143/163 [02:38<00:22,  1.10s/it, loss=3.0525, batch_acc=0.2188, running_acc=0.2240, grad=8.5392]Training epoch 2:  88%|████████▊ | 143/163 [02:38<00:22,  1.10s/it, loss=2.7788, batch_acc=0.2188, running_acc=0.2240, grad=8.5756]Training epoch 2:  88%|████████▊ | 144/163 [02:39<00:19,  1.03s/it, loss=2.7788, batch_acc=0.2188, running_acc=0.2240, grad=8.5756]Training epoch 2:  88%|████████▊ | 144/163 [02:39<00:19,  1.03s/it, loss=2.7834, batch_acc=0.2188, running_acc=0.2240, grad=10.1774]Training epoch 2:  89%|████████▉ | 145/163 [02:40<00:17,  1.01it/s, loss=2.7834, batch_acc=0.2188, running_acc=0.2240, grad=10.1774]Training epoch 2:  89%|████████▉ | 145/163 [02:40<00:17,  1.01it/s, loss=2.8920, batch_acc=0.1875, running_acc=0.2237, grad=8.5553] Training epoch 2:  90%|████████▉ | 146/163 [02:41<00:16,  1.03it/s, loss=2.8920, batch_acc=0.1875, running_acc=0.2237, grad=8.5553]Training epoch 2:  90%|████████▉ | 146/163 [02:41<00:16,  1.03it/s, loss=2.9863, batch_acc=0.2188, running_acc=0.2237, grad=7.8214]Training epoch 2:  90%|█████████ | 147/163 [02:41<00:15,  1.06it/s, loss=2.9863, batch_acc=0.2188, running_acc=0.2237, grad=7.8214]Training epoch 2:  90%|█████████ | 147/163 [02:41<00:15,  1.06it/s, loss=2.6820, batch_acc=0.2188, running_acc=0.2236, grad=11.6906]Training epoch 2:  91%|█████████ | 148/163 [02:42<00:13,  1.08it/s, loss=2.6820, batch_acc=0.2188, running_acc=0.2236, grad=11.6906]Training epoch 2:  91%|█████████ | 148/163 [02:42<00:13,  1.08it/s, loss=2.8946, batch_acc=0.2500, running_acc=0.2238, grad=8.3537] Training epoch 2:  91%|█████████▏| 149/163 [02:43<00:12,  1.10it/s, loss=2.8946, batch_acc=0.2500, running_acc=0.2238, grad=8.3537]Training epoch 2:  91%|█████████▏| 149/163 [02:43<00:12,  1.10it/s, loss=2.9019, batch_acc=0.3438, running_acc=0.2246, grad=14.1156]Training epoch 2:  92%|█████████▏| 150/163 [02:44<00:12,  1.02it/s, loss=2.9019, batch_acc=0.3438, running_acc=0.2246, grad=14.1156]Training epoch 2:  92%|█████████▏| 150/163 [02:44<00:12,  1.02it/s, loss=2.9115, batch_acc=0.1250, running_acc=0.2240, grad=8.0928] Training epoch 2:  93%|█████████▎| 151/163 [02:45<00:11,  1.05it/s, loss=2.9115, batch_acc=0.1250, running_acc=0.2240, grad=8.0928]Training epoch 2:  93%|█████████▎| 151/163 [02:45<00:11,  1.05it/s, loss=2.8025, batch_acc=0.3438, running_acc=0.2248, grad=9.3386]Training epoch 2:  93%|█████████▎| 152/163 [02:46<00:10,  1.08it/s, loss=2.8025, batch_acc=0.3438, running_acc=0.2248, grad=9.3386]Training epoch 2:  93%|█████████▎| 152/163 [02:46<00:10,  1.08it/s, loss=2.7979, batch_acc=0.3438, running_acc=0.2255, grad=8.7837]Training epoch 2:  94%|█████████▍| 153/163 [02:47<00:09,  1.09it/s, loss=2.7979, batch_acc=0.3438, running_acc=0.2255, grad=8.7837]Training epoch 2:  94%|█████████▍| 153/163 [02:47<00:09,  1.09it/s, loss=2.7786, batch_acc=0.2188, running_acc=0.2255, grad=8.1451]Training epoch 2:  94%|█████████▍| 154/163 [02:48<00:09,  1.08s/it, loss=2.7786, batch_acc=0.2188, running_acc=0.2255, grad=8.1451]Training epoch 2:  94%|█████████▍| 154/163 [02:48<00:09,  1.08s/it, loss=2.9139, batch_acc=0.2812, running_acc=0.2259, grad=11.8928]Training epoch 2:  95%|█████████▌| 155/163 [02:49<00:08,  1.02s/it, loss=2.9139, batch_acc=0.2812, running_acc=0.2259, grad=11.8928]Training epoch 2:  95%|█████████▌| 155/163 [02:49<00:08,  1.02s/it, loss=2.9036, batch_acc=0.1875, running_acc=0.2256, grad=12.6906]Training epoch 2:  96%|█████████▌| 156/163 [02:50<00:06,  1.02it/s, loss=2.9036, batch_acc=0.1875, running_acc=0.2256, grad=12.6906]Training epoch 2:  96%|█████████▌| 156/163 [02:50<00:06,  1.02it/s, loss=2.7669, batch_acc=0.3125, running_acc=0.2262, grad=11.9614]Training epoch 2:  96%|█████████▋| 157/163 [02:51<00:05,  1.05it/s, loss=2.7669, batch_acc=0.3125, running_acc=0.2262, grad=11.9614]Training epoch 2:  96%|█████████▋| 157/163 [02:51<00:05,  1.05it/s, loss=2.7360, batch_acc=0.2812, running_acc=0.2265, grad=10.7643]Training epoch 2:  97%|█████████▋| 158/163 [02:52<00:05,  1.07s/it, loss=2.7360, batch_acc=0.2812, running_acc=0.2265, grad=10.7643]Training epoch 2:  97%|█████████▋| 158/163 [02:52<00:05,  1.07s/it, loss=3.2230, batch_acc=0.1562, running_acc=0.2261, grad=9.6454] Training epoch 2:  98%|█████████▊| 159/163 [02:53<00:04,  1.01s/it, loss=3.2230, batch_acc=0.1562, running_acc=0.2261, grad=9.6454]Training epoch 2:  98%|█████████▊| 159/163 [02:53<00:04,  1.01s/it, loss=3.3184, batch_acc=0.1562, running_acc=0.2256, grad=12.4386]Training epoch 2:  98%|█████████▊| 160/163 [02:54<00:02,  1.03it/s, loss=3.3184, batch_acc=0.1562, running_acc=0.2256, grad=12.4386]Training epoch 2:  98%|█████████▊| 160/163 [02:54<00:02,  1.03it/s, loss=2.6688, batch_acc=0.2812, running_acc=0.2260, grad=9.7092] Training epoch 2:  99%|█████████▉| 161/163 [02:55<00:01,  1.06it/s, loss=2.6688, batch_acc=0.2812, running_acc=0.2260, grad=9.7092]Training epoch 2:  99%|█████████▉| 161/163 [02:55<00:01,  1.06it/s, loss=3.0217, batch_acc=0.1875, running_acc=0.2257, grad=10.4243]Training epoch 2:  99%|█████████▉| 162/163 [02:56<00:00,  1.09it/s, loss=3.0217, batch_acc=0.1875, running_acc=0.2257, grad=10.4243]Training epoch 2:  99%|█████████▉| 162/163 [02:56<00:00,  1.09it/s, loss=3.0432, batch_acc=0.2812, running_acc=0.2261, grad=8.0950] Training epoch 2: 100%|██████████| 163/163 [02:57<00:00,  1.19it/s, loss=3.0432, batch_acc=0.2812, running_acc=0.2261, grad=8.0950]Training epoch 2: 100%|██████████| 163/163 [02:57<00:00,  1.19it/s, loss=2.8404, batch_acc=0.1905, running_acc=0.2259, grad=11.8185]Training epoch 2: 100%|██████████| 163/163 [02:57<00:00,  1.09s/it, loss=2.8404, batch_acc=0.1905, running_acc=0.2259, grad=11.8185]
Evaluation epoch 2:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 2:   4%|▎         | 1/28 [00:04<02:11,  4.86s/it]Evaluation epoch 2:   4%|▎         | 1/28 [00:04<02:11,  4.86s/it, loss=2.3268, batch_acc=0.3750, running_acc=0.3750]Evaluation epoch 2:   7%|▋         | 2/28 [00:05<00:56,  2.15s/it, loss=2.3268, batch_acc=0.3750, running_acc=0.3750]Evaluation epoch 2:   7%|▋         | 2/28 [00:05<00:56,  2.15s/it, loss=2.4830, batch_acc=0.4688, running_acc=0.4219]Evaluation epoch 2:  11%|█         | 3/28 [00:05<00:32,  1.29s/it, loss=2.4830, batch_acc=0.4688, running_acc=0.4219]Evaluation epoch 2:  11%|█         | 3/28 [00:05<00:32,  1.29s/it, loss=2.6054, batch_acc=0.1562, running_acc=0.3333]Evaluation epoch 2:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=2.6054, batch_acc=0.1562, running_acc=0.3333]Evaluation epoch 2:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=3.2971, batch_acc=0.0000, running_acc=0.2500]Evaluation epoch 2:  18%|█▊        | 5/28 [00:09<00:38,  1.68s/it, loss=3.2971, batch_acc=0.0000, running_acc=0.2500]Evaluation epoch 2:  18%|█▊        | 5/28 [00:09<00:38,  1.68s/it, loss=3.2503, batch_acc=0.0625, running_acc=0.2125]Evaluation epoch 2:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=3.2503, batch_acc=0.0625, running_acc=0.2125]Evaluation epoch 2:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=3.2055, batch_acc=0.0312, running_acc=0.1823]Evaluation epoch 2:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=3.2055, batch_acc=0.0312, running_acc=0.1823]Evaluation epoch 2:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=3.1190, batch_acc=0.1562, running_acc=0.1786]Evaluation epoch 2:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=3.1190, batch_acc=0.1562, running_acc=0.1786]Evaluation epoch 2:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=2.8260, batch_acc=0.1875, running_acc=0.1797]Evaluation epoch 2:  32%|███▏      | 9/28 [00:14<00:25,  1.32s/it, loss=2.8260, batch_acc=0.1875, running_acc=0.1797]Evaluation epoch 2:  32%|███▏      | 9/28 [00:14<00:25,  1.32s/it, loss=3.2018, batch_acc=0.1562, running_acc=0.1771]Evaluation epoch 2:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=3.2018, batch_acc=0.1562, running_acc=0.1771]Evaluation epoch 2:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=1.6357, batch_acc=0.7500, running_acc=0.2344]Evaluation epoch 2:  39%|███▉      | 11/28 [00:14<00:13,  1.30it/s, loss=1.6357, batch_acc=0.7500, running_acc=0.2344]Evaluation epoch 2:  39%|███▉      | 11/28 [00:14<00:13,  1.30it/s, loss=3.0675, batch_acc=0.3125, running_acc=0.2415]Evaluation epoch 2:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=3.0675, batch_acc=0.3125, running_acc=0.2415]Evaluation epoch 2:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=2.7447, batch_acc=0.3750, running_acc=0.2526]Evaluation epoch 2:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=2.7447, batch_acc=0.3750, running_acc=0.2526]Evaluation epoch 2:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=2.8675, batch_acc=0.3125, running_acc=0.2572]Evaluation epoch 2:  50%|█████     | 14/28 [00:20<00:16,  1.20s/it, loss=2.8675, batch_acc=0.3125, running_acc=0.2572]Evaluation epoch 2:  50%|█████     | 14/28 [00:20<00:16,  1.20s/it, loss=2.8001, batch_acc=0.4375, running_acc=0.2701]Evaluation epoch 2:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=2.8001, batch_acc=0.4375, running_acc=0.2701]Evaluation epoch 2:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=3.3950, batch_acc=0.0312, running_acc=0.2542]Evaluation epoch 2:  57%|█████▋    | 16/28 [00:23<00:17,  1.48s/it, loss=3.3950, batch_acc=0.0312, running_acc=0.2542]Evaluation epoch 2:  57%|█████▋    | 16/28 [00:23<00:17,  1.48s/it, loss=3.3401, batch_acc=0.0625, running_acc=0.2422]Evaluation epoch 2:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=3.3401, batch_acc=0.0625, running_acc=0.2422]Evaluation epoch 2:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=3.1369, batch_acc=0.1562, running_acc=0.2371]Evaluation epoch 2:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=3.1369, batch_acc=0.1562, running_acc=0.2371]Evaluation epoch 2:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=2.7811, batch_acc=0.2500, running_acc=0.2378]Evaluation epoch 2:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=2.7811, batch_acc=0.2500, running_acc=0.2378]Evaluation epoch 2:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=2.6634, batch_acc=0.3750, running_acc=0.2451]Evaluation epoch 2:  71%|███████▏  | 20/28 [00:27<00:10,  1.29s/it, loss=2.6634, batch_acc=0.3750, running_acc=0.2451]Evaluation epoch 2:  71%|███████▏  | 20/28 [00:27<00:10,  1.29s/it, loss=3.1256, batch_acc=0.2188, running_acc=0.2437]Evaluation epoch 2:  75%|███████▌  | 21/28 [00:27<00:06,  1.02it/s, loss=3.1256, batch_acc=0.2188, running_acc=0.2437]Evaluation epoch 2:  75%|███████▌  | 21/28 [00:27<00:06,  1.02it/s, loss=3.1281, batch_acc=0.0312, running_acc=0.2336]Evaluation epoch 2:  79%|███████▊  | 22/28 [00:27<00:04,  1.31it/s, loss=3.1281, batch_acc=0.0312, running_acc=0.2336]Evaluation epoch 2:  79%|███████▊  | 22/28 [00:27<00:04,  1.31it/s, loss=3.1929, batch_acc=0.1562, running_acc=0.2301]Evaluation epoch 2:  82%|████████▏ | 23/28 [00:28<00:03,  1.63it/s, loss=3.1929, batch_acc=0.1562, running_acc=0.2301]Evaluation epoch 2:  82%|████████▏ | 23/28 [00:28<00:03,  1.63it/s, loss=3.1372, batch_acc=0.1250, running_acc=0.2255]Evaluation epoch 2:  86%|████████▌ | 24/28 [00:33<00:07,  1.95s/it, loss=3.1372, batch_acc=0.1250, running_acc=0.2255]Evaluation epoch 2:  86%|████████▌ | 24/28 [00:33<00:07,  1.95s/it, loss=2.3582, batch_acc=0.4688, running_acc=0.2357]Evaluation epoch 2:  89%|████████▉ | 25/28 [00:33<00:04,  1.44s/it, loss=2.3582, batch_acc=0.4688, running_acc=0.2357]Evaluation epoch 2:  89%|████████▉ | 25/28 [00:33<00:04,  1.44s/it, loss=2.0492, batch_acc=0.5000, running_acc=0.2462]Evaluation epoch 2:  93%|█████████▎| 26/28 [00:33<00:02,  1.09s/it, loss=2.0492, batch_acc=0.5000, running_acc=0.2462]Evaluation epoch 2:  93%|█████████▎| 26/28 [00:33<00:02,  1.09s/it, loss=2.4545, batch_acc=0.4688, running_acc=0.2548]Evaluation epoch 2:  96%|█████████▋| 27/28 [00:34<00:00,  1.19it/s, loss=2.4545, batch_acc=0.4688, running_acc=0.2548]Evaluation epoch 2:  96%|█████████▋| 27/28 [00:34<00:00,  1.19it/s, loss=2.7037, batch_acc=0.3438, running_acc=0.2581]Evaluation epoch 2: 100%|██████████| 28/28 [00:34<00:00,  1.19it/s, loss=1.8531, batch_acc=0.6667, running_acc=0.2595]Evaluation epoch 2: 100%|██████████| 28/28 [00:34<00:00,  1.22s/it, loss=1.8531, batch_acc=0.6667, running_acc=0.2595]
Training epoch 3:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 3:   1%|          | 1/163 [00:06<16:46,  6.21s/it]Training epoch 3:   1%|          | 1/163 [00:06<16:46,  6.21s/it, loss=2.8916, batch_acc=0.2812, running_acc=0.2812, grad=10.9638]Training epoch 3:   1%|          | 2/163 [00:07<08:15,  3.08s/it, loss=2.8916, batch_acc=0.2812, running_acc=0.2812, grad=10.9638]Training epoch 3:   1%|          | 2/163 [00:07<08:15,  3.08s/it, loss=2.9254, batch_acc=0.1562, running_acc=0.2188, grad=9.6086] Training epoch 3:   2%|▏         | 3/163 [00:07<05:31,  2.07s/it, loss=2.9254, batch_acc=0.1562, running_acc=0.2188, grad=9.6086]Training epoch 3:   2%|▏         | 3/163 [00:07<05:31,  2.07s/it, loss=2.8777, batch_acc=0.2812, running_acc=0.2396, grad=13.4401]Training epoch 3:   2%|▏         | 4/163 [00:09<05:12,  1.97s/it, loss=2.8777, batch_acc=0.2812, running_acc=0.2396, grad=13.4401]Training epoch 3:   2%|▏         | 4/163 [00:09<05:12,  1.97s/it, loss=2.8671, batch_acc=0.2188, running_acc=0.2344, grad=8.2048] Training epoch 3:   3%|▎         | 5/163 [00:10<04:24,  1.68s/it, loss=2.8671, batch_acc=0.2188, running_acc=0.2344, grad=8.2048]Training epoch 3:   3%|▎         | 5/163 [00:10<04:24,  1.68s/it, loss=2.7733, batch_acc=0.3125, running_acc=0.2500, grad=9.4431]Training epoch 3:   4%|▎         | 6/163 [00:11<03:40,  1.40s/it, loss=2.7733, batch_acc=0.3125, running_acc=0.2500, grad=9.4431]Training epoch 3:   4%|▎         | 6/163 [00:11<03:40,  1.40s/it, loss=2.7524, batch_acc=0.2188, running_acc=0.2448, grad=9.0139]Training epoch 3:   4%|▍         | 7/163 [00:12<03:12,  1.23s/it, loss=2.7524, batch_acc=0.2188, running_acc=0.2448, grad=9.0139]Training epoch 3:   4%|▍         | 7/163 [00:12<03:12,  1.23s/it, loss=2.8414, batch_acc=0.3125, running_acc=0.2545, grad=11.0031]Training epoch 3:   5%|▍         | 8/163 [00:14<03:15,  1.26s/it, loss=2.8414, batch_acc=0.3125, running_acc=0.2545, grad=11.0031]Training epoch 3:   5%|▍         | 8/163 [00:14<03:15,  1.26s/it, loss=2.6985, batch_acc=0.3125, running_acc=0.2617, grad=10.3452]Training epoch 3:   6%|▌         | 9/163 [00:15<03:27,  1.35s/it, loss=2.6985, batch_acc=0.3125, running_acc=0.2617, grad=10.3452]Training epoch 3:   6%|▌         | 9/163 [00:15<03:27,  1.35s/it, loss=2.7762, batch_acc=0.3125, running_acc=0.2674, grad=9.8987] Training epoch 3:   6%|▌         | 10/163 [00:16<03:04,  1.20s/it, loss=2.7762, batch_acc=0.3125, running_acc=0.2674, grad=9.8987]Training epoch 3:   6%|▌         | 10/163 [00:16<03:04,  1.20s/it, loss=2.8506, batch_acc=0.3125, running_acc=0.2719, grad=8.5354]Training epoch 3:   7%|▋         | 11/163 [00:17<02:47,  1.10s/it, loss=2.8506, batch_acc=0.3125, running_acc=0.2719, grad=8.5354]Training epoch 3:   7%|▋         | 11/163 [00:17<02:47,  1.10s/it, loss=2.5009, batch_acc=0.3125, running_acc=0.2756, grad=9.5051]Training epoch 3:   7%|▋         | 12/163 [00:18<02:37,  1.04s/it, loss=2.5009, batch_acc=0.3125, running_acc=0.2756, grad=9.5051]Training epoch 3:   7%|▋         | 12/163 [00:18<02:37,  1.04s/it, loss=2.7255, batch_acc=0.2812, running_acc=0.2760, grad=11.6320]Training epoch 3:   8%|▊         | 13/163 [00:19<03:02,  1.22s/it, loss=2.7255, batch_acc=0.2812, running_acc=0.2760, grad=11.6320]Training epoch 3:   8%|▊         | 13/163 [00:19<03:02,  1.22s/it, loss=3.1193, batch_acc=0.1562, running_acc=0.2668, grad=11.4927]Training epoch 3:   9%|▊         | 14/163 [00:20<02:46,  1.12s/it, loss=3.1193, batch_acc=0.1562, running_acc=0.2668, grad=11.4927]Training epoch 3:   9%|▊         | 14/163 [00:20<02:46,  1.12s/it, loss=2.9820, batch_acc=0.2188, running_acc=0.2634, grad=8.0476] Training epoch 3:   9%|▉         | 15/163 [00:21<02:34,  1.05s/it, loss=2.9820, batch_acc=0.2188, running_acc=0.2634, grad=8.0476]Training epoch 3:   9%|▉         | 15/163 [00:21<02:34,  1.05s/it, loss=2.9274, batch_acc=0.0625, running_acc=0.2500, grad=10.6916]Training epoch 3:  10%|▉         | 16/163 [00:22<02:33,  1.05s/it, loss=2.9274, batch_acc=0.0625, running_acc=0.2500, grad=10.6916]Training epoch 3:  10%|▉         | 16/163 [00:22<02:33,  1.05s/it, loss=2.7831, batch_acc=0.3438, running_acc=0.2559, grad=12.1599]Training epoch 3:  10%|█         | 17/163 [00:23<02:38,  1.08s/it, loss=2.7831, batch_acc=0.3438, running_acc=0.2559, grad=12.1599]Training epoch 3:  10%|█         | 17/163 [00:23<02:38,  1.08s/it, loss=2.7761, batch_acc=0.3125, running_acc=0.2592, grad=7.6613] Training epoch 3:  11%|█         | 18/163 [00:24<02:28,  1.02s/it, loss=2.7761, batch_acc=0.3125, running_acc=0.2592, grad=7.6613]Training epoch 3:  11%|█         | 18/163 [00:24<02:28,  1.02s/it, loss=2.5771, batch_acc=0.2812, running_acc=0.2604, grad=7.5678]Training epoch 3:  12%|█▏        | 19/163 [00:25<02:21,  1.02it/s, loss=2.5771, batch_acc=0.2812, running_acc=0.2604, grad=7.5678]Training epoch 3:  12%|█▏        | 19/163 [00:25<02:21,  1.02it/s, loss=2.9451, batch_acc=0.2500, running_acc=0.2599, grad=10.0716]Training epoch 3:  12%|█▏        | 20/163 [00:27<03:21,  1.41s/it, loss=2.9451, batch_acc=0.2500, running_acc=0.2599, grad=10.0716]Training epoch 3:  12%|█▏        | 20/163 [00:27<03:21,  1.41s/it, loss=2.5849, batch_acc=0.3125, running_acc=0.2625, grad=9.4033] Training epoch 3:  13%|█▎        | 21/163 [00:28<02:57,  1.25s/it, loss=2.5849, batch_acc=0.3125, running_acc=0.2625, grad=9.4033]Training epoch 3:  13%|█▎        | 21/163 [00:28<02:57,  1.25s/it, loss=2.7889, batch_acc=0.2188, running_acc=0.2604, grad=10.0943]Training epoch 3:  13%|█▎        | 22/163 [00:29<02:40,  1.14s/it, loss=2.7889, batch_acc=0.2188, running_acc=0.2604, grad=10.0943]Training epoch 3:  13%|█▎        | 22/163 [00:29<02:40,  1.14s/it, loss=2.7367, batch_acc=0.3125, running_acc=0.2628, grad=9.6202] Training epoch 3:  14%|█▍        | 23/163 [00:30<02:28,  1.06s/it, loss=2.7367, batch_acc=0.3125, running_acc=0.2628, grad=9.6202]Training epoch 3:  14%|█▍        | 23/163 [00:30<02:28,  1.06s/it, loss=2.7498, batch_acc=0.2188, running_acc=0.2609, grad=8.5752]Training epoch 3:  15%|█▍        | 24/163 [00:31<02:38,  1.14s/it, loss=2.7498, batch_acc=0.2188, running_acc=0.2609, grad=8.5752]Training epoch 3:  15%|█▍        | 24/163 [00:31<02:38,  1.14s/it, loss=3.0790, batch_acc=0.1875, running_acc=0.2578, grad=11.1933]Training epoch 3:  15%|█▌        | 25/163 [00:32<02:26,  1.06s/it, loss=3.0790, batch_acc=0.1875, running_acc=0.2578, grad=11.1933]Training epoch 3:  15%|█▌        | 25/163 [00:32<02:26,  1.06s/it, loss=2.5483, batch_acc=0.4062, running_acc=0.2637, grad=14.8674]Training epoch 3:  16%|█▌        | 26/163 [00:33<02:17,  1.01s/it, loss=2.5483, batch_acc=0.4062, running_acc=0.2637, grad=14.8674]Training epoch 3:  16%|█▌        | 26/163 [00:33<02:17,  1.01s/it, loss=2.8890, batch_acc=0.1250, running_acc=0.2584, grad=9.7537] Training epoch 3:  17%|█▋        | 27/163 [00:34<02:11,  1.03it/s, loss=2.8890, batch_acc=0.1250, running_acc=0.2584, grad=9.7537]Training epoch 3:  17%|█▋        | 27/163 [00:34<02:11,  1.03it/s, loss=2.7187, batch_acc=0.2812, running_acc=0.2593, grad=8.7154]Training epoch 3:  17%|█▋        | 28/163 [00:36<02:54,  1.29s/it, loss=2.7187, batch_acc=0.2812, running_acc=0.2593, grad=8.7154]Training epoch 3:  17%|█▋        | 28/163 [00:36<02:54,  1.29s/it, loss=2.7894, batch_acc=0.3750, running_acc=0.2634, grad=8.7494]Training epoch 3:  18%|█▊        | 29/163 [00:37<02:36,  1.17s/it, loss=2.7894, batch_acc=0.3750, running_acc=0.2634, grad=8.7494]Training epoch 3:  18%|█▊        | 29/163 [00:37<02:36,  1.17s/it, loss=2.8981, batch_acc=0.1250, running_acc=0.2586, grad=14.3779]Training epoch 3:  18%|█▊        | 30/163 [00:38<02:23,  1.08s/it, loss=2.8981, batch_acc=0.1250, running_acc=0.2586, grad=14.3779]Training epoch 3:  18%|█▊        | 30/163 [00:38<02:23,  1.08s/it, loss=3.1799, batch_acc=0.1562, running_acc=0.2552, grad=14.7230]Training epoch 3:  19%|█▉        | 31/163 [00:39<02:14,  1.02s/it, loss=3.1799, batch_acc=0.1562, running_acc=0.2552, grad=14.7230]Training epoch 3:  19%|█▉        | 31/163 [00:39<02:14,  1.02s/it, loss=2.5976, batch_acc=0.5312, running_acc=0.2641, grad=8.4273] Training epoch 3:  20%|█▉        | 32/163 [00:41<02:43,  1.24s/it, loss=2.5976, batch_acc=0.5312, running_acc=0.2641, grad=8.4273]Training epoch 3:  20%|█▉        | 32/163 [00:41<02:43,  1.24s/it, loss=2.8794, batch_acc=0.2500, running_acc=0.2637, grad=9.8289]Training epoch 3:  20%|██        | 33/163 [00:41<02:27,  1.14s/it, loss=2.8794, batch_acc=0.2500, running_acc=0.2637, grad=9.8289]Training epoch 3:  20%|██        | 33/163 [00:41<02:27,  1.14s/it, loss=2.8148, batch_acc=0.3750, running_acc=0.2670, grad=10.3943]Training epoch 3:  21%|██        | 34/163 [00:42<02:16,  1.06s/it, loss=2.8148, batch_acc=0.3750, running_acc=0.2670, grad=10.3943]Training epoch 3:  21%|██        | 34/163 [00:42<02:16,  1.06s/it, loss=2.7747, batch_acc=0.2812, running_acc=0.2675, grad=11.7099]Training epoch 3:  21%|██▏       | 35/163 [00:43<02:08,  1.00s/it, loss=2.7747, batch_acc=0.2812, running_acc=0.2675, grad=11.7099]Training epoch 3:  21%|██▏       | 35/163 [00:43<02:08,  1.00s/it, loss=2.6446, batch_acc=0.2500, running_acc=0.2670, grad=10.1924]Training epoch 3:  22%|██▏       | 36/163 [00:45<02:30,  1.19s/it, loss=2.6446, batch_acc=0.2500, running_acc=0.2670, grad=10.1924]Training epoch 3:  22%|██▏       | 36/163 [00:45<02:30,  1.19s/it, loss=2.6081, batch_acc=0.3750, running_acc=0.2700, grad=8.3502] Training epoch 3:  23%|██▎       | 37/163 [00:46<02:18,  1.10s/it, loss=2.6081, batch_acc=0.3750, running_acc=0.2700, grad=8.3502]Training epoch 3:  23%|██▎       | 37/163 [00:46<02:18,  1.10s/it, loss=2.9859, batch_acc=0.3125, running_acc=0.2711, grad=11.4775]Training epoch 3:  23%|██▎       | 38/163 [00:47<02:08,  1.03s/it, loss=2.9859, batch_acc=0.3125, running_acc=0.2711, grad=11.4775]Training epoch 3:  23%|██▎       | 38/163 [00:47<02:08,  1.03s/it, loss=2.7497, batch_acc=0.2188, running_acc=0.2697, grad=9.0152] Training epoch 3:  24%|██▍       | 39/163 [00:47<02:02,  1.01it/s, loss=2.7497, batch_acc=0.2188, running_acc=0.2697, grad=9.0152]Training epoch 3:  24%|██▍       | 39/163 [00:47<02:02,  1.01it/s, loss=2.6253, batch_acc=0.2500, running_acc=0.2692, grad=7.5403]Training epoch 3:  25%|██▍       | 40/163 [00:50<02:41,  1.31s/it, loss=2.6253, batch_acc=0.2500, running_acc=0.2692, grad=7.5403]Training epoch 3:  25%|██▍       | 40/163 [00:50<02:41,  1.31s/it, loss=2.6657, batch_acc=0.3438, running_acc=0.2711, grad=9.8781]Training epoch 3:  25%|██▌       | 41/163 [00:50<02:24,  1.18s/it, loss=2.6657, batch_acc=0.3438, running_acc=0.2711, grad=9.8781]Training epoch 3:  25%|██▌       | 41/163 [00:50<02:24,  1.18s/it, loss=2.4777, batch_acc=0.4062, running_acc=0.2744, grad=9.8579]Training epoch 3:  26%|██▌       | 42/163 [00:51<02:12,  1.09s/it, loss=2.4777, batch_acc=0.4062, running_acc=0.2744, grad=9.8579]Training epoch 3:  26%|██▌       | 42/163 [00:51<02:12,  1.09s/it, loss=2.4873, batch_acc=0.4062, running_acc=0.2775, grad=10.2174]Training epoch 3:  26%|██▋       | 43/163 [00:52<02:03,  1.03s/it, loss=2.4873, batch_acc=0.4062, running_acc=0.2775, grad=10.2174]Training epoch 3:  26%|██▋       | 43/163 [00:52<02:03,  1.03s/it, loss=2.5592, batch_acc=0.3750, running_acc=0.2798, grad=9.3245] Training epoch 3:  27%|██▋       | 44/163 [00:54<02:20,  1.18s/it, loss=2.5592, batch_acc=0.3750, running_acc=0.2798, grad=9.3245]Training epoch 3:  27%|██▋       | 44/163 [00:54<02:20,  1.18s/it, loss=2.7233, batch_acc=0.3750, running_acc=0.2820, grad=11.5248]Training epoch 3:  28%|██▊       | 45/163 [00:55<02:08,  1.09s/it, loss=2.7233, batch_acc=0.3750, running_acc=0.2820, grad=11.5248]Training epoch 3:  28%|██▊       | 45/163 [00:55<02:08,  1.09s/it, loss=2.7496, batch_acc=0.3125, running_acc=0.2826, grad=10.0290]Training epoch 3:  28%|██▊       | 46/163 [00:55<02:00,  1.03s/it, loss=2.7496, batch_acc=0.3125, running_acc=0.2826, grad=10.0290]Training epoch 3:  28%|██▊       | 46/163 [00:55<02:00,  1.03s/it, loss=2.8720, batch_acc=0.3125, running_acc=0.2833, grad=9.2654] Training epoch 3:  29%|██▉       | 47/163 [00:56<01:53,  1.02it/s, loss=2.8720, batch_acc=0.3125, running_acc=0.2833, grad=9.2654]Training epoch 3:  29%|██▉       | 47/163 [00:56<01:53,  1.02it/s, loss=2.9309, batch_acc=0.2500, running_acc=0.2826, grad=9.5538]Training epoch 3:  29%|██▉       | 48/163 [00:58<02:14,  1.17s/it, loss=2.9309, batch_acc=0.2500, running_acc=0.2826, grad=9.5538]Training epoch 3:  29%|██▉       | 48/163 [00:58<02:14,  1.17s/it, loss=2.4532, batch_acc=0.3750, running_acc=0.2845, grad=8.7588]Training epoch 3:  30%|███       | 49/163 [00:59<02:03,  1.08s/it, loss=2.4532, batch_acc=0.3750, running_acc=0.2845, grad=8.7588]Training epoch 3:  30%|███       | 49/163 [00:59<02:03,  1.08s/it, loss=2.7779, batch_acc=0.3438, running_acc=0.2857, grad=10.6881]Training epoch 3:  31%|███       | 50/163 [01:00<01:55,  1.02s/it, loss=2.7779, batch_acc=0.3438, running_acc=0.2857, grad=10.6881]Training epoch 3:  31%|███       | 50/163 [01:00<01:55,  1.02s/it, loss=2.6842, batch_acc=0.3125, running_acc=0.2863, grad=11.4010]Training epoch 3:  31%|███▏      | 51/163 [01:01<01:49,  1.02it/s, loss=2.6842, batch_acc=0.3125, running_acc=0.2863, grad=11.4010]Training epoch 3:  31%|███▏      | 51/163 [01:01<01:49,  1.02it/s, loss=2.6004, batch_acc=0.3750, running_acc=0.2880, grad=10.6684]Training epoch 3:  32%|███▏      | 52/163 [01:02<02:10,  1.17s/it, loss=2.6004, batch_acc=0.3750, running_acc=0.2880, grad=10.6684]Training epoch 3:  32%|███▏      | 52/163 [01:02<02:10,  1.17s/it, loss=2.6436, batch_acc=0.3125, running_acc=0.2885, grad=16.1300]Training epoch 3:  33%|███▎      | 53/163 [01:03<01:59,  1.08s/it, loss=2.6436, batch_acc=0.3125, running_acc=0.2885, grad=16.1300]Training epoch 3:  33%|███▎      | 53/163 [01:03<01:59,  1.08s/it, loss=2.9408, batch_acc=0.1875, running_acc=0.2866, grad=12.8964]Training epoch 3:  33%|███▎      | 54/163 [01:04<01:51,  1.02s/it, loss=2.9408, batch_acc=0.1875, running_acc=0.2866, grad=12.8964]Training epoch 3:  33%|███▎      | 54/163 [01:04<01:51,  1.02s/it, loss=2.7836, batch_acc=0.3125, running_acc=0.2870, grad=9.2226] Training epoch 3:  34%|███▎      | 55/163 [01:05<01:45,  1.02it/s, loss=2.7836, batch_acc=0.3125, running_acc=0.2870, grad=9.2226]Training epoch 3:  34%|███▎      | 55/163 [01:05<01:45,  1.02it/s, loss=2.8419, batch_acc=0.2812, running_acc=0.2869, grad=8.2606]Training epoch 3:  34%|███▍      | 56/163 [01:06<02:06,  1.18s/it, loss=2.8419, batch_acc=0.2812, running_acc=0.2869, grad=8.2606]Training epoch 3:  34%|███▍      | 56/163 [01:06<02:06,  1.18s/it, loss=2.5549, batch_acc=0.3438, running_acc=0.2879, grad=10.7297]Training epoch 3:  35%|███▍      | 57/163 [01:07<01:55,  1.09s/it, loss=2.5549, batch_acc=0.3438, running_acc=0.2879, grad=10.7297]Training epoch 3:  35%|███▍      | 57/163 [01:07<01:55,  1.09s/it, loss=2.6497, batch_acc=0.2500, running_acc=0.2873, grad=10.3418]Training epoch 3:  36%|███▌      | 58/163 [01:08<01:47,  1.03s/it, loss=2.6497, batch_acc=0.2500, running_acc=0.2873, grad=10.3418]Training epoch 3:  36%|███▌      | 58/163 [01:08<01:47,  1.03s/it, loss=2.6265, batch_acc=0.4062, running_acc=0.2893, grad=10.5058]Training epoch 3:  36%|███▌      | 59/163 [01:09<01:42,  1.02it/s, loss=2.6265, batch_acc=0.4062, running_acc=0.2893, grad=10.5058]Training epoch 3:  36%|███▌      | 59/163 [01:09<01:42,  1.02it/s, loss=2.6309, batch_acc=0.3125, running_acc=0.2897, grad=11.7724]Training epoch 3:  37%|███▋      | 60/163 [01:10<01:50,  1.07s/it, loss=2.6309, batch_acc=0.3125, running_acc=0.2897, grad=11.7724]Training epoch 3:  37%|███▋      | 60/163 [01:10<01:50,  1.07s/it, loss=2.6576, batch_acc=0.2188, running_acc=0.2885, grad=8.9298] Training epoch 3:  37%|███▋      | 61/163 [01:11<01:43,  1.01s/it, loss=2.6576, batch_acc=0.2188, running_acc=0.2885, grad=8.9298]Training epoch 3:  37%|███▋      | 61/163 [01:11<01:43,  1.01s/it, loss=2.6031, batch_acc=0.3438, running_acc=0.2894, grad=9.3888]Training epoch 3:  38%|███▊      | 62/163 [01:12<01:38,  1.03it/s, loss=2.6031, batch_acc=0.3438, running_acc=0.2894, grad=9.3888]Training epoch 3:  38%|███▊      | 62/163 [01:12<01:38,  1.03it/s, loss=2.4260, batch_acc=0.4062, running_acc=0.2913, grad=8.7453]Training epoch 3:  39%|███▊      | 63/163 [01:13<01:34,  1.06it/s, loss=2.4260, batch_acc=0.4062, running_acc=0.2913, grad=8.7453]Training epoch 3:  39%|███▊      | 63/163 [01:13<01:34,  1.06it/s, loss=2.8897, batch_acc=0.1875, running_acc=0.2897, grad=13.8396]Training epoch 3:  39%|███▉      | 64/163 [01:15<01:55,  1.17s/it, loss=2.8897, batch_acc=0.1875, running_acc=0.2897, grad=13.8396]Training epoch 3:  39%|███▉      | 64/163 [01:15<01:55,  1.17s/it, loss=2.9866, batch_acc=0.2500, running_acc=0.2891, grad=11.1870]Training epoch 3:  40%|███▉      | 65/163 [01:16<01:45,  1.08s/it, loss=2.9866, batch_acc=0.2500, running_acc=0.2891, grad=11.1870]Training epoch 3:  40%|███▉      | 65/163 [01:16<01:45,  1.08s/it, loss=3.0415, batch_acc=0.1562, running_acc=0.2870, grad=10.5390]Training epoch 3:  40%|████      | 66/163 [01:16<01:39,  1.02s/it, loss=3.0415, batch_acc=0.1562, running_acc=0.2870, grad=10.5390]Training epoch 3:  40%|████      | 66/163 [01:16<01:39,  1.02s/it, loss=2.8519, batch_acc=0.1875, running_acc=0.2855, grad=16.6153]Training epoch 3:  41%|████      | 67/163 [01:17<01:34,  1.02it/s, loss=2.8519, batch_acc=0.1875, running_acc=0.2855, grad=16.6153]Training epoch 3:  41%|████      | 67/163 [01:17<01:34,  1.02it/s, loss=2.6259, batch_acc=0.3750, running_acc=0.2868, grad=15.0192]Training epoch 3:  42%|████▏     | 68/163 [01:19<01:54,  1.20s/it, loss=2.6259, batch_acc=0.3750, running_acc=0.2868, grad=15.0192]Training epoch 3:  42%|████▏     | 68/163 [01:19<01:54,  1.20s/it, loss=2.7511, batch_acc=0.2500, running_acc=0.2863, grad=10.9219]Training epoch 3:  42%|████▏     | 69/163 [01:20<01:44,  1.11s/it, loss=2.7511, batch_acc=0.2500, running_acc=0.2863, grad=10.9219]Training epoch 3:  42%|████▏     | 69/163 [01:20<01:44,  1.11s/it, loss=2.7206, batch_acc=0.3125, running_acc=0.2867, grad=11.0374]Training epoch 3:  43%|████▎     | 70/163 [01:21<01:36,  1.04s/it, loss=2.7206, batch_acc=0.3125, running_acc=0.2867, grad=11.0374]Training epoch 3:  43%|████▎     | 70/163 [01:21<01:36,  1.04s/it, loss=2.4447, batch_acc=0.4062, running_acc=0.2884, grad=11.7976]Training epoch 3:  44%|████▎     | 71/163 [01:22<01:31,  1.01it/s, loss=2.4447, batch_acc=0.4062, running_acc=0.2884, grad=11.7976]Training epoch 3:  44%|████▎     | 71/163 [01:22<01:31,  1.01it/s, loss=2.5625, batch_acc=0.3125, running_acc=0.2887, grad=9.1756] Training epoch 3:  44%|████▍     | 72/163 [01:24<01:52,  1.24s/it, loss=2.5625, batch_acc=0.3125, running_acc=0.2887, grad=9.1756]Training epoch 3:  44%|████▍     | 72/163 [01:24<01:52,  1.24s/it, loss=2.5818, batch_acc=0.2812, running_acc=0.2886, grad=9.4370]Training epoch 3:  45%|████▍     | 73/163 [01:24<01:41,  1.13s/it, loss=2.5818, batch_acc=0.2812, running_acc=0.2886, grad=9.4370]Training epoch 3:  45%|████▍     | 73/163 [01:24<01:41,  1.13s/it, loss=2.7950, batch_acc=0.1875, running_acc=0.2872, grad=9.3224]Training epoch 3:  45%|████▌     | 74/163 [01:25<01:34,  1.06s/it, loss=2.7950, batch_acc=0.1875, running_acc=0.2872, grad=9.3224]Training epoch 3:  45%|████▌     | 74/163 [01:25<01:34,  1.06s/it, loss=2.7022, batch_acc=0.2500, running_acc=0.2867, grad=9.0516]Training epoch 3:  46%|████▌     | 75/163 [01:26<01:28,  1.00s/it, loss=2.7022, batch_acc=0.2500, running_acc=0.2867, grad=9.0516]Training epoch 3:  46%|████▌     | 75/163 [01:26<01:28,  1.00s/it, loss=2.5914, batch_acc=0.4062, running_acc=0.2883, grad=9.0787]Training epoch 3:  47%|████▋     | 76/163 [01:29<02:03,  1.42s/it, loss=2.5914, batch_acc=0.4062, running_acc=0.2883, grad=9.0787]Training epoch 3:  47%|████▋     | 76/163 [01:29<02:03,  1.42s/it, loss=2.7535, batch_acc=0.3438, running_acc=0.2891, grad=11.5895]Training epoch 3:  47%|████▋     | 77/163 [01:29<01:48,  1.26s/it, loss=2.7535, batch_acc=0.3438, running_acc=0.2891, grad=11.5895]Training epoch 3:  47%|████▋     | 77/163 [01:29<01:48,  1.26s/it, loss=2.8185, batch_acc=0.1875, running_acc=0.2877, grad=11.3458]Training epoch 3:  48%|████▊     | 78/163 [01:30<01:37,  1.14s/it, loss=2.8185, batch_acc=0.1875, running_acc=0.2877, grad=11.3458]Training epoch 3:  48%|████▊     | 78/163 [01:30<01:37,  1.14s/it, loss=2.5849, batch_acc=0.3438, running_acc=0.2885, grad=9.7507] Training epoch 3:  48%|████▊     | 79/163 [01:31<01:29,  1.07s/it, loss=2.5849, batch_acc=0.3438, running_acc=0.2885, grad=9.7507]Training epoch 3:  48%|████▊     | 79/163 [01:31<01:29,  1.07s/it, loss=2.8658, batch_acc=0.1875, running_acc=0.2872, grad=9.2366]Training epoch 3:  49%|████▉     | 80/163 [01:33<01:37,  1.18s/it, loss=2.8658, batch_acc=0.1875, running_acc=0.2872, grad=9.2366]Training epoch 3:  49%|████▉     | 80/163 [01:33<01:37,  1.18s/it, loss=2.6897, batch_acc=0.3438, running_acc=0.2879, grad=14.4506]Training epoch 3:  50%|████▉     | 81/163 [01:34<01:29,  1.09s/it, loss=2.6897, batch_acc=0.3438, running_acc=0.2879, grad=14.4506]Training epoch 3:  50%|████▉     | 81/163 [01:34<01:29,  1.09s/it, loss=2.9649, batch_acc=0.2812, running_acc=0.2878, grad=12.6554]Training epoch 3:  50%|█████     | 82/163 [01:34<01:22,  1.02s/it, loss=2.9649, batch_acc=0.2812, running_acc=0.2878, grad=12.6554]Training epoch 3:  50%|█████     | 82/163 [01:34<01:22,  1.02s/it, loss=2.5204, batch_acc=0.3750, running_acc=0.2889, grad=9.4635] Training epoch 3:  51%|█████     | 83/163 [01:35<01:18,  1.02it/s, loss=2.5204, batch_acc=0.3750, running_acc=0.2889, grad=9.4635]Training epoch 3:  51%|█████     | 83/163 [01:35<01:18,  1.02it/s, loss=2.6306, batch_acc=0.2812, running_acc=0.2888, grad=13.6303]Training epoch 3:  52%|█████▏    | 84/163 [01:37<01:41,  1.29s/it, loss=2.6306, batch_acc=0.2812, running_acc=0.2888, grad=13.6303]Training epoch 3:  52%|█████▏    | 84/163 [01:37<01:41,  1.29s/it, loss=2.6918, batch_acc=0.3125, running_acc=0.2891, grad=10.0248]Training epoch 3:  52%|█████▏    | 85/163 [01:38<01:31,  1.17s/it, loss=2.6918, batch_acc=0.3125, running_acc=0.2891, grad=10.0248]Training epoch 3:  52%|█████▏    | 85/163 [01:38<01:31,  1.17s/it, loss=2.5115, batch_acc=0.3750, running_acc=0.2901, grad=10.1685]Training epoch 3:  53%|█████▎    | 86/163 [01:39<01:23,  1.08s/it, loss=2.5115, batch_acc=0.3750, running_acc=0.2901, grad=10.1685]Training epoch 3:  53%|█████▎    | 86/163 [01:39<01:23,  1.08s/it, loss=2.4602, batch_acc=0.4062, running_acc=0.2914, grad=10.5405]Training epoch 3:  53%|█████▎    | 87/163 [01:40<01:17,  1.02s/it, loss=2.4602, batch_acc=0.4062, running_acc=0.2914, grad=10.5405]Training epoch 3:  53%|█████▎    | 87/163 [01:40<01:17,  1.02s/it, loss=2.4771, batch_acc=0.4062, running_acc=0.2927, grad=12.6496]Training epoch 3:  54%|█████▍    | 88/163 [01:41<01:17,  1.04s/it, loss=2.4771, batch_acc=0.4062, running_acc=0.2927, grad=12.6496]Training epoch 3:  54%|█████▍    | 88/163 [01:41<01:17,  1.04s/it, loss=2.7664, batch_acc=0.2188, running_acc=0.2919, grad=10.3081]Training epoch 3:  55%|█████▍    | 89/163 [01:42<01:13,  1.01it/s, loss=2.7664, batch_acc=0.2188, running_acc=0.2919, grad=10.3081]Training epoch 3:  55%|█████▍    | 89/163 [01:42<01:13,  1.01it/s, loss=2.6646, batch_acc=0.3438, running_acc=0.2925, grad=11.5710]Training epoch 3:  55%|█████▌    | 90/163 [01:43<01:09,  1.05it/s, loss=2.6646, batch_acc=0.3438, running_acc=0.2925, grad=11.5710]Training epoch 3:  55%|█████▌    | 90/163 [01:43<01:09,  1.05it/s, loss=2.6417, batch_acc=0.3438, running_acc=0.2931, grad=8.5596] Training epoch 3:  56%|█████▌    | 91/163 [01:44<01:07,  1.07it/s, loss=2.6417, batch_acc=0.3438, running_acc=0.2931, grad=8.5596]Training epoch 3:  56%|█████▌    | 91/163 [01:44<01:07,  1.07it/s, loss=2.4980, batch_acc=0.4062, running_acc=0.2943, grad=9.4831]Training epoch 3:  56%|█████▋    | 92/163 [01:45<01:22,  1.16s/it, loss=2.4980, batch_acc=0.4062, running_acc=0.2943, grad=9.4831]Training epoch 3:  56%|█████▋    | 92/163 [01:45<01:22,  1.16s/it, loss=2.8302, batch_acc=0.2500, running_acc=0.2938, grad=12.2624]Training epoch 3:  57%|█████▋    | 93/163 [01:46<01:15,  1.08s/it, loss=2.8302, batch_acc=0.2500, running_acc=0.2938, grad=12.2624]Training epoch 3:  57%|█████▋    | 93/163 [01:46<01:15,  1.08s/it, loss=2.7867, batch_acc=0.3125, running_acc=0.2940, grad=10.1192]Training epoch 3:  58%|█████▊    | 94/163 [01:47<01:10,  1.02s/it, loss=2.7867, batch_acc=0.3125, running_acc=0.2940, grad=10.1192]Training epoch 3:  58%|█████▊    | 94/163 [01:47<01:10,  1.02s/it, loss=2.3801, batch_acc=0.4688, running_acc=0.2959, grad=9.9556] Training epoch 3:  58%|█████▊    | 95/163 [01:48<01:06,  1.02it/s, loss=2.3801, batch_acc=0.4688, running_acc=0.2959, grad=9.9556]Training epoch 3:  58%|█████▊    | 95/163 [01:48<01:06,  1.02it/s, loss=2.7556, batch_acc=0.2500, running_acc=0.2954, grad=11.6238]Training epoch 3:  59%|█████▉    | 96/163 [01:49<01:11,  1.07s/it, loss=2.7556, batch_acc=0.2500, running_acc=0.2954, grad=11.6238]Training epoch 3:  59%|█████▉    | 96/163 [01:49<01:11,  1.07s/it, loss=3.0207, batch_acc=0.2500, running_acc=0.2949, grad=12.6241]Training epoch 3:  60%|█████▉    | 97/163 [01:50<01:06,  1.01s/it, loss=3.0207, batch_acc=0.2500, running_acc=0.2949, grad=12.6241]Training epoch 3:  60%|█████▉    | 97/163 [01:50<01:06,  1.01s/it, loss=2.7904, batch_acc=0.1875, running_acc=0.2938, grad=9.4492] Training epoch 3:  60%|██████    | 98/163 [01:51<01:03,  1.03it/s, loss=2.7904, batch_acc=0.1875, running_acc=0.2938, grad=9.4492]Training epoch 3:  60%|██████    | 98/163 [01:51<01:03,  1.03it/s, loss=2.3712, batch_acc=0.4062, running_acc=0.2950, grad=10.8550]Training epoch 3:  61%|██████    | 99/163 [01:52<01:00,  1.06it/s, loss=2.3712, batch_acc=0.4062, running_acc=0.2950, grad=10.8550]Training epoch 3:  61%|██████    | 99/163 [01:52<01:00,  1.06it/s, loss=2.8778, batch_acc=0.2812, running_acc=0.2948, grad=12.4022]Training epoch 3:  61%|██████▏   | 100/163 [01:54<01:16,  1.22s/it, loss=2.8778, batch_acc=0.2812, running_acc=0.2948, grad=12.4022]Training epoch 3:  61%|██████▏   | 100/163 [01:54<01:16,  1.22s/it, loss=3.0108, batch_acc=0.2188, running_acc=0.2941, grad=11.1626]Training epoch 3:  62%|██████▏   | 101/163 [01:55<01:09,  1.12s/it, loss=3.0108, batch_acc=0.2188, running_acc=0.2941, grad=11.1626]Training epoch 3:  62%|██████▏   | 101/163 [01:55<01:09,  1.12s/it, loss=2.5607, batch_acc=0.3750, running_acc=0.2949, grad=9.5106] Training epoch 3:  63%|██████▎   | 102/163 [01:56<01:03,  1.04s/it, loss=2.5607, batch_acc=0.3750, running_acc=0.2949, grad=9.5106]Training epoch 3:  63%|██████▎   | 102/163 [01:56<01:03,  1.04s/it, loss=2.5528, batch_acc=0.3750, running_acc=0.2956, grad=12.0362]Training epoch 3:  63%|██████▎   | 103/163 [01:56<00:59,  1.00it/s, loss=2.5528, batch_acc=0.3750, running_acc=0.2956, grad=12.0362]Training epoch 3:  63%|██████▎   | 103/163 [01:56<00:59,  1.00it/s, loss=2.7684, batch_acc=0.2500, running_acc=0.2952, grad=10.8063]Training epoch 3:  64%|██████▍   | 104/163 [01:58<01:05,  1.10s/it, loss=2.7684, batch_acc=0.2500, running_acc=0.2952, grad=10.8063]Training epoch 3:  64%|██████▍   | 104/163 [01:58<01:05,  1.10s/it, loss=2.6370, batch_acc=0.3750, running_acc=0.2960, grad=10.6681]Training epoch 3:  64%|██████▍   | 105/163 [01:59<01:00,  1.04s/it, loss=2.6370, batch_acc=0.3750, running_acc=0.2960, grad=10.6681]Training epoch 3:  64%|██████▍   | 105/163 [01:59<01:00,  1.04s/it, loss=2.6892, batch_acc=0.3125, running_acc=0.2961, grad=10.3352]Training epoch 3:  65%|██████▌   | 106/163 [02:00<00:56,  1.01it/s, loss=2.6892, batch_acc=0.3125, running_acc=0.2961, grad=10.3352]Training epoch 3:  65%|██████▌   | 106/163 [02:00<00:56,  1.01it/s, loss=2.3995, batch_acc=0.3125, running_acc=0.2963, grad=10.3066]Training epoch 3:  66%|██████▌   | 107/163 [02:00<00:53,  1.04it/s, loss=2.3995, batch_acc=0.3125, running_acc=0.2963, grad=10.3066]Training epoch 3:  66%|██████▌   | 107/163 [02:00<00:53,  1.04it/s, loss=2.2416, batch_acc=0.4375, running_acc=0.2976, grad=8.7709] Training epoch 3:  66%|██████▋   | 108/163 [02:02<01:01,  1.11s/it, loss=2.2416, batch_acc=0.4375, running_acc=0.2976, grad=8.7709]Training epoch 3:  66%|██████▋   | 108/163 [02:02<01:01,  1.11s/it, loss=2.5899, batch_acc=0.3438, running_acc=0.2980, grad=12.3820]Training epoch 3:  67%|██████▋   | 109/163 [02:03<00:56,  1.04s/it, loss=2.5899, batch_acc=0.3438, running_acc=0.2980, grad=12.3820]Training epoch 3:  67%|██████▋   | 109/163 [02:03<00:56,  1.04s/it, loss=2.4263, batch_acc=0.2812, running_acc=0.2979, grad=10.1540]Training epoch 3:  67%|██████▋   | 110/163 [02:04<00:52,  1.01it/s, loss=2.4263, batch_acc=0.2812, running_acc=0.2979, grad=10.1540]Training epoch 3:  67%|██████▋   | 110/163 [02:04<00:52,  1.01it/s, loss=2.5163, batch_acc=0.3750, running_acc=0.2986, grad=13.6954]Training epoch 3:  68%|██████▊   | 111/163 [02:05<00:49,  1.04it/s, loss=2.5163, batch_acc=0.3750, running_acc=0.2986, grad=13.6954]Training epoch 3:  68%|██████▊   | 111/163 [02:05<00:49,  1.04it/s, loss=2.6102, batch_acc=0.3750, running_acc=0.2993, grad=14.7132]Training epoch 3:  69%|██████▊   | 112/163 [02:06<00:52,  1.03s/it, loss=2.6102, batch_acc=0.3750, running_acc=0.2993, grad=14.7132]Training epoch 3:  69%|██████▊   | 112/163 [02:06<00:52,  1.03s/it, loss=2.9839, batch_acc=0.1875, running_acc=0.2983, grad=10.3522]Training epoch 3:  69%|██████▉   | 113/163 [02:07<00:49,  1.02it/s, loss=2.9839, batch_acc=0.1875, running_acc=0.2983, grad=10.3522]Training epoch 3:  69%|██████▉   | 113/163 [02:07<00:49,  1.02it/s, loss=2.5025, batch_acc=0.2812, running_acc=0.2981, grad=9.1763] Training epoch 3:  70%|██████▉   | 114/163 [02:07<00:46,  1.05it/s, loss=2.5025, batch_acc=0.2812, running_acc=0.2981, grad=9.1763]Training epoch 3:  70%|██████▉   | 114/163 [02:07<00:46,  1.05it/s, loss=2.6936, batch_acc=0.3125, running_acc=0.2982, grad=10.1152]Training epoch 3:  71%|███████   | 115/163 [02:08<00:44,  1.08it/s, loss=2.6936, batch_acc=0.3125, running_acc=0.2982, grad=10.1152]Training epoch 3:  71%|███████   | 115/163 [02:08<00:44,  1.08it/s, loss=2.8541, batch_acc=0.2188, running_acc=0.2976, grad=10.6858]Training epoch 3:  71%|███████   | 116/163 [02:10<00:50,  1.08s/it, loss=2.8541, batch_acc=0.2188, running_acc=0.2976, grad=10.6858]Training epoch 3:  71%|███████   | 116/163 [02:10<00:50,  1.08s/it, loss=2.9217, batch_acc=0.1562, running_acc=0.2963, grad=11.2074]Training epoch 3:  72%|███████▏  | 117/163 [02:11<00:46,  1.02s/it, loss=2.9217, batch_acc=0.1562, running_acc=0.2963, grad=11.2074]Training epoch 3:  72%|███████▏  | 117/163 [02:11<00:46,  1.02s/it, loss=2.5279, batch_acc=0.3750, running_acc=0.2970, grad=10.3554]Training epoch 3:  72%|███████▏  | 118/163 [02:12<00:44,  1.02it/s, loss=2.5279, batch_acc=0.3750, running_acc=0.2970, grad=10.3554]Training epoch 3:  72%|███████▏  | 118/163 [02:12<00:44,  1.02it/s, loss=2.5148, batch_acc=0.3125, running_acc=0.2971, grad=10.0082]Training epoch 3:  73%|███████▎  | 119/163 [02:12<00:41,  1.05it/s, loss=2.5148, batch_acc=0.3125, running_acc=0.2971, grad=10.0082]Training epoch 3:  73%|███████▎  | 119/163 [02:12<00:41,  1.05it/s, loss=2.8667, batch_acc=0.2188, running_acc=0.2965, grad=12.2849]Training epoch 3:  74%|███████▎  | 120/163 [02:15<00:57,  1.34s/it, loss=2.8667, batch_acc=0.2188, running_acc=0.2965, grad=12.2849]Training epoch 3:  74%|███████▎  | 120/163 [02:15<00:57,  1.34s/it, loss=2.6070, batch_acc=0.3125, running_acc=0.2966, grad=11.7608]Training epoch 3:  74%|███████▍  | 121/163 [02:16<00:50,  1.20s/it, loss=2.6070, batch_acc=0.3125, running_acc=0.2966, grad=11.7608]Training epoch 3:  74%|███████▍  | 121/163 [02:16<00:50,  1.20s/it, loss=2.3474, batch_acc=0.3750, running_acc=0.2973, grad=9.4761] Training epoch 3:  75%|███████▍  | 122/163 [02:16<00:45,  1.10s/it, loss=2.3474, batch_acc=0.3750, running_acc=0.2973, grad=9.4761]Training epoch 3:  75%|███████▍  | 122/163 [02:16<00:45,  1.10s/it, loss=2.6424, batch_acc=0.2500, running_acc=0.2969, grad=10.7380]Training epoch 3:  75%|███████▌  | 123/163 [02:17<00:41,  1.04s/it, loss=2.6424, batch_acc=0.2500, running_acc=0.2969, grad=10.7380]Training epoch 3:  75%|███████▌  | 123/163 [02:17<00:41,  1.04s/it, loss=2.8108, batch_acc=0.2812, running_acc=0.2967, grad=11.3491]Training epoch 3:  76%|███████▌  | 124/163 [02:19<00:46,  1.20s/it, loss=2.8108, batch_acc=0.2812, running_acc=0.2967, grad=11.3491]Training epoch 3:  76%|███████▌  | 124/163 [02:19<00:46,  1.20s/it, loss=2.4690, batch_acc=0.4688, running_acc=0.2981, grad=13.3241]Training epoch 3:  77%|███████▋  | 125/163 [02:20<00:41,  1.10s/it, loss=2.4690, batch_acc=0.4688, running_acc=0.2981, grad=13.3241]Training epoch 3:  77%|███████▋  | 125/163 [02:20<00:41,  1.10s/it, loss=2.6074, batch_acc=0.3438, running_acc=0.2985, grad=9.1865] Training epoch 3:  77%|███████▋  | 126/163 [02:21<00:38,  1.04s/it, loss=2.6074, batch_acc=0.3438, running_acc=0.2985, grad=9.1865]Training epoch 3:  77%|███████▋  | 126/163 [02:21<00:38,  1.04s/it, loss=2.8707, batch_acc=0.3125, running_acc=0.2986, grad=9.7966]Training epoch 3:  78%|███████▊  | 127/163 [02:22<00:35,  1.01it/s, loss=2.8707, batch_acc=0.3125, running_acc=0.2986, grad=9.7966]Training epoch 3:  78%|███████▊  | 127/163 [02:22<00:35,  1.01it/s, loss=2.6098, batch_acc=0.3750, running_acc=0.2992, grad=11.4600]Training epoch 3:  79%|███████▊  | 128/163 [02:24<00:47,  1.35s/it, loss=2.6098, batch_acc=0.3750, running_acc=0.2992, grad=11.4600]Training epoch 3:  79%|███████▊  | 128/163 [02:24<00:47,  1.35s/it, loss=2.6165, batch_acc=0.4062, running_acc=0.3000, grad=8.2688] Training epoch 3:  79%|███████▉  | 129/163 [02:25<00:41,  1.21s/it, loss=2.6165, batch_acc=0.4062, running_acc=0.3000, grad=8.2688]Training epoch 3:  79%|███████▉  | 129/163 [02:25<00:41,  1.21s/it, loss=2.1055, batch_acc=0.4062, running_acc=0.3009, grad=10.7218]Training epoch 3:  80%|███████▉  | 130/163 [02:25<00:36,  1.11s/it, loss=2.1055, batch_acc=0.4062, running_acc=0.3009, grad=10.7218]Training epoch 3:  80%|███████▉  | 130/163 [02:25<00:36,  1.11s/it, loss=2.3002, batch_acc=0.3438, running_acc=0.3012, grad=9.7836] Training epoch 3:  80%|████████  | 131/163 [02:26<00:33,  1.04s/it, loss=2.3002, batch_acc=0.3438, running_acc=0.3012, grad=9.7836]Training epoch 3:  80%|████████  | 131/163 [02:26<00:33,  1.04s/it, loss=2.8774, batch_acc=0.3438, running_acc=0.3015, grad=9.9205]Training epoch 3:  81%|████████  | 132/163 [02:28<00:34,  1.12s/it, loss=2.8774, batch_acc=0.3438, running_acc=0.3015, grad=9.9205]Training epoch 3:  81%|████████  | 132/163 [02:28<00:34,  1.12s/it, loss=2.5789, batch_acc=0.3438, running_acc=0.3018, grad=11.5306]Training epoch 3:  82%|████████▏ | 133/163 [02:29<00:31,  1.05s/it, loss=2.5789, batch_acc=0.3438, running_acc=0.3018, grad=11.5306]Training epoch 3:  82%|████████▏ | 133/163 [02:29<00:31,  1.05s/it, loss=2.7198, batch_acc=0.3438, running_acc=0.3022, grad=15.9892]Training epoch 3:  82%|████████▏ | 134/163 [02:29<00:28,  1.00it/s, loss=2.7198, batch_acc=0.3438, running_acc=0.3022, grad=15.9892]Training epoch 3:  82%|████████▏ | 134/163 [02:29<00:28,  1.00it/s, loss=2.6586, batch_acc=0.3125, running_acc=0.3022, grad=12.6289]Training epoch 3:  83%|████████▎ | 135/163 [02:30<00:26,  1.04it/s, loss=2.6586, batch_acc=0.3125, running_acc=0.3022, grad=12.6289]Training epoch 3:  83%|████████▎ | 135/163 [02:30<00:26,  1.04it/s, loss=2.5681, batch_acc=0.4062, running_acc=0.3030, grad=11.5398]Training epoch 3:  83%|████████▎ | 136/163 [02:32<00:31,  1.17s/it, loss=2.5681, batch_acc=0.4062, running_acc=0.3030, grad=11.5398]Training epoch 3:  83%|████████▎ | 136/163 [02:32<00:31,  1.17s/it, loss=2.4408, batch_acc=0.2188, running_acc=0.3024, grad=9.8925] Training epoch 3:  84%|████████▍ | 137/163 [02:33<00:28,  1.08s/it, loss=2.4408, batch_acc=0.2188, running_acc=0.3024, grad=9.8925]Training epoch 3:  84%|████████▍ | 137/163 [02:33<00:28,  1.08s/it, loss=2.6912, batch_acc=0.3750, running_acc=0.3029, grad=14.6360]Training epoch 3:  85%|████████▍ | 138/163 [02:34<00:25,  1.02s/it, loss=2.6912, batch_acc=0.3750, running_acc=0.3029, grad=14.6360]Training epoch 3:  85%|████████▍ | 138/163 [02:34<00:25,  1.02s/it, loss=2.6959, batch_acc=0.2188, running_acc=0.3023, grad=8.7240] Training epoch 3:  85%|████████▌ | 139/163 [02:35<00:23,  1.02it/s, loss=2.6959, batch_acc=0.2188, running_acc=0.3023, grad=8.7240]Training epoch 3:  85%|████████▌ | 139/163 [02:35<00:23,  1.02it/s, loss=3.0650, batch_acc=0.2188, running_acc=0.3017, grad=10.6084]Training epoch 3:  86%|████████▌ | 140/163 [02:36<00:23,  1.00s/it, loss=3.0650, batch_acc=0.2188, running_acc=0.3017, grad=10.6084]Training epoch 3:  86%|████████▌ | 140/163 [02:36<00:23,  1.00s/it, loss=2.4915, batch_acc=0.3750, running_acc=0.3022, grad=11.7817]Training epoch 3:  87%|████████▋ | 141/163 [02:37<00:21,  1.03it/s, loss=2.4915, batch_acc=0.3750, running_acc=0.3022, grad=11.7817]Training epoch 3:  87%|████████▋ | 141/163 [02:37<00:21,  1.03it/s, loss=2.7432, batch_acc=0.2188, running_acc=0.3016, grad=10.3958]Training epoch 3:  87%|████████▋ | 142/163 [02:37<00:19,  1.06it/s, loss=2.7432, batch_acc=0.2188, running_acc=0.3016, grad=10.3958]Training epoch 3:  87%|████████▋ | 142/163 [02:37<00:19,  1.06it/s, loss=2.3013, batch_acc=0.5000, running_acc=0.3030, grad=11.3546]Training epoch 3:  88%|████████▊ | 143/163 [02:38<00:18,  1.08it/s, loss=2.3013, batch_acc=0.5000, running_acc=0.3030, grad=11.3546]Training epoch 3:  88%|████████▊ | 143/163 [02:38<00:18,  1.08it/s, loss=2.7971, batch_acc=0.3125, running_acc=0.3031, grad=15.5997]Training epoch 3:  88%|████████▊ | 144/163 [02:40<00:21,  1.13s/it, loss=2.7971, batch_acc=0.3125, running_acc=0.3031, grad=15.5997]Training epoch 3:  88%|████████▊ | 144/163 [02:40<00:21,  1.13s/it, loss=2.6255, batch_acc=0.3438, running_acc=0.3034, grad=11.1376]Training epoch 3:  89%|████████▉ | 145/163 [02:41<00:18,  1.05s/it, loss=2.6255, batch_acc=0.3438, running_acc=0.3034, grad=11.1376]Training epoch 3:  89%|████████▉ | 145/163 [02:41<00:18,  1.05s/it, loss=2.6664, batch_acc=0.2188, running_acc=0.3028, grad=12.4496]Training epoch 3:  90%|████████▉ | 146/163 [02:42<00:17,  1.00s/it, loss=2.6664, batch_acc=0.2188, running_acc=0.3028, grad=12.4496]Training epoch 3:  90%|████████▉ | 146/163 [02:42<00:17,  1.00s/it, loss=2.7308, batch_acc=0.3125, running_acc=0.3029, grad=11.0806]Training epoch 3:  90%|█████████ | 147/163 [02:43<00:15,  1.04it/s, loss=2.7308, batch_acc=0.3125, running_acc=0.3029, grad=11.0806]Training epoch 3:  90%|█████████ | 147/163 [02:43<00:15,  1.04it/s, loss=2.4912, batch_acc=0.4062, running_acc=0.3036, grad=11.2908]Training epoch 3:  91%|█████████ | 148/163 [02:45<00:20,  1.34s/it, loss=2.4912, batch_acc=0.4062, running_acc=0.3036, grad=11.2908]Training epoch 3:  91%|█████████ | 148/163 [02:45<00:20,  1.34s/it, loss=2.6523, batch_acc=0.3125, running_acc=0.3036, grad=11.0833]Training epoch 3:  91%|█████████▏| 149/163 [02:46<00:16,  1.20s/it, loss=2.6523, batch_acc=0.3125, running_acc=0.3036, grad=11.0833]Training epoch 3:  91%|█████████▏| 149/163 [02:46<00:16,  1.20s/it, loss=2.6338, batch_acc=0.2812, running_acc=0.3035, grad=9.9898] Training epoch 3:  92%|█████████▏| 150/163 [02:47<00:14,  1.11s/it, loss=2.6338, batch_acc=0.2812, running_acc=0.3035, grad=9.9898]Training epoch 3:  92%|█████████▏| 150/163 [02:47<00:14,  1.11s/it, loss=2.3859, batch_acc=0.4062, running_acc=0.3042, grad=8.5731]Training epoch 3:  93%|█████████▎| 151/163 [02:47<00:12,  1.04s/it, loss=2.3859, batch_acc=0.4062, running_acc=0.3042, grad=8.5731]Training epoch 3:  93%|█████████▎| 151/163 [02:47<00:12,  1.04s/it, loss=2.4865, batch_acc=0.3125, running_acc=0.3042, grad=11.0506]Training epoch 3:  93%|█████████▎| 152/163 [02:49<00:13,  1.25s/it, loss=2.4865, batch_acc=0.3125, running_acc=0.3042, grad=11.0506]Training epoch 3:  93%|█████████▎| 152/163 [02:49<00:13,  1.25s/it, loss=2.4886, batch_acc=0.2500, running_acc=0.3039, grad=10.1196]Training epoch 3:  94%|█████████▍| 153/163 [02:50<00:11,  1.14s/it, loss=2.4886, batch_acc=0.2500, running_acc=0.3039, grad=10.1196]Training epoch 3:  94%|█████████▍| 153/163 [02:50<00:11,  1.14s/it, loss=2.4773, batch_acc=0.3125, running_acc=0.3039, grad=11.8163]Training epoch 3:  94%|█████████▍| 154/163 [02:51<00:09,  1.06s/it, loss=2.4773, batch_acc=0.3125, running_acc=0.3039, grad=11.8163]Training epoch 3:  94%|█████████▍| 154/163 [02:51<00:09,  1.06s/it, loss=2.6729, batch_acc=0.3750, running_acc=0.3044, grad=9.5575] Training epoch 3:  95%|█████████▌| 155/163 [02:52<00:08,  1.01s/it, loss=2.6729, batch_acc=0.3750, running_acc=0.3044, grad=9.5575]Training epoch 3:  95%|█████████▌| 155/163 [02:52<00:08,  1.01s/it, loss=2.5118, batch_acc=0.4688, running_acc=0.3054, grad=8.5029]Training epoch 3:  96%|█████████▌| 156/163 [02:54<00:08,  1.23s/it, loss=2.5118, batch_acc=0.4688, running_acc=0.3054, grad=8.5029]Training epoch 3:  96%|█████████▌| 156/163 [02:54<00:08,  1.23s/it, loss=2.6801, batch_acc=0.2188, running_acc=0.3049, grad=10.7580]Training epoch 3:  96%|█████████▋| 157/163 [02:54<00:06,  1.12s/it, loss=2.6801, batch_acc=0.2188, running_acc=0.3049, grad=10.7580]Training epoch 3:  96%|█████████▋| 157/163 [02:54<00:06,  1.12s/it, loss=2.4685, batch_acc=0.2812, running_acc=0.3047, grad=10.8243]Training epoch 3:  97%|█████████▋| 158/163 [02:55<00:05,  1.05s/it, loss=2.4685, batch_acc=0.2812, running_acc=0.3047, grad=10.8243]Training epoch 3:  97%|█████████▋| 158/163 [02:55<00:05,  1.05s/it, loss=2.4938, batch_acc=0.3438, running_acc=0.3050, grad=11.4440]Training epoch 3:  98%|█████████▊| 159/163 [02:56<00:03,  1.00it/s, loss=2.4938, batch_acc=0.3438, running_acc=0.3050, grad=11.4440]Training epoch 3:  98%|█████████▊| 159/163 [02:56<00:03,  1.00it/s, loss=2.6753, batch_acc=0.3438, running_acc=0.3052, grad=10.7865]Training epoch 3:  98%|█████████▊| 160/163 [02:58<00:03,  1.14s/it, loss=2.6753, batch_acc=0.3438, running_acc=0.3052, grad=10.7865]Training epoch 3:  98%|█████████▊| 160/163 [02:58<00:03,  1.14s/it, loss=2.6605, batch_acc=0.3125, running_acc=0.3053, grad=9.6442] Training epoch 3:  99%|█████████▉| 161/163 [02:59<00:02,  1.06s/it, loss=2.6605, batch_acc=0.3125, running_acc=0.3053, grad=9.6442]Training epoch 3:  99%|█████████▉| 161/163 [02:59<00:02,  1.06s/it, loss=2.6737, batch_acc=0.3438, running_acc=0.3055, grad=14.7522]Training epoch 3:  99%|█████████▉| 162/163 [02:59<00:01,  1.01s/it, loss=2.6737, batch_acc=0.3438, running_acc=0.3055, grad=14.7522]Training epoch 3:  99%|█████████▉| 162/163 [02:59<00:01,  1.01s/it, loss=2.7127, batch_acc=0.2188, running_acc=0.3050, grad=13.2996]Training epoch 3: 100%|██████████| 163/163 [03:00<00:00,  1.11it/s, loss=2.7127, batch_acc=0.2188, running_acc=0.3050, grad=13.2996]Training epoch 3: 100%|██████████| 163/163 [03:00<00:00,  1.11it/s, loss=2.6684, batch_acc=0.1905, running_acc=0.3045, grad=11.8122]Training epoch 3: 100%|██████████| 163/163 [03:00<00:00,  1.11s/it, loss=2.6684, batch_acc=0.1905, running_acc=0.3045, grad=11.8122]
Evaluation epoch 3:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 3:   4%|▎         | 1/28 [00:05<02:15,  5.02s/it]Evaluation epoch 3:   4%|▎         | 1/28 [00:05<02:15,  5.02s/it, loss=2.1045, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 3:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=2.1045, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 3:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=2.1937, batch_acc=0.5625, running_acc=0.5000]Evaluation epoch 3:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=2.1937, batch_acc=0.5625, running_acc=0.5000]Evaluation epoch 3:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=2.3902, batch_acc=0.2188, running_acc=0.4062]Evaluation epoch 3:  14%|█▍        | 4/28 [00:10<01:02,  2.60s/it, loss=2.3902, batch_acc=0.2188, running_acc=0.4062]Evaluation epoch 3:  14%|█▍        | 4/28 [00:10<01:02,  2.60s/it, loss=2.9243, batch_acc=0.0938, running_acc=0.3281]Evaluation epoch 3:  18%|█▊        | 5/28 [00:10<00:40,  1.75s/it, loss=2.9243, batch_acc=0.0938, running_acc=0.3281]Evaluation epoch 3:  18%|█▊        | 5/28 [00:10<00:40,  1.75s/it, loss=3.0353, batch_acc=0.1562, running_acc=0.2938]Evaluation epoch 3:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=3.0353, batch_acc=0.1562, running_acc=0.2938]Evaluation epoch 3:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=3.3422, batch_acc=0.0625, running_acc=0.2552]Evaluation epoch 3:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=3.3422, batch_acc=0.0625, running_acc=0.2552]Evaluation epoch 3:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.8509, batch_acc=0.2188, running_acc=0.2500]Evaluation epoch 3:  29%|██▊       | 8/28 [00:14<00:33,  1.65s/it, loss=2.8509, batch_acc=0.2188, running_acc=0.2500]Evaluation epoch 3:  29%|██▊       | 8/28 [00:14<00:33,  1.65s/it, loss=2.5563, batch_acc=0.2188, running_acc=0.2461]Evaluation epoch 3:  32%|███▏      | 9/28 [00:14<00:23,  1.22s/it, loss=2.5563, batch_acc=0.2188, running_acc=0.2461]Evaluation epoch 3:  32%|███▏      | 9/28 [00:14<00:23,  1.22s/it, loss=2.7456, batch_acc=0.3438, running_acc=0.2569]Evaluation epoch 3:  36%|███▌      | 10/28 [00:14<00:16,  1.08it/s, loss=2.7456, batch_acc=0.3438, running_acc=0.2569]Evaluation epoch 3:  36%|███▌      | 10/28 [00:14<00:16,  1.08it/s, loss=1.2450, batch_acc=0.7812, running_acc=0.3094]Evaluation epoch 3:  39%|███▉      | 11/28 [00:14<00:12,  1.39it/s, loss=1.2450, batch_acc=0.7812, running_acc=0.3094]Evaluation epoch 3:  39%|███▉      | 11/28 [00:14<00:12,  1.39it/s, loss=3.2239, batch_acc=0.1562, running_acc=0.2955]Evaluation epoch 3:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=3.2239, batch_acc=0.1562, running_acc=0.2955]Evaluation epoch 3:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.4462, batch_acc=0.3750, running_acc=0.3021]Evaluation epoch 3:  46%|████▋     | 13/28 [00:20<00:24,  1.62s/it, loss=2.4462, batch_acc=0.3750, running_acc=0.3021]Evaluation epoch 3:  46%|████▋     | 13/28 [00:20<00:24,  1.62s/it, loss=2.5099, batch_acc=0.2812, running_acc=0.3005]Evaluation epoch 3:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=2.5099, batch_acc=0.2812, running_acc=0.3005]Evaluation epoch 3:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=2.8383, batch_acc=0.3125, running_acc=0.3013]Evaluation epoch 3:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.8383, batch_acc=0.3125, running_acc=0.3013]Evaluation epoch 3:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=3.3437, batch_acc=0.1875, running_acc=0.2938]Evaluation epoch 3:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=3.3437, batch_acc=0.1875, running_acc=0.2938]Evaluation epoch 3:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=3.0036, batch_acc=0.2812, running_acc=0.2930]Evaluation epoch 3:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=3.0036, batch_acc=0.2812, running_acc=0.2930]Evaluation epoch 3:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=2.7338, batch_acc=0.4375, running_acc=0.3015]Evaluation epoch 3:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=2.7338, batch_acc=0.4375, running_acc=0.3015]Evaluation epoch 3:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=2.2516, batch_acc=0.4688, running_acc=0.3108]Evaluation epoch 3:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.2516, batch_acc=0.4688, running_acc=0.3108]Evaluation epoch 3:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.4697, batch_acc=0.1875, running_acc=0.3043]Evaluation epoch 3:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=2.4697, batch_acc=0.1875, running_acc=0.3043]Evaluation epoch 3:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=2.9986, batch_acc=0.0000, running_acc=0.2891]Evaluation epoch 3:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=2.9986, batch_acc=0.0000, running_acc=0.2891]Evaluation epoch 3:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=3.0803, batch_acc=0.0938, running_acc=0.2798]Evaluation epoch 3:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=3.0803, batch_acc=0.0938, running_acc=0.2798]Evaluation epoch 3:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=2.8014, batch_acc=0.1875, running_acc=0.2756]Evaluation epoch 3:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=2.8014, batch_acc=0.1875, running_acc=0.2756]Evaluation epoch 3:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=2.4363, batch_acc=0.3750, running_acc=0.2799]Evaluation epoch 3:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=2.4363, batch_acc=0.3750, running_acc=0.2799]Evaluation epoch 3:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=2.0191, batch_acc=0.6250, running_acc=0.2943]Evaluation epoch 3:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=2.0191, batch_acc=0.6250, running_acc=0.2943]Evaluation epoch 3:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=1.9002, batch_acc=0.5000, running_acc=0.3025]Evaluation epoch 3:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.9002, batch_acc=0.5000, running_acc=0.3025]Evaluation epoch 3:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=2.3104, batch_acc=0.4375, running_acc=0.3077]Evaluation epoch 3:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=2.3104, batch_acc=0.4375, running_acc=0.3077]Evaluation epoch 3:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=2.6781, batch_acc=0.3125, running_acc=0.3079]Evaluation epoch 3: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.9377, batch_acc=0.6667, running_acc=0.3091]Evaluation epoch 3: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=1.9377, batch_acc=0.6667, running_acc=0.3091]
Training epoch 4:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 4:   1%|          | 1/163 [00:05<14:44,  5.46s/it]Training epoch 4:   1%|          | 1/163 [00:05<14:44,  5.46s/it, loss=2.6445, batch_acc=0.3750, running_acc=0.3750, grad=14.6290]Training epoch 4:   1%|          | 2/163 [00:06<07:25,  2.77s/it, loss=2.6445, batch_acc=0.3750, running_acc=0.3750, grad=14.6290]Training epoch 4:   1%|          | 2/163 [00:06<07:25,  2.77s/it, loss=2.6269, batch_acc=0.3125, running_acc=0.3438, grad=16.0939]Training epoch 4:   2%|▏         | 3/163 [00:07<05:04,  1.90s/it, loss=2.6269, batch_acc=0.3125, running_acc=0.3438, grad=16.0939]Training epoch 4:   2%|▏         | 3/163 [00:07<05:04,  1.90s/it, loss=2.7867, batch_acc=0.2188, running_acc=0.3021, grad=13.7076]Training epoch 4:   2%|▏         | 4/163 [00:09<05:08,  1.94s/it, loss=2.7867, batch_acc=0.2188, running_acc=0.3021, grad=13.7076]Training epoch 4:   2%|▏         | 4/163 [00:09<05:08,  1.94s/it, loss=2.4658, batch_acc=0.3438, running_acc=0.3125, grad=12.8031]Training epoch 4:   3%|▎         | 5/163 [00:10<04:06,  1.56s/it, loss=2.4658, batch_acc=0.3438, running_acc=0.3125, grad=12.8031]Training epoch 4:   3%|▎         | 5/163 [00:10<04:06,  1.56s/it, loss=2.5803, batch_acc=0.2500, running_acc=0.3000, grad=11.3888]Training epoch 4:   4%|▎         | 6/163 [00:10<03:28,  1.33s/it, loss=2.5803, batch_acc=0.2500, running_acc=0.3000, grad=11.3888]Training epoch 4:   4%|▎         | 6/163 [00:10<03:28,  1.33s/it, loss=2.5088, batch_acc=0.4062, running_acc=0.3177, grad=10.6566]Training epoch 4:   4%|▍         | 7/163 [00:11<03:04,  1.18s/it, loss=2.5088, batch_acc=0.4062, running_acc=0.3177, grad=10.6566]Training epoch 4:   4%|▍         | 7/163 [00:11<03:04,  1.18s/it, loss=2.5751, batch_acc=0.1875, running_acc=0.2991, grad=13.1590]Training epoch 4:   5%|▍         | 8/163 [00:14<04:07,  1.60s/it, loss=2.5751, batch_acc=0.1875, running_acc=0.2991, grad=13.1590]Training epoch 4:   5%|▍         | 8/163 [00:14<04:07,  1.60s/it, loss=2.3380, batch_acc=0.3750, running_acc=0.3086, grad=12.0504]Training epoch 4:   6%|▌         | 9/163 [00:15<03:31,  1.37s/it, loss=2.3380, batch_acc=0.3750, running_acc=0.3086, grad=12.0504]Training epoch 4:   6%|▌         | 9/163 [00:15<03:31,  1.37s/it, loss=2.4047, batch_acc=0.5312, running_acc=0.3333, grad=12.9713]Training epoch 4:   6%|▌         | 10/163 [00:16<03:06,  1.22s/it, loss=2.4047, batch_acc=0.5312, running_acc=0.3333, grad=12.9713]Training epoch 4:   6%|▌         | 10/163 [00:16<03:06,  1.22s/it, loss=2.4240, batch_acc=0.3438, running_acc=0.3344, grad=14.6846]Training epoch 4:   7%|▋         | 11/163 [00:16<02:49,  1.12s/it, loss=2.4240, batch_acc=0.3438, running_acc=0.3344, grad=14.6846]Training epoch 4:   7%|▋         | 11/163 [00:16<02:49,  1.12s/it, loss=2.5515, batch_acc=0.3750, running_acc=0.3381, grad=10.5435]Training epoch 4:   7%|▋         | 12/163 [00:18<03:12,  1.28s/it, loss=2.5515, batch_acc=0.3750, running_acc=0.3381, grad=10.5435]Training epoch 4:   7%|▋         | 12/163 [00:18<03:12,  1.28s/it, loss=2.7527, batch_acc=0.2188, running_acc=0.3281, grad=11.1846]Training epoch 4:   8%|▊         | 13/163 [00:19<02:53,  1.16s/it, loss=2.7527, batch_acc=0.2188, running_acc=0.3281, grad=11.1846]Training epoch 4:   8%|▊         | 13/163 [00:19<02:53,  1.16s/it, loss=2.6967, batch_acc=0.2188, running_acc=0.3197, grad=13.1349]Training epoch 4:   9%|▊         | 14/163 [00:20<02:39,  1.07s/it, loss=2.6967, batch_acc=0.2188, running_acc=0.3197, grad=13.1349]Training epoch 4:   9%|▊         | 14/163 [00:20<02:39,  1.07s/it, loss=2.4663, batch_acc=0.3750, running_acc=0.3237, grad=15.2724]Training epoch 4:   9%|▉         | 15/163 [00:21<02:30,  1.01s/it, loss=2.4663, batch_acc=0.3750, running_acc=0.3237, grad=15.2724]Training epoch 4:   9%|▉         | 15/163 [00:21<02:30,  1.01s/it, loss=2.5932, batch_acc=0.2812, running_acc=0.3208, grad=10.5492]Training epoch 4:  10%|▉         | 16/163 [00:22<02:51,  1.17s/it, loss=2.5932, batch_acc=0.2812, running_acc=0.3208, grad=10.5492]Training epoch 4:  10%|▉         | 16/163 [00:22<02:51,  1.17s/it, loss=2.2191, batch_acc=0.4375, running_acc=0.3281, grad=11.7894]Training epoch 4:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=2.2191, batch_acc=0.4375, running_acc=0.3281, grad=11.7894]Training epoch 4:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=2.7603, batch_acc=0.2500, running_acc=0.3235, grad=17.1953]Training epoch 4:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=2.7603, batch_acc=0.2500, running_acc=0.3235, grad=17.1953]Training epoch 4:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=2.4806, batch_acc=0.3438, running_acc=0.3247, grad=12.1201]Training epoch 4:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=2.4806, batch_acc=0.3438, running_acc=0.3247, grad=12.1201]Training epoch 4:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=2.4181, batch_acc=0.3438, running_acc=0.3257, grad=10.1688]Training epoch 4:  12%|█▏        | 20/163 [00:26<02:38,  1.11s/it, loss=2.4181, batch_acc=0.3438, running_acc=0.3257, grad=10.1688]Training epoch 4:  12%|█▏        | 20/163 [00:26<02:38,  1.11s/it, loss=2.4899, batch_acc=0.3438, running_acc=0.3266, grad=10.7405]Training epoch 4:  13%|█▎        | 21/163 [00:27<02:27,  1.04s/it, loss=2.4899, batch_acc=0.3438, running_acc=0.3266, grad=10.7405]Training epoch 4:  13%|█▎        | 21/163 [00:27<02:27,  1.04s/it, loss=2.7758, batch_acc=0.1875, running_acc=0.3199, grad=14.6831]Training epoch 4:  13%|█▎        | 22/163 [00:28<02:19,  1.01it/s, loss=2.7758, batch_acc=0.1875, running_acc=0.3199, grad=14.6831]Training epoch 4:  13%|█▎        | 22/163 [00:28<02:19,  1.01it/s, loss=2.1214, batch_acc=0.5000, running_acc=0.3281, grad=10.0887]Training epoch 4:  14%|█▍        | 23/163 [00:29<02:15,  1.04it/s, loss=2.1214, batch_acc=0.5000, running_acc=0.3281, grad=10.0887]Training epoch 4:  14%|█▍        | 23/163 [00:29<02:15,  1.04it/s, loss=2.5239, batch_acc=0.2812, running_acc=0.3261, grad=11.1350]Training epoch 4:  15%|█▍        | 24/163 [00:31<03:04,  1.33s/it, loss=2.5239, batch_acc=0.2812, running_acc=0.3261, grad=11.1350]Training epoch 4:  15%|█▍        | 24/163 [00:31<03:04,  1.33s/it, loss=2.5730, batch_acc=0.3750, running_acc=0.3281, grad=14.2599]Training epoch 4:  15%|█▌        | 25/163 [00:32<02:44,  1.19s/it, loss=2.5730, batch_acc=0.3750, running_acc=0.3281, grad=14.2599]Training epoch 4:  15%|█▌        | 25/163 [00:32<02:44,  1.19s/it, loss=2.6126, batch_acc=0.3438, running_acc=0.3287, grad=15.1820]Training epoch 4:  16%|█▌        | 26/163 [00:33<02:30,  1.10s/it, loss=2.6126, batch_acc=0.3438, running_acc=0.3287, grad=15.1820]Training epoch 4:  16%|█▌        | 26/163 [00:33<02:30,  1.10s/it, loss=2.6595, batch_acc=0.3438, running_acc=0.3293, grad=25.5212]Training epoch 4:  17%|█▋        | 27/163 [00:34<02:21,  1.04s/it, loss=2.6595, batch_acc=0.3438, running_acc=0.3293, grad=25.5212]Training epoch 4:  17%|█▋        | 27/163 [00:34<02:21,  1.04s/it, loss=3.0129, batch_acc=0.0938, running_acc=0.3206, grad=17.8571]Training epoch 4:  17%|█▋        | 28/163 [00:35<02:46,  1.23s/it, loss=3.0129, batch_acc=0.0938, running_acc=0.3206, grad=17.8571]Training epoch 4:  17%|█▋        | 28/163 [00:35<02:46,  1.23s/it, loss=2.3801, batch_acc=0.3438, running_acc=0.3214, grad=22.9458]Training epoch 4:  18%|█▊        | 29/163 [00:36<02:30,  1.12s/it, loss=2.3801, batch_acc=0.3438, running_acc=0.3214, grad=22.9458]Training epoch 4:  18%|█▊        | 29/163 [00:36<02:30,  1.12s/it, loss=2.4654, batch_acc=0.2500, running_acc=0.3190, grad=18.7249]Training epoch 4:  18%|█▊        | 30/163 [00:37<02:19,  1.05s/it, loss=2.4654, batch_acc=0.2500, running_acc=0.3190, grad=18.7249]Training epoch 4:  18%|█▊        | 30/163 [00:37<02:19,  1.05s/it, loss=2.4675, batch_acc=0.4062, running_acc=0.3219, grad=11.0670]Training epoch 4:  19%|█▉        | 31/163 [00:38<02:11,  1.00it/s, loss=2.4675, batch_acc=0.4062, running_acc=0.3219, grad=11.0670]Training epoch 4:  19%|█▉        | 31/163 [00:38<02:11,  1.00it/s, loss=2.4211, batch_acc=0.4062, running_acc=0.3246, grad=13.6592]Training epoch 4:  20%|█▉        | 32/163 [00:40<02:32,  1.16s/it, loss=2.4211, batch_acc=0.4062, running_acc=0.3246, grad=13.6592]Training epoch 4:  20%|█▉        | 32/163 [00:40<02:32,  1.16s/it, loss=2.5617, batch_acc=0.3438, running_acc=0.3252, grad=13.5520]Training epoch 4:  20%|██        | 33/163 [00:41<02:19,  1.08s/it, loss=2.5617, batch_acc=0.3438, running_acc=0.3252, grad=13.5520]Training epoch 4:  20%|██        | 33/163 [00:41<02:19,  1.08s/it, loss=2.7006, batch_acc=0.3750, running_acc=0.3267, grad=10.7982]Training epoch 4:  21%|██        | 34/163 [00:41<02:11,  1.02s/it, loss=2.7006, batch_acc=0.3750, running_acc=0.3267, grad=10.7982]Training epoch 4:  21%|██        | 34/163 [00:41<02:11,  1.02s/it, loss=2.5681, batch_acc=0.3750, running_acc=0.3281, grad=16.8550]Training epoch 4:  21%|██▏       | 35/163 [00:42<02:04,  1.03it/s, loss=2.5681, batch_acc=0.3750, running_acc=0.3281, grad=16.8550]Training epoch 4:  21%|██▏       | 35/163 [00:42<02:04,  1.03it/s, loss=2.5532, batch_acc=0.3125, running_acc=0.3277, grad=9.8060] Training epoch 4:  22%|██▏       | 36/163 [00:44<02:15,  1.07s/it, loss=2.5532, batch_acc=0.3125, running_acc=0.3277, grad=9.8060]Training epoch 4:  22%|██▏       | 36/163 [00:44<02:15,  1.07s/it, loss=2.6607, batch_acc=0.3125, running_acc=0.3273, grad=11.6914]Training epoch 4:  23%|██▎       | 37/163 [00:44<02:07,  1.01s/it, loss=2.6607, batch_acc=0.3125, running_acc=0.3273, grad=11.6914]Training epoch 4:  23%|██▎       | 37/163 [00:44<02:07,  1.01s/it, loss=2.7202, batch_acc=0.2500, running_acc=0.3252, grad=10.9604]Training epoch 4:  23%|██▎       | 38/163 [00:45<02:04,  1.01it/s, loss=2.7202, batch_acc=0.2500, running_acc=0.3252, grad=10.9604]Training epoch 4:  23%|██▎       | 38/163 [00:45<02:04,  1.01it/s, loss=2.7075, batch_acc=0.2812, running_acc=0.3240, grad=10.7326]Training epoch 4:  24%|██▍       | 39/163 [00:46<01:59,  1.04it/s, loss=2.7075, batch_acc=0.2812, running_acc=0.3240, grad=10.7326]Training epoch 4:  24%|██▍       | 39/163 [00:46<01:59,  1.04it/s, loss=1.9976, batch_acc=0.6250, running_acc=0.3317, grad=8.8109] Training epoch 4:  25%|██▍       | 40/163 [00:48<02:35,  1.26s/it, loss=1.9976, batch_acc=0.6250, running_acc=0.3317, grad=8.8109]Training epoch 4:  25%|██▍       | 40/163 [00:48<02:35,  1.26s/it, loss=2.4062, batch_acc=0.3750, running_acc=0.3328, grad=10.5308]Training epoch 4:  25%|██▌       | 41/163 [00:49<02:19,  1.15s/it, loss=2.4062, batch_acc=0.3750, running_acc=0.3328, grad=10.5308]Training epoch 4:  25%|██▌       | 41/163 [00:49<02:19,  1.15s/it, loss=2.4723, batch_acc=0.3125, running_acc=0.3323, grad=9.7726] Training epoch 4:  26%|██▌       | 42/163 [00:50<02:08,  1.07s/it, loss=2.4723, batch_acc=0.3125, running_acc=0.3323, grad=9.7726]Training epoch 4:  26%|██▌       | 42/163 [00:50<02:08,  1.07s/it, loss=2.7348, batch_acc=0.3438, running_acc=0.3326, grad=11.2005]Training epoch 4:  26%|██▋       | 43/163 [00:51<02:01,  1.01s/it, loss=2.7348, batch_acc=0.3438, running_acc=0.3326, grad=11.2005]Training epoch 4:  26%|██▋       | 43/163 [00:51<02:01,  1.01s/it, loss=2.7443, batch_acc=0.2188, running_acc=0.3299, grad=12.5707]Training epoch 4:  27%|██▋       | 44/163 [00:53<02:30,  1.26s/it, loss=2.7443, batch_acc=0.2188, running_acc=0.3299, grad=12.5707]Training epoch 4:  27%|██▋       | 44/163 [00:53<02:30,  1.26s/it, loss=2.7120, batch_acc=0.2812, running_acc=0.3288, grad=17.6466]Training epoch 4:  28%|██▊       | 45/163 [00:54<02:15,  1.15s/it, loss=2.7120, batch_acc=0.2812, running_acc=0.3288, grad=17.6466]Training epoch 4:  28%|██▊       | 45/163 [00:54<02:15,  1.15s/it, loss=2.6911, batch_acc=0.2500, running_acc=0.3271, grad=11.6013]Training epoch 4:  28%|██▊       | 46/163 [00:55<02:04,  1.07s/it, loss=2.6911, batch_acc=0.2500, running_acc=0.3271, grad=11.6013]Training epoch 4:  28%|██▊       | 46/163 [00:55<02:04,  1.07s/it, loss=2.1402, batch_acc=0.5312, running_acc=0.3315, grad=10.4659]Training epoch 4:  29%|██▉       | 47/163 [00:55<01:57,  1.01s/it, loss=2.1402, batch_acc=0.5312, running_acc=0.3315, grad=10.4659]Training epoch 4:  29%|██▉       | 47/163 [00:55<01:57,  1.01s/it, loss=2.6829, batch_acc=0.3438, running_acc=0.3318, grad=10.6139]Training epoch 4:  29%|██▉       | 48/163 [00:57<02:23,  1.25s/it, loss=2.6829, batch_acc=0.3438, running_acc=0.3318, grad=10.6139]Training epoch 4:  29%|██▉       | 48/163 [00:57<02:23,  1.25s/it, loss=2.6190, batch_acc=0.3125, running_acc=0.3314, grad=11.1396]Training epoch 4:  30%|███       | 49/163 [00:58<02:09,  1.14s/it, loss=2.6190, batch_acc=0.3125, running_acc=0.3314, grad=11.1396]Training epoch 4:  30%|███       | 49/163 [00:58<02:09,  1.14s/it, loss=2.5334, batch_acc=0.4688, running_acc=0.3342, grad=9.5529] Training epoch 4:  31%|███       | 50/163 [00:59<01:59,  1.06s/it, loss=2.5334, batch_acc=0.4688, running_acc=0.3342, grad=9.5529]Training epoch 4:  31%|███       | 50/163 [00:59<01:59,  1.06s/it, loss=2.3672, batch_acc=0.4062, running_acc=0.3356, grad=9.5393]Training epoch 4:  31%|███▏      | 51/163 [01:00<01:52,  1.00s/it, loss=2.3672, batch_acc=0.4062, running_acc=0.3356, grad=9.5393]Training epoch 4:  31%|███▏      | 51/163 [01:00<01:52,  1.00s/it, loss=2.4819, batch_acc=0.3125, running_acc=0.3352, grad=12.7945]Training epoch 4:  32%|███▏      | 52/163 [01:01<02:03,  1.12s/it, loss=2.4819, batch_acc=0.3125, running_acc=0.3352, grad=12.7945]Training epoch 4:  32%|███▏      | 52/163 [01:01<02:03,  1.12s/it, loss=2.4592, batch_acc=0.4375, running_acc=0.3371, grad=14.1870]Training epoch 4:  33%|███▎      | 53/163 [01:02<01:54,  1.04s/it, loss=2.4592, batch_acc=0.4375, running_acc=0.3371, grad=14.1870]Training epoch 4:  33%|███▎      | 53/163 [01:02<01:54,  1.04s/it, loss=2.8443, batch_acc=0.2812, running_acc=0.3361, grad=10.5038]Training epoch 4:  33%|███▎      | 54/163 [01:03<01:48,  1.01it/s, loss=2.8443, batch_acc=0.2812, running_acc=0.3361, grad=10.5038]Training epoch 4:  33%|███▎      | 54/163 [01:03<01:48,  1.01it/s, loss=2.2922, batch_acc=0.4375, running_acc=0.3380, grad=12.8375]Training epoch 4:  34%|███▎      | 55/163 [01:04<01:43,  1.04it/s, loss=2.2922, batch_acc=0.4375, running_acc=0.3380, grad=12.8375]Training epoch 4:  34%|███▎      | 55/163 [01:04<01:43,  1.04it/s, loss=2.6096, batch_acc=0.3438, running_acc=0.3381, grad=10.2303]Training epoch 4:  34%|███▍      | 56/163 [01:06<02:25,  1.36s/it, loss=2.6096, batch_acc=0.3438, running_acc=0.3381, grad=10.2303]Training epoch 4:  34%|███▍      | 56/163 [01:06<02:25,  1.36s/it, loss=2.4690, batch_acc=0.4062, running_acc=0.3393, grad=12.7243]Training epoch 4:  35%|███▍      | 57/163 [01:07<02:08,  1.22s/it, loss=2.4690, batch_acc=0.4062, running_acc=0.3393, grad=12.7243]Training epoch 4:  35%|███▍      | 57/163 [01:07<02:08,  1.22s/it, loss=2.5006, batch_acc=0.2500, running_acc=0.3377, grad=10.0900]Training epoch 4:  36%|███▌      | 58/163 [01:08<02:00,  1.15s/it, loss=2.5006, batch_acc=0.2500, running_acc=0.3377, grad=10.0900]Training epoch 4:  36%|███▌      | 58/163 [01:08<02:00,  1.15s/it, loss=2.6796, batch_acc=0.2188, running_acc=0.3357, grad=11.6980]Training epoch 4:  36%|███▌      | 59/163 [01:09<01:50,  1.07s/it, loss=2.6796, batch_acc=0.2188, running_acc=0.3357, grad=11.6980]Training epoch 4:  36%|███▌      | 59/163 [01:09<01:50,  1.07s/it, loss=2.8613, batch_acc=0.3125, running_acc=0.3353, grad=12.8065]Training epoch 4:  37%|███▋      | 60/163 [01:11<02:14,  1.31s/it, loss=2.8613, batch_acc=0.3125, running_acc=0.3353, grad=12.8065]Training epoch 4:  37%|███▋      | 60/163 [01:11<02:14,  1.31s/it, loss=2.4984, batch_acc=0.3438, running_acc=0.3354, grad=16.3708]Training epoch 4:  37%|███▋      | 61/163 [01:12<02:00,  1.18s/it, loss=2.4984, batch_acc=0.3438, running_acc=0.3354, grad=16.3708]Training epoch 4:  37%|███▋      | 61/163 [01:12<02:00,  1.18s/it, loss=2.3119, batch_acc=0.4062, running_acc=0.3366, grad=11.3196]Training epoch 4:  38%|███▊      | 62/163 [01:12<01:49,  1.09s/it, loss=2.3119, batch_acc=0.4062, running_acc=0.3366, grad=11.3196]Training epoch 4:  38%|███▊      | 62/163 [01:12<01:49,  1.09s/it, loss=2.3814, batch_acc=0.3750, running_acc=0.3372, grad=10.2917]Training epoch 4:  39%|███▊      | 63/163 [01:13<01:42,  1.02s/it, loss=2.3814, batch_acc=0.3750, running_acc=0.3372, grad=10.2917]Training epoch 4:  39%|███▊      | 63/163 [01:13<01:42,  1.02s/it, loss=2.7432, batch_acc=0.2812, running_acc=0.3363, grad=12.2926]Training epoch 4:  39%|███▉      | 64/163 [01:15<01:50,  1.11s/it, loss=2.7432, batch_acc=0.2812, running_acc=0.3363, grad=12.2926]Training epoch 4:  39%|███▉      | 64/163 [01:15<01:50,  1.11s/it, loss=2.4384, batch_acc=0.5000, running_acc=0.3389, grad=11.5174]Training epoch 4:  40%|███▉      | 65/163 [01:16<01:42,  1.04s/it, loss=2.4384, batch_acc=0.5000, running_acc=0.3389, grad=11.5174]Training epoch 4:  40%|███▉      | 65/163 [01:16<01:42,  1.04s/it, loss=2.5668, batch_acc=0.4062, running_acc=0.3399, grad=11.0800]Training epoch 4:  40%|████      | 66/163 [01:16<01:36,  1.00it/s, loss=2.5668, batch_acc=0.4062, running_acc=0.3399, grad=11.0800]Training epoch 4:  40%|████      | 66/163 [01:16<01:36,  1.00it/s, loss=2.4369, batch_acc=0.3125, running_acc=0.3395, grad=10.8427]Training epoch 4:  41%|████      | 67/163 [01:17<01:32,  1.04it/s, loss=2.4369, batch_acc=0.3125, running_acc=0.3395, grad=10.8427]Training epoch 4:  41%|████      | 67/163 [01:17<01:32,  1.04it/s, loss=2.1457, batch_acc=0.4375, running_acc=0.3410, grad=14.5670]Training epoch 4:  42%|████▏     | 68/163 [01:18<01:35,  1.00s/it, loss=2.1457, batch_acc=0.4375, running_acc=0.3410, grad=14.5670]Training epoch 4:  42%|████▏     | 68/163 [01:18<01:35,  1.00s/it, loss=2.6431, batch_acc=0.3125, running_acc=0.3405, grad=14.6039]Training epoch 4:  42%|████▏     | 69/163 [01:19<01:30,  1.04it/s, loss=2.6431, batch_acc=0.3125, running_acc=0.3405, grad=14.6039]Training epoch 4:  42%|████▏     | 69/163 [01:19<01:30,  1.04it/s, loss=2.5120, batch_acc=0.3438, running_acc=0.3406, grad=12.2077]Training epoch 4:  43%|████▎     | 70/163 [01:20<01:27,  1.06it/s, loss=2.5120, batch_acc=0.3438, running_acc=0.3406, grad=12.2077]Training epoch 4:  43%|████▎     | 70/163 [01:20<01:27,  1.06it/s, loss=2.2824, batch_acc=0.4375, running_acc=0.3420, grad=14.8444]Training epoch 4:  44%|████▎     | 71/163 [01:21<01:24,  1.08it/s, loss=2.2824, batch_acc=0.4375, running_acc=0.3420, grad=14.8444]Training epoch 4:  44%|████▎     | 71/163 [01:21<01:24,  1.08it/s, loss=2.6535, batch_acc=0.3438, running_acc=0.3420, grad=14.5585]Training epoch 4:  44%|████▍     | 72/163 [01:23<01:38,  1.08s/it, loss=2.6535, batch_acc=0.3438, running_acc=0.3420, grad=14.5585]Training epoch 4:  44%|████▍     | 72/163 [01:23<01:38,  1.08s/it, loss=2.3500, batch_acc=0.4688, running_acc=0.3438, grad=19.9326]Training epoch 4:  45%|████▍     | 73/163 [01:23<01:31,  1.02s/it, loss=2.3500, batch_acc=0.4688, running_acc=0.3438, grad=19.9326]Training epoch 4:  45%|████▍     | 73/163 [01:23<01:31,  1.02s/it, loss=2.0148, batch_acc=0.5625, running_acc=0.3467, grad=10.3104]Training epoch 4:  45%|████▌     | 74/163 [01:24<01:27,  1.02it/s, loss=2.0148, batch_acc=0.5625, running_acc=0.3467, grad=10.3104]Training epoch 4:  45%|████▌     | 74/163 [01:24<01:27,  1.02it/s, loss=2.2184, batch_acc=0.4688, running_acc=0.3484, grad=18.9673]Training epoch 4:  46%|████▌     | 75/163 [01:25<01:23,  1.05it/s, loss=2.2184, batch_acc=0.4688, running_acc=0.3484, grad=18.9673]Training epoch 4:  46%|████▌     | 75/163 [01:25<01:23,  1.05it/s, loss=2.3572, batch_acc=0.4688, running_acc=0.3500, grad=17.2917]Training epoch 4:  47%|████▋     | 76/163 [01:27<01:37,  1.12s/it, loss=2.3572, batch_acc=0.4688, running_acc=0.3500, grad=17.2917]Training epoch 4:  47%|████▋     | 76/163 [01:27<01:37,  1.12s/it, loss=2.6142, batch_acc=0.3125, running_acc=0.3495, grad=11.0270]Training epoch 4:  47%|████▋     | 77/163 [01:28<01:30,  1.05s/it, loss=2.6142, batch_acc=0.3125, running_acc=0.3495, grad=11.0270]Training epoch 4:  47%|████▋     | 77/163 [01:28<01:30,  1.05s/it, loss=2.4710, batch_acc=0.3125, running_acc=0.3490, grad=10.9213]Training epoch 4:  48%|████▊     | 78/163 [01:29<01:26,  1.02s/it, loss=2.4710, batch_acc=0.3125, running_acc=0.3490, grad=10.9213]Training epoch 4:  48%|████▊     | 78/163 [01:29<01:26,  1.02s/it, loss=2.5336, batch_acc=0.2812, running_acc=0.3482, grad=9.3264] Training epoch 4:  48%|████▊     | 79/163 [01:29<01:21,  1.03it/s, loss=2.5336, batch_acc=0.2812, running_acc=0.3482, grad=9.3264]Training epoch 4:  48%|████▊     | 79/163 [01:29<01:21,  1.03it/s, loss=2.7864, batch_acc=0.3125, running_acc=0.3477, grad=16.9439]Training epoch 4:  49%|████▉     | 80/163 [01:31<01:43,  1.25s/it, loss=2.7864, batch_acc=0.3125, running_acc=0.3477, grad=16.9439]Training epoch 4:  49%|████▉     | 80/163 [01:31<01:43,  1.25s/it, loss=2.4044, batch_acc=0.3750, running_acc=0.3480, grad=19.7963]Training epoch 4:  50%|████▉     | 81/163 [01:32<01:33,  1.14s/it, loss=2.4044, batch_acc=0.3750, running_acc=0.3480, grad=19.7963]Training epoch 4:  50%|████▉     | 81/163 [01:32<01:33,  1.14s/it, loss=2.6622, batch_acc=0.2500, running_acc=0.3468, grad=11.4957]Training epoch 4:  50%|█████     | 82/163 [01:33<01:26,  1.06s/it, loss=2.6622, batch_acc=0.2500, running_acc=0.3468, grad=11.4957]Training epoch 4:  50%|█████     | 82/163 [01:33<01:26,  1.06s/it, loss=2.3375, batch_acc=0.3438, running_acc=0.3468, grad=11.9578]Training epoch 4:  51%|█████     | 83/163 [01:34<01:20,  1.01s/it, loss=2.3375, batch_acc=0.3438, running_acc=0.3468, grad=11.9578]Training epoch 4:  51%|█████     | 83/163 [01:34<01:20,  1.01s/it, loss=2.3070, batch_acc=0.4375, running_acc=0.3479, grad=16.8544]Training epoch 4:  52%|█████▏    | 84/163 [01:35<01:30,  1.15s/it, loss=2.3070, batch_acc=0.4375, running_acc=0.3479, grad=16.8544]Training epoch 4:  52%|█████▏    | 84/163 [01:35<01:30,  1.15s/it, loss=2.4043, batch_acc=0.4062, running_acc=0.3486, grad=17.4013]Training epoch 4:  52%|█████▏    | 85/163 [01:36<01:23,  1.07s/it, loss=2.4043, batch_acc=0.4062, running_acc=0.3486, grad=17.4013]Training epoch 4:  52%|█████▏    | 85/163 [01:36<01:23,  1.07s/it, loss=2.3739, batch_acc=0.3438, running_acc=0.3485, grad=12.8826]Training epoch 4:  53%|█████▎    | 86/163 [01:37<01:17,  1.01s/it, loss=2.3739, batch_acc=0.3438, running_acc=0.3485, grad=12.8826]Training epoch 4:  53%|█████▎    | 86/163 [01:37<01:17,  1.01s/it, loss=2.5481, batch_acc=0.2500, running_acc=0.3474, grad=11.8798]Training epoch 4:  53%|█████▎    | 87/163 [01:38<01:13,  1.03it/s, loss=2.5481, batch_acc=0.2500, running_acc=0.3474, grad=11.8798]Training epoch 4:  53%|█████▎    | 87/163 [01:38<01:13,  1.03it/s, loss=2.1984, batch_acc=0.4375, running_acc=0.3484, grad=17.3659]Training epoch 4:  54%|█████▍    | 88/163 [01:39<01:23,  1.11s/it, loss=2.1984, batch_acc=0.4375, running_acc=0.3484, grad=17.3659]Training epoch 4:  54%|█████▍    | 88/163 [01:39<01:23,  1.11s/it, loss=2.3799, batch_acc=0.4062, running_acc=0.3491, grad=10.9602]Training epoch 4:  55%|█████▍    | 89/163 [01:40<01:16,  1.04s/it, loss=2.3799, batch_acc=0.4062, running_acc=0.3491, grad=10.9602]Training epoch 4:  55%|█████▍    | 89/163 [01:40<01:16,  1.04s/it, loss=2.5233, batch_acc=0.3750, running_acc=0.3494, grad=17.0475]Training epoch 4:  55%|█████▌    | 90/163 [01:41<01:12,  1.01it/s, loss=2.5233, batch_acc=0.3750, running_acc=0.3494, grad=17.0475]Training epoch 4:  55%|█████▌    | 90/163 [01:41<01:12,  1.01it/s, loss=2.3808, batch_acc=0.2812, running_acc=0.3486, grad=9.9711] Training epoch 4:  56%|█████▌    | 91/163 [01:42<01:08,  1.05it/s, loss=2.3808, batch_acc=0.2812, running_acc=0.3486, grad=9.9711]Training epoch 4:  56%|█████▌    | 91/163 [01:42<01:08,  1.05it/s, loss=2.5200, batch_acc=0.3750, running_acc=0.3489, grad=13.5587]Training epoch 4:  56%|█████▋    | 92/163 [01:44<01:23,  1.17s/it, loss=2.5200, batch_acc=0.3750, running_acc=0.3489, grad=13.5587]Training epoch 4:  56%|█████▋    | 92/163 [01:44<01:23,  1.17s/it, loss=2.2911, batch_acc=0.4375, running_acc=0.3499, grad=9.8874] Training epoch 4:  57%|█████▋    | 93/163 [01:45<01:15,  1.08s/it, loss=2.2911, batch_acc=0.4375, running_acc=0.3499, grad=9.8874]Training epoch 4:  57%|█████▋    | 93/163 [01:45<01:15,  1.08s/it, loss=2.6683, batch_acc=0.2812, running_acc=0.3491, grad=15.5037]Training epoch 4:  58%|█████▊    | 94/163 [01:46<01:10,  1.02s/it, loss=2.6683, batch_acc=0.2812, running_acc=0.3491, grad=15.5037]Training epoch 4:  58%|█████▊    | 94/163 [01:46<01:10,  1.02s/it, loss=2.4311, batch_acc=0.3750, running_acc=0.3494, grad=11.6514]Training epoch 4:  58%|█████▊    | 95/163 [01:46<01:06,  1.02it/s, loss=2.4311, batch_acc=0.3750, running_acc=0.3494, grad=11.6514]Training epoch 4:  58%|█████▊    | 95/163 [01:46<01:06,  1.02it/s, loss=2.3726, batch_acc=0.3750, running_acc=0.3497, grad=12.9411]Training epoch 4:  59%|█████▉    | 96/163 [01:48<01:22,  1.22s/it, loss=2.3726, batch_acc=0.3750, running_acc=0.3497, grad=12.9411]Training epoch 4:  59%|█████▉    | 96/163 [01:48<01:22,  1.22s/it, loss=2.1713, batch_acc=0.3750, running_acc=0.3499, grad=12.1348]Training epoch 4:  60%|█████▉    | 97/163 [01:49<01:13,  1.12s/it, loss=2.1713, batch_acc=0.3750, running_acc=0.3499, grad=12.1348]Training epoch 4:  60%|█████▉    | 97/163 [01:49<01:13,  1.12s/it, loss=2.7985, batch_acc=0.3125, running_acc=0.3495, grad=13.9597]Training epoch 4:  60%|██████    | 98/163 [01:50<01:08,  1.05s/it, loss=2.7985, batch_acc=0.3125, running_acc=0.3495, grad=13.9597]Training epoch 4:  60%|██████    | 98/163 [01:50<01:08,  1.05s/it, loss=2.1310, batch_acc=0.3750, running_acc=0.3498, grad=14.0362]Training epoch 4:  61%|██████    | 99/163 [01:51<01:03,  1.00it/s, loss=2.1310, batch_acc=0.3750, running_acc=0.3498, grad=14.0362]Training epoch 4:  61%|██████    | 99/163 [01:51<01:03,  1.00it/s, loss=2.3678, batch_acc=0.3750, running_acc=0.3501, grad=12.5295]Training epoch 4:  61%|██████▏   | 100/163 [01:52<01:11,  1.13s/it, loss=2.3678, batch_acc=0.3750, running_acc=0.3501, grad=12.5295]Training epoch 4:  61%|██████▏   | 100/163 [01:52<01:11,  1.13s/it, loss=2.3376, batch_acc=0.5000, running_acc=0.3516, grad=12.4071]Training epoch 4:  62%|██████▏   | 101/163 [01:53<01:05,  1.05s/it, loss=2.3376, batch_acc=0.5000, running_acc=0.3516, grad=12.4071]Training epoch 4:  62%|██████▏   | 101/163 [01:53<01:05,  1.05s/it, loss=2.8593, batch_acc=0.2812, running_acc=0.3509, grad=10.0895]Training epoch 4:  63%|██████▎   | 102/163 [01:54<01:01,  1.00s/it, loss=2.8593, batch_acc=0.2812, running_acc=0.3509, grad=10.0895]Training epoch 4:  63%|██████▎   | 102/163 [01:54<01:01,  1.00s/it, loss=2.4596, batch_acc=0.3750, running_acc=0.3511, grad=12.5472]Training epoch 4:  63%|██████▎   | 103/163 [01:55<00:57,  1.04it/s, loss=2.4596, batch_acc=0.3750, running_acc=0.3511, grad=12.5472]Training epoch 4:  63%|██████▎   | 103/163 [01:55<00:57,  1.04it/s, loss=1.9682, batch_acc=0.5625, running_acc=0.3532, grad=9.4101] Training epoch 4:  64%|██████▍   | 104/163 [01:57<01:11,  1.22s/it, loss=1.9682, batch_acc=0.5625, running_acc=0.3532, grad=9.4101]Training epoch 4:  64%|██████▍   | 104/163 [01:57<01:11,  1.22s/it, loss=2.5413, batch_acc=0.4062, running_acc=0.3537, grad=10.6736]Training epoch 4:  64%|██████▍   | 105/163 [01:58<01:04,  1.11s/it, loss=2.5413, batch_acc=0.4062, running_acc=0.3537, grad=10.6736]Training epoch 4:  64%|██████▍   | 105/163 [01:58<01:04,  1.11s/it, loss=2.2385, batch_acc=0.3750, running_acc=0.3539, grad=12.5009]Training epoch 4:  65%|██████▌   | 106/163 [01:58<00:59,  1.04s/it, loss=2.2385, batch_acc=0.3750, running_acc=0.3539, grad=12.5009]Training epoch 4:  65%|██████▌   | 106/163 [01:58<00:59,  1.04s/it, loss=2.4495, batch_acc=0.4688, running_acc=0.3550, grad=13.5528]Training epoch 4:  66%|██████▌   | 107/163 [01:59<00:55,  1.01it/s, loss=2.4495, batch_acc=0.4688, running_acc=0.3550, grad=13.5528]Training epoch 4:  66%|██████▌   | 107/163 [01:59<00:55,  1.01it/s, loss=2.1619, batch_acc=0.3750, running_acc=0.3551, grad=9.9505] Training epoch 4:  66%|██████▋   | 108/163 [02:01<01:11,  1.31s/it, loss=2.1619, batch_acc=0.3750, running_acc=0.3551, grad=9.9505]Training epoch 4:  66%|██████▋   | 108/163 [02:01<01:11,  1.31s/it, loss=2.3594, batch_acc=0.3750, running_acc=0.3553, grad=13.1355]Training epoch 4:  67%|██████▋   | 109/163 [02:02<01:03,  1.18s/it, loss=2.3594, batch_acc=0.3750, running_acc=0.3553, grad=13.1355]Training epoch 4:  67%|██████▋   | 109/163 [02:02<01:03,  1.18s/it, loss=2.6254, batch_acc=0.2188, running_acc=0.3541, grad=13.5133]Training epoch 4:  67%|██████▋   | 110/163 [02:03<00:57,  1.09s/it, loss=2.6254, batch_acc=0.2188, running_acc=0.3541, grad=13.5133]Training epoch 4:  67%|██████▋   | 110/163 [02:03<00:57,  1.09s/it, loss=2.6219, batch_acc=0.2812, running_acc=0.3534, grad=15.9135]Training epoch 4:  68%|██████▊   | 111/163 [02:04<00:53,  1.02s/it, loss=2.6219, batch_acc=0.2812, running_acc=0.3534, grad=15.9135]Training epoch 4:  68%|██████▊   | 111/163 [02:04<00:53,  1.02s/it, loss=2.1983, batch_acc=0.4375, running_acc=0.3542, grad=14.1893]Training epoch 4:  69%|██████▊   | 112/163 [02:06<01:04,  1.27s/it, loss=2.1983, batch_acc=0.4375, running_acc=0.3542, grad=14.1893]Training epoch 4:  69%|██████▊   | 112/163 [02:06<01:04,  1.27s/it, loss=2.4832, batch_acc=0.3125, running_acc=0.3538, grad=10.9498]Training epoch 4:  69%|██████▉   | 113/163 [02:07<00:57,  1.15s/it, loss=2.4832, batch_acc=0.3125, running_acc=0.3538, grad=10.9498]Training epoch 4:  69%|██████▉   | 113/163 [02:07<00:57,  1.15s/it, loss=2.2223, batch_acc=0.3750, running_acc=0.3540, grad=16.3432]Training epoch 4:  70%|██████▉   | 114/163 [02:08<00:52,  1.07s/it, loss=2.2223, batch_acc=0.3750, running_acc=0.3540, grad=16.3432]Training epoch 4:  70%|██████▉   | 114/163 [02:08<00:52,  1.07s/it, loss=2.7878, batch_acc=0.3750, running_acc=0.3542, grad=11.9404]Training epoch 4:  71%|███████   | 115/163 [02:08<00:48,  1.01s/it, loss=2.7878, batch_acc=0.3750, running_acc=0.3542, grad=11.9404]Training epoch 4:  71%|███████   | 115/163 [02:08<00:48,  1.01s/it, loss=2.2265, batch_acc=0.5000, running_acc=0.3554, grad=10.8715]Training epoch 4:  71%|███████   | 116/163 [02:10<00:59,  1.26s/it, loss=2.2265, batch_acc=0.5000, running_acc=0.3554, grad=10.8715]Training epoch 4:  71%|███████   | 116/163 [02:10<00:59,  1.26s/it, loss=2.6284, batch_acc=0.3750, running_acc=0.3556, grad=13.2754]Training epoch 4:  72%|███████▏  | 117/163 [02:11<00:52,  1.15s/it, loss=2.6284, batch_acc=0.3750, running_acc=0.3556, grad=13.2754]Training epoch 4:  72%|███████▏  | 117/163 [02:11<00:52,  1.15s/it, loss=2.5090, batch_acc=0.3750, running_acc=0.3558, grad=10.9770]Training epoch 4:  72%|███████▏  | 118/163 [02:12<00:47,  1.07s/it, loss=2.5090, batch_acc=0.3750, running_acc=0.3558, grad=10.9770]Training epoch 4:  72%|███████▏  | 118/163 [02:12<00:47,  1.07s/it, loss=2.4361, batch_acc=0.2812, running_acc=0.3551, grad=10.8563]Training epoch 4:  73%|███████▎  | 119/163 [02:13<00:44,  1.01s/it, loss=2.4361, batch_acc=0.2812, running_acc=0.3551, grad=10.8563]Training epoch 4:  73%|███████▎  | 119/163 [02:13<00:44,  1.01s/it, loss=1.9441, batch_acc=0.5312, running_acc=0.3566, grad=10.7321]Training epoch 4:  74%|███████▎  | 120/163 [02:14<00:47,  1.11s/it, loss=1.9441, batch_acc=0.5312, running_acc=0.3566, grad=10.7321]Training epoch 4:  74%|███████▎  | 120/163 [02:14<00:47,  1.11s/it, loss=2.5778, batch_acc=0.2500, running_acc=0.3557, grad=11.9314]Training epoch 4:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=2.5778, batch_acc=0.2500, running_acc=0.3557, grad=11.9314]Training epoch 4:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=2.4049, batch_acc=0.4062, running_acc=0.3561, grad=10.3836]Training epoch 4:  75%|███████▍  | 122/163 [02:16<00:40,  1.01it/s, loss=2.4049, batch_acc=0.4062, running_acc=0.3561, grad=10.3836]Training epoch 4:  75%|███████▍  | 122/163 [02:16<00:40,  1.01it/s, loss=2.4632, batch_acc=0.3438, running_acc=0.3560, grad=13.3301]Training epoch 4:  75%|███████▌  | 123/163 [02:17<00:38,  1.04it/s, loss=2.4632, batch_acc=0.3438, running_acc=0.3560, grad=13.3301]Training epoch 4:  75%|███████▌  | 123/163 [02:17<00:38,  1.04it/s, loss=2.6319, batch_acc=0.2500, running_acc=0.3552, grad=14.9325]Training epoch 4:  76%|███████▌  | 124/163 [02:19<00:44,  1.14s/it, loss=2.6319, batch_acc=0.2500, running_acc=0.3552, grad=14.9325]Training epoch 4:  76%|███████▌  | 124/163 [02:19<00:44,  1.14s/it, loss=2.4857, batch_acc=0.2812, running_acc=0.3546, grad=10.3912]Training epoch 4:  77%|███████▋  | 125/163 [02:19<00:40,  1.06s/it, loss=2.4857, batch_acc=0.2812, running_acc=0.3546, grad=10.3912]Training epoch 4:  77%|███████▋  | 125/163 [02:19<00:40,  1.06s/it, loss=2.2646, batch_acc=0.4062, running_acc=0.3550, grad=13.0511]Training epoch 4:  77%|███████▋  | 126/163 [02:20<00:38,  1.04s/it, loss=2.2646, batch_acc=0.4062, running_acc=0.3550, grad=13.0511]Training epoch 4:  77%|███████▋  | 126/163 [02:20<00:38,  1.04s/it, loss=2.0850, batch_acc=0.6250, running_acc=0.3571, grad=11.2664]Training epoch 4:  78%|███████▊  | 127/163 [02:21<00:35,  1.01it/s, loss=2.0850, batch_acc=0.6250, running_acc=0.3571, grad=11.2664]Training epoch 4:  78%|███████▊  | 127/163 [02:21<00:35,  1.01it/s, loss=2.4437, batch_acc=0.3750, running_acc=0.3573, grad=14.3616]Training epoch 4:  79%|███████▊  | 128/163 [02:22<00:35,  1.02s/it, loss=2.4437, batch_acc=0.3750, running_acc=0.3573, grad=14.3616]Training epoch 4:  79%|███████▊  | 128/163 [02:22<00:35,  1.02s/it, loss=2.4337, batch_acc=0.3438, running_acc=0.3572, grad=14.4063]Training epoch 4:  79%|███████▉  | 129/163 [02:23<00:33,  1.02it/s, loss=2.4337, batch_acc=0.3438, running_acc=0.3572, grad=14.4063]Training epoch 4:  79%|███████▉  | 129/163 [02:23<00:33,  1.02it/s, loss=2.4731, batch_acc=0.2812, running_acc=0.3566, grad=11.3663]Training epoch 4:  80%|███████▉  | 130/163 [02:24<00:31,  1.06it/s, loss=2.4731, batch_acc=0.2812, running_acc=0.3566, grad=11.3663]Training epoch 4:  80%|███████▉  | 130/163 [02:24<00:31,  1.06it/s, loss=2.5794, batch_acc=0.3125, running_acc=0.3563, grad=12.2610]Training epoch 4:  80%|████████  | 131/163 [02:25<00:29,  1.08it/s, loss=2.5794, batch_acc=0.3125, running_acc=0.3563, grad=12.2610]Training epoch 4:  80%|████████  | 131/163 [02:25<00:29,  1.08it/s, loss=2.6440, batch_acc=0.3125, running_acc=0.3559, grad=10.1680]Training epoch 4:  81%|████████  | 132/163 [02:26<00:32,  1.06s/it, loss=2.6440, batch_acc=0.3125, running_acc=0.3559, grad=10.1680]Training epoch 4:  81%|████████  | 132/163 [02:26<00:32,  1.06s/it, loss=2.3573, batch_acc=0.4688, running_acc=0.3568, grad=10.9759]Training epoch 4:  82%|████████▏ | 133/163 [02:27<00:30,  1.01s/it, loss=2.3573, batch_acc=0.4688, running_acc=0.3568, grad=10.9759]Training epoch 4:  82%|████████▏ | 133/163 [02:27<00:30,  1.01s/it, loss=2.5522, batch_acc=0.3125, running_acc=0.3564, grad=12.8336]Training epoch 4:  82%|████████▏ | 134/163 [02:28<00:28,  1.03it/s, loss=2.5522, batch_acc=0.3125, running_acc=0.3564, grad=12.8336]Training epoch 4:  82%|████████▏ | 134/163 [02:28<00:28,  1.03it/s, loss=2.3180, batch_acc=0.3750, running_acc=0.3566, grad=10.3681]Training epoch 4:  83%|████████▎ | 135/163 [02:29<00:26,  1.06it/s, loss=2.3180, batch_acc=0.3750, running_acc=0.3566, grad=10.3681]Training epoch 4:  83%|████████▎ | 135/163 [02:29<00:26,  1.06it/s, loss=2.6324, batch_acc=0.2500, running_acc=0.3558, grad=13.7297]Training epoch 4:  83%|████████▎ | 136/163 [02:31<00:31,  1.17s/it, loss=2.6324, batch_acc=0.2500, running_acc=0.3558, grad=13.7297]Training epoch 4:  83%|████████▎ | 136/163 [02:31<00:31,  1.17s/it, loss=2.4271, batch_acc=0.3750, running_acc=0.3559, grad=11.0747]Training epoch 4:  84%|████████▍ | 137/163 [02:32<00:28,  1.08s/it, loss=2.4271, batch_acc=0.3750, running_acc=0.3559, grad=11.0747]Training epoch 4:  84%|████████▍ | 137/163 [02:32<00:28,  1.08s/it, loss=2.6320, batch_acc=0.1562, running_acc=0.3545, grad=10.5005]Training epoch 4:  85%|████████▍ | 138/163 [02:32<00:25,  1.02s/it, loss=2.6320, batch_acc=0.1562, running_acc=0.3545, grad=10.5005]Training epoch 4:  85%|████████▍ | 138/163 [02:32<00:25,  1.02s/it, loss=2.4183, batch_acc=0.4062, running_acc=0.3548, grad=9.5513] Training epoch 4:  85%|████████▌ | 139/163 [02:33<00:23,  1.02it/s, loss=2.4183, batch_acc=0.4062, running_acc=0.3548, grad=9.5513]Training epoch 4:  85%|████████▌ | 139/163 [02:33<00:23,  1.02it/s, loss=2.7395, batch_acc=0.3438, running_acc=0.3548, grad=15.6974]Training epoch 4:  86%|████████▌ | 140/163 [02:35<00:27,  1.18s/it, loss=2.7395, batch_acc=0.3438, running_acc=0.3548, grad=15.6974]Training epoch 4:  86%|████████▌ | 140/163 [02:35<00:27,  1.18s/it, loss=2.4825, batch_acc=0.3438, running_acc=0.3547, grad=15.7648]Training epoch 4:  87%|████████▋ | 141/163 [02:36<00:23,  1.09s/it, loss=2.4825, batch_acc=0.3438, running_acc=0.3547, grad=15.7648]Training epoch 4:  87%|████████▋ | 141/163 [02:36<00:23,  1.09s/it, loss=2.5736, batch_acc=0.2812, running_acc=0.3542, grad=11.3183]Training epoch 4:  87%|████████▋ | 142/163 [02:37<00:21,  1.02s/it, loss=2.5736, batch_acc=0.2812, running_acc=0.3542, grad=11.3183]Training epoch 4:  87%|████████▋ | 142/163 [02:37<00:21,  1.02s/it, loss=2.3584, batch_acc=0.4688, running_acc=0.3550, grad=12.2465]Training epoch 4:  88%|████████▊ | 143/163 [02:38<00:19,  1.02it/s, loss=2.3584, batch_acc=0.4688, running_acc=0.3550, grad=12.2465]Training epoch 4:  88%|████████▊ | 143/163 [02:38<00:19,  1.02it/s, loss=2.4691, batch_acc=0.2188, running_acc=0.3540, grad=14.3563]Training epoch 4:  88%|████████▊ | 144/163 [02:39<00:22,  1.17s/it, loss=2.4691, batch_acc=0.2188, running_acc=0.3540, grad=14.3563]Training epoch 4:  88%|████████▊ | 144/163 [02:39<00:22,  1.17s/it, loss=2.5898, batch_acc=0.2188, running_acc=0.3531, grad=24.7554]Training epoch 4:  89%|████████▉ | 145/163 [02:40<00:19,  1.08s/it, loss=2.5898, batch_acc=0.2188, running_acc=0.3531, grad=24.7554]Training epoch 4:  89%|████████▉ | 145/163 [02:40<00:19,  1.08s/it, loss=2.5616, batch_acc=0.3125, running_acc=0.3528, grad=14.6334]Training epoch 4:  90%|████████▉ | 146/163 [02:41<00:17,  1.02s/it, loss=2.5616, batch_acc=0.3125, running_acc=0.3528, grad=14.6334]Training epoch 4:  90%|████████▉ | 146/163 [02:41<00:17,  1.02s/it, loss=2.3631, batch_acc=0.4062, running_acc=0.3532, grad=10.2634]Training epoch 4:  90%|█████████ | 147/163 [02:42<00:15,  1.02it/s, loss=2.3631, batch_acc=0.4062, running_acc=0.3532, grad=10.2634]Training epoch 4:  90%|█████████ | 147/163 [02:42<00:15,  1.02it/s, loss=2.3922, batch_acc=0.2812, running_acc=0.3527, grad=12.7859]Training epoch 4:  91%|█████████ | 148/163 [02:44<00:18,  1.25s/it, loss=2.3922, batch_acc=0.2812, running_acc=0.3527, grad=12.7859]Training epoch 4:  91%|█████████ | 148/163 [02:44<00:18,  1.25s/it, loss=2.4707, batch_acc=0.3125, running_acc=0.3524, grad=10.2723]Training epoch 4:  91%|█████████▏| 149/163 [02:45<00:15,  1.14s/it, loss=2.4707, batch_acc=0.3125, running_acc=0.3524, grad=10.2723]Training epoch 4:  91%|█████████▏| 149/163 [02:45<00:15,  1.14s/it, loss=2.1104, batch_acc=0.4688, running_acc=0.3532, grad=12.4026]Training epoch 4:  92%|█████████▏| 150/163 [02:46<00:13,  1.06s/it, loss=2.1104, batch_acc=0.4688, running_acc=0.3532, grad=12.4026]Training epoch 4:  92%|█████████▏| 150/163 [02:46<00:13,  1.06s/it, loss=2.4247, batch_acc=0.3125, running_acc=0.3529, grad=14.0445]Training epoch 4:  93%|█████████▎| 151/163 [02:46<00:12,  1.01s/it, loss=2.4247, batch_acc=0.3125, running_acc=0.3529, grad=14.0445]Training epoch 4:  93%|█████████▎| 151/163 [02:46<00:12,  1.01s/it, loss=2.1359, batch_acc=0.3750, running_acc=0.3531, grad=10.6950]Training epoch 4:  93%|█████████▎| 152/163 [02:49<00:15,  1.37s/it, loss=2.1359, batch_acc=0.3750, running_acc=0.3531, grad=10.6950]Training epoch 4:  93%|█████████▎| 152/163 [02:49<00:15,  1.37s/it, loss=2.4259, batch_acc=0.3750, running_acc=0.3532, grad=17.1785]Training epoch 4:  94%|█████████▍| 153/163 [02:49<00:12,  1.22s/it, loss=2.4259, batch_acc=0.3750, running_acc=0.3532, grad=17.1785]Training epoch 4:  94%|█████████▍| 153/163 [02:49<00:12,  1.22s/it, loss=2.2521, batch_acc=0.4062, running_acc=0.3536, grad=9.6012] Training epoch 4:  94%|█████████▍| 154/163 [02:50<00:10,  1.12s/it, loss=2.2521, batch_acc=0.4062, running_acc=0.3536, grad=9.6012]Training epoch 4:  94%|█████████▍| 154/163 [02:50<00:10,  1.12s/it, loss=2.4961, batch_acc=0.3438, running_acc=0.3535, grad=12.0252]Training epoch 4:  95%|█████████▌| 155/163 [02:51<00:08,  1.04s/it, loss=2.4961, batch_acc=0.3438, running_acc=0.3535, grad=12.0252]Training epoch 4:  95%|█████████▌| 155/163 [02:51<00:08,  1.04s/it, loss=2.4316, batch_acc=0.3125, running_acc=0.3532, grad=11.2344]Training epoch 4:  96%|█████████▌| 156/163 [02:53<00:09,  1.35s/it, loss=2.4316, batch_acc=0.3125, running_acc=0.3532, grad=11.2344]Training epoch 4:  96%|█████████▌| 156/163 [02:53<00:09,  1.35s/it, loss=2.5611, batch_acc=0.3438, running_acc=0.3532, grad=11.5576]Training epoch 4:  96%|█████████▋| 157/163 [02:54<00:07,  1.21s/it, loss=2.5611, batch_acc=0.3438, running_acc=0.3532, grad=11.5576]Training epoch 4:  96%|█████████▋| 157/163 [02:54<00:07,  1.21s/it, loss=2.4473, batch_acc=0.3750, running_acc=0.3533, grad=12.0670]Training epoch 4:  97%|█████████▋| 158/163 [02:55<00:05,  1.11s/it, loss=2.4473, batch_acc=0.3750, running_acc=0.3533, grad=12.0670]Training epoch 4:  97%|█████████▋| 158/163 [02:55<00:05,  1.11s/it, loss=2.3891, batch_acc=0.4688, running_acc=0.3540, grad=16.8932]Training epoch 4:  98%|█████████▊| 159/163 [02:56<00:04,  1.04s/it, loss=2.3891, batch_acc=0.4688, running_acc=0.3540, grad=16.8932]Training epoch 4:  98%|█████████▊| 159/163 [02:56<00:04,  1.04s/it, loss=2.3816, batch_acc=0.3438, running_acc=0.3540, grad=11.8476]Training epoch 4:  98%|█████████▊| 160/163 [02:57<00:03,  1.15s/it, loss=2.3816, batch_acc=0.3438, running_acc=0.3540, grad=11.8476]Training epoch 4:  98%|█████████▊| 160/163 [02:57<00:03,  1.15s/it, loss=2.2070, batch_acc=0.4375, running_acc=0.3545, grad=10.0981]Training epoch 4:  99%|█████████▉| 161/163 [02:58<00:02,  1.07s/it, loss=2.2070, batch_acc=0.4375, running_acc=0.3545, grad=10.0981]Training epoch 4:  99%|█████████▉| 161/163 [02:58<00:02,  1.07s/it, loss=2.2652, batch_acc=0.5625, running_acc=0.3558, grad=17.2576]Training epoch 4:  99%|█████████▉| 162/163 [02:59<00:01,  1.01s/it, loss=2.2652, batch_acc=0.5625, running_acc=0.3558, grad=17.2576]Training epoch 4:  99%|█████████▉| 162/163 [02:59<00:01,  1.01s/it, loss=2.5805, batch_acc=0.3125, running_acc=0.3555, grad=19.8566]Training epoch 4: 100%|██████████| 163/163 [03:00<00:00,  1.12it/s, loss=2.5805, batch_acc=0.3125, running_acc=0.3555, grad=19.8566]Training epoch 4: 100%|██████████| 163/163 [03:00<00:00,  1.12it/s, loss=2.4429, batch_acc=0.3333, running_acc=0.3554, grad=15.0939]Training epoch 4: 100%|██████████| 163/163 [03:00<00:00,  1.11s/it, loss=2.4429, batch_acc=0.3333, running_acc=0.3554, grad=15.0939]
Evaluation epoch 4:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 4:   4%|▎         | 1/28 [00:05<02:18,  5.12s/it]Evaluation epoch 4:   4%|▎         | 1/28 [00:05<02:18,  5.12s/it, loss=1.8800, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 4:   7%|▋         | 2/28 [00:05<01:00,  2.34s/it, loss=1.8800, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 4:   7%|▋         | 2/28 [00:05<01:00,  2.34s/it, loss=1.8818, batch_acc=0.6562, running_acc=0.5469]Evaluation epoch 4:  11%|█         | 3/28 [00:05<00:34,  1.39s/it, loss=1.8818, batch_acc=0.6562, running_acc=0.5469]Evaluation epoch 4:  11%|█         | 3/28 [00:05<00:34,  1.39s/it, loss=2.0940, batch_acc=0.3750, running_acc=0.4896]Evaluation epoch 4:  14%|█▍        | 4/28 [00:10<01:01,  2.58s/it, loss=2.0940, batch_acc=0.3750, running_acc=0.4896]Evaluation epoch 4:  14%|█▍        | 4/28 [00:10<01:01,  2.58s/it, loss=2.8918, batch_acc=0.1875, running_acc=0.4141]Evaluation epoch 4:  18%|█▊        | 5/28 [00:10<00:40,  1.75s/it, loss=2.8918, batch_acc=0.1875, running_acc=0.4141]Evaluation epoch 4:  18%|█▊        | 5/28 [00:10<00:40,  1.75s/it, loss=2.5673, batch_acc=0.2812, running_acc=0.3875]Evaluation epoch 4:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=2.5673, batch_acc=0.2812, running_acc=0.3875]Evaluation epoch 4:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=2.8112, batch_acc=0.1875, running_acc=0.3542]Evaluation epoch 4:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=2.8112, batch_acc=0.1875, running_acc=0.3542]Evaluation epoch 4:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=2.5572, batch_acc=0.3750, running_acc=0.3571]Evaluation epoch 4:  29%|██▊       | 8/28 [00:14<00:33,  1.66s/it, loss=2.5572, batch_acc=0.3750, running_acc=0.3571]Evaluation epoch 4:  29%|██▊       | 8/28 [00:14<00:33,  1.66s/it, loss=2.4902, batch_acc=0.2188, running_acc=0.3398]Evaluation epoch 4:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=2.4902, batch_acc=0.2188, running_acc=0.3398]Evaluation epoch 4:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=3.0659, batch_acc=0.1250, running_acc=0.3160]Evaluation epoch 4:  36%|███▌      | 10/28 [00:14<00:16,  1.06it/s, loss=3.0659, batch_acc=0.1250, running_acc=0.3160]Evaluation epoch 4:  36%|███▌      | 10/28 [00:14<00:16,  1.06it/s, loss=1.3169, batch_acc=0.8438, running_acc=0.3688]Evaluation epoch 4:  39%|███▉      | 11/28 [00:15<00:12,  1.36it/s, loss=1.3169, batch_acc=0.8438, running_acc=0.3688]Evaluation epoch 4:  39%|███▉      | 11/28 [00:15<00:12,  1.36it/s, loss=2.8592, batch_acc=0.2188, running_acc=0.3551]Evaluation epoch 4:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.8592, batch_acc=0.2188, running_acc=0.3551]Evaluation epoch 4:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.2777, batch_acc=0.5000, running_acc=0.3672]Evaluation epoch 4:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=2.2777, batch_acc=0.5000, running_acc=0.3672]Evaluation epoch 4:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=2.3534, batch_acc=0.4688, running_acc=0.3750]Evaluation epoch 4:  50%|█████     | 14/28 [00:21<00:17,  1.21s/it, loss=2.3534, batch_acc=0.4688, running_acc=0.3750]Evaluation epoch 4:  50%|█████     | 14/28 [00:21<00:17,  1.21s/it, loss=2.6325, batch_acc=0.4375, running_acc=0.3795]Evaluation epoch 4:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.6325, batch_acc=0.4375, running_acc=0.3795]Evaluation epoch 4:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=3.3526, batch_acc=0.2188, running_acc=0.3688]Evaluation epoch 4:  57%|█████▋    | 16/28 [00:24<00:18,  1.53s/it, loss=3.3526, batch_acc=0.2188, running_acc=0.3688]Evaluation epoch 4:  57%|█████▋    | 16/28 [00:24<00:18,  1.53s/it, loss=2.7793, batch_acc=0.1562, running_acc=0.3555]Evaluation epoch 4:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=2.7793, batch_acc=0.1562, running_acc=0.3555]Evaluation epoch 4:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=2.7016, batch_acc=0.1875, running_acc=0.3456]Evaluation epoch 4:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=2.7016, batch_acc=0.1875, running_acc=0.3456]Evaluation epoch 4:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=2.2944, batch_acc=0.5000, running_acc=0.3542]Evaluation epoch 4:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.2944, batch_acc=0.5000, running_acc=0.3542]Evaluation epoch 4:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.4126, batch_acc=0.1875, running_acc=0.3454]Evaluation epoch 4:  71%|███████▏  | 20/28 [00:28<00:10,  1.35s/it, loss=2.4126, batch_acc=0.1875, running_acc=0.3454]Evaluation epoch 4:  71%|███████▏  | 20/28 [00:28<00:10,  1.35s/it, loss=2.5733, batch_acc=0.2812, running_acc=0.3422]Evaluation epoch 4:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=2.5733, batch_acc=0.2812, running_acc=0.3422]Evaluation epoch 4:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=2.6929, batch_acc=0.2188, running_acc=0.3363]Evaluation epoch 4:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=2.6929, batch_acc=0.2188, running_acc=0.3363]Evaluation epoch 4:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=2.6489, batch_acc=0.2812, running_acc=0.3338]Evaluation epoch 4:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=2.6489, batch_acc=0.2812, running_acc=0.3338]Evaluation epoch 4:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=2.6014, batch_acc=0.1875, running_acc=0.3274]Evaluation epoch 4:  86%|████████▌ | 24/28 [00:34<00:08,  2.02s/it, loss=2.6014, batch_acc=0.1875, running_acc=0.3274]Evaluation epoch 4:  86%|████████▌ | 24/28 [00:34<00:08,  2.02s/it, loss=1.8367, batch_acc=0.6875, running_acc=0.3424]Evaluation epoch 4:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=1.8367, batch_acc=0.6875, running_acc=0.3424]Evaluation epoch 4:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=1.6902, batch_acc=0.5938, running_acc=0.3525]Evaluation epoch 4:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=1.6902, batch_acc=0.5938, running_acc=0.3525]Evaluation epoch 4:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=2.0754, batch_acc=0.5000, running_acc=0.3582]Evaluation epoch 4:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=2.0754, batch_acc=0.5000, running_acc=0.3582]Evaluation epoch 4:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=2.3444, batch_acc=0.4062, running_acc=0.3600]Evaluation epoch 4: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=1.1131, batch_acc=1.0000, running_acc=0.3622]Evaluation epoch 4: 100%|██████████| 28/28 [00:34<00:00,  1.25s/it, loss=1.1131, batch_acc=1.0000, running_acc=0.3622]
Training epoch 5:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 5:   1%|          | 1/163 [00:06<17:16,  6.40s/it]Training epoch 5:   1%|          | 1/163 [00:06<17:16,  6.40s/it, loss=2.2932, batch_acc=0.4375, running_acc=0.4375, grad=11.4980]Training epoch 5:   1%|          | 2/163 [00:07<08:27,  3.15s/it, loss=2.2932, batch_acc=0.4375, running_acc=0.4375, grad=11.4980]Training epoch 5:   1%|          | 2/163 [00:07<08:27,  3.15s/it, loss=2.3577, batch_acc=0.4062, running_acc=0.4219, grad=10.8904]Training epoch 5:   2%|▏         | 3/163 [00:08<05:38,  2.11s/it, loss=2.3577, batch_acc=0.4062, running_acc=0.4219, grad=10.8904]Training epoch 5:   2%|▏         | 3/163 [00:08<05:38,  2.11s/it, loss=2.5444, batch_acc=0.3438, running_acc=0.3958, grad=10.8735]Training epoch 5:   2%|▏         | 4/163 [00:09<04:55,  1.86s/it, loss=2.5444, batch_acc=0.3438, running_acc=0.3958, grad=10.8735]Training epoch 5:   2%|▏         | 4/163 [00:09<04:55,  1.86s/it, loss=2.4062, batch_acc=0.3438, running_acc=0.3828, grad=12.8629]Training epoch 5:   3%|▎         | 5/163 [00:10<04:18,  1.64s/it, loss=2.4062, batch_acc=0.3438, running_acc=0.3828, grad=12.8629]Training epoch 5:   3%|▎         | 5/163 [00:10<04:18,  1.64s/it, loss=2.4034, batch_acc=0.4062, running_acc=0.3875, grad=10.3706]Training epoch 5:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=2.4034, batch_acc=0.4062, running_acc=0.3875, grad=10.3706]Training epoch 5:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=2.2633, batch_acc=0.3750, running_acc=0.3854, grad=14.4867]Training epoch 5:   4%|▍         | 7/163 [00:12<03:09,  1.22s/it, loss=2.2633, batch_acc=0.3750, running_acc=0.3854, grad=14.4867]Training epoch 5:   4%|▍         | 7/163 [00:12<03:09,  1.22s/it, loss=2.6294, batch_acc=0.2812, running_acc=0.3705, grad=15.8006]Training epoch 5:   5%|▍         | 8/163 [00:13<03:12,  1.24s/it, loss=2.6294, batch_acc=0.2812, running_acc=0.3705, grad=15.8006]Training epoch 5:   5%|▍         | 8/163 [00:13<03:12,  1.24s/it, loss=2.7592, batch_acc=0.2812, running_acc=0.3594, grad=11.1102]Training epoch 5:   6%|▌         | 9/163 [00:15<03:04,  1.20s/it, loss=2.7592, batch_acc=0.2812, running_acc=0.3594, grad=11.1102]Training epoch 5:   6%|▌         | 9/163 [00:15<03:04,  1.20s/it, loss=2.3049, batch_acc=0.3438, running_acc=0.3576, grad=15.2975]Training epoch 5:   6%|▌         | 10/163 [00:15<02:48,  1.10s/it, loss=2.3049, batch_acc=0.3438, running_acc=0.3576, grad=15.2975]Training epoch 5:   6%|▌         | 10/163 [00:15<02:48,  1.10s/it, loss=2.4175, batch_acc=0.4688, running_acc=0.3688, grad=13.2836]Training epoch 5:   7%|▋         | 11/163 [00:16<02:37,  1.03s/it, loss=2.4175, batch_acc=0.4688, running_acc=0.3688, grad=13.2836]Training epoch 5:   7%|▋         | 11/163 [00:16<02:37,  1.03s/it, loss=2.5082, batch_acc=0.3750, running_acc=0.3693, grad=12.8330]Training epoch 5:   7%|▋         | 12/163 [00:18<02:50,  1.13s/it, loss=2.5082, batch_acc=0.3750, running_acc=0.3693, grad=12.8330]Training epoch 5:   7%|▋         | 12/163 [00:18<02:50,  1.13s/it, loss=2.3860, batch_acc=0.2812, running_acc=0.3620, grad=10.2996]Training epoch 5:   8%|▊         | 13/163 [00:19<02:50,  1.13s/it, loss=2.3860, batch_acc=0.2812, running_acc=0.3620, grad=10.2996]Training epoch 5:   8%|▊         | 13/163 [00:19<02:50,  1.13s/it, loss=2.4085, batch_acc=0.4062, running_acc=0.3654, grad=12.6735]Training epoch 5:   9%|▊         | 14/163 [00:20<02:37,  1.06s/it, loss=2.4085, batch_acc=0.4062, running_acc=0.3654, grad=12.6735]Training epoch 5:   9%|▊         | 14/163 [00:20<02:37,  1.06s/it, loss=2.3746, batch_acc=0.3750, running_acc=0.3661, grad=17.6118]Training epoch 5:   9%|▉         | 15/163 [00:21<02:28,  1.00s/it, loss=2.3746, batch_acc=0.3750, running_acc=0.3661, grad=17.6118]Training epoch 5:   9%|▉         | 15/163 [00:21<02:28,  1.00s/it, loss=2.3491, batch_acc=0.3438, running_acc=0.3646, grad=23.4149]Training epoch 5:  10%|▉         | 16/163 [00:23<03:17,  1.34s/it, loss=2.3491, batch_acc=0.3438, running_acc=0.3646, grad=23.4149]Training epoch 5:  10%|▉         | 16/163 [00:23<03:17,  1.34s/it, loss=2.1196, batch_acc=0.4375, running_acc=0.3691, grad=14.2125]Training epoch 5:  10%|█         | 17/163 [00:24<02:57,  1.22s/it, loss=2.1196, batch_acc=0.4375, running_acc=0.3691, grad=14.2125]Training epoch 5:  10%|█         | 17/163 [00:24<02:57,  1.22s/it, loss=2.0581, batch_acc=0.4062, running_acc=0.3713, grad=11.9181]Training epoch 5:  11%|█         | 18/163 [00:24<02:41,  1.12s/it, loss=2.0581, batch_acc=0.4062, running_acc=0.3713, grad=11.9181]Training epoch 5:  11%|█         | 18/163 [00:24<02:41,  1.12s/it, loss=2.2316, batch_acc=0.5000, running_acc=0.3785, grad=10.2657]Training epoch 5:  12%|█▏        | 19/163 [00:25<02:30,  1.04s/it, loss=2.2316, batch_acc=0.5000, running_acc=0.3785, grad=10.2657]Training epoch 5:  12%|█▏        | 19/163 [00:25<02:30,  1.04s/it, loss=2.1532, batch_acc=0.4688, running_acc=0.3832, grad=10.7994]Training epoch 5:  12%|█▏        | 20/163 [00:27<03:07,  1.31s/it, loss=2.1532, batch_acc=0.4688, running_acc=0.3832, grad=10.7994]Training epoch 5:  12%|█▏        | 20/163 [00:27<03:07,  1.31s/it, loss=2.6604, batch_acc=0.2188, running_acc=0.3750, grad=13.1733]Training epoch 5:  13%|█▎        | 21/163 [00:28<02:48,  1.18s/it, loss=2.6604, batch_acc=0.2188, running_acc=0.3750, grad=13.1733]Training epoch 5:  13%|█▎        | 21/163 [00:28<02:48,  1.18s/it, loss=2.4177, batch_acc=0.3438, running_acc=0.3735, grad=17.3039]Training epoch 5:  13%|█▎        | 22/163 [00:29<02:34,  1.09s/it, loss=2.4177, batch_acc=0.3438, running_acc=0.3735, grad=17.3039]Training epoch 5:  13%|█▎        | 22/163 [00:29<02:34,  1.09s/it, loss=2.2102, batch_acc=0.4688, running_acc=0.3778, grad=13.0858]Training epoch 5:  14%|█▍        | 23/163 [00:30<02:24,  1.03s/it, loss=2.2102, batch_acc=0.4688, running_acc=0.3778, grad=13.0858]Training epoch 5:  14%|█▍        | 23/163 [00:30<02:24,  1.03s/it, loss=2.4711, batch_acc=0.3438, running_acc=0.3764, grad=18.5250]Training epoch 5:  15%|█▍        | 24/163 [00:32<02:47,  1.21s/it, loss=2.4711, batch_acc=0.3438, running_acc=0.3764, grad=18.5250]Training epoch 5:  15%|█▍        | 24/163 [00:32<02:47,  1.21s/it, loss=2.3333, batch_acc=0.3125, running_acc=0.3737, grad=13.3062]Training epoch 5:  15%|█▌        | 25/163 [00:33<02:37,  1.14s/it, loss=2.3333, batch_acc=0.3125, running_acc=0.3737, grad=13.3062]Training epoch 5:  15%|█▌        | 25/163 [00:33<02:37,  1.14s/it, loss=2.3129, batch_acc=0.5312, running_acc=0.3800, grad=12.7237]Training epoch 5:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=2.3129, batch_acc=0.5312, running_acc=0.3800, grad=12.7237]Training epoch 5:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=2.4084, batch_acc=0.3750, running_acc=0.3798, grad=11.1532]Training epoch 5:  17%|█▋        | 27/163 [00:34<02:16,  1.01s/it, loss=2.4084, batch_acc=0.3750, running_acc=0.3798, grad=11.1532]Training epoch 5:  17%|█▋        | 27/163 [00:34<02:16,  1.01s/it, loss=2.3043, batch_acc=0.4062, running_acc=0.3808, grad=16.4105]Training epoch 5:  17%|█▋        | 28/163 [00:36<02:36,  1.16s/it, loss=2.3043, batch_acc=0.4062, running_acc=0.3808, grad=16.4105]Training epoch 5:  17%|█▋        | 28/163 [00:36<02:36,  1.16s/it, loss=2.5548, batch_acc=0.2812, running_acc=0.3772, grad=15.9344]Training epoch 5:  18%|█▊        | 29/163 [00:37<02:24,  1.08s/it, loss=2.5548, batch_acc=0.2812, running_acc=0.3772, grad=15.9344]Training epoch 5:  18%|█▊        | 29/163 [00:37<02:24,  1.08s/it, loss=2.3782, batch_acc=0.4062, running_acc=0.3782, grad=9.2929] Training epoch 5:  18%|█▊        | 30/163 [00:38<02:15,  1.02s/it, loss=2.3782, batch_acc=0.4062, running_acc=0.3782, grad=9.2929]Training epoch 5:  18%|█▊        | 30/163 [00:38<02:15,  1.02s/it, loss=2.3334, batch_acc=0.3750, running_acc=0.3781, grad=11.4612]Training epoch 5:  19%|█▉        | 31/163 [00:38<02:08,  1.02it/s, loss=2.3334, batch_acc=0.3750, running_acc=0.3781, grad=11.4612]Training epoch 5:  19%|█▉        | 31/163 [00:38<02:08,  1.02it/s, loss=2.5391, batch_acc=0.4062, running_acc=0.3790, grad=13.1558]Training epoch 5:  20%|█▉        | 32/163 [00:40<02:31,  1.16s/it, loss=2.5391, batch_acc=0.4062, running_acc=0.3790, grad=13.1558]Training epoch 5:  20%|█▉        | 32/163 [00:40<02:31,  1.16s/it, loss=2.0600, batch_acc=0.5000, running_acc=0.3828, grad=18.5616]Training epoch 5:  20%|██        | 33/163 [00:41<02:24,  1.11s/it, loss=2.0600, batch_acc=0.5000, running_acc=0.3828, grad=18.5616]Training epoch 5:  20%|██        | 33/163 [00:41<02:24,  1.11s/it, loss=2.4454, batch_acc=0.2188, running_acc=0.3778, grad=13.5421]Training epoch 5:  21%|██        | 34/163 [00:42<02:14,  1.04s/it, loss=2.4454, batch_acc=0.2188, running_acc=0.3778, grad=13.5421]Training epoch 5:  21%|██        | 34/163 [00:42<02:14,  1.04s/it, loss=2.2491, batch_acc=0.4062, running_acc=0.3787, grad=27.6453]Training epoch 5:  21%|██▏       | 35/163 [00:43<02:07,  1.01it/s, loss=2.2491, batch_acc=0.4062, running_acc=0.3787, grad=27.6453]Training epoch 5:  21%|██▏       | 35/163 [00:43<02:07,  1.01it/s, loss=2.4281, batch_acc=0.3438, running_acc=0.3777, grad=11.7805]Training epoch 5:  22%|██▏       | 36/163 [00:44<02:21,  1.12s/it, loss=2.4281, batch_acc=0.3438, running_acc=0.3777, grad=11.7805]Training epoch 5:  22%|██▏       | 36/163 [00:44<02:21,  1.12s/it, loss=2.3924, batch_acc=0.3125, running_acc=0.3759, grad=14.9807]Training epoch 5:  23%|██▎       | 37/163 [00:46<02:30,  1.19s/it, loss=2.3924, batch_acc=0.3125, running_acc=0.3759, grad=14.9807]Training epoch 5:  23%|██▎       | 37/163 [00:46<02:30,  1.19s/it, loss=2.6068, batch_acc=0.3750, running_acc=0.3758, grad=15.4992]Training epoch 5:  23%|██▎       | 38/163 [00:46<02:17,  1.10s/it, loss=2.6068, batch_acc=0.3750, running_acc=0.3758, grad=15.4992]Training epoch 5:  23%|██▎       | 38/163 [00:46<02:17,  1.10s/it, loss=2.1443, batch_acc=0.4375, running_acc=0.3775, grad=11.6400]Training epoch 5:  24%|██▍       | 39/163 [00:47<02:08,  1.03s/it, loss=2.1443, batch_acc=0.4375, running_acc=0.3775, grad=11.6400]Training epoch 5:  24%|██▍       | 39/163 [00:47<02:08,  1.03s/it, loss=2.0739, batch_acc=0.5938, running_acc=0.3830, grad=13.3078]Training epoch 5:  25%|██▍       | 40/163 [00:49<02:24,  1.17s/it, loss=2.0739, batch_acc=0.5938, running_acc=0.3830, grad=13.3078]Training epoch 5:  25%|██▍       | 40/163 [00:49<02:24,  1.17s/it, loss=2.2003, batch_acc=0.4375, running_acc=0.3844, grad=13.5498]Training epoch 5:  25%|██▌       | 41/163 [00:50<02:37,  1.29s/it, loss=2.2003, batch_acc=0.4375, running_acc=0.3844, grad=13.5498]Training epoch 5:  25%|██▌       | 41/163 [00:50<02:37,  1.29s/it, loss=2.2116, batch_acc=0.4688, running_acc=0.3864, grad=14.3627]Training epoch 5:  26%|██▌       | 42/163 [00:51<02:21,  1.17s/it, loss=2.2116, batch_acc=0.4688, running_acc=0.3864, grad=14.3627]Training epoch 5:  26%|██▌       | 42/163 [00:51<02:21,  1.17s/it, loss=2.1631, batch_acc=0.3438, running_acc=0.3854, grad=15.3592]Training epoch 5:  26%|██▋       | 43/163 [00:52<02:09,  1.08s/it, loss=2.1631, batch_acc=0.3438, running_acc=0.3854, grad=15.3592]Training epoch 5:  26%|██▋       | 43/163 [00:52<02:09,  1.08s/it, loss=2.3243, batch_acc=0.4688, running_acc=0.3874, grad=15.5472]Training epoch 5:  27%|██▋       | 44/163 [00:53<02:14,  1.13s/it, loss=2.3243, batch_acc=0.4688, running_acc=0.3874, grad=15.5472]Training epoch 5:  27%|██▋       | 44/163 [00:53<02:14,  1.13s/it, loss=2.4171, batch_acc=0.3750, running_acc=0.3871, grad=12.2106]Training epoch 5:  28%|██▊       | 45/163 [00:54<02:08,  1.09s/it, loss=2.4171, batch_acc=0.3750, running_acc=0.3871, grad=12.2106]Training epoch 5:  28%|██▊       | 45/163 [00:54<02:08,  1.09s/it, loss=2.2917, batch_acc=0.2188, running_acc=0.3833, grad=25.7657]Training epoch 5:  28%|██▊       | 46/163 [00:55<01:59,  1.02s/it, loss=2.2917, batch_acc=0.2188, running_acc=0.3833, grad=25.7657]Training epoch 5:  28%|██▊       | 46/163 [00:55<01:59,  1.02s/it, loss=2.4819, batch_acc=0.2812, running_acc=0.3811, grad=11.6252]Training epoch 5:  29%|██▉       | 47/163 [00:56<01:53,  1.02it/s, loss=2.4819, batch_acc=0.2812, running_acc=0.3811, grad=11.6252]Training epoch 5:  29%|██▉       | 47/163 [00:56<01:53,  1.02it/s, loss=2.4160, batch_acc=0.3750, running_acc=0.3810, grad=15.5413]Training epoch 5:  29%|██▉       | 48/163 [00:58<02:08,  1.12s/it, loss=2.4160, batch_acc=0.3750, running_acc=0.3810, grad=15.5413]Training epoch 5:  29%|██▉       | 48/163 [00:58<02:08,  1.12s/it, loss=2.1360, batch_acc=0.4688, running_acc=0.3828, grad=18.5967]Training epoch 5:  30%|███       | 49/163 [01:02<04:07,  2.17s/it, loss=2.1360, batch_acc=0.4688, running_acc=0.3828, grad=18.5967]Training epoch 5:  30%|███       | 49/163 [01:02<04:07,  2.17s/it, loss=2.3536, batch_acc=0.2812, running_acc=0.3807, grad=19.8191]Training epoch 5:  31%|███       | 50/163 [01:03<03:21,  1.78s/it, loss=2.3536, batch_acc=0.2812, running_acc=0.3807, grad=19.8191]Training epoch 5:  31%|███       | 50/163 [01:03<03:21,  1.78s/it, loss=2.4115, batch_acc=0.2500, running_acc=0.3781, grad=10.9325]Training epoch 5:  31%|███▏      | 51/163 [01:04<02:49,  1.51s/it, loss=2.4115, batch_acc=0.2500, running_acc=0.3781, grad=10.9325]Training epoch 5:  31%|███▏      | 51/163 [01:04<02:49,  1.51s/it, loss=2.2535, batch_acc=0.3125, running_acc=0.3768, grad=11.8286]Training epoch 5:  32%|███▏      | 52/163 [01:05<02:26,  1.32s/it, loss=2.2535, batch_acc=0.3125, running_acc=0.3768, grad=11.8286]Training epoch 5:  32%|███▏      | 52/163 [01:05<02:26,  1.32s/it, loss=2.4927, batch_acc=0.4062, running_acc=0.3774, grad=17.1185]Training epoch 5:  33%|███▎      | 53/163 [01:07<02:37,  1.44s/it, loss=2.4927, batch_acc=0.4062, running_acc=0.3774, grad=17.1185]Training epoch 5:  33%|███▎      | 53/163 [01:07<02:37,  1.44s/it, loss=2.4638, batch_acc=0.3125, running_acc=0.3762, grad=12.0472]Training epoch 5:  33%|███▎      | 54/163 [01:07<02:18,  1.27s/it, loss=2.4638, batch_acc=0.3125, running_acc=0.3762, grad=12.0472]Training epoch 5:  33%|███▎      | 54/163 [01:07<02:18,  1.27s/it, loss=2.2402, batch_acc=0.5000, running_acc=0.3785, grad=13.7601]Training epoch 5:  34%|███▎      | 55/163 [01:08<02:04,  1.15s/it, loss=2.2402, batch_acc=0.5000, running_acc=0.3785, grad=13.7601]Training epoch 5:  34%|███▎      | 55/163 [01:08<02:04,  1.15s/it, loss=2.4416, batch_acc=0.2812, running_acc=0.3767, grad=14.0606]Training epoch 5:  34%|███▍      | 56/163 [01:09<01:54,  1.07s/it, loss=2.4416, batch_acc=0.2812, running_acc=0.3767, grad=14.0606]Training epoch 5:  34%|███▍      | 56/163 [01:09<01:54,  1.07s/it, loss=2.3532, batch_acc=0.3750, running_acc=0.3767, grad=19.8610]Training epoch 5:  35%|███▍      | 57/163 [01:11<02:10,  1.23s/it, loss=2.3532, batch_acc=0.3750, running_acc=0.3767, grad=19.8610]Training epoch 5:  35%|███▍      | 57/163 [01:11<02:10,  1.23s/it, loss=2.2189, batch_acc=0.4062, running_acc=0.3772, grad=11.9329]Training epoch 5:  36%|███▌      | 58/163 [01:12<01:58,  1.13s/it, loss=2.2189, batch_acc=0.4062, running_acc=0.3772, grad=11.9329]Training epoch 5:  36%|███▌      | 58/163 [01:12<01:58,  1.13s/it, loss=2.2373, batch_acc=0.4375, running_acc=0.3782, grad=16.0681]Training epoch 5:  36%|███▌      | 59/163 [01:13<01:49,  1.05s/it, loss=2.2373, batch_acc=0.4375, running_acc=0.3782, grad=16.0681]Training epoch 5:  36%|███▌      | 59/163 [01:13<01:49,  1.05s/it, loss=2.2587, batch_acc=0.5312, running_acc=0.3808, grad=11.1677]Training epoch 5:  37%|███▋      | 60/163 [01:13<01:43,  1.00s/it, loss=2.2587, batch_acc=0.5312, running_acc=0.3808, grad=11.1677]Training epoch 5:  37%|███▋      | 60/163 [01:13<01:43,  1.00s/it, loss=2.1282, batch_acc=0.4062, running_acc=0.3812, grad=11.5865]Training epoch 5:  37%|███▋      | 61/163 [01:15<02:00,  1.19s/it, loss=2.1282, batch_acc=0.4062, running_acc=0.3812, grad=11.5865]Training epoch 5:  37%|███▋      | 61/163 [01:15<02:00,  1.19s/it, loss=2.2208, batch_acc=0.5000, running_acc=0.3832, grad=17.6082]Training epoch 5:  38%|███▊      | 62/163 [01:16<01:50,  1.09s/it, loss=2.2208, batch_acc=0.5000, running_acc=0.3832, grad=17.6082]Training epoch 5:  38%|███▊      | 62/163 [01:16<01:50,  1.09s/it, loss=2.1753, batch_acc=0.3125, running_acc=0.3821, grad=13.9047]Training epoch 5:  39%|███▊      | 63/163 [01:17<01:43,  1.03s/it, loss=2.1753, batch_acc=0.3125, running_acc=0.3821, grad=13.9047]Training epoch 5:  39%|███▊      | 63/163 [01:17<01:43,  1.03s/it, loss=2.2001, batch_acc=0.4375, running_acc=0.3829, grad=13.2539]Training epoch 5:  39%|███▉      | 64/163 [01:18<01:39,  1.01s/it, loss=2.2001, batch_acc=0.4375, running_acc=0.3829, grad=13.2539]Training epoch 5:  39%|███▉      | 64/163 [01:18<01:39,  1.01s/it, loss=2.2833, batch_acc=0.4688, running_acc=0.3843, grad=13.6418]Training epoch 5:  40%|███▉      | 65/163 [01:19<01:43,  1.06s/it, loss=2.2833, batch_acc=0.4688, running_acc=0.3843, grad=13.6418]Training epoch 5:  40%|███▉      | 65/163 [01:19<01:43,  1.06s/it, loss=2.1042, batch_acc=0.5625, running_acc=0.3870, grad=13.7376]Training epoch 5:  40%|████      | 66/163 [01:20<01:37,  1.01s/it, loss=2.1042, batch_acc=0.5625, running_acc=0.3870, grad=13.7376]Training epoch 5:  40%|████      | 66/163 [01:20<01:37,  1.01s/it, loss=2.0916, batch_acc=0.4375, running_acc=0.3878, grad=11.6228]Training epoch 5:  41%|████      | 67/163 [01:21<01:32,  1.03it/s, loss=2.0916, batch_acc=0.4375, running_acc=0.3878, grad=11.6228]Training epoch 5:  41%|████      | 67/163 [01:21<01:32,  1.03it/s, loss=2.2885, batch_acc=0.4375, running_acc=0.3885, grad=11.7016]Training epoch 5:  42%|████▏     | 68/163 [01:22<01:29,  1.06it/s, loss=2.2885, batch_acc=0.4375, running_acc=0.3885, grad=11.7016]Training epoch 5:  42%|████▏     | 68/163 [01:22<01:29,  1.06it/s, loss=2.4162, batch_acc=0.4688, running_acc=0.3897, grad=12.0618]Training epoch 5:  42%|████▏     | 69/163 [01:24<02:02,  1.31s/it, loss=2.4162, batch_acc=0.4688, running_acc=0.3897, grad=12.0618]Training epoch 5:  42%|████▏     | 69/163 [01:24<02:02,  1.31s/it, loss=2.4246, batch_acc=0.2812, running_acc=0.3881, grad=13.2660]Training epoch 5:  43%|████▎     | 70/163 [01:25<01:49,  1.18s/it, loss=2.4246, batch_acc=0.2812, running_acc=0.3881, grad=13.2660]Training epoch 5:  43%|████▎     | 70/163 [01:25<01:49,  1.18s/it, loss=2.4807, batch_acc=0.3750, running_acc=0.3879, grad=11.8500]Training epoch 5:  44%|████▎     | 71/163 [01:26<01:40,  1.09s/it, loss=2.4807, batch_acc=0.3750, running_acc=0.3879, grad=11.8500]Training epoch 5:  44%|████▎     | 71/163 [01:26<01:40,  1.09s/it, loss=1.9697, batch_acc=0.4688, running_acc=0.3891, grad=10.4493]Training epoch 5:  44%|████▍     | 72/163 [01:26<01:33,  1.03s/it, loss=1.9697, batch_acc=0.4688, running_acc=0.3891, grad=10.4493]Training epoch 5:  44%|████▍     | 72/163 [01:26<01:33,  1.03s/it, loss=2.3370, batch_acc=0.4062, running_acc=0.3893, grad=16.0520]Training epoch 5:  45%|████▍     | 73/163 [01:28<01:49,  1.21s/it, loss=2.3370, batch_acc=0.4062, running_acc=0.3893, grad=16.0520]Training epoch 5:  45%|████▍     | 73/163 [01:28<01:49,  1.21s/it, loss=2.2292, batch_acc=0.4375, running_acc=0.3900, grad=14.3009]Training epoch 5:  45%|████▌     | 74/163 [01:29<01:39,  1.11s/it, loss=2.2292, batch_acc=0.4375, running_acc=0.3900, grad=14.3009]Training epoch 5:  45%|████▌     | 74/163 [01:29<01:39,  1.11s/it, loss=2.5152, batch_acc=0.3438, running_acc=0.3894, grad=14.1832]Training epoch 5:  46%|████▌     | 75/163 [01:30<01:31,  1.04s/it, loss=2.5152, batch_acc=0.3438, running_acc=0.3894, grad=14.1832]Training epoch 5:  46%|████▌     | 75/163 [01:30<01:31,  1.04s/it, loss=2.4608, batch_acc=0.2812, running_acc=0.3879, grad=15.0718]Training epoch 5:  47%|████▋     | 76/163 [01:31<01:26,  1.01it/s, loss=2.4608, batch_acc=0.2812, running_acc=0.3879, grad=15.0718]Training epoch 5:  47%|████▋     | 76/163 [01:31<01:26,  1.01it/s, loss=2.1701, batch_acc=0.3750, running_acc=0.3877, grad=15.3492]Training epoch 5:  47%|████▋     | 77/163 [01:33<01:48,  1.26s/it, loss=2.1701, batch_acc=0.3750, running_acc=0.3877, grad=15.3492]Training epoch 5:  47%|████▋     | 77/163 [01:33<01:48,  1.26s/it, loss=2.4327, batch_acc=0.4062, running_acc=0.3880, grad=12.9954]Training epoch 5:  48%|████▊     | 78/163 [01:33<01:37,  1.15s/it, loss=2.4327, batch_acc=0.4062, running_acc=0.3880, grad=12.9954]Training epoch 5:  48%|████▊     | 78/163 [01:33<01:37,  1.15s/it, loss=2.1675, batch_acc=0.4062, running_acc=0.3882, grad=11.1032]Training epoch 5:  48%|████▊     | 79/163 [01:34<01:29,  1.07s/it, loss=2.1675, batch_acc=0.4062, running_acc=0.3882, grad=11.1032]Training epoch 5:  48%|████▊     | 79/163 [01:34<01:29,  1.07s/it, loss=2.4752, batch_acc=0.3438, running_acc=0.3877, grad=12.5610]Training epoch 5:  49%|████▉     | 80/163 [01:35<01:23,  1.01s/it, loss=2.4752, batch_acc=0.3438, running_acc=0.3877, grad=12.5610]Training epoch 5:  49%|████▉     | 80/163 [01:35<01:23,  1.01s/it, loss=2.2313, batch_acc=0.5625, running_acc=0.3898, grad=12.9757]Training epoch 5:  50%|████▉     | 81/163 [01:37<01:39,  1.22s/it, loss=2.2313, batch_acc=0.5625, running_acc=0.3898, grad=12.9757]Training epoch 5:  50%|████▉     | 81/163 [01:37<01:39,  1.22s/it, loss=2.2650, batch_acc=0.4062, running_acc=0.3900, grad=13.8725]Training epoch 5:  50%|█████     | 82/163 [01:38<01:30,  1.12s/it, loss=2.2650, batch_acc=0.4062, running_acc=0.3900, grad=13.8725]Training epoch 5:  50%|█████     | 82/163 [01:38<01:30,  1.12s/it, loss=2.7847, batch_acc=0.1875, running_acc=0.3876, grad=13.9106]Training epoch 5:  51%|█████     | 83/163 [01:39<01:23,  1.05s/it, loss=2.7847, batch_acc=0.1875, running_acc=0.3876, grad=13.9106]Training epoch 5:  51%|█████     | 83/163 [01:39<01:23,  1.05s/it, loss=2.1555, batch_acc=0.6250, running_acc=0.3904, grad=20.0414]Training epoch 5:  52%|█████▏    | 84/163 [01:40<01:20,  1.02s/it, loss=2.1555, batch_acc=0.6250, running_acc=0.3904, grad=20.0414]Training epoch 5:  52%|█████▏    | 84/163 [01:40<01:20,  1.02s/it, loss=2.1625, batch_acc=0.4062, running_acc=0.3906, grad=16.6655]Training epoch 5:  52%|█████▏    | 85/163 [01:41<01:37,  1.25s/it, loss=2.1625, batch_acc=0.4062, running_acc=0.3906, grad=16.6655]Training epoch 5:  52%|█████▏    | 85/163 [01:41<01:37,  1.25s/it, loss=2.0821, batch_acc=0.3750, running_acc=0.3904, grad=11.7960]Training epoch 5:  53%|█████▎    | 86/163 [01:42<01:27,  1.14s/it, loss=2.0821, batch_acc=0.3750, running_acc=0.3904, grad=11.7960]Training epoch 5:  53%|█████▎    | 86/163 [01:42<01:27,  1.14s/it, loss=2.4657, batch_acc=0.3750, running_acc=0.3903, grad=18.7291]Training epoch 5:  53%|█████▎    | 87/163 [01:43<01:20,  1.06s/it, loss=2.4657, batch_acc=0.3750, running_acc=0.3903, grad=18.7291]Training epoch 5:  53%|█████▎    | 87/163 [01:43<01:20,  1.06s/it, loss=1.9252, batch_acc=0.5938, running_acc=0.3926, grad=11.6188]Training epoch 5:  54%|█████▍    | 88/163 [01:44<01:16,  1.02s/it, loss=1.9252, batch_acc=0.5938, running_acc=0.3926, grad=11.6188]Training epoch 5:  54%|█████▍    | 88/163 [01:44<01:16,  1.02s/it, loss=2.5699, batch_acc=0.2500, running_acc=0.3910, grad=14.5480]Training epoch 5:  55%|█████▍    | 89/163 [01:45<01:17,  1.04s/it, loss=2.5699, batch_acc=0.2500, running_acc=0.3910, grad=14.5480]Training epoch 5:  55%|█████▍    | 89/163 [01:45<01:17,  1.04s/it, loss=2.1448, batch_acc=0.4688, running_acc=0.3919, grad=12.3633]Training epoch 5:  55%|█████▌    | 90/163 [01:46<01:12,  1.01it/s, loss=2.1448, batch_acc=0.4688, running_acc=0.3919, grad=12.3633]Training epoch 5:  55%|█████▌    | 90/163 [01:46<01:12,  1.01it/s, loss=2.2330, batch_acc=0.5000, running_acc=0.3931, grad=12.9423]Training epoch 5:  56%|█████▌    | 91/163 [01:47<01:09,  1.04it/s, loss=2.2330, batch_acc=0.5000, running_acc=0.3931, grad=12.9423]Training epoch 5:  56%|█████▌    | 91/163 [01:47<01:09,  1.04it/s, loss=2.2019, batch_acc=0.4688, running_acc=0.3939, grad=21.8988]Training epoch 5:  56%|█████▋    | 92/163 [01:48<01:06,  1.07it/s, loss=2.2019, batch_acc=0.4688, running_acc=0.3939, grad=21.8988]Training epoch 5:  56%|█████▋    | 92/163 [01:48<01:06,  1.07it/s, loss=2.4795, batch_acc=0.3750, running_acc=0.3937, grad=14.1422]Training epoch 5:  57%|█████▋    | 93/163 [01:49<01:16,  1.09s/it, loss=2.4795, batch_acc=0.3750, running_acc=0.3937, grad=14.1422]Training epoch 5:  57%|█████▋    | 93/163 [01:49<01:16,  1.09s/it, loss=2.1855, batch_acc=0.5312, running_acc=0.3952, grad=15.5382]Training epoch 5:  58%|█████▊    | 94/163 [01:50<01:10,  1.02s/it, loss=2.1855, batch_acc=0.5312, running_acc=0.3952, grad=15.5382]Training epoch 5:  58%|█████▊    | 94/163 [01:50<01:10,  1.02s/it, loss=2.2684, batch_acc=0.4375, running_acc=0.3956, grad=14.8095]Training epoch 5:  58%|█████▊    | 95/163 [01:51<01:06,  1.02it/s, loss=2.2684, batch_acc=0.4375, running_acc=0.3956, grad=14.8095]Training epoch 5:  58%|█████▊    | 95/163 [01:51<01:06,  1.02it/s, loss=2.2747, batch_acc=0.4375, running_acc=0.3961, grad=12.2822]Training epoch 5:  59%|█████▉    | 96/163 [01:52<01:03,  1.05it/s, loss=2.2747, batch_acc=0.4375, running_acc=0.3961, grad=12.2822]Training epoch 5:  59%|█████▉    | 96/163 [01:52<01:03,  1.05it/s, loss=2.0874, batch_acc=0.5625, running_acc=0.3978, grad=10.8594]Training epoch 5:  60%|█████▉    | 97/163 [01:53<01:03,  1.04it/s, loss=2.0874, batch_acc=0.5625, running_acc=0.3978, grad=10.8594]Training epoch 5:  60%|█████▉    | 97/163 [01:53<01:03,  1.04it/s, loss=2.4202, batch_acc=0.3438, running_acc=0.3972, grad=19.2701]Training epoch 5:  60%|██████    | 98/163 [01:54<01:01,  1.06it/s, loss=2.4202, batch_acc=0.3438, running_acc=0.3972, grad=19.2701]Training epoch 5:  60%|██████    | 98/163 [01:54<01:01,  1.06it/s, loss=2.3338, batch_acc=0.4062, running_acc=0.3973, grad=13.2912]Training epoch 5:  61%|██████    | 99/163 [01:55<00:59,  1.08it/s, loss=2.3338, batch_acc=0.4062, running_acc=0.3973, grad=13.2912]Training epoch 5:  61%|██████    | 99/163 [01:55<00:59,  1.08it/s, loss=2.1834, batch_acc=0.5000, running_acc=0.3984, grad=16.7865]Training epoch 5:  61%|██████▏   | 100/163 [01:56<01:08,  1.08s/it, loss=2.1834, batch_acc=0.5000, running_acc=0.3984, grad=16.7865]Training epoch 5:  61%|██████▏   | 100/163 [01:56<01:08,  1.08s/it, loss=2.2827, batch_acc=0.4688, running_acc=0.3991, grad=14.6749]Training epoch 5:  62%|██████▏   | 101/163 [01:57<01:09,  1.12s/it, loss=2.2827, batch_acc=0.4688, running_acc=0.3991, grad=14.6749]Training epoch 5:  62%|██████▏   | 101/163 [01:57<01:09,  1.12s/it, loss=2.3615, batch_acc=0.3438, running_acc=0.3985, grad=14.5573]Training epoch 5:  63%|██████▎   | 102/163 [01:58<01:03,  1.05s/it, loss=2.3615, batch_acc=0.3438, running_acc=0.3985, grad=14.5573]Training epoch 5:  63%|██████▎   | 102/163 [01:58<01:03,  1.05s/it, loss=2.1075, batch_acc=0.4062, running_acc=0.3986, grad=20.0197]Training epoch 5:  63%|██████▎   | 103/163 [01:59<00:59,  1.00it/s, loss=2.1075, batch_acc=0.4062, running_acc=0.3986, grad=20.0197]Training epoch 5:  63%|██████▎   | 103/163 [01:59<00:59,  1.00it/s, loss=2.2304, batch_acc=0.5312, running_acc=0.3999, grad=11.0906]Training epoch 5:  64%|██████▍   | 104/163 [02:01<01:15,  1.28s/it, loss=2.2304, batch_acc=0.5312, running_acc=0.3999, grad=11.0906]Training epoch 5:  64%|██████▍   | 104/163 [02:01<01:15,  1.28s/it, loss=2.1460, batch_acc=0.4375, running_acc=0.4002, grad=12.1980]Training epoch 5:  64%|██████▍   | 105/163 [02:02<01:07,  1.16s/it, loss=2.1460, batch_acc=0.4375, running_acc=0.4002, grad=12.1980]Training epoch 5:  64%|██████▍   | 105/163 [02:02<01:07,  1.16s/it, loss=1.9465, batch_acc=0.4375, running_acc=0.4006, grad=12.2538]Training epoch 5:  65%|██████▌   | 106/163 [02:03<01:01,  1.08s/it, loss=1.9465, batch_acc=0.4375, running_acc=0.4006, grad=12.2538]Training epoch 5:  65%|██████▌   | 106/163 [02:03<01:01,  1.08s/it, loss=2.4090, batch_acc=0.3125, running_acc=0.3998, grad=16.3829]Training epoch 5:  66%|██████▌   | 107/163 [02:04<00:57,  1.02s/it, loss=2.4090, batch_acc=0.3125, running_acc=0.3998, grad=16.3829]Training epoch 5:  66%|██████▌   | 107/163 [02:04<00:57,  1.02s/it, loss=2.4124, batch_acc=0.3125, running_acc=0.3989, grad=20.1254]Training epoch 5:  66%|██████▋   | 108/163 [02:05<01:05,  1.20s/it, loss=2.4124, batch_acc=0.3125, running_acc=0.3989, grad=20.1254]Training epoch 5:  66%|██████▋   | 108/163 [02:05<01:05,  1.20s/it, loss=2.2492, batch_acc=0.3750, running_acc=0.3987, grad=17.8429]Training epoch 5:  67%|██████▋   | 109/163 [02:06<00:59,  1.10s/it, loss=2.2492, batch_acc=0.3750, running_acc=0.3987, grad=17.8429]Training epoch 5:  67%|██████▋   | 109/163 [02:06<00:59,  1.10s/it, loss=2.4748, batch_acc=0.2500, running_acc=0.3974, grad=13.2525]Training epoch 5:  67%|██████▋   | 110/163 [02:07<00:54,  1.04s/it, loss=2.4748, batch_acc=0.2500, running_acc=0.3974, grad=13.2525]Training epoch 5:  67%|██████▋   | 110/163 [02:07<00:54,  1.04s/it, loss=2.2827, batch_acc=0.4375, running_acc=0.3977, grad=11.7452]Training epoch 5:  68%|██████▊   | 111/163 [02:08<00:51,  1.01it/s, loss=2.2827, batch_acc=0.4375, running_acc=0.3977, grad=11.7452]Training epoch 5:  68%|██████▊   | 111/163 [02:08<00:51,  1.01it/s, loss=2.3363, batch_acc=0.3125, running_acc=0.3970, grad=12.3328]Training epoch 5:  69%|██████▊   | 112/163 [02:10<01:01,  1.21s/it, loss=2.3363, batch_acc=0.3125, running_acc=0.3970, grad=12.3328]Training epoch 5:  69%|██████▊   | 112/163 [02:10<01:01,  1.21s/it, loss=2.4416, batch_acc=0.4062, running_acc=0.3970, grad=13.2241]Training epoch 5:  69%|██████▉   | 113/163 [02:11<00:55,  1.11s/it, loss=2.4416, batch_acc=0.4062, running_acc=0.3970, grad=13.2241]Training epoch 5:  69%|██████▉   | 113/163 [02:11<00:55,  1.11s/it, loss=2.3620, batch_acc=0.3750, running_acc=0.3968, grad=10.0140]Training epoch 5:  70%|██████▉   | 114/163 [02:11<00:51,  1.04s/it, loss=2.3620, batch_acc=0.3750, running_acc=0.3968, grad=10.0140]Training epoch 5:  70%|██████▉   | 114/163 [02:11<00:51,  1.04s/it, loss=2.2428, batch_acc=0.3438, running_acc=0.3964, grad=11.2478]Training epoch 5:  71%|███████   | 115/163 [02:12<00:47,  1.01it/s, loss=2.2428, batch_acc=0.3438, running_acc=0.3964, grad=11.2478]Training epoch 5:  71%|███████   | 115/163 [02:12<00:47,  1.01it/s, loss=2.3884, batch_acc=0.4375, running_acc=0.3967, grad=12.0880]Training epoch 5:  71%|███████   | 116/163 [02:14<01:01,  1.32s/it, loss=2.3884, batch_acc=0.4375, running_acc=0.3967, grad=12.0880]Training epoch 5:  71%|███████   | 116/163 [02:14<01:01,  1.32s/it, loss=2.2160, batch_acc=0.5000, running_acc=0.3976, grad=14.4126]Training epoch 5:  72%|███████▏  | 117/163 [02:15<00:54,  1.18s/it, loss=2.2160, batch_acc=0.5000, running_acc=0.3976, grad=14.4126]Training epoch 5:  72%|███████▏  | 117/163 [02:15<00:54,  1.18s/it, loss=2.3686, batch_acc=0.2812, running_acc=0.3966, grad=15.4216]Training epoch 5:  72%|███████▏  | 118/163 [02:16<00:49,  1.09s/it, loss=2.3686, batch_acc=0.2812, running_acc=0.3966, grad=15.4216]Training epoch 5:  72%|███████▏  | 118/163 [02:16<00:49,  1.09s/it, loss=2.0596, batch_acc=0.5312, running_acc=0.3978, grad=11.6804]Training epoch 5:  73%|███████▎  | 119/163 [02:17<00:45,  1.03s/it, loss=2.0596, batch_acc=0.5312, running_acc=0.3978, grad=11.6804]Training epoch 5:  73%|███████▎  | 119/163 [02:17<00:45,  1.03s/it, loss=2.1992, batch_acc=0.5000, running_acc=0.3986, grad=13.3584]Training epoch 5:  74%|███████▎  | 120/163 [02:19<00:53,  1.24s/it, loss=2.1992, batch_acc=0.5000, running_acc=0.3986, grad=13.3584]Training epoch 5:  74%|███████▎  | 120/163 [02:19<00:53,  1.24s/it, loss=2.4711, batch_acc=0.3750, running_acc=0.3984, grad=16.2804]Training epoch 5:  74%|███████▍  | 121/163 [02:20<00:47,  1.13s/it, loss=2.4711, batch_acc=0.3750, running_acc=0.3984, grad=16.2804]Training epoch 5:  74%|███████▍  | 121/163 [02:20<00:47,  1.13s/it, loss=2.1283, batch_acc=0.3750, running_acc=0.3982, grad=14.3969]Training epoch 5:  75%|███████▍  | 122/163 [02:21<00:43,  1.06s/it, loss=2.1283, batch_acc=0.3750, running_acc=0.3982, grad=14.3969]Training epoch 5:  75%|███████▍  | 122/163 [02:21<00:43,  1.06s/it, loss=2.1753, batch_acc=0.4688, running_acc=0.3988, grad=12.8669]Training epoch 5:  75%|███████▌  | 123/163 [02:21<00:40,  1.00s/it, loss=2.1753, batch_acc=0.4688, running_acc=0.3988, grad=12.8669]Training epoch 5:  75%|███████▌  | 123/163 [02:21<00:40,  1.00s/it, loss=2.0215, batch_acc=0.4688, running_acc=0.3994, grad=12.5718]Training epoch 5:  76%|███████▌  | 124/163 [02:23<00:50,  1.31s/it, loss=2.0215, batch_acc=0.4688, running_acc=0.3994, grad=12.5718]Training epoch 5:  76%|███████▌  | 124/163 [02:23<00:50,  1.31s/it, loss=2.2295, batch_acc=0.4688, running_acc=0.3999, grad=13.0249]Training epoch 5:  77%|███████▋  | 125/163 [02:24<00:44,  1.18s/it, loss=2.2295, batch_acc=0.4688, running_acc=0.3999, grad=13.0249]Training epoch 5:  77%|███████▋  | 125/163 [02:24<00:44,  1.18s/it, loss=2.4124, batch_acc=0.4688, running_acc=0.4005, grad=15.9963]Training epoch 5:  77%|███████▋  | 126/163 [02:25<00:40,  1.09s/it, loss=2.4124, batch_acc=0.4688, running_acc=0.4005, grad=15.9963]Training epoch 5:  77%|███████▋  | 126/163 [02:25<00:40,  1.09s/it, loss=2.2875, batch_acc=0.3438, running_acc=0.4000, grad=12.8861]Training epoch 5:  78%|███████▊  | 127/163 [02:26<00:36,  1.03s/it, loss=2.2875, batch_acc=0.3438, running_acc=0.4000, grad=12.8861]Training epoch 5:  78%|███████▊  | 127/163 [02:26<00:36,  1.03s/it, loss=2.7563, batch_acc=0.3125, running_acc=0.3994, grad=19.2402]Training epoch 5:  79%|███████▊  | 128/163 [02:28<00:41,  1.19s/it, loss=2.7563, batch_acc=0.3125, running_acc=0.3994, grad=19.2402]Training epoch 5:  79%|███████▊  | 128/163 [02:28<00:41,  1.19s/it, loss=2.1033, batch_acc=0.4062, running_acc=0.3994, grad=14.2025]Training epoch 5:  79%|███████▉  | 129/163 [02:29<00:37,  1.10s/it, loss=2.1033, batch_acc=0.4062, running_acc=0.3994, grad=14.2025]Training epoch 5:  79%|███████▉  | 129/163 [02:29<00:37,  1.10s/it, loss=2.7997, batch_acc=0.2812, running_acc=0.3985, grad=11.9453]Training epoch 5:  80%|███████▉  | 130/163 [02:29<00:34,  1.03s/it, loss=2.7997, batch_acc=0.2812, running_acc=0.3985, grad=11.9453]Training epoch 5:  80%|███████▉  | 130/163 [02:29<00:34,  1.03s/it, loss=2.3681, batch_acc=0.3438, running_acc=0.3981, grad=14.4821]Training epoch 5:  80%|████████  | 131/163 [02:30<00:31,  1.01it/s, loss=2.3681, batch_acc=0.3438, running_acc=0.3981, grad=14.4821]Training epoch 5:  80%|████████  | 131/163 [02:30<00:31,  1.01it/s, loss=1.9079, batch_acc=0.5312, running_acc=0.3991, grad=13.9718]Training epoch 5:  81%|████████  | 132/163 [02:32<00:33,  1.07s/it, loss=1.9079, batch_acc=0.5312, running_acc=0.3991, grad=13.9718]Training epoch 5:  81%|████████  | 132/163 [02:32<00:33,  1.07s/it, loss=2.2421, batch_acc=0.5312, running_acc=0.4001, grad=12.9821]Training epoch 5:  82%|████████▏ | 133/163 [02:32<00:30,  1.01s/it, loss=2.2421, batch_acc=0.5312, running_acc=0.4001, grad=12.9821]Training epoch 5:  82%|████████▏ | 133/163 [02:32<00:30,  1.01s/it, loss=2.2230, batch_acc=0.4375, running_acc=0.4004, grad=13.6482]Training epoch 5:  82%|████████▏ | 134/163 [02:33<00:28,  1.03it/s, loss=2.2230, batch_acc=0.4375, running_acc=0.4004, grad=13.6482]Training epoch 5:  82%|████████▏ | 134/163 [02:33<00:28,  1.03it/s, loss=2.5582, batch_acc=0.3125, running_acc=0.3997, grad=15.5273]Training epoch 5:  83%|████████▎ | 135/163 [02:34<00:26,  1.06it/s, loss=2.5582, batch_acc=0.3125, running_acc=0.3997, grad=15.5273]Training epoch 5:  83%|████████▎ | 135/163 [02:34<00:26,  1.06it/s, loss=2.3838, batch_acc=0.3750, running_acc=0.3995, grad=12.9308]Training epoch 5:  83%|████████▎ | 136/163 [02:36<00:32,  1.20s/it, loss=2.3838, batch_acc=0.3750, running_acc=0.3995, grad=12.9308]Training epoch 5:  83%|████████▎ | 136/163 [02:36<00:32,  1.20s/it, loss=2.1649, batch_acc=0.3750, running_acc=0.3994, grad=12.8231]Training epoch 5:  84%|████████▍ | 137/163 [02:37<00:28,  1.10s/it, loss=2.1649, batch_acc=0.3750, running_acc=0.3994, grad=12.8231]Training epoch 5:  84%|████████▍ | 137/163 [02:37<00:28,  1.10s/it, loss=2.2213, batch_acc=0.4688, running_acc=0.3999, grad=14.3897]Training epoch 5:  85%|████████▍ | 138/163 [02:38<00:25,  1.04s/it, loss=2.2213, batch_acc=0.4688, running_acc=0.3999, grad=14.3897]Training epoch 5:  85%|████████▍ | 138/163 [02:38<00:25,  1.04s/it, loss=2.1301, batch_acc=0.5312, running_acc=0.4008, grad=12.2292]Training epoch 5:  85%|████████▌ | 139/163 [02:39<00:23,  1.01it/s, loss=2.1301, batch_acc=0.5312, running_acc=0.4008, grad=12.2292]Training epoch 5:  85%|████████▌ | 139/163 [02:39<00:23,  1.01it/s, loss=2.0423, batch_acc=0.5312, running_acc=0.4018, grad=22.6784]Training epoch 5:  86%|████████▌ | 140/163 [02:41<00:30,  1.31s/it, loss=2.0423, batch_acc=0.5312, running_acc=0.4018, grad=22.6784]Training epoch 5:  86%|████████▌ | 140/163 [02:41<00:30,  1.31s/it, loss=2.4496, batch_acc=0.3125, running_acc=0.4011, grad=16.0272]Training epoch 5:  87%|████████▋ | 141/163 [02:42<00:26,  1.18s/it, loss=2.4496, batch_acc=0.3125, running_acc=0.4011, grad=16.0272]Training epoch 5:  87%|████████▋ | 141/163 [02:42<00:26,  1.18s/it, loss=2.4828, batch_acc=0.3125, running_acc=0.4005, grad=12.6461]Training epoch 5:  87%|████████▋ | 142/163 [02:42<00:22,  1.09s/it, loss=2.4828, batch_acc=0.3125, running_acc=0.4005, grad=12.6461]Training epoch 5:  87%|████████▋ | 142/163 [02:42<00:22,  1.09s/it, loss=2.2644, batch_acc=0.4375, running_acc=0.4007, grad=12.3546]Training epoch 5:  88%|████████▊ | 143/163 [02:43<00:20,  1.03s/it, loss=2.2644, batch_acc=0.4375, running_acc=0.4007, grad=12.3546]Training epoch 5:  88%|████████▊ | 143/163 [02:43<00:20,  1.03s/it, loss=2.2558, batch_acc=0.3125, running_acc=0.4001, grad=15.5565]Training epoch 5:  88%|████████▊ | 144/163 [02:45<00:22,  1.16s/it, loss=2.2558, batch_acc=0.3125, running_acc=0.4001, grad=15.5565]Training epoch 5:  88%|████████▊ | 144/163 [02:45<00:22,  1.16s/it, loss=2.3318, batch_acc=0.3438, running_acc=0.3997, grad=13.7146]Training epoch 5:  89%|████████▉ | 145/163 [02:46<00:19,  1.08s/it, loss=2.3318, batch_acc=0.3438, running_acc=0.3997, grad=13.7146]Training epoch 5:  89%|████████▉ | 145/163 [02:46<00:19,  1.08s/it, loss=2.1006, batch_acc=0.4688, running_acc=0.4002, grad=10.0409]Training epoch 5:  90%|████████▉ | 146/163 [02:47<00:17,  1.02s/it, loss=2.1006, batch_acc=0.4688, running_acc=0.4002, grad=10.0409]Training epoch 5:  90%|████████▉ | 146/163 [02:47<00:17,  1.02s/it, loss=2.1343, batch_acc=0.4688, running_acc=0.4007, grad=16.6404]Training epoch 5:  90%|█████████ | 147/163 [02:47<00:15,  1.03it/s, loss=2.1343, batch_acc=0.4688, running_acc=0.4007, grad=16.6404]Training epoch 5:  90%|█████████ | 147/163 [02:47<00:15,  1.03it/s, loss=2.2473, batch_acc=0.3750, running_acc=0.4005, grad=21.3514]Training epoch 5:  91%|█████████ | 148/163 [02:49<00:16,  1.12s/it, loss=2.2473, batch_acc=0.3750, running_acc=0.4005, grad=21.3514]Training epoch 5:  91%|█████████ | 148/163 [02:49<00:16,  1.12s/it, loss=1.9838, batch_acc=0.5000, running_acc=0.4012, grad=10.2266]Training epoch 5:  91%|█████████▏| 149/163 [02:50<00:14,  1.05s/it, loss=1.9838, batch_acc=0.5000, running_acc=0.4012, grad=10.2266]Training epoch 5:  91%|█████████▏| 149/163 [02:50<00:14,  1.05s/it, loss=2.2073, batch_acc=0.4375, running_acc=0.4014, grad=11.2639]Training epoch 5:  92%|█████████▏| 150/163 [02:51<00:12,  1.00it/s, loss=2.2073, batch_acc=0.4375, running_acc=0.4014, grad=11.2639]Training epoch 5:  92%|█████████▏| 150/163 [02:51<00:12,  1.00it/s, loss=2.3813, batch_acc=0.4062, running_acc=0.4015, grad=15.3129]Training epoch 5:  93%|█████████▎| 151/163 [02:52<00:11,  1.04it/s, loss=2.3813, batch_acc=0.4062, running_acc=0.4015, grad=15.3129]Training epoch 5:  93%|█████████▎| 151/163 [02:52<00:11,  1.04it/s, loss=2.4395, batch_acc=0.3438, running_acc=0.4011, grad=12.9286]Training epoch 5:  93%|█████████▎| 152/163 [02:53<00:13,  1.19s/it, loss=2.4395, batch_acc=0.3438, running_acc=0.4011, grad=12.9286]Training epoch 5:  93%|█████████▎| 152/163 [02:53<00:13,  1.19s/it, loss=2.4327, batch_acc=0.4375, running_acc=0.4013, grad=13.9529]Training epoch 5:  94%|█████████▍| 153/163 [02:54<00:10,  1.10s/it, loss=2.4327, batch_acc=0.4375, running_acc=0.4013, grad=13.9529]Training epoch 5:  94%|█████████▍| 153/163 [02:54<00:10,  1.10s/it, loss=2.4626, batch_acc=0.4375, running_acc=0.4016, grad=16.1438]Training epoch 5:  94%|█████████▍| 154/163 [02:55<00:09,  1.03s/it, loss=2.4626, batch_acc=0.4375, running_acc=0.4016, grad=16.1438]Training epoch 5:  94%|█████████▍| 154/163 [02:55<00:09,  1.03s/it, loss=2.0633, batch_acc=0.4062, running_acc=0.4016, grad=13.1923]Training epoch 5:  95%|█████████▌| 155/163 [02:56<00:07,  1.01it/s, loss=2.0633, batch_acc=0.4062, running_acc=0.4016, grad=13.1923]Training epoch 5:  95%|█████████▌| 155/163 [02:56<00:07,  1.01it/s, loss=2.2987, batch_acc=0.5625, running_acc=0.4026, grad=13.4359]Training epoch 5:  96%|█████████▌| 156/163 [02:57<00:07,  1.06s/it, loss=2.2987, batch_acc=0.5625, running_acc=0.4026, grad=13.4359]Training epoch 5:  96%|█████████▌| 156/163 [02:57<00:07,  1.06s/it, loss=2.2589, batch_acc=0.4688, running_acc=0.4030, grad=11.3320]Training epoch 5:  96%|█████████▋| 157/163 [02:58<00:06,  1.00s/it, loss=2.2589, batch_acc=0.4688, running_acc=0.4030, grad=11.3320]Training epoch 5:  96%|█████████▋| 157/163 [02:58<00:06,  1.00s/it, loss=2.2464, batch_acc=0.4062, running_acc=0.4031, grad=11.9286]Training epoch 5:  97%|█████████▋| 158/163 [02:59<00:04,  1.04it/s, loss=2.2464, batch_acc=0.4062, running_acc=0.4031, grad=11.9286]Training epoch 5:  97%|█████████▋| 158/163 [02:59<00:04,  1.04it/s, loss=1.9392, batch_acc=0.4375, running_acc=0.4033, grad=13.8167]Training epoch 5:  98%|█████████▊| 159/163 [03:00<00:03,  1.06it/s, loss=1.9392, batch_acc=0.4375, running_acc=0.4033, grad=13.8167]Training epoch 5:  98%|█████████▊| 159/163 [03:00<00:03,  1.06it/s, loss=2.4683, batch_acc=0.2500, running_acc=0.4023, grad=15.7462]Training epoch 5:  98%|█████████▊| 160/163 [03:01<00:03,  1.06s/it, loss=2.4683, batch_acc=0.2500, running_acc=0.4023, grad=15.7462]Training epoch 5:  98%|█████████▊| 160/163 [03:01<00:03,  1.06s/it, loss=2.3415, batch_acc=0.4688, running_acc=0.4027, grad=13.3198]Training epoch 5:  99%|█████████▉| 161/163 [03:02<00:02,  1.01s/it, loss=2.3415, batch_acc=0.4688, running_acc=0.4027, grad=13.3198]Training epoch 5:  99%|█████████▉| 161/163 [03:02<00:02,  1.01s/it, loss=2.3498, batch_acc=0.3750, running_acc=0.4026, grad=12.6698]Training epoch 5:  99%|█████████▉| 162/163 [03:03<00:00,  1.03it/s, loss=2.3498, batch_acc=0.3750, running_acc=0.4026, grad=12.6698]Training epoch 5:  99%|█████████▉| 162/163 [03:03<00:00,  1.03it/s, loss=2.3200, batch_acc=0.4688, running_acc=0.4030, grad=12.3178]Training epoch 5: 100%|██████████| 163/163 [03:03<00:00,  1.15it/s, loss=2.3200, batch_acc=0.4688, running_acc=0.4030, grad=12.3178]Training epoch 5: 100%|██████████| 163/163 [03:03<00:00,  1.15it/s, loss=2.2686, batch_acc=0.4762, running_acc=0.4033, grad=17.4206]Training epoch 5: 100%|██████████| 163/163 [03:03<00:00,  1.13s/it, loss=2.2686, batch_acc=0.4762, running_acc=0.4033, grad=17.4206]
Evaluation epoch 5:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 5:   4%|▎         | 1/28 [00:05<02:18,  5.12s/it]Evaluation epoch 5:   4%|▎         | 1/28 [00:05<02:18,  5.12s/it, loss=1.8948, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 5:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=1.8948, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 5:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=1.9383, batch_acc=0.5312, running_acc=0.5469]Evaluation epoch 5:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=1.9383, batch_acc=0.5312, running_acc=0.5469]Evaluation epoch 5:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=2.0549, batch_acc=0.4375, running_acc=0.5104]Evaluation epoch 5:  14%|█▍        | 4/28 [00:10<01:01,  2.58s/it, loss=2.0549, batch_acc=0.4375, running_acc=0.5104]Evaluation epoch 5:  14%|█▍        | 4/28 [00:10<01:01,  2.58s/it, loss=2.6480, batch_acc=0.2500, running_acc=0.4453]Evaluation epoch 5:  18%|█▊        | 5/28 [00:10<00:40,  1.74s/it, loss=2.6480, batch_acc=0.2500, running_acc=0.4453]Evaluation epoch 5:  18%|█▊        | 5/28 [00:10<00:40,  1.74s/it, loss=2.8024, batch_acc=0.1562, running_acc=0.3875]Evaluation epoch 5:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=2.8024, batch_acc=0.1562, running_acc=0.3875]Evaluation epoch 5:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=2.7059, batch_acc=0.2188, running_acc=0.3594]Evaluation epoch 5:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=2.7059, batch_acc=0.2188, running_acc=0.3594]Evaluation epoch 5:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=2.5623, batch_acc=0.2812, running_acc=0.3482]Evaluation epoch 5:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=2.5623, batch_acc=0.2812, running_acc=0.3482]Evaluation epoch 5:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=2.3385, batch_acc=0.3750, running_acc=0.3516]Evaluation epoch 5:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=2.3385, batch_acc=0.3750, running_acc=0.3516]Evaluation epoch 5:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=2.5032, batch_acc=0.3438, running_acc=0.3507]Evaluation epoch 5:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=2.5032, batch_acc=0.3438, running_acc=0.3507]Evaluation epoch 5:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=1.0657, batch_acc=0.8438, running_acc=0.4000]Evaluation epoch 5:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=1.0657, batch_acc=0.8438, running_acc=0.4000]Evaluation epoch 5:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=2.4877, batch_acc=0.2812, running_acc=0.3892]Evaluation epoch 5:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.4877, batch_acc=0.2812, running_acc=0.3892]Evaluation epoch 5:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.2011, batch_acc=0.4375, running_acc=0.3932]Evaluation epoch 5:  46%|████▋     | 13/28 [00:20<00:24,  1.62s/it, loss=2.2011, batch_acc=0.4375, running_acc=0.3932]Evaluation epoch 5:  46%|████▋     | 13/28 [00:20<00:24,  1.62s/it, loss=2.2325, batch_acc=0.2812, running_acc=0.3846]Evaluation epoch 5:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=2.2325, batch_acc=0.2812, running_acc=0.3846]Evaluation epoch 5:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=2.6326, batch_acc=0.3750, running_acc=0.3839]Evaluation epoch 5:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.6326, batch_acc=0.3750, running_acc=0.3839]Evaluation epoch 5:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=3.1969, batch_acc=0.2188, running_acc=0.3729]Evaluation epoch 5:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=3.1969, batch_acc=0.2188, running_acc=0.3729]Evaluation epoch 5:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=2.8842, batch_acc=0.1250, running_acc=0.3574]Evaluation epoch 5:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=2.8842, batch_acc=0.1250, running_acc=0.3574]Evaluation epoch 5:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=2.3437, batch_acc=0.4375, running_acc=0.3621]Evaluation epoch 5:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=2.3437, batch_acc=0.4375, running_acc=0.3621]Evaluation epoch 5:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=1.6097, batch_acc=0.6875, running_acc=0.3802]Evaluation epoch 5:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=1.6097, batch_acc=0.6875, running_acc=0.3802]Evaluation epoch 5:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=2.1400, batch_acc=0.4062, running_acc=0.3816]Evaluation epoch 5:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=2.1400, batch_acc=0.4062, running_acc=0.3816]Evaluation epoch 5:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=2.2794, batch_acc=0.4062, running_acc=0.3828]Evaluation epoch 5:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=2.2794, batch_acc=0.4062, running_acc=0.3828]Evaluation epoch 5:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=2.6168, batch_acc=0.2812, running_acc=0.3780]Evaluation epoch 5:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=2.6168, batch_acc=0.2812, running_acc=0.3780]Evaluation epoch 5:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=2.5849, batch_acc=0.3125, running_acc=0.3750]Evaluation epoch 5:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=2.5849, batch_acc=0.3125, running_acc=0.3750]Evaluation epoch 5:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=2.1730, batch_acc=0.4062, running_acc=0.3764]Evaluation epoch 5:  86%|████████▌ | 24/28 [00:34<00:08,  2.03s/it, loss=2.1730, batch_acc=0.4062, running_acc=0.3764]Evaluation epoch 5:  86%|████████▌ | 24/28 [00:34<00:08,  2.03s/it, loss=1.8065, batch_acc=0.5625, running_acc=0.3841]Evaluation epoch 5:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=1.8065, batch_acc=0.5625, running_acc=0.3841]Evaluation epoch 5:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=1.5520, batch_acc=0.6562, running_acc=0.3950]Evaluation epoch 5:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=1.5520, batch_acc=0.6562, running_acc=0.3950]Evaluation epoch 5:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=2.1236, batch_acc=0.4375, running_acc=0.3966]Evaluation epoch 5:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=2.1236, batch_acc=0.4375, running_acc=0.3966]Evaluation epoch 5:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=2.2658, batch_acc=0.3125, running_acc=0.3935]Evaluation epoch 5: 100%|██████████| 28/28 [00:35<00:00,  1.15it/s, loss=1.1982, batch_acc=1.0000, running_acc=0.3956]Evaluation epoch 5: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=1.1982, batch_acc=1.0000, running_acc=0.3956]
Training epoch 6:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 6:   1%|          | 1/163 [00:05<15:35,  5.77s/it]Training epoch 6:   1%|          | 1/163 [00:05<15:35,  5.77s/it, loss=1.8906, batch_acc=0.5312, running_acc=0.5312, grad=11.0240]Training epoch 6:   1%|          | 2/163 [00:06<07:45,  2.89s/it, loss=1.8906, batch_acc=0.5312, running_acc=0.5312, grad=11.0240]Training epoch 6:   1%|          | 2/163 [00:06<07:45,  2.89s/it, loss=2.0734, batch_acc=0.4375, running_acc=0.4844, grad=16.4487]Training epoch 6:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=2.0734, batch_acc=0.4375, running_acc=0.4844, grad=16.4487]Training epoch 6:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=2.1235, batch_acc=0.4062, running_acc=0.4583, grad=13.0255]Training epoch 6:   2%|▏         | 4/163 [00:09<05:07,  1.93s/it, loss=2.1235, batch_acc=0.4062, running_acc=0.4583, grad=13.0255]Training epoch 6:   2%|▏         | 4/163 [00:09<05:07,  1.93s/it, loss=1.9490, batch_acc=0.5312, running_acc=0.4766, grad=11.0693]Training epoch 6:   3%|▎         | 5/163 [00:10<04:05,  1.55s/it, loss=1.9490, batch_acc=0.5312, running_acc=0.4766, grad=11.0693]Training epoch 6:   3%|▎         | 5/163 [00:10<04:05,  1.55s/it, loss=1.6943, batch_acc=0.6875, running_acc=0.5188, grad=17.1488]Training epoch 6:   4%|▎         | 6/163 [00:11<03:27,  1.32s/it, loss=1.6943, batch_acc=0.6875, running_acc=0.5188, grad=17.1488]Training epoch 6:   4%|▎         | 6/163 [00:11<03:27,  1.32s/it, loss=2.2032, batch_acc=0.3438, running_acc=0.4896, grad=14.5697]Training epoch 6:   4%|▍         | 7/163 [00:12<03:03,  1.18s/it, loss=2.2032, batch_acc=0.3438, running_acc=0.4896, grad=14.5697]Training epoch 6:   4%|▍         | 7/163 [00:12<03:03,  1.18s/it, loss=2.0192, batch_acc=0.4375, running_acc=0.4821, grad=11.8165]Training epoch 6:   5%|▍         | 8/163 [00:14<03:51,  1.49s/it, loss=2.0192, batch_acc=0.4375, running_acc=0.4821, grad=11.8165]Training epoch 6:   5%|▍         | 8/163 [00:14<03:51,  1.49s/it, loss=2.2898, batch_acc=0.3125, running_acc=0.4609, grad=13.3198]Training epoch 6:   6%|▌         | 9/163 [00:15<03:20,  1.30s/it, loss=2.2898, batch_acc=0.3125, running_acc=0.4609, grad=13.3198]Training epoch 6:   6%|▌         | 9/163 [00:15<03:20,  1.30s/it, loss=2.1156, batch_acc=0.5000, running_acc=0.4653, grad=26.4910]Training epoch 6:   6%|▌         | 10/163 [00:15<02:58,  1.17s/it, loss=2.1156, batch_acc=0.5000, running_acc=0.4653, grad=26.4910]Training epoch 6:   6%|▌         | 10/163 [00:15<02:58,  1.17s/it, loss=2.2728, batch_acc=0.3750, running_acc=0.4562, grad=13.5728]Training epoch 6:   7%|▋         | 11/163 [00:16<02:44,  1.08s/it, loss=2.2728, batch_acc=0.3750, running_acc=0.4562, grad=13.5728]Training epoch 6:   7%|▋         | 11/163 [00:16<02:44,  1.08s/it, loss=2.3726, batch_acc=0.3750, running_acc=0.4489, grad=12.2952]Training epoch 6:   7%|▋         | 12/163 [00:19<03:38,  1.44s/it, loss=2.3726, batch_acc=0.3750, running_acc=0.4489, grad=12.2952]Training epoch 6:   7%|▋         | 12/163 [00:19<03:38,  1.44s/it, loss=2.0128, batch_acc=0.5312, running_acc=0.4557, grad=14.7223]Training epoch 6:   8%|▊         | 13/163 [00:19<03:10,  1.27s/it, loss=2.0128, batch_acc=0.5312, running_acc=0.4557, grad=14.7223]Training epoch 6:   8%|▊         | 13/163 [00:19<03:10,  1.27s/it, loss=2.1784, batch_acc=0.3750, running_acc=0.4495, grad=11.1743]Training epoch 6:   9%|▊         | 14/163 [00:20<02:51,  1.15s/it, loss=2.1784, batch_acc=0.3750, running_acc=0.4495, grad=11.1743]Training epoch 6:   9%|▊         | 14/163 [00:20<02:51,  1.15s/it, loss=2.1805, batch_acc=0.5000, running_acc=0.4531, grad=18.5642]Training epoch 6:   9%|▉         | 15/163 [00:21<02:38,  1.07s/it, loss=2.1805, batch_acc=0.5000, running_acc=0.4531, grad=18.5642]Training epoch 6:   9%|▉         | 15/163 [00:21<02:38,  1.07s/it, loss=1.9247, batch_acc=0.4688, running_acc=0.4542, grad=13.9451]Training epoch 6:  10%|▉         | 16/163 [00:23<03:10,  1.30s/it, loss=1.9247, batch_acc=0.4688, running_acc=0.4542, grad=13.9451]Training epoch 6:  10%|▉         | 16/163 [00:23<03:10,  1.30s/it, loss=2.0726, batch_acc=0.5625, running_acc=0.4609, grad=19.4323]Training epoch 6:  10%|█         | 17/163 [00:24<02:51,  1.17s/it, loss=2.0726, batch_acc=0.5625, running_acc=0.4609, grad=19.4323]Training epoch 6:  10%|█         | 17/163 [00:24<02:51,  1.17s/it, loss=2.1988, batch_acc=0.5312, running_acc=0.4651, grad=11.8767]Training epoch 6:  11%|█         | 18/163 [00:25<02:37,  1.08s/it, loss=2.1988, batch_acc=0.5312, running_acc=0.4651, grad=11.8767]Training epoch 6:  11%|█         | 18/163 [00:25<02:37,  1.08s/it, loss=2.1089, batch_acc=0.4688, running_acc=0.4653, grad=13.2986]Training epoch 6:  12%|█▏        | 19/163 [00:26<02:27,  1.02s/it, loss=2.1089, batch_acc=0.4688, running_acc=0.4653, grad=13.2986]Training epoch 6:  12%|█▏        | 19/163 [00:26<02:27,  1.02s/it, loss=2.0633, batch_acc=0.4688, running_acc=0.4655, grad=11.1363]Training epoch 6:  12%|█▏        | 20/163 [00:27<02:48,  1.18s/it, loss=2.0633, batch_acc=0.4688, running_acc=0.4655, grad=11.1363]Training epoch 6:  12%|█▏        | 20/163 [00:27<02:48,  1.18s/it, loss=2.2021, batch_acc=0.4062, running_acc=0.4625, grad=22.9073]Training epoch 6:  13%|█▎        | 21/163 [00:28<02:34,  1.09s/it, loss=2.2021, batch_acc=0.4062, running_acc=0.4625, grad=22.9073]Training epoch 6:  13%|█▎        | 21/163 [00:28<02:34,  1.09s/it, loss=2.0798, batch_acc=0.5625, running_acc=0.4673, grad=11.1666]Training epoch 6:  13%|█▎        | 22/163 [00:29<02:41,  1.15s/it, loss=2.0798, batch_acc=0.5625, running_acc=0.4673, grad=11.1666]Training epoch 6:  13%|█▎        | 22/163 [00:29<02:41,  1.15s/it, loss=2.3781, batch_acc=0.4688, running_acc=0.4673, grad=11.3239]Training epoch 6:  14%|█▍        | 23/163 [00:30<02:29,  1.07s/it, loss=2.3781, batch_acc=0.4688, running_acc=0.4673, grad=11.3239]Training epoch 6:  14%|█▍        | 23/163 [00:30<02:29,  1.07s/it, loss=2.1473, batch_acc=0.4688, running_acc=0.4674, grad=16.7092]Training epoch 6:  15%|█▍        | 24/163 [00:32<02:44,  1.19s/it, loss=2.1473, batch_acc=0.4688, running_acc=0.4674, grad=16.7092]Training epoch 6:  15%|█▍        | 24/163 [00:32<02:44,  1.19s/it, loss=2.1139, batch_acc=0.4375, running_acc=0.4661, grad=12.2328]Training epoch 6:  15%|█▌        | 25/163 [00:33<02:31,  1.09s/it, loss=2.1139, batch_acc=0.4375, running_acc=0.4661, grad=12.2328]Training epoch 6:  15%|█▌        | 25/163 [00:33<02:31,  1.09s/it, loss=2.0633, batch_acc=0.4375, running_acc=0.4650, grad=13.9939]Training epoch 6:  16%|█▌        | 26/163 [00:34<02:46,  1.22s/it, loss=2.0633, batch_acc=0.4375, running_acc=0.4650, grad=13.9939]Training epoch 6:  16%|█▌        | 26/163 [00:34<02:46,  1.22s/it, loss=2.3380, batch_acc=0.3438, running_acc=0.4603, grad=15.1779]Training epoch 6:  17%|█▋        | 27/163 [00:35<02:31,  1.11s/it, loss=2.3380, batch_acc=0.3438, running_acc=0.4603, grad=15.1779]Training epoch 6:  17%|█▋        | 27/163 [00:35<02:31,  1.11s/it, loss=2.0027, batch_acc=0.5000, running_acc=0.4618, grad=13.5475]Training epoch 6:  17%|█▋        | 28/163 [00:36<02:44,  1.22s/it, loss=2.0027, batch_acc=0.5000, running_acc=0.4618, grad=13.5475]Training epoch 6:  17%|█▋        | 28/163 [00:36<02:44,  1.22s/it, loss=2.3162, batch_acc=0.3438, running_acc=0.4576, grad=18.2363]Training epoch 6:  18%|█▊        | 29/163 [00:37<02:29,  1.12s/it, loss=2.3162, batch_acc=0.3438, running_acc=0.4576, grad=18.2363]Training epoch 6:  18%|█▊        | 29/163 [00:37<02:29,  1.12s/it, loss=1.9987, batch_acc=0.5000, running_acc=0.4591, grad=13.6833]Training epoch 6:  18%|█▊        | 30/163 [00:39<02:40,  1.20s/it, loss=1.9987, batch_acc=0.5000, running_acc=0.4591, grad=13.6833]Training epoch 6:  18%|█▊        | 30/163 [00:39<02:40,  1.20s/it, loss=2.0955, batch_acc=0.4062, running_acc=0.4573, grad=16.1081]Training epoch 6:  19%|█▉        | 31/163 [00:40<02:26,  1.11s/it, loss=2.0955, batch_acc=0.4062, running_acc=0.4573, grad=16.1081]Training epoch 6:  19%|█▉        | 31/163 [00:40<02:26,  1.11s/it, loss=2.3963, batch_acc=0.4375, running_acc=0.4567, grad=16.9461]Training epoch 6:  20%|█▉        | 32/163 [00:41<02:33,  1.17s/it, loss=2.3963, batch_acc=0.4375, running_acc=0.4567, grad=16.9461]Training epoch 6:  20%|█▉        | 32/163 [00:41<02:33,  1.17s/it, loss=2.1414, batch_acc=0.4375, running_acc=0.4561, grad=14.2666]Training epoch 6:  20%|██        | 33/163 [00:42<02:20,  1.08s/it, loss=2.1414, batch_acc=0.4375, running_acc=0.4561, grad=14.2666]Training epoch 6:  20%|██        | 33/163 [00:42<02:20,  1.08s/it, loss=2.2145, batch_acc=0.4688, running_acc=0.4564, grad=18.3956]Training epoch 6:  21%|██        | 34/163 [00:43<02:38,  1.23s/it, loss=2.2145, batch_acc=0.4688, running_acc=0.4564, grad=18.3956]Training epoch 6:  21%|██        | 34/163 [00:43<02:38,  1.23s/it, loss=2.0735, batch_acc=0.5000, running_acc=0.4577, grad=16.3634]Training epoch 6:  21%|██▏       | 35/163 [00:44<02:24,  1.13s/it, loss=2.0735, batch_acc=0.5000, running_acc=0.4577, grad=16.3634]Training epoch 6:  21%|██▏       | 35/163 [00:44<02:24,  1.13s/it, loss=2.3022, batch_acc=0.4375, running_acc=0.4571, grad=15.1817]Training epoch 6:  22%|██▏       | 36/163 [00:45<02:13,  1.05s/it, loss=2.3022, batch_acc=0.4375, running_acc=0.4571, grad=15.1817]Training epoch 6:  22%|██▏       | 36/163 [00:45<02:13,  1.05s/it, loss=2.2729, batch_acc=0.3750, running_acc=0.4549, grad=17.9986]Training epoch 6:  23%|██▎       | 37/163 [00:46<02:06,  1.00s/it, loss=2.2729, batch_acc=0.3750, running_acc=0.4549, grad=17.9986]Training epoch 6:  23%|██▎       | 37/163 [00:46<02:06,  1.00s/it, loss=2.3366, batch_acc=0.4375, running_acc=0.4544, grad=14.3098]Training epoch 6:  23%|██▎       | 38/163 [00:48<02:37,  1.26s/it, loss=2.3366, batch_acc=0.4375, running_acc=0.4544, grad=14.3098]Training epoch 6:  23%|██▎       | 38/163 [00:48<02:37,  1.26s/it, loss=1.7347, batch_acc=0.6875, running_acc=0.4605, grad=12.3307]Training epoch 6:  24%|██▍       | 39/163 [00:49<02:22,  1.15s/it, loss=1.7347, batch_acc=0.6875, running_acc=0.4605, grad=12.3307]Training epoch 6:  24%|██▍       | 39/163 [00:49<02:22,  1.15s/it, loss=2.1279, batch_acc=0.3125, running_acc=0.4567, grad=13.2912]Training epoch 6:  25%|██▍       | 40/163 [00:50<02:13,  1.09s/it, loss=2.1279, batch_acc=0.3125, running_acc=0.4567, grad=13.2912]Training epoch 6:  25%|██▍       | 40/163 [00:50<02:13,  1.09s/it, loss=2.1296, batch_acc=0.4688, running_acc=0.4570, grad=16.5778]Training epoch 6:  25%|██▌       | 41/163 [00:51<02:05,  1.02s/it, loss=2.1296, batch_acc=0.4688, running_acc=0.4570, grad=16.5778]Training epoch 6:  25%|██▌       | 41/163 [00:51<02:05,  1.02s/it, loss=2.2034, batch_acc=0.3750, running_acc=0.4550, grad=13.8316]Training epoch 6:  26%|██▌       | 42/163 [00:52<02:26,  1.21s/it, loss=2.2034, batch_acc=0.3750, running_acc=0.4550, grad=13.8316]Training epoch 6:  26%|██▌       | 42/163 [00:52<02:26,  1.21s/it, loss=1.9008, batch_acc=0.4688, running_acc=0.4554, grad=12.7622]Training epoch 6:  26%|██▋       | 43/163 [00:53<02:13,  1.11s/it, loss=1.9008, batch_acc=0.4688, running_acc=0.4554, grad=12.7622]Training epoch 6:  26%|██▋       | 43/163 [00:53<02:13,  1.11s/it, loss=2.1135, batch_acc=0.5000, running_acc=0.4564, grad=12.2425]Training epoch 6:  27%|██▋       | 44/163 [00:54<02:04,  1.04s/it, loss=2.1135, batch_acc=0.5000, running_acc=0.4564, grad=12.2425]Training epoch 6:  27%|██▋       | 44/163 [00:54<02:04,  1.04s/it, loss=2.3355, batch_acc=0.4062, running_acc=0.4553, grad=23.9774]Training epoch 6:  28%|██▊       | 45/163 [00:55<01:57,  1.01it/s, loss=2.3355, batch_acc=0.4062, running_acc=0.4553, grad=23.9774]Training epoch 6:  28%|██▊       | 45/163 [00:55<01:57,  1.01it/s, loss=2.5972, batch_acc=0.2500, running_acc=0.4507, grad=15.5535]Training epoch 6:  28%|██▊       | 46/163 [00:57<02:17,  1.17s/it, loss=2.5972, batch_acc=0.2500, running_acc=0.4507, grad=15.5535]Training epoch 6:  28%|██▊       | 46/163 [00:57<02:17,  1.17s/it, loss=2.3305, batch_acc=0.4375, running_acc=0.4504, grad=14.3965]Training epoch 6:  29%|██▉       | 47/163 [00:57<02:05,  1.08s/it, loss=2.3305, batch_acc=0.4375, running_acc=0.4504, grad=14.3965]Training epoch 6:  29%|██▉       | 47/163 [00:57<02:05,  1.08s/it, loss=2.4610, batch_acc=0.3125, running_acc=0.4475, grad=16.9952]Training epoch 6:  29%|██▉       | 48/163 [00:58<01:57,  1.02s/it, loss=2.4610, batch_acc=0.3125, running_acc=0.4475, grad=16.9952]Training epoch 6:  29%|██▉       | 48/163 [00:58<01:57,  1.02s/it, loss=2.5126, batch_acc=0.3750, running_acc=0.4460, grad=15.1745]Training epoch 6:  30%|███       | 49/163 [00:59<01:51,  1.02it/s, loss=2.5126, batch_acc=0.3750, running_acc=0.4460, grad=15.1745]Training epoch 6:  30%|███       | 49/163 [00:59<01:51,  1.02it/s, loss=2.2696, batch_acc=0.3750, running_acc=0.4445, grad=18.8224]Training epoch 6:  31%|███       | 50/163 [01:01<02:21,  1.25s/it, loss=2.2696, batch_acc=0.3750, running_acc=0.4445, grad=18.8224]Training epoch 6:  31%|███       | 50/163 [01:01<02:21,  1.25s/it, loss=2.1128, batch_acc=0.4688, running_acc=0.4450, grad=15.1698]Training epoch 6:  31%|███▏      | 51/163 [01:02<02:07,  1.14s/it, loss=2.1128, batch_acc=0.4688, running_acc=0.4450, grad=15.1698]Training epoch 6:  31%|███▏      | 51/163 [01:02<02:07,  1.14s/it, loss=2.5265, batch_acc=0.3438, running_acc=0.4430, grad=16.6247]Training epoch 6:  32%|███▏      | 52/163 [01:03<01:58,  1.06s/it, loss=2.5265, batch_acc=0.3438, running_acc=0.4430, grad=16.6247]Training epoch 6:  32%|███▏      | 52/163 [01:03<01:58,  1.06s/it, loss=2.2542, batch_acc=0.3750, running_acc=0.4417, grad=15.4795]Training epoch 6:  33%|███▎      | 53/163 [01:04<01:50,  1.01s/it, loss=2.2542, batch_acc=0.3750, running_acc=0.4417, grad=15.4795]Training epoch 6:  33%|███▎      | 53/163 [01:04<01:50,  1.01s/it, loss=2.4352, batch_acc=0.3438, running_acc=0.4399, grad=15.7974]Training epoch 6:  33%|███▎      | 54/163 [01:06<02:29,  1.38s/it, loss=2.4352, batch_acc=0.3438, running_acc=0.4399, grad=15.7974]Training epoch 6:  33%|███▎      | 54/163 [01:06<02:29,  1.38s/it, loss=1.9853, batch_acc=0.4688, running_acc=0.4404, grad=18.3170]Training epoch 6:  34%|███▎      | 55/163 [01:07<02:12,  1.23s/it, loss=1.9853, batch_acc=0.4688, running_acc=0.4404, grad=18.3170]Training epoch 6:  34%|███▎      | 55/163 [01:07<02:12,  1.23s/it, loss=2.0911, batch_acc=0.5000, running_acc=0.4415, grad=12.9562]Training epoch 6:  34%|███▍      | 56/163 [01:08<02:00,  1.12s/it, loss=2.0911, batch_acc=0.5000, running_acc=0.4415, grad=12.9562]Training epoch 6:  34%|███▍      | 56/163 [01:08<02:00,  1.12s/it, loss=2.4520, batch_acc=0.3125, running_acc=0.4392, grad=14.2157]Training epoch 6:  35%|███▍      | 57/163 [01:09<01:51,  1.05s/it, loss=2.4520, batch_acc=0.3125, running_acc=0.4392, grad=14.2157]Training epoch 6:  35%|███▍      | 57/163 [01:09<01:51,  1.05s/it, loss=2.1663, batch_acc=0.5625, running_acc=0.4413, grad=18.1206]Training epoch 6:  36%|███▌      | 58/163 [01:10<02:07,  1.21s/it, loss=2.1663, batch_acc=0.5625, running_acc=0.4413, grad=18.1206]Training epoch 6:  36%|███▌      | 58/163 [01:10<02:07,  1.21s/it, loss=1.9457, batch_acc=0.5625, running_acc=0.4434, grad=12.4557]Training epoch 6:  36%|███▌      | 59/163 [01:11<01:55,  1.11s/it, loss=1.9457, batch_acc=0.5625, running_acc=0.4434, grad=12.4557]Training epoch 6:  36%|███▌      | 59/163 [01:11<01:55,  1.11s/it, loss=2.0032, batch_acc=0.4062, running_acc=0.4428, grad=14.5778]Training epoch 6:  37%|███▋      | 60/163 [01:12<01:47,  1.04s/it, loss=2.0032, batch_acc=0.4062, running_acc=0.4428, grad=14.5778]Training epoch 6:  37%|███▋      | 60/163 [01:12<01:47,  1.04s/it, loss=2.2972, batch_acc=0.4375, running_acc=0.4427, grad=12.3858]Training epoch 6:  37%|███▋      | 61/163 [01:13<01:41,  1.01it/s, loss=2.2972, batch_acc=0.4375, running_acc=0.4427, grad=12.3858]Training epoch 6:  37%|███▋      | 61/163 [01:13<01:41,  1.01it/s, loss=1.8015, batch_acc=0.6250, running_acc=0.4457, grad=15.6614]Training epoch 6:  38%|███▊      | 62/163 [01:14<01:59,  1.18s/it, loss=1.8015, batch_acc=0.6250, running_acc=0.4457, grad=15.6614]Training epoch 6:  38%|███▊      | 62/163 [01:14<01:59,  1.18s/it, loss=2.2520, batch_acc=0.4062, running_acc=0.4451, grad=12.5051]Training epoch 6:  39%|███▊      | 63/163 [01:15<01:49,  1.09s/it, loss=2.2520, batch_acc=0.4062, running_acc=0.4451, grad=12.5051]Training epoch 6:  39%|███▊      | 63/163 [01:15<01:49,  1.09s/it, loss=2.2108, batch_acc=0.5000, running_acc=0.4459, grad=19.7978]Training epoch 6:  39%|███▉      | 64/163 [01:16<01:41,  1.03s/it, loss=2.2108, batch_acc=0.5000, running_acc=0.4459, grad=19.7978]Training epoch 6:  39%|███▉      | 64/163 [01:16<01:41,  1.03s/it, loss=2.1546, batch_acc=0.4688, running_acc=0.4463, grad=14.7799]Training epoch 6:  40%|███▉      | 65/163 [01:17<01:36,  1.02it/s, loss=2.1546, batch_acc=0.4688, running_acc=0.4463, grad=14.7799]Training epoch 6:  40%|███▉      | 65/163 [01:17<01:36,  1.02it/s, loss=2.3314, batch_acc=0.2812, running_acc=0.4437, grad=17.5517]Training epoch 6:  40%|████      | 66/163 [01:19<02:00,  1.24s/it, loss=2.3314, batch_acc=0.2812, running_acc=0.4437, grad=17.5517]Training epoch 6:  40%|████      | 66/163 [01:19<02:00,  1.24s/it, loss=2.2142, batch_acc=0.4062, running_acc=0.4432, grad=15.0542]Training epoch 6:  41%|████      | 67/163 [01:20<01:48,  1.13s/it, loss=2.2142, batch_acc=0.4062, running_acc=0.4432, grad=15.0542]Training epoch 6:  41%|████      | 67/163 [01:20<01:48,  1.13s/it, loss=1.9666, batch_acc=0.5312, running_acc=0.4445, grad=13.8077]Training epoch 6:  42%|████▏     | 68/163 [01:21<01:40,  1.06s/it, loss=1.9666, batch_acc=0.5312, running_acc=0.4445, grad=13.8077]Training epoch 6:  42%|████▏     | 68/163 [01:21<01:40,  1.06s/it, loss=2.1597, batch_acc=0.4375, running_acc=0.4444, grad=13.6768]Training epoch 6:  42%|████▏     | 69/163 [01:22<01:34,  1.00s/it, loss=2.1597, batch_acc=0.4375, running_acc=0.4444, grad=13.6768]Training epoch 6:  42%|████▏     | 69/163 [01:22<01:34,  1.00s/it, loss=2.4068, batch_acc=0.3750, running_acc=0.4434, grad=12.5624]Training epoch 6:  43%|████▎     | 70/163 [01:24<02:01,  1.31s/it, loss=2.4068, batch_acc=0.3750, running_acc=0.4434, grad=12.5624]Training epoch 6:  43%|████▎     | 70/163 [01:24<02:01,  1.31s/it, loss=2.1316, batch_acc=0.4375, running_acc=0.4433, grad=20.7576]Training epoch 6:  44%|████▎     | 71/163 [01:24<01:48,  1.18s/it, loss=2.1316, batch_acc=0.4375, running_acc=0.4433, grad=20.7576]Training epoch 6:  44%|████▎     | 71/163 [01:24<01:48,  1.18s/it, loss=2.1695, batch_acc=0.4062, running_acc=0.4428, grad=10.6451]Training epoch 6:  44%|████▍     | 72/163 [01:25<01:39,  1.09s/it, loss=2.1695, batch_acc=0.4062, running_acc=0.4428, grad=10.6451]Training epoch 6:  44%|████▍     | 72/163 [01:25<01:39,  1.09s/it, loss=1.9232, batch_acc=0.5312, running_acc=0.4440, grad=13.9427]Training epoch 6:  45%|████▍     | 73/163 [01:26<01:32,  1.03s/it, loss=1.9232, batch_acc=0.5312, running_acc=0.4440, grad=13.9427]Training epoch 6:  45%|████▍     | 73/163 [01:26<01:32,  1.03s/it, loss=2.1179, batch_acc=0.5000, running_acc=0.4448, grad=12.2015]Training epoch 6:  45%|████▌     | 74/163 [01:28<01:47,  1.21s/it, loss=2.1179, batch_acc=0.5000, running_acc=0.4448, grad=12.2015]Training epoch 6:  45%|████▌     | 74/163 [01:28<01:47,  1.21s/it, loss=2.3672, batch_acc=0.4375, running_acc=0.4447, grad=15.0297]Training epoch 6:  46%|████▌     | 75/163 [01:29<01:37,  1.11s/it, loss=2.3672, batch_acc=0.4375, running_acc=0.4447, grad=15.0297]Training epoch 6:  46%|████▌     | 75/163 [01:29<01:37,  1.11s/it, loss=2.3447, batch_acc=0.3438, running_acc=0.4433, grad=17.9409]Training epoch 6:  47%|████▋     | 76/163 [01:30<01:30,  1.04s/it, loss=2.3447, batch_acc=0.3438, running_acc=0.4433, grad=17.9409]Training epoch 6:  47%|████▋     | 76/163 [01:30<01:30,  1.04s/it, loss=2.1382, batch_acc=0.4688, running_acc=0.4437, grad=19.3567]Training epoch 6:  47%|████▋     | 77/163 [01:30<01:25,  1.01it/s, loss=2.1382, batch_acc=0.4688, running_acc=0.4437, grad=19.3567]Training epoch 6:  47%|████▋     | 77/163 [01:30<01:25,  1.01it/s, loss=2.0988, batch_acc=0.4688, running_acc=0.4440, grad=17.8254]Training epoch 6:  48%|████▊     | 78/163 [01:32<01:40,  1.18s/it, loss=2.0988, batch_acc=0.4688, running_acc=0.4440, grad=17.8254]Training epoch 6:  48%|████▊     | 78/163 [01:32<01:40,  1.18s/it, loss=2.3781, batch_acc=0.3438, running_acc=0.4427, grad=19.6263]Training epoch 6:  48%|████▊     | 79/163 [01:33<01:31,  1.09s/it, loss=2.3781, batch_acc=0.3438, running_acc=0.4427, grad=19.6263]Training epoch 6:  48%|████▊     | 79/163 [01:33<01:31,  1.09s/it, loss=2.0947, batch_acc=0.5312, running_acc=0.4438, grad=16.8929]Training epoch 6:  49%|████▉     | 80/163 [01:34<01:25,  1.03s/it, loss=2.0947, batch_acc=0.5312, running_acc=0.4438, grad=16.8929]Training epoch 6:  49%|████▉     | 80/163 [01:34<01:25,  1.03s/it, loss=2.0852, batch_acc=0.5000, running_acc=0.4445, grad=13.4206]Training epoch 6:  50%|████▉     | 81/163 [01:35<01:20,  1.02it/s, loss=2.0852, batch_acc=0.5000, running_acc=0.4445, grad=13.4206]Training epoch 6:  50%|████▉     | 81/163 [01:35<01:20,  1.02it/s, loss=2.1841, batch_acc=0.4375, running_acc=0.4444, grad=14.4158]Training epoch 6:  50%|█████     | 82/163 [01:37<01:47,  1.33s/it, loss=2.1841, batch_acc=0.4375, running_acc=0.4444, grad=14.4158]Training epoch 6:  50%|█████     | 82/163 [01:37<01:47,  1.33s/it, loss=2.1575, batch_acc=0.3438, running_acc=0.4432, grad=14.8388]Training epoch 6:  51%|█████     | 83/163 [01:38<01:35,  1.19s/it, loss=2.1575, batch_acc=0.3438, running_acc=0.4432, grad=14.8388]Training epoch 6:  51%|█████     | 83/163 [01:38<01:35,  1.19s/it, loss=2.4348, batch_acc=0.3438, running_acc=0.4420, grad=15.4942]Training epoch 6:  52%|█████▏    | 84/163 [01:39<01:26,  1.10s/it, loss=2.4348, batch_acc=0.3438, running_acc=0.4420, grad=15.4942]Training epoch 6:  52%|█████▏    | 84/163 [01:39<01:26,  1.10s/it, loss=2.1614, batch_acc=0.4062, running_acc=0.4416, grad=13.2933]Training epoch 6:  52%|█████▏    | 85/163 [01:40<01:20,  1.03s/it, loss=2.1614, batch_acc=0.4062, running_acc=0.4416, grad=13.2933]Training epoch 6:  52%|█████▏    | 85/163 [01:40<01:20,  1.03s/it, loss=2.1951, batch_acc=0.4375, running_acc=0.4415, grad=18.3193]Training epoch 6:  53%|█████▎    | 86/163 [01:41<01:40,  1.30s/it, loss=2.1951, batch_acc=0.4375, running_acc=0.4415, grad=18.3193]Training epoch 6:  53%|█████▎    | 86/163 [01:41<01:40,  1.30s/it, loss=1.8792, batch_acc=0.5938, running_acc=0.4433, grad=13.4908]Training epoch 6:  53%|█████▎    | 87/163 [01:42<01:29,  1.18s/it, loss=1.8792, batch_acc=0.5938, running_acc=0.4433, grad=13.4908]Training epoch 6:  53%|█████▎    | 87/163 [01:42<01:29,  1.18s/it, loss=2.1739, batch_acc=0.5000, running_acc=0.4440, grad=16.2920]Training epoch 6:  54%|█████▍    | 88/163 [01:43<01:21,  1.09s/it, loss=2.1739, batch_acc=0.5000, running_acc=0.4440, grad=16.2920]Training epoch 6:  54%|█████▍    | 88/163 [01:43<01:21,  1.09s/it, loss=2.1571, batch_acc=0.5000, running_acc=0.4446, grad=16.8154]Training epoch 6:  55%|█████▍    | 89/163 [01:44<01:15,  1.02s/it, loss=2.1571, batch_acc=0.5000, running_acc=0.4446, grad=16.8154]Training epoch 6:  55%|█████▍    | 89/163 [01:44<01:15,  1.02s/it, loss=2.0093, batch_acc=0.5625, running_acc=0.4459, grad=16.1064]Training epoch 6:  55%|█████▌    | 90/163 [01:45<01:22,  1.14s/it, loss=2.0093, batch_acc=0.5625, running_acc=0.4459, grad=16.1064]Training epoch 6:  55%|█████▌    | 90/163 [01:45<01:22,  1.14s/it, loss=2.3164, batch_acc=0.5938, running_acc=0.4476, grad=22.5132]Training epoch 6:  56%|█████▌    | 91/163 [01:46<01:16,  1.06s/it, loss=2.3164, batch_acc=0.5938, running_acc=0.4476, grad=22.5132]Training epoch 6:  56%|█████▌    | 91/163 [01:46<01:16,  1.06s/it, loss=1.7024, batch_acc=0.6250, running_acc=0.4495, grad=10.5268]Training epoch 6:  56%|█████▋    | 92/163 [01:47<01:11,  1.01s/it, loss=1.7024, batch_acc=0.6250, running_acc=0.4495, grad=10.5268]Training epoch 6:  56%|█████▋    | 92/163 [01:47<01:11,  1.01s/it, loss=1.9359, batch_acc=0.4375, running_acc=0.4494, grad=11.1295]Training epoch 6:  57%|█████▋    | 93/163 [01:48<01:07,  1.03it/s, loss=1.9359, batch_acc=0.4375, running_acc=0.4494, grad=11.1295]Training epoch 6:  57%|█████▋    | 93/163 [01:48<01:07,  1.03it/s, loss=2.2476, batch_acc=0.4688, running_acc=0.4496, grad=11.8420]Training epoch 6:  58%|█████▊    | 94/163 [01:50<01:25,  1.25s/it, loss=2.2476, batch_acc=0.4688, running_acc=0.4496, grad=11.8420]Training epoch 6:  58%|█████▊    | 94/163 [01:50<01:25,  1.25s/it, loss=2.0239, batch_acc=0.5625, running_acc=0.4508, grad=12.5688]Training epoch 6:  58%|█████▊    | 95/163 [01:51<01:17,  1.14s/it, loss=2.0239, batch_acc=0.5625, running_acc=0.4508, grad=12.5688]Training epoch 6:  58%|█████▊    | 95/163 [01:51<01:17,  1.14s/it, loss=1.8685, batch_acc=0.4375, running_acc=0.4507, grad=18.0907]Training epoch 6:  59%|█████▉    | 96/163 [01:52<01:10,  1.06s/it, loss=1.8685, batch_acc=0.4375, running_acc=0.4507, grad=18.0907]Training epoch 6:  59%|█████▉    | 96/163 [01:52<01:10,  1.06s/it, loss=2.3259, batch_acc=0.5312, running_acc=0.4515, grad=12.2652]Training epoch 6:  60%|█████▉    | 97/163 [01:53<01:06,  1.01s/it, loss=2.3259, batch_acc=0.5312, running_acc=0.4515, grad=12.2652]Training epoch 6:  60%|█████▉    | 97/163 [01:53<01:06,  1.01s/it, loss=1.9968, batch_acc=0.4375, running_acc=0.4514, grad=16.5812]Training epoch 6:  60%|██████    | 98/163 [01:54<01:06,  1.03s/it, loss=1.9968, batch_acc=0.4375, running_acc=0.4514, grad=16.5812]Training epoch 6:  60%|██████    | 98/163 [01:54<01:06,  1.03s/it, loss=2.3301, batch_acc=0.3125, running_acc=0.4499, grad=19.0707]Training epoch 6:  61%|██████    | 99/163 [01:55<01:02,  1.02it/s, loss=2.3301, batch_acc=0.3125, running_acc=0.4499, grad=19.0707]Training epoch 6:  61%|██████    | 99/163 [01:55<01:02,  1.02it/s, loss=2.2452, batch_acc=0.4062, running_acc=0.4495, grad=12.9636]Training epoch 6:  61%|██████▏   | 100/163 [01:55<01:00,  1.05it/s, loss=2.2452, batch_acc=0.4062, running_acc=0.4495, grad=12.9636]Training epoch 6:  61%|██████▏   | 100/163 [01:55<01:00,  1.05it/s, loss=2.0736, batch_acc=0.3750, running_acc=0.4487, grad=12.4179]Training epoch 6:  62%|██████▏   | 101/163 [01:56<00:57,  1.07it/s, loss=2.0736, batch_acc=0.3750, running_acc=0.4487, grad=12.4179]Training epoch 6:  62%|██████▏   | 101/163 [01:56<00:57,  1.07it/s, loss=2.0795, batch_acc=0.4688, running_acc=0.4489, grad=15.2994]Training epoch 6:  63%|██████▎   | 102/163 [01:59<01:21,  1.34s/it, loss=2.0795, batch_acc=0.4688, running_acc=0.4489, grad=15.2994]Training epoch 6:  63%|██████▎   | 102/163 [01:59<01:21,  1.34s/it, loss=2.3074, batch_acc=0.5000, running_acc=0.4494, grad=13.6567]Training epoch 6:  63%|██████▎   | 103/163 [02:00<01:12,  1.20s/it, loss=2.3074, batch_acc=0.5000, running_acc=0.4494, grad=13.6567]Training epoch 6:  63%|██████▎   | 103/163 [02:00<01:12,  1.20s/it, loss=2.0449, batch_acc=0.5312, running_acc=0.4502, grad=12.3633]Training epoch 6:  64%|██████▍   | 104/163 [02:00<01:05,  1.10s/it, loss=2.0449, batch_acc=0.5312, running_acc=0.4502, grad=12.3633]Training epoch 6:  64%|██████▍   | 104/163 [02:00<01:05,  1.10s/it, loss=2.3891, batch_acc=0.3438, running_acc=0.4492, grad=12.5692]Training epoch 6:  64%|██████▍   | 105/163 [02:01<01:00,  1.04s/it, loss=2.3891, batch_acc=0.3438, running_acc=0.4492, grad=12.5692]Training epoch 6:  64%|██████▍   | 105/163 [02:01<01:00,  1.04s/it, loss=2.1298, batch_acc=0.4375, running_acc=0.4491, grad=15.3857]Training epoch 6:  65%|██████▌   | 106/163 [02:03<01:05,  1.15s/it, loss=2.1298, batch_acc=0.4375, running_acc=0.4491, grad=15.3857]Training epoch 6:  65%|██████▌   | 106/163 [02:03<01:05,  1.15s/it, loss=2.1560, batch_acc=0.4062, running_acc=0.4487, grad=12.0289]Training epoch 6:  66%|██████▌   | 107/163 [02:04<00:59,  1.07s/it, loss=2.1560, batch_acc=0.4062, running_acc=0.4487, grad=12.0289]Training epoch 6:  66%|██████▌   | 107/163 [02:04<00:59,  1.07s/it, loss=2.0466, batch_acc=0.4688, running_acc=0.4489, grad=12.3218]Training epoch 6:  66%|██████▋   | 108/163 [02:04<00:55,  1.01s/it, loss=2.0466, batch_acc=0.4688, running_acc=0.4489, grad=12.3218]Training epoch 6:  66%|██████▋   | 108/163 [02:04<00:55,  1.01s/it, loss=2.1767, batch_acc=0.4062, running_acc=0.4485, grad=15.4082]Training epoch 6:  67%|██████▋   | 109/163 [02:05<00:52,  1.03it/s, loss=2.1767, batch_acc=0.4062, running_acc=0.4485, grad=15.4082]Training epoch 6:  67%|██████▋   | 109/163 [02:05<00:52,  1.03it/s, loss=1.6612, batch_acc=0.5312, running_acc=0.4493, grad=11.1675]Training epoch 6:  67%|██████▋   | 110/163 [02:07<01:01,  1.16s/it, loss=1.6612, batch_acc=0.5312, running_acc=0.4493, grad=11.1675]Training epoch 6:  67%|██████▋   | 110/163 [02:07<01:01,  1.16s/it, loss=1.8370, batch_acc=0.5000, running_acc=0.4497, grad=12.6503]Training epoch 6:  68%|██████▊   | 111/163 [02:08<00:56,  1.08s/it, loss=1.8370, batch_acc=0.5000, running_acc=0.4497, grad=12.6503]Training epoch 6:  68%|██████▊   | 111/163 [02:08<00:56,  1.08s/it, loss=2.1837, batch_acc=0.3750, running_acc=0.4490, grad=16.5415]Training epoch 6:  69%|██████▊   | 112/163 [02:09<00:52,  1.02s/it, loss=2.1837, batch_acc=0.3750, running_acc=0.4490, grad=16.5415]Training epoch 6:  69%|██████▊   | 112/163 [02:09<00:52,  1.02s/it, loss=2.3228, batch_acc=0.5000, running_acc=0.4495, grad=16.9676]Training epoch 6:  69%|██████▉   | 113/163 [02:10<00:48,  1.02it/s, loss=2.3228, batch_acc=0.5000, running_acc=0.4495, grad=16.9676]Training epoch 6:  69%|██████▉   | 113/163 [02:10<00:48,  1.02it/s, loss=1.9983, batch_acc=0.5000, running_acc=0.4499, grad=14.9788]Training epoch 6:  70%|██████▉   | 114/163 [02:12<01:01,  1.26s/it, loss=1.9983, batch_acc=0.5000, running_acc=0.4499, grad=14.9788]Training epoch 6:  70%|██████▉   | 114/163 [02:12<01:01,  1.26s/it, loss=2.0569, batch_acc=0.4688, running_acc=0.4501, grad=16.5218]Training epoch 6:  71%|███████   | 115/163 [02:12<00:54,  1.15s/it, loss=2.0569, batch_acc=0.4688, running_acc=0.4501, grad=16.5218]Training epoch 6:  71%|███████   | 115/163 [02:12<00:54,  1.15s/it, loss=2.1975, batch_acc=0.4375, running_acc=0.4500, grad=19.4058]Training epoch 6:  71%|███████   | 116/163 [02:13<00:50,  1.07s/it, loss=2.1975, batch_acc=0.4375, running_acc=0.4500, grad=19.4058]Training epoch 6:  71%|███████   | 116/163 [02:13<00:50,  1.07s/it, loss=2.2601, batch_acc=0.2812, running_acc=0.4485, grad=14.8145]Training epoch 6:  72%|███████▏  | 117/163 [02:14<00:46,  1.01s/it, loss=2.2601, batch_acc=0.2812, running_acc=0.4485, grad=14.8145]Training epoch 6:  72%|███████▏  | 117/163 [02:14<00:46,  1.01s/it, loss=1.9155, batch_acc=0.5312, running_acc=0.4493, grad=18.9417]Training epoch 6:  72%|███████▏  | 118/163 [02:16<00:50,  1.13s/it, loss=1.9155, batch_acc=0.5312, running_acc=0.4493, grad=18.9417]Training epoch 6:  72%|███████▏  | 118/163 [02:16<00:50,  1.13s/it, loss=2.3465, batch_acc=0.4062, running_acc=0.4489, grad=13.9951]Training epoch 6:  73%|███████▎  | 119/163 [02:16<00:46,  1.05s/it, loss=2.3465, batch_acc=0.4062, running_acc=0.4489, grad=13.9951]Training epoch 6:  73%|███████▎  | 119/163 [02:16<00:46,  1.05s/it, loss=2.4559, batch_acc=0.2812, running_acc=0.4475, grad=19.4300]Training epoch 6:  74%|███████▎  | 120/163 [02:17<00:43,  1.00s/it, loss=2.4559, batch_acc=0.2812, running_acc=0.4475, grad=19.4300]Training epoch 6:  74%|███████▎  | 120/163 [02:17<00:43,  1.00s/it, loss=2.1886, batch_acc=0.5625, running_acc=0.4484, grad=15.6737]Training epoch 6:  74%|███████▍  | 121/163 [02:18<00:40,  1.04it/s, loss=2.1886, batch_acc=0.5625, running_acc=0.4484, grad=15.6737]Training epoch 6:  74%|███████▍  | 121/163 [02:18<00:40,  1.04it/s, loss=2.0782, batch_acc=0.5000, running_acc=0.4489, grad=17.3852]Training epoch 6:  75%|███████▍  | 122/163 [02:20<00:48,  1.19s/it, loss=2.0782, batch_acc=0.5000, running_acc=0.4489, grad=17.3852]Training epoch 6:  75%|███████▍  | 122/163 [02:20<00:48,  1.19s/it, loss=2.1305, batch_acc=0.4688, running_acc=0.4490, grad=18.7594]Training epoch 6:  75%|███████▌  | 123/163 [02:21<00:43,  1.09s/it, loss=2.1305, batch_acc=0.4688, running_acc=0.4490, grad=18.7594]Training epoch 6:  75%|███████▌  | 123/163 [02:21<00:43,  1.09s/it, loss=1.8520, batch_acc=0.5625, running_acc=0.4499, grad=13.9067]Training epoch 6:  76%|███████▌  | 124/163 [02:22<00:40,  1.03s/it, loss=1.8520, batch_acc=0.5625, running_acc=0.4499, grad=13.9067]Training epoch 6:  76%|███████▌  | 124/163 [02:22<00:40,  1.03s/it, loss=1.9542, batch_acc=0.5312, running_acc=0.4506, grad=17.8959]Training epoch 6:  77%|███████▋  | 125/163 [02:23<00:37,  1.01it/s, loss=1.9542, batch_acc=0.5312, running_acc=0.4506, grad=17.8959]Training epoch 6:  77%|███████▋  | 125/163 [02:23<00:37,  1.01it/s, loss=2.2644, batch_acc=0.4375, running_acc=0.4505, grad=16.5457]Training epoch 6:  77%|███████▋  | 126/163 [02:25<00:50,  1.36s/it, loss=2.2644, batch_acc=0.4375, running_acc=0.4505, grad=16.5457]Training epoch 6:  77%|███████▋  | 126/163 [02:25<00:50,  1.36s/it, loss=2.3060, batch_acc=0.3750, running_acc=0.4499, grad=15.5773]Training epoch 6:  78%|███████▊  | 127/163 [02:26<00:43,  1.22s/it, loss=2.3060, batch_acc=0.3750, running_acc=0.4499, grad=15.5773]Training epoch 6:  78%|███████▊  | 127/163 [02:26<00:43,  1.22s/it, loss=2.2086, batch_acc=0.3750, running_acc=0.4493, grad=18.7342]Training epoch 6:  79%|███████▊  | 128/163 [02:27<00:39,  1.12s/it, loss=2.2086, batch_acc=0.3750, running_acc=0.4493, grad=18.7342]Training epoch 6:  79%|███████▊  | 128/163 [02:27<00:39,  1.12s/it, loss=2.1086, batch_acc=0.5000, running_acc=0.4497, grad=16.9187]Training epoch 6:  79%|███████▉  | 129/163 [02:27<00:35,  1.05s/it, loss=2.1086, batch_acc=0.5000, running_acc=0.4497, grad=16.9187]Training epoch 6:  79%|███████▉  | 129/163 [02:27<00:35,  1.05s/it, loss=2.4013, batch_acc=0.3438, running_acc=0.4489, grad=18.2652]Training epoch 6:  80%|███████▉  | 130/163 [02:30<00:45,  1.39s/it, loss=2.4013, batch_acc=0.3438, running_acc=0.4489, grad=18.2652]Training epoch 6:  80%|███████▉  | 130/163 [02:30<00:45,  1.39s/it, loss=2.2207, batch_acc=0.4688, running_acc=0.4490, grad=13.1989]Training epoch 6:  80%|████████  | 131/163 [02:30<00:39,  1.23s/it, loss=2.2207, batch_acc=0.4688, running_acc=0.4490, grad=13.1989]Training epoch 6:  80%|████████  | 131/163 [02:30<00:39,  1.23s/it, loss=2.3740, batch_acc=0.3750, running_acc=0.4485, grad=14.5693]Training epoch 6:  81%|████████  | 132/163 [02:31<00:34,  1.13s/it, loss=2.3740, batch_acc=0.3750, running_acc=0.4485, grad=14.5693]Training epoch 6:  81%|████████  | 132/163 [02:31<00:34,  1.13s/it, loss=1.9148, batch_acc=0.5312, running_acc=0.4491, grad=15.4789]Training epoch 6:  82%|████████▏ | 133/163 [02:32<00:31,  1.05s/it, loss=1.9148, batch_acc=0.5312, running_acc=0.4491, grad=15.4789]Training epoch 6:  82%|████████▏ | 133/163 [02:32<00:31,  1.05s/it, loss=1.8800, batch_acc=0.5312, running_acc=0.4497, grad=17.6709]Training epoch 6:  82%|████████▏ | 134/163 [02:35<00:41,  1.44s/it, loss=1.8800, batch_acc=0.5312, running_acc=0.4497, grad=17.6709]Training epoch 6:  82%|████████▏ | 134/163 [02:35<00:41,  1.44s/it, loss=2.2723, batch_acc=0.4688, running_acc=0.4499, grad=15.0507]Training epoch 6:  83%|████████▎ | 135/163 [02:35<00:35,  1.27s/it, loss=2.2723, batch_acc=0.4688, running_acc=0.4499, grad=15.0507]Training epoch 6:  83%|████████▎ | 135/163 [02:35<00:35,  1.27s/it, loss=2.3069, batch_acc=0.5312, running_acc=0.4505, grad=15.8171]Training epoch 6:  83%|████████▎ | 136/163 [02:36<00:31,  1.15s/it, loss=2.3069, batch_acc=0.5312, running_acc=0.4505, grad=15.8171]Training epoch 6:  83%|████████▎ | 136/163 [02:36<00:31,  1.15s/it, loss=2.1426, batch_acc=0.3438, running_acc=0.4497, grad=18.4062]Training epoch 6:  84%|████████▍ | 137/163 [02:37<00:27,  1.07s/it, loss=2.1426, batch_acc=0.3438, running_acc=0.4497, grad=18.4062]Training epoch 6:  84%|████████▍ | 137/163 [02:37<00:27,  1.07s/it, loss=2.0105, batch_acc=0.5000, running_acc=0.4500, grad=24.0313]Training epoch 6:  85%|████████▍ | 138/163 [02:39<00:33,  1.35s/it, loss=2.0105, batch_acc=0.5000, running_acc=0.4500, grad=24.0313]Training epoch 6:  85%|████████▍ | 138/163 [02:39<00:33,  1.35s/it, loss=2.2222, batch_acc=0.3438, running_acc=0.4493, grad=18.6136]Training epoch 6:  85%|████████▌ | 139/163 [02:40<00:29,  1.21s/it, loss=2.2222, batch_acc=0.3438, running_acc=0.4493, grad=18.6136]Training epoch 6:  85%|████████▌ | 139/163 [02:40<00:29,  1.21s/it, loss=1.8230, batch_acc=0.5938, running_acc=0.4503, grad=16.4082]Training epoch 6:  86%|████████▌ | 140/163 [02:41<00:25,  1.11s/it, loss=1.8230, batch_acc=0.5938, running_acc=0.4503, grad=16.4082]Training epoch 6:  86%|████████▌ | 140/163 [02:41<00:25,  1.11s/it, loss=1.9379, batch_acc=0.5000, running_acc=0.4507, grad=16.9806]Training epoch 6:  87%|████████▋ | 141/163 [02:42<00:22,  1.04s/it, loss=1.9379, batch_acc=0.5000, running_acc=0.4507, grad=16.9806]Training epoch 6:  87%|████████▋ | 141/163 [02:42<00:22,  1.04s/it, loss=2.0796, batch_acc=0.4375, running_acc=0.4506, grad=18.9410]Training epoch 6:  87%|████████▋ | 142/163 [02:44<00:29,  1.38s/it, loss=2.0796, batch_acc=0.4375, running_acc=0.4506, grad=18.9410]Training epoch 6:  87%|████████▋ | 142/163 [02:44<00:29,  1.38s/it, loss=2.4671, batch_acc=0.3438, running_acc=0.4498, grad=22.5702]Training epoch 6:  88%|████████▊ | 143/163 [02:45<00:24,  1.23s/it, loss=2.4671, batch_acc=0.3438, running_acc=0.4498, grad=22.5702]Training epoch 6:  88%|████████▊ | 143/163 [02:45<00:24,  1.23s/it, loss=2.2189, batch_acc=0.4375, running_acc=0.4497, grad=14.7729]Training epoch 6:  88%|████████▊ | 144/163 [02:46<00:21,  1.13s/it, loss=2.2189, batch_acc=0.4375, running_acc=0.4497, grad=14.7729]Training epoch 6:  88%|████████▊ | 144/163 [02:46<00:21,  1.13s/it, loss=2.2526, batch_acc=0.4375, running_acc=0.4497, grad=14.4947]Training epoch 6:  89%|████████▉ | 145/163 [02:47<00:18,  1.05s/it, loss=2.2526, batch_acc=0.4375, running_acc=0.4497, grad=14.4947]Training epoch 6:  89%|████████▉ | 145/163 [02:47<00:18,  1.05s/it, loss=1.9771, batch_acc=0.5312, running_acc=0.4502, grad=14.4117]Training epoch 6:  90%|████████▉ | 146/163 [02:48<00:20,  1.21s/it, loss=1.9771, batch_acc=0.5312, running_acc=0.4502, grad=14.4117]Training epoch 6:  90%|████████▉ | 146/163 [02:48<00:20,  1.21s/it, loss=1.7463, batch_acc=0.6562, running_acc=0.4516, grad=13.1147]Training epoch 6:  90%|█████████ | 147/163 [02:49<00:17,  1.11s/it, loss=1.7463, batch_acc=0.6562, running_acc=0.4516, grad=13.1147]Training epoch 6:  90%|█████████ | 147/163 [02:49<00:17,  1.11s/it, loss=1.7782, batch_acc=0.5000, running_acc=0.4520, grad=12.8433]Training epoch 6:  91%|█████████ | 148/163 [02:50<00:15,  1.04s/it, loss=1.7782, batch_acc=0.5000, running_acc=0.4520, grad=12.8433]Training epoch 6:  91%|█████████ | 148/163 [02:50<00:15,  1.04s/it, loss=2.1730, batch_acc=0.3750, running_acc=0.4514, grad=22.1361]Training epoch 6:  91%|█████████▏| 149/163 [02:51<00:13,  1.01it/s, loss=2.1730, batch_acc=0.3750, running_acc=0.4514, grad=22.1361]Training epoch 6:  91%|█████████▏| 149/163 [02:51<00:13,  1.01it/s, loss=2.0146, batch_acc=0.4688, running_acc=0.4516, grad=13.1516]Training epoch 6:  92%|█████████▏| 150/163 [02:52<00:15,  1.17s/it, loss=2.0146, batch_acc=0.4688, running_acc=0.4516, grad=13.1516]Training epoch 6:  92%|█████████▏| 150/163 [02:52<00:15,  1.17s/it, loss=2.5179, batch_acc=0.3125, running_acc=0.4506, grad=19.7603]Training epoch 6:  93%|█████████▎| 151/163 [02:53<00:13,  1.08s/it, loss=2.5179, batch_acc=0.3125, running_acc=0.4506, grad=19.7603]Training epoch 6:  93%|█████████▎| 151/163 [02:53<00:13,  1.08s/it, loss=2.2710, batch_acc=0.4062, running_acc=0.4503, grad=15.8575]Training epoch 6:  93%|█████████▎| 152/163 [02:54<00:11,  1.02s/it, loss=2.2710, batch_acc=0.4062, running_acc=0.4503, grad=15.8575]Training epoch 6:  93%|█████████▎| 152/163 [02:54<00:11,  1.02s/it, loss=2.4204, batch_acc=0.3750, running_acc=0.4498, grad=28.5337]Training epoch 6:  94%|█████████▍| 153/163 [02:55<00:09,  1.02it/s, loss=2.4204, batch_acc=0.3750, running_acc=0.4498, grad=28.5337]Training epoch 6:  94%|█████████▍| 153/163 [02:55<00:09,  1.02it/s, loss=1.9140, batch_acc=0.5312, running_acc=0.4504, grad=26.8219]Training epoch 6:  94%|█████████▍| 154/163 [02:57<00:11,  1.26s/it, loss=1.9140, batch_acc=0.5312, running_acc=0.4504, grad=26.8219]Training epoch 6:  94%|█████████▍| 154/163 [02:57<00:11,  1.26s/it, loss=1.7788, batch_acc=0.5000, running_acc=0.4507, grad=11.8642]Training epoch 6:  95%|█████████▌| 155/163 [02:58<00:09,  1.15s/it, loss=1.7788, batch_acc=0.5000, running_acc=0.4507, grad=11.8642]Training epoch 6:  95%|█████████▌| 155/163 [02:58<00:09,  1.15s/it, loss=2.0888, batch_acc=0.4375, running_acc=0.4506, grad=14.3004]Training epoch 6:  96%|█████████▌| 156/163 [02:59<00:07,  1.07s/it, loss=2.0888, batch_acc=0.4375, running_acc=0.4506, grad=14.3004]Training epoch 6:  96%|█████████▌| 156/163 [02:59<00:07,  1.07s/it, loss=1.9848, batch_acc=0.5000, running_acc=0.4509, grad=21.1454]Training epoch 6:  96%|█████████▋| 157/163 [03:00<00:06,  1.01s/it, loss=1.9848, batch_acc=0.5000, running_acc=0.4509, grad=21.1454]Training epoch 6:  96%|█████████▋| 157/163 [03:00<00:06,  1.01s/it, loss=2.3446, batch_acc=0.3750, running_acc=0.4504, grad=13.9313]Training epoch 6:  97%|█████████▋| 158/163 [03:02<00:06,  1.28s/it, loss=2.3446, batch_acc=0.3750, running_acc=0.4504, grad=13.9313]Training epoch 6:  97%|█████████▋| 158/163 [03:02<00:06,  1.28s/it, loss=1.8615, batch_acc=0.4062, running_acc=0.4502, grad=15.7737]Training epoch 6:  98%|█████████▊| 159/163 [03:02<00:04,  1.16s/it, loss=1.8615, batch_acc=0.4062, running_acc=0.4502, grad=15.7737]Training epoch 6:  98%|█████████▊| 159/163 [03:02<00:04,  1.16s/it, loss=1.9400, batch_acc=0.4688, running_acc=0.4503, grad=12.6641]Training epoch 6:  98%|█████████▊| 160/163 [03:03<00:03,  1.08s/it, loss=1.9400, batch_acc=0.4688, running_acc=0.4503, grad=12.6641]Training epoch 6:  98%|█████████▊| 160/163 [03:03<00:03,  1.08s/it, loss=2.6966, batch_acc=0.2500, running_acc=0.4490, grad=14.6996]Training epoch 6:  99%|█████████▉| 161/163 [03:04<00:02,  1.02s/it, loss=2.6966, batch_acc=0.2500, running_acc=0.4490, grad=14.6996]Training epoch 6:  99%|█████████▉| 161/163 [03:04<00:02,  1.02s/it, loss=1.9319, batch_acc=0.4688, running_acc=0.4491, grad=11.6463]Training epoch 6:  99%|█████████▉| 162/163 [03:05<00:00,  1.03it/s, loss=1.9319, batch_acc=0.4688, running_acc=0.4491, grad=11.6463]Training epoch 6:  99%|█████████▉| 162/163 [03:05<00:00,  1.03it/s, loss=2.0655, batch_acc=0.4062, running_acc=0.4489, grad=12.7051]Training epoch 6: 100%|██████████| 163/163 [03:06<00:00,  1.15it/s, loss=2.0655, batch_acc=0.4062, running_acc=0.4489, grad=12.7051]Training epoch 6: 100%|██████████| 163/163 [03:06<00:00,  1.15it/s, loss=2.1730, batch_acc=0.5714, running_acc=0.4494, grad=16.9577]Training epoch 6: 100%|██████████| 163/163 [03:06<00:00,  1.14s/it, loss=2.1730, batch_acc=0.5714, running_acc=0.4494, grad=16.9577]
Evaluation epoch 6:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 6:   4%|▎         | 1/28 [00:04<02:11,  4.89s/it]Evaluation epoch 6:   4%|▎         | 1/28 [00:04<02:11,  4.89s/it, loss=1.6397, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 6:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=1.6397, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 6:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=1.8814, batch_acc=0.5000, running_acc=0.5938]Evaluation epoch 6:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=1.8814, batch_acc=0.5000, running_acc=0.5938]Evaluation epoch 6:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=1.7982, batch_acc=0.5312, running_acc=0.5729]Evaluation epoch 6:  14%|█▍        | 4/28 [00:09<01:01,  2.58s/it, loss=1.7982, batch_acc=0.5312, running_acc=0.5729]Evaluation epoch 6:  14%|█▍        | 4/28 [00:09<01:01,  2.58s/it, loss=2.4843, batch_acc=0.2500, running_acc=0.4922]Evaluation epoch 6:  18%|█▊        | 5/28 [00:10<00:40,  1.75s/it, loss=2.4843, batch_acc=0.2500, running_acc=0.4922]Evaluation epoch 6:  18%|█▊        | 5/28 [00:10<00:40,  1.75s/it, loss=2.5046, batch_acc=0.3438, running_acc=0.4625]Evaluation epoch 6:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=2.5046, batch_acc=0.3438, running_acc=0.4625]Evaluation epoch 6:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=2.4504, batch_acc=0.4062, running_acc=0.4531]Evaluation epoch 6:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.4504, batch_acc=0.4062, running_acc=0.4531]Evaluation epoch 6:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.2961, batch_acc=0.3750, running_acc=0.4420]Evaluation epoch 6:  29%|██▊       | 8/28 [00:14<00:35,  1.80s/it, loss=2.2961, batch_acc=0.3750, running_acc=0.4420]Evaluation epoch 6:  29%|██▊       | 8/28 [00:14<00:35,  1.80s/it, loss=2.0019, batch_acc=0.3750, running_acc=0.4336]Evaluation epoch 6:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=2.0019, batch_acc=0.3750, running_acc=0.4336]Evaluation epoch 6:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=2.4896, batch_acc=0.5000, running_acc=0.4410]Evaluation epoch 6:  36%|███▌      | 10/28 [00:15<00:18,  1.01s/it, loss=2.4896, batch_acc=0.5000, running_acc=0.4410]Evaluation epoch 6:  36%|███▌      | 10/28 [00:15<00:18,  1.01s/it, loss=1.1853, batch_acc=0.8438, running_acc=0.4813]Evaluation epoch 6:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=1.1853, batch_acc=0.8438, running_acc=0.4813]Evaluation epoch 6:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=2.9275, batch_acc=0.1562, running_acc=0.4517]Evaluation epoch 6:  43%|████▎     | 12/28 [00:21<00:39,  2.46s/it, loss=2.9275, batch_acc=0.1562, running_acc=0.4517]Evaluation epoch 6:  43%|████▎     | 12/28 [00:21<00:39,  2.46s/it, loss=2.2905, batch_acc=0.5000, running_acc=0.4557]Evaluation epoch 6:  46%|████▋     | 13/28 [00:21<00:26,  1.79s/it, loss=2.2905, batch_acc=0.5000, running_acc=0.4557]Evaluation epoch 6:  46%|████▋     | 13/28 [00:21<00:26,  1.79s/it, loss=1.8683, batch_acc=0.5312, running_acc=0.4615]Evaluation epoch 6:  50%|█████     | 14/28 [00:22<00:18,  1.33s/it, loss=1.8683, batch_acc=0.5312, running_acc=0.4615]Evaluation epoch 6:  50%|█████     | 14/28 [00:22<00:18,  1.33s/it, loss=2.4333, batch_acc=0.4688, running_acc=0.4621]Evaluation epoch 6:  54%|█████▎    | 15/28 [00:22<00:13,  1.01s/it, loss=2.4333, batch_acc=0.4688, running_acc=0.4621]Evaluation epoch 6:  54%|█████▎    | 15/28 [00:22<00:13,  1.01s/it, loss=3.0630, batch_acc=0.2500, running_acc=0.4479]Evaluation epoch 6:  57%|█████▋    | 16/28 [00:25<00:19,  1.61s/it, loss=3.0630, batch_acc=0.2500, running_acc=0.4479]Evaluation epoch 6:  57%|█████▋    | 16/28 [00:25<00:19,  1.61s/it, loss=2.4112, batch_acc=0.2812, running_acc=0.4375]Evaluation epoch 6:  61%|██████    | 17/28 [00:25<00:13,  1.20s/it, loss=2.4112, batch_acc=0.2812, running_acc=0.4375]Evaluation epoch 6:  61%|██████    | 17/28 [00:25<00:13,  1.20s/it, loss=2.0918, batch_acc=0.5000, running_acc=0.4412]Evaluation epoch 6:  64%|██████▍   | 18/28 [00:25<00:09,  1.09it/s, loss=2.0918, batch_acc=0.5000, running_acc=0.4412]Evaluation epoch 6:  64%|██████▍   | 18/28 [00:25<00:09,  1.09it/s, loss=1.7170, batch_acc=0.6875, running_acc=0.4549]Evaluation epoch 6:  68%|██████▊   | 19/28 [00:26<00:06,  1.38it/s, loss=1.7170, batch_acc=0.6875, running_acc=0.4549]Evaluation epoch 6:  68%|██████▊   | 19/28 [00:26<00:06,  1.38it/s, loss=1.9026, batch_acc=0.5000, running_acc=0.4572]Evaluation epoch 6:  71%|███████▏  | 20/28 [00:29<00:10,  1.37s/it, loss=1.9026, batch_acc=0.5000, running_acc=0.4572]Evaluation epoch 6:  71%|███████▏  | 20/28 [00:29<00:10,  1.37s/it, loss=2.3494, batch_acc=0.3438, running_acc=0.4516]Evaluation epoch 6:  75%|███████▌  | 21/28 [00:29<00:07,  1.04s/it, loss=2.3494, batch_acc=0.3438, running_acc=0.4516]Evaluation epoch 6:  75%|███████▌  | 21/28 [00:29<00:07,  1.04s/it, loss=2.5530, batch_acc=0.1562, running_acc=0.4375]Evaluation epoch 6:  79%|███████▊  | 22/28 [00:29<00:04,  1.24it/s, loss=2.5530, batch_acc=0.1562, running_acc=0.4375]Evaluation epoch 6:  79%|███████▊  | 22/28 [00:29<00:04,  1.24it/s, loss=2.6059, batch_acc=0.4688, running_acc=0.4389]Evaluation epoch 6:  82%|████████▏ | 23/28 [00:29<00:03,  1.55it/s, loss=2.6059, batch_acc=0.4688, running_acc=0.4389]Evaluation epoch 6:  82%|████████▏ | 23/28 [00:29<00:03,  1.55it/s, loss=2.3911, batch_acc=0.2812, running_acc=0.4321]Evaluation epoch 6:  86%|████████▌ | 24/28 [00:35<00:08,  2.06s/it, loss=2.3911, batch_acc=0.2812, running_acc=0.4321]Evaluation epoch 6:  86%|████████▌ | 24/28 [00:35<00:08,  2.06s/it, loss=1.6492, batch_acc=0.6562, running_acc=0.4414]Evaluation epoch 6:  89%|████████▉ | 25/28 [00:35<00:04,  1.52s/it, loss=1.6492, batch_acc=0.6562, running_acc=0.4414]Evaluation epoch 6:  89%|████████▉ | 25/28 [00:35<00:04,  1.52s/it, loss=1.6560, batch_acc=0.5000, running_acc=0.4437]Evaluation epoch 6:  93%|█████████▎| 26/28 [00:35<00:02,  1.14s/it, loss=1.6560, batch_acc=0.5000, running_acc=0.4437]Evaluation epoch 6:  93%|█████████▎| 26/28 [00:35<00:02,  1.14s/it, loss=1.7307, batch_acc=0.6250, running_acc=0.4507]Evaluation epoch 6:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=1.7307, batch_acc=0.6250, running_acc=0.4507]Evaluation epoch 6:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=2.0166, batch_acc=0.4688, running_acc=0.4514]Evaluation epoch 6: 100%|██████████| 28/28 [00:36<00:00,  1.14it/s, loss=0.8221, batch_acc=1.0000, running_acc=0.4533]Evaluation epoch 6: 100%|██████████| 28/28 [00:36<00:00,  1.29s/it, loss=0.8221, batch_acc=1.0000, running_acc=0.4533]
Training epoch 7:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 7:   1%|          | 1/163 [00:06<16:12,  6.00s/it]Training epoch 7:   1%|          | 1/163 [00:06<16:12,  6.00s/it, loss=1.7840, batch_acc=0.5938, running_acc=0.5938, grad=13.7981]Training epoch 7:   1%|          | 2/163 [00:06<08:01,  2.99s/it, loss=1.7840, batch_acc=0.5938, running_acc=0.5938, grad=13.7981]Training epoch 7:   1%|          | 2/163 [00:06<08:01,  2.99s/it, loss=2.0888, batch_acc=0.3750, running_acc=0.4844, grad=14.1563]Training epoch 7:   2%|▏         | 3/163 [00:07<05:23,  2.02s/it, loss=2.0888, batch_acc=0.3750, running_acc=0.4844, grad=14.1563]Training epoch 7:   2%|▏         | 3/163 [00:07<05:23,  2.02s/it, loss=2.1598, batch_acc=0.4688, running_acc=0.4792, grad=16.3791]Training epoch 7:   2%|▏         | 4/163 [00:10<06:09,  2.32s/it, loss=2.1598, batch_acc=0.4688, running_acc=0.4792, grad=16.3791]Training epoch 7:   2%|▏         | 4/163 [00:10<06:09,  2.32s/it, loss=1.7978, batch_acc=0.4375, running_acc=0.4688, grad=24.5180]Training epoch 7:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=1.7978, batch_acc=0.4375, running_acc=0.4688, grad=24.5180]Training epoch 7:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=1.9470, batch_acc=0.5000, running_acc=0.4750, grad=10.8965]Training epoch 7:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=1.9470, batch_acc=0.5000, running_acc=0.4750, grad=10.8965]Training epoch 7:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=2.1214, batch_acc=0.5938, running_acc=0.4948, grad=14.8843]Training epoch 7:   4%|▍         | 7/163 [00:13<03:20,  1.29s/it, loss=2.1214, batch_acc=0.5938, running_acc=0.4948, grad=14.8843]Training epoch 7:   4%|▍         | 7/163 [00:13<03:20,  1.29s/it, loss=1.9872, batch_acc=0.5625, running_acc=0.5045, grad=13.3917]Training epoch 7:   5%|▍         | 8/163 [00:14<03:22,  1.31s/it, loss=1.9872, batch_acc=0.5625, running_acc=0.5045, grad=13.3917]Training epoch 7:   5%|▍         | 8/163 [00:14<03:22,  1.31s/it, loss=1.9393, batch_acc=0.5312, running_acc=0.5078, grad=18.4479]Training epoch 7:   6%|▌         | 9/163 [00:15<03:00,  1.17s/it, loss=1.9393, batch_acc=0.5312, running_acc=0.5078, grad=18.4479]Training epoch 7:   6%|▌         | 9/163 [00:15<03:00,  1.17s/it, loss=2.0991, batch_acc=0.4688, running_acc=0.5035, grad=21.9136]Training epoch 7:   6%|▌         | 10/163 [00:16<02:45,  1.08s/it, loss=2.0991, batch_acc=0.4688, running_acc=0.5035, grad=21.9136]Training epoch 7:   6%|▌         | 10/163 [00:16<02:45,  1.08s/it, loss=2.1253, batch_acc=0.3750, running_acc=0.4906, grad=19.8476]Training epoch 7:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=2.1253, batch_acc=0.3750, running_acc=0.4906, grad=19.8476]Training epoch 7:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=2.0505, batch_acc=0.5000, running_acc=0.4915, grad=15.2988]Training epoch 7:   7%|▋         | 12/163 [00:18<03:04,  1.22s/it, loss=2.0505, batch_acc=0.5000, running_acc=0.4915, grad=15.2988]Training epoch 7:   7%|▋         | 12/163 [00:18<03:04,  1.22s/it, loss=1.8286, batch_acc=0.5938, running_acc=0.5000, grad=17.1268]Training epoch 7:   8%|▊         | 13/163 [00:19<02:47,  1.12s/it, loss=1.8286, batch_acc=0.5938, running_acc=0.5000, grad=17.1268]Training epoch 7:   8%|▊         | 13/163 [00:19<02:47,  1.12s/it, loss=2.3317, batch_acc=0.5312, running_acc=0.5024, grad=24.8091]Training epoch 7:   9%|▊         | 14/163 [00:20<02:35,  1.04s/it, loss=2.3317, batch_acc=0.5312, running_acc=0.5024, grad=24.8091]Training epoch 7:   9%|▊         | 14/163 [00:20<02:35,  1.04s/it, loss=2.2605, batch_acc=0.5000, running_acc=0.5022, grad=14.8091]Training epoch 7:   9%|▉         | 15/163 [00:21<02:27,  1.01it/s, loss=2.2605, batch_acc=0.5000, running_acc=0.5022, grad=14.8091]Training epoch 7:   9%|▉         | 15/163 [00:21<02:27,  1.01it/s, loss=1.9149, batch_acc=0.5000, running_acc=0.5021, grad=18.5383]Training epoch 7:  10%|▉         | 16/163 [00:23<02:51,  1.17s/it, loss=1.9149, batch_acc=0.5000, running_acc=0.5021, grad=18.5383]Training epoch 7:  10%|▉         | 16/163 [00:23<02:51,  1.17s/it, loss=2.0770, batch_acc=0.4375, running_acc=0.4980, grad=13.5992]Training epoch 7:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=2.0770, batch_acc=0.4375, running_acc=0.4980, grad=13.5992]Training epoch 7:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=2.0328, batch_acc=0.5000, running_acc=0.4982, grad=13.1418]Training epoch 7:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=2.0328, batch_acc=0.5000, running_acc=0.4982, grad=13.1418]Training epoch 7:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=2.1366, batch_acc=0.4688, running_acc=0.4965, grad=16.7216]Training epoch 7:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=2.1366, batch_acc=0.4688, running_acc=0.4965, grad=16.7216]Training epoch 7:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=2.2348, batch_acc=0.3750, running_acc=0.4901, grad=17.3658]Training epoch 7:  12%|█▏        | 20/163 [00:27<02:42,  1.14s/it, loss=2.2348, batch_acc=0.3750, running_acc=0.4901, grad=17.3658]Training epoch 7:  12%|█▏        | 20/163 [00:27<02:42,  1.14s/it, loss=1.8085, batch_acc=0.6250, running_acc=0.4969, grad=13.3631]Training epoch 7:  13%|█▎        | 21/163 [00:28<02:30,  1.06s/it, loss=1.8085, batch_acc=0.6250, running_acc=0.4969, grad=13.3631]Training epoch 7:  13%|█▎        | 21/163 [00:28<02:30,  1.06s/it, loss=2.1498, batch_acc=0.3438, running_acc=0.4896, grad=20.5216]Training epoch 7:  13%|█▎        | 22/163 [00:28<02:22,  1.01s/it, loss=2.1498, batch_acc=0.3438, running_acc=0.4896, grad=20.5216]Training epoch 7:  13%|█▎        | 22/163 [00:28<02:22,  1.01s/it, loss=2.0204, batch_acc=0.5000, running_acc=0.4901, grad=16.6614]Training epoch 7:  14%|█▍        | 23/163 [00:29<02:15,  1.03it/s, loss=2.0204, batch_acc=0.5000, running_acc=0.4901, grad=16.6614]Training epoch 7:  14%|█▍        | 23/163 [00:29<02:15,  1.03it/s, loss=1.9855, batch_acc=0.5938, running_acc=0.4946, grad=15.7301]Training epoch 7:  15%|█▍        | 24/163 [00:31<02:30,  1.08s/it, loss=1.9855, batch_acc=0.5938, running_acc=0.4946, grad=15.7301]Training epoch 7:  15%|█▍        | 24/163 [00:31<02:30,  1.08s/it, loss=2.2204, batch_acc=0.5000, running_acc=0.4948, grad=19.4612]Training epoch 7:  15%|█▌        | 25/163 [00:32<02:21,  1.02s/it, loss=2.2204, batch_acc=0.5000, running_acc=0.4948, grad=19.4612]Training epoch 7:  15%|█▌        | 25/163 [00:32<02:21,  1.02s/it, loss=1.7502, batch_acc=0.5625, running_acc=0.4975, grad=13.9094]Training epoch 7:  16%|█▌        | 26/163 [00:32<02:14,  1.02it/s, loss=1.7502, batch_acc=0.5625, running_acc=0.4975, grad=13.9094]Training epoch 7:  16%|█▌        | 26/163 [00:32<02:14,  1.02it/s, loss=1.9313, batch_acc=0.5938, running_acc=0.5012, grad=21.0329]Training epoch 7:  17%|█▋        | 27/163 [00:33<02:09,  1.05it/s, loss=1.9313, batch_acc=0.5938, running_acc=0.5012, grad=21.0329]Training epoch 7:  17%|█▋        | 27/163 [00:33<02:09,  1.05it/s, loss=1.5503, batch_acc=0.5938, running_acc=0.5046, grad=12.5554]Training epoch 7:  17%|█▋        | 28/163 [00:35<02:17,  1.02s/it, loss=1.5503, batch_acc=0.5938, running_acc=0.5046, grad=12.5554]Training epoch 7:  17%|█▋        | 28/163 [00:35<02:17,  1.02s/it, loss=1.6217, batch_acc=0.6875, running_acc=0.5112, grad=14.1722]Training epoch 7:  18%|█▊        | 29/163 [00:35<02:10,  1.03it/s, loss=1.6217, batch_acc=0.6875, running_acc=0.5112, grad=14.1722]Training epoch 7:  18%|█▊        | 29/163 [00:35<02:10,  1.03it/s, loss=2.0359, batch_acc=0.5000, running_acc=0.5108, grad=20.1537]Training epoch 7:  18%|█▊        | 30/163 [00:36<02:05,  1.06it/s, loss=2.0359, batch_acc=0.5000, running_acc=0.5108, grad=20.1537]Training epoch 7:  18%|█▊        | 30/163 [00:36<02:05,  1.06it/s, loss=2.3122, batch_acc=0.5000, running_acc=0.5104, grad=19.3035]Training epoch 7:  19%|█▉        | 31/163 [00:37<02:02,  1.08it/s, loss=2.3122, batch_acc=0.5000, running_acc=0.5104, grad=19.3035]Training epoch 7:  19%|█▉        | 31/163 [00:37<02:02,  1.08it/s, loss=1.8927, batch_acc=0.4062, running_acc=0.5071, grad=12.1309]Training epoch 7:  20%|█▉        | 32/163 [00:39<02:42,  1.24s/it, loss=1.8927, batch_acc=0.4062, running_acc=0.5071, grad=12.1309]Training epoch 7:  20%|█▉        | 32/163 [00:39<02:42,  1.24s/it, loss=1.8880, batch_acc=0.5312, running_acc=0.5078, grad=15.5616]Training epoch 7:  20%|██        | 33/163 [00:40<02:27,  1.13s/it, loss=1.8880, batch_acc=0.5312, running_acc=0.5078, grad=15.5616]Training epoch 7:  20%|██        | 33/163 [00:40<02:27,  1.13s/it, loss=2.0051, batch_acc=0.4375, running_acc=0.5057, grad=19.0365]Training epoch 7:  21%|██        | 34/163 [00:41<02:16,  1.06s/it, loss=2.0051, batch_acc=0.4375, running_acc=0.5057, grad=19.0365]Training epoch 7:  21%|██        | 34/163 [00:41<02:16,  1.06s/it, loss=1.8068, batch_acc=0.4375, running_acc=0.5037, grad=13.0846]Training epoch 7:  21%|██▏       | 35/163 [00:42<02:08,  1.01s/it, loss=1.8068, batch_acc=0.4375, running_acc=0.5037, grad=13.0846]Training epoch 7:  21%|██▏       | 35/163 [00:42<02:08,  1.01s/it, loss=2.1347, batch_acc=0.5000, running_acc=0.5036, grad=14.3201]Training epoch 7:  22%|██▏       | 36/163 [00:43<02:23,  1.13s/it, loss=2.1347, batch_acc=0.5000, running_acc=0.5036, grad=14.3201]Training epoch 7:  22%|██▏       | 36/163 [00:43<02:23,  1.13s/it, loss=1.9573, batch_acc=0.5000, running_acc=0.5035, grad=18.3327]Training epoch 7:  23%|██▎       | 37/163 [00:44<02:12,  1.06s/it, loss=1.9573, batch_acc=0.5000, running_acc=0.5035, grad=18.3327]Training epoch 7:  23%|██▎       | 37/163 [00:44<02:12,  1.06s/it, loss=1.8268, batch_acc=0.5625, running_acc=0.5051, grad=14.3832]Training epoch 7:  23%|██▎       | 38/163 [00:45<02:05,  1.00s/it, loss=1.8268, batch_acc=0.5625, running_acc=0.5051, grad=14.3832]Training epoch 7:  23%|██▎       | 38/163 [00:45<02:05,  1.00s/it, loss=1.9191, batch_acc=0.5625, running_acc=0.5066, grad=15.4124]Training epoch 7:  24%|██▍       | 39/163 [00:46<01:59,  1.04it/s, loss=1.9191, batch_acc=0.5625, running_acc=0.5066, grad=15.4124]Training epoch 7:  24%|██▍       | 39/163 [00:46<01:59,  1.04it/s, loss=2.0006, batch_acc=0.4375, running_acc=0.5048, grad=25.2538]Training epoch 7:  25%|██▍       | 40/163 [00:47<02:11,  1.07s/it, loss=2.0006, batch_acc=0.4375, running_acc=0.5048, grad=25.2538]Training epoch 7:  25%|██▍       | 40/163 [00:47<02:11,  1.07s/it, loss=1.8542, batch_acc=0.5938, running_acc=0.5070, grad=15.0128]Training epoch 7:  25%|██▌       | 41/163 [00:48<02:03,  1.01s/it, loss=1.8542, batch_acc=0.5938, running_acc=0.5070, grad=15.0128]Training epoch 7:  25%|██▌       | 41/163 [00:48<02:03,  1.01s/it, loss=1.9613, batch_acc=0.5312, running_acc=0.5076, grad=14.8105]Training epoch 7:  26%|██▌       | 42/163 [00:49<01:57,  1.03it/s, loss=1.9613, batch_acc=0.5312, running_acc=0.5076, grad=14.8105]Training epoch 7:  26%|██▌       | 42/163 [00:49<01:57,  1.03it/s, loss=1.8267, batch_acc=0.5938, running_acc=0.5097, grad=16.2643]Training epoch 7:  26%|██▋       | 43/163 [00:50<01:53,  1.06it/s, loss=1.8267, batch_acc=0.5938, running_acc=0.5097, grad=16.2643]Training epoch 7:  26%|██▋       | 43/163 [00:50<01:53,  1.06it/s, loss=2.0851, batch_acc=0.5000, running_acc=0.5094, grad=16.9174]Training epoch 7:  27%|██▋       | 44/163 [00:51<01:52,  1.05it/s, loss=2.0851, batch_acc=0.5000, running_acc=0.5094, grad=16.9174]Training epoch 7:  27%|██▋       | 44/163 [00:51<01:52,  1.05it/s, loss=1.9825, batch_acc=0.5000, running_acc=0.5092, grad=14.8234]Training epoch 7:  28%|██▊       | 45/163 [00:52<01:49,  1.08it/s, loss=1.9825, batch_acc=0.5000, running_acc=0.5092, grad=14.8234]Training epoch 7:  28%|██▊       | 45/163 [00:52<01:49,  1.08it/s, loss=2.0916, batch_acc=0.4375, running_acc=0.5076, grad=14.3180]Training epoch 7:  28%|██▊       | 46/163 [00:53<01:46,  1.09it/s, loss=2.0916, batch_acc=0.4375, running_acc=0.5076, grad=14.3180]Training epoch 7:  28%|██▊       | 46/163 [00:53<01:46,  1.09it/s, loss=1.9509, batch_acc=0.4688, running_acc=0.5068, grad=16.5478]Training epoch 7:  29%|██▉       | 47/163 [00:53<01:44,  1.11it/s, loss=1.9509, batch_acc=0.4688, running_acc=0.5068, grad=16.5478]Training epoch 7:  29%|██▉       | 47/163 [00:53<01:44,  1.11it/s, loss=2.2058, batch_acc=0.4062, running_acc=0.5047, grad=15.8549]Training epoch 7:  29%|██▉       | 48/163 [00:55<02:11,  1.14s/it, loss=2.2058, batch_acc=0.4062, running_acc=0.5047, grad=15.8549]Training epoch 7:  29%|██▉       | 48/163 [00:55<02:11,  1.14s/it, loss=2.0826, batch_acc=0.3750, running_acc=0.5020, grad=16.3543]Training epoch 7:  30%|███       | 49/163 [00:56<02:01,  1.06s/it, loss=2.0826, batch_acc=0.3750, running_acc=0.5020, grad=16.3543]Training epoch 7:  30%|███       | 49/163 [00:56<02:01,  1.06s/it, loss=2.0629, batch_acc=0.4062, running_acc=0.5000, grad=11.3040]Training epoch 7:  31%|███       | 50/163 [00:57<01:54,  1.01s/it, loss=2.0629, batch_acc=0.4062, running_acc=0.5000, grad=11.3040]Training epoch 7:  31%|███       | 50/163 [00:57<01:54,  1.01s/it, loss=1.9839, batch_acc=0.5000, running_acc=0.5000, grad=14.7272]Training epoch 7:  31%|███▏      | 51/163 [00:58<01:51,  1.00it/s, loss=1.9839, batch_acc=0.5000, running_acc=0.5000, grad=14.7272]Training epoch 7:  31%|███▏      | 51/163 [00:58<01:51,  1.00it/s, loss=2.1864, batch_acc=0.5625, running_acc=0.5012, grad=15.8383]Training epoch 7:  32%|███▏      | 52/163 [00:59<01:53,  1.03s/it, loss=2.1864, batch_acc=0.5625, running_acc=0.5012, grad=15.8383]Training epoch 7:  32%|███▏      | 52/163 [00:59<01:53,  1.03s/it, loss=2.2006, batch_acc=0.3438, running_acc=0.4982, grad=15.8820]Training epoch 7:  33%|███▎      | 53/163 [01:00<01:48,  1.02it/s, loss=2.2006, batch_acc=0.3438, running_acc=0.4982, grad=15.8820]Training epoch 7:  33%|███▎      | 53/163 [01:00<01:48,  1.02it/s, loss=2.0172, batch_acc=0.5000, running_acc=0.4982, grad=13.9543]Training epoch 7:  33%|███▎      | 54/163 [01:01<01:43,  1.05it/s, loss=2.0172, batch_acc=0.5000, running_acc=0.4982, grad=13.9543]Training epoch 7:  33%|███▎      | 54/163 [01:01<01:43,  1.05it/s, loss=2.3371, batch_acc=0.3438, running_acc=0.4954, grad=18.2335]Training epoch 7:  34%|███▎      | 55/163 [01:02<01:54,  1.06s/it, loss=2.3371, batch_acc=0.3438, running_acc=0.4954, grad=18.2335]Training epoch 7:  34%|███▎      | 55/163 [01:02<01:54,  1.06s/it, loss=1.8027, batch_acc=0.5000, running_acc=0.4955, grad=18.3258]Training epoch 7:  34%|███▍      | 56/163 [01:03<01:47,  1.01s/it, loss=1.8027, batch_acc=0.5000, running_acc=0.4955, grad=18.3258]Training epoch 7:  34%|███▍      | 56/163 [01:03<01:47,  1.01s/it, loss=2.0659, batch_acc=0.5000, running_acc=0.4955, grad=11.8288]Training epoch 7:  35%|███▍      | 57/163 [01:04<01:42,  1.03it/s, loss=2.0659, batch_acc=0.5000, running_acc=0.4955, grad=11.8288]Training epoch 7:  35%|███▍      | 57/163 [01:04<01:42,  1.03it/s, loss=1.9767, batch_acc=0.4375, running_acc=0.4945, grad=13.9549]Training epoch 7:  36%|███▌      | 58/163 [01:05<01:39,  1.06it/s, loss=1.9767, batch_acc=0.4375, running_acc=0.4945, grad=13.9549]Training epoch 7:  36%|███▌      | 58/163 [01:05<01:39,  1.06it/s, loss=1.9122, batch_acc=0.5000, running_acc=0.4946, grad=18.1872]Training epoch 7:  36%|███▌      | 59/163 [01:07<02:08,  1.24s/it, loss=1.9122, batch_acc=0.5000, running_acc=0.4946, grad=18.1872]Training epoch 7:  36%|███▌      | 59/163 [01:07<02:08,  1.24s/it, loss=1.8962, batch_acc=0.5625, running_acc=0.4958, grad=12.7357]Training epoch 7:  37%|███▋      | 60/163 [01:07<01:56,  1.13s/it, loss=1.8962, batch_acc=0.5625, running_acc=0.4958, grad=12.7357]Training epoch 7:  37%|███▋      | 60/163 [01:07<01:56,  1.13s/it, loss=1.7721, batch_acc=0.5625, running_acc=0.4969, grad=14.2779]Training epoch 7:  37%|███▋      | 61/163 [01:08<01:47,  1.06s/it, loss=1.7721, batch_acc=0.5625, running_acc=0.4969, grad=14.2779]Training epoch 7:  37%|███▋      | 61/163 [01:08<01:47,  1.06s/it, loss=2.0556, batch_acc=0.5625, running_acc=0.4980, grad=14.2154]Training epoch 7:  38%|███▊      | 62/163 [01:09<01:41,  1.00s/it, loss=2.0556, batch_acc=0.5625, running_acc=0.4980, grad=14.2154]Training epoch 7:  38%|███▊      | 62/163 [01:09<01:41,  1.00s/it, loss=1.6801, batch_acc=0.5625, running_acc=0.4990, grad=13.3924]Training epoch 7:  39%|███▊      | 63/163 [01:11<02:05,  1.26s/it, loss=1.6801, batch_acc=0.5625, running_acc=0.4990, grad=13.3924]Training epoch 7:  39%|███▊      | 63/163 [01:11<02:05,  1.26s/it, loss=2.1457, batch_acc=0.5312, running_acc=0.4995, grad=14.1007]Training epoch 7:  39%|███▉      | 64/163 [01:12<01:53,  1.15s/it, loss=2.1457, batch_acc=0.5312, running_acc=0.4995, grad=14.1007]Training epoch 7:  39%|███▉      | 64/163 [01:12<01:53,  1.15s/it, loss=2.0852, batch_acc=0.5625, running_acc=0.5005, grad=14.4795]Training epoch 7:  40%|███▉      | 65/163 [01:13<01:44,  1.07s/it, loss=2.0852, batch_acc=0.5625, running_acc=0.5005, grad=14.4795]Training epoch 7:  40%|███▉      | 65/163 [01:13<01:44,  1.07s/it, loss=2.2311, batch_acc=0.3125, running_acc=0.4976, grad=14.9817]Training epoch 7:  40%|████      | 66/163 [01:14<01:37,  1.01s/it, loss=2.2311, batch_acc=0.3125, running_acc=0.4976, grad=14.9817]Training epoch 7:  40%|████      | 66/163 [01:14<01:37,  1.01s/it, loss=2.0821, batch_acc=0.4688, running_acc=0.4972, grad=14.7528]Training epoch 7:  41%|████      | 67/163 [01:16<02:04,  1.30s/it, loss=2.0821, batch_acc=0.4688, running_acc=0.4972, grad=14.7528]Training epoch 7:  41%|████      | 67/163 [01:16<02:04,  1.30s/it, loss=2.0656, batch_acc=0.3438, running_acc=0.4949, grad=14.2613]Training epoch 7:  42%|████▏     | 68/163 [01:17<01:51,  1.17s/it, loss=2.0656, batch_acc=0.3438, running_acc=0.4949, grad=14.2613]Training epoch 7:  42%|████▏     | 68/163 [01:17<01:51,  1.17s/it, loss=2.0687, batch_acc=0.4062, running_acc=0.4936, grad=13.9124]Training epoch 7:  42%|████▏     | 69/163 [01:17<01:42,  1.09s/it, loss=2.0687, batch_acc=0.4062, running_acc=0.4936, grad=13.9124]Training epoch 7:  42%|████▏     | 69/163 [01:17<01:42,  1.09s/it, loss=1.8800, batch_acc=0.5000, running_acc=0.4937, grad=17.1459]Training epoch 7:  43%|████▎     | 70/163 [01:18<01:35,  1.02s/it, loss=1.8800, batch_acc=0.5000, running_acc=0.4937, grad=17.1459]Training epoch 7:  43%|████▎     | 70/163 [01:18<01:35,  1.02s/it, loss=2.1128, batch_acc=0.5312, running_acc=0.4942, grad=17.6099]Training epoch 7:  44%|████▎     | 71/163 [01:20<01:49,  1.19s/it, loss=2.1128, batch_acc=0.5312, running_acc=0.4942, grad=17.6099]Training epoch 7:  44%|████▎     | 71/163 [01:20<01:49,  1.19s/it, loss=1.8380, batch_acc=0.5625, running_acc=0.4952, grad=13.4820]Training epoch 7:  44%|████▍     | 72/163 [01:21<01:39,  1.09s/it, loss=1.8380, batch_acc=0.5625, running_acc=0.4952, grad=13.4820]Training epoch 7:  44%|████▍     | 72/163 [01:21<01:39,  1.09s/it, loss=1.8902, batch_acc=0.5312, running_acc=0.4957, grad=15.5160]Training epoch 7:  45%|████▍     | 73/163 [01:22<01:32,  1.03s/it, loss=1.8902, batch_acc=0.5312, running_acc=0.4957, grad=15.5160]Training epoch 7:  45%|████▍     | 73/163 [01:22<01:32,  1.03s/it, loss=2.0871, batch_acc=0.3125, running_acc=0.4932, grad=17.1948]Training epoch 7:  45%|████▌     | 74/163 [01:23<01:27,  1.02it/s, loss=2.0871, batch_acc=0.3125, running_acc=0.4932, grad=17.1948]Training epoch 7:  45%|████▌     | 74/163 [01:23<01:27,  1.02it/s, loss=2.1028, batch_acc=0.5312, running_acc=0.4937, grad=14.6496]Training epoch 7:  46%|████▌     | 75/163 [01:24<01:45,  1.20s/it, loss=2.1028, batch_acc=0.5312, running_acc=0.4937, grad=14.6496]Training epoch 7:  46%|████▌     | 75/163 [01:24<01:45,  1.20s/it, loss=2.0513, batch_acc=0.4375, running_acc=0.4929, grad=13.5144]Training epoch 7:  47%|████▋     | 76/163 [01:25<01:35,  1.10s/it, loss=2.0513, batch_acc=0.4375, running_acc=0.4929, grad=13.5144]Training epoch 7:  47%|████▋     | 76/163 [01:25<01:35,  1.10s/it, loss=2.1611, batch_acc=0.4375, running_acc=0.4922, grad=14.9659]Training epoch 7:  47%|████▋     | 77/163 [01:26<01:29,  1.04s/it, loss=2.1611, batch_acc=0.4375, running_acc=0.4922, grad=14.9659]Training epoch 7:  47%|████▋     | 77/163 [01:26<01:29,  1.04s/it, loss=2.3144, batch_acc=0.4062, running_acc=0.4911, grad=18.2348]Training epoch 7:  48%|████▊     | 78/163 [01:27<01:24,  1.01it/s, loss=2.3144, batch_acc=0.4062, running_acc=0.4911, grad=18.2348]Training epoch 7:  48%|████▊     | 78/163 [01:27<01:24,  1.01it/s, loss=1.9290, batch_acc=0.5000, running_acc=0.4912, grad=18.5170]Training epoch 7:  48%|████▊     | 79/163 [01:28<01:31,  1.09s/it, loss=1.9290, batch_acc=0.5000, running_acc=0.4912, grad=18.5170]Training epoch 7:  48%|████▊     | 79/163 [01:28<01:31,  1.09s/it, loss=2.4563, batch_acc=0.3750, running_acc=0.4897, grad=14.7997]Training epoch 7:  49%|████▉     | 80/163 [01:29<01:24,  1.02s/it, loss=2.4563, batch_acc=0.3750, running_acc=0.4897, grad=14.7997]Training epoch 7:  49%|████▉     | 80/163 [01:29<01:24,  1.02s/it, loss=1.8197, batch_acc=0.6250, running_acc=0.4914, grad=15.4453]Training epoch 7:  50%|████▉     | 81/163 [01:30<01:20,  1.02it/s, loss=1.8197, batch_acc=0.6250, running_acc=0.4914, grad=15.4453]Training epoch 7:  50%|████▉     | 81/163 [01:30<01:20,  1.02it/s, loss=2.0939, batch_acc=0.4688, running_acc=0.4911, grad=16.8847]Training epoch 7:  50%|█████     | 82/163 [01:31<01:17,  1.05it/s, loss=2.0939, batch_acc=0.4688, running_acc=0.4911, grad=16.8847]Training epoch 7:  50%|█████     | 82/163 [01:31<01:17,  1.05it/s, loss=1.9223, batch_acc=0.5312, running_acc=0.4916, grad=16.3712]Training epoch 7:  51%|█████     | 83/163 [01:33<01:38,  1.23s/it, loss=1.9223, batch_acc=0.5312, running_acc=0.4916, grad=16.3712]Training epoch 7:  51%|█████     | 83/163 [01:33<01:38,  1.23s/it, loss=1.9006, batch_acc=0.5000, running_acc=0.4917, grad=14.9825]Training epoch 7:  52%|█████▏    | 84/163 [01:34<01:28,  1.13s/it, loss=1.9006, batch_acc=0.5000, running_acc=0.4917, grad=14.9825]Training epoch 7:  52%|█████▏    | 84/163 [01:34<01:28,  1.13s/it, loss=1.9908, batch_acc=0.5000, running_acc=0.4918, grad=15.2801]Training epoch 7:  52%|█████▏    | 85/163 [01:34<01:22,  1.05s/it, loss=1.9908, batch_acc=0.5000, running_acc=0.4918, grad=15.2801]Training epoch 7:  52%|█████▏    | 85/163 [01:34<01:22,  1.05s/it, loss=1.7244, batch_acc=0.6875, running_acc=0.4941, grad=15.4850]Training epoch 7:  53%|█████▎    | 86/163 [01:35<01:17,  1.00s/it, loss=1.7244, batch_acc=0.6875, running_acc=0.4941, grad=15.4850]Training epoch 7:  53%|█████▎    | 86/163 [01:35<01:17,  1.00s/it, loss=2.1084, batch_acc=0.5312, running_acc=0.4945, grad=26.1739]Training epoch 7:  53%|█████▎    | 87/163 [01:37<01:25,  1.13s/it, loss=2.1084, batch_acc=0.5312, running_acc=0.4945, grad=26.1739]Training epoch 7:  53%|█████▎    | 87/163 [01:37<01:25,  1.13s/it, loss=2.3155, batch_acc=0.3750, running_acc=0.4932, grad=21.0605]Training epoch 7:  54%|█████▍    | 88/163 [01:38<01:19,  1.06s/it, loss=2.3155, batch_acc=0.3750, running_acc=0.4932, grad=21.0605]Training epoch 7:  54%|█████▍    | 88/163 [01:38<01:19,  1.06s/it, loss=1.6502, batch_acc=0.5938, running_acc=0.4943, grad=22.4929]Training epoch 7:  55%|█████▍    | 89/163 [01:39<01:14,  1.00s/it, loss=1.6502, batch_acc=0.5938, running_acc=0.4943, grad=22.4929]Training epoch 7:  55%|█████▍    | 89/163 [01:39<01:14,  1.00s/it, loss=2.0205, batch_acc=0.4375, running_acc=0.4937, grad=15.3885]Training epoch 7:  55%|█████▌    | 90/163 [01:39<01:10,  1.03it/s, loss=2.0205, batch_acc=0.4375, running_acc=0.4937, grad=15.3885]Training epoch 7:  55%|█████▌    | 90/163 [01:39<01:10,  1.03it/s, loss=1.9954, batch_acc=0.5312, running_acc=0.4941, grad=13.0442]Training epoch 7:  56%|█████▌    | 91/163 [01:42<01:34,  1.31s/it, loss=1.9954, batch_acc=0.5312, running_acc=0.4941, grad=13.0442]Training epoch 7:  56%|█████▌    | 91/163 [01:42<01:34,  1.31s/it, loss=1.8890, batch_acc=0.4688, running_acc=0.4938, grad=17.4722]Training epoch 7:  56%|█████▋    | 92/163 [01:42<01:23,  1.18s/it, loss=1.8890, batch_acc=0.4688, running_acc=0.4938, grad=17.4722]Training epoch 7:  56%|█████▋    | 92/163 [01:42<01:23,  1.18s/it, loss=2.1803, batch_acc=0.3438, running_acc=0.4922, grad=20.7188]Training epoch 7:  57%|█████▋    | 93/163 [01:43<01:16,  1.09s/it, loss=2.1803, batch_acc=0.3438, running_acc=0.4922, grad=20.7188]Training epoch 7:  57%|█████▋    | 93/163 [01:43<01:16,  1.09s/it, loss=2.0127, batch_acc=0.4375, running_acc=0.4916, grad=15.0007]Training epoch 7:  58%|█████▊    | 94/163 [01:44<01:10,  1.03s/it, loss=2.0127, batch_acc=0.4375, running_acc=0.4916, grad=15.0007]Training epoch 7:  58%|█████▊    | 94/163 [01:44<01:10,  1.03s/it, loss=2.1003, batch_acc=0.5312, running_acc=0.4920, grad=25.6991]Training epoch 7:  58%|█████▊    | 95/163 [01:46<01:28,  1.31s/it, loss=2.1003, batch_acc=0.5312, running_acc=0.4920, grad=25.6991]Training epoch 7:  58%|█████▊    | 95/163 [01:46<01:28,  1.31s/it, loss=1.9177, batch_acc=0.4688, running_acc=0.4918, grad=17.5447]Training epoch 7:  59%|█████▉    | 96/163 [01:47<01:18,  1.18s/it, loss=1.9177, batch_acc=0.4688, running_acc=0.4918, grad=17.5447]Training epoch 7:  59%|█████▉    | 96/163 [01:47<01:18,  1.18s/it, loss=1.7362, batch_acc=0.6250, running_acc=0.4932, grad=19.7067]Training epoch 7:  60%|█████▉    | 97/163 [01:48<01:11,  1.09s/it, loss=1.7362, batch_acc=0.6250, running_acc=0.4932, grad=19.7067]Training epoch 7:  60%|█████▉    | 97/163 [01:48<01:11,  1.09s/it, loss=1.7410, batch_acc=0.4375, running_acc=0.4926, grad=17.3790]Training epoch 7:  60%|██████    | 98/163 [01:49<01:06,  1.03s/it, loss=1.7410, batch_acc=0.4375, running_acc=0.4926, grad=17.3790]Training epoch 7:  60%|██████    | 98/163 [01:49<01:06,  1.03s/it, loss=2.0279, batch_acc=0.4375, running_acc=0.4920, grad=15.0847]Training epoch 7:  61%|██████    | 99/163 [01:50<01:16,  1.19s/it, loss=2.0279, batch_acc=0.4375, running_acc=0.4920, grad=15.0847]Training epoch 7:  61%|██████    | 99/163 [01:50<01:16,  1.19s/it, loss=1.8623, batch_acc=0.5312, running_acc=0.4924, grad=14.0809]Training epoch 7:  61%|██████▏   | 100/163 [01:51<01:09,  1.10s/it, loss=1.8623, batch_acc=0.5312, running_acc=0.4924, grad=14.0809]Training epoch 7:  61%|██████▏   | 100/163 [01:51<01:09,  1.10s/it, loss=2.2043, batch_acc=0.4062, running_acc=0.4916, grad=18.7914]Training epoch 7:  62%|██████▏   | 101/163 [01:52<01:04,  1.03s/it, loss=2.2043, batch_acc=0.4062, running_acc=0.4916, grad=18.7914]Training epoch 7:  62%|██████▏   | 101/163 [01:52<01:04,  1.03s/it, loss=2.0686, batch_acc=0.4062, running_acc=0.4907, grad=18.9867]Training epoch 7:  63%|██████▎   | 102/163 [01:53<01:00,  1.01it/s, loss=2.0686, batch_acc=0.4062, running_acc=0.4907, grad=18.9867]Training epoch 7:  63%|██████▎   | 102/163 [01:53<01:00,  1.01it/s, loss=1.9762, batch_acc=0.5000, running_acc=0.4908, grad=16.0281]Training epoch 7:  63%|██████▎   | 103/163 [01:55<01:09,  1.17s/it, loss=1.9762, batch_acc=0.5000, running_acc=0.4908, grad=16.0281]Training epoch 7:  63%|██████▎   | 103/163 [01:55<01:09,  1.17s/it, loss=1.8384, batch_acc=0.6250, running_acc=0.4921, grad=16.4331]Training epoch 7:  64%|██████▍   | 104/163 [01:55<01:03,  1.08s/it, loss=1.8384, batch_acc=0.6250, running_acc=0.4921, grad=16.4331]Training epoch 7:  64%|██████▍   | 104/163 [01:55<01:03,  1.08s/it, loss=2.0487, batch_acc=0.4688, running_acc=0.4919, grad=14.0084]Training epoch 7:  64%|██████▍   | 105/163 [01:56<00:59,  1.02s/it, loss=2.0487, batch_acc=0.4688, running_acc=0.4919, grad=14.0084]Training epoch 7:  64%|██████▍   | 105/163 [01:56<00:59,  1.02s/it, loss=2.2104, batch_acc=0.4688, running_acc=0.4917, grad=21.5487]Training epoch 7:  65%|██████▌   | 106/163 [01:57<00:55,  1.02it/s, loss=2.2104, batch_acc=0.4688, running_acc=0.4917, grad=21.5487]Training epoch 7:  65%|██████▌   | 106/163 [01:57<00:55,  1.02it/s, loss=2.2123, batch_acc=0.3750, running_acc=0.4906, grad=16.4762]Training epoch 7:  66%|██████▌   | 107/163 [02:00<01:17,  1.38s/it, loss=2.2123, batch_acc=0.3750, running_acc=0.4906, grad=16.4762]Training epoch 7:  66%|██████▌   | 107/163 [02:00<01:17,  1.38s/it, loss=1.7977, batch_acc=0.5625, running_acc=0.4912, grad=17.0858]Training epoch 7:  66%|██████▋   | 108/163 [02:00<01:07,  1.23s/it, loss=1.7977, batch_acc=0.5625, running_acc=0.4912, grad=17.0858]Training epoch 7:  66%|██████▋   | 108/163 [02:00<01:07,  1.23s/it, loss=2.1808, batch_acc=0.3125, running_acc=0.4896, grad=14.4514]Training epoch 7:  67%|██████▋   | 109/163 [02:01<01:00,  1.12s/it, loss=2.1808, batch_acc=0.3125, running_acc=0.4896, grad=14.4514]Training epoch 7:  67%|██████▋   | 109/163 [02:01<01:00,  1.12s/it, loss=2.0971, batch_acc=0.4062, running_acc=0.4888, grad=16.8745]Training epoch 7:  67%|██████▋   | 110/163 [02:02<00:55,  1.05s/it, loss=2.0971, batch_acc=0.4062, running_acc=0.4888, grad=16.8745]Training epoch 7:  67%|██████▋   | 110/163 [02:02<00:55,  1.05s/it, loss=2.0556, batch_acc=0.4375, running_acc=0.4884, grad=17.5227]Training epoch 7:  68%|██████▊   | 111/163 [02:04<01:04,  1.24s/it, loss=2.0556, batch_acc=0.4375, running_acc=0.4884, grad=17.5227]Training epoch 7:  68%|██████▊   | 111/163 [02:04<01:04,  1.24s/it, loss=1.8757, batch_acc=0.5312, running_acc=0.4887, grad=19.0247]Training epoch 7:  69%|██████▊   | 112/163 [02:05<00:57,  1.13s/it, loss=1.8757, batch_acc=0.5312, running_acc=0.4887, grad=19.0247]Training epoch 7:  69%|██████▊   | 112/163 [02:05<00:57,  1.13s/it, loss=1.7425, batch_acc=0.4688, running_acc=0.4886, grad=20.9089]Training epoch 7:  69%|██████▉   | 113/163 [02:06<00:52,  1.06s/it, loss=1.7425, batch_acc=0.4688, running_acc=0.4886, grad=20.9089]Training epoch 7:  69%|██████▉   | 113/163 [02:06<00:52,  1.06s/it, loss=2.2029, batch_acc=0.4688, running_acc=0.4884, grad=20.1531]Training epoch 7:  70%|██████▉   | 114/163 [02:07<00:49,  1.00s/it, loss=2.2029, batch_acc=0.4688, running_acc=0.4884, grad=20.1531]Training epoch 7:  70%|██████▉   | 114/163 [02:07<00:49,  1.00s/it, loss=2.0882, batch_acc=0.5312, running_acc=0.4888, grad=17.5976]Training epoch 7:  71%|███████   | 115/163 [02:08<00:55,  1.15s/it, loss=2.0882, batch_acc=0.5312, running_acc=0.4888, grad=17.5976]Training epoch 7:  71%|███████   | 115/163 [02:08<00:55,  1.15s/it, loss=2.2999, batch_acc=0.5938, running_acc=0.4897, grad=17.6879]Training epoch 7:  71%|███████   | 116/163 [02:09<00:50,  1.07s/it, loss=2.2999, batch_acc=0.5938, running_acc=0.4897, grad=17.6879]Training epoch 7:  71%|███████   | 116/163 [02:09<00:50,  1.07s/it, loss=1.9885, batch_acc=0.5625, running_acc=0.4903, grad=13.8616]Training epoch 7:  72%|███████▏  | 117/163 [02:10<00:46,  1.01s/it, loss=1.9885, batch_acc=0.5625, running_acc=0.4903, grad=13.8616]Training epoch 7:  72%|███████▏  | 117/163 [02:10<00:46,  1.01s/it, loss=1.6510, batch_acc=0.5938, running_acc=0.4912, grad=21.0488]Training epoch 7:  72%|███████▏  | 118/163 [02:11<00:43,  1.03it/s, loss=1.6510, batch_acc=0.5938, running_acc=0.4912, grad=21.0488]Training epoch 7:  72%|███████▏  | 118/163 [02:11<00:43,  1.03it/s, loss=2.0568, batch_acc=0.5000, running_acc=0.4913, grad=15.7031]Training epoch 7:  73%|███████▎  | 119/163 [02:12<00:51,  1.16s/it, loss=2.0568, batch_acc=0.5000, running_acc=0.4913, grad=15.7031]Training epoch 7:  73%|███████▎  | 119/163 [02:12<00:51,  1.16s/it, loss=1.9265, batch_acc=0.4688, running_acc=0.4911, grad=23.4795]Training epoch 7:  74%|███████▎  | 120/163 [02:13<00:46,  1.08s/it, loss=1.9265, batch_acc=0.4688, running_acc=0.4911, grad=23.4795]Training epoch 7:  74%|███████▎  | 120/163 [02:13<00:46,  1.08s/it, loss=1.8789, batch_acc=0.5625, running_acc=0.4917, grad=13.6886]Training epoch 7:  74%|███████▍  | 121/163 [02:14<00:42,  1.02s/it, loss=1.8789, batch_acc=0.5625, running_acc=0.4917, grad=13.6886]Training epoch 7:  74%|███████▍  | 121/163 [02:14<00:42,  1.02s/it, loss=1.7543, batch_acc=0.5938, running_acc=0.4925, grad=20.4474]Training epoch 7:  75%|███████▍  | 122/163 [02:15<00:40,  1.02it/s, loss=1.7543, batch_acc=0.5938, running_acc=0.4925, grad=20.4474]Training epoch 7:  75%|███████▍  | 122/163 [02:15<00:40,  1.02it/s, loss=2.4295, batch_acc=0.4062, running_acc=0.4918, grad=22.0750]Training epoch 7:  75%|███████▌  | 123/163 [02:17<00:51,  1.30s/it, loss=2.4295, batch_acc=0.4062, running_acc=0.4918, grad=22.0750]Training epoch 7:  75%|███████▌  | 123/163 [02:17<00:51,  1.30s/it, loss=1.8167, batch_acc=0.6562, running_acc=0.4931, grad=15.2629]Training epoch 7:  76%|███████▌  | 124/163 [02:18<00:45,  1.17s/it, loss=1.8167, batch_acc=0.6562, running_acc=0.4931, grad=15.2629]Training epoch 7:  76%|███████▌  | 124/163 [02:18<00:45,  1.17s/it, loss=2.1449, batch_acc=0.4688, running_acc=0.4929, grad=14.4826]Training epoch 7:  77%|███████▋  | 125/163 [02:19<00:41,  1.08s/it, loss=2.1449, batch_acc=0.4688, running_acc=0.4929, grad=14.4826]Training epoch 7:  77%|███████▋  | 125/163 [02:19<00:41,  1.08s/it, loss=2.1118, batch_acc=0.4375, running_acc=0.4925, grad=23.4804]Training epoch 7:  77%|███████▋  | 126/163 [02:20<00:37,  1.02s/it, loss=2.1118, batch_acc=0.4375, running_acc=0.4925, grad=23.4804]Training epoch 7:  77%|███████▋  | 126/163 [02:20<00:37,  1.02s/it, loss=2.1163, batch_acc=0.5312, running_acc=0.4928, grad=22.5258]Training epoch 7:  78%|███████▊  | 127/163 [02:21<00:44,  1.23s/it, loss=2.1163, batch_acc=0.5312, running_acc=0.4928, grad=22.5258]Training epoch 7:  78%|███████▊  | 127/163 [02:21<00:44,  1.23s/it, loss=1.7005, batch_acc=0.5938, running_acc=0.4936, grad=12.2486]Training epoch 7:  79%|███████▊  | 128/163 [02:22<00:39,  1.13s/it, loss=1.7005, batch_acc=0.5938, running_acc=0.4936, grad=12.2486]Training epoch 7:  79%|███████▊  | 128/163 [02:22<00:39,  1.13s/it, loss=2.1770, batch_acc=0.4375, running_acc=0.4932, grad=24.4819]Training epoch 7:  79%|███████▉  | 129/163 [02:23<00:35,  1.05s/it, loss=2.1770, batch_acc=0.4375, running_acc=0.4932, grad=24.4819]Training epoch 7:  79%|███████▉  | 129/163 [02:23<00:35,  1.05s/it, loss=1.9674, batch_acc=0.5938, running_acc=0.4939, grad=25.4542]Training epoch 7:  80%|███████▉  | 130/163 [02:24<00:33,  1.00s/it, loss=1.9674, batch_acc=0.5938, running_acc=0.4939, grad=25.4542]Training epoch 7:  80%|███████▉  | 130/163 [02:24<00:33,  1.00s/it, loss=2.2599, batch_acc=0.3438, running_acc=0.4928, grad=16.2626]Training epoch 7:  80%|████████  | 131/163 [02:25<00:36,  1.15s/it, loss=2.2599, batch_acc=0.3438, running_acc=0.4928, grad=16.2626]Training epoch 7:  80%|████████  | 131/163 [02:25<00:36,  1.15s/it, loss=1.5861, batch_acc=0.5625, running_acc=0.4933, grad=13.8365]Training epoch 7:  81%|████████  | 132/163 [02:26<00:33,  1.07s/it, loss=1.5861, batch_acc=0.5625, running_acc=0.4933, grad=13.8365]Training epoch 7:  81%|████████  | 132/163 [02:26<00:33,  1.07s/it, loss=1.8517, batch_acc=0.4375, running_acc=0.4929, grad=19.5912]Training epoch 7:  82%|████████▏ | 133/163 [02:27<00:30,  1.01s/it, loss=1.8517, batch_acc=0.4375, running_acc=0.4929, grad=19.5912]Training epoch 7:  82%|████████▏ | 133/163 [02:27<00:30,  1.01s/it, loss=2.1715, batch_acc=0.5000, running_acc=0.4930, grad=26.1918]Training epoch 7:  82%|████████▏ | 134/163 [02:28<00:28,  1.03it/s, loss=2.1715, batch_acc=0.5000, running_acc=0.4930, grad=26.1918]Training epoch 7:  82%|████████▏ | 134/163 [02:28<00:28,  1.03it/s, loss=1.7254, batch_acc=0.8125, running_acc=0.4953, grad=14.3830]Training epoch 7:  83%|████████▎ | 135/163 [02:30<00:33,  1.20s/it, loss=1.7254, batch_acc=0.8125, running_acc=0.4953, grad=14.3830]Training epoch 7:  83%|████████▎ | 135/163 [02:30<00:33,  1.20s/it, loss=2.0979, batch_acc=0.5000, running_acc=0.4954, grad=17.2460]Training epoch 7:  83%|████████▎ | 136/163 [02:31<00:29,  1.10s/it, loss=2.0979, batch_acc=0.5000, running_acc=0.4954, grad=17.2460]Training epoch 7:  83%|████████▎ | 136/163 [02:31<00:29,  1.10s/it, loss=2.0330, batch_acc=0.5312, running_acc=0.4956, grad=13.3913]Training epoch 7:  84%|████████▍ | 137/163 [02:32<00:26,  1.04s/it, loss=2.0330, batch_acc=0.5312, running_acc=0.4956, grad=13.3913]Training epoch 7:  84%|████████▍ | 137/163 [02:32<00:26,  1.04s/it, loss=2.1974, batch_acc=0.4688, running_acc=0.4954, grad=21.7476]Training epoch 7:  85%|████████▍ | 138/163 [02:32<00:24,  1.01it/s, loss=2.1974, batch_acc=0.4688, running_acc=0.4954, grad=21.7476]Training epoch 7:  85%|████████▍ | 138/163 [02:32<00:24,  1.01it/s, loss=1.9762, batch_acc=0.4688, running_acc=0.4952, grad=20.9525]Training epoch 7:  85%|████████▌ | 139/163 [02:34<00:28,  1.17s/it, loss=1.9762, batch_acc=0.4688, running_acc=0.4952, grad=20.9525]Training epoch 7:  85%|████████▌ | 139/163 [02:34<00:28,  1.17s/it, loss=1.8939, batch_acc=0.5000, running_acc=0.4953, grad=16.1487]Training epoch 7:  86%|████████▌ | 140/163 [02:35<00:24,  1.08s/it, loss=1.8939, batch_acc=0.5000, running_acc=0.4953, grad=16.1487]Training epoch 7:  86%|████████▌ | 140/163 [02:35<00:24,  1.08s/it, loss=1.8932, batch_acc=0.5625, running_acc=0.4958, grad=16.8451]Training epoch 7:  87%|████████▋ | 141/163 [02:36<00:22,  1.02s/it, loss=1.8932, batch_acc=0.5625, running_acc=0.4958, grad=16.8451]Training epoch 7:  87%|████████▋ | 141/163 [02:36<00:22,  1.02s/it, loss=1.7903, batch_acc=0.6562, running_acc=0.4969, grad=13.3014]Training epoch 7:  87%|████████▋ | 142/163 [02:37<00:20,  1.02it/s, loss=1.7903, batch_acc=0.6562, running_acc=0.4969, grad=13.3014]Training epoch 7:  87%|████████▋ | 142/163 [02:37<00:20,  1.02it/s, loss=2.1545, batch_acc=0.4375, running_acc=0.4965, grad=18.2167]Training epoch 7:  88%|████████▊ | 143/163 [02:39<00:24,  1.23s/it, loss=2.1545, batch_acc=0.4375, running_acc=0.4965, grad=18.2167]Training epoch 7:  88%|████████▊ | 143/163 [02:39<00:24,  1.23s/it, loss=1.8827, batch_acc=0.4375, running_acc=0.4961, grad=21.0653]Training epoch 7:  88%|████████▊ | 144/163 [02:39<00:21,  1.13s/it, loss=1.8827, batch_acc=0.4375, running_acc=0.4961, grad=21.0653]Training epoch 7:  88%|████████▊ | 144/163 [02:39<00:21,  1.13s/it, loss=1.9004, batch_acc=0.4688, running_acc=0.4959, grad=15.0719]Training epoch 7:  89%|████████▉ | 145/163 [02:40<00:18,  1.05s/it, loss=1.9004, batch_acc=0.4688, running_acc=0.4959, grad=15.0719]Training epoch 7:  89%|████████▉ | 145/163 [02:40<00:18,  1.05s/it, loss=2.1826, batch_acc=0.3125, running_acc=0.4946, grad=18.2035]Training epoch 7:  90%|████████▉ | 146/163 [02:41<00:17,  1.00s/it, loss=2.1826, batch_acc=0.3125, running_acc=0.4946, grad=18.2035]Training epoch 7:  90%|████████▉ | 146/163 [02:41<00:17,  1.00s/it, loss=2.0794, batch_acc=0.4688, running_acc=0.4944, grad=16.7890]Training epoch 7:  90%|█████████ | 147/163 [02:43<00:20,  1.28s/it, loss=2.0794, batch_acc=0.4688, running_acc=0.4944, grad=16.7890]Training epoch 7:  90%|█████████ | 147/163 [02:43<00:20,  1.28s/it, loss=1.7915, batch_acc=0.6562, running_acc=0.4955, grad=17.9701]Training epoch 7:  91%|█████████ | 148/163 [02:44<00:17,  1.16s/it, loss=1.7915, batch_acc=0.6562, running_acc=0.4955, grad=17.9701]Training epoch 7:  91%|█████████ | 148/163 [02:44<00:17,  1.16s/it, loss=1.8743, batch_acc=0.4688, running_acc=0.4954, grad=16.9797]Training epoch 7:  91%|█████████▏| 149/163 [02:45<00:15,  1.08s/it, loss=1.8743, batch_acc=0.4688, running_acc=0.4954, grad=16.9797]Training epoch 7:  91%|█████████▏| 149/163 [02:45<00:15,  1.08s/it, loss=1.8322, batch_acc=0.5625, running_acc=0.4958, grad=16.0391]Training epoch 7:  92%|█████████▏| 150/163 [02:46<00:13,  1.02s/it, loss=1.8322, batch_acc=0.5625, running_acc=0.4958, grad=16.0391]Training epoch 7:  92%|█████████▏| 150/163 [02:46<00:13,  1.02s/it, loss=1.8604, batch_acc=0.5938, running_acc=0.4965, grad=18.9504]Training epoch 7:  93%|█████████▎| 151/163 [02:48<00:15,  1.26s/it, loss=1.8604, batch_acc=0.5938, running_acc=0.4965, grad=18.9504]Training epoch 7:  93%|█████████▎| 151/163 [02:48<00:15,  1.26s/it, loss=1.9342, batch_acc=0.5938, running_acc=0.4971, grad=16.1098]Training epoch 7:  93%|█████████▎| 152/163 [02:48<00:12,  1.15s/it, loss=1.9342, batch_acc=0.5938, running_acc=0.4971, grad=16.1098]Training epoch 7:  93%|█████████▎| 152/163 [02:48<00:12,  1.15s/it, loss=2.2114, batch_acc=0.5312, running_acc=0.4973, grad=18.5580]Training epoch 7:  94%|█████████▍| 153/163 [02:49<00:10,  1.07s/it, loss=2.2114, batch_acc=0.5312, running_acc=0.4973, grad=18.5580]Training epoch 7:  94%|█████████▍| 153/163 [02:49<00:10,  1.07s/it, loss=2.0166, batch_acc=0.5312, running_acc=0.4975, grad=16.2642]Training epoch 7:  94%|█████████▍| 154/163 [02:50<00:09,  1.01s/it, loss=2.0166, batch_acc=0.5312, running_acc=0.4975, grad=16.2642]Training epoch 7:  94%|█████████▍| 154/163 [02:50<00:09,  1.01s/it, loss=2.0829, batch_acc=0.5312, running_acc=0.4978, grad=18.0284]Training epoch 7:  95%|█████████▌| 155/163 [02:52<00:09,  1.16s/it, loss=2.0829, batch_acc=0.5312, running_acc=0.4978, grad=18.0284]Training epoch 7:  95%|█████████▌| 155/163 [02:52<00:09,  1.16s/it, loss=1.9718, batch_acc=0.4688, running_acc=0.4976, grad=18.7795]Training epoch 7:  96%|█████████▌| 156/163 [02:53<00:07,  1.07s/it, loss=1.9718, batch_acc=0.4688, running_acc=0.4976, grad=18.7795]Training epoch 7:  96%|█████████▌| 156/163 [02:53<00:07,  1.07s/it, loss=2.0571, batch_acc=0.5000, running_acc=0.4976, grad=17.0060]Training epoch 7:  96%|█████████▋| 157/163 [02:53<00:06,  1.01s/it, loss=2.0571, batch_acc=0.5000, running_acc=0.4976, grad=17.0060]Training epoch 7:  96%|█████████▋| 157/163 [02:53<00:06,  1.01s/it, loss=1.7405, batch_acc=0.6250, running_acc=0.4984, grad=14.2491]Training epoch 7:  97%|█████████▋| 158/163 [02:54<00:04,  1.03it/s, loss=1.7405, batch_acc=0.6250, running_acc=0.4984, grad=14.2491]Training epoch 7:  97%|█████████▋| 158/163 [02:54<00:04,  1.03it/s, loss=1.9429, batch_acc=0.4375, running_acc=0.4980, grad=15.1689]Training epoch 7:  98%|█████████▊| 159/163 [02:55<00:03,  1.01it/s, loss=1.9429, batch_acc=0.4375, running_acc=0.4980, grad=15.1689]Training epoch 7:  98%|█████████▊| 159/163 [02:55<00:03,  1.01it/s, loss=1.8777, batch_acc=0.5625, running_acc=0.4984, grad=16.9130]Training epoch 7:  98%|█████████▊| 160/163 [02:56<00:02,  1.04it/s, loss=1.8777, batch_acc=0.5625, running_acc=0.4984, grad=16.9130]Training epoch 7:  98%|█████████▊| 160/163 [02:56<00:02,  1.04it/s, loss=1.9277, batch_acc=0.4375, running_acc=0.4980, grad=23.3622]Training epoch 7:  99%|█████████▉| 161/163 [02:57<00:01,  1.07it/s, loss=1.9277, batch_acc=0.4375, running_acc=0.4980, grad=23.3622]Training epoch 7:  99%|█████████▉| 161/163 [02:57<00:01,  1.07it/s, loss=1.7919, batch_acc=0.5312, running_acc=0.4983, grad=14.5123]Training epoch 7:  99%|█████████▉| 162/163 [02:58<00:00,  1.09it/s, loss=1.7919, batch_acc=0.5312, running_acc=0.4983, grad=14.5123]Training epoch 7:  99%|█████████▉| 162/163 [02:58<00:00,  1.09it/s, loss=1.7223, batch_acc=0.5312, running_acc=0.4985, grad=17.2249]Training epoch 7: 100%|██████████| 163/163 [02:59<00:00,  1.20it/s, loss=1.7223, batch_acc=0.5312, running_acc=0.4985, grad=17.2249]Training epoch 7: 100%|██████████| 163/163 [02:59<00:00,  1.20it/s, loss=1.8071, batch_acc=0.6190, running_acc=0.4989, grad=20.8583]Training epoch 7: 100%|██████████| 163/163 [02:59<00:00,  1.10s/it, loss=1.8071, batch_acc=0.6190, running_acc=0.4989, grad=20.8583]
Evaluation epoch 7:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 7:   4%|▎         | 1/28 [00:05<02:22,  5.27s/it]Evaluation epoch 7:   4%|▎         | 1/28 [00:05<02:22,  5.27s/it, loss=1.6215, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 7:   7%|▋         | 2/28 [00:05<01:00,  2.32s/it, loss=1.6215, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 7:   7%|▋         | 2/28 [00:05<01:00,  2.32s/it, loss=1.5717, batch_acc=0.6875, running_acc=0.5625]Evaluation epoch 7:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=1.5717, batch_acc=0.6875, running_acc=0.5625]Evaluation epoch 7:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=1.7709, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 7:  14%|█▍        | 4/28 [00:10<01:03,  2.65s/it, loss=1.7709, batch_acc=0.5625, running_acc=0.5625]Evaluation epoch 7:  14%|█▍        | 4/28 [00:10<01:03,  2.65s/it, loss=2.5529, batch_acc=0.1875, running_acc=0.4688]Evaluation epoch 7:  18%|█▊        | 5/28 [00:10<00:41,  1.79s/it, loss=2.5529, batch_acc=0.1875, running_acc=0.4688]Evaluation epoch 7:  18%|█▊        | 5/28 [00:10<00:41,  1.79s/it, loss=2.2005, batch_acc=0.5000, running_acc=0.4750]Evaluation epoch 7:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=2.2005, batch_acc=0.5000, running_acc=0.4750]Evaluation epoch 7:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=2.5128, batch_acc=0.3750, running_acc=0.4583]Evaluation epoch 7:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=2.5128, batch_acc=0.3750, running_acc=0.4583]Evaluation epoch 7:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=2.4981, batch_acc=0.3125, running_acc=0.4375]Evaluation epoch 7:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=2.4981, batch_acc=0.3125, running_acc=0.4375]Evaluation epoch 7:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=2.0923, batch_acc=0.3438, running_acc=0.4258]Evaluation epoch 7:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=2.0923, batch_acc=0.3438, running_acc=0.4258]Evaluation epoch 7:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=2.3196, batch_acc=0.4375, running_acc=0.4271]Evaluation epoch 7:  36%|███▌      | 10/28 [00:15<00:17,  1.03it/s, loss=2.3196, batch_acc=0.4375, running_acc=0.4271]Evaluation epoch 7:  36%|███▌      | 10/28 [00:15<00:17,  1.03it/s, loss=1.1191, batch_acc=0.8438, running_acc=0.4688]Evaluation epoch 7:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=1.1191, batch_acc=0.8438, running_acc=0.4688]Evaluation epoch 7:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=2.5376, batch_acc=0.2500, running_acc=0.4489]Evaluation epoch 7:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.5376, batch_acc=0.2500, running_acc=0.4489]Evaluation epoch 7:  43%|████▎     | 12/28 [00:20<00:35,  2.22s/it, loss=2.0072, batch_acc=0.5000, running_acc=0.4531]Evaluation epoch 7:  46%|████▋     | 13/28 [00:21<00:24,  1.63s/it, loss=2.0072, batch_acc=0.5000, running_acc=0.4531]Evaluation epoch 7:  46%|████▋     | 13/28 [00:21<00:24,  1.63s/it, loss=1.5521, batch_acc=0.7188, running_acc=0.4736]Evaluation epoch 7:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=1.5521, batch_acc=0.7188, running_acc=0.4736]Evaluation epoch 7:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=2.3158, batch_acc=0.5000, running_acc=0.4754]Evaluation epoch 7:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.3158, batch_acc=0.5000, running_acc=0.4754]Evaluation epoch 7:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.7612, batch_acc=0.3438, running_acc=0.4667]Evaluation epoch 7:  57%|█████▋    | 16/28 [00:24<00:17,  1.49s/it, loss=2.7612, batch_acc=0.3438, running_acc=0.4667]Evaluation epoch 7:  57%|█████▋    | 16/28 [00:24<00:17,  1.49s/it, loss=1.9482, batch_acc=0.4688, running_acc=0.4668]Evaluation epoch 7:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=1.9482, batch_acc=0.4688, running_acc=0.4668]Evaluation epoch 7:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=1.7010, batch_acc=0.6562, running_acc=0.4779]Evaluation epoch 7:  64%|██████▍   | 18/28 [00:25<00:08,  1.16it/s, loss=1.7010, batch_acc=0.6562, running_acc=0.4779]Evaluation epoch 7:  64%|██████▍   | 18/28 [00:25<00:08,  1.16it/s, loss=1.6391, batch_acc=0.5938, running_acc=0.4844]Evaluation epoch 7:  68%|██████▊   | 19/28 [00:25<00:06,  1.47it/s, loss=1.6391, batch_acc=0.5938, running_acc=0.4844]Evaluation epoch 7:  68%|██████▊   | 19/28 [00:25<00:06,  1.47it/s, loss=2.1688, batch_acc=0.1562, running_acc=0.4671]Evaluation epoch 7:  71%|███████▏  | 20/28 [00:27<00:10,  1.27s/it, loss=2.1688, batch_acc=0.1562, running_acc=0.4671]Evaluation epoch 7:  71%|███████▏  | 20/28 [00:27<00:10,  1.27s/it, loss=2.5534, batch_acc=0.1250, running_acc=0.4500]Evaluation epoch 7:  75%|███████▌  | 21/28 [00:28<00:06,  1.03it/s, loss=2.5534, batch_acc=0.1250, running_acc=0.4500]Evaluation epoch 7:  75%|███████▌  | 21/28 [00:28<00:06,  1.03it/s, loss=2.4969, batch_acc=0.1875, running_acc=0.4375]Evaluation epoch 7:  79%|███████▊  | 22/28 [00:28<00:04,  1.32it/s, loss=2.4969, batch_acc=0.1875, running_acc=0.4375]Evaluation epoch 7:  79%|███████▊  | 22/28 [00:28<00:04,  1.32it/s, loss=2.3036, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 7:  82%|████████▏ | 23/28 [00:28<00:03,  1.64it/s, loss=2.3036, batch_acc=0.4375, running_acc=0.4375]Evaluation epoch 7:  82%|████████▏ | 23/28 [00:28<00:03,  1.64it/s, loss=2.2372, batch_acc=0.2812, running_acc=0.4307]Evaluation epoch 7:  86%|████████▌ | 24/28 [00:33<00:07,  1.96s/it, loss=2.2372, batch_acc=0.2812, running_acc=0.4307]Evaluation epoch 7:  86%|████████▌ | 24/28 [00:33<00:07,  1.96s/it, loss=1.4686, batch_acc=0.7188, running_acc=0.4427]Evaluation epoch 7:  89%|████████▉ | 25/28 [00:34<00:04,  1.45s/it, loss=1.4686, batch_acc=0.7188, running_acc=0.4427]Evaluation epoch 7:  89%|████████▉ | 25/28 [00:34<00:04,  1.45s/it, loss=1.4239, batch_acc=0.6250, running_acc=0.4500]Evaluation epoch 7:  93%|█████████▎| 26/28 [00:34<00:02,  1.09s/it, loss=1.4239, batch_acc=0.6250, running_acc=0.4500]Evaluation epoch 7:  93%|█████████▎| 26/28 [00:34<00:02,  1.09s/it, loss=1.9841, batch_acc=0.3438, running_acc=0.4459]Evaluation epoch 7:  96%|█████████▋| 27/28 [00:34<00:00,  1.19it/s, loss=1.9841, batch_acc=0.3438, running_acc=0.4459]Evaluation epoch 7:  96%|█████████▋| 27/28 [00:34<00:00,  1.19it/s, loss=1.8290, batch_acc=0.5000, running_acc=0.4479]Evaluation epoch 7: 100%|██████████| 28/28 [00:34<00:00,  1.19it/s, loss=1.0496, batch_acc=0.6667, running_acc=0.4487]Evaluation epoch 7: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.0496, batch_acc=0.6667, running_acc=0.4487]
Training epoch 8:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 8:   1%|          | 1/163 [00:05<14:18,  5.30s/it]Training epoch 8:   1%|          | 1/163 [00:05<14:18,  5.30s/it, loss=2.3754, batch_acc=0.4062, running_acc=0.4062, grad=20.2210]Training epoch 8:   1%|          | 2/163 [00:06<07:14,  2.70s/it, loss=2.3754, batch_acc=0.4062, running_acc=0.4062, grad=20.2210]Training epoch 8:   1%|          | 2/163 [00:06<07:14,  2.70s/it, loss=1.7268, batch_acc=0.6562, running_acc=0.5312, grad=17.4319]Training epoch 8:   2%|▏         | 3/163 [00:07<04:59,  1.87s/it, loss=1.7268, batch_acc=0.6562, running_acc=0.5312, grad=17.4319]Training epoch 8:   2%|▏         | 3/163 [00:07<04:59,  1.87s/it, loss=1.7822, batch_acc=0.5938, running_acc=0.5521, grad=15.5889]Training epoch 8:   2%|▏         | 4/163 [00:09<05:23,  2.04s/it, loss=1.7822, batch_acc=0.5938, running_acc=0.5521, grad=15.5889]Training epoch 8:   2%|▏         | 4/163 [00:09<05:23,  2.04s/it, loss=1.6207, batch_acc=0.7188, running_acc=0.5938, grad=12.5853]Training epoch 8:   3%|▎         | 5/163 [00:10<04:18,  1.63s/it, loss=1.6207, batch_acc=0.7188, running_acc=0.5938, grad=12.5853]Training epoch 8:   3%|▎         | 5/163 [00:10<04:18,  1.63s/it, loss=1.9415, batch_acc=0.5625, running_acc=0.5875, grad=12.6438]Training epoch 8:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=1.9415, batch_acc=0.5625, running_acc=0.5875, grad=12.6438]Training epoch 8:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=1.9067, batch_acc=0.5938, running_acc=0.5885, grad=23.1681]Training epoch 8:   4%|▍         | 7/163 [00:12<03:09,  1.21s/it, loss=1.9067, batch_acc=0.5938, running_acc=0.5885, grad=23.1681]Training epoch 8:   4%|▍         | 7/163 [00:12<03:09,  1.21s/it, loss=2.2382, batch_acc=0.2500, running_acc=0.5402, grad=22.5627]Training epoch 8:   5%|▍         | 8/163 [00:13<03:36,  1.39s/it, loss=2.2382, batch_acc=0.2500, running_acc=0.5402, grad=22.5627]Training epoch 8:   5%|▍         | 8/163 [00:13<03:36,  1.39s/it, loss=1.9229, batch_acc=0.5000, running_acc=0.5352, grad=15.5158]Training epoch 8:   6%|▌         | 9/163 [00:14<03:10,  1.23s/it, loss=1.9229, batch_acc=0.5000, running_acc=0.5352, grad=15.5158]Training epoch 8:   6%|▌         | 9/163 [00:14<03:10,  1.23s/it, loss=2.1248, batch_acc=0.4062, running_acc=0.5208, grad=14.5502]Training epoch 8:   6%|▌         | 10/163 [00:15<02:52,  1.12s/it, loss=2.1248, batch_acc=0.4062, running_acc=0.5208, grad=14.5502]Training epoch 8:   6%|▌         | 10/163 [00:15<02:52,  1.12s/it, loss=2.0398, batch_acc=0.4062, running_acc=0.5094, grad=19.7275]Training epoch 8:   7%|▋         | 11/163 [00:16<02:39,  1.05s/it, loss=2.0398, batch_acc=0.4062, running_acc=0.5094, grad=19.7275]Training epoch 8:   7%|▋         | 11/163 [00:16<02:39,  1.05s/it, loss=1.9102, batch_acc=0.6250, running_acc=0.5199, grad=15.6013]Training epoch 8:   7%|▋         | 12/163 [00:18<03:14,  1.29s/it, loss=1.9102, batch_acc=0.6250, running_acc=0.5199, grad=15.6013]Training epoch 8:   7%|▋         | 12/163 [00:18<03:14,  1.29s/it, loss=2.1068, batch_acc=0.5312, running_acc=0.5208, grad=15.7813]Training epoch 8:   8%|▊         | 13/163 [00:19<02:54,  1.16s/it, loss=2.1068, batch_acc=0.5312, running_acc=0.5208, grad=15.7813]Training epoch 8:   8%|▊         | 13/163 [00:19<02:54,  1.16s/it, loss=1.7108, batch_acc=0.5938, running_acc=0.5264, grad=15.1988]Training epoch 8:   9%|▊         | 14/163 [00:20<02:40,  1.08s/it, loss=1.7108, batch_acc=0.5938, running_acc=0.5264, grad=15.1988]Training epoch 8:   9%|▊         | 14/163 [00:20<02:40,  1.08s/it, loss=1.9852, batch_acc=0.5312, running_acc=0.5268, grad=22.7770]Training epoch 8:   9%|▉         | 15/163 [00:20<02:30,  1.02s/it, loss=1.9852, batch_acc=0.5312, running_acc=0.5268, grad=22.7770]Training epoch 8:   9%|▉         | 15/163 [00:20<02:30,  1.02s/it, loss=1.9813, batch_acc=0.4688, running_acc=0.5229, grad=23.3722]Training epoch 8:  10%|▉         | 16/163 [00:22<03:10,  1.30s/it, loss=1.9813, batch_acc=0.4688, running_acc=0.5229, grad=23.3722]Training epoch 8:  10%|▉         | 16/163 [00:22<03:10,  1.30s/it, loss=1.4186, batch_acc=0.7812, running_acc=0.5391, grad=18.5300]Training epoch 8:  10%|█         | 17/163 [00:23<02:50,  1.17s/it, loss=1.4186, batch_acc=0.7812, running_acc=0.5391, grad=18.5300]Training epoch 8:  10%|█         | 17/163 [00:23<02:50,  1.17s/it, loss=1.8208, batch_acc=0.4375, running_acc=0.5331, grad=17.8372]Training epoch 8:  11%|█         | 18/163 [00:24<02:37,  1.08s/it, loss=1.8208, batch_acc=0.4375, running_acc=0.5331, grad=17.8372]Training epoch 8:  11%|█         | 18/163 [00:24<02:37,  1.08s/it, loss=1.8104, batch_acc=0.5625, running_acc=0.5347, grad=17.5594]Training epoch 8:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=1.8104, batch_acc=0.5625, running_acc=0.5347, grad=17.5594]Training epoch 8:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=1.9277, batch_acc=0.5000, running_acc=0.5329, grad=15.3418]Training epoch 8:  12%|█▏        | 20/163 [00:27<02:57,  1.24s/it, loss=1.9277, batch_acc=0.5000, running_acc=0.5329, grad=15.3418]Training epoch 8:  12%|█▏        | 20/163 [00:27<02:57,  1.24s/it, loss=2.0997, batch_acc=0.5625, running_acc=0.5344, grad=21.9417]Training epoch 8:  13%|█▎        | 21/163 [00:28<02:40,  1.13s/it, loss=2.0997, batch_acc=0.5625, running_acc=0.5344, grad=21.9417]Training epoch 8:  13%|█▎        | 21/163 [00:28<02:40,  1.13s/it, loss=1.8795, batch_acc=0.5000, running_acc=0.5327, grad=20.3275]Training epoch 8:  13%|█▎        | 22/163 [00:29<02:28,  1.06s/it, loss=1.8795, batch_acc=0.5000, running_acc=0.5327, grad=20.3275]Training epoch 8:  13%|█▎        | 22/163 [00:29<02:28,  1.06s/it, loss=2.1584, batch_acc=0.4375, running_acc=0.5284, grad=15.3245]Training epoch 8:  14%|█▍        | 23/163 [00:29<02:20,  1.00s/it, loss=2.1584, batch_acc=0.4375, running_acc=0.5284, grad=15.3245]Training epoch 8:  14%|█▍        | 23/163 [00:29<02:20,  1.00s/it, loss=2.0535, batch_acc=0.4375, running_acc=0.5245, grad=18.2420]Training epoch 8:  15%|█▍        | 24/163 [00:32<03:33,  1.53s/it, loss=2.0535, batch_acc=0.4375, running_acc=0.5245, grad=18.2420]Training epoch 8:  15%|█▍        | 24/163 [00:32<03:33,  1.53s/it, loss=1.7675, batch_acc=0.6250, running_acc=0.5286, grad=19.2303]Training epoch 8:  15%|█▌        | 25/163 [00:33<03:04,  1.34s/it, loss=1.7675, batch_acc=0.6250, running_acc=0.5286, grad=19.2303]Training epoch 8:  15%|█▌        | 25/163 [00:33<03:04,  1.34s/it, loss=1.8884, batch_acc=0.4688, running_acc=0.5262, grad=17.5380]Training epoch 8:  16%|█▌        | 26/163 [00:34<02:44,  1.20s/it, loss=1.8884, batch_acc=0.4688, running_acc=0.5262, grad=17.5380]Training epoch 8:  16%|█▌        | 26/163 [00:34<02:44,  1.20s/it, loss=1.9813, batch_acc=0.5312, running_acc=0.5264, grad=14.6097]Training epoch 8:  17%|█▋        | 27/163 [00:35<02:30,  1.10s/it, loss=1.9813, batch_acc=0.5312, running_acc=0.5264, grad=14.6097]Training epoch 8:  17%|█▋        | 27/163 [00:35<02:30,  1.10s/it, loss=1.7430, batch_acc=0.5625, running_acc=0.5278, grad=13.6774]Training epoch 8:  17%|█▋        | 28/163 [00:36<02:50,  1.26s/it, loss=1.7430, batch_acc=0.5625, running_acc=0.5278, grad=13.6774]Training epoch 8:  17%|█▋        | 28/163 [00:36<02:50,  1.26s/it, loss=1.8236, batch_acc=0.5312, running_acc=0.5279, grad=15.2065]Training epoch 8:  18%|█▊        | 29/163 [00:37<02:33,  1.15s/it, loss=1.8236, batch_acc=0.5312, running_acc=0.5279, grad=15.2065]Training epoch 8:  18%|█▊        | 29/163 [00:37<02:33,  1.15s/it, loss=1.7383, batch_acc=0.5312, running_acc=0.5280, grad=11.7184]Training epoch 8:  18%|█▊        | 30/163 [00:38<02:21,  1.07s/it, loss=1.7383, batch_acc=0.5312, running_acc=0.5280, grad=11.7184]Training epoch 8:  18%|█▊        | 30/163 [00:38<02:21,  1.07s/it, loss=2.0268, batch_acc=0.4688, running_acc=0.5260, grad=26.5299]Training epoch 8:  19%|█▉        | 31/163 [00:39<02:13,  1.01s/it, loss=2.0268, batch_acc=0.4688, running_acc=0.5260, grad=26.5299]Training epoch 8:  19%|█▉        | 31/163 [00:39<02:13,  1.01s/it, loss=1.9646, batch_acc=0.5000, running_acc=0.5252, grad=22.0410]Training epoch 8:  20%|█▉        | 32/163 [00:41<02:49,  1.29s/it, loss=1.9646, batch_acc=0.5000, running_acc=0.5252, grad=22.0410]Training epoch 8:  20%|█▉        | 32/163 [00:41<02:49,  1.29s/it, loss=1.9906, batch_acc=0.5312, running_acc=0.5254, grad=20.6482]Training epoch 8:  20%|██        | 33/163 [00:42<02:32,  1.17s/it, loss=1.9906, batch_acc=0.5312, running_acc=0.5254, grad=20.6482]Training epoch 8:  20%|██        | 33/163 [00:42<02:32,  1.17s/it, loss=2.0945, batch_acc=0.4688, running_acc=0.5237, grad=14.1861]Training epoch 8:  21%|██        | 34/163 [00:43<02:19,  1.08s/it, loss=2.0945, batch_acc=0.4688, running_acc=0.5237, grad=14.1861]Training epoch 8:  21%|██        | 34/163 [00:43<02:19,  1.08s/it, loss=1.8663, batch_acc=0.6250, running_acc=0.5267, grad=13.5721]Training epoch 8:  21%|██▏       | 35/163 [00:44<02:10,  1.02s/it, loss=1.8663, batch_acc=0.6250, running_acc=0.5267, grad=13.5721]Training epoch 8:  21%|██▏       | 35/163 [00:44<02:10,  1.02s/it, loss=1.7681, batch_acc=0.5312, running_acc=0.5268, grad=19.3234]Training epoch 8:  22%|██▏       | 36/163 [00:45<02:24,  1.14s/it, loss=1.7681, batch_acc=0.5312, running_acc=0.5268, grad=19.3234]Training epoch 8:  22%|██▏       | 36/163 [00:45<02:24,  1.14s/it, loss=1.8677, batch_acc=0.5938, running_acc=0.5286, grad=15.7676]Training epoch 8:  23%|██▎       | 37/163 [00:46<02:13,  1.06s/it, loss=1.8677, batch_acc=0.5938, running_acc=0.5286, grad=15.7676]Training epoch 8:  23%|██▎       | 37/163 [00:46<02:13,  1.06s/it, loss=1.8121, batch_acc=0.5000, running_acc=0.5279, grad=16.9367]Training epoch 8:  23%|██▎       | 38/163 [00:47<02:05,  1.00s/it, loss=1.8121, batch_acc=0.5000, running_acc=0.5279, grad=16.9367]Training epoch 8:  23%|██▎       | 38/163 [00:47<02:05,  1.00s/it, loss=1.9592, batch_acc=0.4375, running_acc=0.5255, grad=17.5077]Training epoch 8:  24%|██▍       | 39/163 [00:48<01:59,  1.03it/s, loss=1.9592, batch_acc=0.4375, running_acc=0.5255, grad=17.5077]Training epoch 8:  24%|██▍       | 39/163 [00:48<01:59,  1.03it/s, loss=1.9090, batch_acc=0.5625, running_acc=0.5264, grad=19.0868]Training epoch 8:  25%|██▍       | 40/163 [00:49<02:20,  1.14s/it, loss=1.9090, batch_acc=0.5625, running_acc=0.5264, grad=19.0868]Training epoch 8:  25%|██▍       | 40/163 [00:49<02:20,  1.14s/it, loss=1.8513, batch_acc=0.5938, running_acc=0.5281, grad=19.0178]Training epoch 8:  25%|██▌       | 41/163 [00:50<02:09,  1.06s/it, loss=1.8513, batch_acc=0.5938, running_acc=0.5281, grad=19.0178]Training epoch 8:  25%|██▌       | 41/163 [00:50<02:09,  1.06s/it, loss=1.6959, batch_acc=0.5312, running_acc=0.5282, grad=18.7361]Training epoch 8:  26%|██▌       | 42/163 [00:51<02:01,  1.01s/it, loss=1.6959, batch_acc=0.5312, running_acc=0.5282, grad=18.7361]Training epoch 8:  26%|██▌       | 42/163 [00:51<02:01,  1.01s/it, loss=1.6475, batch_acc=0.6562, running_acc=0.5312, grad=18.7328]Training epoch 8:  26%|██▋       | 43/163 [00:52<01:56,  1.03it/s, loss=1.6475, batch_acc=0.6562, running_acc=0.5312, grad=18.7328]Training epoch 8:  26%|██▋       | 43/163 [00:52<01:56,  1.03it/s, loss=1.9471, batch_acc=0.5312, running_acc=0.5312, grad=13.3094]Training epoch 8:  27%|██▋       | 44/163 [00:53<02:13,  1.12s/it, loss=1.9471, batch_acc=0.5312, running_acc=0.5312, grad=13.3094]Training epoch 8:  27%|██▋       | 44/163 [00:53<02:13,  1.12s/it, loss=1.7356, batch_acc=0.5312, running_acc=0.5312, grad=18.5301]Training epoch 8:  28%|██▊       | 45/163 [00:54<02:03,  1.05s/it, loss=1.7356, batch_acc=0.5312, running_acc=0.5312, grad=18.5301]Training epoch 8:  28%|██▊       | 45/163 [00:54<02:03,  1.05s/it, loss=1.9366, batch_acc=0.5000, running_acc=0.5306, grad=18.5573]Training epoch 8:  28%|██▊       | 46/163 [00:55<01:56,  1.00it/s, loss=1.9366, batch_acc=0.5000, running_acc=0.5306, grad=18.5573]Training epoch 8:  28%|██▊       | 46/163 [00:55<01:56,  1.00it/s, loss=2.1194, batch_acc=0.4375, running_acc=0.5285, grad=20.8434]Training epoch 8:  29%|██▉       | 47/163 [00:56<01:51,  1.04it/s, loss=2.1194, batch_acc=0.4375, running_acc=0.5285, grad=20.8434]Training epoch 8:  29%|██▉       | 47/163 [00:56<01:51,  1.04it/s, loss=1.5888, batch_acc=0.5312, running_acc=0.5286, grad=19.1724]Training epoch 8:  29%|██▉       | 48/163 [00:58<02:09,  1.13s/it, loss=1.5888, batch_acc=0.5312, running_acc=0.5286, grad=19.1724]Training epoch 8:  29%|██▉       | 48/163 [00:58<02:09,  1.13s/it, loss=1.5238, batch_acc=0.6562, running_acc=0.5312, grad=21.8303]Training epoch 8:  30%|███       | 49/163 [00:58<01:59,  1.05s/it, loss=1.5238, batch_acc=0.6562, running_acc=0.5312, grad=21.8303]Training epoch 8:  30%|███       | 49/163 [00:58<01:59,  1.05s/it, loss=1.7410, batch_acc=0.6562, running_acc=0.5338, grad=12.7050]Training epoch 8:  31%|███       | 50/163 [00:59<01:52,  1.00it/s, loss=1.7410, batch_acc=0.6562, running_acc=0.5338, grad=12.7050]Training epoch 8:  31%|███       | 50/163 [00:59<01:52,  1.00it/s, loss=1.9706, batch_acc=0.5312, running_acc=0.5337, grad=15.7541]Training epoch 8:  31%|███▏      | 51/163 [01:00<01:47,  1.04it/s, loss=1.9706, batch_acc=0.5312, running_acc=0.5337, grad=15.7541]Training epoch 8:  31%|███▏      | 51/163 [01:00<01:47,  1.04it/s, loss=1.9711, batch_acc=0.5000, running_acc=0.5331, grad=15.1149]Training epoch 8:  32%|███▏      | 52/163 [01:02<02:05,  1.14s/it, loss=1.9711, batch_acc=0.5000, running_acc=0.5331, grad=15.1149]Training epoch 8:  32%|███▏      | 52/163 [01:02<02:05,  1.14s/it, loss=1.9864, batch_acc=0.4688, running_acc=0.5319, grad=18.5107]Training epoch 8:  33%|███▎      | 53/163 [01:03<02:09,  1.18s/it, loss=1.9864, batch_acc=0.4688, running_acc=0.5319, grad=18.5107]Training epoch 8:  33%|███▎      | 53/163 [01:03<02:09,  1.18s/it, loss=1.8240, batch_acc=0.5938, running_acc=0.5330, grad=16.0205]Training epoch 8:  33%|███▎      | 54/163 [01:04<01:58,  1.09s/it, loss=1.8240, batch_acc=0.5938, running_acc=0.5330, grad=16.0205]Training epoch 8:  33%|███▎      | 54/163 [01:04<01:58,  1.09s/it, loss=1.7276, batch_acc=0.6250, running_acc=0.5347, grad=13.9990]Training epoch 8:  34%|███▎      | 55/163 [01:05<01:50,  1.02s/it, loss=1.7276, batch_acc=0.6250, running_acc=0.5347, grad=13.9990]Training epoch 8:  34%|███▎      | 55/163 [01:05<01:50,  1.02s/it, loss=1.9165, batch_acc=0.5625, running_acc=0.5352, grad=18.3462]Training epoch 8:  34%|███▍      | 56/163 [01:06<02:13,  1.25s/it, loss=1.9165, batch_acc=0.5625, running_acc=0.5352, grad=18.3462]Training epoch 8:  34%|███▍      | 56/163 [01:06<02:13,  1.25s/it, loss=1.9446, batch_acc=0.4688, running_acc=0.5340, grad=19.2451]Training epoch 8:  35%|███▍      | 57/163 [01:07<02:00,  1.14s/it, loss=1.9446, batch_acc=0.4688, running_acc=0.5340, grad=19.2451]Training epoch 8:  35%|███▍      | 57/163 [01:07<02:00,  1.14s/it, loss=1.7508, batch_acc=0.5938, running_acc=0.5351, grad=23.8145]Training epoch 8:  36%|███▌      | 58/163 [01:08<01:51,  1.06s/it, loss=1.7508, batch_acc=0.5938, running_acc=0.5351, grad=23.8145]Training epoch 8:  36%|███▌      | 58/163 [01:08<01:51,  1.06s/it, loss=1.8334, batch_acc=0.5625, running_acc=0.5356, grad=12.8833]Training epoch 8:  36%|███▌      | 59/163 [01:09<01:44,  1.01s/it, loss=1.8334, batch_acc=0.5625, running_acc=0.5356, grad=12.8833]Training epoch 8:  36%|███▌      | 59/163 [01:09<01:44,  1.01s/it, loss=1.8344, batch_acc=0.5938, running_acc=0.5365, grad=22.6776]Training epoch 8:  37%|███▋      | 60/163 [01:11<02:01,  1.18s/it, loss=1.8344, batch_acc=0.5938, running_acc=0.5365, grad=22.6776]Training epoch 8:  37%|███▋      | 60/163 [01:11<02:01,  1.18s/it, loss=2.3606, batch_acc=0.4062, running_acc=0.5344, grad=23.1277]Training epoch 8:  37%|███▋      | 61/163 [01:12<01:51,  1.09s/it, loss=2.3606, batch_acc=0.4062, running_acc=0.5344, grad=23.1277]Training epoch 8:  37%|███▋      | 61/163 [01:12<01:51,  1.09s/it, loss=1.8738, batch_acc=0.5938, running_acc=0.5353, grad=27.8428]Training epoch 8:  38%|███▊      | 62/163 [01:12<01:43,  1.03s/it, loss=1.8738, batch_acc=0.5938, running_acc=0.5353, grad=27.8428]Training epoch 8:  38%|███▊      | 62/163 [01:12<01:43,  1.03s/it, loss=2.2050, batch_acc=0.3750, running_acc=0.5328, grad=15.1730]Training epoch 8:  39%|███▊      | 63/163 [01:13<01:38,  1.02it/s, loss=2.2050, batch_acc=0.3750, running_acc=0.5328, grad=15.1730]Training epoch 8:  39%|███▊      | 63/163 [01:13<01:38,  1.02it/s, loss=1.7240, batch_acc=0.5625, running_acc=0.5332, grad=18.9264]Training epoch 8:  39%|███▉      | 64/163 [01:15<01:52,  1.14s/it, loss=1.7240, batch_acc=0.5625, running_acc=0.5332, grad=18.9264]Training epoch 8:  39%|███▉      | 64/163 [01:15<01:52,  1.14s/it, loss=1.8321, batch_acc=0.5938, running_acc=0.5342, grad=16.1333]Training epoch 8:  40%|███▉      | 65/163 [01:16<01:46,  1.09s/it, loss=1.8321, batch_acc=0.5938, running_acc=0.5342, grad=16.1333]Training epoch 8:  40%|███▉      | 65/163 [01:16<01:46,  1.09s/it, loss=2.0250, batch_acc=0.4688, running_acc=0.5332, grad=18.6506]Training epoch 8:  40%|████      | 66/163 [01:17<01:39,  1.02s/it, loss=2.0250, batch_acc=0.4688, running_acc=0.5332, grad=18.6506]Training epoch 8:  40%|████      | 66/163 [01:17<01:39,  1.02s/it, loss=1.8075, batch_acc=0.5625, running_acc=0.5336, grad=24.6136]Training epoch 8:  41%|████      | 67/163 [01:18<01:34,  1.02it/s, loss=1.8075, batch_acc=0.5625, running_acc=0.5336, grad=24.6136]Training epoch 8:  41%|████      | 67/163 [01:18<01:34,  1.02it/s, loss=1.8640, batch_acc=0.5000, running_acc=0.5331, grad=22.5353]Training epoch 8:  42%|████▏     | 68/163 [01:19<01:56,  1.23s/it, loss=1.8640, batch_acc=0.5000, running_acc=0.5331, grad=22.5353]Training epoch 8:  42%|████▏     | 68/163 [01:19<01:56,  1.23s/it, loss=1.6374, batch_acc=0.6250, running_acc=0.5345, grad=21.6061]Training epoch 8:  42%|████▏     | 69/163 [01:20<01:45,  1.12s/it, loss=1.6374, batch_acc=0.6250, running_acc=0.5345, grad=21.6061]Training epoch 8:  42%|████▏     | 69/163 [01:20<01:45,  1.12s/it, loss=1.3456, batch_acc=0.7500, running_acc=0.5376, grad=17.4560]Training epoch 8:  43%|████▎     | 70/163 [01:21<01:37,  1.05s/it, loss=1.3456, batch_acc=0.7500, running_acc=0.5376, grad=17.4560]Training epoch 8:  43%|████▎     | 70/163 [01:21<01:37,  1.05s/it, loss=1.7355, batch_acc=0.5000, running_acc=0.5371, grad=15.0716]Training epoch 8:  44%|████▎     | 71/163 [01:22<01:31,  1.00it/s, loss=1.7355, batch_acc=0.5000, running_acc=0.5371, grad=15.0716]Training epoch 8:  44%|████▎     | 71/163 [01:22<01:31,  1.00it/s, loss=2.0006, batch_acc=0.5312, running_acc=0.5370, grad=19.5647]Training epoch 8:  44%|████▍     | 72/163 [01:24<01:51,  1.23s/it, loss=2.0006, batch_acc=0.5312, running_acc=0.5370, grad=19.5647]Training epoch 8:  44%|████▍     | 72/163 [01:24<01:51,  1.23s/it, loss=1.6983, batch_acc=0.5312, running_acc=0.5369, grad=17.3251]Training epoch 8:  45%|████▍     | 73/163 [01:25<01:40,  1.12s/it, loss=1.6983, batch_acc=0.5312, running_acc=0.5369, grad=17.3251]Training epoch 8:  45%|████▍     | 73/163 [01:25<01:40,  1.12s/it, loss=2.0460, batch_acc=0.4375, running_acc=0.5355, grad=19.2918]Training epoch 8:  45%|████▌     | 74/163 [01:26<01:33,  1.05s/it, loss=2.0460, batch_acc=0.4375, running_acc=0.5355, grad=19.2918]Training epoch 8:  45%|████▌     | 74/163 [01:26<01:33,  1.05s/it, loss=1.6656, batch_acc=0.6250, running_acc=0.5367, grad=16.5651]Training epoch 8:  46%|████▌     | 75/163 [01:26<01:27,  1.00it/s, loss=1.6656, batch_acc=0.6250, running_acc=0.5367, grad=16.5651]Training epoch 8:  46%|████▌     | 75/163 [01:26<01:27,  1.00it/s, loss=1.5797, batch_acc=0.5625, running_acc=0.5371, grad=20.8388]Training epoch 8:  47%|████▋     | 76/163 [01:28<01:36,  1.11s/it, loss=1.5797, batch_acc=0.5625, running_acc=0.5371, grad=20.8388]Training epoch 8:  47%|████▋     | 76/163 [01:28<01:36,  1.11s/it, loss=1.9577, batch_acc=0.4375, running_acc=0.5358, grad=18.7152]Training epoch 8:  47%|████▋     | 77/163 [01:29<01:29,  1.04s/it, loss=1.9577, batch_acc=0.4375, running_acc=0.5358, grad=18.7152]Training epoch 8:  47%|████▋     | 77/163 [01:29<01:29,  1.04s/it, loss=2.2620, batch_acc=0.5312, running_acc=0.5357, grad=19.4605]Training epoch 8:  48%|████▊     | 78/163 [01:30<01:24,  1.01it/s, loss=2.2620, batch_acc=0.5312, running_acc=0.5357, grad=19.4605]Training epoch 8:  48%|████▊     | 78/163 [01:30<01:24,  1.01it/s, loss=1.9553, batch_acc=0.5000, running_acc=0.5353, grad=21.5050]Training epoch 8:  48%|████▊     | 79/163 [01:30<01:20,  1.04it/s, loss=1.9553, batch_acc=0.5000, running_acc=0.5353, grad=21.5050]Training epoch 8:  48%|████▊     | 79/163 [01:30<01:20,  1.04it/s, loss=1.7665, batch_acc=0.4688, running_acc=0.5344, grad=18.5200]Training epoch 8:  49%|████▉     | 80/163 [01:32<01:41,  1.22s/it, loss=1.7665, batch_acc=0.4688, running_acc=0.5344, grad=18.5200]Training epoch 8:  49%|████▉     | 80/163 [01:32<01:41,  1.22s/it, loss=1.5408, batch_acc=0.6875, running_acc=0.5363, grad=16.3559]Training epoch 8:  50%|████▉     | 81/163 [01:33<01:32,  1.12s/it, loss=1.5408, batch_acc=0.6875, running_acc=0.5363, grad=16.3559]Training epoch 8:  50%|████▉     | 81/163 [01:33<01:32,  1.12s/it, loss=1.9530, batch_acc=0.5625, running_acc=0.5367, grad=15.9451]Training epoch 8:  50%|█████     | 82/163 [01:34<01:25,  1.06s/it, loss=1.9530, batch_acc=0.5625, running_acc=0.5367, grad=15.9451]Training epoch 8:  50%|█████     | 82/163 [01:34<01:25,  1.06s/it, loss=1.6417, batch_acc=0.6250, running_acc=0.5377, grad=17.3591]Training epoch 8:  51%|█████     | 83/163 [01:35<01:20,  1.01s/it, loss=1.6417, batch_acc=0.6250, running_acc=0.5377, grad=17.3591]Training epoch 8:  51%|█████     | 83/163 [01:35<01:20,  1.01s/it, loss=1.8242, batch_acc=0.5938, running_acc=0.5384, grad=13.0068]Training epoch 8:  52%|█████▏    | 84/163 [01:37<01:33,  1.18s/it, loss=1.8242, batch_acc=0.5938, running_acc=0.5384, grad=13.0068]Training epoch 8:  52%|█████▏    | 84/163 [01:37<01:33,  1.18s/it, loss=1.6652, batch_acc=0.5625, running_acc=0.5387, grad=15.1111]Training epoch 8:  52%|█████▏    | 85/163 [01:37<01:26,  1.11s/it, loss=1.6652, batch_acc=0.5625, running_acc=0.5387, grad=15.1111]Training epoch 8:  52%|█████▏    | 85/163 [01:37<01:26,  1.11s/it, loss=1.8546, batch_acc=0.5625, running_acc=0.5390, grad=20.1179]Training epoch 8:  53%|█████▎    | 86/163 [01:38<01:20,  1.04s/it, loss=1.8546, batch_acc=0.5625, running_acc=0.5390, grad=20.1179]Training epoch 8:  53%|█████▎    | 86/163 [01:38<01:20,  1.04s/it, loss=1.5308, batch_acc=0.8438, running_acc=0.5425, grad=15.8370]Training epoch 8:  53%|█████▎    | 87/163 [01:39<01:15,  1.01it/s, loss=1.5308, batch_acc=0.8438, running_acc=0.5425, grad=15.8370]Training epoch 8:  53%|█████▎    | 87/163 [01:39<01:15,  1.01it/s, loss=1.7536, batch_acc=0.5938, running_acc=0.5431, grad=27.1252]Training epoch 8:  54%|█████▍    | 88/163 [01:40<01:20,  1.07s/it, loss=1.7536, batch_acc=0.5938, running_acc=0.5431, grad=27.1252]Training epoch 8:  54%|█████▍    | 88/163 [01:40<01:20,  1.07s/it, loss=1.7154, batch_acc=0.5938, running_acc=0.5437, grad=19.2052]Training epoch 8:  55%|█████▍    | 89/163 [01:42<01:26,  1.17s/it, loss=1.7154, batch_acc=0.5938, running_acc=0.5437, grad=19.2052]Training epoch 8:  55%|█████▍    | 89/163 [01:42<01:26,  1.17s/it, loss=2.0216, batch_acc=0.5000, running_acc=0.5432, grad=20.2389]Training epoch 8:  55%|█████▌    | 90/163 [01:43<01:18,  1.08s/it, loss=2.0216, batch_acc=0.5000, running_acc=0.5432, grad=20.2389]Training epoch 8:  55%|█████▌    | 90/163 [01:43<01:18,  1.08s/it, loss=1.9589, batch_acc=0.5625, running_acc=0.5434, grad=16.8772]Training epoch 8:  56%|█████▌    | 91/163 [01:44<01:13,  1.02s/it, loss=1.9589, batch_acc=0.5625, running_acc=0.5434, grad=16.8772]Training epoch 8:  56%|█████▌    | 91/163 [01:44<01:13,  1.02s/it, loss=1.6847, batch_acc=0.5938, running_acc=0.5440, grad=16.1485]Training epoch 8:  56%|█████▋    | 92/163 [01:45<01:09,  1.02it/s, loss=1.6847, batch_acc=0.5938, running_acc=0.5440, grad=16.1485]Training epoch 8:  56%|█████▋    | 92/163 [01:45<01:09,  1.02it/s, loss=1.6152, batch_acc=0.6250, running_acc=0.5448, grad=16.2998]Training epoch 8:  57%|█████▋    | 93/163 [01:47<01:31,  1.31s/it, loss=1.6152, batch_acc=0.6250, running_acc=0.5448, grad=16.2998]Training epoch 8:  57%|█████▋    | 93/163 [01:47<01:31,  1.31s/it, loss=1.9128, batch_acc=0.5312, running_acc=0.5447, grad=19.8286]Training epoch 8:  58%|█████▊    | 94/163 [01:47<01:21,  1.18s/it, loss=1.9128, batch_acc=0.5312, running_acc=0.5447, grad=19.8286]Training epoch 8:  58%|█████▊    | 94/163 [01:47<01:21,  1.18s/it, loss=1.6154, batch_acc=0.5938, running_acc=0.5452, grad=16.1989]Training epoch 8:  58%|█████▊    | 95/163 [01:48<01:14,  1.09s/it, loss=1.6154, batch_acc=0.5938, running_acc=0.5452, grad=16.1989]Training epoch 8:  58%|█████▊    | 95/163 [01:48<01:14,  1.09s/it, loss=1.9797, batch_acc=0.4688, running_acc=0.5444, grad=17.9376]Training epoch 8:  59%|█████▉    | 96/163 [01:49<01:08,  1.03s/it, loss=1.9797, batch_acc=0.4688, running_acc=0.5444, grad=17.9376]Training epoch 8:  59%|█████▉    | 96/163 [01:49<01:08,  1.03s/it, loss=1.7265, batch_acc=0.6875, running_acc=0.5459, grad=18.5024]Training epoch 8:  60%|█████▉    | 97/163 [01:51<01:15,  1.14s/it, loss=1.7265, batch_acc=0.6875, running_acc=0.5459, grad=18.5024]Training epoch 8:  60%|█████▉    | 97/163 [01:51<01:15,  1.14s/it, loss=1.7418, batch_acc=0.6250, running_acc=0.5467, grad=15.1188]Training epoch 8:  60%|██████    | 98/163 [01:52<01:09,  1.06s/it, loss=1.7418, batch_acc=0.6250, running_acc=0.5467, grad=15.1188]Training epoch 8:  60%|██████    | 98/163 [01:52<01:09,  1.06s/it, loss=1.8893, batch_acc=0.5312, running_acc=0.5466, grad=20.2763]Training epoch 8:  61%|██████    | 99/163 [01:52<01:04,  1.01s/it, loss=1.8893, batch_acc=0.5312, running_acc=0.5466, grad=20.2763]Training epoch 8:  61%|██████    | 99/163 [01:52<01:04,  1.01s/it, loss=1.7827, batch_acc=0.6250, running_acc=0.5473, grad=16.2337]Training epoch 8:  61%|██████▏   | 100/163 [01:53<01:01,  1.03it/s, loss=1.7827, batch_acc=0.6250, running_acc=0.5473, grad=16.2337]Training epoch 8:  61%|██████▏   | 100/163 [01:53<01:01,  1.03it/s, loss=1.7579, batch_acc=0.5625, running_acc=0.5475, grad=20.1116]Training epoch 8:  62%|██████▏   | 101/163 [01:55<01:21,  1.31s/it, loss=1.7579, batch_acc=0.5625, running_acc=0.5475, grad=20.1116]Training epoch 8:  62%|██████▏   | 101/163 [01:55<01:21,  1.31s/it, loss=1.5401, batch_acc=0.6250, running_acc=0.5483, grad=22.4318]Training epoch 8:  63%|██████▎   | 102/163 [01:56<01:12,  1.18s/it, loss=1.5401, batch_acc=0.6250, running_acc=0.5483, grad=22.4318]Training epoch 8:  63%|██████▎   | 102/163 [01:56<01:12,  1.18s/it, loss=1.9535, batch_acc=0.4688, running_acc=0.5475, grad=16.8776]Training epoch 8:  63%|██████▎   | 103/163 [01:57<01:05,  1.09s/it, loss=1.9535, batch_acc=0.4688, running_acc=0.5475, grad=16.8776]Training epoch 8:  63%|██████▎   | 103/163 [01:57<01:05,  1.09s/it, loss=1.6888, batch_acc=0.4062, running_acc=0.5461, grad=13.7396]Training epoch 8:  64%|██████▍   | 104/163 [01:58<01:00,  1.03s/it, loss=1.6888, batch_acc=0.4062, running_acc=0.5461, grad=13.7396]Training epoch 8:  64%|██████▍   | 104/163 [01:58<01:00,  1.03s/it, loss=1.7381, batch_acc=0.6875, running_acc=0.5475, grad=13.8758]Training epoch 8:  64%|██████▍   | 105/163 [01:59<01:05,  1.14s/it, loss=1.7381, batch_acc=0.6875, running_acc=0.5475, grad=13.8758]Training epoch 8:  64%|██████▍   | 105/163 [01:59<01:05,  1.14s/it, loss=2.1388, batch_acc=0.3438, running_acc=0.5455, grad=14.8043]Training epoch 8:  65%|██████▌   | 106/163 [02:00<01:00,  1.06s/it, loss=2.1388, batch_acc=0.3438, running_acc=0.5455, grad=14.8043]Training epoch 8:  65%|██████▌   | 106/163 [02:00<01:00,  1.06s/it, loss=1.4893, batch_acc=0.6562, running_acc=0.5466, grad=19.4306]Training epoch 8:  66%|██████▌   | 107/163 [02:01<00:56,  1.01s/it, loss=1.4893, batch_acc=0.6562, running_acc=0.5466, grad=19.4306]Training epoch 8:  66%|██████▌   | 107/163 [02:01<00:56,  1.01s/it, loss=1.5771, batch_acc=0.5312, running_acc=0.5464, grad=12.9108]Training epoch 8:  66%|██████▋   | 108/163 [02:02<00:53,  1.03it/s, loss=1.5771, batch_acc=0.5312, running_acc=0.5464, grad=12.9108]Training epoch 8:  66%|██████▋   | 108/163 [02:02<00:53,  1.03it/s, loss=1.9159, batch_acc=0.5312, running_acc=0.5463, grad=15.1604]Training epoch 8:  67%|██████▋   | 109/163 [02:04<01:02,  1.16s/it, loss=1.9159, batch_acc=0.5312, running_acc=0.5463, grad=15.1604]Training epoch 8:  67%|██████▋   | 109/163 [02:04<01:02,  1.16s/it, loss=2.1233, batch_acc=0.4062, running_acc=0.5450, grad=29.5855]Training epoch 8:  67%|██████▋   | 110/163 [02:05<00:56,  1.07s/it, loss=2.1233, batch_acc=0.4062, running_acc=0.5450, grad=29.5855]Training epoch 8:  67%|██████▋   | 110/163 [02:05<00:56,  1.07s/it, loss=1.7514, batch_acc=0.6562, running_acc=0.5460, grad=19.9451]Training epoch 8:  68%|██████▊   | 111/163 [02:05<00:52,  1.02s/it, loss=1.7514, batch_acc=0.6562, running_acc=0.5460, grad=19.9451]Training epoch 8:  68%|██████▊   | 111/163 [02:05<00:52,  1.02s/it, loss=1.5076, batch_acc=0.5938, running_acc=0.5465, grad=14.0752]Training epoch 8:  69%|██████▊   | 112/163 [02:06<00:49,  1.02it/s, loss=1.5076, batch_acc=0.5938, running_acc=0.5465, grad=14.0752]Training epoch 8:  69%|██████▊   | 112/163 [02:06<00:49,  1.02it/s, loss=1.7250, batch_acc=0.5938, running_acc=0.5469, grad=17.2487]Training epoch 8:  69%|██████▉   | 113/163 [02:08<00:54,  1.10s/it, loss=1.7250, batch_acc=0.5938, running_acc=0.5469, grad=17.2487]Training epoch 8:  69%|██████▉   | 113/163 [02:08<00:54,  1.10s/it, loss=1.9219, batch_acc=0.5312, running_acc=0.5467, grad=22.6649]Training epoch 8:  70%|██████▉   | 114/163 [02:09<00:50,  1.03s/it, loss=1.9219, batch_acc=0.5312, running_acc=0.5467, grad=22.6649]Training epoch 8:  70%|██████▉   | 114/163 [02:09<00:50,  1.03s/it, loss=1.8969, batch_acc=0.5000, running_acc=0.5463, grad=27.9509]Training epoch 8:  71%|███████   | 115/163 [02:09<00:47,  1.01it/s, loss=1.8969, batch_acc=0.5000, running_acc=0.5463, grad=27.9509]Training epoch 8:  71%|███████   | 115/163 [02:09<00:47,  1.01it/s, loss=1.6643, batch_acc=0.5938, running_acc=0.5467, grad=16.6627]Training epoch 8:  71%|███████   | 116/163 [02:11<00:51,  1.09s/it, loss=1.6643, batch_acc=0.5938, running_acc=0.5467, grad=16.6627]Training epoch 8:  71%|███████   | 116/163 [02:11<00:51,  1.09s/it, loss=1.9148, batch_acc=0.5312, running_acc=0.5466, grad=26.7893]Training epoch 8:  72%|███████▏  | 117/163 [02:12<00:58,  1.27s/it, loss=1.9148, batch_acc=0.5312, running_acc=0.5466, grad=26.7893]Training epoch 8:  72%|███████▏  | 117/163 [02:12<00:58,  1.27s/it, loss=2.0122, batch_acc=0.5000, running_acc=0.5462, grad=15.4726]Training epoch 8:  72%|███████▏  | 118/163 [02:13<00:51,  1.15s/it, loss=2.0122, batch_acc=0.5000, running_acc=0.5462, grad=15.4726]Training epoch 8:  72%|███████▏  | 118/163 [02:13<00:51,  1.15s/it, loss=1.9968, batch_acc=0.4688, running_acc=0.5456, grad=26.8190]Training epoch 8:  73%|███████▎  | 119/163 [02:14<00:47,  1.07s/it, loss=1.9968, batch_acc=0.4688, running_acc=0.5456, grad=26.8190]Training epoch 8:  73%|███████▎  | 119/163 [02:14<00:47,  1.07s/it, loss=2.0332, batch_acc=0.3750, running_acc=0.5441, grad=19.0649]Training epoch 8:  74%|███████▎  | 120/163 [02:15<00:48,  1.12s/it, loss=2.0332, batch_acc=0.3750, running_acc=0.5441, grad=19.0649]Training epoch 8:  74%|███████▎  | 120/163 [02:15<00:48,  1.12s/it, loss=1.5522, batch_acc=0.6562, running_acc=0.5451, grad=16.0433]Training epoch 8:  74%|███████▍  | 121/163 [02:17<00:48,  1.16s/it, loss=1.5522, batch_acc=0.6562, running_acc=0.5451, grad=16.0433]Training epoch 8:  74%|███████▍  | 121/163 [02:17<00:48,  1.16s/it, loss=1.7921, batch_acc=0.6250, running_acc=0.5457, grad=18.9946]Training epoch 8:  75%|███████▍  | 122/163 [02:18<00:44,  1.08s/it, loss=1.7921, batch_acc=0.6250, running_acc=0.5457, grad=18.9946]Training epoch 8:  75%|███████▍  | 122/163 [02:18<00:44,  1.08s/it, loss=1.9707, batch_acc=0.5312, running_acc=0.5456, grad=16.6465]Training epoch 8:  75%|███████▌  | 123/163 [02:18<00:40,  1.02s/it, loss=1.9707, batch_acc=0.5312, running_acc=0.5456, grad=16.6465]Training epoch 8:  75%|███████▌  | 123/163 [02:18<00:40,  1.02s/it, loss=1.7810, batch_acc=0.5312, running_acc=0.5455, grad=18.0695]Training epoch 8:  76%|███████▌  | 124/163 [02:20<00:44,  1.14s/it, loss=1.7810, batch_acc=0.5312, running_acc=0.5455, grad=18.0695]Training epoch 8:  76%|███████▌  | 124/163 [02:20<00:44,  1.14s/it, loss=2.0260, batch_acc=0.3750, running_acc=0.5441, grad=18.4266]Training epoch 8:  77%|███████▋  | 125/163 [02:21<00:45,  1.19s/it, loss=2.0260, batch_acc=0.3750, running_acc=0.5441, grad=18.4266]Training epoch 8:  77%|███████▋  | 125/163 [02:21<00:45,  1.19s/it, loss=1.7743, batch_acc=0.6250, running_acc=0.5447, grad=23.6112]Training epoch 8:  77%|███████▋  | 126/163 [02:22<00:40,  1.10s/it, loss=1.7743, batch_acc=0.6250, running_acc=0.5447, grad=23.6112]Training epoch 8:  77%|███████▋  | 126/163 [02:22<00:40,  1.10s/it, loss=1.5200, batch_acc=0.6562, running_acc=0.5456, grad=21.5751]Training epoch 8:  78%|███████▊  | 127/163 [02:23<00:37,  1.03s/it, loss=1.5200, batch_acc=0.6562, running_acc=0.5456, grad=21.5751]Training epoch 8:  78%|███████▊  | 127/163 [02:23<00:37,  1.03s/it, loss=1.9138, batch_acc=0.5625, running_acc=0.5458, grad=19.9982]Training epoch 8:  79%|███████▊  | 128/163 [02:24<00:40,  1.15s/it, loss=1.9138, batch_acc=0.5625, running_acc=0.5458, grad=19.9982]Training epoch 8:  79%|███████▊  | 128/163 [02:24<00:40,  1.15s/it, loss=1.8452, batch_acc=0.5000, running_acc=0.5454, grad=17.0299]Training epoch 8:  79%|███████▉  | 129/163 [02:26<00:38,  1.14s/it, loss=1.8452, batch_acc=0.5000, running_acc=0.5454, grad=17.0299]Training epoch 8:  79%|███████▉  | 129/163 [02:26<00:38,  1.14s/it, loss=1.8604, batch_acc=0.4688, running_acc=0.5448, grad=18.1154]Training epoch 8:  80%|███████▉  | 130/163 [02:26<00:35,  1.06s/it, loss=1.8604, batch_acc=0.4688, running_acc=0.5448, grad=18.1154]Training epoch 8:  80%|███████▉  | 130/163 [02:26<00:35,  1.06s/it, loss=1.8904, batch_acc=0.6562, running_acc=0.5457, grad=20.6784]Training epoch 8:  80%|████████  | 131/163 [02:27<00:32,  1.01s/it, loss=1.8904, batch_acc=0.6562, running_acc=0.5457, grad=20.6784]Training epoch 8:  80%|████████  | 131/163 [02:27<00:32,  1.01s/it, loss=1.7175, batch_acc=0.6562, running_acc=0.5465, grad=19.7421]Training epoch 8:  81%|████████  | 132/163 [02:29<00:37,  1.20s/it, loss=1.7175, batch_acc=0.6562, running_acc=0.5465, grad=19.7421]Training epoch 8:  81%|████████  | 132/163 [02:29<00:37,  1.20s/it, loss=2.0607, batch_acc=0.4375, running_acc=0.5457, grad=19.3786]Training epoch 8:  82%|████████▏ | 133/163 [02:30<00:33,  1.10s/it, loss=2.0607, batch_acc=0.4375, running_acc=0.5457, grad=19.3786]Training epoch 8:  82%|████████▏ | 133/163 [02:30<00:33,  1.10s/it, loss=1.8375, batch_acc=0.6250, running_acc=0.5463, grad=17.9985]Training epoch 8:  82%|████████▏ | 134/163 [02:31<00:30,  1.04s/it, loss=1.8375, batch_acc=0.6250, running_acc=0.5463, grad=17.9985]Training epoch 8:  82%|████████▏ | 134/163 [02:31<00:30,  1.04s/it, loss=1.7972, batch_acc=0.5000, running_acc=0.5459, grad=19.7989]Training epoch 8:  83%|████████▎ | 135/163 [02:32<00:27,  1.01it/s, loss=1.7972, batch_acc=0.5000, running_acc=0.5459, grad=19.7989]Training epoch 8:  83%|████████▎ | 135/163 [02:32<00:27,  1.01it/s, loss=1.9848, batch_acc=0.5938, running_acc=0.5463, grad=19.4868]Training epoch 8:  83%|████████▎ | 136/163 [02:33<00:29,  1.11s/it, loss=1.9848, batch_acc=0.5938, running_acc=0.5463, grad=19.4868]Training epoch 8:  83%|████████▎ | 136/163 [02:33<00:29,  1.11s/it, loss=1.4596, batch_acc=0.7500, running_acc=0.5478, grad=15.4117]Training epoch 8:  84%|████████▍ | 137/163 [02:34<00:30,  1.17s/it, loss=1.4596, batch_acc=0.7500, running_acc=0.5478, grad=15.4117]Training epoch 8:  84%|████████▍ | 137/163 [02:34<00:30,  1.17s/it, loss=2.0776, batch_acc=0.5000, running_acc=0.5474, grad=19.3006]Training epoch 8:  85%|████████▍ | 138/163 [02:35<00:27,  1.08s/it, loss=2.0776, batch_acc=0.5000, running_acc=0.5474, grad=19.3006]Training epoch 8:  85%|████████▍ | 138/163 [02:35<00:27,  1.08s/it, loss=1.8022, batch_acc=0.5312, running_acc=0.5473, grad=20.8758]Training epoch 8:  85%|████████▌ | 139/163 [02:36<00:24,  1.02s/it, loss=1.8022, batch_acc=0.5312, running_acc=0.5473, grad=20.8758]Training epoch 8:  85%|████████▌ | 139/163 [02:36<00:24,  1.02s/it, loss=1.7037, batch_acc=0.5625, running_acc=0.5474, grad=17.2984]Training epoch 8:  86%|████████▌ | 140/163 [02:37<00:25,  1.10s/it, loss=1.7037, batch_acc=0.5625, running_acc=0.5474, grad=17.2984]Training epoch 8:  86%|████████▌ | 140/163 [02:37<00:25,  1.10s/it, loss=1.8758, batch_acc=0.6250, running_acc=0.5480, grad=19.4158]Training epoch 8:  87%|████████▋ | 141/163 [02:38<00:24,  1.10s/it, loss=1.8758, batch_acc=0.6250, running_acc=0.5480, grad=19.4158]Training epoch 8:  87%|████████▋ | 141/163 [02:38<00:24,  1.10s/it, loss=1.9568, batch_acc=0.4688, running_acc=0.5474, grad=20.8065]Training epoch 8:  87%|████████▋ | 142/163 [02:39<00:21,  1.03s/it, loss=1.9568, batch_acc=0.4688, running_acc=0.5474, grad=20.8065]Training epoch 8:  87%|████████▋ | 142/163 [02:39<00:21,  1.03s/it, loss=1.7790, batch_acc=0.5312, running_acc=0.5473, grad=21.2262]Training epoch 8:  88%|████████▊ | 143/163 [02:40<00:19,  1.01it/s, loss=1.7790, batch_acc=0.5312, running_acc=0.5473, grad=21.2262]Training epoch 8:  88%|████████▊ | 143/163 [02:40<00:19,  1.01it/s, loss=1.8744, batch_acc=0.5000, running_acc=0.5470, grad=16.7578]Training epoch 8:  88%|████████▊ | 144/163 [02:42<00:20,  1.09s/it, loss=1.8744, batch_acc=0.5000, running_acc=0.5470, grad=16.7578]Training epoch 8:  88%|████████▊ | 144/163 [02:42<00:20,  1.09s/it, loss=2.1362, batch_acc=0.5000, running_acc=0.5467, grad=18.8098]Training epoch 8:  89%|████████▉ | 145/163 [02:43<00:20,  1.12s/it, loss=2.1362, batch_acc=0.5000, running_acc=0.5467, grad=18.8098]Training epoch 8:  89%|████████▉ | 145/163 [02:43<00:20,  1.12s/it, loss=1.8818, batch_acc=0.5000, running_acc=0.5463, grad=18.3770]Training epoch 8:  90%|████████▉ | 146/163 [02:44<00:17,  1.04s/it, loss=1.8818, batch_acc=0.5000, running_acc=0.5463, grad=18.3770]Training epoch 8:  90%|████████▉ | 146/163 [02:44<00:17,  1.04s/it, loss=2.1281, batch_acc=0.4688, running_acc=0.5458, grad=16.7301]Training epoch 8:  90%|█████████ | 147/163 [02:44<00:15,  1.00it/s, loss=2.1281, batch_acc=0.4688, running_acc=0.5458, grad=16.7301]Training epoch 8:  90%|█████████ | 147/163 [02:44<00:15,  1.00it/s, loss=1.7846, batch_acc=0.6250, running_acc=0.5463, grad=17.5327]Training epoch 8:  91%|█████████ | 148/163 [02:46<00:17,  1.16s/it, loss=1.7846, batch_acc=0.6250, running_acc=0.5463, grad=17.5327]Training epoch 8:  91%|█████████ | 148/163 [02:46<00:17,  1.16s/it, loss=1.3736, batch_acc=0.6875, running_acc=0.5473, grad=14.1867]Training epoch 8:  91%|█████████▏| 149/163 [02:48<00:18,  1.32s/it, loss=1.3736, batch_acc=0.6875, running_acc=0.5473, grad=14.1867]Training epoch 8:  91%|█████████▏| 149/163 [02:48<00:18,  1.32s/it, loss=1.9099, batch_acc=0.5938, running_acc=0.5476, grad=20.3773]Training epoch 8:  92%|█████████▏| 150/163 [02:49<00:15,  1.19s/it, loss=1.9099, batch_acc=0.5938, running_acc=0.5476, grad=20.3773]Training epoch 8:  92%|█████████▏| 150/163 [02:49<00:15,  1.19s/it, loss=1.7956, batch_acc=0.5938, running_acc=0.5479, grad=18.1442]Training epoch 8:  93%|█████████▎| 151/163 [02:49<00:13,  1.09s/it, loss=1.7956, batch_acc=0.5938, running_acc=0.5479, grad=18.1442]Training epoch 8:  93%|█████████▎| 151/163 [02:49<00:13,  1.09s/it, loss=1.6411, batch_acc=0.6250, running_acc=0.5484, grad=17.2935]Training epoch 8:  93%|█████████▎| 152/163 [02:51<00:12,  1.15s/it, loss=1.6411, batch_acc=0.6250, running_acc=0.5484, grad=17.2935]Training epoch 8:  93%|█████████▎| 152/163 [02:51<00:12,  1.15s/it, loss=2.1700, batch_acc=0.4688, running_acc=0.5479, grad=23.1195]Training epoch 8:  94%|█████████▍| 153/163 [02:52<00:12,  1.26s/it, loss=2.1700, batch_acc=0.4688, running_acc=0.5479, grad=23.1195]Training epoch 8:  94%|█████████▍| 153/163 [02:52<00:12,  1.26s/it, loss=2.2336, batch_acc=0.4688, running_acc=0.5474, grad=19.2084]Training epoch 8:  94%|█████████▍| 154/163 [02:53<00:10,  1.14s/it, loss=2.2336, batch_acc=0.4688, running_acc=0.5474, grad=19.2084]Training epoch 8:  94%|█████████▍| 154/163 [02:53<00:10,  1.14s/it, loss=1.8236, batch_acc=0.5000, running_acc=0.5471, grad=18.8666]Training epoch 8:  95%|█████████▌| 155/163 [02:54<00:08,  1.06s/it, loss=1.8236, batch_acc=0.5000, running_acc=0.5471, grad=18.8666]Training epoch 8:  95%|█████████▌| 155/163 [02:54<00:08,  1.06s/it, loss=2.0505, batch_acc=0.3750, running_acc=0.5460, grad=25.7488]Training epoch 8:  96%|█████████▌| 156/163 [02:55<00:07,  1.08s/it, loss=2.0505, batch_acc=0.3750, running_acc=0.5460, grad=25.7488]Training epoch 8:  96%|█████████▌| 156/163 [02:55<00:07,  1.08s/it, loss=1.8597, batch_acc=0.5000, running_acc=0.5457, grad=20.7472]Training epoch 8:  96%|█████████▋| 157/163 [02:57<00:07,  1.27s/it, loss=1.8597, batch_acc=0.5000, running_acc=0.5457, grad=20.7472]Training epoch 8:  96%|█████████▋| 157/163 [02:57<00:07,  1.27s/it, loss=1.7349, batch_acc=0.5625, running_acc=0.5458, grad=15.3935]Training epoch 8:  97%|█████████▋| 158/163 [02:58<00:05,  1.15s/it, loss=1.7349, batch_acc=0.5625, running_acc=0.5458, grad=15.3935]Training epoch 8:  97%|█████████▋| 158/163 [02:58<00:05,  1.15s/it, loss=1.3811, batch_acc=0.8438, running_acc=0.5477, grad=11.7330]Training epoch 8:  98%|█████████▊| 159/163 [02:59<00:04,  1.07s/it, loss=1.3811, batch_acc=0.8438, running_acc=0.5477, grad=11.7330]Training epoch 8:  98%|█████████▊| 159/163 [02:59<00:04,  1.07s/it, loss=1.6699, batch_acc=0.5312, running_acc=0.5476, grad=18.8822]Training epoch 8:  98%|█████████▊| 160/163 [02:59<00:03,  1.02s/it, loss=1.6699, batch_acc=0.5312, running_acc=0.5476, grad=18.8822]Training epoch 8:  98%|█████████▊| 160/163 [02:59<00:03,  1.02s/it, loss=1.7074, batch_acc=0.5938, running_acc=0.5479, grad=15.7729]Training epoch 8:  99%|█████████▉| 161/163 [03:01<00:02,  1.26s/it, loss=1.7074, batch_acc=0.5938, running_acc=0.5479, grad=15.7729]Training epoch 8:  99%|█████████▉| 161/163 [03:01<00:02,  1.26s/it, loss=1.9615, batch_acc=0.5000, running_acc=0.5476, grad=17.5740]Training epoch 8:  99%|█████████▉| 162/163 [03:02<00:01,  1.14s/it, loss=1.9615, batch_acc=0.5000, running_acc=0.5476, grad=17.5740]Training epoch 8:  99%|█████████▉| 162/163 [03:02<00:01,  1.14s/it, loss=1.8263, batch_acc=0.5312, running_acc=0.5475, grad=15.0606]Training epoch 8: 100%|██████████| 163/163 [03:03<00:00,  1.01it/s, loss=1.8263, batch_acc=0.5312, running_acc=0.5475, grad=15.0606]Training epoch 8: 100%|██████████| 163/163 [03:03<00:00,  1.01it/s, loss=1.7566, batch_acc=0.6667, running_acc=0.5479, grad=20.8954]Training epoch 8: 100%|██████████| 163/163 [03:03<00:00,  1.12s/it, loss=1.7566, batch_acc=0.6667, running_acc=0.5479, grad=20.8954]
Evaluation epoch 8:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 8:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it]Evaluation epoch 8:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it, loss=1.3920, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 8:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=1.3920, batch_acc=0.6562, running_acc=0.6562]Evaluation epoch 8:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=1.5764, batch_acc=0.6250, running_acc=0.6406]Evaluation epoch 8:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=1.5764, batch_acc=0.6250, running_acc=0.6406]Evaluation epoch 8:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=1.5487, batch_acc=0.6562, running_acc=0.6458]Evaluation epoch 8:  14%|█▍        | 4/28 [00:09<00:59,  2.50s/it, loss=1.5487, batch_acc=0.6562, running_acc=0.6458]Evaluation epoch 8:  14%|█▍        | 4/28 [00:09<00:59,  2.50s/it, loss=2.3659, batch_acc=0.2500, running_acc=0.5469]Evaluation epoch 8:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=2.3659, batch_acc=0.2500, running_acc=0.5469]Evaluation epoch 8:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=2.1387, batch_acc=0.3750, running_acc=0.5125]Evaluation epoch 8:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=2.1387, batch_acc=0.3750, running_acc=0.5125]Evaluation epoch 8:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=2.4448, batch_acc=0.3438, running_acc=0.4844]Evaluation epoch 8:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=2.4448, batch_acc=0.3438, running_acc=0.4844]Evaluation epoch 8:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=2.3727, batch_acc=0.3438, running_acc=0.4643]Evaluation epoch 8:  29%|██▊       | 8/28 [00:14<00:34,  1.74s/it, loss=2.3727, batch_acc=0.3438, running_acc=0.4643]Evaluation epoch 8:  29%|██▊       | 8/28 [00:14<00:34,  1.74s/it, loss=1.8636, batch_acc=0.5000, running_acc=0.4688]Evaluation epoch 8:  32%|███▏      | 9/28 [00:14<00:24,  1.31s/it, loss=1.8636, batch_acc=0.5000, running_acc=0.4688]Evaluation epoch 8:  32%|███▏      | 9/28 [00:14<00:24,  1.31s/it, loss=2.0764, batch_acc=0.4688, running_acc=0.4688]Evaluation epoch 8:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=2.0764, batch_acc=0.4688, running_acc=0.4688]Evaluation epoch 8:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=1.0388, batch_acc=0.8438, running_acc=0.5062]Evaluation epoch 8:  39%|███▉      | 11/28 [00:15<00:13,  1.31it/s, loss=1.0388, batch_acc=0.8438, running_acc=0.5062]Evaluation epoch 8:  39%|███▉      | 11/28 [00:15<00:13,  1.31it/s, loss=2.2347, batch_acc=0.4688, running_acc=0.5028]Evaluation epoch 8:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=2.2347, batch_acc=0.4688, running_acc=0.5028]Evaluation epoch 8:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=1.8120, batch_acc=0.5938, running_acc=0.5104]Evaluation epoch 8:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=1.8120, batch_acc=0.5938, running_acc=0.5104]Evaluation epoch 8:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=1.4654, batch_acc=0.6875, running_acc=0.5240]Evaluation epoch 8:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=1.4654, batch_acc=0.6875, running_acc=0.5240]Evaluation epoch 8:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=2.3024, batch_acc=0.5000, running_acc=0.5223]Evaluation epoch 8:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.3024, batch_acc=0.5000, running_acc=0.5223]Evaluation epoch 8:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=2.7613, batch_acc=0.2812, running_acc=0.5062]Evaluation epoch 8:  57%|█████▋    | 16/28 [00:24<00:17,  1.47s/it, loss=2.7613, batch_acc=0.2812, running_acc=0.5062]Evaluation epoch 8:  57%|█████▋    | 16/28 [00:24<00:17,  1.47s/it, loss=2.1873, batch_acc=0.2500, running_acc=0.4902]Evaluation epoch 8:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=2.1873, batch_acc=0.2500, running_acc=0.4902]Evaluation epoch 8:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=1.9928, batch_acc=0.3438, running_acc=0.4816]Evaluation epoch 8:  64%|██████▍   | 18/28 [00:24<00:08,  1.17it/s, loss=1.9928, batch_acc=0.3438, running_acc=0.4816]Evaluation epoch 8:  64%|██████▍   | 18/28 [00:24<00:08,  1.17it/s, loss=1.4169, batch_acc=0.7188, running_acc=0.4948]Evaluation epoch 8:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=1.4169, batch_acc=0.7188, running_acc=0.4948]Evaluation epoch 8:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=2.1681, batch_acc=0.3125, running_acc=0.4852]Evaluation epoch 8:  71%|███████▏  | 20/28 [00:27<00:10,  1.31s/it, loss=2.1681, batch_acc=0.3125, running_acc=0.4852]Evaluation epoch 8:  71%|███████▏  | 20/28 [00:27<00:10,  1.31s/it, loss=2.0276, batch_acc=0.5938, running_acc=0.4906]Evaluation epoch 8:  75%|███████▌  | 21/28 [00:28<00:06,  1.00it/s, loss=2.0276, batch_acc=0.5938, running_acc=0.4906]Evaluation epoch 8:  75%|███████▌  | 21/28 [00:28<00:06,  1.00it/s, loss=2.0542, batch_acc=0.4375, running_acc=0.4881]Evaluation epoch 8:  79%|███████▊  | 22/28 [00:28<00:04,  1.29it/s, loss=2.0542, batch_acc=0.4375, running_acc=0.4881]Evaluation epoch 8:  79%|███████▊  | 22/28 [00:28<00:04,  1.29it/s, loss=2.3625, batch_acc=0.3750, running_acc=0.4830]Evaluation epoch 8:  82%|████████▏ | 23/28 [00:28<00:03,  1.60it/s, loss=2.3625, batch_acc=0.3750, running_acc=0.4830]Evaluation epoch 8:  82%|████████▏ | 23/28 [00:28<00:03,  1.60it/s, loss=2.1325, batch_acc=0.4062, running_acc=0.4796]Evaluation epoch 8:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=2.1325, batch_acc=0.4062, running_acc=0.4796]Evaluation epoch 8:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=1.5063, batch_acc=0.5000, running_acc=0.4805]Evaluation epoch 8:  89%|████████▉ | 25/28 [00:34<00:04,  1.48s/it, loss=1.5063, batch_acc=0.5000, running_acc=0.4805]Evaluation epoch 8:  89%|████████▉ | 25/28 [00:34<00:04,  1.48s/it, loss=1.3673, batch_acc=0.6250, running_acc=0.4863]Evaluation epoch 8:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=1.3673, batch_acc=0.6250, running_acc=0.4863]Evaluation epoch 8:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=1.5675, batch_acc=0.5625, running_acc=0.4892]Evaluation epoch 8:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=1.5675, batch_acc=0.5625, running_acc=0.4892]Evaluation epoch 8:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=1.8468, batch_acc=0.4688, running_acc=0.4884]Evaluation epoch 8: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=1.0125, batch_acc=1.0000, running_acc=0.4902]Evaluation epoch 8: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.0125, batch_acc=1.0000, running_acc=0.4902]
Training epoch 9:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 9:   1%|          | 1/163 [00:05<15:40,  5.80s/it]Training epoch 9:   1%|          | 1/163 [00:05<15:40,  5.80s/it, loss=1.7438, batch_acc=0.5000, running_acc=0.5000, grad=19.7743]Training epoch 9:   1%|          | 2/163 [00:06<07:50,  2.92s/it, loss=1.7438, batch_acc=0.5000, running_acc=0.5000, grad=19.7743]Training epoch 9:   1%|          | 2/163 [00:06<07:50,  2.92s/it, loss=1.8402, batch_acc=0.5000, running_acc=0.5000, grad=18.1603]Training epoch 9:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=1.8402, batch_acc=0.5000, running_acc=0.5000, grad=18.1603]Training epoch 9:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=1.3048, batch_acc=0.8125, running_acc=0.6042, grad=17.3254]Training epoch 9:   2%|▏         | 4/163 [00:09<05:40,  2.14s/it, loss=1.3048, batch_acc=0.8125, running_acc=0.6042, grad=17.3254]Training epoch 9:   2%|▏         | 4/163 [00:09<05:40,  2.14s/it, loss=1.9166, batch_acc=0.5625, running_acc=0.5938, grad=16.3574]Training epoch 9:   3%|▎         | 5/163 [00:10<04:26,  1.69s/it, loss=1.9166, batch_acc=0.5625, running_acc=0.5938, grad=16.3574]Training epoch 9:   3%|▎         | 5/163 [00:10<04:26,  1.69s/it, loss=1.8135, batch_acc=0.6250, running_acc=0.6000, grad=16.3816]Training epoch 9:   4%|▎         | 6/163 [00:11<03:41,  1.41s/it, loss=1.8135, batch_acc=0.6250, running_acc=0.6000, grad=16.3816]Training epoch 9:   4%|▎         | 6/163 [00:11<03:41,  1.41s/it, loss=2.0866, batch_acc=0.5625, running_acc=0.5938, grad=20.3554]Training epoch 9:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=2.0866, batch_acc=0.5625, running_acc=0.5938, grad=20.3554]Training epoch 9:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=1.8986, batch_acc=0.5000, running_acc=0.5804, grad=18.0300]Training epoch 9:   5%|▍         | 8/163 [00:14<03:27,  1.34s/it, loss=1.8986, batch_acc=0.5000, running_acc=0.5804, grad=18.0300]Training epoch 9:   5%|▍         | 8/163 [00:14<03:27,  1.34s/it, loss=1.7453, batch_acc=0.7500, running_acc=0.6016, grad=23.7287]Training epoch 9:   6%|▌         | 9/163 [00:15<03:03,  1.19s/it, loss=1.7453, batch_acc=0.7500, running_acc=0.6016, grad=23.7287]Training epoch 9:   6%|▌         | 9/163 [00:15<03:03,  1.19s/it, loss=1.8368, batch_acc=0.6250, running_acc=0.6042, grad=17.4273]Training epoch 9:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=1.8368, batch_acc=0.6250, running_acc=0.6042, grad=17.4273]Training epoch 9:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=1.4850, batch_acc=0.5625, running_acc=0.6000, grad=17.5582]Training epoch 9:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=1.4850, batch_acc=0.5625, running_acc=0.6000, grad=17.5582]Training epoch 9:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=2.2376, batch_acc=0.4688, running_acc=0.5881, grad=15.1910]Training epoch 9:   7%|▋         | 12/163 [00:18<03:19,  1.32s/it, loss=2.2376, batch_acc=0.4688, running_acc=0.5881, grad=15.1910]Training epoch 9:   7%|▋         | 12/163 [00:18<03:19,  1.32s/it, loss=1.8298, batch_acc=0.6562, running_acc=0.5938, grad=18.6365]Training epoch 9:   8%|▊         | 13/163 [00:19<02:57,  1.19s/it, loss=1.8298, batch_acc=0.6562, running_acc=0.5938, grad=18.6365]Training epoch 9:   8%|▊         | 13/163 [00:19<02:57,  1.19s/it, loss=1.3063, batch_acc=0.7500, running_acc=0.6058, grad=15.9333]Training epoch 9:   9%|▊         | 14/163 [00:20<02:43,  1.09s/it, loss=1.3063, batch_acc=0.7500, running_acc=0.6058, grad=15.9333]Training epoch 9:   9%|▊         | 14/163 [00:20<02:43,  1.09s/it, loss=1.6778, batch_acc=0.5938, running_acc=0.6049, grad=15.4350]Training epoch 9:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=1.6778, batch_acc=0.5938, running_acc=0.6049, grad=15.4350]Training epoch 9:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=1.6383, batch_acc=0.5625, running_acc=0.6021, grad=21.1109]Training epoch 9:  10%|▉         | 16/163 [00:22<02:50,  1.16s/it, loss=1.6383, batch_acc=0.5625, running_acc=0.6021, grad=21.1109]Training epoch 9:  10%|▉         | 16/163 [00:22<02:50,  1.16s/it, loss=1.6662, batch_acc=0.5625, running_acc=0.5996, grad=17.2685]Training epoch 9:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=1.6662, batch_acc=0.5625, running_acc=0.5996, grad=17.2685]Training epoch 9:  10%|█         | 17/163 [00:23<02:37,  1.08s/it, loss=1.7147, batch_acc=0.5312, running_acc=0.5956, grad=14.8463]Training epoch 9:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=1.7147, batch_acc=0.5312, running_acc=0.5956, grad=14.8463]Training epoch 9:  11%|█         | 18/163 [00:24<02:27,  1.02s/it, loss=1.8814, batch_acc=0.5312, running_acc=0.5920, grad=18.4745]Training epoch 9:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=1.8814, batch_acc=0.5312, running_acc=0.5920, grad=18.4745]Training epoch 9:  12%|█▏        | 19/163 [00:25<02:20,  1.02it/s, loss=1.4953, batch_acc=0.6562, running_acc=0.5954, grad=24.4784]Training epoch 9:  12%|█▏        | 20/163 [00:27<02:55,  1.23s/it, loss=1.4953, batch_acc=0.6562, running_acc=0.5954, grad=24.4784]Training epoch 9:  12%|█▏        | 20/163 [00:27<02:55,  1.23s/it, loss=1.6824, batch_acc=0.6562, running_acc=0.5984, grad=18.0494]Training epoch 9:  13%|█▎        | 21/163 [00:28<02:39,  1.12s/it, loss=1.6824, batch_acc=0.6562, running_acc=0.5984, grad=18.0494]Training epoch 9:  13%|█▎        | 21/163 [00:28<02:39,  1.12s/it, loss=1.9055, batch_acc=0.5625, running_acc=0.5967, grad=18.5655]Training epoch 9:  13%|█▎        | 22/163 [00:29<02:28,  1.05s/it, loss=1.9055, batch_acc=0.5625, running_acc=0.5967, grad=18.5655]Training epoch 9:  13%|█▎        | 22/163 [00:29<02:28,  1.05s/it, loss=1.7683, batch_acc=0.6250, running_acc=0.5980, grad=18.3597]Training epoch 9:  14%|█▍        | 23/163 [00:29<02:20,  1.00s/it, loss=1.7683, batch_acc=0.6250, running_acc=0.5980, grad=18.3597]Training epoch 9:  14%|█▍        | 23/163 [00:29<02:20,  1.00s/it, loss=1.9890, batch_acc=0.5312, running_acc=0.5951, grad=19.1590]Training epoch 9:  15%|█▍        | 24/163 [00:31<02:55,  1.26s/it, loss=1.9890, batch_acc=0.5312, running_acc=0.5951, grad=19.1590]Training epoch 9:  15%|█▍        | 24/163 [00:31<02:55,  1.26s/it, loss=1.8225, batch_acc=0.5938, running_acc=0.5951, grad=18.7995]Training epoch 9:  15%|█▌        | 25/163 [00:32<02:38,  1.15s/it, loss=1.8225, batch_acc=0.5938, running_acc=0.5951, grad=18.7995]Training epoch 9:  15%|█▌        | 25/163 [00:32<02:38,  1.15s/it, loss=1.8114, batch_acc=0.5625, running_acc=0.5938, grad=23.9842]Training epoch 9:  16%|█▌        | 26/163 [00:33<02:30,  1.10s/it, loss=1.8114, batch_acc=0.5625, running_acc=0.5938, grad=23.9842]Training epoch 9:  16%|█▌        | 26/163 [00:33<02:30,  1.10s/it, loss=1.5730, batch_acc=0.6562, running_acc=0.5962, grad=14.7502]Training epoch 9:  17%|█▋        | 27/163 [00:34<02:20,  1.03s/it, loss=1.5730, batch_acc=0.6562, running_acc=0.5962, grad=14.7502]Training epoch 9:  17%|█▋        | 27/163 [00:34<02:20,  1.03s/it, loss=2.1453, batch_acc=0.4062, running_acc=0.5891, grad=27.4029]Training epoch 9:  17%|█▋        | 28/163 [00:36<03:01,  1.34s/it, loss=2.1453, batch_acc=0.4062, running_acc=0.5891, grad=27.4029]Training epoch 9:  17%|█▋        | 28/163 [00:36<03:01,  1.34s/it, loss=1.5830, batch_acc=0.6250, running_acc=0.5904, grad=19.2504]Training epoch 9:  18%|█▊        | 29/163 [00:37<02:41,  1.20s/it, loss=1.5830, batch_acc=0.6250, running_acc=0.5904, grad=19.2504]Training epoch 9:  18%|█▊        | 29/163 [00:37<02:41,  1.20s/it, loss=1.5398, batch_acc=0.6875, running_acc=0.5938, grad=14.6852]Training epoch 9:  18%|█▊        | 30/163 [00:38<02:27,  1.11s/it, loss=1.5398, batch_acc=0.6875, running_acc=0.5938, grad=14.6852]Training epoch 9:  18%|█▊        | 30/163 [00:38<02:27,  1.11s/it, loss=1.6768, batch_acc=0.6250, running_acc=0.5948, grad=15.3267]Training epoch 9:  19%|█▉        | 31/163 [00:39<02:17,  1.04s/it, loss=1.6768, batch_acc=0.6250, running_acc=0.5948, grad=15.3267]Training epoch 9:  19%|█▉        | 31/163 [00:39<02:17,  1.04s/it, loss=1.6271, batch_acc=0.7188, running_acc=0.5988, grad=25.2748]Training epoch 9:  20%|█▉        | 32/163 [00:41<02:42,  1.24s/it, loss=1.6271, batch_acc=0.7188, running_acc=0.5988, grad=25.2748]Training epoch 9:  20%|█▉        | 32/163 [00:41<02:42,  1.24s/it, loss=1.6900, batch_acc=0.5000, running_acc=0.5957, grad=16.7994]Training epoch 9:  20%|██        | 33/163 [00:41<02:26,  1.13s/it, loss=1.6900, batch_acc=0.5000, running_acc=0.5957, grad=16.7994]Training epoch 9:  20%|██        | 33/163 [00:41<02:26,  1.13s/it, loss=1.3596, batch_acc=0.6562, running_acc=0.5975, grad=16.5667]Training epoch 9:  21%|██        | 34/163 [00:42<02:24,  1.12s/it, loss=1.3596, batch_acc=0.6562, running_acc=0.5975, grad=16.5667]Training epoch 9:  21%|██        | 34/163 [00:42<02:24,  1.12s/it, loss=1.8848, batch_acc=0.5938, running_acc=0.5974, grad=19.7128]Training epoch 9:  21%|██▏       | 35/163 [00:43<02:13,  1.05s/it, loss=1.8848, batch_acc=0.5938, running_acc=0.5974, grad=19.7128]Training epoch 9:  21%|██▏       | 35/163 [00:43<02:13,  1.05s/it, loss=2.0489, batch_acc=0.4062, running_acc=0.5920, grad=16.7380]Training epoch 9:  22%|██▏       | 36/163 [00:45<02:26,  1.15s/it, loss=2.0489, batch_acc=0.4062, running_acc=0.5920, grad=16.7380]Training epoch 9:  22%|██▏       | 36/163 [00:45<02:26,  1.15s/it, loss=1.4802, batch_acc=0.6250, running_acc=0.5929, grad=17.3691]Training epoch 9:  23%|██▎       | 37/163 [00:46<02:14,  1.07s/it, loss=1.4802, batch_acc=0.6250, running_acc=0.5929, grad=17.3691]Training epoch 9:  23%|██▎       | 37/163 [00:46<02:14,  1.07s/it, loss=1.7983, batch_acc=0.5000, running_acc=0.5904, grad=21.5595]Training epoch 9:  23%|██▎       | 38/163 [00:47<02:09,  1.04s/it, loss=1.7983, batch_acc=0.5000, running_acc=0.5904, grad=21.5595]Training epoch 9:  23%|██▎       | 38/163 [00:47<02:09,  1.04s/it, loss=1.4426, batch_acc=0.6250, running_acc=0.5913, grad=14.2244]Training epoch 9:  24%|██▍       | 39/163 [00:47<02:02,  1.01it/s, loss=1.4426, batch_acc=0.6250, running_acc=0.5913, grad=14.2244]Training epoch 9:  24%|██▍       | 39/163 [00:47<02:02,  1.01it/s, loss=1.7775, batch_acc=0.5312, running_acc=0.5897, grad=21.0205]Training epoch 9:  25%|██▍       | 40/163 [00:49<02:10,  1.06s/it, loss=1.7775, batch_acc=0.5312, running_acc=0.5897, grad=21.0205]Training epoch 9:  25%|██▍       | 40/163 [00:49<02:10,  1.06s/it, loss=1.5636, batch_acc=0.6875, running_acc=0.5922, grad=13.5483]Training epoch 9:  25%|██▌       | 41/163 [00:50<02:02,  1.00s/it, loss=1.5636, batch_acc=0.6875, running_acc=0.5922, grad=13.5483]Training epoch 9:  25%|██▌       | 41/163 [00:50<02:02,  1.00s/it, loss=1.6491, batch_acc=0.6875, running_acc=0.5945, grad=15.9810]Training epoch 9:  26%|██▌       | 42/163 [00:51<02:01,  1.00s/it, loss=1.6491, batch_acc=0.6875, running_acc=0.5945, grad=15.9810]Training epoch 9:  26%|██▌       | 42/163 [00:51<02:01,  1.00s/it, loss=1.7175, batch_acc=0.6250, running_acc=0.5952, grad=16.3375]Training epoch 9:  26%|██▋       | 43/163 [00:51<01:56,  1.03it/s, loss=1.7175, batch_acc=0.6250, running_acc=0.5952, grad=16.3375]Training epoch 9:  26%|██▋       | 43/163 [00:51<01:56,  1.03it/s, loss=1.8929, batch_acc=0.5938, running_acc=0.5952, grad=19.9968]Training epoch 9:  27%|██▋       | 44/163 [00:53<02:18,  1.17s/it, loss=1.8929, batch_acc=0.5938, running_acc=0.5952, grad=19.9968]Training epoch 9:  27%|██▋       | 44/163 [00:53<02:18,  1.17s/it, loss=1.7670, batch_acc=0.6250, running_acc=0.5959, grad=20.9055]Training epoch 9:  28%|██▊       | 45/163 [00:54<02:07,  1.08s/it, loss=1.7670, batch_acc=0.6250, running_acc=0.5959, grad=20.9055]Training epoch 9:  28%|██▊       | 45/163 [00:54<02:07,  1.08s/it, loss=1.9901, batch_acc=0.5000, running_acc=0.5938, grad=19.0860]Training epoch 9:  28%|██▊       | 46/163 [00:55<01:59,  1.02s/it, loss=1.9901, batch_acc=0.5000, running_acc=0.5938, grad=19.0860]Training epoch 9:  28%|██▊       | 46/163 [00:55<01:59,  1.02s/it, loss=1.8353, batch_acc=0.5625, running_acc=0.5931, grad=18.9575]Training epoch 9:  29%|██▉       | 47/163 [00:56<01:53,  1.02it/s, loss=1.8353, batch_acc=0.5625, running_acc=0.5931, grad=18.9575]Training epoch 9:  29%|██▉       | 47/163 [00:56<01:53,  1.02it/s, loss=1.5633, batch_acc=0.7188, running_acc=0.5957, grad=17.3451]Training epoch 9:  29%|██▉       | 48/163 [00:57<02:11,  1.14s/it, loss=1.5633, batch_acc=0.7188, running_acc=0.5957, grad=17.3451]Training epoch 9:  29%|██▉       | 48/163 [00:57<02:11,  1.14s/it, loss=1.4958, batch_acc=0.5938, running_acc=0.5957, grad=22.0616]Training epoch 9:  30%|███       | 49/163 [00:58<02:01,  1.06s/it, loss=1.4958, batch_acc=0.5938, running_acc=0.5957, grad=22.0616]Training epoch 9:  30%|███       | 49/163 [00:58<02:01,  1.06s/it, loss=1.8796, batch_acc=0.5000, running_acc=0.5938, grad=15.1958]Training epoch 9:  31%|███       | 50/163 [00:59<02:00,  1.07s/it, loss=1.8796, batch_acc=0.5000, running_acc=0.5938, grad=15.1958]Training epoch 9:  31%|███       | 50/163 [00:59<02:00,  1.07s/it, loss=1.6727, batch_acc=0.5938, running_acc=0.5938, grad=18.4999]Training epoch 9:  31%|███▏      | 51/163 [01:00<01:53,  1.01s/it, loss=1.6727, batch_acc=0.5938, running_acc=0.5938, grad=18.4999]Training epoch 9:  31%|███▏      | 51/163 [01:00<01:53,  1.01s/it, loss=1.5421, batch_acc=0.6875, running_acc=0.5956, grad=15.2256]Training epoch 9:  32%|███▏      | 52/163 [01:02<02:10,  1.17s/it, loss=1.5421, batch_acc=0.6875, running_acc=0.5956, grad=15.2256]Training epoch 9:  32%|███▏      | 52/163 [01:02<02:10,  1.17s/it, loss=2.3854, batch_acc=0.2812, running_acc=0.5895, grad=37.2843]Training epoch 9:  33%|███▎      | 53/163 [01:03<01:59,  1.09s/it, loss=2.3854, batch_acc=0.2812, running_acc=0.5895, grad=37.2843]Training epoch 9:  33%|███▎      | 53/163 [01:03<01:59,  1.09s/it, loss=1.8788, batch_acc=0.5000, running_acc=0.5879, grad=28.8662]Training epoch 9:  33%|███▎      | 54/163 [01:03<01:53,  1.04s/it, loss=1.8788, batch_acc=0.5000, running_acc=0.5879, grad=28.8662]Training epoch 9:  33%|███▎      | 54/163 [01:03<01:53,  1.04s/it, loss=1.7400, batch_acc=0.5938, running_acc=0.5880, grad=24.1630]Training epoch 9:  34%|███▎      | 55/163 [01:04<01:47,  1.01it/s, loss=1.7400, batch_acc=0.5938, running_acc=0.5880, grad=24.1630]Training epoch 9:  34%|███▎      | 55/163 [01:04<01:47,  1.01it/s, loss=1.6101, batch_acc=0.6562, running_acc=0.5892, grad=19.4272]Training epoch 9:  34%|███▍      | 56/163 [01:06<02:08,  1.20s/it, loss=1.6101, batch_acc=0.6562, running_acc=0.5892, grad=19.4272]Training epoch 9:  34%|███▍      | 56/163 [01:06<02:08,  1.20s/it, loss=1.6681, batch_acc=0.5625, running_acc=0.5887, grad=15.7222]Training epoch 9:  35%|███▍      | 57/163 [01:07<01:57,  1.10s/it, loss=1.6681, batch_acc=0.5625, running_acc=0.5887, grad=15.7222]Training epoch 9:  35%|███▍      | 57/163 [01:07<01:57,  1.10s/it, loss=1.5607, batch_acc=0.6875, running_acc=0.5905, grad=17.9907]Training epoch 9:  36%|███▌      | 58/163 [01:08<01:54,  1.09s/it, loss=1.5607, batch_acc=0.6875, running_acc=0.5905, grad=17.9907]Training epoch 9:  36%|███▌      | 58/163 [01:08<01:54,  1.09s/it, loss=1.8425, batch_acc=0.5312, running_acc=0.5894, grad=18.7247]Training epoch 9:  36%|███▌      | 59/163 [01:09<01:46,  1.03s/it, loss=1.8425, batch_acc=0.5312, running_acc=0.5894, grad=18.7247]Training epoch 9:  36%|███▌      | 59/163 [01:09<01:46,  1.03s/it, loss=1.9796, batch_acc=0.4688, running_acc=0.5874, grad=15.1215]Training epoch 9:  37%|███▋      | 60/163 [01:10<01:52,  1.09s/it, loss=1.9796, batch_acc=0.4688, running_acc=0.5874, grad=15.1215]Training epoch 9:  37%|███▋      | 60/163 [01:10<01:52,  1.09s/it, loss=1.6379, batch_acc=0.5938, running_acc=0.5875, grad=17.8977]Training epoch 9:  37%|███▋      | 61/163 [01:11<01:44,  1.03s/it, loss=1.6379, batch_acc=0.5938, running_acc=0.5875, grad=17.8977]Training epoch 9:  37%|███▋      | 61/163 [01:11<01:44,  1.03s/it, loss=1.6638, batch_acc=0.6250, running_acc=0.5881, grad=23.8720]Training epoch 9:  38%|███▊      | 62/163 [01:13<02:06,  1.26s/it, loss=1.6638, batch_acc=0.6250, running_acc=0.5881, grad=23.8720]Training epoch 9:  38%|███▊      | 62/163 [01:13<02:06,  1.26s/it, loss=1.4897, batch_acc=0.6562, running_acc=0.5892, grad=17.2480]Training epoch 9:  39%|███▊      | 63/163 [01:14<01:54,  1.14s/it, loss=1.4897, batch_acc=0.6562, running_acc=0.5892, grad=17.2480]Training epoch 9:  39%|███▊      | 63/163 [01:14<01:54,  1.14s/it, loss=1.8224, batch_acc=0.6250, running_acc=0.5898, grad=18.8185]Training epoch 9:  39%|███▉      | 64/163 [01:15<01:46,  1.07s/it, loss=1.8224, batch_acc=0.6250, running_acc=0.5898, grad=18.8185]Training epoch 9:  39%|███▉      | 64/163 [01:15<01:46,  1.07s/it, loss=1.7420, batch_acc=0.5625, running_acc=0.5894, grad=17.5843]Training epoch 9:  40%|███▉      | 65/163 [01:15<01:39,  1.01s/it, loss=1.7420, batch_acc=0.5625, running_acc=0.5894, grad=17.5843]Training epoch 9:  40%|███▉      | 65/163 [01:15<01:39,  1.01s/it, loss=1.4979, batch_acc=0.7500, running_acc=0.5918, grad=21.2755]Training epoch 9:  40%|████      | 66/163 [01:17<01:46,  1.10s/it, loss=1.4979, batch_acc=0.7500, running_acc=0.5918, grad=21.2755]Training epoch 9:  40%|████      | 66/163 [01:17<01:46,  1.10s/it, loss=1.8955, batch_acc=0.4688, running_acc=0.5900, grad=22.9870]Training epoch 9:  41%|████      | 67/163 [01:18<01:39,  1.03s/it, loss=1.8955, batch_acc=0.4688, running_acc=0.5900, grad=22.9870]Training epoch 9:  41%|████      | 67/163 [01:18<01:39,  1.03s/it, loss=1.6204, batch_acc=0.7188, running_acc=0.5919, grad=18.1096]Training epoch 9:  42%|████▏     | 68/163 [01:18<01:33,  1.01it/s, loss=1.6204, batch_acc=0.7188, running_acc=0.5919, grad=18.1096]Training epoch 9:  42%|████▏     | 68/163 [01:18<01:33,  1.01it/s, loss=1.4987, batch_acc=0.7812, running_acc=0.5947, grad=16.4033]Training epoch 9:  42%|████▏     | 69/163 [01:19<01:29,  1.05it/s, loss=1.4987, batch_acc=0.7812, running_acc=0.5947, grad=16.4033]Training epoch 9:  42%|████▏     | 69/163 [01:19<01:29,  1.05it/s, loss=1.6965, batch_acc=0.5625, running_acc=0.5942, grad=18.5378]Training epoch 9:  43%|████▎     | 70/163 [01:20<01:28,  1.05it/s, loss=1.6965, batch_acc=0.5625, running_acc=0.5942, grad=18.5378]Training epoch 9:  43%|████▎     | 70/163 [01:20<01:28,  1.05it/s, loss=2.1225, batch_acc=0.4062, running_acc=0.5915, grad=22.7472]Training epoch 9:  44%|████▎     | 71/163 [01:21<01:25,  1.07it/s, loss=2.1225, batch_acc=0.4062, running_acc=0.5915, grad=22.7472]Training epoch 9:  44%|████▎     | 71/163 [01:21<01:25,  1.07it/s, loss=1.7183, batch_acc=0.4375, running_acc=0.5893, grad=19.6255]Training epoch 9:  44%|████▍     | 72/163 [01:23<01:45,  1.15s/it, loss=1.7183, batch_acc=0.4375, running_acc=0.5893, grad=19.6255]Training epoch 9:  44%|████▍     | 72/163 [01:23<01:45,  1.15s/it, loss=1.8678, batch_acc=0.5000, running_acc=0.5881, grad=17.0891]Training epoch 9:  45%|████▍     | 73/163 [01:24<01:36,  1.07s/it, loss=1.8678, batch_acc=0.5000, running_acc=0.5881, grad=17.0891]Training epoch 9:  45%|████▍     | 73/163 [01:24<01:36,  1.07s/it, loss=1.4905, batch_acc=0.7188, running_acc=0.5899, grad=19.4963]Training epoch 9:  45%|████▌     | 74/163 [01:25<01:33,  1.05s/it, loss=1.4905, batch_acc=0.7188, running_acc=0.5899, grad=19.4963]Training epoch 9:  45%|████▌     | 74/163 [01:25<01:33,  1.05s/it, loss=1.5163, batch_acc=0.6875, running_acc=0.5912, grad=16.7334]Training epoch 9:  46%|████▌     | 75/163 [01:26<01:28,  1.00s/it, loss=1.5163, batch_acc=0.6875, running_acc=0.5912, grad=16.7334]Training epoch 9:  46%|████▌     | 75/163 [01:26<01:28,  1.00s/it, loss=1.5506, batch_acc=0.5938, running_acc=0.5913, grad=21.1108]Training epoch 9:  47%|████▋     | 76/163 [01:27<01:25,  1.02it/s, loss=1.5506, batch_acc=0.5938, running_acc=0.5913, grad=21.1108]Training epoch 9:  47%|████▋     | 76/163 [01:27<01:25,  1.02it/s, loss=1.9257, batch_acc=0.4375, running_acc=0.5892, grad=20.7274]Training epoch 9:  47%|████▋     | 77/163 [01:27<01:21,  1.05it/s, loss=1.9257, batch_acc=0.4375, running_acc=0.5892, grad=20.7274]Training epoch 9:  47%|████▋     | 77/163 [01:27<01:21,  1.05it/s, loss=2.0868, batch_acc=0.4062, running_acc=0.5869, grad=18.3017]Training epoch 9:  48%|████▊     | 78/163 [01:29<01:48,  1.28s/it, loss=2.0868, batch_acc=0.4062, running_acc=0.5869, grad=18.3017]Training epoch 9:  48%|████▊     | 78/163 [01:29<01:48,  1.28s/it, loss=1.6286, batch_acc=0.6250, running_acc=0.5873, grad=15.3806]Training epoch 9:  48%|████▊     | 79/163 [01:30<01:37,  1.16s/it, loss=1.6286, batch_acc=0.6250, running_acc=0.5873, grad=15.3806]Training epoch 9:  48%|████▊     | 79/163 [01:30<01:37,  1.16s/it, loss=1.7407, batch_acc=0.5625, running_acc=0.5870, grad=19.6219]Training epoch 9:  49%|████▉     | 80/163 [01:31<01:31,  1.10s/it, loss=1.7407, batch_acc=0.5625, running_acc=0.5870, grad=19.6219]Training epoch 9:  49%|████▉     | 80/163 [01:31<01:31,  1.10s/it, loss=1.7428, batch_acc=0.5938, running_acc=0.5871, grad=16.1280]Training epoch 9:  50%|████▉     | 81/163 [01:32<01:24,  1.03s/it, loss=1.7428, batch_acc=0.5938, running_acc=0.5871, grad=16.1280]Training epoch 9:  50%|████▉     | 81/163 [01:32<01:24,  1.03s/it, loss=1.4151, batch_acc=0.6250, running_acc=0.5876, grad=19.1041]Training epoch 9:  50%|█████     | 82/163 [01:34<01:38,  1.21s/it, loss=1.4151, batch_acc=0.6250, running_acc=0.5876, grad=19.1041]Training epoch 9:  50%|█████     | 82/163 [01:34<01:38,  1.21s/it, loss=1.3334, batch_acc=0.7500, running_acc=0.5896, grad=17.2156]Training epoch 9:  51%|█████     | 83/163 [01:35<01:28,  1.11s/it, loss=1.3334, batch_acc=0.7500, running_acc=0.5896, grad=17.2156]Training epoch 9:  51%|█████     | 83/163 [01:35<01:28,  1.11s/it, loss=1.9048, batch_acc=0.4688, running_acc=0.5881, grad=24.5391]Training epoch 9:  52%|█████▏    | 84/163 [01:36<01:22,  1.04s/it, loss=1.9048, batch_acc=0.4688, running_acc=0.5881, grad=24.5391]Training epoch 9:  52%|█████▏    | 84/163 [01:36<01:22,  1.04s/it, loss=1.7221, batch_acc=0.5938, running_acc=0.5882, grad=23.6713]Training epoch 9:  52%|█████▏    | 85/163 [01:36<01:17,  1.01it/s, loss=1.7221, batch_acc=0.5938, running_acc=0.5882, grad=23.6713]Training epoch 9:  52%|█████▏    | 85/163 [01:36<01:17,  1.01it/s, loss=2.0812, batch_acc=0.5312, running_acc=0.5875, grad=16.5255]Training epoch 9:  53%|█████▎    | 86/163 [01:38<01:30,  1.18s/it, loss=2.0812, batch_acc=0.5312, running_acc=0.5875, grad=16.5255]Training epoch 9:  53%|█████▎    | 86/163 [01:38<01:30,  1.18s/it, loss=1.8537, batch_acc=0.6250, running_acc=0.5879, grad=18.5711]Training epoch 9:  53%|█████▎    | 87/163 [01:39<01:22,  1.09s/it, loss=1.8537, batch_acc=0.6250, running_acc=0.5879, grad=18.5711]Training epoch 9:  53%|█████▎    | 87/163 [01:39<01:22,  1.09s/it, loss=2.0546, batch_acc=0.5625, running_acc=0.5876, grad=26.1318]Training epoch 9:  54%|█████▍    | 88/163 [01:40<01:18,  1.05s/it, loss=2.0546, batch_acc=0.5625, running_acc=0.5876, grad=26.1318]Training epoch 9:  54%|█████▍    | 88/163 [01:40<01:18,  1.05s/it, loss=1.8527, batch_acc=0.5625, running_acc=0.5874, grad=22.5321]Training epoch 9:  55%|█████▍    | 89/163 [01:41<01:13,  1.00it/s, loss=1.8527, batch_acc=0.5625, running_acc=0.5874, grad=22.5321]Training epoch 9:  55%|█████▍    | 89/163 [01:41<01:13,  1.00it/s, loss=1.5137, batch_acc=0.6562, running_acc=0.5881, grad=16.9850]Training epoch 9:  55%|█████▌    | 90/163 [01:42<01:27,  1.19s/it, loss=1.5137, batch_acc=0.6562, running_acc=0.5881, grad=16.9850]Training epoch 9:  55%|█████▌    | 90/163 [01:42<01:27,  1.19s/it, loss=1.6233, batch_acc=0.6562, running_acc=0.5889, grad=19.5128]Training epoch 9:  56%|█████▌    | 91/163 [01:43<01:19,  1.10s/it, loss=1.6233, batch_acc=0.6562, running_acc=0.5889, grad=19.5128]Training epoch 9:  56%|█████▌    | 91/163 [01:43<01:19,  1.10s/it, loss=1.4516, batch_acc=0.5625, running_acc=0.5886, grad=17.2192]Training epoch 9:  56%|█████▋    | 92/163 [01:44<01:13,  1.03s/it, loss=1.4516, batch_acc=0.5625, running_acc=0.5886, grad=17.2192]Training epoch 9:  56%|█████▋    | 92/163 [01:44<01:13,  1.03s/it, loss=1.5720, batch_acc=0.5625, running_acc=0.5883, grad=18.3523]Training epoch 9:  57%|█████▋    | 93/163 [01:45<01:09,  1.01it/s, loss=1.5720, batch_acc=0.5625, running_acc=0.5883, grad=18.3523]Training epoch 9:  57%|█████▋    | 93/163 [01:45<01:09,  1.01it/s, loss=1.8759, batch_acc=0.5938, running_acc=0.5884, grad=16.9993]Training epoch 9:  58%|█████▊    | 94/163 [01:47<01:18,  1.13s/it, loss=1.8759, batch_acc=0.5938, running_acc=0.5884, grad=16.9993]Training epoch 9:  58%|█████▊    | 94/163 [01:47<01:18,  1.13s/it, loss=1.9658, batch_acc=0.4375, running_acc=0.5868, grad=19.7291]Training epoch 9:  58%|█████▊    | 95/163 [01:47<01:11,  1.06s/it, loss=1.9658, batch_acc=0.4375, running_acc=0.5868, grad=19.7291]Training epoch 9:  58%|█████▊    | 95/163 [01:47<01:11,  1.06s/it, loss=1.3851, batch_acc=0.6250, running_acc=0.5872, grad=17.1792]Training epoch 9:  59%|█████▉    | 96/163 [01:48<01:07,  1.01s/it, loss=1.3851, batch_acc=0.6250, running_acc=0.5872, grad=17.1792]Training epoch 9:  59%|█████▉    | 96/163 [01:48<01:07,  1.01s/it, loss=1.7404, batch_acc=0.5000, running_acc=0.5863, grad=27.4896]Training epoch 9:  60%|█████▉    | 97/163 [01:49<01:03,  1.03it/s, loss=1.7404, batch_acc=0.5000, running_acc=0.5863, grad=27.4896]Training epoch 9:  60%|█████▉    | 97/163 [01:49<01:03,  1.03it/s, loss=1.7688, batch_acc=0.5000, running_acc=0.5854, grad=21.7376]Training epoch 9:  60%|██████    | 98/163 [01:50<01:05,  1.01s/it, loss=1.7688, batch_acc=0.5000, running_acc=0.5854, grad=21.7376]Training epoch 9:  60%|██████    | 98/163 [01:50<01:05,  1.01s/it, loss=1.8397, batch_acc=0.5312, running_acc=0.5848, grad=22.7920]Training epoch 9:  61%|██████    | 99/163 [01:51<01:02,  1.03it/s, loss=1.8397, batch_acc=0.5312, running_acc=0.5848, grad=22.7920]Training epoch 9:  61%|██████    | 99/163 [01:51<01:02,  1.03it/s, loss=1.4603, batch_acc=0.6875, running_acc=0.5859, grad=16.9563]Training epoch 9:  61%|██████▏   | 100/163 [01:52<00:59,  1.06it/s, loss=1.4603, batch_acc=0.6875, running_acc=0.5859, grad=16.9563]Training epoch 9:  61%|██████▏   | 100/163 [01:52<00:59,  1.06it/s, loss=1.7189, batch_acc=0.5312, running_acc=0.5853, grad=18.0306]Training epoch 9:  62%|██████▏   | 101/163 [01:53<00:57,  1.08it/s, loss=1.7189, batch_acc=0.5312, running_acc=0.5853, grad=18.0306]Training epoch 9:  62%|██████▏   | 101/163 [01:53<00:57,  1.08it/s, loss=1.5215, batch_acc=0.5938, running_acc=0.5854, grad=16.2303]Training epoch 9:  63%|██████▎   | 102/163 [01:55<01:12,  1.19s/it, loss=1.5215, batch_acc=0.5938, running_acc=0.5854, grad=16.2303]Training epoch 9:  63%|██████▎   | 102/163 [01:55<01:12,  1.19s/it, loss=1.8344, batch_acc=0.3750, running_acc=0.5833, grad=23.4443]Training epoch 9:  63%|██████▎   | 103/163 [01:56<01:05,  1.10s/it, loss=1.8344, batch_acc=0.3750, running_acc=0.5833, grad=23.4443]Training epoch 9:  63%|██████▎   | 103/163 [01:56<01:05,  1.10s/it, loss=1.7550, batch_acc=0.5938, running_acc=0.5834, grad=20.1209]Training epoch 9:  64%|██████▍   | 104/163 [01:57<01:00,  1.03s/it, loss=1.7550, batch_acc=0.5938, running_acc=0.5834, grad=20.1209]Training epoch 9:  64%|██████▍   | 104/163 [01:57<01:00,  1.03s/it, loss=1.7018, batch_acc=0.5625, running_acc=0.5832, grad=24.4860]Training epoch 9:  64%|██████▍   | 105/163 [01:57<00:57,  1.01it/s, loss=1.7018, batch_acc=0.5625, running_acc=0.5832, grad=24.4860]Training epoch 9:  64%|██████▍   | 105/163 [01:57<00:57,  1.01it/s, loss=1.8889, batch_acc=0.5625, running_acc=0.5830, grad=24.1557]Training epoch 9:  65%|██████▌   | 106/163 [01:59<01:04,  1.12s/it, loss=1.8889, batch_acc=0.5625, running_acc=0.5830, grad=24.1557]Training epoch 9:  65%|██████▌   | 106/163 [01:59<01:04,  1.12s/it, loss=1.3609, batch_acc=0.6875, running_acc=0.5840, grad=18.5663]Training epoch 9:  66%|██████▌   | 107/163 [02:00<00:58,  1.05s/it, loss=1.3609, batch_acc=0.6875, running_acc=0.5840, grad=18.5663]Training epoch 9:  66%|██████▌   | 107/163 [02:00<00:58,  1.05s/it, loss=1.5981, batch_acc=0.6562, running_acc=0.5847, grad=21.5505]Training epoch 9:  66%|██████▋   | 108/163 [02:01<00:54,  1.00it/s, loss=1.5981, batch_acc=0.6562, running_acc=0.5847, grad=21.5505]Training epoch 9:  66%|██████▋   | 108/163 [02:01<00:54,  1.00it/s, loss=1.7865, batch_acc=0.5312, running_acc=0.5842, grad=18.0716]Training epoch 9:  67%|██████▋   | 109/163 [02:01<00:52,  1.04it/s, loss=1.7865, batch_acc=0.5312, running_acc=0.5842, grad=18.0716]Training epoch 9:  67%|██████▋   | 109/163 [02:01<00:52,  1.04it/s, loss=1.6775, batch_acc=0.5938, running_acc=0.5843, grad=20.6267]Training epoch 9:  67%|██████▋   | 110/163 [02:03<01:00,  1.15s/it, loss=1.6775, batch_acc=0.5938, running_acc=0.5843, grad=20.6267]Training epoch 9:  67%|██████▋   | 110/163 [02:03<01:00,  1.15s/it, loss=1.7681, batch_acc=0.6250, running_acc=0.5847, grad=19.5315]Training epoch 9:  68%|██████▊   | 111/163 [02:04<00:55,  1.07s/it, loss=1.7681, batch_acc=0.6250, running_acc=0.5847, grad=19.5315]Training epoch 9:  68%|██████▊   | 111/163 [02:04<00:55,  1.07s/it, loss=1.7573, batch_acc=0.5312, running_acc=0.5842, grad=20.0897]Training epoch 9:  69%|██████▊   | 112/163 [02:05<00:51,  1.01s/it, loss=1.7573, batch_acc=0.5312, running_acc=0.5842, grad=20.0897]Training epoch 9:  69%|██████▊   | 112/163 [02:05<00:51,  1.01s/it, loss=1.6899, batch_acc=0.5938, running_acc=0.5843, grad=21.3843]Training epoch 9:  69%|██████▉   | 113/163 [02:06<00:48,  1.03it/s, loss=1.6899, batch_acc=0.5938, running_acc=0.5843, grad=21.3843]Training epoch 9:  69%|██████▉   | 113/163 [02:06<00:48,  1.03it/s, loss=1.8623, batch_acc=0.5000, running_acc=0.5835, grad=19.5521]Training epoch 9:  70%|██████▉   | 114/163 [02:07<00:56,  1.15s/it, loss=1.8623, batch_acc=0.5000, running_acc=0.5835, grad=19.5521]Training epoch 9:  70%|██████▉   | 114/163 [02:07<00:56,  1.15s/it, loss=1.4806, batch_acc=0.6562, running_acc=0.5842, grad=15.2270]Training epoch 9:  71%|███████   | 115/163 [02:08<00:51,  1.07s/it, loss=1.4806, batch_acc=0.6562, running_acc=0.5842, grad=15.2270]Training epoch 9:  71%|███████   | 115/163 [02:08<00:51,  1.07s/it, loss=1.7839, batch_acc=0.5000, running_acc=0.5834, grad=19.7713]Training epoch 9:  71%|███████   | 116/163 [02:09<00:48,  1.03s/it, loss=1.7839, batch_acc=0.5000, running_acc=0.5834, grad=19.7713]Training epoch 9:  71%|███████   | 116/163 [02:09<00:48,  1.03s/it, loss=1.6167, batch_acc=0.6250, running_acc=0.5838, grad=17.4011]Training epoch 9:  72%|███████▏  | 117/163 [02:10<00:45,  1.01it/s, loss=1.6167, batch_acc=0.6250, running_acc=0.5838, grad=17.4011]Training epoch 9:  72%|███████▏  | 117/163 [02:10<00:45,  1.01it/s, loss=1.3584, batch_acc=0.6875, running_acc=0.5847, grad=24.8467]Training epoch 9:  72%|███████▏  | 118/163 [02:12<00:54,  1.20s/it, loss=1.3584, batch_acc=0.6875, running_acc=0.5847, grad=24.8467]Training epoch 9:  72%|███████▏  | 118/163 [02:12<00:54,  1.20s/it, loss=1.6962, batch_acc=0.5625, running_acc=0.5845, grad=27.6247]Training epoch 9:  73%|███████▎  | 119/163 [02:13<00:48,  1.11s/it, loss=1.6962, batch_acc=0.5625, running_acc=0.5845, grad=27.6247]Training epoch 9:  73%|███████▎  | 119/163 [02:13<00:48,  1.11s/it, loss=1.8409, batch_acc=0.5625, running_acc=0.5843, grad=19.8136]Training epoch 9:  74%|███████▎  | 120/163 [02:13<00:44,  1.04s/it, loss=1.8409, batch_acc=0.5625, running_acc=0.5843, grad=19.8136]Training epoch 9:  74%|███████▎  | 120/163 [02:13<00:44,  1.04s/it, loss=1.7381, batch_acc=0.6250, running_acc=0.5846, grad=21.3299]Training epoch 9:  74%|███████▍  | 121/163 [02:14<00:41,  1.01it/s, loss=1.7381, batch_acc=0.6250, running_acc=0.5846, grad=21.3299]Training epoch 9:  74%|███████▍  | 121/163 [02:14<00:41,  1.01it/s, loss=1.5623, batch_acc=0.5625, running_acc=0.5845, grad=20.7602]Training epoch 9:  75%|███████▍  | 122/163 [02:16<00:51,  1.26s/it, loss=1.5623, batch_acc=0.5625, running_acc=0.5845, grad=20.7602]Training epoch 9:  75%|███████▍  | 122/163 [02:16<00:51,  1.26s/it, loss=1.6458, batch_acc=0.6250, running_acc=0.5848, grad=18.1204]Training epoch 9:  75%|███████▌  | 123/163 [02:17<00:45,  1.14s/it, loss=1.6458, batch_acc=0.6250, running_acc=0.5848, grad=18.1204]Training epoch 9:  75%|███████▌  | 123/163 [02:17<00:45,  1.14s/it, loss=1.5636, batch_acc=0.6875, running_acc=0.5856, grad=26.0453]Training epoch 9:  76%|███████▌  | 124/163 [02:18<00:41,  1.07s/it, loss=1.5636, batch_acc=0.6875, running_acc=0.5856, grad=26.0453]Training epoch 9:  76%|███████▌  | 124/163 [02:18<00:41,  1.07s/it, loss=1.8641, batch_acc=0.4688, running_acc=0.5847, grad=19.2103]Training epoch 9:  77%|███████▋  | 125/163 [02:19<00:38,  1.01s/it, loss=1.8641, batch_acc=0.4688, running_acc=0.5847, grad=19.2103]Training epoch 9:  77%|███████▋  | 125/163 [02:19<00:38,  1.01s/it, loss=1.4938, batch_acc=0.6562, running_acc=0.5853, grad=16.3936]Training epoch 9:  77%|███████▋  | 126/163 [02:21<00:50,  1.37s/it, loss=1.4938, batch_acc=0.6562, running_acc=0.5853, grad=16.3936]Training epoch 9:  77%|███████▋  | 126/163 [02:21<00:50,  1.37s/it, loss=1.5027, batch_acc=0.6250, running_acc=0.5856, grad=21.6160]Training epoch 9:  78%|███████▊  | 127/163 [02:22<00:44,  1.23s/it, loss=1.5027, batch_acc=0.6250, running_acc=0.5856, grad=21.6160]Training epoch 9:  78%|███████▊  | 127/163 [02:22<00:44,  1.23s/it, loss=1.4334, batch_acc=0.5625, running_acc=0.5854, grad=23.3177]Training epoch 9:  79%|███████▊  | 128/163 [02:23<00:39,  1.12s/it, loss=1.4334, batch_acc=0.5625, running_acc=0.5854, grad=23.3177]Training epoch 9:  79%|███████▊  | 128/163 [02:23<00:39,  1.12s/it, loss=1.5357, batch_acc=0.6250, running_acc=0.5857, grad=22.1789]Training epoch 9:  79%|███████▉  | 129/163 [02:24<00:35,  1.05s/it, loss=1.5357, batch_acc=0.6250, running_acc=0.5857, grad=22.1789]Training epoch 9:  79%|███████▉  | 129/163 [02:24<00:35,  1.05s/it, loss=1.7609, batch_acc=0.5938, running_acc=0.5858, grad=27.6165]Training epoch 9:  80%|███████▉  | 130/163 [02:25<00:36,  1.12s/it, loss=1.7609, batch_acc=0.5938, running_acc=0.5858, grad=27.6165]Training epoch 9:  80%|███████▉  | 130/163 [02:25<00:36,  1.12s/it, loss=1.4315, batch_acc=0.7188, running_acc=0.5868, grad=23.6639]Training epoch 9:  80%|████████  | 131/163 [02:26<00:33,  1.05s/it, loss=1.4315, batch_acc=0.7188, running_acc=0.5868, grad=23.6639]Training epoch 9:  80%|████████  | 131/163 [02:26<00:33,  1.05s/it, loss=1.7002, batch_acc=0.5625, running_acc=0.5866, grad=16.5770]Training epoch 9:  81%|████████  | 132/163 [02:27<00:30,  1.00it/s, loss=1.7002, batch_acc=0.5625, running_acc=0.5866, grad=16.5770]Training epoch 9:  81%|████████  | 132/163 [02:27<00:30,  1.00it/s, loss=1.5587, batch_acc=0.6250, running_acc=0.5869, grad=17.0254]Training epoch 9:  82%|████████▏ | 133/163 [02:28<00:28,  1.04it/s, loss=1.5587, batch_acc=0.6250, running_acc=0.5869, grad=17.0254]Training epoch 9:  82%|████████▏ | 133/163 [02:28<00:28,  1.04it/s, loss=1.4822, batch_acc=0.6250, running_acc=0.5872, grad=15.6282]Training epoch 9:  82%|████████▏ | 134/163 [02:29<00:33,  1.16s/it, loss=1.4822, batch_acc=0.6250, running_acc=0.5872, grad=15.6282]Training epoch 9:  82%|████████▏ | 134/163 [02:29<00:33,  1.16s/it, loss=1.5535, batch_acc=0.5625, running_acc=0.5870, grad=22.6218]Training epoch 9:  83%|████████▎ | 135/163 [02:30<00:30,  1.07s/it, loss=1.5535, batch_acc=0.5625, running_acc=0.5870, grad=22.6218]Training epoch 9:  83%|████████▎ | 135/163 [02:30<00:30,  1.07s/it, loss=1.4911, batch_acc=0.6875, running_acc=0.5877, grad=18.7702]Training epoch 9:  83%|████████▎ | 136/163 [02:31<00:27,  1.03s/it, loss=1.4911, batch_acc=0.6875, running_acc=0.5877, grad=18.7702]Training epoch 9:  83%|████████▎ | 136/163 [02:31<00:27,  1.03s/it, loss=1.8829, batch_acc=0.5312, running_acc=0.5873, grad=25.0591]Training epoch 9:  84%|████████▍ | 137/163 [02:32<00:25,  1.01it/s, loss=1.8829, batch_acc=0.5312, running_acc=0.5873, grad=25.0591]Training epoch 9:  84%|████████▍ | 137/163 [02:32<00:25,  1.01it/s, loss=1.8011, batch_acc=0.4688, running_acc=0.5865, grad=18.5785]Training epoch 9:  85%|████████▍ | 138/163 [02:34<00:29,  1.20s/it, loss=1.8011, batch_acc=0.4688, running_acc=0.5865, grad=18.5785]Training epoch 9:  85%|████████▍ | 138/163 [02:34<00:29,  1.20s/it, loss=1.6572, batch_acc=0.5625, running_acc=0.5863, grad=20.3591]Training epoch 9:  85%|████████▌ | 139/163 [02:35<00:26,  1.10s/it, loss=1.6572, batch_acc=0.5625, running_acc=0.5863, grad=20.3591]Training epoch 9:  85%|████████▌ | 139/163 [02:35<00:26,  1.10s/it, loss=1.6991, batch_acc=0.5625, running_acc=0.5861, grad=20.7635]Training epoch 9:  86%|████████▌ | 140/163 [02:36<00:24,  1.08s/it, loss=1.6991, batch_acc=0.5625, running_acc=0.5861, grad=20.7635]Training epoch 9:  86%|████████▌ | 140/163 [02:36<00:24,  1.08s/it, loss=1.3792, batch_acc=0.7188, running_acc=0.5871, grad=24.0358]Training epoch 9:  87%|████████▋ | 141/163 [02:36<00:22,  1.02s/it, loss=1.3792, batch_acc=0.7188, running_acc=0.5871, grad=24.0358]Training epoch 9:  87%|████████▋ | 141/163 [02:36<00:22,  1.02s/it, loss=1.9252, batch_acc=0.5312, running_acc=0.5867, grad=22.6486]Training epoch 9:  87%|████████▋ | 142/163 [02:38<00:22,  1.08s/it, loss=1.9252, batch_acc=0.5312, running_acc=0.5867, grad=22.6486]Training epoch 9:  87%|████████▋ | 142/163 [02:38<00:22,  1.08s/it, loss=1.9071, batch_acc=0.5938, running_acc=0.5867, grad=21.8753]Training epoch 9:  88%|████████▊ | 143/163 [02:39<00:20,  1.02s/it, loss=1.9071, batch_acc=0.5938, running_acc=0.5867, grad=21.8753]Training epoch 9:  88%|████████▊ | 143/163 [02:39<00:20,  1.02s/it, loss=1.7298, batch_acc=0.5938, running_acc=0.5868, grad=24.3915]Training epoch 9:  88%|████████▊ | 144/163 [02:40<00:22,  1.16s/it, loss=1.7298, batch_acc=0.5938, running_acc=0.5868, grad=24.3915]Training epoch 9:  88%|████████▊ | 144/163 [02:40<00:22,  1.16s/it, loss=1.8918, batch_acc=0.5625, running_acc=0.5866, grad=20.3425]Training epoch 9:  89%|████████▉ | 145/163 [02:41<00:19,  1.08s/it, loss=1.8918, batch_acc=0.5625, running_acc=0.5866, grad=20.3425]Training epoch 9:  89%|████████▉ | 145/163 [02:41<00:19,  1.08s/it, loss=1.5322, batch_acc=0.6875, running_acc=0.5873, grad=20.0695]Training epoch 9:  90%|████████▉ | 146/163 [02:42<00:20,  1.19s/it, loss=1.5322, batch_acc=0.6875, running_acc=0.5873, grad=20.0695]Training epoch 9:  90%|████████▉ | 146/163 [02:42<00:20,  1.19s/it, loss=1.8236, batch_acc=0.5000, running_acc=0.5867, grad=19.4228]Training epoch 9:  90%|█████████ | 147/163 [02:43<00:17,  1.10s/it, loss=1.8236, batch_acc=0.5000, running_acc=0.5867, grad=19.4228]Training epoch 9:  90%|█████████ | 147/163 [02:43<00:17,  1.10s/it, loss=1.7121, batch_acc=0.5625, running_acc=0.5865, grad=16.5036]Training epoch 9:  91%|█████████ | 148/163 [02:45<00:18,  1.22s/it, loss=1.7121, batch_acc=0.5625, running_acc=0.5865, grad=16.5036]Training epoch 9:  91%|█████████ | 148/163 [02:45<00:18,  1.22s/it, loss=1.7280, batch_acc=0.6562, running_acc=0.5870, grad=20.2582]Training epoch 9:  91%|█████████▏| 149/163 [02:46<00:15,  1.12s/it, loss=1.7280, batch_acc=0.6562, running_acc=0.5870, grad=20.2582]Training epoch 9:  91%|█████████▏| 149/163 [02:46<00:15,  1.12s/it, loss=1.5841, batch_acc=0.6250, running_acc=0.5872, grad=18.6075]Training epoch 9:  92%|█████████▏| 150/163 [02:47<00:14,  1.09s/it, loss=1.5841, batch_acc=0.6250, running_acc=0.5872, grad=18.6075]Training epoch 9:  92%|█████████▏| 150/163 [02:47<00:14,  1.09s/it, loss=1.8429, batch_acc=0.5938, running_acc=0.5873, grad=21.4508]Training epoch 9:  93%|█████████▎| 151/163 [02:48<00:12,  1.03s/it, loss=1.8429, batch_acc=0.5938, running_acc=0.5873, grad=21.4508]Training epoch 9:  93%|█████████▎| 151/163 [02:48<00:12,  1.03s/it, loss=1.4219, batch_acc=0.7188, running_acc=0.5882, grad=19.7986]Training epoch 9:  93%|█████████▎| 152/163 [02:49<00:14,  1.30s/it, loss=1.4219, batch_acc=0.7188, running_acc=0.5882, grad=19.7986]Training epoch 9:  93%|█████████▎| 152/163 [02:49<00:14,  1.30s/it, loss=1.8593, batch_acc=0.5000, running_acc=0.5876, grad=22.6244]Training epoch 9:  94%|█████████▍| 153/163 [02:50<00:11,  1.18s/it, loss=1.8593, batch_acc=0.5000, running_acc=0.5876, grad=22.6244]Training epoch 9:  94%|█████████▍| 153/163 [02:50<00:11,  1.18s/it, loss=1.4851, batch_acc=0.6250, running_acc=0.5878, grad=22.5867]Training epoch 9:  94%|█████████▍| 154/163 [02:51<00:09,  1.09s/it, loss=1.4851, batch_acc=0.6250, running_acc=0.5878, grad=22.5867]Training epoch 9:  94%|█████████▍| 154/163 [02:51<00:09,  1.09s/it, loss=2.0222, batch_acc=0.4688, running_acc=0.5871, grad=22.0540]Training epoch 9:  95%|█████████▌| 155/163 [02:52<00:08,  1.03s/it, loss=2.0222, batch_acc=0.4688, running_acc=0.5871, grad=22.0540]Training epoch 9:  95%|█████████▌| 155/163 [02:52<00:08,  1.03s/it, loss=1.4441, batch_acc=0.7188, running_acc=0.5879, grad=16.7349]Training epoch 9:  96%|█████████▌| 156/163 [02:54<00:09,  1.36s/it, loss=1.4441, batch_acc=0.7188, running_acc=0.5879, grad=16.7349]Training epoch 9:  96%|█████████▌| 156/163 [02:54<00:09,  1.36s/it, loss=1.6721, batch_acc=0.5000, running_acc=0.5873, grad=29.4106]Training epoch 9:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=1.6721, batch_acc=0.5000, running_acc=0.5873, grad=29.4106]Training epoch 9:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=1.6241, batch_acc=0.5938, running_acc=0.5874, grad=15.8476]Training epoch 9:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=1.6241, batch_acc=0.5938, running_acc=0.5874, grad=15.8476]Training epoch 9:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=1.6586, batch_acc=0.5312, running_acc=0.5870, grad=15.9045]Training epoch 9:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=1.6586, batch_acc=0.5312, running_acc=0.5870, grad=15.9045]Training epoch 9:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=1.3843, batch_acc=0.7188, running_acc=0.5879, grad=19.9728]Training epoch 9:  98%|█████████▊| 160/163 [02:59<00:03,  1.31s/it, loss=1.3843, batch_acc=0.7188, running_acc=0.5879, grad=19.9728]Training epoch 9:  98%|█████████▊| 160/163 [02:59<00:03,  1.31s/it, loss=1.4683, batch_acc=0.6562, running_acc=0.5883, grad=22.5616]Training epoch 9:  99%|█████████▉| 161/163 [03:00<00:02,  1.18s/it, loss=1.4683, batch_acc=0.6562, running_acc=0.5883, grad=22.5616]Training epoch 9:  99%|█████████▉| 161/163 [03:00<00:02,  1.18s/it, loss=2.0365, batch_acc=0.4688, running_acc=0.5875, grad=21.4256]Training epoch 9:  99%|█████████▉| 162/163 [03:01<00:01,  1.09s/it, loss=2.0365, batch_acc=0.4688, running_acc=0.5875, grad=21.4256]Training epoch 9:  99%|█████████▉| 162/163 [03:01<00:01,  1.09s/it, loss=1.6473, batch_acc=0.5312, running_acc=0.5872, grad=21.7218]Training epoch 9: 100%|██████████| 163/163 [03:01<00:00,  1.05it/s, loss=1.6473, batch_acc=0.5312, running_acc=0.5872, grad=21.7218]Training epoch 9: 100%|██████████| 163/163 [03:01<00:00,  1.05it/s, loss=1.6507, batch_acc=0.5714, running_acc=0.5871, grad=27.2015]Training epoch 9: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=1.6507, batch_acc=0.5714, running_acc=0.5871, grad=27.2015]
Evaluation epoch 9:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 9:   4%|▎         | 1/28 [00:05<02:19,  5.15s/it]Evaluation epoch 9:   4%|▎         | 1/28 [00:05<02:19,  5.15s/it, loss=1.2849, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 9:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=1.2849, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 9:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=1.4560, batch_acc=0.5938, running_acc=0.6562]Evaluation epoch 9:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=1.4560, batch_acc=0.5938, running_acc=0.6562]Evaluation epoch 9:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=1.5471, batch_acc=0.5938, running_acc=0.6354]Evaluation epoch 9:  14%|█▍        | 4/28 [00:10<01:02,  2.60s/it, loss=1.5471, batch_acc=0.5938, running_acc=0.6354]Evaluation epoch 9:  14%|█▍        | 4/28 [00:10<01:02,  2.60s/it, loss=2.3974, batch_acc=0.2812, running_acc=0.5469]Evaluation epoch 9:  18%|█▊        | 5/28 [00:10<00:40,  1.76s/it, loss=2.3974, batch_acc=0.2812, running_acc=0.5469]Evaluation epoch 9:  18%|█▊        | 5/28 [00:10<00:40,  1.76s/it, loss=2.3154, batch_acc=0.5000, running_acc=0.5375]Evaluation epoch 9:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=2.3154, batch_acc=0.5000, running_acc=0.5375]Evaluation epoch 9:  21%|██▏       | 6/28 [00:10<00:27,  1.25s/it, loss=2.3136, batch_acc=0.3125, running_acc=0.5000]Evaluation epoch 9:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.3136, batch_acc=0.3125, running_acc=0.5000]Evaluation epoch 9:  25%|██▌       | 7/28 [00:10<00:19,  1.08it/s, loss=2.0595, batch_acc=0.4375, running_acc=0.4911]Evaluation epoch 9:  29%|██▊       | 8/28 [00:14<00:32,  1.63s/it, loss=2.0595, batch_acc=0.4375, running_acc=0.4911]Evaluation epoch 9:  29%|██▊       | 8/28 [00:14<00:32,  1.63s/it, loss=1.7629, batch_acc=0.5312, running_acc=0.4961]Evaluation epoch 9:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=1.7629, batch_acc=0.5312, running_acc=0.4961]Evaluation epoch 9:  32%|███▏      | 9/28 [00:14<00:23,  1.24s/it, loss=2.0088, batch_acc=0.5000, running_acc=0.4965]Evaluation epoch 9:  36%|███▌      | 10/28 [00:14<00:16,  1.07it/s, loss=2.0088, batch_acc=0.5000, running_acc=0.4965]Evaluation epoch 9:  36%|███▌      | 10/28 [00:14<00:16,  1.07it/s, loss=0.8720, batch_acc=0.8750, running_acc=0.5344]Evaluation epoch 9:  39%|███▉      | 11/28 [00:15<00:12,  1.37it/s, loss=0.8720, batch_acc=0.8750, running_acc=0.5344]Evaluation epoch 9:  39%|███▉      | 11/28 [00:15<00:12,  1.37it/s, loss=1.8687, batch_acc=0.6250, running_acc=0.5426]Evaluation epoch 9:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=1.8687, batch_acc=0.6250, running_acc=0.5426]Evaluation epoch 9:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=1.7513, batch_acc=0.5938, running_acc=0.5469]Evaluation epoch 9:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=1.7513, batch_acc=0.5938, running_acc=0.5469]Evaluation epoch 9:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=1.5608, batch_acc=0.5938, running_acc=0.5505]Evaluation epoch 9:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=1.5608, batch_acc=0.5938, running_acc=0.5505]Evaluation epoch 9:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=2.1291, batch_acc=0.5625, running_acc=0.5513]Evaluation epoch 9:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=2.1291, batch_acc=0.5625, running_acc=0.5513]Evaluation epoch 9:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=2.7805, batch_acc=0.2812, running_acc=0.5333]Evaluation epoch 9:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=2.7805, batch_acc=0.2812, running_acc=0.5333]Evaluation epoch 9:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=1.9761, batch_acc=0.3750, running_acc=0.5234]Evaluation epoch 9:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=1.9761, batch_acc=0.3750, running_acc=0.5234]Evaluation epoch 9:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=1.6548, batch_acc=0.5312, running_acc=0.5239]Evaluation epoch 9:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=1.6548, batch_acc=0.5312, running_acc=0.5239]Evaluation epoch 9:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=1.5845, batch_acc=0.6250, running_acc=0.5295]Evaluation epoch 9:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=1.5845, batch_acc=0.6250, running_acc=0.5295]Evaluation epoch 9:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=1.5852, batch_acc=0.5938, running_acc=0.5329]Evaluation epoch 9:  71%|███████▏  | 20/28 [00:28<00:11,  1.38s/it, loss=1.5852, batch_acc=0.5938, running_acc=0.5329]Evaluation epoch 9:  71%|███████▏  | 20/28 [00:28<00:11,  1.38s/it, loss=1.8575, batch_acc=0.5625, running_acc=0.5344]Evaluation epoch 9:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=1.8575, batch_acc=0.5625, running_acc=0.5344]Evaluation epoch 9:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=1.9483, batch_acc=0.5625, running_acc=0.5357]Evaluation epoch 9:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=1.9483, batch_acc=0.5625, running_acc=0.5357]Evaluation epoch 9:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=2.1946, batch_acc=0.4688, running_acc=0.5327]Evaluation epoch 9:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=2.1946, batch_acc=0.4688, running_acc=0.5327]Evaluation epoch 9:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=1.9454, batch_acc=0.5000, running_acc=0.5312]Evaluation epoch 9:  86%|████████▌ | 24/28 [00:34<00:08,  2.08s/it, loss=1.9454, batch_acc=0.5000, running_acc=0.5312]Evaluation epoch 9:  86%|████████▌ | 24/28 [00:34<00:08,  2.08s/it, loss=1.0665, batch_acc=0.7500, running_acc=0.5404]Evaluation epoch 9:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=1.0665, batch_acc=0.7500, running_acc=0.5404]Evaluation epoch 9:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=1.3248, batch_acc=0.6250, running_acc=0.5437]Evaluation epoch 9:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.3248, batch_acc=0.6250, running_acc=0.5437]Evaluation epoch 9:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.8205, batch_acc=0.3438, running_acc=0.5361]Evaluation epoch 9:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.8205, batch_acc=0.3438, running_acc=0.5361]Evaluation epoch 9:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.7918, batch_acc=0.5000, running_acc=0.5347]Evaluation epoch 9: 100%|██████████| 28/28 [00:35<00:00,  1.13it/s, loss=0.8210, batch_acc=1.0000, running_acc=0.5363]Evaluation epoch 9: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=0.8210, batch_acc=1.0000, running_acc=0.5363]
Training epoch 10:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 10:   1%|          | 1/163 [00:05<14:59,  5.55s/it]Training epoch 10:   1%|          | 1/163 [00:05<14:59,  5.55s/it, loss=1.5472, batch_acc=0.6250, running_acc=0.6250, grad=22.5849]Training epoch 10:   1%|          | 2/163 [00:06<07:31,  2.81s/it, loss=1.5472, batch_acc=0.6250, running_acc=0.6250, grad=22.5849]Training epoch 10:   1%|          | 2/163 [00:06<07:31,  2.81s/it, loss=1.7274, batch_acc=0.4688, running_acc=0.5469, grad=22.7713]Training epoch 10:   2%|▏         | 3/163 [00:07<05:08,  1.93s/it, loss=1.7274, batch_acc=0.4688, running_acc=0.5469, grad=22.7713]Training epoch 10:   2%|▏         | 3/163 [00:07<05:08,  1.93s/it, loss=1.4195, batch_acc=0.5625, running_acc=0.5521, grad=16.5415]Training epoch 10:   2%|▏         | 4/163 [00:09<05:41,  2.15s/it, loss=1.4195, batch_acc=0.5625, running_acc=0.5521, grad=16.5415]Training epoch 10:   2%|▏         | 4/163 [00:09<05:41,  2.15s/it, loss=1.6944, batch_acc=0.6250, running_acc=0.5703, grad=15.6215]Training epoch 10:   3%|▎         | 5/163 [00:10<04:27,  1.69s/it, loss=1.6944, batch_acc=0.6250, running_acc=0.5703, grad=15.6215]Training epoch 10:   3%|▎         | 5/163 [00:10<04:27,  1.69s/it, loss=1.8792, batch_acc=0.5938, running_acc=0.5750, grad=18.0012]Training epoch 10:   4%|▎         | 6/163 [00:11<03:42,  1.42s/it, loss=1.8792, batch_acc=0.5938, running_acc=0.5750, grad=18.0012]Training epoch 10:   4%|▎         | 6/163 [00:11<03:42,  1.42s/it, loss=1.4066, batch_acc=0.7188, running_acc=0.5990, grad=15.6650]Training epoch 10:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=1.4066, batch_acc=0.7188, running_acc=0.5990, grad=15.6650]Training epoch 10:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=1.3255, batch_acc=0.8750, running_acc=0.6384, grad=15.0394]Training epoch 10:   5%|▍         | 8/163 [00:14<03:29,  1.35s/it, loss=1.3255, batch_acc=0.8750, running_acc=0.6384, grad=15.0394]Training epoch 10:   5%|▍         | 8/163 [00:14<03:29,  1.35s/it, loss=1.3556, batch_acc=0.7188, running_acc=0.6484, grad=19.6697]Training epoch 10:   6%|▌         | 9/163 [00:14<03:05,  1.20s/it, loss=1.3556, batch_acc=0.7188, running_acc=0.6484, grad=19.6697]Training epoch 10:   6%|▌         | 9/163 [00:14<03:05,  1.20s/it, loss=1.6125, batch_acc=0.5938, running_acc=0.6424, grad=17.9725]Training epoch 10:   6%|▌         | 10/163 [00:15<02:48,  1.10s/it, loss=1.6125, batch_acc=0.5938, running_acc=0.6424, grad=17.9725]Training epoch 10:   6%|▌         | 10/163 [00:15<02:48,  1.10s/it, loss=1.2417, batch_acc=0.7500, running_acc=0.6531, grad=17.5196]Training epoch 10:   7%|▋         | 11/163 [00:16<02:37,  1.04s/it, loss=1.2417, batch_acc=0.7500, running_acc=0.6531, grad=17.5196]Training epoch 10:   7%|▋         | 11/163 [00:16<02:37,  1.04s/it, loss=1.2839, batch_acc=0.6562, running_acc=0.6534, grad=15.5479]Training epoch 10:   7%|▋         | 12/163 [00:18<03:03,  1.22s/it, loss=1.2839, batch_acc=0.6562, running_acc=0.6534, grad=15.5479]Training epoch 10:   7%|▋         | 12/163 [00:18<03:03,  1.22s/it, loss=1.3342, batch_acc=0.7500, running_acc=0.6615, grad=15.5739]Training epoch 10:   8%|▊         | 13/163 [00:19<02:47,  1.12s/it, loss=1.3342, batch_acc=0.7500, running_acc=0.6615, grad=15.5739]Training epoch 10:   8%|▊         | 13/163 [00:19<02:47,  1.12s/it, loss=1.6082, batch_acc=0.5938, running_acc=0.6562, grad=18.2369]Training epoch 10:   9%|▊         | 14/163 [00:20<02:35,  1.04s/it, loss=1.6082, batch_acc=0.5938, running_acc=0.6562, grad=18.2369]Training epoch 10:   9%|▊         | 14/163 [00:20<02:35,  1.04s/it, loss=1.5288, batch_acc=0.6250, running_acc=0.6540, grad=16.8808]Training epoch 10:   9%|▉         | 15/163 [00:20<02:27,  1.00it/s, loss=1.5288, batch_acc=0.6250, running_acc=0.6540, grad=16.8808]Training epoch 10:   9%|▉         | 15/163 [00:20<02:27,  1.00it/s, loss=1.7018, batch_acc=0.6250, running_acc=0.6521, grad=24.0036]Training epoch 10:  10%|▉         | 16/163 [00:22<03:11,  1.30s/it, loss=1.7018, batch_acc=0.6250, running_acc=0.6521, grad=24.0036]Training epoch 10:  10%|▉         | 16/163 [00:22<03:11,  1.30s/it, loss=1.8886, batch_acc=0.5312, running_acc=0.6445, grad=18.0032]Training epoch 10:  10%|█         | 17/163 [00:23<02:51,  1.17s/it, loss=1.8886, batch_acc=0.5312, running_acc=0.6445, grad=18.0032]Training epoch 10:  10%|█         | 17/163 [00:23<02:51,  1.17s/it, loss=1.6115, batch_acc=0.6250, running_acc=0.6434, grad=18.3103]Training epoch 10:  11%|█         | 18/163 [00:24<02:37,  1.09s/it, loss=1.6115, batch_acc=0.6250, running_acc=0.6434, grad=18.3103]Training epoch 10:  11%|█         | 18/163 [00:24<02:37,  1.09s/it, loss=1.5743, batch_acc=0.5000, running_acc=0.6354, grad=27.1331]Training epoch 10:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=1.5743, batch_acc=0.5000, running_acc=0.6354, grad=27.1331]Training epoch 10:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=1.7927, batch_acc=0.5312, running_acc=0.6299, grad=33.6623]Training epoch 10:  12%|█▏        | 20/163 [00:27<02:48,  1.18s/it, loss=1.7927, batch_acc=0.5312, running_acc=0.6299, grad=33.6623]Training epoch 10:  12%|█▏        | 20/163 [00:27<02:48,  1.18s/it, loss=1.4072, batch_acc=0.6875, running_acc=0.6328, grad=18.9169]Training epoch 10:  13%|█▎        | 21/163 [00:28<02:34,  1.09s/it, loss=1.4072, batch_acc=0.6875, running_acc=0.6328, grad=18.9169]Training epoch 10:  13%|█▎        | 21/163 [00:28<02:34,  1.09s/it, loss=1.3727, batch_acc=0.6875, running_acc=0.6354, grad=18.0249]Training epoch 10:  13%|█▎        | 22/163 [00:28<02:24,  1.03s/it, loss=1.3727, batch_acc=0.6875, running_acc=0.6354, grad=18.0249]Training epoch 10:  13%|█▎        | 22/163 [00:28<02:24,  1.03s/it, loss=1.7689, batch_acc=0.5938, running_acc=0.6335, grad=18.6575]Training epoch 10:  14%|█▍        | 23/163 [00:29<02:17,  1.02it/s, loss=1.7689, batch_acc=0.5938, running_acc=0.6335, grad=18.6575]Training epoch 10:  14%|█▍        | 23/163 [00:29<02:17,  1.02it/s, loss=1.5560, batch_acc=0.6875, running_acc=0.6359, grad=18.9808]Training epoch 10:  15%|█▍        | 24/163 [00:31<02:45,  1.19s/it, loss=1.5560, batch_acc=0.6875, running_acc=0.6359, grad=18.9808]Training epoch 10:  15%|█▍        | 24/163 [00:31<02:45,  1.19s/it, loss=1.3484, batch_acc=0.6562, running_acc=0.6367, grad=19.4184]Training epoch 10:  15%|█▌        | 25/163 [00:32<02:31,  1.10s/it, loss=1.3484, batch_acc=0.6562, running_acc=0.6367, grad=19.4184]Training epoch 10:  15%|█▌        | 25/163 [00:32<02:31,  1.10s/it, loss=1.9252, batch_acc=0.5625, running_acc=0.6338, grad=24.1622]Training epoch 10:  16%|█▌        | 26/163 [00:33<02:21,  1.03s/it, loss=1.9252, batch_acc=0.5625, running_acc=0.6338, grad=24.1622]Training epoch 10:  16%|█▌        | 26/163 [00:33<02:21,  1.03s/it, loss=1.3933, batch_acc=0.7500, running_acc=0.6382, grad=25.9583]Training epoch 10:  17%|█▋        | 27/163 [00:34<02:14,  1.01it/s, loss=1.3933, batch_acc=0.7500, running_acc=0.6382, grad=25.9583]Training epoch 10:  17%|█▋        | 27/163 [00:34<02:14,  1.01it/s, loss=1.6388, batch_acc=0.7500, running_acc=0.6424, grad=22.5038]Training epoch 10:  17%|█▋        | 28/163 [00:35<02:29,  1.11s/it, loss=1.6388, batch_acc=0.7500, running_acc=0.6424, grad=22.5038]Training epoch 10:  17%|█▋        | 28/163 [00:35<02:29,  1.11s/it, loss=1.6194, batch_acc=0.5938, running_acc=0.6406, grad=16.6155]Training epoch 10:  18%|█▊        | 29/163 [00:36<02:19,  1.04s/it, loss=1.6194, batch_acc=0.5938, running_acc=0.6406, grad=16.6155]Training epoch 10:  18%|█▊        | 29/163 [00:36<02:19,  1.04s/it, loss=1.6224, batch_acc=0.5938, running_acc=0.6390, grad=18.8945]Training epoch 10:  18%|█▊        | 30/163 [00:37<02:12,  1.01it/s, loss=1.6224, batch_acc=0.5938, running_acc=0.6390, grad=18.8945]Training epoch 10:  18%|█▊        | 30/163 [00:37<02:12,  1.01it/s, loss=1.3815, batch_acc=0.6562, running_acc=0.6396, grad=20.2876]Training epoch 10:  19%|█▉        | 31/163 [00:38<02:07,  1.04it/s, loss=1.3815, batch_acc=0.6562, running_acc=0.6396, grad=20.2876]Training epoch 10:  19%|█▉        | 31/163 [00:38<02:07,  1.04it/s, loss=1.6287, batch_acc=0.6562, running_acc=0.6401, grad=16.5689]Training epoch 10:  20%|█▉        | 32/163 [00:39<02:24,  1.10s/it, loss=1.6287, batch_acc=0.6562, running_acc=0.6401, grad=16.5689]Training epoch 10:  20%|█▉        | 32/163 [00:39<02:24,  1.10s/it, loss=1.7286, batch_acc=0.6250, running_acc=0.6396, grad=23.8011]Training epoch 10:  20%|██        | 33/163 [00:40<02:14,  1.04s/it, loss=1.7286, batch_acc=0.6250, running_acc=0.6396, grad=23.8011]Training epoch 10:  20%|██        | 33/163 [00:40<02:14,  1.04s/it, loss=1.7012, batch_acc=0.5625, running_acc=0.6373, grad=21.7659]Training epoch 10:  21%|██        | 34/163 [00:41<02:07,  1.01it/s, loss=1.7012, batch_acc=0.5625, running_acc=0.6373, grad=21.7659]Training epoch 10:  21%|██        | 34/163 [00:41<02:07,  1.01it/s, loss=1.5275, batch_acc=0.5938, running_acc=0.6360, grad=22.0403]Training epoch 10:  21%|██▏       | 35/163 [00:42<02:02,  1.04it/s, loss=1.5275, batch_acc=0.5938, running_acc=0.6360, grad=22.0403]Training epoch 10:  21%|██▏       | 35/163 [00:42<02:02,  1.04it/s, loss=1.4042, batch_acc=0.6875, running_acc=0.6375, grad=13.9426]Training epoch 10:  22%|██▏       | 36/163 [00:43<02:11,  1.03s/it, loss=1.4042, batch_acc=0.6875, running_acc=0.6375, grad=13.9426]Training epoch 10:  22%|██▏       | 36/163 [00:43<02:11,  1.03s/it, loss=1.6620, batch_acc=0.5000, running_acc=0.6337, grad=20.6992]Training epoch 10:  23%|██▎       | 37/163 [00:44<02:04,  1.01it/s, loss=1.6620, batch_acc=0.5000, running_acc=0.6337, grad=20.6992]Training epoch 10:  23%|██▎       | 37/163 [00:44<02:04,  1.01it/s, loss=1.6740, batch_acc=0.5625, running_acc=0.6318, grad=25.9359]Training epoch 10:  23%|██▎       | 38/163 [00:45<01:59,  1.05it/s, loss=1.6740, batch_acc=0.5625, running_acc=0.6318, grad=25.9359]Training epoch 10:  23%|██▎       | 38/163 [00:45<01:59,  1.05it/s, loss=1.2836, batch_acc=0.6875, running_acc=0.6332, grad=13.8987]Training epoch 10:  24%|██▍       | 39/163 [00:46<01:55,  1.07it/s, loss=1.2836, batch_acc=0.6875, running_acc=0.6332, grad=13.8987]Training epoch 10:  24%|██▍       | 39/163 [00:46<01:55,  1.07it/s, loss=1.7242, batch_acc=0.6250, running_acc=0.6330, grad=19.0254]Training epoch 10:  25%|██▍       | 40/163 [00:48<02:43,  1.33s/it, loss=1.7242, batch_acc=0.6250, running_acc=0.6330, grad=19.0254]Training epoch 10:  25%|██▍       | 40/163 [00:48<02:43,  1.33s/it, loss=1.4071, batch_acc=0.6562, running_acc=0.6336, grad=21.6269]Training epoch 10:  25%|██▌       | 41/163 [00:49<02:25,  1.20s/it, loss=1.4071, batch_acc=0.6562, running_acc=0.6336, grad=21.6269]Training epoch 10:  25%|██▌       | 41/163 [00:49<02:25,  1.20s/it, loss=1.9114, batch_acc=0.5625, running_acc=0.6319, grad=27.5591]Training epoch 10:  26%|██▌       | 42/163 [00:50<02:13,  1.10s/it, loss=1.9114, batch_acc=0.5625, running_acc=0.6319, grad=27.5591]Training epoch 10:  26%|██▌       | 42/163 [00:50<02:13,  1.10s/it, loss=1.6204, batch_acc=0.5312, running_acc=0.6295, grad=19.7931]Training epoch 10:  26%|██▋       | 43/163 [00:50<02:04,  1.03s/it, loss=1.6204, batch_acc=0.5312, running_acc=0.6295, grad=19.7931]Training epoch 10:  26%|██▋       | 43/163 [00:50<02:04,  1.03s/it, loss=1.6773, batch_acc=0.5312, running_acc=0.6272, grad=27.4518]Training epoch 10:  27%|██▋       | 44/163 [00:52<02:12,  1.12s/it, loss=1.6773, batch_acc=0.5312, running_acc=0.6272, grad=27.4518]Training epoch 10:  27%|██▋       | 44/163 [00:52<02:12,  1.12s/it, loss=1.5157, batch_acc=0.7188, running_acc=0.6293, grad=21.9646]Training epoch 10:  28%|██▊       | 45/163 [00:53<02:03,  1.04s/it, loss=1.5157, batch_acc=0.7188, running_acc=0.6293, grad=21.9646]Training epoch 10:  28%|██▊       | 45/163 [00:53<02:03,  1.04s/it, loss=1.4930, batch_acc=0.6875, running_acc=0.6306, grad=24.2512]Training epoch 10:  28%|██▊       | 46/163 [00:54<01:56,  1.01it/s, loss=1.4930, batch_acc=0.6875, running_acc=0.6306, grad=24.2512]Training epoch 10:  28%|██▊       | 46/163 [00:54<01:56,  1.01it/s, loss=1.5701, batch_acc=0.6250, running_acc=0.6304, grad=18.1071]Training epoch 10:  29%|██▉       | 47/163 [00:54<01:51,  1.04it/s, loss=1.5701, batch_acc=0.6250, running_acc=0.6304, grad=18.1071]Training epoch 10:  29%|██▉       | 47/163 [00:54<01:51,  1.04it/s, loss=1.4917, batch_acc=0.7188, running_acc=0.6323, grad=19.6102]Training epoch 10:  29%|██▉       | 48/163 [00:56<02:04,  1.08s/it, loss=1.4917, batch_acc=0.7188, running_acc=0.6323, grad=19.6102]Training epoch 10:  29%|██▉       | 48/163 [00:56<02:04,  1.08s/it, loss=1.5730, batch_acc=0.5625, running_acc=0.6309, grad=18.9334]Training epoch 10:  30%|███       | 49/163 [00:57<01:56,  1.02s/it, loss=1.5730, batch_acc=0.5625, running_acc=0.6309, grad=18.9334]Training epoch 10:  30%|███       | 49/163 [00:57<01:56,  1.02s/it, loss=1.4420, batch_acc=0.7188, running_acc=0.6327, grad=16.9788]Training epoch 10:  31%|███       | 50/163 [00:58<01:50,  1.02it/s, loss=1.4420, batch_acc=0.7188, running_acc=0.6327, grad=16.9788]Training epoch 10:  31%|███       | 50/163 [00:58<01:50,  1.02it/s, loss=1.6541, batch_acc=0.7188, running_acc=0.6344, grad=19.5156]Training epoch 10:  31%|███▏      | 51/163 [00:58<01:46,  1.05it/s, loss=1.6541, batch_acc=0.7188, running_acc=0.6344, grad=19.5156]Training epoch 10:  31%|███▏      | 51/163 [00:58<01:46,  1.05it/s, loss=1.5699, batch_acc=0.6562, running_acc=0.6348, grad=19.7871]Training epoch 10:  32%|███▏      | 52/163 [01:00<02:09,  1.17s/it, loss=1.5699, batch_acc=0.6562, running_acc=0.6348, grad=19.7871]Training epoch 10:  32%|███▏      | 52/163 [01:00<02:09,  1.17s/it, loss=1.6540, batch_acc=0.6250, running_acc=0.6346, grad=25.0580]Training epoch 10:  33%|███▎      | 53/163 [01:01<01:58,  1.08s/it, loss=1.6540, batch_acc=0.6250, running_acc=0.6346, grad=25.0580]Training epoch 10:  33%|███▎      | 53/163 [01:01<01:58,  1.08s/it, loss=1.3975, batch_acc=0.7812, running_acc=0.6374, grad=30.4734]Training epoch 10:  33%|███▎      | 54/163 [01:02<01:51,  1.02s/it, loss=1.3975, batch_acc=0.7812, running_acc=0.6374, grad=30.4734]Training epoch 10:  33%|███▎      | 54/163 [01:02<01:51,  1.02s/it, loss=1.5549, batch_acc=0.5938, running_acc=0.6366, grad=27.3737]Training epoch 10:  34%|███▎      | 55/163 [01:03<01:45,  1.02it/s, loss=1.5549, batch_acc=0.5938, running_acc=0.6366, grad=27.3737]Training epoch 10:  34%|███▎      | 55/163 [01:03<01:45,  1.02it/s, loss=1.2900, batch_acc=0.7188, running_acc=0.6381, grad=19.0599]Training epoch 10:  34%|███▍      | 56/163 [01:05<02:17,  1.28s/it, loss=1.2900, batch_acc=0.7188, running_acc=0.6381, grad=19.0599]Training epoch 10:  34%|███▍      | 56/163 [01:05<02:17,  1.28s/it, loss=1.4689, batch_acc=0.5938, running_acc=0.6373, grad=22.1488]Training epoch 10:  35%|███▍      | 57/163 [01:06<02:02,  1.16s/it, loss=1.4689, batch_acc=0.5938, running_acc=0.6373, grad=22.1488]Training epoch 10:  35%|███▍      | 57/163 [01:06<02:02,  1.16s/it, loss=1.3992, batch_acc=0.7812, running_acc=0.6398, grad=20.0499]Training epoch 10:  36%|███▌      | 58/163 [01:06<01:52,  1.08s/it, loss=1.3992, batch_acc=0.7812, running_acc=0.6398, grad=20.0499]Training epoch 10:  36%|███▌      | 58/163 [01:06<01:52,  1.08s/it, loss=1.7858, batch_acc=0.4688, running_acc=0.6369, grad=26.9879]Training epoch 10:  36%|███▌      | 59/163 [01:07<01:49,  1.05s/it, loss=1.7858, batch_acc=0.4688, running_acc=0.6369, grad=26.9879]Training epoch 10:  36%|███▌      | 59/163 [01:07<01:49,  1.05s/it, loss=1.4346, batch_acc=0.5312, running_acc=0.6351, grad=15.5932]Training epoch 10:  37%|███▋      | 60/163 [01:09<02:00,  1.17s/it, loss=1.4346, batch_acc=0.5312, running_acc=0.6351, grad=15.5932]Training epoch 10:  37%|███▋      | 60/163 [01:09<02:00,  1.17s/it, loss=1.6178, batch_acc=0.6875, running_acc=0.6359, grad=22.5655]Training epoch 10:  37%|███▋      | 61/163 [01:10<01:50,  1.08s/it, loss=1.6178, batch_acc=0.6875, running_acc=0.6359, grad=22.5655]Training epoch 10:  37%|███▋      | 61/163 [01:10<01:50,  1.08s/it, loss=1.5177, batch_acc=0.6562, running_acc=0.6363, grad=19.4627]Training epoch 10:  38%|███▊      | 62/163 [01:11<01:43,  1.02s/it, loss=1.5177, batch_acc=0.6562, running_acc=0.6363, grad=19.4627]Training epoch 10:  38%|███▊      | 62/163 [01:11<01:43,  1.02s/it, loss=1.7816, batch_acc=0.5625, running_acc=0.6351, grad=23.0092]Training epoch 10:  39%|███▊      | 63/163 [01:12<01:37,  1.02it/s, loss=1.7816, batch_acc=0.5625, running_acc=0.6351, grad=23.0092]Training epoch 10:  39%|███▊      | 63/163 [01:12<01:37,  1.02it/s, loss=1.7148, batch_acc=0.5312, running_acc=0.6334, grad=22.3667]Training epoch 10:  39%|███▉      | 64/163 [01:14<02:08,  1.30s/it, loss=1.7148, batch_acc=0.5312, running_acc=0.6334, grad=22.3667]Training epoch 10:  39%|███▉      | 64/163 [01:14<02:08,  1.30s/it, loss=1.8212, batch_acc=0.6250, running_acc=0.6333, grad=24.0587]Training epoch 10:  40%|███▉      | 65/163 [01:14<01:55,  1.17s/it, loss=1.8212, batch_acc=0.6250, running_acc=0.6333, grad=24.0587]Training epoch 10:  40%|███▉      | 65/163 [01:14<01:55,  1.17s/it, loss=1.5555, batch_acc=0.7188, running_acc=0.6346, grad=20.5830]Training epoch 10:  40%|████      | 66/163 [01:15<01:45,  1.09s/it, loss=1.5555, batch_acc=0.7188, running_acc=0.6346, grad=20.5830]Training epoch 10:  40%|████      | 66/163 [01:15<01:45,  1.09s/it, loss=1.6833, batch_acc=0.5625, running_acc=0.6335, grad=19.1342]Training epoch 10:  41%|████      | 67/163 [01:16<01:38,  1.02s/it, loss=1.6833, batch_acc=0.5625, running_acc=0.6335, grad=19.1342]Training epoch 10:  41%|████      | 67/163 [01:16<01:38,  1.02s/it, loss=1.4633, batch_acc=0.6562, running_acc=0.6339, grad=21.6960]Training epoch 10:  42%|████▏     | 68/163 [01:17<01:40,  1.05s/it, loss=1.4633, batch_acc=0.6562, running_acc=0.6339, grad=21.6960]Training epoch 10:  42%|████▏     | 68/163 [01:17<01:40,  1.05s/it, loss=1.3685, batch_acc=0.6875, running_acc=0.6347, grad=17.6492]Training epoch 10:  42%|████▏     | 69/163 [01:18<01:34,  1.00s/it, loss=1.3685, batch_acc=0.6875, running_acc=0.6347, grad=17.6492]Training epoch 10:  42%|████▏     | 69/163 [01:18<01:34,  1.00s/it, loss=1.7961, batch_acc=0.5625, running_acc=0.6336, grad=20.8184]Training epoch 10:  43%|████▎     | 70/163 [01:19<01:29,  1.04it/s, loss=1.7961, batch_acc=0.5625, running_acc=0.6336, grad=20.8184]Training epoch 10:  43%|████▎     | 70/163 [01:19<01:29,  1.04it/s, loss=1.2727, batch_acc=0.7812, running_acc=0.6357, grad=16.2559]Training epoch 10:  44%|████▎     | 71/163 [01:20<01:26,  1.06it/s, loss=1.2727, batch_acc=0.7812, running_acc=0.6357, grad=16.2559]Training epoch 10:  44%|████▎     | 71/163 [01:20<01:26,  1.06it/s, loss=1.4654, batch_acc=0.6250, running_acc=0.6356, grad=28.2708]Training epoch 10:  44%|████▍     | 72/163 [01:22<02:01,  1.34s/it, loss=1.4654, batch_acc=0.6250, running_acc=0.6356, grad=28.2708]Training epoch 10:  44%|████▍     | 72/163 [01:22<02:01,  1.34s/it, loss=1.5408, batch_acc=0.6250, running_acc=0.6354, grad=17.8292]Training epoch 10:  45%|████▍     | 73/163 [01:23<01:48,  1.20s/it, loss=1.5408, batch_acc=0.6250, running_acc=0.6354, grad=17.8292]Training epoch 10:  45%|████▍     | 73/163 [01:23<01:48,  1.20s/it, loss=1.4936, batch_acc=0.5938, running_acc=0.6348, grad=17.8153]Training epoch 10:  45%|████▌     | 74/163 [01:24<01:38,  1.10s/it, loss=1.4936, batch_acc=0.5938, running_acc=0.6348, grad=17.8153]Training epoch 10:  45%|████▌     | 74/163 [01:24<01:38,  1.10s/it, loss=1.3475, batch_acc=0.6562, running_acc=0.6351, grad=21.2093]Training epoch 10:  46%|████▌     | 75/163 [01:25<01:31,  1.04s/it, loss=1.3475, batch_acc=0.6562, running_acc=0.6351, grad=21.2093]Training epoch 10:  46%|████▌     | 75/163 [01:25<01:31,  1.04s/it, loss=1.5921, batch_acc=0.6250, running_acc=0.6350, grad=17.1651]Training epoch 10:  47%|████▋     | 76/163 [01:27<01:57,  1.35s/it, loss=1.5921, batch_acc=0.6250, running_acc=0.6350, grad=17.1651]Training epoch 10:  47%|████▋     | 76/163 [01:27<01:57,  1.35s/it, loss=1.7352, batch_acc=0.5625, running_acc=0.6340, grad=15.3339]Training epoch 10:  47%|████▋     | 77/163 [01:28<01:43,  1.21s/it, loss=1.7352, batch_acc=0.5625, running_acc=0.6340, grad=15.3339]Training epoch 10:  47%|████▋     | 77/163 [01:28<01:43,  1.21s/it, loss=1.6748, batch_acc=0.5938, running_acc=0.6335, grad=18.2566]Training epoch 10:  48%|████▊     | 78/163 [01:29<01:34,  1.11s/it, loss=1.6748, batch_acc=0.5938, running_acc=0.6335, grad=18.2566]Training epoch 10:  48%|████▊     | 78/163 [01:29<01:34,  1.11s/it, loss=1.7084, batch_acc=0.5938, running_acc=0.6330, grad=27.3247]Training epoch 10:  48%|████▊     | 79/163 [01:30<01:27,  1.04s/it, loss=1.7084, batch_acc=0.5938, running_acc=0.6330, grad=27.3247]Training epoch 10:  48%|████▊     | 79/163 [01:30<01:27,  1.04s/it, loss=1.9005, batch_acc=0.5625, running_acc=0.6321, grad=25.5497]Training epoch 10:  49%|████▉     | 80/163 [01:31<01:43,  1.25s/it, loss=1.9005, batch_acc=0.5625, running_acc=0.6321, grad=25.5497]Training epoch 10:  49%|████▉     | 80/163 [01:31<01:43,  1.25s/it, loss=1.7541, batch_acc=0.6250, running_acc=0.6320, grad=22.6517]Training epoch 10:  50%|████▉     | 81/163 [01:32<01:33,  1.14s/it, loss=1.7541, batch_acc=0.6250, running_acc=0.6320, grad=22.6517]Training epoch 10:  50%|████▉     | 81/163 [01:32<01:33,  1.14s/it, loss=1.5171, batch_acc=0.5625, running_acc=0.6312, grad=15.5160]Training epoch 10:  50%|█████     | 82/163 [01:33<01:25,  1.06s/it, loss=1.5171, batch_acc=0.5625, running_acc=0.6312, grad=15.5160]Training epoch 10:  50%|█████     | 82/163 [01:33<01:25,  1.06s/it, loss=1.6822, batch_acc=0.5000, running_acc=0.6296, grad=21.1828]Training epoch 10:  51%|█████     | 83/163 [01:34<01:20,  1.01s/it, loss=1.6822, batch_acc=0.5000, running_acc=0.6296, grad=21.1828]Training epoch 10:  51%|█████     | 83/163 [01:34<01:20,  1.01s/it, loss=1.3909, batch_acc=0.7500, running_acc=0.6310, grad=19.9220]Training epoch 10:  52%|█████▏    | 84/163 [01:36<01:33,  1.18s/it, loss=1.3909, batch_acc=0.7500, running_acc=0.6310, grad=19.9220]Training epoch 10:  52%|█████▏    | 84/163 [01:36<01:33,  1.18s/it, loss=1.2346, batch_acc=0.7500, running_acc=0.6324, grad=17.4832]Training epoch 10:  52%|█████▏    | 85/163 [01:36<01:24,  1.09s/it, loss=1.2346, batch_acc=0.7500, running_acc=0.6324, grad=17.4832]Training epoch 10:  52%|█████▏    | 85/163 [01:36<01:24,  1.09s/it, loss=1.4739, batch_acc=0.5625, running_acc=0.6316, grad=26.8564]Training epoch 10:  53%|█████▎    | 86/163 [01:37<01:18,  1.03s/it, loss=1.4739, batch_acc=0.5625, running_acc=0.6316, grad=26.8564]Training epoch 10:  53%|█████▎    | 86/163 [01:37<01:18,  1.03s/it, loss=1.7523, batch_acc=0.6875, running_acc=0.6323, grad=20.3651]Training epoch 10:  53%|█████▎    | 87/163 [01:38<01:14,  1.02it/s, loss=1.7523, batch_acc=0.6875, running_acc=0.6323, grad=20.3651]Training epoch 10:  53%|█████▎    | 87/163 [01:38<01:14,  1.02it/s, loss=1.6502, batch_acc=0.6250, running_acc=0.6322, grad=20.0522]Training epoch 10:  54%|█████▍    | 88/163 [01:40<01:35,  1.27s/it, loss=1.6502, batch_acc=0.6250, running_acc=0.6322, grad=20.0522]Training epoch 10:  54%|█████▍    | 88/163 [01:40<01:35,  1.27s/it, loss=1.5131, batch_acc=0.7188, running_acc=0.6332, grad=22.9456]Training epoch 10:  55%|█████▍    | 89/163 [01:41<01:25,  1.15s/it, loss=1.5131, batch_acc=0.7188, running_acc=0.6332, grad=22.9456]Training epoch 10:  55%|█████▍    | 89/163 [01:41<01:25,  1.15s/it, loss=1.5462, batch_acc=0.6875, running_acc=0.6338, grad=22.1288]Training epoch 10:  55%|█████▌    | 90/163 [01:42<01:18,  1.07s/it, loss=1.5462, batch_acc=0.6875, running_acc=0.6338, grad=22.1288]Training epoch 10:  55%|█████▌    | 90/163 [01:42<01:18,  1.07s/it, loss=1.6219, batch_acc=0.5625, running_acc=0.6330, grad=18.0405]Training epoch 10:  56%|█████▌    | 91/163 [01:43<01:12,  1.01s/it, loss=1.6219, batch_acc=0.5625, running_acc=0.6330, grad=18.0405]Training epoch 10:  56%|█████▌    | 91/163 [01:43<01:12,  1.01s/it, loss=1.7556, batch_acc=0.6250, running_acc=0.6329, grad=19.2666]Training epoch 10:  56%|█████▋    | 92/163 [01:45<01:28,  1.25s/it, loss=1.7556, batch_acc=0.6250, running_acc=0.6329, grad=19.2666]Training epoch 10:  56%|█████▋    | 92/163 [01:45<01:28,  1.25s/it, loss=1.4505, batch_acc=0.6875, running_acc=0.6335, grad=21.9274]Training epoch 10:  57%|█████▋    | 93/163 [01:45<01:19,  1.14s/it, loss=1.4505, batch_acc=0.6875, running_acc=0.6335, grad=21.9274]Training epoch 10:  57%|█████▋    | 93/163 [01:45<01:19,  1.14s/it, loss=1.6372, batch_acc=0.6250, running_acc=0.6334, grad=16.3007]Training epoch 10:  58%|█████▊    | 94/163 [01:46<01:13,  1.06s/it, loss=1.6372, batch_acc=0.6250, running_acc=0.6334, grad=16.3007]Training epoch 10:  58%|█████▊    | 94/163 [01:46<01:13,  1.06s/it, loss=1.5539, batch_acc=0.6250, running_acc=0.6333, grad=17.4538]Training epoch 10:  58%|█████▊    | 95/163 [01:47<01:08,  1.01s/it, loss=1.5539, batch_acc=0.6250, running_acc=0.6333, grad=17.4538]Training epoch 10:  58%|█████▊    | 95/163 [01:47<01:08,  1.01s/it, loss=1.2991, batch_acc=0.7812, running_acc=0.6349, grad=20.0175]Training epoch 10:  59%|█████▉    | 96/163 [01:49<01:17,  1.16s/it, loss=1.2991, batch_acc=0.7812, running_acc=0.6349, grad=20.0175]Training epoch 10:  59%|█████▉    | 96/163 [01:49<01:17,  1.16s/it, loss=1.2900, batch_acc=0.6250, running_acc=0.6348, grad=17.0372]Training epoch 10:  60%|█████▉    | 97/163 [01:50<01:11,  1.08s/it, loss=1.2900, batch_acc=0.6250, running_acc=0.6348, grad=17.0372]Training epoch 10:  60%|█████▉    | 97/163 [01:50<01:11,  1.08s/it, loss=1.5578, batch_acc=0.5938, running_acc=0.6343, grad=24.1942]Training epoch 10:  60%|██████    | 98/163 [01:51<01:06,  1.02s/it, loss=1.5578, batch_acc=0.5938, running_acc=0.6343, grad=24.1942]Training epoch 10:  60%|██████    | 98/163 [01:51<01:06,  1.02s/it, loss=1.4792, batch_acc=0.6875, running_acc=0.6349, grad=20.8255]Training epoch 10:  61%|██████    | 99/163 [01:51<01:02,  1.02it/s, loss=1.4792, batch_acc=0.6875, running_acc=0.6349, grad=20.8255]Training epoch 10:  61%|██████    | 99/163 [01:51<01:02,  1.02it/s, loss=1.6267, batch_acc=0.6250, running_acc=0.6348, grad=16.8790]Training epoch 10:  61%|██████▏   | 100/163 [01:53<01:17,  1.24s/it, loss=1.6267, batch_acc=0.6250, running_acc=0.6348, grad=16.8790]Training epoch 10:  61%|██████▏   | 100/163 [01:53<01:17,  1.24s/it, loss=1.5862, batch_acc=0.6562, running_acc=0.6350, grad=24.4743]Training epoch 10:  62%|██████▏   | 101/163 [01:54<01:10,  1.13s/it, loss=1.5862, batch_acc=0.6562, running_acc=0.6350, grad=24.4743]Training epoch 10:  62%|██████▏   | 101/163 [01:54<01:10,  1.13s/it, loss=1.5471, batch_acc=0.6250, running_acc=0.6349, grad=18.3546]Training epoch 10:  63%|██████▎   | 102/163 [01:55<01:04,  1.05s/it, loss=1.5471, batch_acc=0.6250, running_acc=0.6349, grad=18.3546]Training epoch 10:  63%|██████▎   | 102/163 [01:55<01:04,  1.05s/it, loss=1.5917, batch_acc=0.5938, running_acc=0.6345, grad=21.8854]Training epoch 10:  63%|██████▎   | 103/163 [01:56<01:00,  1.00s/it, loss=1.5917, batch_acc=0.5938, running_acc=0.6345, grad=21.8854]Training epoch 10:  63%|██████▎   | 103/163 [01:56<01:00,  1.00s/it, loss=1.5125, batch_acc=0.6250, running_acc=0.6344, grad=16.1967]Training epoch 10:  64%|██████▍   | 104/163 [01:58<01:17,  1.32s/it, loss=1.5125, batch_acc=0.6250, running_acc=0.6344, grad=16.1967]Training epoch 10:  64%|██████▍   | 104/163 [01:58<01:17,  1.32s/it, loss=1.3890, batch_acc=0.6875, running_acc=0.6349, grad=18.8734]Training epoch 10:  64%|██████▍   | 105/163 [01:59<01:08,  1.18s/it, loss=1.3890, batch_acc=0.6875, running_acc=0.6349, grad=18.8734]Training epoch 10:  64%|██████▍   | 105/163 [01:59<01:08,  1.18s/it, loss=1.4855, batch_acc=0.7188, running_acc=0.6357, grad=18.4620]Training epoch 10:  65%|██████▌   | 106/163 [02:00<01:02,  1.09s/it, loss=1.4855, batch_acc=0.7188, running_acc=0.6357, grad=18.4620]Training epoch 10:  65%|██████▌   | 106/163 [02:00<01:02,  1.09s/it, loss=1.6041, batch_acc=0.6875, running_acc=0.6362, grad=20.1879]Training epoch 10:  66%|██████▌   | 107/163 [02:01<00:57,  1.03s/it, loss=1.6041, batch_acc=0.6875, running_acc=0.6362, grad=20.1879]Training epoch 10:  66%|██████▌   | 107/163 [02:01<00:57,  1.03s/it, loss=1.3550, batch_acc=0.7500, running_acc=0.6373, grad=21.1135]Training epoch 10:  66%|██████▋   | 108/163 [02:02<01:02,  1.14s/it, loss=1.3550, batch_acc=0.7500, running_acc=0.6373, grad=21.1135]Training epoch 10:  66%|██████▋   | 108/163 [02:02<01:02,  1.14s/it, loss=1.7782, batch_acc=0.4688, running_acc=0.6357, grad=23.2377]Training epoch 10:  67%|██████▋   | 109/163 [02:03<00:57,  1.06s/it, loss=1.7782, batch_acc=0.4688, running_acc=0.6357, grad=23.2377]Training epoch 10:  67%|██████▋   | 109/163 [02:03<00:57,  1.06s/it, loss=1.5894, batch_acc=0.5938, running_acc=0.6353, grad=23.5099]Training epoch 10:  67%|██████▋   | 110/163 [02:04<00:53,  1.01s/it, loss=1.5894, batch_acc=0.5938, running_acc=0.6353, grad=23.5099]Training epoch 10:  67%|██████▋   | 110/163 [02:04<00:53,  1.01s/it, loss=1.6986, batch_acc=0.5938, running_acc=0.6349, grad=21.6366]Training epoch 10:  68%|██████▊   | 111/163 [02:05<00:50,  1.03it/s, loss=1.6986, batch_acc=0.5938, running_acc=0.6349, grad=21.6366]Training epoch 10:  68%|██████▊   | 111/163 [02:05<00:50,  1.03it/s, loss=1.6555, batch_acc=0.6875, running_acc=0.6354, grad=23.7536]Training epoch 10:  69%|██████▊   | 112/163 [02:06<01:00,  1.19s/it, loss=1.6555, batch_acc=0.6875, running_acc=0.6354, grad=23.7536]Training epoch 10:  69%|██████▊   | 112/163 [02:06<01:00,  1.19s/it, loss=1.3443, batch_acc=0.7500, running_acc=0.6364, grad=27.4957]Training epoch 10:  69%|██████▉   | 113/163 [02:07<00:54,  1.09s/it, loss=1.3443, batch_acc=0.7500, running_acc=0.6364, grad=27.4957]Training epoch 10:  69%|██████▉   | 113/163 [02:07<00:54,  1.09s/it, loss=1.2756, batch_acc=0.6562, running_acc=0.6366, grad=28.4401]Training epoch 10:  70%|██████▉   | 114/163 [02:08<00:50,  1.03s/it, loss=1.2756, batch_acc=0.6562, running_acc=0.6366, grad=28.4401]Training epoch 10:  70%|██████▉   | 114/163 [02:08<00:50,  1.03s/it, loss=1.6262, batch_acc=0.6250, running_acc=0.6365, grad=19.0121]Training epoch 10:  71%|███████   | 115/163 [02:09<00:47,  1.02it/s, loss=1.6262, batch_acc=0.6250, running_acc=0.6365, grad=19.0121]Training epoch 10:  71%|███████   | 115/163 [02:09<00:47,  1.02it/s, loss=1.3918, batch_acc=0.6875, running_acc=0.6370, grad=20.4160]Training epoch 10:  71%|███████   | 116/163 [02:10<00:51,  1.09s/it, loss=1.3918, batch_acc=0.6875, running_acc=0.6370, grad=20.4160]Training epoch 10:  71%|███████   | 116/163 [02:10<00:51,  1.09s/it, loss=1.7293, batch_acc=0.5938, running_acc=0.6366, grad=22.6806]Training epoch 10:  72%|███████▏  | 117/163 [02:11<00:47,  1.02s/it, loss=1.7293, batch_acc=0.5938, running_acc=0.6366, grad=22.6806]Training epoch 10:  72%|███████▏  | 117/163 [02:11<00:47,  1.02s/it, loss=1.6949, batch_acc=0.5312, running_acc=0.6357, grad=23.1569]Training epoch 10:  72%|███████▏  | 118/163 [02:12<00:44,  1.02it/s, loss=1.6949, batch_acc=0.5312, running_acc=0.6357, grad=23.1569]Training epoch 10:  72%|███████▏  | 118/163 [02:12<00:44,  1.02it/s, loss=1.5552, batch_acc=0.6562, running_acc=0.6359, grad=20.3188]Training epoch 10:  73%|███████▎  | 119/163 [02:13<00:41,  1.05it/s, loss=1.5552, batch_acc=0.6562, running_acc=0.6359, grad=20.3188]Training epoch 10:  73%|███████▎  | 119/163 [02:13<00:41,  1.05it/s, loss=1.7553, batch_acc=0.5625, running_acc=0.6352, grad=26.2874]Training epoch 10:  74%|███████▎  | 120/163 [02:14<00:47,  1.11s/it, loss=1.7553, batch_acc=0.5625, running_acc=0.6352, grad=26.2874]Training epoch 10:  74%|███████▎  | 120/163 [02:14<00:47,  1.11s/it, loss=1.5325, batch_acc=0.5625, running_acc=0.6346, grad=18.4516]Training epoch 10:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=1.5325, batch_acc=0.5625, running_acc=0.6346, grad=18.4516]Training epoch 10:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=1.4875, batch_acc=0.6250, running_acc=0.6346, grad=20.9911]Training epoch 10:  75%|███████▍  | 122/163 [02:16<00:40,  1.01it/s, loss=1.4875, batch_acc=0.6250, running_acc=0.6346, grad=20.9911]Training epoch 10:  75%|███████▍  | 122/163 [02:16<00:40,  1.01it/s, loss=1.4493, batch_acc=0.6250, running_acc=0.6345, grad=30.0348]Training epoch 10:  75%|███████▌  | 123/163 [02:17<00:38,  1.04it/s, loss=1.4493, batch_acc=0.6250, running_acc=0.6345, grad=30.0348]Training epoch 10:  75%|███████▌  | 123/163 [02:17<00:38,  1.04it/s, loss=1.7334, batch_acc=0.6250, running_acc=0.6344, grad=30.5439]Training epoch 10:  76%|███████▌  | 124/163 [02:19<00:46,  1.18s/it, loss=1.7334, batch_acc=0.6250, running_acc=0.6344, grad=30.5439]Training epoch 10:  76%|███████▌  | 124/163 [02:19<00:46,  1.18s/it, loss=1.4586, batch_acc=0.6875, running_acc=0.6348, grad=16.1246]Training epoch 10:  77%|███████▋  | 125/163 [02:20<00:41,  1.09s/it, loss=1.4586, batch_acc=0.6875, running_acc=0.6348, grad=16.1246]Training epoch 10:  77%|███████▋  | 125/163 [02:20<00:41,  1.09s/it, loss=1.6967, batch_acc=0.5312, running_acc=0.6340, grad=19.6437]Training epoch 10:  77%|███████▋  | 126/163 [02:20<00:38,  1.03s/it, loss=1.6967, batch_acc=0.5312, running_acc=0.6340, grad=19.6437]Training epoch 10:  77%|███████▋  | 126/163 [02:20<00:38,  1.03s/it, loss=1.5242, batch_acc=0.5938, running_acc=0.6337, grad=22.5252]Training epoch 10:  78%|███████▊  | 127/163 [02:21<00:35,  1.02it/s, loss=1.5242, batch_acc=0.5938, running_acc=0.6337, grad=22.5252]Training epoch 10:  78%|███████▊  | 127/163 [02:21<00:35,  1.02it/s, loss=1.8241, batch_acc=0.6250, running_acc=0.6336, grad=24.5625]Training epoch 10:  79%|███████▊  | 128/163 [02:23<00:43,  1.23s/it, loss=1.8241, batch_acc=0.6250, running_acc=0.6336, grad=24.5625]Training epoch 10:  79%|███████▊  | 128/163 [02:23<00:43,  1.23s/it, loss=1.5136, batch_acc=0.6562, running_acc=0.6338, grad=20.8791]Training epoch 10:  79%|███████▉  | 129/163 [02:24<00:38,  1.13s/it, loss=1.5136, batch_acc=0.6562, running_acc=0.6338, grad=20.8791]Training epoch 10:  79%|███████▉  | 129/163 [02:24<00:38,  1.13s/it, loss=1.6310, batch_acc=0.6562, running_acc=0.6340, grad=24.5821]Training epoch 10:  80%|███████▉  | 130/163 [02:25<00:34,  1.05s/it, loss=1.6310, batch_acc=0.6562, running_acc=0.6340, grad=24.5821]Training epoch 10:  80%|███████▉  | 130/163 [02:25<00:34,  1.05s/it, loss=1.5852, batch_acc=0.6562, running_acc=0.6341, grad=22.9997]Training epoch 10:  80%|████████  | 131/163 [02:26<00:32,  1.00s/it, loss=1.5852, batch_acc=0.6562, running_acc=0.6341, grad=22.9997]Training epoch 10:  80%|████████  | 131/163 [02:26<00:32,  1.00s/it, loss=1.3219, batch_acc=0.7188, running_acc=0.6348, grad=16.8679]Training epoch 10:  81%|████████  | 132/163 [02:27<00:36,  1.19s/it, loss=1.3219, batch_acc=0.7188, running_acc=0.6348, grad=16.8679]Training epoch 10:  81%|████████  | 132/163 [02:27<00:36,  1.19s/it, loss=1.3674, batch_acc=0.7188, running_acc=0.6354, grad=20.8685]Training epoch 10:  82%|████████▏ | 133/163 [02:28<00:32,  1.10s/it, loss=1.3674, batch_acc=0.7188, running_acc=0.6354, grad=20.8685]Training epoch 10:  82%|████████▏ | 133/163 [02:28<00:32,  1.10s/it, loss=1.5833, batch_acc=0.5938, running_acc=0.6351, grad=24.3036]Training epoch 10:  82%|████████▏ | 134/163 [02:29<00:29,  1.03s/it, loss=1.5833, batch_acc=0.5938, running_acc=0.6351, grad=24.3036]Training epoch 10:  82%|████████▏ | 134/163 [02:29<00:29,  1.03s/it, loss=1.6123, batch_acc=0.6250, running_acc=0.6350, grad=19.1366]Training epoch 10:  83%|████████▎ | 135/163 [02:30<00:27,  1.01it/s, loss=1.6123, batch_acc=0.6250, running_acc=0.6350, grad=19.1366]Training epoch 10:  83%|████████▎ | 135/163 [02:30<00:27,  1.01it/s, loss=1.6550, batch_acc=0.6875, running_acc=0.6354, grad=18.9882]Training epoch 10:  83%|████████▎ | 136/163 [02:32<00:30,  1.13s/it, loss=1.6550, batch_acc=0.6875, running_acc=0.6354, grad=18.9882]Training epoch 10:  83%|████████▎ | 136/163 [02:32<00:30,  1.13s/it, loss=1.7727, batch_acc=0.5625, running_acc=0.6349, grad=18.5170]Training epoch 10:  84%|████████▍ | 137/163 [02:32<00:27,  1.06s/it, loss=1.7727, batch_acc=0.5625, running_acc=0.6349, grad=18.5170]Training epoch 10:  84%|████████▍ | 137/163 [02:32<00:27,  1.06s/it, loss=1.6908, batch_acc=0.5000, running_acc=0.6339, grad=20.5038]Training epoch 10:  85%|████████▍ | 138/163 [02:33<00:25,  1.00s/it, loss=1.6908, batch_acc=0.5000, running_acc=0.6339, grad=20.5038]Training epoch 10:  85%|████████▍ | 138/163 [02:33<00:25,  1.00s/it, loss=1.7885, batch_acc=0.5312, running_acc=0.6332, grad=17.9813]Training epoch 10:  85%|████████▌ | 139/163 [02:34<00:23,  1.03it/s, loss=1.7885, batch_acc=0.5312, running_acc=0.6332, grad=17.9813]Training epoch 10:  85%|████████▌ | 139/163 [02:34<00:23,  1.03it/s, loss=1.3692, batch_acc=0.6875, running_acc=0.6335, grad=22.1144]Training epoch 10:  86%|████████▌ | 140/163 [02:36<00:31,  1.36s/it, loss=1.3692, batch_acc=0.6875, running_acc=0.6335, grad=22.1144]Training epoch 10:  86%|████████▌ | 140/163 [02:36<00:31,  1.36s/it, loss=1.7304, batch_acc=0.5312, running_acc=0.6328, grad=19.5912]Training epoch 10:  87%|████████▋ | 141/163 [02:37<00:26,  1.22s/it, loss=1.7304, batch_acc=0.5312, running_acc=0.6328, grad=19.5912]Training epoch 10:  87%|████████▋ | 141/163 [02:37<00:26,  1.22s/it, loss=1.7880, batch_acc=0.5938, running_acc=0.6325, grad=29.2155]Training epoch 10:  87%|████████▋ | 142/163 [02:38<00:23,  1.12s/it, loss=1.7880, batch_acc=0.5938, running_acc=0.6325, grad=29.2155]Training epoch 10:  87%|████████▋ | 142/163 [02:38<00:23,  1.12s/it, loss=1.6337, batch_acc=0.5938, running_acc=0.6323, grad=27.3304]Training epoch 10:  88%|████████▊ | 143/163 [02:39<00:20,  1.05s/it, loss=1.6337, batch_acc=0.5938, running_acc=0.6323, grad=27.3304]Training epoch 10:  88%|████████▊ | 143/163 [02:39<00:20,  1.05s/it, loss=1.7743, batch_acc=0.5625, running_acc=0.6318, grad=24.5553]Training epoch 10:  88%|████████▊ | 144/163 [02:41<00:25,  1.34s/it, loss=1.7743, batch_acc=0.5625, running_acc=0.6318, grad=24.5553]Training epoch 10:  88%|████████▊ | 144/163 [02:41<00:25,  1.34s/it, loss=1.1988, batch_acc=0.8125, running_acc=0.6330, grad=16.1398]Training epoch 10:  89%|████████▉ | 145/163 [02:42<00:21,  1.20s/it, loss=1.1988, batch_acc=0.8125, running_acc=0.6330, grad=16.1398]Training epoch 10:  89%|████████▉ | 145/163 [02:42<00:21,  1.20s/it, loss=1.6461, batch_acc=0.5938, running_acc=0.6328, grad=22.1538]Training epoch 10:  90%|████████▉ | 146/163 [02:43<00:18,  1.10s/it, loss=1.6461, batch_acc=0.5938, running_acc=0.6328, grad=22.1538]Training epoch 10:  90%|████████▉ | 146/163 [02:43<00:18,  1.10s/it, loss=1.4870, batch_acc=0.6250, running_acc=0.6327, grad=17.3417]Training epoch 10:  90%|█████████ | 147/163 [02:44<00:16,  1.04s/it, loss=1.4870, batch_acc=0.6250, running_acc=0.6327, grad=17.3417]Training epoch 10:  90%|█████████ | 147/163 [02:44<00:16,  1.04s/it, loss=1.3547, batch_acc=0.7500, running_acc=0.6335, grad=17.6719]Training epoch 10:  91%|█████████ | 148/163 [02:46<00:19,  1.28s/it, loss=1.3547, batch_acc=0.7500, running_acc=0.6335, grad=17.6719]Training epoch 10:  91%|█████████ | 148/163 [02:46<00:19,  1.28s/it, loss=1.6677, batch_acc=0.5938, running_acc=0.6332, grad=19.7917]Training epoch 10:  91%|█████████▏| 149/163 [02:47<00:16,  1.16s/it, loss=1.6677, batch_acc=0.5938, running_acc=0.6332, grad=19.7917]Training epoch 10:  91%|█████████▏| 149/163 [02:47<00:16,  1.16s/it, loss=1.8306, batch_acc=0.5625, running_acc=0.6328, grad=22.9932]Training epoch 10:  92%|█████████▏| 150/163 [02:47<00:13,  1.07s/it, loss=1.8306, batch_acc=0.5625, running_acc=0.6328, grad=22.9932]Training epoch 10:  92%|█████████▏| 150/163 [02:47<00:13,  1.07s/it, loss=1.7368, batch_acc=0.5000, running_acc=0.6319, grad=29.5637]Training epoch 10:  93%|█████████▎| 151/163 [02:48<00:12,  1.02s/it, loss=1.7368, batch_acc=0.5000, running_acc=0.6319, grad=29.5637]Training epoch 10:  93%|█████████▎| 151/163 [02:48<00:12,  1.02s/it, loss=1.5593, batch_acc=0.7188, running_acc=0.6325, grad=19.7401]Training epoch 10:  93%|█████████▎| 152/163 [02:50<00:12,  1.13s/it, loss=1.5593, batch_acc=0.7188, running_acc=0.6325, grad=19.7401]Training epoch 10:  93%|█████████▎| 152/163 [02:50<00:12,  1.13s/it, loss=1.5512, batch_acc=0.6875, running_acc=0.6328, grad=23.9116]Training epoch 10:  94%|█████████▍| 153/163 [02:51<00:10,  1.05s/it, loss=1.5512, batch_acc=0.6875, running_acc=0.6328, grad=23.9116]Training epoch 10:  94%|█████████▍| 153/163 [02:51<00:10,  1.05s/it, loss=1.7016, batch_acc=0.5312, running_acc=0.6321, grad=19.3914]Training epoch 10:  94%|█████████▍| 154/163 [02:51<00:09,  1.00s/it, loss=1.7016, batch_acc=0.5312, running_acc=0.6321, grad=19.3914]Training epoch 10:  94%|█████████▍| 154/163 [02:51<00:09,  1.00s/it, loss=1.4986, batch_acc=0.6875, running_acc=0.6325, grad=21.8350]Training epoch 10:  95%|█████████▌| 155/163 [02:52<00:07,  1.03it/s, loss=1.4986, batch_acc=0.6875, running_acc=0.6325, grad=21.8350]Training epoch 10:  95%|█████████▌| 155/163 [02:52<00:07,  1.03it/s, loss=1.3500, batch_acc=0.7500, running_acc=0.6333, grad=25.8156]Training epoch 10:  96%|█████████▌| 156/163 [02:55<00:09,  1.36s/it, loss=1.3500, batch_acc=0.7500, running_acc=0.6333, grad=25.8156]Training epoch 10:  96%|█████████▌| 156/163 [02:55<00:09,  1.36s/it, loss=1.7191, batch_acc=0.5938, running_acc=0.6330, grad=21.6231]Training epoch 10:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=1.7191, batch_acc=0.5938, running_acc=0.6330, grad=21.6231]Training epoch 10:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=1.5175, batch_acc=0.7500, running_acc=0.6338, grad=20.3563]Training epoch 10:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=1.5175, batch_acc=0.7500, running_acc=0.6338, grad=20.3563]Training epoch 10:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=1.7753, batch_acc=0.5938, running_acc=0.6335, grad=19.5485]Training epoch 10:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=1.7753, batch_acc=0.5938, running_acc=0.6335, grad=19.5485]Training epoch 10:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=1.2305, batch_acc=0.6875, running_acc=0.6338, grad=16.6483]Training epoch 10:  98%|█████████▊| 160/163 [02:59<00:03,  1.27s/it, loss=1.2305, batch_acc=0.6875, running_acc=0.6338, grad=16.6483]Training epoch 10:  98%|█████████▊| 160/163 [02:59<00:03,  1.27s/it, loss=1.2987, batch_acc=0.6562, running_acc=0.6340, grad=20.9746]Training epoch 10:  99%|█████████▉| 161/163 [03:00<00:02,  1.15s/it, loss=1.2987, batch_acc=0.6562, running_acc=0.6340, grad=20.9746]Training epoch 10:  99%|█████████▉| 161/163 [03:00<00:02,  1.15s/it, loss=1.4798, batch_acc=0.7500, running_acc=0.6347, grad=19.7086]Training epoch 10:  99%|█████████▉| 162/163 [03:01<00:01,  1.07s/it, loss=1.4798, batch_acc=0.7500, running_acc=0.6347, grad=19.7086]Training epoch 10:  99%|█████████▉| 162/163 [03:01<00:01,  1.07s/it, loss=1.7035, batch_acc=0.5625, running_acc=0.6343, grad=19.8961]Training epoch 10: 100%|██████████| 163/163 [03:01<00:00,  1.06it/s, loss=1.7035, batch_acc=0.5625, running_acc=0.6343, grad=19.8961]Training epoch 10: 100%|██████████| 163/163 [03:01<00:00,  1.06it/s, loss=1.7359, batch_acc=0.6667, running_acc=0.6344, grad=27.6821]Training epoch 10: 100%|██████████| 163/163 [03:01<00:00,  1.12s/it, loss=1.7359, batch_acc=0.6667, running_acc=0.6344, grad=27.6821]
Evaluation epoch 10:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 10:   4%|▎         | 1/28 [00:04<02:14,  4.98s/it]Evaluation epoch 10:   4%|▎         | 1/28 [00:04<02:14,  4.98s/it, loss=1.2291, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 10:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=1.2291, batch_acc=0.7188, running_acc=0.7188]Evaluation epoch 10:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=1.3671, batch_acc=0.6250, running_acc=0.6719]Evaluation epoch 10:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=1.3671, batch_acc=0.6250, running_acc=0.6719]Evaluation epoch 10:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=1.4847, batch_acc=0.5625, running_acc=0.6354]Evaluation epoch 10:  14%|█▍        | 4/28 [00:10<01:03,  2.65s/it, loss=1.4847, batch_acc=0.5625, running_acc=0.6354]Evaluation epoch 10:  14%|█▍        | 4/28 [00:10<01:03,  2.65s/it, loss=2.4657, batch_acc=0.2500, running_acc=0.5391]Evaluation epoch 10:  18%|█▊        | 5/28 [00:10<00:41,  1.79s/it, loss=2.4657, batch_acc=0.2500, running_acc=0.5391]Evaluation epoch 10:  18%|█▊        | 5/28 [00:10<00:41,  1.79s/it, loss=2.1963, batch_acc=0.4375, running_acc=0.5188]Evaluation epoch 10:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=2.1963, batch_acc=0.4375, running_acc=0.5188]Evaluation epoch 10:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=2.0324, batch_acc=0.4062, running_acc=0.5000]Evaluation epoch 10:  25%|██▌       | 7/28 [00:10<00:19,  1.06it/s, loss=2.0324, batch_acc=0.4062, running_acc=0.5000]Evaluation epoch 10:  25%|██▌       | 7/28 [00:10<00:19,  1.06it/s, loss=1.9172, batch_acc=0.5312, running_acc=0.5045]Evaluation epoch 10:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=1.9172, batch_acc=0.5312, running_acc=0.5045]Evaluation epoch 10:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=1.5728, batch_acc=0.5938, running_acc=0.5156]Evaluation epoch 10:  32%|███▏      | 9/28 [00:14<00:24,  1.27s/it, loss=1.5728, batch_acc=0.5938, running_acc=0.5156]Evaluation epoch 10:  32%|███▏      | 9/28 [00:14<00:24,  1.27s/it, loss=2.0589, batch_acc=0.4688, running_acc=0.5104]Evaluation epoch 10:  36%|███▌      | 10/28 [00:14<00:17,  1.04it/s, loss=2.0589, batch_acc=0.4688, running_acc=0.5104]Evaluation epoch 10:  36%|███▌      | 10/28 [00:14<00:17,  1.04it/s, loss=0.8644, batch_acc=0.8750, running_acc=0.5469]Evaluation epoch 10:  39%|███▉      | 11/28 [00:15<00:12,  1.34it/s, loss=0.8644, batch_acc=0.8750, running_acc=0.5469]Evaluation epoch 10:  39%|███▉      | 11/28 [00:15<00:12,  1.34it/s, loss=1.8890, batch_acc=0.6250, running_acc=0.5540]Evaluation epoch 10:  43%|████▎     | 12/28 [00:20<00:36,  2.28s/it, loss=1.8890, batch_acc=0.6250, running_acc=0.5540]Evaluation epoch 10:  43%|████▎     | 12/28 [00:20<00:36,  2.28s/it, loss=1.9009, batch_acc=0.5312, running_acc=0.5521]Evaluation epoch 10:  46%|████▋     | 13/28 [00:21<00:25,  1.67s/it, loss=1.9009, batch_acc=0.5312, running_acc=0.5521]Evaluation epoch 10:  46%|████▋     | 13/28 [00:21<00:25,  1.67s/it, loss=1.3868, batch_acc=0.7500, running_acc=0.5673]Evaluation epoch 10:  50%|█████     | 14/28 [00:21<00:17,  1.25s/it, loss=1.3868, batch_acc=0.7500, running_acc=0.5673]Evaluation epoch 10:  50%|█████     | 14/28 [00:21<00:17,  1.25s/it, loss=2.2130, batch_acc=0.5000, running_acc=0.5625]Evaluation epoch 10:  54%|█████▎    | 15/28 [00:21<00:12,  1.05it/s, loss=2.2130, batch_acc=0.5000, running_acc=0.5625]Evaluation epoch 10:  54%|█████▎    | 15/28 [00:21<00:12,  1.05it/s, loss=2.5741, batch_acc=0.3438, running_acc=0.5479]Evaluation epoch 10:  57%|█████▋    | 16/28 [00:24<00:18,  1.58s/it, loss=2.5741, batch_acc=0.3438, running_acc=0.5479]Evaluation epoch 10:  57%|█████▋    | 16/28 [00:24<00:18,  1.58s/it, loss=1.6823, batch_acc=0.4688, running_acc=0.5430]Evaluation epoch 10:  61%|██████    | 17/28 [00:25<00:12,  1.18s/it, loss=1.6823, batch_acc=0.4688, running_acc=0.5430]Evaluation epoch 10:  61%|██████    | 17/28 [00:25<00:12,  1.18s/it, loss=1.3742, batch_acc=0.7188, running_acc=0.5533]Evaluation epoch 10:  64%|██████▍   | 18/28 [00:25<00:09,  1.10it/s, loss=1.3742, batch_acc=0.7188, running_acc=0.5533]Evaluation epoch 10:  64%|██████▍   | 18/28 [00:25<00:09,  1.10it/s, loss=1.4429, batch_acc=0.6250, running_acc=0.5573]Evaluation epoch 10:  68%|██████▊   | 19/28 [00:25<00:06,  1.40it/s, loss=1.4429, batch_acc=0.6250, running_acc=0.5573]Evaluation epoch 10:  68%|██████▊   | 19/28 [00:25<00:06,  1.40it/s, loss=1.4736, batch_acc=0.5312, running_acc=0.5559]Evaluation epoch 10:  71%|███████▏  | 20/28 [00:28<00:11,  1.42s/it, loss=1.4736, batch_acc=0.5312, running_acc=0.5559]Evaluation epoch 10:  71%|███████▏  | 20/28 [00:28<00:11,  1.42s/it, loss=1.6540, batch_acc=0.5312, running_acc=0.5547]Evaluation epoch 10:  75%|███████▌  | 21/28 [00:28<00:07,  1.08s/it, loss=1.6540, batch_acc=0.5312, running_acc=0.5547]Evaluation epoch 10:  75%|███████▌  | 21/28 [00:28<00:07,  1.08s/it, loss=2.1117, batch_acc=0.3750, running_acc=0.5461]Evaluation epoch 10:  79%|███████▊  | 22/28 [00:29<00:04,  1.20it/s, loss=2.1117, batch_acc=0.3750, running_acc=0.5461]Evaluation epoch 10:  79%|███████▊  | 22/28 [00:29<00:04,  1.20it/s, loss=2.0555, batch_acc=0.5000, running_acc=0.5440]Evaluation epoch 10:  82%|████████▏ | 23/28 [00:29<00:03,  1.51it/s, loss=2.0555, batch_acc=0.5000, running_acc=0.5440]Evaluation epoch 10:  82%|████████▏ | 23/28 [00:29<00:03,  1.51it/s, loss=1.7352, batch_acc=0.5938, running_acc=0.5462]Evaluation epoch 10:  86%|████████▌ | 24/28 [00:35<00:08,  2.15s/it, loss=1.7352, batch_acc=0.5938, running_acc=0.5462]Evaluation epoch 10:  86%|████████▌ | 24/28 [00:35<00:08,  2.15s/it, loss=0.8745, batch_acc=0.9062, running_acc=0.5612]Evaluation epoch 10:  89%|████████▉ | 25/28 [00:35<00:04,  1.59s/it, loss=0.8745, batch_acc=0.9062, running_acc=0.5612]Evaluation epoch 10:  89%|████████▉ | 25/28 [00:35<00:04,  1.59s/it, loss=1.1039, batch_acc=0.7188, running_acc=0.5675]Evaluation epoch 10:  93%|█████████▎| 26/28 [00:35<00:02,  1.19s/it, loss=1.1039, batch_acc=0.7188, running_acc=0.5675]Evaluation epoch 10:  93%|█████████▎| 26/28 [00:35<00:02,  1.19s/it, loss=1.6243, batch_acc=0.4688, running_acc=0.5637]Evaluation epoch 10:  96%|█████████▋| 27/28 [00:35<00:00,  1.10it/s, loss=1.6243, batch_acc=0.4688, running_acc=0.5637]Evaluation epoch 10:  96%|█████████▋| 27/28 [00:35<00:00,  1.10it/s, loss=1.5710, batch_acc=0.5000, running_acc=0.5613]Evaluation epoch 10: 100%|██████████| 28/28 [00:35<00:00,  1.10it/s, loss=1.0640, batch_acc=0.6667, running_acc=0.5617]Evaluation epoch 10: 100%|██████████| 28/28 [00:35<00:00,  1.28s/it, loss=1.0640, batch_acc=0.6667, running_acc=0.5617]
Training epoch 11:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 11:   1%|          | 1/163 [00:05<15:04,  5.58s/it]Training epoch 11:   1%|          | 1/163 [00:05<15:04,  5.58s/it, loss=1.3133, batch_acc=0.7500, running_acc=0.7500, grad=15.6461]Training epoch 11:   1%|          | 2/163 [00:06<07:33,  2.82s/it, loss=1.3133, batch_acc=0.7500, running_acc=0.7500, grad=15.6461]Training epoch 11:   1%|          | 2/163 [00:06<07:33,  2.82s/it, loss=1.5349, batch_acc=0.5625, running_acc=0.6562, grad=17.1922]Training epoch 11:   2%|▏         | 3/163 [00:07<05:08,  1.93s/it, loss=1.5349, batch_acc=0.5625, running_acc=0.6562, grad=17.1922]Training epoch 11:   2%|▏         | 3/163 [00:07<05:08,  1.93s/it, loss=1.4389, batch_acc=0.6562, running_acc=0.6562, grad=22.3277]Training epoch 11:   2%|▏         | 4/163 [00:10<06:08,  2.32s/it, loss=1.4389, batch_acc=0.6562, running_acc=0.6562, grad=22.3277]Training epoch 11:   2%|▏         | 4/163 [00:10<06:08,  2.32s/it, loss=1.6037, batch_acc=0.5312, running_acc=0.6250, grad=21.5686]Training epoch 11:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=1.6037, batch_acc=0.5312, running_acc=0.6250, grad=21.5686]Training epoch 11:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=1.6574, batch_acc=0.6562, running_acc=0.6312, grad=22.2667]Training epoch 11:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=1.6574, batch_acc=0.6562, running_acc=0.6312, grad=22.2667]Training epoch 11:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=1.6116, batch_acc=0.6562, running_acc=0.6354, grad=25.1551]Training epoch 11:   4%|▍         | 7/163 [00:12<03:20,  1.29s/it, loss=1.6116, batch_acc=0.6562, running_acc=0.6354, grad=25.1551]Training epoch 11:   4%|▍         | 7/163 [00:12<03:20,  1.29s/it, loss=1.1590, batch_acc=0.7812, running_acc=0.6562, grad=19.0761]Training epoch 11:   5%|▍         | 8/163 [00:14<03:45,  1.46s/it, loss=1.1590, batch_acc=0.7812, running_acc=0.6562, grad=19.0761]Training epoch 11:   5%|▍         | 8/163 [00:14<03:45,  1.46s/it, loss=1.7630, batch_acc=0.5000, running_acc=0.6367, grad=17.2198]Training epoch 11:   6%|▌         | 9/163 [00:15<03:16,  1.28s/it, loss=1.7630, batch_acc=0.5000, running_acc=0.6367, grad=17.2198]Training epoch 11:   6%|▌         | 9/163 [00:15<03:16,  1.28s/it, loss=1.5721, batch_acc=0.6875, running_acc=0.6424, grad=23.3033]Training epoch 11:   6%|▌         | 10/163 [00:16<02:56,  1.15s/it, loss=1.5721, batch_acc=0.6875, running_acc=0.6424, grad=23.3033]Training epoch 11:   6%|▌         | 10/163 [00:16<02:56,  1.15s/it, loss=1.2488, batch_acc=0.7812, running_acc=0.6562, grad=17.5047]Training epoch 11:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=1.2488, batch_acc=0.7812, running_acc=0.6562, grad=17.5047]Training epoch 11:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=1.6698, batch_acc=0.5625, running_acc=0.6477, grad=29.7608]Training epoch 11:   7%|▋         | 12/163 [00:19<03:09,  1.26s/it, loss=1.6698, batch_acc=0.5625, running_acc=0.6477, grad=29.7608]Training epoch 11:   7%|▋         | 12/163 [00:19<03:09,  1.26s/it, loss=1.2599, batch_acc=0.6875, running_acc=0.6510, grad=18.5140]Training epoch 11:   8%|▊         | 13/163 [00:19<02:51,  1.14s/it, loss=1.2599, batch_acc=0.6875, running_acc=0.6510, grad=18.5140]Training epoch 11:   8%|▊         | 13/163 [00:19<02:51,  1.14s/it, loss=1.2861, batch_acc=0.7812, running_acc=0.6611, grad=14.7124]Training epoch 11:   9%|▊         | 14/163 [00:20<02:38,  1.06s/it, loss=1.2861, batch_acc=0.7812, running_acc=0.6611, grad=14.7124]Training epoch 11:   9%|▊         | 14/163 [00:20<02:38,  1.06s/it, loss=1.3874, batch_acc=0.7188, running_acc=0.6652, grad=20.1519]Training epoch 11:   9%|▉         | 15/163 [00:21<02:29,  1.01s/it, loss=1.3874, batch_acc=0.7188, running_acc=0.6652, grad=20.1519]Training epoch 11:   9%|▉         | 15/163 [00:21<02:29,  1.01s/it, loss=1.2933, batch_acc=0.8125, running_acc=0.6750, grad=20.4349]Training epoch 11:  10%|▉         | 16/163 [00:23<03:13,  1.32s/it, loss=1.2933, batch_acc=0.8125, running_acc=0.6750, grad=20.4349]Training epoch 11:  10%|▉         | 16/163 [00:23<03:13,  1.32s/it, loss=1.5278, batch_acc=0.6875, running_acc=0.6758, grad=20.8269]Training epoch 11:  10%|█         | 17/163 [00:24<02:52,  1.18s/it, loss=1.5278, batch_acc=0.6875, running_acc=0.6758, grad=20.8269]Training epoch 11:  10%|█         | 17/163 [00:24<02:52,  1.18s/it, loss=1.4153, batch_acc=0.7500, running_acc=0.6801, grad=19.3427]Training epoch 11:  11%|█         | 18/163 [00:25<02:38,  1.09s/it, loss=1.4153, batch_acc=0.7500, running_acc=0.6801, grad=19.3427]Training epoch 11:  11%|█         | 18/163 [00:25<02:38,  1.09s/it, loss=1.5780, batch_acc=0.5938, running_acc=0.6753, grad=23.5107]Training epoch 11:  12%|█▏        | 19/163 [00:26<02:28,  1.03s/it, loss=1.5780, batch_acc=0.5938, running_acc=0.6753, grad=23.5107]Training epoch 11:  12%|█▏        | 19/163 [00:26<02:28,  1.03s/it, loss=1.6764, batch_acc=0.5000, running_acc=0.6661, grad=21.9479]Training epoch 11:  12%|█▏        | 20/163 [00:28<02:56,  1.23s/it, loss=1.6764, batch_acc=0.5000, running_acc=0.6661, grad=21.9479]Training epoch 11:  12%|█▏        | 20/163 [00:28<02:56,  1.23s/it, loss=1.4258, batch_acc=0.7500, running_acc=0.6703, grad=25.4775]Training epoch 11:  13%|█▎        | 21/163 [00:28<02:40,  1.13s/it, loss=1.4258, batch_acc=0.7500, running_acc=0.6703, grad=25.4775]Training epoch 11:  13%|█▎        | 21/163 [00:28<02:40,  1.13s/it, loss=1.3162, batch_acc=0.7188, running_acc=0.6726, grad=15.1982]Training epoch 11:  13%|█▎        | 22/163 [00:29<02:28,  1.05s/it, loss=1.3162, batch_acc=0.7188, running_acc=0.6726, grad=15.1982]Training epoch 11:  13%|█▎        | 22/163 [00:29<02:28,  1.05s/it, loss=1.3777, batch_acc=0.6875, running_acc=0.6733, grad=20.5978]Training epoch 11:  14%|█▍        | 23/163 [00:30<02:20,  1.00s/it, loss=1.3777, batch_acc=0.6875, running_acc=0.6733, grad=20.5978]Training epoch 11:  14%|█▍        | 23/163 [00:30<02:20,  1.00s/it, loss=1.3108, batch_acc=0.6875, running_acc=0.6739, grad=21.8350]Training epoch 11:  15%|█▍        | 24/163 [00:32<03:07,  1.35s/it, loss=1.3108, batch_acc=0.6875, running_acc=0.6739, grad=21.8350]Training epoch 11:  15%|█▍        | 24/163 [00:32<03:07,  1.35s/it, loss=1.2759, batch_acc=0.8125, running_acc=0.6797, grad=33.4288]Training epoch 11:  15%|█▌        | 25/163 [00:33<02:46,  1.21s/it, loss=1.2759, batch_acc=0.8125, running_acc=0.6797, grad=33.4288]Training epoch 11:  15%|█▌        | 25/163 [00:33<02:46,  1.21s/it, loss=1.3804, batch_acc=0.6875, running_acc=0.6800, grad=36.6282]Training epoch 11:  16%|█▌        | 26/163 [00:34<02:31,  1.11s/it, loss=1.3804, batch_acc=0.6875, running_acc=0.6800, grad=36.6282]Training epoch 11:  16%|█▌        | 26/163 [00:34<02:31,  1.11s/it, loss=1.5717, batch_acc=0.5625, running_acc=0.6755, grad=18.0168]Training epoch 11:  17%|█▋        | 27/163 [00:35<02:21,  1.04s/it, loss=1.5717, batch_acc=0.5625, running_acc=0.6755, grad=18.0168]Training epoch 11:  17%|█▋        | 27/163 [00:35<02:21,  1.04s/it, loss=1.3907, batch_acc=0.6875, running_acc=0.6759, grad=26.1618]Training epoch 11:  17%|█▋        | 28/163 [00:37<02:56,  1.31s/it, loss=1.3907, batch_acc=0.6875, running_acc=0.6759, grad=26.1618]Training epoch 11:  17%|█▋        | 28/163 [00:37<02:56,  1.31s/it, loss=1.5421, batch_acc=0.7500, running_acc=0.6786, grad=23.0427]Training epoch 11:  18%|█▊        | 29/163 [00:38<02:37,  1.18s/it, loss=1.5421, batch_acc=0.7500, running_acc=0.6786, grad=23.0427]Training epoch 11:  18%|█▊        | 29/163 [00:38<02:37,  1.18s/it, loss=1.4626, batch_acc=0.6875, running_acc=0.6789, grad=21.9122]Training epoch 11:  18%|█▊        | 30/163 [00:39<02:24,  1.09s/it, loss=1.4626, batch_acc=0.6875, running_acc=0.6789, grad=21.9122]Training epoch 11:  18%|█▊        | 30/163 [00:39<02:24,  1.09s/it, loss=1.5774, batch_acc=0.6250, running_acc=0.6771, grad=23.2565]Training epoch 11:  19%|█▉        | 31/163 [00:40<02:15,  1.02s/it, loss=1.5774, batch_acc=0.6250, running_acc=0.6771, grad=23.2565]Training epoch 11:  19%|█▉        | 31/163 [00:40<02:15,  1.02s/it, loss=1.3246, batch_acc=0.6875, running_acc=0.6774, grad=14.1934]Training epoch 11:  20%|█▉        | 32/163 [00:41<02:32,  1.16s/it, loss=1.3246, batch_acc=0.6875, running_acc=0.6774, grad=14.1934]Training epoch 11:  20%|█▉        | 32/163 [00:41<02:32,  1.16s/it, loss=1.3295, batch_acc=0.8125, running_acc=0.6816, grad=21.8556]Training epoch 11:  20%|██        | 33/163 [00:42<02:20,  1.08s/it, loss=1.3295, batch_acc=0.8125, running_acc=0.6816, grad=21.8556]Training epoch 11:  20%|██        | 33/163 [00:42<02:20,  1.08s/it, loss=1.7826, batch_acc=0.5625, running_acc=0.6780, grad=25.1150]Training epoch 11:  21%|██        | 34/163 [00:43<02:11,  1.02s/it, loss=1.7826, batch_acc=0.5625, running_acc=0.6780, grad=25.1150]Training epoch 11:  21%|██        | 34/163 [00:43<02:11,  1.02s/it, loss=1.1793, batch_acc=0.8125, running_acc=0.6820, grad=21.2392]Training epoch 11:  21%|██▏       | 35/163 [00:44<02:04,  1.02it/s, loss=1.1793, batch_acc=0.8125, running_acc=0.6820, grad=21.2392]Training epoch 11:  21%|██▏       | 35/163 [00:44<02:04,  1.02it/s, loss=1.5445, batch_acc=0.6562, running_acc=0.6813, grad=22.3348]Training epoch 11:  22%|██▏       | 36/163 [00:46<03:00,  1.42s/it, loss=1.5445, batch_acc=0.6562, running_acc=0.6813, grad=22.3348]Training epoch 11:  22%|██▏       | 36/163 [00:46<03:00,  1.42s/it, loss=1.4334, batch_acc=0.6250, running_acc=0.6797, grad=18.5003]Training epoch 11:  23%|██▎       | 37/163 [00:47<02:38,  1.26s/it, loss=1.4334, batch_acc=0.6250, running_acc=0.6797, grad=18.5003]Training epoch 11:  23%|██▎       | 37/163 [00:47<02:38,  1.26s/it, loss=1.0183, batch_acc=0.8750, running_acc=0.6850, grad=14.0860]Training epoch 11:  23%|██▎       | 38/163 [00:48<02:22,  1.14s/it, loss=1.0183, batch_acc=0.8750, running_acc=0.6850, grad=14.0860]Training epoch 11:  23%|██▎       | 38/163 [00:48<02:22,  1.14s/it, loss=1.3810, batch_acc=0.6875, running_acc=0.6850, grad=18.3402]Training epoch 11:  24%|██▍       | 39/163 [00:49<02:11,  1.06s/it, loss=1.3810, batch_acc=0.6875, running_acc=0.6850, grad=18.3402]Training epoch 11:  24%|██▍       | 39/163 [00:49<02:11,  1.06s/it, loss=1.7336, batch_acc=0.5312, running_acc=0.6811, grad=24.5750]Training epoch 11:  25%|██▍       | 40/163 [00:50<02:31,  1.23s/it, loss=1.7336, batch_acc=0.5312, running_acc=0.6811, grad=24.5750]Training epoch 11:  25%|██▍       | 40/163 [00:50<02:31,  1.23s/it, loss=1.1375, batch_acc=0.7812, running_acc=0.6836, grad=16.5001]Training epoch 11:  25%|██▌       | 41/163 [00:51<02:17,  1.13s/it, loss=1.1375, batch_acc=0.7812, running_acc=0.6836, grad=16.5001]Training epoch 11:  25%|██▌       | 41/163 [00:51<02:17,  1.13s/it, loss=1.6920, batch_acc=0.4688, running_acc=0.6784, grad=23.7099]Training epoch 11:  26%|██▌       | 42/163 [00:52<02:07,  1.05s/it, loss=1.6920, batch_acc=0.4688, running_acc=0.6784, grad=23.7099]Training epoch 11:  26%|██▌       | 42/163 [00:52<02:07,  1.05s/it, loss=1.4279, batch_acc=0.5625, running_acc=0.6756, grad=21.5912]Training epoch 11:  26%|██▋       | 43/163 [00:53<01:59,  1.00it/s, loss=1.4279, batch_acc=0.5625, running_acc=0.6756, grad=21.5912]Training epoch 11:  26%|██▋       | 43/163 [00:53<01:59,  1.00it/s, loss=1.2891, batch_acc=0.6875, running_acc=0.6759, grad=21.5871]Training epoch 11:  27%|██▋       | 44/163 [00:55<02:27,  1.24s/it, loss=1.2891, batch_acc=0.6875, running_acc=0.6759, grad=21.5871]Training epoch 11:  27%|██▋       | 44/163 [00:55<02:27,  1.24s/it, loss=1.5503, batch_acc=0.6250, running_acc=0.6747, grad=25.5627]Training epoch 11:  28%|██▊       | 45/163 [00:56<02:13,  1.13s/it, loss=1.5503, batch_acc=0.6250, running_acc=0.6747, grad=25.5627]Training epoch 11:  28%|██▊       | 45/163 [00:56<02:13,  1.13s/it, loss=1.3006, batch_acc=0.7500, running_acc=0.6764, grad=20.8283]Training epoch 11:  28%|██▊       | 46/163 [00:57<02:03,  1.05s/it, loss=1.3006, batch_acc=0.7500, running_acc=0.6764, grad=20.8283]Training epoch 11:  28%|██▊       | 46/163 [00:57<02:03,  1.05s/it, loss=1.4666, batch_acc=0.6250, running_acc=0.6753, grad=17.0608]Training epoch 11:  29%|██▉       | 47/163 [00:57<01:56,  1.00s/it, loss=1.4666, batch_acc=0.6250, running_acc=0.6753, grad=17.0608]Training epoch 11:  29%|██▉       | 47/163 [00:57<01:56,  1.00s/it, loss=1.1465, batch_acc=0.7812, running_acc=0.6775, grad=17.0657]Training epoch 11:  29%|██▉       | 48/163 [01:00<02:32,  1.32s/it, loss=1.1465, batch_acc=0.7812, running_acc=0.6775, grad=17.0657]Training epoch 11:  29%|██▉       | 48/163 [01:00<02:32,  1.32s/it, loss=1.7337, batch_acc=0.5938, running_acc=0.6758, grad=22.1886]Training epoch 11:  30%|███       | 49/163 [01:00<02:15,  1.19s/it, loss=1.7337, batch_acc=0.5938, running_acc=0.6758, grad=22.1886]Training epoch 11:  30%|███       | 49/163 [01:00<02:15,  1.19s/it, loss=1.4444, batch_acc=0.6562, running_acc=0.6754, grad=20.0998]Training epoch 11:  31%|███       | 50/163 [01:01<02:03,  1.10s/it, loss=1.4444, batch_acc=0.6562, running_acc=0.6754, grad=20.0998]Training epoch 11:  31%|███       | 50/163 [01:01<02:03,  1.10s/it, loss=1.5399, batch_acc=0.5938, running_acc=0.6737, grad=15.6716]Training epoch 11:  31%|███▏      | 51/163 [01:02<01:55,  1.03s/it, loss=1.5399, batch_acc=0.5938, running_acc=0.6737, grad=15.6716]Training epoch 11:  31%|███▏      | 51/163 [01:02<01:55,  1.03s/it, loss=1.6623, batch_acc=0.5938, running_acc=0.6722, grad=20.9178]Training epoch 11:  32%|███▏      | 52/163 [01:04<02:21,  1.27s/it, loss=1.6623, batch_acc=0.5938, running_acc=0.6722, grad=20.9178]Training epoch 11:  32%|███▏      | 52/163 [01:04<02:21,  1.27s/it, loss=1.6250, batch_acc=0.5938, running_acc=0.6707, grad=18.8092]Training epoch 11:  33%|███▎      | 53/163 [01:05<02:06,  1.15s/it, loss=1.6250, batch_acc=0.5938, running_acc=0.6707, grad=18.8092]Training epoch 11:  33%|███▎      | 53/163 [01:05<02:06,  1.15s/it, loss=1.4139, batch_acc=0.6250, running_acc=0.6698, grad=16.8791]Training epoch 11:  33%|███▎      | 54/163 [01:06<01:56,  1.07s/it, loss=1.4139, batch_acc=0.6250, running_acc=0.6698, grad=16.8791]Training epoch 11:  33%|███▎      | 54/163 [01:06<01:56,  1.07s/it, loss=1.7541, batch_acc=0.5000, running_acc=0.6667, grad=22.4243]Training epoch 11:  34%|███▎      | 55/163 [01:07<01:49,  1.01s/it, loss=1.7541, batch_acc=0.5000, running_acc=0.6667, grad=22.4243]Training epoch 11:  34%|███▎      | 55/163 [01:07<01:49,  1.01s/it, loss=1.5348, batch_acc=0.6875, running_acc=0.6670, grad=21.7632]Training epoch 11:  34%|███▍      | 56/163 [01:09<02:26,  1.37s/it, loss=1.5348, batch_acc=0.6875, running_acc=0.6670, grad=21.7632]Training epoch 11:  34%|███▍      | 56/163 [01:09<02:26,  1.37s/it, loss=1.4213, batch_acc=0.6875, running_acc=0.6674, grad=27.4309]Training epoch 11:  35%|███▍      | 57/163 [01:10<02:09,  1.22s/it, loss=1.4213, batch_acc=0.6875, running_acc=0.6674, grad=27.4309]Training epoch 11:  35%|███▍      | 57/163 [01:10<02:09,  1.22s/it, loss=1.3623, batch_acc=0.6562, running_acc=0.6672, grad=26.9028]Training epoch 11:  36%|███▌      | 58/163 [01:11<01:57,  1.12s/it, loss=1.3623, batch_acc=0.6562, running_acc=0.6672, grad=26.9028]Training epoch 11:  36%|███▌      | 58/163 [01:11<01:57,  1.12s/it, loss=1.4025, batch_acc=0.6562, running_acc=0.6670, grad=22.4853]Training epoch 11:  36%|███▌      | 59/163 [01:11<01:48,  1.05s/it, loss=1.4025, batch_acc=0.6562, running_acc=0.6670, grad=22.4853]Training epoch 11:  36%|███▌      | 59/163 [01:11<01:48,  1.05s/it, loss=1.4901, batch_acc=0.6875, running_acc=0.6674, grad=22.5527]Training epoch 11:  37%|███▋      | 60/163 [01:13<02:07,  1.24s/it, loss=1.4901, batch_acc=0.6875, running_acc=0.6674, grad=22.5527]Training epoch 11:  37%|███▋      | 60/163 [01:13<02:07,  1.24s/it, loss=1.7101, batch_acc=0.6250, running_acc=0.6667, grad=24.3412]Training epoch 11:  37%|███▋      | 61/163 [01:14<01:55,  1.13s/it, loss=1.7101, batch_acc=0.6250, running_acc=0.6667, grad=24.3412]Training epoch 11:  37%|███▋      | 61/163 [01:14<01:55,  1.13s/it, loss=1.1918, batch_acc=0.7812, running_acc=0.6685, grad=16.1455]Training epoch 11:  38%|███▊      | 62/163 [01:15<01:46,  1.05s/it, loss=1.1918, batch_acc=0.7812, running_acc=0.6685, grad=16.1455]Training epoch 11:  38%|███▊      | 62/163 [01:15<01:46,  1.05s/it, loss=1.6503, batch_acc=0.5625, running_acc=0.6668, grad=17.4627]Training epoch 11:  39%|███▊      | 63/163 [01:16<01:40,  1.00s/it, loss=1.6503, batch_acc=0.5625, running_acc=0.6668, grad=17.4627]Training epoch 11:  39%|███▊      | 63/163 [01:16<01:40,  1.00s/it, loss=1.3567, batch_acc=0.6875, running_acc=0.6672, grad=21.3771]Training epoch 11:  39%|███▉      | 64/163 [01:17<02:00,  1.21s/it, loss=1.3567, batch_acc=0.6875, running_acc=0.6672, grad=21.3771]Training epoch 11:  39%|███▉      | 64/163 [01:17<02:00,  1.21s/it, loss=2.0047, batch_acc=0.5312, running_acc=0.6650, grad=28.8759]Training epoch 11:  40%|███▉      | 65/163 [01:18<01:49,  1.11s/it, loss=2.0047, batch_acc=0.5312, running_acc=0.6650, grad=28.8759]Training epoch 11:  40%|███▉      | 65/163 [01:18<01:49,  1.11s/it, loss=1.1864, batch_acc=0.7500, running_acc=0.6663, grad=16.8539]Training epoch 11:  40%|████      | 66/163 [01:19<01:41,  1.04s/it, loss=1.1864, batch_acc=0.7500, running_acc=0.6663, grad=16.8539]Training epoch 11:  40%|████      | 66/163 [01:19<01:41,  1.04s/it, loss=1.6649, batch_acc=0.5938, running_acc=0.6652, grad=20.3779]Training epoch 11:  41%|████      | 67/163 [01:20<01:35,  1.01it/s, loss=1.6649, batch_acc=0.5938, running_acc=0.6652, grad=20.3779]Training epoch 11:  41%|████      | 67/163 [01:20<01:35,  1.01it/s, loss=1.6350, batch_acc=0.5625, running_acc=0.6637, grad=19.1970]Training epoch 11:  42%|████▏     | 68/163 [01:22<01:52,  1.18s/it, loss=1.6350, batch_acc=0.5625, running_acc=0.6637, grad=19.1970]Training epoch 11:  42%|████▏     | 68/163 [01:22<01:52,  1.18s/it, loss=1.5016, batch_acc=0.6562, running_acc=0.6636, grad=22.6524]Training epoch 11:  42%|████▏     | 69/163 [01:23<01:42,  1.09s/it, loss=1.5016, batch_acc=0.6562, running_acc=0.6636, grad=22.6524]Training epoch 11:  42%|████▏     | 69/163 [01:23<01:42,  1.09s/it, loss=1.3243, batch_acc=0.7500, running_acc=0.6649, grad=25.9184]Training epoch 11:  43%|████▎     | 70/163 [01:23<01:35,  1.03s/it, loss=1.3243, batch_acc=0.7500, running_acc=0.6649, grad=25.9184]Training epoch 11:  43%|████▎     | 70/163 [01:23<01:35,  1.03s/it, loss=1.7141, batch_acc=0.5938, running_acc=0.6638, grad=22.1297]Training epoch 11:  44%|████▎     | 71/163 [01:24<01:30,  1.02it/s, loss=1.7141, batch_acc=0.5938, running_acc=0.6638, grad=22.1297]Training epoch 11:  44%|████▎     | 71/163 [01:24<01:30,  1.02it/s, loss=1.6573, batch_acc=0.6875, running_acc=0.6642, grad=22.6573]Training epoch 11:  44%|████▍     | 72/163 [01:26<01:59,  1.31s/it, loss=1.6573, batch_acc=0.6875, running_acc=0.6642, grad=22.6573]Training epoch 11:  44%|████▍     | 72/163 [01:26<01:59,  1.31s/it, loss=1.2660, batch_acc=0.7500, running_acc=0.6654, grad=18.9760]Training epoch 11:  45%|████▍     | 73/163 [01:27<01:46,  1.18s/it, loss=1.2660, batch_acc=0.7500, running_acc=0.6654, grad=18.9760]Training epoch 11:  45%|████▍     | 73/163 [01:27<01:46,  1.18s/it, loss=1.3301, batch_acc=0.7188, running_acc=0.6661, grad=18.4968]Training epoch 11:  45%|████▌     | 74/163 [01:28<01:37,  1.09s/it, loss=1.3301, batch_acc=0.7188, running_acc=0.6661, grad=18.4968]Training epoch 11:  45%|████▌     | 74/163 [01:28<01:37,  1.09s/it, loss=1.0471, batch_acc=0.8438, running_acc=0.6685, grad=19.9992]Training epoch 11:  46%|████▌     | 75/163 [01:29<01:30,  1.03s/it, loss=1.0471, batch_acc=0.8438, running_acc=0.6685, grad=19.9992]Training epoch 11:  46%|████▌     | 75/163 [01:29<01:30,  1.03s/it, loss=1.5299, batch_acc=0.6250, running_acc=0.6679, grad=19.5235]Training epoch 11:  47%|████▋     | 76/163 [01:31<01:50,  1.28s/it, loss=1.5299, batch_acc=0.6250, running_acc=0.6679, grad=19.5235]Training epoch 11:  47%|████▋     | 76/163 [01:31<01:50,  1.28s/it, loss=1.4174, batch_acc=0.6250, running_acc=0.6674, grad=21.6880]Training epoch 11:  47%|████▋     | 77/163 [01:32<01:39,  1.16s/it, loss=1.4174, batch_acc=0.6250, running_acc=0.6674, grad=21.6880]Training epoch 11:  47%|████▋     | 77/163 [01:32<01:39,  1.16s/it, loss=1.4841, batch_acc=0.6875, running_acc=0.6676, grad=28.6727]Training epoch 11:  48%|████▊     | 78/163 [01:33<01:31,  1.07s/it, loss=1.4841, batch_acc=0.6875, running_acc=0.6676, grad=28.6727]Training epoch 11:  48%|████▊     | 78/163 [01:33<01:31,  1.07s/it, loss=1.8254, batch_acc=0.6250, running_acc=0.6671, grad=25.7603]Training epoch 11:  48%|████▊     | 79/163 [01:34<01:25,  1.01s/it, loss=1.8254, batch_acc=0.6250, running_acc=0.6671, grad=25.7603]Training epoch 11:  48%|████▊     | 79/163 [01:34<01:25,  1.01s/it, loss=1.5703, batch_acc=0.7188, running_acc=0.6677, grad=26.4747]Training epoch 11:  49%|████▉     | 80/163 [01:36<01:48,  1.31s/it, loss=1.5703, batch_acc=0.7188, running_acc=0.6677, grad=26.4747]Training epoch 11:  49%|████▉     | 80/163 [01:36<01:48,  1.31s/it, loss=1.4241, batch_acc=0.7188, running_acc=0.6684, grad=21.3141]Training epoch 11:  50%|████▉     | 81/163 [01:36<01:36,  1.18s/it, loss=1.4241, batch_acc=0.7188, running_acc=0.6684, grad=21.3141]Training epoch 11:  50%|████▉     | 81/163 [01:36<01:36,  1.18s/it, loss=1.4562, batch_acc=0.5312, running_acc=0.6667, grad=22.3630]Training epoch 11:  50%|█████     | 82/163 [01:37<01:28,  1.09s/it, loss=1.4562, batch_acc=0.5312, running_acc=0.6667, grad=22.3630]Training epoch 11:  50%|█████     | 82/163 [01:37<01:28,  1.09s/it, loss=1.5533, batch_acc=0.6562, running_acc=0.6665, grad=21.2226]Training epoch 11:  51%|█████     | 83/163 [01:38<01:22,  1.03s/it, loss=1.5533, batch_acc=0.6562, running_acc=0.6665, grad=21.2226]Training epoch 11:  51%|█████     | 83/163 [01:38<01:22,  1.03s/it, loss=1.5619, batch_acc=0.7188, running_acc=0.6672, grad=17.6153]Training epoch 11:  52%|█████▏    | 84/163 [01:40<01:41,  1.29s/it, loss=1.5619, batch_acc=0.7188, running_acc=0.6672, grad=17.6153]Training epoch 11:  52%|█████▏    | 84/163 [01:40<01:41,  1.29s/it, loss=1.3596, batch_acc=0.6562, running_acc=0.6670, grad=20.7364]Training epoch 11:  52%|█████▏    | 85/163 [01:41<01:30,  1.17s/it, loss=1.3596, batch_acc=0.6562, running_acc=0.6670, grad=20.7364]Training epoch 11:  52%|█████▏    | 85/163 [01:41<01:30,  1.17s/it, loss=1.6185, batch_acc=0.5625, running_acc=0.6658, grad=20.8543]Training epoch 11:  53%|█████▎    | 86/163 [01:42<01:23,  1.08s/it, loss=1.6185, batch_acc=0.5625, running_acc=0.6658, grad=20.8543]Training epoch 11:  53%|█████▎    | 86/163 [01:42<01:23,  1.08s/it, loss=1.7515, batch_acc=0.5625, running_acc=0.6646, grad=25.3396]Training epoch 11:  53%|█████▎    | 87/163 [01:43<01:17,  1.02s/it, loss=1.7515, batch_acc=0.5625, running_acc=0.6646, grad=25.3396]Training epoch 11:  53%|█████▎    | 87/163 [01:43<01:17,  1.02s/it, loss=1.2838, batch_acc=0.7500, running_acc=0.6656, grad=23.0942]Training epoch 11:  54%|█████▍    | 88/163 [01:45<01:39,  1.33s/it, loss=1.2838, batch_acc=0.7500, running_acc=0.6656, grad=23.0942]Training epoch 11:  54%|█████▍    | 88/163 [01:45<01:39,  1.33s/it, loss=1.2366, batch_acc=0.7812, running_acc=0.6669, grad=19.6639]Training epoch 11:  55%|█████▍    | 89/163 [01:46<01:28,  1.19s/it, loss=1.2366, batch_acc=0.7812, running_acc=0.6669, grad=19.6639]Training epoch 11:  55%|█████▍    | 89/163 [01:46<01:28,  1.19s/it, loss=1.5117, batch_acc=0.6250, running_acc=0.6664, grad=23.2504]Training epoch 11:  55%|█████▌    | 90/163 [01:47<01:20,  1.10s/it, loss=1.5117, batch_acc=0.6250, running_acc=0.6664, grad=23.2504]Training epoch 11:  55%|█████▌    | 90/163 [01:47<01:20,  1.10s/it, loss=1.5288, batch_acc=0.6562, running_acc=0.6663, grad=23.0295]Training epoch 11:  56%|█████▌    | 91/163 [01:47<01:14,  1.03s/it, loss=1.5288, batch_acc=0.6562, running_acc=0.6663, grad=23.0295]Training epoch 11:  56%|█████▌    | 91/163 [01:47<01:14,  1.03s/it, loss=1.6599, batch_acc=0.5625, running_acc=0.6652, grad=16.1349]Training epoch 11:  56%|█████▋    | 92/163 [01:49<01:33,  1.32s/it, loss=1.6599, batch_acc=0.5625, running_acc=0.6652, grad=16.1349]Training epoch 11:  56%|█████▋    | 92/163 [01:49<01:33,  1.32s/it, loss=1.0990, batch_acc=0.7188, running_acc=0.6658, grad=18.8241]Training epoch 11:  57%|█████▋    | 93/163 [01:50<01:23,  1.19s/it, loss=1.0990, batch_acc=0.7188, running_acc=0.6658, grad=18.8241]Training epoch 11:  57%|█████▋    | 93/163 [01:50<01:23,  1.19s/it, loss=1.4738, batch_acc=0.5625, running_acc=0.6647, grad=24.8299]Training epoch 11:  58%|█████▊    | 94/163 [01:51<01:15,  1.10s/it, loss=1.4738, batch_acc=0.5625, running_acc=0.6647, grad=24.8299]Training epoch 11:  58%|█████▊    | 94/163 [01:51<01:15,  1.10s/it, loss=1.2144, batch_acc=0.7500, running_acc=0.6656, grad=18.4444]Training epoch 11:  58%|█████▊    | 95/163 [01:52<01:10,  1.03s/it, loss=1.2144, batch_acc=0.7500, running_acc=0.6656, grad=18.4444]Training epoch 11:  58%|█████▊    | 95/163 [01:52<01:10,  1.03s/it, loss=1.3098, batch_acc=0.6562, running_acc=0.6655, grad=24.5457]Training epoch 11:  59%|█████▉    | 96/163 [01:54<01:23,  1.25s/it, loss=1.3098, batch_acc=0.6562, running_acc=0.6655, grad=24.5457]Training epoch 11:  59%|█████▉    | 96/163 [01:54<01:23,  1.25s/it, loss=1.4332, batch_acc=0.6562, running_acc=0.6654, grad=19.8994]Training epoch 11:  60%|█████▉    | 97/163 [01:55<01:15,  1.14s/it, loss=1.4332, batch_acc=0.6562, running_acc=0.6654, grad=19.8994]Training epoch 11:  60%|█████▉    | 97/163 [01:55<01:15,  1.14s/it, loss=1.3556, batch_acc=0.6250, running_acc=0.6649, grad=21.2832]Training epoch 11:  60%|██████    | 98/163 [01:56<01:08,  1.06s/it, loss=1.3556, batch_acc=0.6250, running_acc=0.6649, grad=21.2832]Training epoch 11:  60%|██████    | 98/163 [01:56<01:08,  1.06s/it, loss=1.4100, batch_acc=0.6562, running_acc=0.6649, grad=28.4898]Training epoch 11:  61%|██████    | 99/163 [01:56<01:04,  1.01s/it, loss=1.4100, batch_acc=0.6562, running_acc=0.6649, grad=28.4898]Training epoch 11:  61%|██████    | 99/163 [01:56<01:04,  1.01s/it, loss=1.2195, batch_acc=0.7500, running_acc=0.6657, grad=27.5515]Training epoch 11:  61%|██████▏   | 100/163 [01:58<01:15,  1.19s/it, loss=1.2195, batch_acc=0.7500, running_acc=0.6657, grad=27.5515]Training epoch 11:  61%|██████▏   | 100/163 [01:58<01:15,  1.19s/it, loss=1.3694, batch_acc=0.7500, running_acc=0.6666, grad=21.4457]Training epoch 11:  62%|██████▏   | 101/163 [01:59<01:08,  1.10s/it, loss=1.3694, batch_acc=0.7500, running_acc=0.6666, grad=21.4457]Training epoch 11:  62%|██████▏   | 101/163 [01:59<01:08,  1.10s/it, loss=1.4643, batch_acc=0.7188, running_acc=0.6671, grad=18.7584]Training epoch 11:  63%|██████▎   | 102/163 [02:00<01:02,  1.03s/it, loss=1.4643, batch_acc=0.7188, running_acc=0.6671, grad=18.7584]Training epoch 11:  63%|██████▎   | 102/163 [02:00<01:02,  1.03s/it, loss=1.2680, batch_acc=0.7812, running_acc=0.6682, grad=17.3607]Training epoch 11:  63%|██████▎   | 103/163 [02:01<00:59,  1.01it/s, loss=1.2680, batch_acc=0.7812, running_acc=0.6682, grad=17.3607]Training epoch 11:  63%|██████▎   | 103/163 [02:01<00:59,  1.01it/s, loss=1.6031, batch_acc=0.5938, running_acc=0.6675, grad=20.9344]Training epoch 11:  64%|██████▍   | 104/163 [02:03<01:18,  1.33s/it, loss=1.6031, batch_acc=0.5938, running_acc=0.6675, grad=20.9344]Training epoch 11:  64%|██████▍   | 104/163 [02:03<01:18,  1.33s/it, loss=1.5897, batch_acc=0.5938, running_acc=0.6668, grad=28.1710]Training epoch 11:  64%|██████▍   | 105/163 [02:04<01:09,  1.19s/it, loss=1.5897, batch_acc=0.5938, running_acc=0.6668, grad=28.1710]Training epoch 11:  64%|██████▍   | 105/163 [02:04<01:09,  1.19s/it, loss=1.4404, batch_acc=0.5625, running_acc=0.6658, grad=23.8508]Training epoch 11:  65%|██████▌   | 106/163 [02:05<01:02,  1.10s/it, loss=1.4404, batch_acc=0.5625, running_acc=0.6658, grad=23.8508]Training epoch 11:  65%|██████▌   | 106/163 [02:05<01:02,  1.10s/it, loss=1.2909, batch_acc=0.7812, running_acc=0.6669, grad=19.7098]Training epoch 11:  66%|██████▌   | 107/163 [02:05<00:57,  1.03s/it, loss=1.2909, batch_acc=0.7812, running_acc=0.6669, grad=19.7098]Training epoch 11:  66%|██████▌   | 107/163 [02:05<00:57,  1.03s/it, loss=1.2201, batch_acc=0.7188, running_acc=0.6673, grad=18.8760]Training epoch 11:  66%|██████▋   | 108/163 [02:07<01:08,  1.24s/it, loss=1.2201, batch_acc=0.7188, running_acc=0.6673, grad=18.8760]Training epoch 11:  66%|██████▋   | 108/163 [02:07<01:08,  1.24s/it, loss=1.4414, batch_acc=0.6562, running_acc=0.6672, grad=26.5116]Training epoch 11:  67%|██████▋   | 109/163 [02:08<01:01,  1.13s/it, loss=1.4414, batch_acc=0.6562, running_acc=0.6672, grad=26.5116]Training epoch 11:  67%|██████▋   | 109/163 [02:08<01:01,  1.13s/it, loss=1.5056, batch_acc=0.7500, running_acc=0.6680, grad=20.6982]Training epoch 11:  67%|██████▋   | 110/163 [02:09<00:55,  1.05s/it, loss=1.5056, batch_acc=0.7500, running_acc=0.6680, grad=20.6982]Training epoch 11:  67%|██████▋   | 110/163 [02:09<00:55,  1.05s/it, loss=1.3507, batch_acc=0.7188, running_acc=0.6685, grad=18.1916]Training epoch 11:  68%|██████▊   | 111/163 [02:10<00:52,  1.00s/it, loss=1.3507, batch_acc=0.7188, running_acc=0.6685, grad=18.1916]Training epoch 11:  68%|██████▊   | 111/163 [02:10<00:52,  1.00s/it, loss=0.9190, batch_acc=0.9062, running_acc=0.6706, grad=20.2276]Training epoch 11:  69%|██████▊   | 112/163 [02:11<00:56,  1.10s/it, loss=0.9190, batch_acc=0.9062, running_acc=0.6706, grad=20.2276]Training epoch 11:  69%|██████▊   | 112/163 [02:11<00:56,  1.10s/it, loss=1.4143, batch_acc=0.6875, running_acc=0.6708, grad=27.7415]Training epoch 11:  69%|██████▉   | 113/163 [02:12<00:51,  1.04s/it, loss=1.4143, batch_acc=0.6875, running_acc=0.6708, grad=27.7415]Training epoch 11:  69%|██████▉   | 113/163 [02:12<00:51,  1.04s/it, loss=1.4834, batch_acc=0.6875, running_acc=0.6709, grad=20.3039]Training epoch 11:  70%|██████▉   | 114/163 [02:13<00:48,  1.01it/s, loss=1.4834, batch_acc=0.6875, running_acc=0.6709, grad=20.3039]Training epoch 11:  70%|██████▉   | 114/163 [02:13<00:48,  1.01it/s, loss=1.2997, batch_acc=0.7188, running_acc=0.6713, grad=20.2550]Training epoch 11:  71%|███████   | 115/163 [02:14<00:45,  1.04it/s, loss=1.2997, batch_acc=0.7188, running_acc=0.6713, grad=20.2550]Training epoch 11:  71%|███████   | 115/163 [02:14<00:45,  1.04it/s, loss=1.5460, batch_acc=0.6875, running_acc=0.6715, grad=20.6566]Training epoch 11:  71%|███████   | 116/163 [02:16<00:58,  1.24s/it, loss=1.5460, batch_acc=0.6875, running_acc=0.6715, grad=20.6566]Training epoch 11:  71%|███████   | 116/163 [02:16<00:58,  1.24s/it, loss=1.1239, batch_acc=0.7812, running_acc=0.6724, grad=24.5576]Training epoch 11:  72%|███████▏  | 117/163 [02:17<00:51,  1.13s/it, loss=1.1239, batch_acc=0.7812, running_acc=0.6724, grad=24.5576]Training epoch 11:  72%|███████▏  | 117/163 [02:17<00:51,  1.13s/it, loss=1.6170, batch_acc=0.5938, running_acc=0.6717, grad=23.8457]Training epoch 11:  72%|███████▏  | 118/163 [02:17<00:47,  1.05s/it, loss=1.6170, batch_acc=0.5938, running_acc=0.6717, grad=23.8457]Training epoch 11:  72%|███████▏  | 118/163 [02:17<00:47,  1.05s/it, loss=1.4353, batch_acc=0.7188, running_acc=0.6721, grad=18.5653]Training epoch 11:  73%|███████▎  | 119/163 [02:18<00:44,  1.00s/it, loss=1.4353, batch_acc=0.7188, running_acc=0.6721, grad=18.5653]Training epoch 11:  73%|███████▎  | 119/163 [02:18<00:44,  1.00s/it, loss=1.0760, batch_acc=0.7812, running_acc=0.6731, grad=17.6438]Training epoch 11:  74%|███████▎  | 120/163 [02:21<00:59,  1.38s/it, loss=1.0760, batch_acc=0.7812, running_acc=0.6731, grad=17.6438]Training epoch 11:  74%|███████▎  | 120/163 [02:21<00:59,  1.38s/it, loss=1.4808, batch_acc=0.6562, running_acc=0.6729, grad=21.2241]Training epoch 11:  74%|███████▍  | 121/163 [02:21<00:51,  1.23s/it, loss=1.4808, batch_acc=0.6562, running_acc=0.6729, grad=21.2241]Training epoch 11:  74%|███████▍  | 121/163 [02:21<00:51,  1.23s/it, loss=1.3669, batch_acc=0.5938, running_acc=0.6723, grad=20.9870]Training epoch 11:  75%|███████▍  | 122/163 [02:22<00:46,  1.13s/it, loss=1.3669, batch_acc=0.5938, running_acc=0.6723, grad=20.9870]Training epoch 11:  75%|███████▍  | 122/163 [02:22<00:46,  1.13s/it, loss=1.4019, batch_acc=0.5625, running_acc=0.6714, grad=25.6122]Training epoch 11:  75%|███████▌  | 123/163 [02:23<00:42,  1.05s/it, loss=1.4019, batch_acc=0.5625, running_acc=0.6714, grad=25.6122]Training epoch 11:  75%|███████▌  | 123/163 [02:23<00:42,  1.05s/it, loss=1.6778, batch_acc=0.5938, running_acc=0.6707, grad=36.9070]Training epoch 11:  76%|███████▌  | 124/163 [02:25<00:49,  1.27s/it, loss=1.6778, batch_acc=0.5938, running_acc=0.6707, grad=36.9070]Training epoch 11:  76%|███████▌  | 124/163 [02:25<00:49,  1.27s/it, loss=1.6202, batch_acc=0.5938, running_acc=0.6701, grad=21.0801]Training epoch 11:  77%|███████▋  | 125/163 [02:26<00:43,  1.15s/it, loss=1.6202, batch_acc=0.5938, running_acc=0.6701, grad=21.0801]Training epoch 11:  77%|███████▋  | 125/163 [02:26<00:43,  1.15s/it, loss=1.3585, batch_acc=0.6562, running_acc=0.6700, grad=23.8121]Training epoch 11:  77%|███████▋  | 126/163 [02:27<00:39,  1.07s/it, loss=1.3585, batch_acc=0.6562, running_acc=0.6700, grad=23.8121]Training epoch 11:  77%|███████▋  | 126/163 [02:27<00:39,  1.07s/it, loss=1.2281, batch_acc=0.7812, running_acc=0.6709, grad=23.5462]Training epoch 11:  78%|███████▊  | 127/163 [02:28<00:36,  1.01s/it, loss=1.2281, batch_acc=0.7812, running_acc=0.6709, grad=23.5462]Training epoch 11:  78%|███████▊  | 127/163 [02:28<00:36,  1.01s/it, loss=1.3819, batch_acc=0.7500, running_acc=0.6715, grad=20.9265]Training epoch 11:  79%|███████▊  | 128/163 [02:30<00:45,  1.30s/it, loss=1.3819, batch_acc=0.7500, running_acc=0.6715, grad=20.9265]Training epoch 11:  79%|███████▊  | 128/163 [02:30<00:45,  1.30s/it, loss=1.8154, batch_acc=0.5000, running_acc=0.6702, grad=35.5119]Training epoch 11:  79%|███████▉  | 129/163 [02:31<00:40,  1.18s/it, loss=1.8154, batch_acc=0.5000, running_acc=0.6702, grad=35.5119]Training epoch 11:  79%|███████▉  | 129/163 [02:31<00:40,  1.18s/it, loss=1.3562, batch_acc=0.6875, running_acc=0.6703, grad=34.3231]Training epoch 11:  80%|███████▉  | 130/163 [02:31<00:35,  1.09s/it, loss=1.3562, batch_acc=0.6875, running_acc=0.6703, grad=34.3231]Training epoch 11:  80%|███████▉  | 130/163 [02:31<00:35,  1.09s/it, loss=1.2731, batch_acc=0.8125, running_acc=0.6714, grad=21.5739]Training epoch 11:  80%|████████  | 131/163 [02:32<00:32,  1.03s/it, loss=1.2731, batch_acc=0.8125, running_acc=0.6714, grad=21.5739]Training epoch 11:  80%|████████  | 131/163 [02:32<00:32,  1.03s/it, loss=1.4473, batch_acc=0.5312, running_acc=0.6703, grad=20.6776]Training epoch 11:  81%|████████  | 132/163 [02:34<00:36,  1.16s/it, loss=1.4473, batch_acc=0.5312, running_acc=0.6703, grad=20.6776]Training epoch 11:  81%|████████  | 132/163 [02:34<00:36,  1.16s/it, loss=1.5854, batch_acc=0.6562, running_acc=0.6702, grad=20.7798]Training epoch 11:  82%|████████▏ | 133/163 [02:35<00:32,  1.08s/it, loss=1.5854, batch_acc=0.6562, running_acc=0.6702, grad=20.7798]Training epoch 11:  82%|████████▏ | 133/163 [02:35<00:32,  1.08s/it, loss=1.7636, batch_acc=0.5312, running_acc=0.6692, grad=19.1762]Training epoch 11:  82%|████████▏ | 134/163 [02:36<00:29,  1.02s/it, loss=1.7636, batch_acc=0.5312, running_acc=0.6692, grad=19.1762]Training epoch 11:  82%|████████▏ | 134/163 [02:36<00:29,  1.02s/it, loss=1.5112, batch_acc=0.6875, running_acc=0.6693, grad=26.0309]Training epoch 11:  83%|████████▎ | 135/163 [02:36<00:27,  1.02it/s, loss=1.5112, batch_acc=0.6875, running_acc=0.6693, grad=26.0309]Training epoch 11:  83%|████████▎ | 135/163 [02:36<00:27,  1.02it/s, loss=1.3763, batch_acc=0.7188, running_acc=0.6697, grad=17.4604]Training epoch 11:  83%|████████▎ | 136/163 [02:39<00:36,  1.35s/it, loss=1.3763, batch_acc=0.7188, running_acc=0.6697, grad=17.4604]Training epoch 11:  83%|████████▎ | 136/163 [02:39<00:36,  1.35s/it, loss=1.6461, batch_acc=0.6250, running_acc=0.6693, grad=31.1647]Training epoch 11:  84%|████████▍ | 137/163 [02:40<00:31,  1.21s/it, loss=1.6461, batch_acc=0.6250, running_acc=0.6693, grad=31.1647]Training epoch 11:  84%|████████▍ | 137/163 [02:40<00:31,  1.21s/it, loss=1.2845, batch_acc=0.7500, running_acc=0.6699, grad=22.9132]Training epoch 11:  85%|████████▍ | 138/163 [02:40<00:27,  1.11s/it, loss=1.2845, batch_acc=0.7500, running_acc=0.6699, grad=22.9132]Training epoch 11:  85%|████████▍ | 138/163 [02:40<00:27,  1.11s/it, loss=1.5921, batch_acc=0.6562, running_acc=0.6698, grad=23.0413]Training epoch 11:  85%|████████▌ | 139/163 [02:41<00:24,  1.04s/it, loss=1.5921, batch_acc=0.6562, running_acc=0.6698, grad=23.0413]Training epoch 11:  85%|████████▌ | 139/163 [02:41<00:24,  1.04s/it, loss=1.4306, batch_acc=0.6562, running_acc=0.6697, grad=22.7259]Training epoch 11:  86%|████████▌ | 140/163 [02:43<00:28,  1.23s/it, loss=1.4306, batch_acc=0.6562, running_acc=0.6697, grad=22.7259]Training epoch 11:  86%|████████▌ | 140/163 [02:43<00:28,  1.23s/it, loss=1.2120, batch_acc=0.7500, running_acc=0.6703, grad=27.5952]Training epoch 11:  87%|████████▋ | 141/163 [02:44<00:24,  1.12s/it, loss=1.2120, batch_acc=0.7500, running_acc=0.6703, grad=27.5952]Training epoch 11:  87%|████████▋ | 141/163 [02:44<00:24,  1.12s/it, loss=1.4037, batch_acc=0.7500, running_acc=0.6709, grad=19.7670]Training epoch 11:  87%|████████▋ | 142/163 [02:45<00:22,  1.05s/it, loss=1.4037, batch_acc=0.7500, running_acc=0.6709, grad=19.7670]Training epoch 11:  87%|████████▋ | 142/163 [02:45<00:22,  1.05s/it, loss=1.5171, batch_acc=0.7188, running_acc=0.6712, grad=26.2559]Training epoch 11:  88%|████████▊ | 143/163 [02:46<00:19,  1.00it/s, loss=1.5171, batch_acc=0.7188, running_acc=0.6712, grad=26.2559]Training epoch 11:  88%|████████▊ | 143/163 [02:46<00:19,  1.00it/s, loss=1.2382, batch_acc=0.7188, running_acc=0.6715, grad=16.9538]Training epoch 11:  88%|████████▊ | 144/163 [02:48<00:24,  1.31s/it, loss=1.2382, batch_acc=0.7188, running_acc=0.6715, grad=16.9538]Training epoch 11:  88%|████████▊ | 144/163 [02:48<00:24,  1.31s/it, loss=1.3078, batch_acc=0.7812, running_acc=0.6723, grad=19.3127]Training epoch 11:  89%|████████▉ | 145/163 [02:48<00:21,  1.18s/it, loss=1.3078, batch_acc=0.7812, running_acc=0.6723, grad=19.3127]Training epoch 11:  89%|████████▉ | 145/163 [02:48<00:21,  1.18s/it, loss=1.4214, batch_acc=0.7188, running_acc=0.6726, grad=34.7292]Training epoch 11:  90%|████████▉ | 146/163 [02:49<00:18,  1.09s/it, loss=1.4214, batch_acc=0.7188, running_acc=0.6726, grad=34.7292]Training epoch 11:  90%|████████▉ | 146/163 [02:49<00:18,  1.09s/it, loss=1.5130, batch_acc=0.5625, running_acc=0.6719, grad=24.6197]Training epoch 11:  90%|█████████ | 147/163 [02:50<00:16,  1.03s/it, loss=1.5130, batch_acc=0.5625, running_acc=0.6719, grad=24.6197]Training epoch 11:  90%|█████████ | 147/163 [02:50<00:16,  1.03s/it, loss=1.5749, batch_acc=0.6250, running_acc=0.6716, grad=25.1516]Training epoch 11:  91%|█████████ | 148/163 [02:52<00:17,  1.20s/it, loss=1.5749, batch_acc=0.6250, running_acc=0.6716, grad=25.1516]Training epoch 11:  91%|█████████ | 148/163 [02:52<00:17,  1.20s/it, loss=1.3680, batch_acc=0.6875, running_acc=0.6717, grad=31.4898]Training epoch 11:  91%|█████████▏| 149/163 [02:53<00:15,  1.10s/it, loss=1.3680, batch_acc=0.6875, running_acc=0.6717, grad=31.4898]Training epoch 11:  91%|█████████▏| 149/163 [02:53<00:15,  1.10s/it, loss=1.9636, batch_acc=0.4375, running_acc=0.6701, grad=29.7229]Training epoch 11:  92%|█████████▏| 150/163 [02:54<00:13,  1.03s/it, loss=1.9636, batch_acc=0.4375, running_acc=0.6701, grad=29.7229]Training epoch 11:  92%|█████████▏| 150/163 [02:54<00:13,  1.03s/it, loss=1.3434, batch_acc=0.7188, running_acc=0.6704, grad=20.9732]Training epoch 11:  93%|█████████▎| 151/163 [02:54<00:11,  1.01it/s, loss=1.3434, batch_acc=0.7188, running_acc=0.6704, grad=20.9732]Training epoch 11:  93%|█████████▎| 151/163 [02:54<00:11,  1.01it/s, loss=1.4304, batch_acc=0.6875, running_acc=0.6705, grad=20.0008]Training epoch 11:  93%|█████████▎| 152/163 [02:56<00:13,  1.26s/it, loss=1.4304, batch_acc=0.6875, running_acc=0.6705, grad=20.0008]Training epoch 11:  93%|█████████▎| 152/163 [02:56<00:13,  1.26s/it, loss=1.1737, batch_acc=0.7812, running_acc=0.6713, grad=22.6145]Training epoch 11:  94%|█████████▍| 153/163 [02:57<00:11,  1.14s/it, loss=1.1737, batch_acc=0.7812, running_acc=0.6713, grad=22.6145]Training epoch 11:  94%|█████████▍| 153/163 [02:57<00:11,  1.14s/it, loss=1.3675, batch_acc=0.6250, running_acc=0.6710, grad=23.8026]Training epoch 11:  94%|█████████▍| 154/163 [02:58<00:09,  1.06s/it, loss=1.3675, batch_acc=0.6250, running_acc=0.6710, grad=23.8026]Training epoch 11:  94%|█████████▍| 154/163 [02:58<00:09,  1.06s/it, loss=1.2533, batch_acc=0.5938, running_acc=0.6705, grad=18.7286]Training epoch 11:  95%|█████████▌| 155/163 [02:59<00:08,  1.01s/it, loss=1.2533, batch_acc=0.5938, running_acc=0.6705, grad=18.7286]Training epoch 11:  95%|█████████▌| 155/163 [02:59<00:08,  1.01s/it, loss=1.3414, batch_acc=0.5938, running_acc=0.6700, grad=18.1147]Training epoch 11:  96%|█████████▌| 156/163 [03:01<00:08,  1.25s/it, loss=1.3414, batch_acc=0.5938, running_acc=0.6700, grad=18.1147]Training epoch 11:  96%|█████████▌| 156/163 [03:01<00:08,  1.25s/it, loss=1.3195, batch_acc=0.5938, running_acc=0.6695, grad=18.8588]Training epoch 11:  96%|█████████▋| 157/163 [03:02<00:06,  1.14s/it, loss=1.3195, batch_acc=0.5938, running_acc=0.6695, grad=18.8588]Training epoch 11:  96%|█████████▋| 157/163 [03:02<00:06,  1.14s/it, loss=1.3641, batch_acc=0.7812, running_acc=0.6702, grad=17.7153]Training epoch 11:  97%|█████████▋| 158/163 [03:03<00:05,  1.06s/it, loss=1.3641, batch_acc=0.7812, running_acc=0.6702, grad=17.7153]Training epoch 11:  97%|█████████▋| 158/163 [03:03<00:05,  1.06s/it, loss=1.5231, batch_acc=0.6250, running_acc=0.6699, grad=22.9503]Training epoch 11:  98%|█████████▊| 159/163 [03:03<00:04,  1.01s/it, loss=1.5231, batch_acc=0.6250, running_acc=0.6699, grad=22.9503]Training epoch 11:  98%|█████████▊| 159/163 [03:03<00:04,  1.01s/it, loss=1.6202, batch_acc=0.5000, running_acc=0.6688, grad=30.6094]Training epoch 11:  98%|█████████▊| 160/163 [03:04<00:03,  1.01s/it, loss=1.6202, batch_acc=0.5000, running_acc=0.6688, grad=30.6094]Training epoch 11:  98%|█████████▊| 160/163 [03:04<00:03,  1.01s/it, loss=1.3237, batch_acc=0.7500, running_acc=0.6693, grad=23.8987]Training epoch 11:  99%|█████████▉| 161/163 [03:05<00:01,  1.03it/s, loss=1.3237, batch_acc=0.7500, running_acc=0.6693, grad=23.8987]Training epoch 11:  99%|█████████▉| 161/163 [03:05<00:01,  1.03it/s, loss=1.0723, batch_acc=0.8438, running_acc=0.6704, grad=20.5060]Training epoch 11:  99%|█████████▉| 162/163 [03:06<00:00,  1.06it/s, loss=1.0723, batch_acc=0.8438, running_acc=0.6704, grad=20.5060]Training epoch 11:  99%|█████████▉| 162/163 [03:06<00:00,  1.06it/s, loss=1.1202, batch_acc=0.7500, running_acc=0.6709, grad=17.4256]Training epoch 11: 100%|██████████| 163/163 [03:07<00:00,  1.17it/s, loss=1.1202, batch_acc=0.7500, running_acc=0.6709, grad=17.4256]Training epoch 11: 100%|██████████| 163/163 [03:07<00:00,  1.17it/s, loss=0.9902, batch_acc=0.8095, running_acc=0.6715, grad=22.1783]Training epoch 11: 100%|██████████| 163/163 [03:07<00:00,  1.15s/it, loss=0.9902, batch_acc=0.8095, running_acc=0.6715, grad=22.1783]
Evaluation epoch 11:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 11:   4%|▎         | 1/28 [00:05<02:21,  5.24s/it]Evaluation epoch 11:   4%|▎         | 1/28 [00:05<02:21,  5.24s/it, loss=1.2343, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 11:   7%|▋         | 2/28 [00:05<01:00,  2.31s/it, loss=1.2343, batch_acc=0.6875, running_acc=0.6875]Evaluation epoch 11:   7%|▋         | 2/28 [00:05<01:00,  2.31s/it, loss=1.5030, batch_acc=0.5938, running_acc=0.6406]Evaluation epoch 11:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=1.5030, batch_acc=0.5938, running_acc=0.6406]Evaluation epoch 11:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=1.2811, batch_acc=0.6875, running_acc=0.6562]Evaluation epoch 11:  14%|█▍        | 4/28 [00:10<01:03,  2.64s/it, loss=1.2811, batch_acc=0.6875, running_acc=0.6562]Evaluation epoch 11:  14%|█▍        | 4/28 [00:10<01:03,  2.64s/it, loss=1.9429, batch_acc=0.4688, running_acc=0.6094]Evaluation epoch 11:  18%|█▊        | 5/28 [00:10<00:41,  1.78s/it, loss=1.9429, batch_acc=0.4688, running_acc=0.6094]Evaluation epoch 11:  18%|█▊        | 5/28 [00:10<00:41,  1.78s/it, loss=1.9542, batch_acc=0.5312, running_acc=0.5938]Evaluation epoch 11:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=1.9542, batch_acc=0.5312, running_acc=0.5938]Evaluation epoch 11:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=1.7296, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 11:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=1.7296, batch_acc=0.5938, running_acc=0.5938]Evaluation epoch 11:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=1.9864, batch_acc=0.5000, running_acc=0.5804]Evaluation epoch 11:  29%|██▊       | 8/28 [00:14<00:36,  1.81s/it, loss=1.9864, batch_acc=0.5000, running_acc=0.5804]Evaluation epoch 11:  29%|██▊       | 8/28 [00:14<00:36,  1.81s/it, loss=1.4640, batch_acc=0.5938, running_acc=0.5820]Evaluation epoch 11:  32%|███▏      | 9/28 [00:15<00:28,  1.48s/it, loss=1.4640, batch_acc=0.5938, running_acc=0.5820]Evaluation epoch 11:  32%|███▏      | 9/28 [00:15<00:28,  1.48s/it, loss=1.8774, batch_acc=0.5000, running_acc=0.5729]Evaluation epoch 11:  36%|███▌      | 10/28 [00:15<00:19,  1.10s/it, loss=1.8774, batch_acc=0.5000, running_acc=0.5729]Evaluation epoch 11:  36%|███▌      | 10/28 [00:15<00:19,  1.10s/it, loss=0.7824, batch_acc=0.8438, running_acc=0.6000]Evaluation epoch 11:  39%|███▉      | 11/28 [00:16<00:14,  1.18it/s, loss=0.7824, batch_acc=0.8438, running_acc=0.6000]Evaluation epoch 11:  39%|███▉      | 11/28 [00:16<00:14,  1.18it/s, loss=1.7640, batch_acc=0.6875, running_acc=0.6080]Evaluation epoch 11:  43%|████▎     | 12/28 [00:21<00:36,  2.27s/it, loss=1.7640, batch_acc=0.6875, running_acc=0.6080]Evaluation epoch 11:  43%|████▎     | 12/28 [00:21<00:36,  2.27s/it, loss=1.6803, batch_acc=0.5625, running_acc=0.6042]Evaluation epoch 11:  46%|████▋     | 13/28 [00:21<00:24,  1.66s/it, loss=1.6803, batch_acc=0.5625, running_acc=0.6042]Evaluation epoch 11:  46%|████▋     | 13/28 [00:21<00:24,  1.66s/it, loss=1.0212, batch_acc=0.8125, running_acc=0.6202]Evaluation epoch 11:  50%|█████     | 14/28 [00:22<00:17,  1.24s/it, loss=1.0212, batch_acc=0.8125, running_acc=0.6202]Evaluation epoch 11:  50%|█████     | 14/28 [00:22<00:17,  1.24s/it, loss=1.7508, batch_acc=0.6250, running_acc=0.6205]Evaluation epoch 11:  54%|█████▎    | 15/28 [00:22<00:12,  1.06it/s, loss=1.7508, batch_acc=0.6250, running_acc=0.6205]Evaluation epoch 11:  54%|█████▎    | 15/28 [00:22<00:12,  1.06it/s, loss=2.6488, batch_acc=0.4062, running_acc=0.6062]Evaluation epoch 11:  57%|█████▋    | 16/28 [00:25<00:19,  1.60s/it, loss=2.6488, batch_acc=0.4062, running_acc=0.6062]Evaluation epoch 11:  57%|█████▋    | 16/28 [00:25<00:19,  1.60s/it, loss=1.4914, batch_acc=0.6250, running_acc=0.6074]Evaluation epoch 11:  61%|██████    | 17/28 [00:25<00:13,  1.20s/it, loss=1.4914, batch_acc=0.6250, running_acc=0.6074]Evaluation epoch 11:  61%|██████    | 17/28 [00:25<00:13,  1.20s/it, loss=1.2882, batch_acc=0.6875, running_acc=0.6121]Evaluation epoch 11:  64%|██████▍   | 18/28 [00:26<00:09,  1.09it/s, loss=1.2882, batch_acc=0.6875, running_acc=0.6121]Evaluation epoch 11:  64%|██████▍   | 18/28 [00:26<00:09,  1.09it/s, loss=1.2913, batch_acc=0.6562, running_acc=0.6146]Evaluation epoch 11:  68%|██████▊   | 19/28 [00:26<00:06,  1.39it/s, loss=1.2913, batch_acc=0.6562, running_acc=0.6146]Evaluation epoch 11:  68%|██████▊   | 19/28 [00:26<00:06,  1.39it/s, loss=1.3875, batch_acc=0.5312, running_acc=0.6102]Evaluation epoch 11:  71%|███████▏  | 20/28 [00:29<00:11,  1.49s/it, loss=1.3875, batch_acc=0.5312, running_acc=0.6102]Evaluation epoch 11:  71%|███████▏  | 20/28 [00:29<00:11,  1.49s/it, loss=1.7706, batch_acc=0.4688, running_acc=0.6031]Evaluation epoch 11:  75%|███████▌  | 21/28 [00:29<00:07,  1.12s/it, loss=1.7706, batch_acc=0.4688, running_acc=0.6031]Evaluation epoch 11:  75%|███████▌  | 21/28 [00:29<00:07,  1.12s/it, loss=1.7703, batch_acc=0.5312, running_acc=0.5997]Evaluation epoch 11:  79%|███████▊  | 22/28 [00:30<00:05,  1.16it/s, loss=1.7703, batch_acc=0.5312, running_acc=0.5997]Evaluation epoch 11:  79%|███████▊  | 22/28 [00:30<00:05,  1.16it/s, loss=2.0587, batch_acc=0.4688, running_acc=0.5938]Evaluation epoch 11:  82%|████████▏ | 23/28 [00:30<00:03,  1.46it/s, loss=2.0587, batch_acc=0.4688, running_acc=0.5938]Evaluation epoch 11:  82%|████████▏ | 23/28 [00:30<00:03,  1.46it/s, loss=2.0444, batch_acc=0.4375, running_acc=0.5870]Evaluation epoch 11:  86%|████████▌ | 24/28 [00:35<00:08,  2.14s/it, loss=2.0444, batch_acc=0.4375, running_acc=0.5870]Evaluation epoch 11:  86%|████████▌ | 24/28 [00:35<00:08,  2.14s/it, loss=1.3185, batch_acc=0.5625, running_acc=0.5859]Evaluation epoch 11:  89%|████████▉ | 25/28 [00:36<00:04,  1.58s/it, loss=1.3185, batch_acc=0.5625, running_acc=0.5859]Evaluation epoch 11:  89%|████████▉ | 25/28 [00:36<00:04,  1.58s/it, loss=1.0769, batch_acc=0.7500, running_acc=0.5925]Evaluation epoch 11:  93%|█████████▎| 26/28 [00:36<00:02,  1.18s/it, loss=1.0769, batch_acc=0.7500, running_acc=0.5925]Evaluation epoch 11:  93%|█████████▎| 26/28 [00:36<00:02,  1.18s/it, loss=1.3934, batch_acc=0.5625, running_acc=0.5913]Evaluation epoch 11:  96%|█████████▋| 27/28 [00:36<00:00,  1.10it/s, loss=1.3934, batch_acc=0.5625, running_acc=0.5913]Evaluation epoch 11:  96%|█████████▋| 27/28 [00:36<00:00,  1.10it/s, loss=1.5993, batch_acc=0.5312, running_acc=0.5891]Evaluation epoch 11: 100%|██████████| 28/28 [00:36<00:00,  1.10it/s, loss=1.1646, batch_acc=0.6667, running_acc=0.5894]Evaluation epoch 11: 100%|██████████| 28/28 [00:36<00:00,  1.31s/it, loss=1.1646, batch_acc=0.6667, running_acc=0.5894]
Training epoch 12:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 12:   1%|          | 1/163 [00:05<15:48,  5.85s/it]Training epoch 12:   1%|          | 1/163 [00:05<15:48,  5.85s/it, loss=1.3445, batch_acc=0.6875, running_acc=0.6875, grad=16.0188]Training epoch 12:   1%|          | 2/163 [00:06<07:51,  2.93s/it, loss=1.3445, batch_acc=0.6875, running_acc=0.6875, grad=16.0188]Training epoch 12:   1%|          | 2/163 [00:06<07:51,  2.93s/it, loss=1.4560, batch_acc=0.6875, running_acc=0.6875, grad=20.8408]Training epoch 12:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=1.4560, batch_acc=0.6875, running_acc=0.6875, grad=20.8408]Training epoch 12:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=1.3748, batch_acc=0.5938, running_acc=0.6562, grad=20.6993]Training epoch 12:   2%|▏         | 4/163 [00:09<05:33,  2.10s/it, loss=1.3748, batch_acc=0.5938, running_acc=0.6562, grad=20.6993]Training epoch 12:   2%|▏         | 4/163 [00:09<05:33,  2.10s/it, loss=1.3984, batch_acc=0.6562, running_acc=0.6562, grad=21.5334]Training epoch 12:   3%|▎         | 5/163 [00:10<04:22,  1.66s/it, loss=1.3984, batch_acc=0.6562, running_acc=0.6562, grad=21.5334]Training epoch 12:   3%|▎         | 5/163 [00:10<04:22,  1.66s/it, loss=1.0283, batch_acc=0.8438, running_acc=0.6937, grad=14.6513]Training epoch 12:   4%|▎         | 6/163 [00:11<03:39,  1.40s/it, loss=1.0283, batch_acc=0.8438, running_acc=0.6937, grad=14.6513]Training epoch 12:   4%|▎         | 6/163 [00:11<03:39,  1.40s/it, loss=1.0945, batch_acc=0.7188, running_acc=0.6979, grad=16.9458]Training epoch 12:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=1.0945, batch_acc=0.7188, running_acc=0.6979, grad=16.9458]Training epoch 12:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=1.5772, batch_acc=0.6250, running_acc=0.6875, grad=17.3190]Training epoch 12:   5%|▍         | 8/163 [00:14<03:48,  1.47s/it, loss=1.5772, batch_acc=0.6250, running_acc=0.6875, grad=17.3190]Training epoch 12:   5%|▍         | 8/163 [00:14<03:48,  1.47s/it, loss=1.1973, batch_acc=0.7812, running_acc=0.6992, grad=18.7509]Training epoch 12:   6%|▌         | 9/163 [00:15<03:18,  1.29s/it, loss=1.1973, batch_acc=0.7812, running_acc=0.6992, grad=18.7509]Training epoch 12:   6%|▌         | 9/163 [00:15<03:18,  1.29s/it, loss=1.3065, batch_acc=0.7500, running_acc=0.7049, grad=20.8476]Training epoch 12:   6%|▌         | 10/163 [00:16<02:57,  1.16s/it, loss=1.3065, batch_acc=0.7500, running_acc=0.7049, grad=20.8476]Training epoch 12:   6%|▌         | 10/163 [00:16<02:57,  1.16s/it, loss=1.0559, batch_acc=0.8125, running_acc=0.7156, grad=25.3157]Training epoch 12:   7%|▋         | 11/163 [00:17<02:43,  1.07s/it, loss=1.0559, batch_acc=0.8125, running_acc=0.7156, grad=25.3157]Training epoch 12:   7%|▋         | 11/163 [00:17<02:43,  1.07s/it, loss=1.1050, batch_acc=0.8125, running_acc=0.7244, grad=21.0066]Training epoch 12:   7%|▋         | 12/163 [00:19<03:21,  1.34s/it, loss=1.1050, batch_acc=0.8125, running_acc=0.7244, grad=21.0066]Training epoch 12:   7%|▋         | 12/163 [00:19<03:21,  1.34s/it, loss=1.0503, batch_acc=0.7812, running_acc=0.7292, grad=25.2481]Training epoch 12:   8%|▊         | 13/163 [00:19<02:59,  1.20s/it, loss=1.0503, batch_acc=0.7812, running_acc=0.7292, grad=25.2481]Training epoch 12:   8%|▊         | 13/163 [00:19<02:59,  1.20s/it, loss=1.2836, batch_acc=0.7812, running_acc=0.7332, grad=17.9834]Training epoch 12:   9%|▊         | 14/163 [00:20<02:44,  1.10s/it, loss=1.2836, batch_acc=0.7812, running_acc=0.7332, grad=17.9834]Training epoch 12:   9%|▊         | 14/163 [00:20<02:44,  1.10s/it, loss=1.3454, batch_acc=0.5938, running_acc=0.7232, grad=17.5910]Training epoch 12:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=1.3454, batch_acc=0.5938, running_acc=0.7232, grad=17.5910]Training epoch 12:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=1.3950, batch_acc=0.7500, running_acc=0.7250, grad=24.8545]Training epoch 12:  10%|▉         | 16/163 [00:23<02:49,  1.15s/it, loss=1.3950, batch_acc=0.7500, running_acc=0.7250, grad=24.8545]Training epoch 12:  10%|▉         | 16/163 [00:23<02:49,  1.15s/it, loss=1.4751, batch_acc=0.6250, running_acc=0.7188, grad=21.8036]Training epoch 12:  10%|█         | 17/163 [00:24<02:35,  1.07s/it, loss=1.4751, batch_acc=0.6250, running_acc=0.7188, grad=21.8036]Training epoch 12:  10%|█         | 17/163 [00:24<02:35,  1.07s/it, loss=1.4175, batch_acc=0.6875, running_acc=0.7169, grad=23.8286]Training epoch 12:  11%|█         | 18/163 [00:24<02:26,  1.01s/it, loss=1.4175, batch_acc=0.6875, running_acc=0.7169, grad=23.8286]Training epoch 12:  11%|█         | 18/163 [00:24<02:26,  1.01s/it, loss=1.6058, batch_acc=0.5625, running_acc=0.7083, grad=28.3032]Training epoch 12:  12%|█▏        | 19/163 [00:25<02:19,  1.03it/s, loss=1.6058, batch_acc=0.5625, running_acc=0.7083, grad=28.3032]Training epoch 12:  12%|█▏        | 19/163 [00:25<02:19,  1.03it/s, loss=1.4182, batch_acc=0.6250, running_acc=0.7039, grad=20.5810]Training epoch 12:  12%|█▏        | 20/163 [00:27<02:38,  1.11s/it, loss=1.4182, batch_acc=0.6250, running_acc=0.7039, grad=20.5810]Training epoch 12:  12%|█▏        | 20/163 [00:27<02:38,  1.11s/it, loss=1.4986, batch_acc=0.6250, running_acc=0.7000, grad=19.5077]Training epoch 12:  13%|█▎        | 21/163 [00:28<02:27,  1.04s/it, loss=1.4986, batch_acc=0.6250, running_acc=0.7000, grad=19.5077]Training epoch 12:  13%|█▎        | 21/163 [00:28<02:27,  1.04s/it, loss=1.3175, batch_acc=0.7188, running_acc=0.7009, grad=15.5358]Training epoch 12:  13%|█▎        | 22/163 [00:28<02:19,  1.01it/s, loss=1.3175, batch_acc=0.7188, running_acc=0.7009, grad=15.5358]Training epoch 12:  13%|█▎        | 22/163 [00:28<02:19,  1.01it/s, loss=1.1884, batch_acc=0.7188, running_acc=0.7017, grad=21.7036]Training epoch 12:  14%|█▍        | 23/163 [00:29<02:13,  1.05it/s, loss=1.1884, batch_acc=0.7188, running_acc=0.7017, grad=21.7036]Training epoch 12:  14%|█▍        | 23/163 [00:29<02:13,  1.05it/s, loss=1.2768, batch_acc=0.7188, running_acc=0.7024, grad=20.1284]Training epoch 12:  15%|█▍        | 24/163 [00:31<02:36,  1.13s/it, loss=1.2768, batch_acc=0.7188, running_acc=0.7024, grad=20.1284]Training epoch 12:  15%|█▍        | 24/163 [00:31<02:36,  1.13s/it, loss=1.4229, batch_acc=0.6562, running_acc=0.7005, grad=23.1824]Training epoch 12:  15%|█▌        | 25/163 [00:32<02:25,  1.05s/it, loss=1.4229, batch_acc=0.6562, running_acc=0.7005, grad=23.1824]Training epoch 12:  15%|█▌        | 25/163 [00:32<02:25,  1.05s/it, loss=1.2349, batch_acc=0.6875, running_acc=0.7000, grad=18.1811]Training epoch 12:  16%|█▌        | 26/163 [00:33<02:17,  1.00s/it, loss=1.2349, batch_acc=0.6875, running_acc=0.7000, grad=18.1811]Training epoch 12:  16%|█▌        | 26/163 [00:33<02:17,  1.00s/it, loss=1.2775, batch_acc=0.6562, running_acc=0.6983, grad=18.5287]Training epoch 12:  17%|█▋        | 27/163 [00:33<02:11,  1.04it/s, loss=1.2775, batch_acc=0.6562, running_acc=0.6983, grad=18.5287]Training epoch 12:  17%|█▋        | 27/163 [00:33<02:11,  1.04it/s, loss=1.2647, batch_acc=0.7812, running_acc=0.7014, grad=24.0868]Training epoch 12:  17%|█▋        | 28/163 [00:35<02:35,  1.15s/it, loss=1.2647, batch_acc=0.7812, running_acc=0.7014, grad=24.0868]Training epoch 12:  17%|█▋        | 28/163 [00:35<02:35,  1.15s/it, loss=1.2386, batch_acc=0.7500, running_acc=0.7031, grad=24.0004]Training epoch 12:  18%|█▊        | 29/163 [00:36<02:23,  1.07s/it, loss=1.2386, batch_acc=0.7500, running_acc=0.7031, grad=24.0004]Training epoch 12:  18%|█▊        | 29/163 [00:36<02:23,  1.07s/it, loss=1.1966, batch_acc=0.7188, running_acc=0.7037, grad=23.6137]Training epoch 12:  18%|█▊        | 30/163 [00:37<02:14,  1.01s/it, loss=1.1966, batch_acc=0.7188, running_acc=0.7037, grad=23.6137]Training epoch 12:  18%|█▊        | 30/163 [00:37<02:14,  1.01s/it, loss=1.3937, batch_acc=0.6250, running_acc=0.7010, grad=20.4289]Training epoch 12:  19%|█▉        | 31/163 [00:38<02:08,  1.03it/s, loss=1.3937, batch_acc=0.6250, running_acc=0.7010, grad=20.4289]Training epoch 12:  19%|█▉        | 31/163 [00:38<02:08,  1.03it/s, loss=1.2165, batch_acc=0.7812, running_acc=0.7036, grad=17.5273]Training epoch 12:  20%|█▉        | 32/163 [00:40<02:52,  1.32s/it, loss=1.2165, batch_acc=0.7812, running_acc=0.7036, grad=17.5273]Training epoch 12:  20%|█▉        | 32/163 [00:40<02:52,  1.32s/it, loss=1.1261, batch_acc=0.6562, running_acc=0.7021, grad=22.3027]Training epoch 12:  20%|██        | 33/163 [00:41<02:34,  1.19s/it, loss=1.1261, batch_acc=0.6562, running_acc=0.7021, grad=22.3027]Training epoch 12:  20%|██        | 33/163 [00:41<02:34,  1.19s/it, loss=1.0903, batch_acc=0.8438, running_acc=0.7064, grad=18.3046]Training epoch 12:  21%|██        | 34/163 [00:42<02:21,  1.09s/it, loss=1.0903, batch_acc=0.8438, running_acc=0.7064, grad=18.3046]Training epoch 12:  21%|██        | 34/163 [00:42<02:21,  1.09s/it, loss=1.2871, batch_acc=0.6562, running_acc=0.7050, grad=24.4515]Training epoch 12:  21%|██▏       | 35/163 [00:42<02:11,  1.03s/it, loss=1.2871, batch_acc=0.6562, running_acc=0.7050, grad=24.4515]Training epoch 12:  21%|██▏       | 35/163 [00:42<02:11,  1.03s/it, loss=1.2614, batch_acc=0.6250, running_acc=0.7027, grad=20.6949]Training epoch 12:  22%|██▏       | 36/163 [00:43<02:10,  1.03s/it, loss=1.2614, batch_acc=0.6250, running_acc=0.7027, grad=20.6949]Training epoch 12:  22%|██▏       | 36/163 [00:43<02:10,  1.03s/it, loss=1.4128, batch_acc=0.6875, running_acc=0.7023, grad=20.5552]Training epoch 12:  23%|██▎       | 37/163 [00:44<02:03,  1.02it/s, loss=1.4128, batch_acc=0.6875, running_acc=0.7023, grad=20.5552]Training epoch 12:  23%|██▎       | 37/163 [00:44<02:03,  1.02it/s, loss=1.3391, batch_acc=0.6875, running_acc=0.7019, grad=25.0090]Training epoch 12:  23%|██▎       | 38/163 [00:45<01:58,  1.05it/s, loss=1.3391, batch_acc=0.6875, running_acc=0.7019, grad=25.0090]Training epoch 12:  23%|██▎       | 38/163 [00:45<01:58,  1.05it/s, loss=1.5113, batch_acc=0.6562, running_acc=0.7007, grad=24.0405]Training epoch 12:  24%|██▍       | 39/163 [00:46<01:55,  1.08it/s, loss=1.5113, batch_acc=0.6562, running_acc=0.7007, grad=24.0405]Training epoch 12:  24%|██▍       | 39/163 [00:46<01:55,  1.08it/s, loss=1.3606, batch_acc=0.6875, running_acc=0.7003, grad=31.5502]Training epoch 12:  25%|██▍       | 40/163 [00:48<02:22,  1.16s/it, loss=1.3606, batch_acc=0.6875, running_acc=0.7003, grad=31.5502]Training epoch 12:  25%|██▍       | 40/163 [00:48<02:22,  1.16s/it, loss=1.1171, batch_acc=0.8750, running_acc=0.7047, grad=19.3996]Training epoch 12:  25%|██▌       | 41/163 [00:49<02:10,  1.07s/it, loss=1.1171, batch_acc=0.8750, running_acc=0.7047, grad=19.3996]Training epoch 12:  25%|██▌       | 41/163 [00:49<02:10,  1.07s/it, loss=1.0730, batch_acc=0.7812, running_acc=0.7066, grad=17.7839]Training epoch 12:  26%|██▌       | 42/163 [00:50<02:02,  1.01s/it, loss=1.0730, batch_acc=0.7812, running_acc=0.7066, grad=17.7839]Training epoch 12:  26%|██▌       | 42/163 [00:50<02:02,  1.01s/it, loss=1.2044, batch_acc=0.6875, running_acc=0.7061, grad=29.4217]Training epoch 12:  26%|██▋       | 43/163 [00:50<01:56,  1.03it/s, loss=1.2044, batch_acc=0.6875, running_acc=0.7061, grad=29.4217]Training epoch 12:  26%|██▋       | 43/163 [00:50<01:56,  1.03it/s, loss=1.0725, batch_acc=0.9062, running_acc=0.7108, grad=17.5499]Training epoch 12:  27%|██▋       | 44/163 [00:52<02:22,  1.20s/it, loss=1.0725, batch_acc=0.9062, running_acc=0.7108, grad=17.5499]Training epoch 12:  27%|██▋       | 44/163 [00:52<02:22,  1.20s/it, loss=1.0997, batch_acc=0.8125, running_acc=0.7131, grad=20.8964]Training epoch 12:  28%|██▊       | 45/163 [00:53<02:09,  1.10s/it, loss=1.0997, batch_acc=0.8125, running_acc=0.7131, grad=20.8964]Training epoch 12:  28%|██▊       | 45/163 [00:53<02:09,  1.10s/it, loss=1.4033, batch_acc=0.6562, running_acc=0.7118, grad=25.5664]Training epoch 12:  28%|██▊       | 46/163 [00:54<02:01,  1.03s/it, loss=1.4033, batch_acc=0.6562, running_acc=0.7118, grad=25.5664]Training epoch 12:  28%|██▊       | 46/163 [00:54<02:01,  1.03s/it, loss=1.2783, batch_acc=0.7188, running_acc=0.7120, grad=19.7905]Training epoch 12:  29%|██▉       | 47/163 [00:55<01:54,  1.01it/s, loss=1.2783, batch_acc=0.7188, running_acc=0.7120, grad=19.7905]Training epoch 12:  29%|██▉       | 47/163 [00:55<01:54,  1.01it/s, loss=1.1833, batch_acc=0.7500, running_acc=0.7128, grad=25.7656]Training epoch 12:  29%|██▉       | 48/163 [00:56<01:54,  1.01it/s, loss=1.1833, batch_acc=0.7500, running_acc=0.7128, grad=25.7656]Training epoch 12:  29%|██▉       | 48/163 [00:56<01:54,  1.01it/s, loss=1.0511, batch_acc=0.7500, running_acc=0.7135, grad=19.2382]Training epoch 12:  30%|███       | 49/163 [00:57<01:49,  1.04it/s, loss=1.0511, batch_acc=0.7500, running_acc=0.7135, grad=19.2382]Training epoch 12:  30%|███       | 49/163 [00:57<01:49,  1.04it/s, loss=1.2738, batch_acc=0.7812, running_acc=0.7149, grad=19.5891]Training epoch 12:  31%|███       | 50/163 [00:58<01:45,  1.07it/s, loss=1.2738, batch_acc=0.7812, running_acc=0.7149, grad=19.5891]Training epoch 12:  31%|███       | 50/163 [00:58<01:45,  1.07it/s, loss=1.5739, batch_acc=0.5938, running_acc=0.7125, grad=23.5746]Training epoch 12:  31%|███▏      | 51/163 [00:58<01:42,  1.09it/s, loss=1.5739, batch_acc=0.5938, running_acc=0.7125, grad=23.5746]Training epoch 12:  31%|███▏      | 51/163 [00:58<01:42,  1.09it/s, loss=1.2303, batch_acc=0.7500, running_acc=0.7132, grad=24.3013]Training epoch 12:  32%|███▏      | 52/163 [01:00<02:16,  1.23s/it, loss=1.2303, batch_acc=0.7500, running_acc=0.7132, grad=24.3013]Training epoch 12:  32%|███▏      | 52/163 [01:00<02:16,  1.23s/it, loss=1.6130, batch_acc=0.5625, running_acc=0.7103, grad=25.5851]Training epoch 12:  33%|███▎      | 53/163 [01:01<02:03,  1.13s/it, loss=1.6130, batch_acc=0.5625, running_acc=0.7103, grad=25.5851]Training epoch 12:  33%|███▎      | 53/163 [01:01<02:03,  1.13s/it, loss=1.3405, batch_acc=0.6250, running_acc=0.7087, grad=21.5690]Training epoch 12:  33%|███▎      | 54/163 [01:02<01:54,  1.05s/it, loss=1.3405, batch_acc=0.6250, running_acc=0.7087, grad=21.5690]Training epoch 12:  33%|███▎      | 54/163 [01:02<01:54,  1.05s/it, loss=1.5928, batch_acc=0.5625, running_acc=0.7060, grad=32.3684]Training epoch 12:  34%|███▎      | 55/163 [01:03<01:47,  1.00it/s, loss=1.5928, batch_acc=0.5625, running_acc=0.7060, grad=32.3684]Training epoch 12:  34%|███▎      | 55/163 [01:03<01:47,  1.00it/s, loss=1.4022, batch_acc=0.6875, running_acc=0.7057, grad=22.9150]Training epoch 12:  34%|███▍      | 56/163 [01:05<02:03,  1.15s/it, loss=1.4022, batch_acc=0.6875, running_acc=0.7057, grad=22.9150]Training epoch 12:  34%|███▍      | 56/163 [01:05<02:03,  1.15s/it, loss=1.4484, batch_acc=0.5312, running_acc=0.7026, grad=24.0666]Training epoch 12:  35%|███▍      | 57/163 [01:05<01:53,  1.07s/it, loss=1.4484, batch_acc=0.5312, running_acc=0.7026, grad=24.0666]Training epoch 12:  35%|███▍      | 57/163 [01:05<01:53,  1.07s/it, loss=1.2780, batch_acc=0.7188, running_acc=0.7029, grad=20.7420]Training epoch 12:  36%|███▌      | 58/163 [01:06<01:46,  1.01s/it, loss=1.2780, batch_acc=0.7188, running_acc=0.7029, grad=20.7420]Training epoch 12:  36%|███▌      | 58/163 [01:06<01:46,  1.01s/it, loss=1.6647, batch_acc=0.6250, running_acc=0.7015, grad=20.1812]Training epoch 12:  36%|███▌      | 59/163 [01:07<01:41,  1.03it/s, loss=1.6647, batch_acc=0.6250, running_acc=0.7015, grad=20.1812]Training epoch 12:  36%|███▌      | 59/163 [01:07<01:41,  1.03it/s, loss=1.4363, batch_acc=0.7188, running_acc=0.7018, grad=23.2207]Training epoch 12:  37%|███▋      | 60/163 [01:08<01:46,  1.03s/it, loss=1.4363, batch_acc=0.7188, running_acc=0.7018, grad=23.2207]Training epoch 12:  37%|███▋      | 60/163 [01:08<01:46,  1.03s/it, loss=1.5655, batch_acc=0.6250, running_acc=0.7005, grad=29.0208]Training epoch 12:  37%|███▋      | 61/163 [01:09<01:40,  1.01it/s, loss=1.5655, batch_acc=0.6250, running_acc=0.7005, grad=29.0208]Training epoch 12:  37%|███▋      | 61/163 [01:09<01:40,  1.01it/s, loss=1.2895, batch_acc=0.7500, running_acc=0.7013, grad=22.8433]Training epoch 12:  38%|███▊      | 62/163 [01:10<01:36,  1.05it/s, loss=1.2895, batch_acc=0.7500, running_acc=0.7013, grad=22.8433]Training epoch 12:  38%|███▊      | 62/163 [01:10<01:36,  1.05it/s, loss=1.2058, batch_acc=0.7812, running_acc=0.7026, grad=19.5801]Training epoch 12:  39%|███▊      | 63/163 [01:11<01:33,  1.07it/s, loss=1.2058, batch_acc=0.7812, running_acc=0.7026, grad=19.5801]Training epoch 12:  39%|███▊      | 63/163 [01:11<01:33,  1.07it/s, loss=1.8686, batch_acc=0.5312, running_acc=0.6999, grad=30.0025]Training epoch 12:  39%|███▉      | 64/163 [01:13<02:09,  1.31s/it, loss=1.8686, batch_acc=0.5312, running_acc=0.6999, grad=30.0025]Training epoch 12:  39%|███▉      | 64/163 [01:13<02:09,  1.31s/it, loss=1.2823, batch_acc=0.6562, running_acc=0.6992, grad=21.3084]Training epoch 12:  40%|███▉      | 65/163 [01:14<01:56,  1.18s/it, loss=1.2823, batch_acc=0.6562, running_acc=0.6992, grad=21.3084]Training epoch 12:  40%|███▉      | 65/163 [01:14<01:56,  1.18s/it, loss=1.6166, batch_acc=0.5625, running_acc=0.6971, grad=22.9296]Training epoch 12:  40%|████      | 66/163 [01:15<01:45,  1.09s/it, loss=1.6166, batch_acc=0.5625, running_acc=0.6971, grad=22.9296]Training epoch 12:  40%|████      | 66/163 [01:15<01:45,  1.09s/it, loss=1.1569, batch_acc=0.7812, running_acc=0.6984, grad=20.9210]Training epoch 12:  41%|████      | 67/163 [01:16<01:38,  1.03s/it, loss=1.1569, batch_acc=0.7812, running_acc=0.6984, grad=20.9210]Training epoch 12:  41%|████      | 67/163 [01:16<01:38,  1.03s/it, loss=1.3799, batch_acc=0.6250, running_acc=0.6973, grad=27.4766]Training epoch 12:  42%|████▏     | 68/163 [01:17<01:47,  1.13s/it, loss=1.3799, batch_acc=0.6250, running_acc=0.6973, grad=27.4766]Training epoch 12:  42%|████▏     | 68/163 [01:17<01:47,  1.13s/it, loss=1.2237, batch_acc=0.7500, running_acc=0.6981, grad=21.9306]Training epoch 12:  42%|████▏     | 69/163 [01:18<01:39,  1.06s/it, loss=1.2237, batch_acc=0.7500, running_acc=0.6981, grad=21.9306]Training epoch 12:  42%|████▏     | 69/163 [01:18<01:39,  1.06s/it, loss=1.3023, batch_acc=0.6875, running_acc=0.6979, grad=18.3014]Training epoch 12:  43%|████▎     | 70/163 [01:19<01:33,  1.00s/it, loss=1.3023, batch_acc=0.6875, running_acc=0.6979, grad=18.3014]Training epoch 12:  43%|████▎     | 70/163 [01:19<01:33,  1.00s/it, loss=1.4142, batch_acc=0.7188, running_acc=0.6982, grad=22.5512]Training epoch 12:  44%|████▎     | 71/163 [01:20<01:28,  1.04it/s, loss=1.4142, batch_acc=0.7188, running_acc=0.6982, grad=22.5512]Training epoch 12:  44%|████▎     | 71/163 [01:20<01:28,  1.04it/s, loss=1.3541, batch_acc=0.5938, running_acc=0.6967, grad=25.4196]Training epoch 12:  44%|████▍     | 72/163 [01:21<01:46,  1.17s/it, loss=1.3541, batch_acc=0.5938, running_acc=0.6967, grad=25.4196]Training epoch 12:  44%|████▍     | 72/163 [01:21<01:46,  1.17s/it, loss=1.1599, batch_acc=0.8125, running_acc=0.6984, grad=17.9992]Training epoch 12:  45%|████▍     | 73/163 [01:22<01:37,  1.08s/it, loss=1.1599, batch_acc=0.8125, running_acc=0.6984, grad=17.9992]Training epoch 12:  45%|████▍     | 73/163 [01:22<01:37,  1.08s/it, loss=0.8705, batch_acc=0.8750, running_acc=0.7008, grad=13.6034]Training epoch 12:  45%|████▌     | 74/163 [01:23<01:30,  1.02s/it, loss=0.8705, batch_acc=0.8750, running_acc=0.7008, grad=13.6034]Training epoch 12:  45%|████▌     | 74/163 [01:23<01:30,  1.02s/it, loss=1.2047, batch_acc=0.7500, running_acc=0.7014, grad=26.8678]Training epoch 12:  46%|████▌     | 75/163 [01:24<01:25,  1.02it/s, loss=1.2047, batch_acc=0.7500, running_acc=0.7014, grad=26.8678]Training epoch 12:  46%|████▌     | 75/163 [01:24<01:25,  1.02it/s, loss=1.2584, batch_acc=0.7500, running_acc=0.7021, grad=26.1361]Training epoch 12:  47%|████▋     | 76/163 [01:25<01:28,  1.01s/it, loss=1.2584, batch_acc=0.7500, running_acc=0.7021, grad=26.1361]Training epoch 12:  47%|████▋     | 76/163 [01:25<01:28,  1.01s/it, loss=1.4648, batch_acc=0.6875, running_acc=0.7019, grad=20.9825]Training epoch 12:  47%|████▋     | 77/163 [01:27<01:34,  1.09s/it, loss=1.4648, batch_acc=0.6875, running_acc=0.7019, grad=20.9825]Training epoch 12:  47%|████▋     | 77/163 [01:27<01:34,  1.09s/it, loss=1.2456, batch_acc=0.7500, running_acc=0.7025, grad=24.4338]Training epoch 12:  48%|████▊     | 78/163 [01:27<01:27,  1.03s/it, loss=1.2456, batch_acc=0.7500, running_acc=0.7025, grad=24.4338]Training epoch 12:  48%|████▊     | 78/163 [01:27<01:27,  1.03s/it, loss=1.1529, batch_acc=0.8125, running_acc=0.7039, grad=24.0552]Training epoch 12:  48%|████▊     | 79/163 [01:28<01:22,  1.02it/s, loss=1.1529, batch_acc=0.8125, running_acc=0.7039, grad=24.0552]Training epoch 12:  48%|████▊     | 79/163 [01:28<01:22,  1.02it/s, loss=1.3624, batch_acc=0.6250, running_acc=0.7029, grad=21.6421]Training epoch 12:  49%|████▉     | 80/163 [01:29<01:23,  1.01s/it, loss=1.3624, batch_acc=0.6250, running_acc=0.7029, grad=21.6421]Training epoch 12:  49%|████▉     | 80/163 [01:29<01:23,  1.01s/it, loss=1.2955, batch_acc=0.6875, running_acc=0.7027, grad=19.8897]Training epoch 12:  50%|████▉     | 81/163 [01:31<01:36,  1.17s/it, loss=1.2955, batch_acc=0.6875, running_acc=0.7027, grad=19.8897]Training epoch 12:  50%|████▉     | 81/163 [01:31<01:36,  1.17s/it, loss=1.6647, batch_acc=0.5312, running_acc=0.7006, grad=23.5350]Training epoch 12:  50%|█████     | 82/163 [01:32<01:27,  1.09s/it, loss=1.6647, batch_acc=0.5312, running_acc=0.7006, grad=23.5350]Training epoch 12:  50%|█████     | 82/163 [01:32<01:27,  1.09s/it, loss=1.2642, batch_acc=0.6250, running_acc=0.6997, grad=22.5519]Training epoch 12:  51%|█████     | 83/163 [01:33<01:22,  1.03s/it, loss=1.2642, batch_acc=0.6250, running_acc=0.6997, grad=22.5519]Training epoch 12:  51%|█████     | 83/163 [01:33<01:22,  1.03s/it, loss=1.1446, batch_acc=0.6875, running_acc=0.6995, grad=18.0176]Training epoch 12:  52%|█████▏    | 84/163 [01:34<01:20,  1.02s/it, loss=1.1446, batch_acc=0.6875, running_acc=0.6995, grad=18.0176]Training epoch 12:  52%|█████▏    | 84/163 [01:34<01:20,  1.02s/it, loss=1.3736, batch_acc=0.7188, running_acc=0.6998, grad=23.9545]Training epoch 12:  52%|█████▏    | 85/163 [01:35<01:24,  1.08s/it, loss=1.3736, batch_acc=0.7188, running_acc=0.6998, grad=23.9545]Training epoch 12:  52%|█████▏    | 85/163 [01:35<01:24,  1.08s/it, loss=1.2409, batch_acc=0.7188, running_acc=0.7000, grad=22.5319]Training epoch 12:  53%|█████▎    | 86/163 [01:36<01:18,  1.02s/it, loss=1.2409, batch_acc=0.7188, running_acc=0.7000, grad=22.5319]Training epoch 12:  53%|█████▎    | 86/163 [01:36<01:18,  1.02s/it, loss=1.2587, batch_acc=0.6875, running_acc=0.6999, grad=21.0443]Training epoch 12:  53%|█████▎    | 87/163 [01:37<01:19,  1.05s/it, loss=1.2587, batch_acc=0.6875, running_acc=0.6999, grad=21.0443]Training epoch 12:  53%|█████▎    | 87/163 [01:37<01:19,  1.05s/it, loss=1.1993, batch_acc=0.6875, running_acc=0.6997, grad=30.9937]Training epoch 12:  54%|█████▍    | 88/163 [01:38<01:14,  1.00it/s, loss=1.1993, batch_acc=0.6875, running_acc=0.6997, grad=30.9937]Training epoch 12:  54%|█████▍    | 88/163 [01:38<01:14,  1.00it/s, loss=1.3454, batch_acc=0.7188, running_acc=0.6999, grad=25.5124]Training epoch 12:  55%|█████▍    | 89/163 [01:40<01:34,  1.28s/it, loss=1.3454, batch_acc=0.7188, running_acc=0.6999, grad=25.5124]Training epoch 12:  55%|█████▍    | 89/163 [01:40<01:34,  1.28s/it, loss=1.2953, batch_acc=0.7188, running_acc=0.7001, grad=24.8323]Training epoch 12:  55%|█████▌    | 90/163 [01:41<01:24,  1.16s/it, loss=1.2953, batch_acc=0.7188, running_acc=0.7001, grad=24.8323]Training epoch 12:  55%|█████▌    | 90/163 [01:41<01:24,  1.16s/it, loss=1.2659, batch_acc=0.6875, running_acc=0.7000, grad=23.6754]Training epoch 12:  56%|█████▌    | 91/163 [01:41<01:17,  1.08s/it, loss=1.2659, batch_acc=0.6875, running_acc=0.7000, grad=23.6754]Training epoch 12:  56%|█████▌    | 91/163 [01:41<01:17,  1.08s/it, loss=1.1787, batch_acc=0.6562, running_acc=0.6995, grad=25.8507]Training epoch 12:  56%|█████▋    | 92/163 [01:42<01:12,  1.02s/it, loss=1.1787, batch_acc=0.6562, running_acc=0.6995, grad=25.8507]Training epoch 12:  56%|█████▋    | 92/163 [01:42<01:12,  1.02s/it, loss=1.2028, batch_acc=0.6875, running_acc=0.6994, grad=21.4363]Training epoch 12:  57%|█████▋    | 93/163 [01:44<01:19,  1.14s/it, loss=1.2028, batch_acc=0.6875, running_acc=0.6994, grad=21.4363]Training epoch 12:  57%|█████▋    | 93/163 [01:44<01:19,  1.14s/it, loss=1.4709, batch_acc=0.6875, running_acc=0.6993, grad=26.2485]Training epoch 12:  58%|█████▊    | 94/163 [01:45<01:13,  1.06s/it, loss=1.4709, batch_acc=0.6875, running_acc=0.6993, grad=26.2485]Training epoch 12:  58%|█████▊    | 94/163 [01:45<01:13,  1.06s/it, loss=1.1806, batch_acc=0.7188, running_acc=0.6995, grad=17.7822]Training epoch 12:  58%|█████▊    | 95/163 [01:46<01:22,  1.22s/it, loss=1.1806, batch_acc=0.7188, running_acc=0.6995, grad=17.7822]Training epoch 12:  58%|█████▊    | 95/163 [01:46<01:22,  1.22s/it, loss=1.2122, batch_acc=0.7812, running_acc=0.7003, grad=26.7105]Training epoch 12:  59%|█████▉    | 96/163 [01:47<01:14,  1.12s/it, loss=1.2122, batch_acc=0.7812, running_acc=0.7003, grad=26.7105]Training epoch 12:  59%|█████▉    | 96/163 [01:47<01:14,  1.12s/it, loss=1.6154, batch_acc=0.5312, running_acc=0.6986, grad=23.1288]Training epoch 12:  60%|█████▉    | 97/163 [01:48<01:10,  1.07s/it, loss=1.6154, batch_acc=0.5312, running_acc=0.6986, grad=23.1288]Training epoch 12:  60%|█████▉    | 97/163 [01:48<01:10,  1.07s/it, loss=1.3411, batch_acc=0.6875, running_acc=0.6985, grad=22.1941]Training epoch 12:  60%|██████    | 98/163 [01:49<01:05,  1.01s/it, loss=1.3411, batch_acc=0.6875, running_acc=0.6985, grad=22.1941]Training epoch 12:  60%|██████    | 98/163 [01:49<01:05,  1.01s/it, loss=1.2259, batch_acc=0.8125, running_acc=0.6996, grad=20.1923]Training epoch 12:  61%|██████    | 99/163 [01:51<01:18,  1.22s/it, loss=1.2259, batch_acc=0.8125, running_acc=0.6996, grad=20.1923]Training epoch 12:  61%|██████    | 99/163 [01:51<01:18,  1.22s/it, loss=1.4399, batch_acc=0.6875, running_acc=0.6995, grad=25.0048]Training epoch 12:  61%|██████▏   | 100/163 [01:52<01:10,  1.12s/it, loss=1.4399, batch_acc=0.6875, running_acc=0.6995, grad=25.0048]Training epoch 12:  61%|██████▏   | 100/163 [01:52<01:10,  1.12s/it, loss=1.5408, batch_acc=0.6875, running_acc=0.6994, grad=30.7061]Training epoch 12:  62%|██████▏   | 101/163 [01:52<01:04,  1.05s/it, loss=1.5408, batch_acc=0.6875, running_acc=0.6994, grad=30.7061]Training epoch 12:  62%|██████▏   | 101/163 [01:52<01:04,  1.05s/it, loss=1.6699, batch_acc=0.5312, running_acc=0.6977, grad=33.0568]Training epoch 12:  63%|██████▎   | 102/163 [01:53<01:00,  1.00it/s, loss=1.6699, batch_acc=0.5312, running_acc=0.6977, grad=33.0568]Training epoch 12:  63%|██████▎   | 102/163 [01:53<01:00,  1.00it/s, loss=1.2124, batch_acc=0.7500, running_acc=0.6982, grad=23.8449]Training epoch 12:  63%|██████▎   | 103/163 [01:55<01:10,  1.18s/it, loss=1.2124, batch_acc=0.7500, running_acc=0.6982, grad=23.8449]Training epoch 12:  63%|██████▎   | 103/163 [01:55<01:10,  1.18s/it, loss=1.3245, batch_acc=0.6562, running_acc=0.6978, grad=24.5263]Training epoch 12:  64%|██████▍   | 104/163 [01:56<01:04,  1.09s/it, loss=1.3245, batch_acc=0.6562, running_acc=0.6978, grad=24.5263]Training epoch 12:  64%|██████▍   | 104/163 [01:56<01:04,  1.09s/it, loss=1.2925, batch_acc=0.7188, running_acc=0.6980, grad=18.3106]Training epoch 12:  64%|██████▍   | 105/163 [01:57<00:59,  1.03s/it, loss=1.2925, batch_acc=0.7188, running_acc=0.6980, grad=18.3106]Training epoch 12:  64%|██████▍   | 105/163 [01:57<00:59,  1.03s/it, loss=1.2402, batch_acc=0.7812, running_acc=0.6988, grad=22.6416]Training epoch 12:  65%|██████▌   | 106/163 [01:58<00:55,  1.02it/s, loss=1.2402, batch_acc=0.7812, running_acc=0.6988, grad=22.6416]Training epoch 12:  65%|██████▌   | 106/163 [01:58<00:55,  1.02it/s, loss=1.0503, batch_acc=0.7188, running_acc=0.6990, grad=21.2556]Training epoch 12:  66%|██████▌   | 107/163 [01:59<01:06,  1.18s/it, loss=1.0503, batch_acc=0.7188, running_acc=0.6990, grad=21.2556]Training epoch 12:  66%|██████▌   | 107/163 [01:59<01:06,  1.18s/it, loss=1.2551, batch_acc=0.7188, running_acc=0.6992, grad=24.1146]Training epoch 12:  66%|██████▋   | 108/163 [02:00<01:00,  1.09s/it, loss=1.2551, batch_acc=0.7188, running_acc=0.6992, grad=24.1146]Training epoch 12:  66%|██████▋   | 108/163 [02:00<01:00,  1.09s/it, loss=1.5400, batch_acc=0.6562, running_acc=0.6988, grad=27.3974]Training epoch 12:  67%|██████▋   | 109/163 [02:01<00:55,  1.03s/it, loss=1.5400, batch_acc=0.6562, running_acc=0.6988, grad=27.3974]Training epoch 12:  67%|██████▋   | 109/163 [02:01<00:55,  1.03s/it, loss=1.3252, batch_acc=0.7500, running_acc=0.6993, grad=22.2776]Training epoch 12:  67%|██████▋   | 110/163 [02:02<00:52,  1.02it/s, loss=1.3252, batch_acc=0.7500, running_acc=0.6993, grad=22.2776]Training epoch 12:  67%|██████▋   | 110/163 [02:02<00:52,  1.02it/s, loss=0.9081, batch_acc=0.8125, running_acc=0.7003, grad=18.8427]Training epoch 12:  68%|██████▊   | 111/163 [02:04<01:17,  1.49s/it, loss=0.9081, batch_acc=0.8125, running_acc=0.7003, grad=18.8427]Training epoch 12:  68%|██████▊   | 111/163 [02:04<01:17,  1.49s/it, loss=1.4682, batch_acc=0.6562, running_acc=0.6999, grad=21.9350]Training epoch 12:  69%|██████▊   | 112/163 [02:05<01:06,  1.30s/it, loss=1.4682, batch_acc=0.6562, running_acc=0.6999, grad=21.9350]Training epoch 12:  69%|██████▊   | 112/163 [02:05<01:06,  1.30s/it, loss=1.3283, batch_acc=0.6875, running_acc=0.6998, grad=27.0046]Training epoch 12:  69%|██████▉   | 113/163 [02:06<00:58,  1.18s/it, loss=1.3283, batch_acc=0.6875, running_acc=0.6998, grad=27.0046]Training epoch 12:  69%|██████▉   | 113/163 [02:06<00:58,  1.18s/it, loss=1.4083, batch_acc=0.6250, running_acc=0.6991, grad=20.6772]Training epoch 12:  70%|██████▉   | 114/163 [02:07<00:53,  1.09s/it, loss=1.4083, batch_acc=0.6250, running_acc=0.6991, grad=20.6772]Training epoch 12:  70%|██████▉   | 114/163 [02:07<00:53,  1.09s/it, loss=1.1644, batch_acc=0.7500, running_acc=0.6996, grad=26.7289]Training epoch 12:  71%|███████   | 115/163 [02:09<00:57,  1.21s/it, loss=1.1644, batch_acc=0.7500, running_acc=0.6996, grad=26.7289]Training epoch 12:  71%|███████   | 115/163 [02:09<00:57,  1.21s/it, loss=1.5835, batch_acc=0.5938, running_acc=0.6986, grad=27.8257]Training epoch 12:  71%|███████   | 116/163 [02:09<00:52,  1.11s/it, loss=1.5835, batch_acc=0.5938, running_acc=0.6986, grad=27.8257]Training epoch 12:  71%|███████   | 116/163 [02:09<00:52,  1.11s/it, loss=1.6134, batch_acc=0.6562, running_acc=0.6983, grad=30.3684]Training epoch 12:  72%|███████▏  | 117/163 [02:10<00:47,  1.04s/it, loss=1.6134, batch_acc=0.6562, running_acc=0.6983, grad=30.3684]Training epoch 12:  72%|███████▏  | 117/163 [02:10<00:47,  1.04s/it, loss=0.9181, batch_acc=0.8750, running_acc=0.6998, grad=20.7682]Training epoch 12:  72%|███████▏  | 118/163 [02:11<00:44,  1.01it/s, loss=0.9181, batch_acc=0.8750, running_acc=0.6998, grad=20.7682]Training epoch 12:  72%|███████▏  | 118/163 [02:11<00:44,  1.01it/s, loss=1.2143, batch_acc=0.7500, running_acc=0.7002, grad=19.0320]Training epoch 12:  73%|███████▎  | 119/163 [02:13<00:53,  1.21s/it, loss=1.2143, batch_acc=0.7500, running_acc=0.7002, grad=19.0320]Training epoch 12:  73%|███████▎  | 119/163 [02:13<00:53,  1.21s/it, loss=1.1707, batch_acc=0.7188, running_acc=0.7004, grad=21.4159]Training epoch 12:  74%|███████▎  | 120/163 [02:14<00:47,  1.11s/it, loss=1.1707, batch_acc=0.7188, running_acc=0.7004, grad=21.4159]Training epoch 12:  74%|███████▎  | 120/163 [02:14<00:47,  1.11s/it, loss=1.1508, batch_acc=0.8125, running_acc=0.7013, grad=19.5701]Training epoch 12:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=1.1508, batch_acc=0.8125, running_acc=0.7013, grad=19.5701]Training epoch 12:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=1.3468, batch_acc=0.6875, running_acc=0.7012, grad=20.5935]Training epoch 12:  75%|███████▍  | 122/163 [02:16<00:40,  1.01it/s, loss=1.3468, batch_acc=0.6875, running_acc=0.7012, grad=20.5935]Training epoch 12:  75%|███████▍  | 122/163 [02:16<00:40,  1.01it/s, loss=1.6275, batch_acc=0.5938, running_acc=0.7003, grad=21.0609]Training epoch 12:  75%|███████▌  | 123/163 [02:18<00:57,  1.43s/it, loss=1.6275, batch_acc=0.5938, running_acc=0.7003, grad=21.0609]Training epoch 12:  75%|███████▌  | 123/163 [02:18<00:57,  1.43s/it, loss=1.2256, batch_acc=0.7500, running_acc=0.7007, grad=15.8008]Training epoch 12:  76%|███████▌  | 124/163 [02:19<00:49,  1.26s/it, loss=1.2256, batch_acc=0.7500, running_acc=0.7007, grad=15.8008]Training epoch 12:  76%|███████▌  | 124/163 [02:19<00:49,  1.26s/it, loss=1.4477, batch_acc=0.7500, running_acc=0.7011, grad=31.7960]Training epoch 12:  77%|███████▋  | 125/163 [02:20<00:43,  1.15s/it, loss=1.4477, batch_acc=0.7500, running_acc=0.7011, grad=31.7960]Training epoch 12:  77%|███████▋  | 125/163 [02:20<00:43,  1.15s/it, loss=1.1059, batch_acc=0.8125, running_acc=0.7020, grad=22.6619]Training epoch 12:  77%|███████▋  | 126/163 [02:21<00:39,  1.07s/it, loss=1.1059, batch_acc=0.8125, running_acc=0.7020, grad=22.6619]Training epoch 12:  77%|███████▋  | 126/163 [02:21<00:39,  1.07s/it, loss=1.2885, batch_acc=0.8438, running_acc=0.7031, grad=21.1780]Training epoch 12:  78%|███████▊  | 127/163 [02:22<00:41,  1.15s/it, loss=1.2885, batch_acc=0.8438, running_acc=0.7031, grad=21.1780]Training epoch 12:  78%|███████▊  | 127/163 [02:22<00:41,  1.15s/it, loss=1.5038, batch_acc=0.6562, running_acc=0.7028, grad=34.4881]Training epoch 12:  79%|███████▊  | 128/163 [02:23<00:37,  1.07s/it, loss=1.5038, batch_acc=0.6562, running_acc=0.7028, grad=34.4881]Training epoch 12:  79%|███████▊  | 128/163 [02:23<00:37,  1.07s/it, loss=1.3437, batch_acc=0.7188, running_acc=0.7029, grad=26.0201]Training epoch 12:  79%|███████▉  | 129/163 [02:24<00:34,  1.01s/it, loss=1.3437, batch_acc=0.7188, running_acc=0.7029, grad=26.0201]Training epoch 12:  79%|███████▉  | 129/163 [02:24<00:34,  1.01s/it, loss=1.2784, batch_acc=0.6875, running_acc=0.7028, grad=19.9060]Training epoch 12:  80%|███████▉  | 130/163 [02:25<00:32,  1.03it/s, loss=1.2784, batch_acc=0.6875, running_acc=0.7028, grad=19.9060]Training epoch 12:  80%|███████▉  | 130/163 [02:25<00:32,  1.03it/s, loss=1.7389, batch_acc=0.6562, running_acc=0.7024, grad=23.2133]Training epoch 12:  80%|████████  | 131/163 [02:27<00:42,  1.34s/it, loss=1.7389, batch_acc=0.6562, running_acc=0.7024, grad=23.2133]Training epoch 12:  80%|████████  | 131/163 [02:27<00:42,  1.34s/it, loss=1.4166, batch_acc=0.6562, running_acc=0.7021, grad=28.9679]Training epoch 12:  81%|████████  | 132/163 [02:28<00:37,  1.20s/it, loss=1.4166, batch_acc=0.6562, running_acc=0.7021, grad=28.9679]Training epoch 12:  81%|████████  | 132/163 [02:28<00:37,  1.20s/it, loss=1.2191, batch_acc=0.7812, running_acc=0.7027, grad=22.9049]Training epoch 12:  82%|████████▏ | 133/163 [02:29<00:33,  1.10s/it, loss=1.2191, batch_acc=0.7812, running_acc=0.7027, grad=22.9049]Training epoch 12:  82%|████████▏ | 133/163 [02:29<00:33,  1.10s/it, loss=1.3538, batch_acc=0.6562, running_acc=0.7023, grad=19.5157]Training epoch 12:  82%|████████▏ | 134/163 [02:29<00:30,  1.04s/it, loss=1.3538, batch_acc=0.6562, running_acc=0.7023, grad=19.5157]Training epoch 12:  82%|████████▏ | 134/163 [02:29<00:30,  1.04s/it, loss=1.3016, batch_acc=0.7188, running_acc=0.7024, grad=26.0900]Training epoch 12:  83%|████████▎ | 135/163 [02:31<00:34,  1.24s/it, loss=1.3016, batch_acc=0.7188, running_acc=0.7024, grad=26.0900]Training epoch 12:  83%|████████▎ | 135/163 [02:31<00:34,  1.24s/it, loss=1.1112, batch_acc=0.7500, running_acc=0.7028, grad=19.6272]Training epoch 12:  83%|████████▎ | 136/163 [02:32<00:30,  1.13s/it, loss=1.1112, batch_acc=0.7500, running_acc=0.7028, grad=19.6272]Training epoch 12:  83%|████████▎ | 136/163 [02:32<00:30,  1.13s/it, loss=1.3335, batch_acc=0.7812, running_acc=0.7034, grad=20.5656]Training epoch 12:  84%|████████▍ | 137/163 [02:33<00:27,  1.06s/it, loss=1.3335, batch_acc=0.7812, running_acc=0.7034, grad=20.5656]Training epoch 12:  84%|████████▍ | 137/163 [02:33<00:27,  1.06s/it, loss=1.2153, batch_acc=0.7812, running_acc=0.7039, grad=25.0406]Training epoch 12:  85%|████████▍ | 138/163 [02:34<00:25,  1.00s/it, loss=1.2153, batch_acc=0.7812, running_acc=0.7039, grad=25.0406]Training epoch 12:  85%|████████▍ | 138/163 [02:34<00:25,  1.00s/it, loss=1.3121, batch_acc=0.7188, running_acc=0.7040, grad=20.6774]Training epoch 12:  85%|████████▌ | 139/163 [02:35<00:28,  1.18s/it, loss=1.3121, batch_acc=0.7188, running_acc=0.7040, grad=20.6774]Training epoch 12:  85%|████████▌ | 139/163 [02:35<00:28,  1.18s/it, loss=1.0688, batch_acc=0.7812, running_acc=0.7046, grad=20.6073]Training epoch 12:  86%|████████▌ | 140/163 [02:36<00:25,  1.09s/it, loss=1.0688, batch_acc=0.7812, running_acc=0.7046, grad=20.6073]Training epoch 12:  86%|████████▌ | 140/163 [02:36<00:25,  1.09s/it, loss=1.3033, batch_acc=0.7188, running_acc=0.7047, grad=21.0376]Training epoch 12:  87%|████████▋ | 141/163 [02:37<00:22,  1.03s/it, loss=1.3033, batch_acc=0.7188, running_acc=0.7047, grad=21.0376]Training epoch 12:  87%|████████▋ | 141/163 [02:37<00:22,  1.03s/it, loss=1.5459, batch_acc=0.6250, running_acc=0.7041, grad=20.4956]Training epoch 12:  87%|████████▋ | 142/163 [02:38<00:20,  1.02it/s, loss=1.5459, batch_acc=0.6250, running_acc=0.7041, grad=20.4956]Training epoch 12:  87%|████████▋ | 142/163 [02:38<00:20,  1.02it/s, loss=1.3411, batch_acc=0.6875, running_acc=0.7040, grad=20.4801]Training epoch 12:  88%|████████▊ | 143/163 [02:40<00:24,  1.22s/it, loss=1.3411, batch_acc=0.6875, running_acc=0.7040, grad=20.4801]Training epoch 12:  88%|████████▊ | 143/163 [02:40<00:24,  1.22s/it, loss=1.3089, batch_acc=0.7188, running_acc=0.7041, grad=20.7804]Training epoch 12:  88%|████████▊ | 144/163 [02:41<00:21,  1.12s/it, loss=1.3089, batch_acc=0.7188, running_acc=0.7041, grad=20.7804]Training epoch 12:  88%|████████▊ | 144/163 [02:41<00:21,  1.12s/it, loss=1.1234, batch_acc=0.8125, running_acc=0.7049, grad=24.6327]Training epoch 12:  89%|████████▉ | 145/163 [02:42<00:18,  1.05s/it, loss=1.1234, batch_acc=0.8125, running_acc=0.7049, grad=24.6327]Training epoch 12:  89%|████████▉ | 145/163 [02:42<00:18,  1.05s/it, loss=1.2434, batch_acc=0.7812, running_acc=0.7054, grad=24.3721]Training epoch 12:  90%|████████▉ | 146/163 [02:43<00:16,  1.00it/s, loss=1.2434, batch_acc=0.7812, running_acc=0.7054, grad=24.3721]Training epoch 12:  90%|████████▉ | 146/163 [02:43<00:16,  1.00it/s, loss=1.5203, batch_acc=0.5312, running_acc=0.7042, grad=21.6485]Training epoch 12:  90%|█████████ | 147/163 [02:44<00:18,  1.14s/it, loss=1.5203, batch_acc=0.5312, running_acc=0.7042, grad=21.6485]Training epoch 12:  90%|█████████ | 147/163 [02:44<00:18,  1.14s/it, loss=1.4085, batch_acc=0.6562, running_acc=0.7039, grad=26.5725]Training epoch 12:  91%|█████████ | 148/163 [02:45<00:15,  1.06s/it, loss=1.4085, batch_acc=0.6562, running_acc=0.7039, grad=26.5725]Training epoch 12:  91%|█████████ | 148/163 [02:45<00:15,  1.06s/it, loss=1.5514, batch_acc=0.5625, running_acc=0.7029, grad=25.8320]Training epoch 12:  91%|█████████▏| 149/163 [02:46<00:14,  1.01s/it, loss=1.5514, batch_acc=0.5625, running_acc=0.7029, grad=25.8320]Training epoch 12:  91%|█████████▏| 149/163 [02:46<00:14,  1.01s/it, loss=1.4712, batch_acc=0.7188, running_acc=0.7030, grad=18.6628]Training epoch 12:  92%|█████████▏| 150/163 [02:47<00:12,  1.03it/s, loss=1.4712, batch_acc=0.7188, running_acc=0.7030, grad=18.6628]Training epoch 12:  92%|█████████▏| 150/163 [02:47<00:12,  1.03it/s, loss=1.2580, batch_acc=0.6562, running_acc=0.7027, grad=24.5041]Training epoch 12:  93%|█████████▎| 151/163 [02:48<00:13,  1.16s/it, loss=1.2580, batch_acc=0.6562, running_acc=0.7027, grad=24.5041]Training epoch 12:  93%|█████████▎| 151/163 [02:48<00:13,  1.16s/it, loss=1.3935, batch_acc=0.6562, running_acc=0.7024, grad=27.4553]Training epoch 12:  93%|█████████▎| 152/163 [02:49<00:11,  1.08s/it, loss=1.3935, batch_acc=0.6562, running_acc=0.7024, grad=27.4553]Training epoch 12:  93%|█████████▎| 152/163 [02:49<00:11,  1.08s/it, loss=1.3025, batch_acc=0.7188, running_acc=0.7025, grad=24.6714]Training epoch 12:  94%|█████████▍| 153/163 [02:50<00:10,  1.02s/it, loss=1.3025, batch_acc=0.7188, running_acc=0.7025, grad=24.6714]Training epoch 12:  94%|█████████▍| 153/163 [02:50<00:10,  1.02s/it, loss=1.3590, batch_acc=0.7188, running_acc=0.7026, grad=27.0912]Training epoch 12:  94%|█████████▍| 154/163 [02:51<00:08,  1.02it/s, loss=1.3590, batch_acc=0.7188, running_acc=0.7026, grad=27.0912]Training epoch 12:  94%|█████████▍| 154/163 [02:51<00:08,  1.02it/s, loss=0.8330, batch_acc=0.8750, running_acc=0.7037, grad=20.4762]Training epoch 12:  95%|█████████▌| 155/163 [02:53<00:10,  1.29s/it, loss=0.8330, batch_acc=0.8750, running_acc=0.7037, grad=20.4762]Training epoch 12:  95%|█████████▌| 155/163 [02:53<00:10,  1.29s/it, loss=1.2755, batch_acc=0.7812, running_acc=0.7042, grad=22.8775]Training epoch 12:  96%|█████████▌| 156/163 [02:54<00:08,  1.17s/it, loss=1.2755, batch_acc=0.7812, running_acc=0.7042, grad=22.8775]Training epoch 12:  96%|█████████▌| 156/163 [02:54<00:08,  1.17s/it, loss=1.1571, batch_acc=0.8125, running_acc=0.7049, grad=21.6358]Training epoch 12:  96%|█████████▋| 157/163 [02:55<00:06,  1.08s/it, loss=1.1571, batch_acc=0.8125, running_acc=0.7049, grad=21.6358]Training epoch 12:  96%|█████████▋| 157/163 [02:55<00:06,  1.08s/it, loss=0.9434, batch_acc=0.8438, running_acc=0.7058, grad=24.1170]Training epoch 12:  97%|█████████▋| 158/163 [02:56<00:05,  1.02s/it, loss=0.9434, batch_acc=0.8438, running_acc=0.7058, grad=24.1170]Training epoch 12:  97%|█████████▋| 158/163 [02:56<00:05,  1.02s/it, loss=1.0677, batch_acc=0.8125, running_acc=0.7065, grad=15.7074]Training epoch 12:  98%|█████████▊| 159/163 [02:57<00:04,  1.23s/it, loss=1.0677, batch_acc=0.8125, running_acc=0.7065, grad=15.7074]Training epoch 12:  98%|█████████▊| 159/163 [02:57<00:04,  1.23s/it, loss=1.2852, batch_acc=0.6562, running_acc=0.7062, grad=18.7043]Training epoch 12:  98%|█████████▊| 160/163 [02:58<00:03,  1.12s/it, loss=1.2852, batch_acc=0.6562, running_acc=0.7062, grad=18.7043]Training epoch 12:  98%|█████████▊| 160/163 [02:58<00:03,  1.12s/it, loss=1.2504, batch_acc=0.7500, running_acc=0.7064, grad=24.0719]Training epoch 12:  99%|█████████▉| 161/163 [02:59<00:02,  1.05s/it, loss=1.2504, batch_acc=0.7500, running_acc=0.7064, grad=24.0719]Training epoch 12:  99%|█████████▉| 161/163 [02:59<00:02,  1.05s/it, loss=1.0199, batch_acc=0.8438, running_acc=0.7073, grad=18.0521]Training epoch 12:  99%|█████████▉| 162/163 [03:00<00:00,  1.00it/s, loss=1.0199, batch_acc=0.8438, running_acc=0.7073, grad=18.0521]Training epoch 12:  99%|█████████▉| 162/163 [03:00<00:00,  1.00it/s, loss=1.5787, batch_acc=0.5625, running_acc=0.7064, grad=24.7863]Training epoch 12: 100%|██████████| 163/163 [03:01<00:00,  1.12it/s, loss=1.5787, batch_acc=0.5625, running_acc=0.7064, grad=24.7863]Training epoch 12: 100%|██████████| 163/163 [03:01<00:00,  1.12it/s, loss=1.4324, batch_acc=0.6190, running_acc=0.7061, grad=31.6785]Training epoch 12: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=1.4324, batch_acc=0.6190, running_acc=0.7061, grad=31.6785]
Evaluation epoch 12:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 12:   4%|▎         | 1/28 [00:04<02:12,  4.92s/it]Evaluation epoch 12:   4%|▎         | 1/28 [00:04<02:12,  4.92s/it, loss=1.1129, batch_acc=0.7812, running_acc=0.7812]Evaluation epoch 12:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=1.1129, batch_acc=0.7812, running_acc=0.7812]Evaluation epoch 12:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=1.2309, batch_acc=0.6250, running_acc=0.7031]Evaluation epoch 12:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=1.2309, batch_acc=0.6250, running_acc=0.7031]Evaluation epoch 12:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=1.1547, batch_acc=0.8438, running_acc=0.7500]Evaluation epoch 12:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=1.1547, batch_acc=0.8438, running_acc=0.7500]Evaluation epoch 12:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=1.9560, batch_acc=0.4062, running_acc=0.6641]Evaluation epoch 12:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.9560, batch_acc=0.4062, running_acc=0.6641]Evaluation epoch 12:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=2.1649, batch_acc=0.4688, running_acc=0.6250]Evaluation epoch 12:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=2.1649, batch_acc=0.4688, running_acc=0.6250]Evaluation epoch 12:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.6825, batch_acc=0.5625, running_acc=0.6146]Evaluation epoch 12:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.6825, batch_acc=0.5625, running_acc=0.6146]Evaluation epoch 12:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.9123, batch_acc=0.5312, running_acc=0.6027]Evaluation epoch 12:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=1.9123, batch_acc=0.5312, running_acc=0.6027]Evaluation epoch 12:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=1.2138, batch_acc=0.6875, running_acc=0.6133]Evaluation epoch 12:  32%|███▏      | 9/28 [00:14<00:25,  1.37s/it, loss=1.2138, batch_acc=0.6875, running_acc=0.6133]Evaluation epoch 12:  32%|███▏      | 9/28 [00:14<00:25,  1.37s/it, loss=1.5274, batch_acc=0.6562, running_acc=0.6181]Evaluation epoch 12:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=1.5274, batch_acc=0.6562, running_acc=0.6181]Evaluation epoch 12:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.8108, batch_acc=0.8750, running_acc=0.6438]Evaluation epoch 12:  39%|███▉      | 11/28 [00:15<00:13,  1.26it/s, loss=0.8108, batch_acc=0.8750, running_acc=0.6438]Evaluation epoch 12:  39%|███▉      | 11/28 [00:15<00:13,  1.26it/s, loss=1.5723, batch_acc=0.7188, running_acc=0.6506]Evaluation epoch 12:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=1.5723, batch_acc=0.7188, running_acc=0.6506]Evaluation epoch 12:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=1.4681, batch_acc=0.6562, running_acc=0.6510]Evaluation epoch 12:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=1.4681, batch_acc=0.6562, running_acc=0.6510]Evaluation epoch 12:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=1.0329, batch_acc=0.8438, running_acc=0.6659]Evaluation epoch 12:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=1.0329, batch_acc=0.8438, running_acc=0.6659]Evaluation epoch 12:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=1.6743, batch_acc=0.6562, running_acc=0.6652]Evaluation epoch 12:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=1.6743, batch_acc=0.6562, running_acc=0.6652]Evaluation epoch 12:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=2.5490, batch_acc=0.3750, running_acc=0.6458]Evaluation epoch 12:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=2.5490, batch_acc=0.3750, running_acc=0.6458]Evaluation epoch 12:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=1.5775, batch_acc=0.5312, running_acc=0.6387]Evaluation epoch 12:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=1.5775, batch_acc=0.5312, running_acc=0.6387]Evaluation epoch 12:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=1.3696, batch_acc=0.7188, running_acc=0.6434]Evaluation epoch 12:  64%|██████▍   | 18/28 [00:24<00:08,  1.11it/s, loss=1.3696, batch_acc=0.7188, running_acc=0.6434]Evaluation epoch 12:  64%|██████▍   | 18/28 [00:24<00:08,  1.11it/s, loss=1.4276, batch_acc=0.6250, running_acc=0.6424]Evaluation epoch 12:  68%|██████▊   | 19/28 [00:25<00:06,  1.41it/s, loss=1.4276, batch_acc=0.6250, running_acc=0.6424]Evaluation epoch 12:  68%|██████▊   | 19/28 [00:25<00:06,  1.41it/s, loss=1.3368, batch_acc=0.5625, running_acc=0.6382]Evaluation epoch 12:  71%|███████▏  | 20/28 [00:28<00:11,  1.41s/it, loss=1.3368, batch_acc=0.5625, running_acc=0.6382]Evaluation epoch 12:  71%|███████▏  | 20/28 [00:28<00:11,  1.41s/it, loss=1.5662, batch_acc=0.5312, running_acc=0.6328]Evaluation epoch 12:  75%|███████▌  | 21/28 [00:28<00:07,  1.07s/it, loss=1.5662, batch_acc=0.5312, running_acc=0.6328]Evaluation epoch 12:  75%|███████▌  | 21/28 [00:28<00:07,  1.07s/it, loss=1.4054, batch_acc=0.7188, running_acc=0.6369]Evaluation epoch 12:  79%|███████▊  | 22/28 [00:28<00:04,  1.21it/s, loss=1.4054, batch_acc=0.7188, running_acc=0.6369]Evaluation epoch 12:  79%|███████▊  | 22/28 [00:28<00:04,  1.21it/s, loss=1.7286, batch_acc=0.5312, running_acc=0.6321]Evaluation epoch 12:  82%|████████▏ | 23/28 [00:29<00:03,  1.52it/s, loss=1.7286, batch_acc=0.5312, running_acc=0.6321]Evaluation epoch 12:  82%|████████▏ | 23/28 [00:29<00:03,  1.52it/s, loss=1.8216, batch_acc=0.5000, running_acc=0.6264]Evaluation epoch 12:  86%|████████▌ | 24/28 [00:34<00:08,  2.10s/it, loss=1.8216, batch_acc=0.5000, running_acc=0.6264]Evaluation epoch 12:  86%|████████▌ | 24/28 [00:34<00:08,  2.10s/it, loss=1.1579, batch_acc=0.7500, running_acc=0.6315]Evaluation epoch 12:  89%|████████▉ | 25/28 [00:34<00:04,  1.55s/it, loss=1.1579, batch_acc=0.7500, running_acc=0.6315]Evaluation epoch 12:  89%|████████▉ | 25/28 [00:34<00:04,  1.55s/it, loss=0.8135, batch_acc=0.8438, running_acc=0.6400]Evaluation epoch 12:  93%|█████████▎| 26/28 [00:35<00:02,  1.16s/it, loss=0.8135, batch_acc=0.8438, running_acc=0.6400]Evaluation epoch 12:  93%|█████████▎| 26/28 [00:35<00:02,  1.16s/it, loss=1.5953, batch_acc=0.4688, running_acc=0.6334]Evaluation epoch 12:  96%|█████████▋| 27/28 [00:35<00:00,  1.12it/s, loss=1.5953, batch_acc=0.4688, running_acc=0.6334]Evaluation epoch 12:  96%|█████████▋| 27/28 [00:35<00:00,  1.12it/s, loss=1.4280, batch_acc=0.5938, running_acc=0.6319]Evaluation epoch 12: 100%|██████████| 28/28 [00:35<00:00,  1.12it/s, loss=1.0337, batch_acc=0.6667, running_acc=0.6321]Evaluation epoch 12: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.0337, batch_acc=0.6667, running_acc=0.6321]
Training epoch 13:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 13:   1%|          | 1/163 [00:05<15:39,  5.80s/it]Training epoch 13:   1%|          | 1/163 [00:05<15:39,  5.80s/it, loss=0.9682, batch_acc=0.8125, running_acc=0.8125, grad=19.1724]Training epoch 13:   1%|          | 2/163 [00:06<07:47,  2.90s/it, loss=0.9682, batch_acc=0.8125, running_acc=0.8125, grad=19.1724]Training epoch 13:   1%|          | 2/163 [00:06<07:47,  2.90s/it, loss=1.2991, batch_acc=0.7188, running_acc=0.7656, grad=22.0287]Training epoch 13:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=1.2991, batch_acc=0.7188, running_acc=0.7656, grad=22.0287]Training epoch 13:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=1.0210, batch_acc=0.8438, running_acc=0.7917, grad=20.1265]Training epoch 13:   2%|▏         | 4/163 [00:09<05:33,  2.10s/it, loss=1.0210, batch_acc=0.8438, running_acc=0.7917, grad=20.1265]Training epoch 13:   2%|▏         | 4/163 [00:09<05:33,  2.10s/it, loss=1.4077, batch_acc=0.7500, running_acc=0.7812, grad=22.4169]Training epoch 13:   3%|▎         | 5/163 [00:11<04:38,  1.77s/it, loss=1.4077, batch_acc=0.7500, running_acc=0.7812, grad=22.4169]Training epoch 13:   3%|▎         | 5/163 [00:11<04:38,  1.77s/it, loss=1.3299, batch_acc=0.7500, running_acc=0.7750, grad=29.1128]Training epoch 13:   4%|▎         | 6/163 [00:11<03:49,  1.46s/it, loss=1.3299, batch_acc=0.7500, running_acc=0.7750, grad=29.1128]Training epoch 13:   4%|▎         | 6/163 [00:11<03:49,  1.46s/it, loss=1.2799, batch_acc=0.7188, running_acc=0.7656, grad=18.9951]Training epoch 13:   4%|▍         | 7/163 [00:12<03:18,  1.27s/it, loss=1.2799, batch_acc=0.7188, running_acc=0.7656, grad=18.9951]Training epoch 13:   4%|▍         | 7/163 [00:12<03:18,  1.27s/it, loss=1.0301, batch_acc=0.8438, running_acc=0.7768, grad=19.5079]Training epoch 13:   5%|▍         | 8/163 [00:14<03:25,  1.32s/it, loss=1.0301, batch_acc=0.8438, running_acc=0.7768, grad=19.5079]Training epoch 13:   5%|▍         | 8/163 [00:14<03:25,  1.32s/it, loss=1.1545, batch_acc=0.7188, running_acc=0.7695, grad=24.4165]Training epoch 13:   6%|▌         | 9/163 [00:15<03:05,  1.20s/it, loss=1.1545, batch_acc=0.7188, running_acc=0.7695, grad=24.4165]Training epoch 13:   6%|▌         | 9/163 [00:15<03:05,  1.20s/it, loss=1.2803, batch_acc=0.6875, running_acc=0.7604, grad=28.3088]Training epoch 13:   6%|▌         | 10/163 [00:16<02:48,  1.10s/it, loss=1.2803, batch_acc=0.6875, running_acc=0.7604, grad=28.3088]Training epoch 13:   6%|▌         | 10/163 [00:16<02:48,  1.10s/it, loss=1.0921, batch_acc=0.8750, running_acc=0.7719, grad=24.9938]Training epoch 13:   7%|▋         | 11/163 [00:16<02:37,  1.03s/it, loss=1.0921, batch_acc=0.8750, running_acc=0.7719, grad=24.9938]Training epoch 13:   7%|▋         | 11/163 [00:16<02:37,  1.03s/it, loss=1.1989, batch_acc=0.7500, running_acc=0.7699, grad=20.3573]Training epoch 13:   7%|▋         | 12/163 [00:18<02:56,  1.17s/it, loss=1.1989, batch_acc=0.7500, running_acc=0.7699, grad=20.3573]Training epoch 13:   7%|▋         | 12/163 [00:18<02:56,  1.17s/it, loss=1.0801, batch_acc=0.6875, running_acc=0.7630, grad=19.7862]Training epoch 13:   8%|▊         | 13/163 [00:19<02:55,  1.17s/it, loss=1.0801, batch_acc=0.6875, running_acc=0.7630, grad=19.7862]Training epoch 13:   8%|▊         | 13/163 [00:19<02:55,  1.17s/it, loss=1.1743, batch_acc=0.8438, running_acc=0.7692, grad=19.8034]Training epoch 13:   9%|▊         | 14/163 [00:20<02:41,  1.08s/it, loss=1.1743, batch_acc=0.8438, running_acc=0.7692, grad=19.8034]Training epoch 13:   9%|▊         | 14/163 [00:20<02:41,  1.08s/it, loss=1.4525, batch_acc=0.6250, running_acc=0.7589, grad=23.1093]Training epoch 13:   9%|▉         | 15/163 [00:21<02:31,  1.02s/it, loss=1.4525, batch_acc=0.6250, running_acc=0.7589, grad=23.1093]Training epoch 13:   9%|▉         | 15/163 [00:21<02:31,  1.02s/it, loss=1.3129, batch_acc=0.7500, running_acc=0.7583, grad=29.8676]Training epoch 13:  10%|▉         | 16/163 [00:22<02:55,  1.19s/it, loss=1.3129, batch_acc=0.7500, running_acc=0.7583, grad=29.8676]Training epoch 13:  10%|▉         | 16/163 [00:22<02:55,  1.19s/it, loss=1.2621, batch_acc=0.6875, running_acc=0.7539, grad=26.0404]Training epoch 13:  10%|█         | 17/163 [00:24<02:57,  1.22s/it, loss=1.2621, batch_acc=0.6875, running_acc=0.7539, grad=26.0404]Training epoch 13:  10%|█         | 17/163 [00:24<02:57,  1.22s/it, loss=0.9867, batch_acc=0.7188, running_acc=0.7518, grad=19.1162]Training epoch 13:  11%|█         | 18/163 [00:25<02:41,  1.11s/it, loss=0.9867, batch_acc=0.7188, running_acc=0.7518, grad=19.1162]Training epoch 13:  11%|█         | 18/163 [00:25<02:41,  1.11s/it, loss=1.1272, batch_acc=0.7812, running_acc=0.7535, grad=21.8339]Training epoch 13:  12%|█▏        | 19/163 [00:25<02:30,  1.04s/it, loss=1.1272, batch_acc=0.7812, running_acc=0.7535, grad=21.8339]Training epoch 13:  12%|█▏        | 19/163 [00:25<02:30,  1.04s/it, loss=1.0470, batch_acc=0.7500, running_acc=0.7533, grad=25.7004]Training epoch 13:  12%|█▏        | 20/163 [00:27<02:49,  1.18s/it, loss=1.0470, batch_acc=0.7500, running_acc=0.7533, grad=25.7004]Training epoch 13:  12%|█▏        | 20/163 [00:27<02:49,  1.18s/it, loss=1.2122, batch_acc=0.7188, running_acc=0.7516, grad=20.2323]Training epoch 13:  13%|█▎        | 21/163 [00:29<03:06,  1.31s/it, loss=1.2122, batch_acc=0.7188, running_acc=0.7516, grad=20.2323]Training epoch 13:  13%|█▎        | 21/163 [00:29<03:06,  1.31s/it, loss=1.3277, batch_acc=0.7188, running_acc=0.7500, grad=23.0412]Training epoch 13:  13%|█▎        | 22/163 [00:29<02:46,  1.18s/it, loss=1.3277, batch_acc=0.7188, running_acc=0.7500, grad=23.0412]Training epoch 13:  13%|█▎        | 22/163 [00:29<02:46,  1.18s/it, loss=1.1992, batch_acc=0.7500, running_acc=0.7500, grad=19.6417]Training epoch 13:  14%|█▍        | 23/163 [00:30<02:32,  1.09s/it, loss=1.1992, batch_acc=0.7500, running_acc=0.7500, grad=19.6417]Training epoch 13:  14%|█▍        | 23/163 [00:30<02:32,  1.09s/it, loss=1.2576, batch_acc=0.7188, running_acc=0.7486, grad=28.1611]Training epoch 13:  15%|█▍        | 24/163 [00:31<02:33,  1.10s/it, loss=1.2576, batch_acc=0.7188, running_acc=0.7486, grad=28.1611]Training epoch 13:  15%|█▍        | 24/163 [00:31<02:33,  1.10s/it, loss=1.3302, batch_acc=0.6250, running_acc=0.7435, grad=23.2058]Training epoch 13:  15%|█▌        | 25/163 [00:33<02:58,  1.30s/it, loss=1.3302, batch_acc=0.6250, running_acc=0.7435, grad=23.2058]Training epoch 13:  15%|█▌        | 25/163 [00:33<02:58,  1.30s/it, loss=1.1154, batch_acc=0.7188, running_acc=0.7425, grad=22.1274]Training epoch 13:  16%|█▌        | 26/163 [00:34<02:40,  1.17s/it, loss=1.1154, batch_acc=0.7188, running_acc=0.7425, grad=22.1274]Training epoch 13:  16%|█▌        | 26/163 [00:34<02:40,  1.17s/it, loss=1.3055, batch_acc=0.6562, running_acc=0.7392, grad=24.0288]Training epoch 13:  17%|█▋        | 27/163 [00:35<02:27,  1.08s/it, loss=1.3055, batch_acc=0.6562, running_acc=0.7392, grad=24.0288]Training epoch 13:  17%|█▋        | 27/163 [00:35<02:27,  1.08s/it, loss=1.2332, batch_acc=0.7188, running_acc=0.7384, grad=23.1573]Training epoch 13:  17%|█▋        | 28/163 [00:36<02:37,  1.17s/it, loss=1.2332, batch_acc=0.7188, running_acc=0.7384, grad=23.1573]Training epoch 13:  17%|█▋        | 28/163 [00:36<02:37,  1.17s/it, loss=1.3754, batch_acc=0.6875, running_acc=0.7366, grad=27.9639]Training epoch 13:  18%|█▊        | 29/163 [00:37<02:24,  1.08s/it, loss=1.3754, batch_acc=0.6875, running_acc=0.7366, grad=27.9639]Training epoch 13:  18%|█▊        | 29/163 [00:37<02:24,  1.08s/it, loss=1.1755, batch_acc=0.6562, running_acc=0.7338, grad=17.1150]Training epoch 13:  18%|█▊        | 30/163 [00:38<02:15,  1.02s/it, loss=1.1755, batch_acc=0.6562, running_acc=0.7338, grad=17.1150]Training epoch 13:  18%|█▊        | 30/163 [00:38<02:15,  1.02s/it, loss=0.8865, batch_acc=0.8750, running_acc=0.7385, grad=25.0966]Training epoch 13:  19%|█▉        | 31/163 [00:39<02:09,  1.02it/s, loss=0.8865, batch_acc=0.8750, running_acc=0.7385, grad=25.0966]Training epoch 13:  19%|█▉        | 31/163 [00:39<02:09,  1.02it/s, loss=1.2770, batch_acc=0.6562, running_acc=0.7359, grad=19.7859]Training epoch 13:  20%|█▉        | 32/163 [00:41<02:42,  1.24s/it, loss=1.2770, batch_acc=0.6562, running_acc=0.7359, grad=19.7859]Training epoch 13:  20%|█▉        | 32/163 [00:41<02:42,  1.24s/it, loss=0.9051, batch_acc=0.9062, running_acc=0.7412, grad=15.4487]Training epoch 13:  20%|██        | 33/163 [00:42<02:26,  1.13s/it, loss=0.9051, batch_acc=0.9062, running_acc=0.7412, grad=15.4487]Training epoch 13:  20%|██        | 33/163 [00:42<02:26,  1.13s/it, loss=1.2830, batch_acc=0.7500, running_acc=0.7415, grad=24.5620]Training epoch 13:  21%|██        | 34/163 [00:43<02:15,  1.05s/it, loss=1.2830, batch_acc=0.7500, running_acc=0.7415, grad=24.5620]Training epoch 13:  21%|██        | 34/163 [00:43<02:15,  1.05s/it, loss=1.3963, batch_acc=0.6875, running_acc=0.7399, grad=19.5839]Training epoch 13:  21%|██▏       | 35/163 [00:43<02:08,  1.00s/it, loss=1.3963, batch_acc=0.6875, running_acc=0.7399, grad=19.5839]Training epoch 13:  21%|██▏       | 35/163 [00:43<02:08,  1.00s/it, loss=0.9545, batch_acc=0.8125, running_acc=0.7420, grad=19.5162]Training epoch 13:  22%|██▏       | 36/163 [00:45<02:36,  1.23s/it, loss=0.9545, batch_acc=0.8125, running_acc=0.7420, grad=19.5162]Training epoch 13:  22%|██▏       | 36/163 [00:45<02:36,  1.23s/it, loss=0.9997, batch_acc=0.8438, running_acc=0.7448, grad=18.1242]Training epoch 13:  23%|██▎       | 37/163 [00:46<02:25,  1.16s/it, loss=0.9997, batch_acc=0.8438, running_acc=0.7448, grad=18.1242]Training epoch 13:  23%|██▎       | 37/163 [00:46<02:25,  1.16s/it, loss=1.2274, batch_acc=0.7500, running_acc=0.7449, grad=19.7922]Training epoch 13:  23%|██▎       | 38/163 [00:47<02:14,  1.07s/it, loss=1.2274, batch_acc=0.7500, running_acc=0.7449, grad=19.7922]Training epoch 13:  23%|██▎       | 38/163 [00:47<02:14,  1.07s/it, loss=1.0012, batch_acc=0.7812, running_acc=0.7459, grad=20.9051]Training epoch 13:  24%|██▍       | 39/163 [00:48<02:06,  1.02s/it, loss=1.0012, batch_acc=0.7812, running_acc=0.7459, grad=20.9051]Training epoch 13:  24%|██▍       | 39/163 [00:48<02:06,  1.02s/it, loss=1.2224, batch_acc=0.8125, running_acc=0.7476, grad=18.6657]Training epoch 13:  25%|██▍       | 40/163 [00:49<02:12,  1.08s/it, loss=1.2224, batch_acc=0.8125, running_acc=0.7476, grad=18.6657]Training epoch 13:  25%|██▍       | 40/163 [00:49<02:12,  1.08s/it, loss=1.1120, batch_acc=0.7812, running_acc=0.7484, grad=27.5325]Training epoch 13:  25%|██▌       | 41/163 [00:51<02:34,  1.27s/it, loss=1.1120, batch_acc=0.7812, running_acc=0.7484, grad=27.5325]Training epoch 13:  25%|██▌       | 41/163 [00:51<02:34,  1.27s/it, loss=1.3959, batch_acc=0.7500, running_acc=0.7485, grad=29.0660]Training epoch 13:  26%|██▌       | 42/163 [00:52<02:19,  1.15s/it, loss=1.3959, batch_acc=0.7500, running_acc=0.7485, grad=29.0660]Training epoch 13:  26%|██▌       | 42/163 [00:52<02:19,  1.15s/it, loss=1.2430, batch_acc=0.7188, running_acc=0.7478, grad=21.2658]Training epoch 13:  26%|██▋       | 43/163 [00:53<02:11,  1.09s/it, loss=1.2430, batch_acc=0.7188, running_acc=0.7478, grad=21.2658]Training epoch 13:  26%|██▋       | 43/163 [00:53<02:11,  1.09s/it, loss=1.4312, batch_acc=0.7500, running_acc=0.7478, grad=24.0317]Training epoch 13:  27%|██▋       | 44/163 [00:54<02:06,  1.06s/it, loss=1.4312, batch_acc=0.7500, running_acc=0.7478, grad=24.0317]Training epoch 13:  27%|██▋       | 44/163 [00:54<02:06,  1.06s/it, loss=1.0434, batch_acc=0.7500, running_acc=0.7479, grad=21.6728]Training epoch 13:  28%|██▊       | 45/163 [00:55<02:16,  1.16s/it, loss=1.0434, batch_acc=0.7500, running_acc=0.7479, grad=21.6728]Training epoch 13:  28%|██▊       | 45/163 [00:55<02:16,  1.16s/it, loss=1.4215, batch_acc=0.7812, running_acc=0.7486, grad=24.5972]Training epoch 13:  28%|██▊       | 46/163 [00:56<02:05,  1.07s/it, loss=1.4215, batch_acc=0.7812, running_acc=0.7486, grad=24.5972]Training epoch 13:  28%|██▊       | 46/163 [00:56<02:05,  1.07s/it, loss=0.8427, batch_acc=0.9062, running_acc=0.7520, grad=19.0301]Training epoch 13:  29%|██▉       | 47/163 [00:57<02:01,  1.05s/it, loss=0.8427, batch_acc=0.9062, running_acc=0.7520, grad=19.0301]Training epoch 13:  29%|██▉       | 47/163 [00:57<02:01,  1.05s/it, loss=1.1894, batch_acc=0.8750, running_acc=0.7547, grad=20.6297]Training epoch 13:  29%|██▉       | 48/163 [00:58<02:08,  1.12s/it, loss=1.1894, batch_acc=0.8750, running_acc=0.7547, grad=20.6297]Training epoch 13:  29%|██▉       | 48/163 [00:58<02:08,  1.12s/it, loss=1.0635, batch_acc=0.8438, running_acc=0.7565, grad=20.8327]Training epoch 13:  30%|███       | 49/163 [01:00<02:20,  1.23s/it, loss=1.0635, batch_acc=0.8438, running_acc=0.7565, grad=20.8327]Training epoch 13:  30%|███       | 49/163 [01:00<02:20,  1.23s/it, loss=1.2663, batch_acc=0.7500, running_acc=0.7564, grad=25.1308]Training epoch 13:  31%|███       | 50/163 [01:01<02:07,  1.13s/it, loss=1.2663, batch_acc=0.7500, running_acc=0.7564, grad=25.1308]Training epoch 13:  31%|███       | 50/163 [01:01<02:07,  1.13s/it, loss=1.1758, batch_acc=0.6562, running_acc=0.7544, grad=17.9160]Training epoch 13:  31%|███▏      | 51/163 [01:01<01:57,  1.05s/it, loss=1.1758, batch_acc=0.6562, running_acc=0.7544, grad=17.9160]Training epoch 13:  31%|███▏      | 51/163 [01:01<01:57,  1.05s/it, loss=0.8719, batch_acc=0.8438, running_acc=0.7561, grad=14.7216]Training epoch 13:  32%|███▏      | 52/163 [01:03<01:57,  1.05s/it, loss=0.8719, batch_acc=0.8438, running_acc=0.7561, grad=14.7216]Training epoch 13:  32%|███▏      | 52/163 [01:03<01:57,  1.05s/it, loss=1.3561, batch_acc=0.6562, running_acc=0.7542, grad=20.7836]Training epoch 13:  33%|███▎      | 53/163 [01:04<02:02,  1.11s/it, loss=1.3561, batch_acc=0.6562, running_acc=0.7542, grad=20.7836]Training epoch 13:  33%|███▎      | 53/163 [01:04<02:02,  1.11s/it, loss=1.5384, batch_acc=0.6875, running_acc=0.7529, grad=27.1586]Training epoch 13:  33%|███▎      | 54/163 [01:05<01:53,  1.04s/it, loss=1.5384, batch_acc=0.6875, running_acc=0.7529, grad=27.1586]Training epoch 13:  33%|███▎      | 54/163 [01:05<01:53,  1.04s/it, loss=1.2036, batch_acc=0.7188, running_acc=0.7523, grad=26.3714]Training epoch 13:  34%|███▎      | 55/163 [01:06<01:47,  1.01it/s, loss=1.2036, batch_acc=0.7188, running_acc=0.7523, grad=26.3714]Training epoch 13:  34%|███▎      | 55/163 [01:06<01:47,  1.01it/s, loss=1.3466, batch_acc=0.7188, running_acc=0.7517, grad=21.3187]Training epoch 13:  34%|███▍      | 56/163 [01:07<01:50,  1.03s/it, loss=1.3466, batch_acc=0.7188, running_acc=0.7517, grad=21.3187]Training epoch 13:  34%|███▍      | 56/163 [01:07<01:50,  1.03s/it, loss=0.9383, batch_acc=0.8438, running_acc=0.7533, grad=17.1301]Training epoch 13:  35%|███▍      | 57/163 [01:08<01:48,  1.03s/it, loss=0.9383, batch_acc=0.8438, running_acc=0.7533, grad=17.1301]Training epoch 13:  35%|███▍      | 57/163 [01:08<01:48,  1.03s/it, loss=1.2005, batch_acc=0.7500, running_acc=0.7533, grad=18.6334]Training epoch 13:  36%|███▌      | 58/163 [01:09<01:42,  1.02it/s, loss=1.2005, batch_acc=0.7500, running_acc=0.7533, grad=18.6334]Training epoch 13:  36%|███▌      | 58/163 [01:09<01:42,  1.02it/s, loss=1.2805, batch_acc=0.7812, running_acc=0.7538, grad=26.2906]Training epoch 13:  36%|███▌      | 59/163 [01:09<01:38,  1.05it/s, loss=1.2805, batch_acc=0.7812, running_acc=0.7538, grad=26.2906]Training epoch 13:  36%|███▌      | 59/163 [01:09<01:38,  1.05it/s, loss=1.2362, batch_acc=0.7188, running_acc=0.7532, grad=34.3525]Training epoch 13:  37%|███▋      | 60/163 [01:12<02:13,  1.29s/it, loss=1.2362, batch_acc=0.7188, running_acc=0.7532, grad=34.3525]Training epoch 13:  37%|███▋      | 60/163 [01:12<02:13,  1.29s/it, loss=1.4198, batch_acc=0.6562, running_acc=0.7516, grad=25.5004]Training epoch 13:  37%|███▋      | 61/163 [01:12<01:59,  1.17s/it, loss=1.4198, batch_acc=0.6562, running_acc=0.7516, grad=25.5004]Training epoch 13:  37%|███▋      | 61/163 [01:12<01:59,  1.17s/it, loss=1.1707, batch_acc=0.7812, running_acc=0.7520, grad=27.2645]Training epoch 13:  38%|███▊      | 62/163 [01:13<01:49,  1.08s/it, loss=1.1707, batch_acc=0.7812, running_acc=0.7520, grad=27.2645]Training epoch 13:  38%|███▊      | 62/163 [01:13<01:49,  1.08s/it, loss=1.4050, batch_acc=0.5938, running_acc=0.7495, grad=27.8158]Training epoch 13:  39%|███▊      | 63/163 [01:14<01:43,  1.04s/it, loss=1.4050, batch_acc=0.5938, running_acc=0.7495, grad=27.8158]Training epoch 13:  39%|███▊      | 63/163 [01:14<01:43,  1.04s/it, loss=1.4172, batch_acc=0.5938, running_acc=0.7470, grad=21.6415]Training epoch 13:  39%|███▉      | 64/163 [01:15<01:38,  1.00it/s, loss=1.4172, batch_acc=0.5938, running_acc=0.7470, grad=21.6415]Training epoch 13:  39%|███▉      | 64/163 [01:15<01:38,  1.00it/s, loss=1.1701, batch_acc=0.7812, running_acc=0.7476, grad=26.5181]Training epoch 13:  40%|███▉      | 65/163 [01:16<01:34,  1.04it/s, loss=1.1701, batch_acc=0.7812, running_acc=0.7476, grad=26.5181]Training epoch 13:  40%|███▉      | 65/163 [01:16<01:34,  1.04it/s, loss=1.2105, batch_acc=0.7188, running_acc=0.7471, grad=23.0181]Training epoch 13:  40%|████      | 66/163 [01:17<01:30,  1.07it/s, loss=1.2105, batch_acc=0.7188, running_acc=0.7471, grad=23.0181]Training epoch 13:  40%|████      | 66/163 [01:17<01:30,  1.07it/s, loss=1.0353, batch_acc=0.7500, running_acc=0.7472, grad=20.3142]Training epoch 13:  41%|████      | 67/163 [01:19<01:50,  1.15s/it, loss=1.0353, batch_acc=0.7500, running_acc=0.7472, grad=20.3142]Training epoch 13:  41%|████      | 67/163 [01:19<01:50,  1.15s/it, loss=1.5789, batch_acc=0.6250, running_acc=0.7453, grad=26.2708]Training epoch 13:  42%|████▏     | 68/163 [01:20<01:48,  1.15s/it, loss=1.5789, batch_acc=0.6250, running_acc=0.7453, grad=26.2708]Training epoch 13:  42%|████▏     | 68/163 [01:20<01:48,  1.15s/it, loss=1.1370, batch_acc=0.7500, running_acc=0.7454, grad=23.2658]Training epoch 13:  42%|████▏     | 69/163 [01:21<01:40,  1.06s/it, loss=1.1370, batch_acc=0.7500, running_acc=0.7454, grad=23.2658]Training epoch 13:  42%|████▏     | 69/163 [01:21<01:40,  1.06s/it, loss=1.1278, batch_acc=0.8750, running_acc=0.7473, grad=22.0602]Training epoch 13:  43%|████▎     | 70/163 [01:21<01:33,  1.01s/it, loss=1.1278, batch_acc=0.8750, running_acc=0.7473, grad=22.0602]Training epoch 13:  43%|████▎     | 70/163 [01:21<01:33,  1.01s/it, loss=1.3275, batch_acc=0.6875, running_acc=0.7464, grad=26.5074]Training epoch 13:  44%|████▎     | 71/163 [01:23<01:40,  1.09s/it, loss=1.3275, batch_acc=0.6875, running_acc=0.7464, grad=26.5074]Training epoch 13:  44%|████▎     | 71/163 [01:23<01:40,  1.09s/it, loss=1.0927, batch_acc=0.7812, running_acc=0.7469, grad=27.9100]Training epoch 13:  44%|████▍     | 72/163 [01:24<01:36,  1.06s/it, loss=1.0927, batch_acc=0.7812, running_acc=0.7469, grad=27.9100]Training epoch 13:  44%|████▍     | 72/163 [01:24<01:36,  1.06s/it, loss=1.1718, batch_acc=0.7500, running_acc=0.7470, grad=23.3422]Training epoch 13:  45%|████▍     | 73/163 [01:25<01:30,  1.00s/it, loss=1.1718, batch_acc=0.7500, running_acc=0.7470, grad=23.3422]Training epoch 13:  45%|████▍     | 73/163 [01:25<01:30,  1.00s/it, loss=1.0769, batch_acc=0.7500, running_acc=0.7470, grad=17.6448]Training epoch 13:  45%|████▌     | 74/163 [01:25<01:25,  1.04it/s, loss=1.0769, batch_acc=0.7500, running_acc=0.7470, grad=17.6448]Training epoch 13:  45%|████▌     | 74/163 [01:25<01:25,  1.04it/s, loss=1.1099, batch_acc=0.7500, running_acc=0.7470, grad=21.3459]Training epoch 13:  46%|████▌     | 75/163 [01:27<01:45,  1.20s/it, loss=1.1099, batch_acc=0.7500, running_acc=0.7470, grad=21.3459]Training epoch 13:  46%|████▌     | 75/163 [01:27<01:45,  1.20s/it, loss=0.9587, batch_acc=0.8438, running_acc=0.7483, grad=26.9961]Training epoch 13:  47%|████▋     | 76/163 [01:28<01:36,  1.10s/it, loss=0.9587, batch_acc=0.8438, running_acc=0.7483, grad=26.9961]Training epoch 13:  47%|████▋     | 76/163 [01:28<01:36,  1.10s/it, loss=1.4543, batch_acc=0.6562, running_acc=0.7471, grad=27.6750]Training epoch 13:  47%|████▋     | 77/163 [01:29<01:37,  1.13s/it, loss=1.4543, batch_acc=0.6562, running_acc=0.7471, grad=27.6750]Training epoch 13:  47%|████▋     | 77/163 [01:29<01:37,  1.13s/it, loss=1.0474, batch_acc=0.8125, running_acc=0.7480, grad=19.2740]Training epoch 13:  48%|████▊     | 78/163 [01:30<01:29,  1.05s/it, loss=1.0474, batch_acc=0.8125, running_acc=0.7480, grad=19.2740]Training epoch 13:  48%|████▊     | 78/163 [01:30<01:29,  1.05s/it, loss=0.8944, batch_acc=0.9062, running_acc=0.7500, grad=23.1054]Training epoch 13:  48%|████▊     | 79/163 [01:31<01:36,  1.15s/it, loss=0.8944, batch_acc=0.9062, running_acc=0.7500, grad=23.1054]Training epoch 13:  48%|████▊     | 79/163 [01:31<01:36,  1.15s/it, loss=1.2521, batch_acc=0.7188, running_acc=0.7496, grad=20.9894]Training epoch 13:  49%|████▉     | 80/163 [01:32<01:28,  1.07s/it, loss=1.2521, batch_acc=0.7188, running_acc=0.7496, grad=20.9894]Training epoch 13:  49%|████▉     | 80/163 [01:32<01:28,  1.07s/it, loss=1.1063, batch_acc=0.7812, running_acc=0.7500, grad=19.3242]Training epoch 13:  50%|████▉     | 81/163 [01:33<01:25,  1.04s/it, loss=1.1063, batch_acc=0.7812, running_acc=0.7500, grad=19.3242]Training epoch 13:  50%|████▉     | 81/163 [01:33<01:25,  1.04s/it, loss=0.6535, batch_acc=0.9375, running_acc=0.7523, grad=13.3681]Training epoch 13:  50%|█████     | 82/163 [01:34<01:20,  1.01it/s, loss=0.6535, batch_acc=0.9375, running_acc=0.7523, grad=13.3681]Training epoch 13:  50%|█████     | 82/163 [01:34<01:20,  1.01it/s, loss=1.2492, batch_acc=0.7188, running_acc=0.7519, grad=25.3198]Training epoch 13:  51%|█████     | 83/163 [01:36<01:41,  1.27s/it, loss=1.2492, batch_acc=0.7188, running_acc=0.7519, grad=25.3198]Training epoch 13:  51%|█████     | 83/163 [01:36<01:41,  1.27s/it, loss=1.3022, batch_acc=0.7188, running_acc=0.7515, grad=29.0630]Training epoch 13:  52%|█████▏    | 84/163 [01:37<01:31,  1.15s/it, loss=1.3022, batch_acc=0.7188, running_acc=0.7515, grad=29.0630]Training epoch 13:  52%|█████▏    | 84/163 [01:37<01:31,  1.15s/it, loss=1.1818, batch_acc=0.7812, running_acc=0.7519, grad=20.1389]Training epoch 13:  52%|█████▏    | 85/163 [01:38<01:23,  1.07s/it, loss=1.1818, batch_acc=0.7812, running_acc=0.7519, grad=20.1389]Training epoch 13:  52%|█████▏    | 85/163 [01:38<01:23,  1.07s/it, loss=1.3123, batch_acc=0.6875, running_acc=0.7511, grad=30.8980]Training epoch 13:  53%|█████▎    | 86/163 [01:39<01:18,  1.01s/it, loss=1.3123, batch_acc=0.6875, running_acc=0.7511, grad=30.8980]Training epoch 13:  53%|█████▎    | 86/163 [01:39<01:18,  1.01s/it, loss=1.5130, batch_acc=0.6875, running_acc=0.7504, grad=21.2304]Training epoch 13:  53%|█████▎    | 87/163 [01:41<01:33,  1.23s/it, loss=1.5130, batch_acc=0.6875, running_acc=0.7504, grad=21.2304]Training epoch 13:  53%|█████▎    | 87/163 [01:41<01:33,  1.23s/it, loss=1.3031, batch_acc=0.6562, running_acc=0.7493, grad=22.8984]Training epoch 13:  54%|█████▍    | 88/163 [01:41<01:24,  1.12s/it, loss=1.3031, batch_acc=0.6562, running_acc=0.7493, grad=22.8984]Training epoch 13:  54%|█████▍    | 88/163 [01:41<01:24,  1.12s/it, loss=1.1765, batch_acc=0.7188, running_acc=0.7489, grad=21.5947]Training epoch 13:  55%|█████▍    | 89/163 [01:42<01:17,  1.05s/it, loss=1.1765, batch_acc=0.7188, running_acc=0.7489, grad=21.5947]Training epoch 13:  55%|█████▍    | 89/163 [01:42<01:17,  1.05s/it, loss=1.2000, batch_acc=0.7500, running_acc=0.7489, grad=22.6132]Training epoch 13:  55%|█████▌    | 90/163 [01:43<01:12,  1.00it/s, loss=1.2000, batch_acc=0.7500, running_acc=0.7489, grad=22.6132]Training epoch 13:  55%|█████▌    | 90/163 [01:43<01:12,  1.00it/s, loss=1.0546, batch_acc=0.6875, running_acc=0.7483, grad=21.0457]Training epoch 13:  56%|█████▌    | 91/163 [01:45<01:20,  1.11s/it, loss=1.0546, batch_acc=0.6875, running_acc=0.7483, grad=21.0457]Training epoch 13:  56%|█████▌    | 91/163 [01:45<01:20,  1.11s/it, loss=1.3924, batch_acc=0.6875, running_acc=0.7476, grad=21.1228]Training epoch 13:  56%|█████▋    | 92/163 [01:45<01:14,  1.04s/it, loss=1.3924, batch_acc=0.6875, running_acc=0.7476, grad=21.1228]Training epoch 13:  56%|█████▋    | 92/163 [01:45<01:14,  1.04s/it, loss=1.1733, batch_acc=0.7500, running_acc=0.7476, grad=24.1840]Training epoch 13:  57%|█████▋    | 93/163 [01:46<01:09,  1.01it/s, loss=1.1733, batch_acc=0.7500, running_acc=0.7476, grad=24.1840]Training epoch 13:  57%|█████▋    | 93/163 [01:46<01:09,  1.01it/s, loss=1.1606, batch_acc=0.7812, running_acc=0.7480, grad=27.2683]Training epoch 13:  58%|█████▊    | 94/163 [01:47<01:06,  1.04it/s, loss=1.1606, batch_acc=0.7812, running_acc=0.7480, grad=27.2683]Training epoch 13:  58%|█████▊    | 94/163 [01:47<01:06,  1.04it/s, loss=1.1183, batch_acc=0.7500, running_acc=0.7480, grad=21.6790]Training epoch 13:  58%|█████▊    | 95/163 [01:49<01:13,  1.08s/it, loss=1.1183, batch_acc=0.7500, running_acc=0.7480, grad=21.6790]Training epoch 13:  58%|█████▊    | 95/163 [01:49<01:13,  1.08s/it, loss=1.4448, batch_acc=0.7188, running_acc=0.7477, grad=22.0569]Training epoch 13:  59%|█████▉    | 96/163 [01:49<01:08,  1.02s/it, loss=1.4448, batch_acc=0.7188, running_acc=0.7477, grad=22.0569]Training epoch 13:  59%|█████▉    | 96/163 [01:49<01:08,  1.02s/it, loss=1.1246, batch_acc=0.8438, running_acc=0.7487, grad=22.0824]Training epoch 13:  60%|█████▉    | 97/163 [01:51<01:14,  1.12s/it, loss=1.1246, batch_acc=0.8438, running_acc=0.7487, grad=22.0824]Training epoch 13:  60%|█████▉    | 97/163 [01:51<01:14,  1.12s/it, loss=0.9338, batch_acc=0.8125, running_acc=0.7494, grad=21.7028]Training epoch 13:  60%|██████    | 98/163 [01:52<01:08,  1.05s/it, loss=0.9338, batch_acc=0.8125, running_acc=0.7494, grad=21.7028]Training epoch 13:  60%|██████    | 98/163 [01:52<01:08,  1.05s/it, loss=1.1344, batch_acc=0.7812, running_acc=0.7497, grad=26.0236]Training epoch 13:  61%|██████    | 99/163 [01:53<01:17,  1.21s/it, loss=1.1344, batch_acc=0.7812, running_acc=0.7497, grad=26.0236]Training epoch 13:  61%|██████    | 99/163 [01:53<01:17,  1.21s/it, loss=1.2028, batch_acc=0.6562, running_acc=0.7487, grad=34.5723]Training epoch 13:  61%|██████▏   | 100/163 [01:54<01:10,  1.11s/it, loss=1.2028, batch_acc=0.6562, running_acc=0.7487, grad=34.5723]Training epoch 13:  61%|██████▏   | 100/163 [01:54<01:10,  1.11s/it, loss=1.0711, batch_acc=0.7500, running_acc=0.7488, grad=24.2133]Training epoch 13:  62%|██████▏   | 101/163 [01:56<01:15,  1.23s/it, loss=1.0711, batch_acc=0.7500, running_acc=0.7488, grad=24.2133]Training epoch 13:  62%|██████▏   | 101/163 [01:56<01:15,  1.23s/it, loss=1.2775, batch_acc=0.6875, running_acc=0.7481, grad=23.5081]Training epoch 13:  63%|██████▎   | 102/163 [01:56<01:08,  1.12s/it, loss=1.2775, batch_acc=0.6875, running_acc=0.7481, grad=23.5081]Training epoch 13:  63%|██████▎   | 102/163 [01:56<01:08,  1.12s/it, loss=1.0849, batch_acc=0.7500, running_acc=0.7482, grad=23.8286]Training epoch 13:  63%|██████▎   | 103/163 [01:58<01:08,  1.14s/it, loss=1.0849, batch_acc=0.7500, running_acc=0.7482, grad=23.8286]Training epoch 13:  63%|██████▎   | 103/163 [01:58<01:08,  1.14s/it, loss=1.0240, batch_acc=0.8438, running_acc=0.7491, grad=22.7146]Training epoch 13:  64%|██████▍   | 104/163 [01:59<01:02,  1.06s/it, loss=1.0240, batch_acc=0.8438, running_acc=0.7491, grad=22.7146]Training epoch 13:  64%|██████▍   | 104/163 [01:59<01:02,  1.06s/it, loss=1.2807, batch_acc=0.6562, running_acc=0.7482, grad=25.8805]Training epoch 13:  64%|██████▍   | 105/163 [02:00<01:15,  1.30s/it, loss=1.2807, batch_acc=0.6562, running_acc=0.7482, grad=25.8805]Training epoch 13:  64%|██████▍   | 105/163 [02:00<01:15,  1.30s/it, loss=1.2103, batch_acc=0.7500, running_acc=0.7482, grad=26.0395]Training epoch 13:  65%|██████▌   | 106/163 [02:01<01:06,  1.17s/it, loss=1.2103, batch_acc=0.7500, running_acc=0.7482, grad=26.0395]Training epoch 13:  65%|██████▌   | 106/163 [02:01<01:06,  1.17s/it, loss=1.3159, batch_acc=0.7500, running_acc=0.7482, grad=30.8875]Training epoch 13:  66%|██████▌   | 107/163 [02:02<01:00,  1.09s/it, loss=1.3159, batch_acc=0.7500, running_acc=0.7482, grad=30.8875]Training epoch 13:  66%|██████▌   | 107/163 [02:02<01:00,  1.09s/it, loss=1.1244, batch_acc=0.7812, running_acc=0.7485, grad=24.8233]Training epoch 13:  66%|██████▋   | 108/163 [02:03<00:56,  1.02s/it, loss=1.1244, batch_acc=0.7812, running_acc=0.7485, grad=24.8233]Training epoch 13:  66%|██████▋   | 108/163 [02:03<00:56,  1.02s/it, loss=1.4389, batch_acc=0.6562, running_acc=0.7477, grad=27.6939]Training epoch 13:  67%|██████▋   | 109/163 [02:05<01:03,  1.17s/it, loss=1.4389, batch_acc=0.6562, running_acc=0.7477, grad=27.6939]Training epoch 13:  67%|██████▋   | 109/163 [02:05<01:03,  1.17s/it, loss=1.1817, batch_acc=0.6875, running_acc=0.7471, grad=23.7896]Training epoch 13:  67%|██████▋   | 110/163 [02:05<00:57,  1.08s/it, loss=1.1817, batch_acc=0.6875, running_acc=0.7471, grad=23.7896]Training epoch 13:  67%|██████▋   | 110/163 [02:05<00:57,  1.08s/it, loss=0.9588, batch_acc=0.8438, running_acc=0.7480, grad=19.8317]Training epoch 13:  68%|██████▊   | 111/163 [02:07<00:59,  1.13s/it, loss=0.9588, batch_acc=0.8438, running_acc=0.7480, grad=19.8317]Training epoch 13:  68%|██████▊   | 111/163 [02:07<00:59,  1.13s/it, loss=1.0706, batch_acc=0.7812, running_acc=0.7483, grad=32.1448]Training epoch 13:  69%|██████▊   | 112/163 [02:08<00:53,  1.06s/it, loss=1.0706, batch_acc=0.7812, running_acc=0.7483, grad=32.1448]Training epoch 13:  69%|██████▊   | 112/163 [02:08<00:53,  1.06s/it, loss=1.1338, batch_acc=0.7500, running_acc=0.7483, grad=21.5517]Training epoch 13:  69%|██████▉   | 113/163 [02:09<00:55,  1.11s/it, loss=1.1338, batch_acc=0.7500, running_acc=0.7483, grad=21.5517]Training epoch 13:  69%|██████▉   | 113/163 [02:09<00:55,  1.11s/it, loss=1.0232, batch_acc=0.8438, running_acc=0.7492, grad=20.9389]Training epoch 13:  70%|██████▉   | 114/163 [02:10<00:50,  1.04s/it, loss=1.0232, batch_acc=0.8438, running_acc=0.7492, grad=20.9389]Training epoch 13:  70%|██████▉   | 114/163 [02:10<00:50,  1.04s/it, loss=1.2265, batch_acc=0.7812, running_acc=0.7495, grad=19.6700]Training epoch 13:  71%|███████   | 115/163 [02:11<00:50,  1.05s/it, loss=1.2265, batch_acc=0.7812, running_acc=0.7495, grad=19.6700]Training epoch 13:  71%|███████   | 115/163 [02:11<00:50,  1.05s/it, loss=1.2861, batch_acc=0.6875, running_acc=0.7489, grad=22.6019]Training epoch 13:  71%|███████   | 116/163 [02:12<00:46,  1.00it/s, loss=1.2861, batch_acc=0.6875, running_acc=0.7489, grad=22.6019]Training epoch 13:  71%|███████   | 116/163 [02:12<00:46,  1.00it/s, loss=1.3081, batch_acc=0.8438, running_acc=0.7497, grad=27.4340]Training epoch 13:  72%|███████▏  | 117/163 [02:13<00:56,  1.24s/it, loss=1.3081, batch_acc=0.8438, running_acc=0.7497, grad=27.4340]Training epoch 13:  72%|███████▏  | 117/163 [02:13<00:56,  1.24s/it, loss=1.2684, batch_acc=0.6562, running_acc=0.7489, grad=24.6624]Training epoch 13:  72%|███████▏  | 118/163 [02:14<00:50,  1.13s/it, loss=1.2684, batch_acc=0.6562, running_acc=0.7489, grad=24.6624]Training epoch 13:  72%|███████▏  | 118/163 [02:14<00:50,  1.13s/it, loss=1.4659, batch_acc=0.6875, running_acc=0.7484, grad=29.5922]Training epoch 13:  73%|███████▎  | 119/163 [02:15<00:49,  1.14s/it, loss=1.4659, batch_acc=0.6875, running_acc=0.7484, grad=29.5922]Training epoch 13:  73%|███████▎  | 119/163 [02:15<00:49,  1.14s/it, loss=1.1807, batch_acc=0.7500, running_acc=0.7484, grad=21.1999]Training epoch 13:  74%|███████▎  | 120/163 [02:16<00:45,  1.06s/it, loss=1.1807, batch_acc=0.7500, running_acc=0.7484, grad=21.1999]Training epoch 13:  74%|███████▎  | 120/163 [02:16<00:45,  1.06s/it, loss=1.3532, batch_acc=0.7188, running_acc=0.7482, grad=27.3740]Training epoch 13:  74%|███████▍  | 121/163 [02:18<00:53,  1.28s/it, loss=1.3532, batch_acc=0.7188, running_acc=0.7482, grad=27.3740]Training epoch 13:  74%|███████▍  | 121/163 [02:18<00:53,  1.28s/it, loss=1.0351, batch_acc=0.8125, running_acc=0.7487, grad=22.9154]Training epoch 13:  75%|███████▍  | 122/163 [02:19<00:47,  1.16s/it, loss=1.0351, batch_acc=0.8125, running_acc=0.7487, grad=22.9154]Training epoch 13:  75%|███████▍  | 122/163 [02:19<00:47,  1.16s/it, loss=1.3899, batch_acc=0.5625, running_acc=0.7472, grad=31.6992]Training epoch 13:  75%|███████▌  | 123/163 [02:20<00:43,  1.08s/it, loss=1.3899, batch_acc=0.5625, running_acc=0.7472, grad=31.6992]Training epoch 13:  75%|███████▌  | 123/163 [02:20<00:43,  1.08s/it, loss=1.3840, batch_acc=0.6250, running_acc=0.7462, grad=24.7765]Training epoch 13:  76%|███████▌  | 124/163 [02:21<00:39,  1.02s/it, loss=1.3840, batch_acc=0.6250, running_acc=0.7462, grad=24.7765]Training epoch 13:  76%|███████▌  | 124/163 [02:21<00:39,  1.02s/it, loss=1.1832, batch_acc=0.7812, running_acc=0.7465, grad=20.3999]Training epoch 13:  77%|███████▋  | 125/163 [02:23<00:47,  1.25s/it, loss=1.1832, batch_acc=0.7812, running_acc=0.7465, grad=20.3999]Training epoch 13:  77%|███████▋  | 125/163 [02:23<00:47,  1.25s/it, loss=1.1197, batch_acc=0.7812, running_acc=0.7468, grad=25.0479]Training epoch 13:  77%|███████▋  | 126/163 [02:23<00:42,  1.14s/it, loss=1.1197, batch_acc=0.7812, running_acc=0.7468, grad=25.0479]Training epoch 13:  77%|███████▋  | 126/163 [02:23<00:42,  1.14s/it, loss=0.9897, batch_acc=0.7500, running_acc=0.7468, grad=25.9714]Training epoch 13:  78%|███████▊  | 127/163 [02:24<00:38,  1.06s/it, loss=0.9897, batch_acc=0.7500, running_acc=0.7468, grad=25.9714]Training epoch 13:  78%|███████▊  | 127/163 [02:24<00:38,  1.06s/it, loss=1.1647, batch_acc=0.7812, running_acc=0.7470, grad=30.6842]Training epoch 13:  79%|███████▊  | 128/163 [02:25<00:35,  1.01s/it, loss=1.1647, batch_acc=0.7812, running_acc=0.7470, grad=30.6842]Training epoch 13:  79%|███████▊  | 128/163 [02:25<00:35,  1.01s/it, loss=0.8716, batch_acc=0.8750, running_acc=0.7480, grad=17.2288]Training epoch 13:  79%|███████▉  | 129/163 [02:27<00:43,  1.28s/it, loss=0.8716, batch_acc=0.8750, running_acc=0.7480, grad=17.2288]Training epoch 13:  79%|███████▉  | 129/163 [02:27<00:43,  1.28s/it, loss=1.0433, batch_acc=0.7812, running_acc=0.7483, grad=19.7802]Training epoch 13:  80%|███████▉  | 130/163 [02:28<00:38,  1.16s/it, loss=1.0433, batch_acc=0.7812, running_acc=0.7483, grad=19.7802]Training epoch 13:  80%|███████▉  | 130/163 [02:28<00:38,  1.16s/it, loss=1.2318, batch_acc=0.7812, running_acc=0.7486, grad=20.1149]Training epoch 13:  80%|████████  | 131/163 [02:29<00:34,  1.08s/it, loss=1.2318, batch_acc=0.7812, running_acc=0.7486, grad=20.1149]Training epoch 13:  80%|████████  | 131/163 [02:29<00:34,  1.08s/it, loss=0.9161, batch_acc=0.8438, running_acc=0.7493, grad=23.0414]Training epoch 13:  81%|████████  | 132/163 [02:30<00:31,  1.02s/it, loss=0.9161, batch_acc=0.8438, running_acc=0.7493, grad=23.0414]Training epoch 13:  81%|████████  | 132/163 [02:30<00:31,  1.02s/it, loss=1.4176, batch_acc=0.6875, running_acc=0.7488, grad=27.1613]Training epoch 13:  82%|████████▏ | 133/163 [02:32<00:39,  1.32s/it, loss=1.4176, batch_acc=0.6875, running_acc=0.7488, grad=27.1613]Training epoch 13:  82%|████████▏ | 133/163 [02:32<00:39,  1.32s/it, loss=1.1419, batch_acc=0.7500, running_acc=0.7488, grad=23.9890]Training epoch 13:  82%|████████▏ | 134/163 [02:33<00:34,  1.19s/it, loss=1.1419, batch_acc=0.7500, running_acc=0.7488, grad=23.9890]Training epoch 13:  82%|████████▏ | 134/163 [02:33<00:34,  1.19s/it, loss=1.1703, batch_acc=0.7812, running_acc=0.7491, grad=34.1420]Training epoch 13:  83%|████████▎ | 135/163 [02:34<00:30,  1.10s/it, loss=1.1703, batch_acc=0.7812, running_acc=0.7491, grad=34.1420]Training epoch 13:  83%|████████▎ | 135/163 [02:34<00:30,  1.10s/it, loss=1.4047, batch_acc=0.5938, running_acc=0.7479, grad=26.3349]Training epoch 13:  83%|████████▎ | 136/163 [02:34<00:27,  1.03s/it, loss=1.4047, batch_acc=0.5938, running_acc=0.7479, grad=26.3349]Training epoch 13:  83%|████████▎ | 136/163 [02:34<00:27,  1.03s/it, loss=1.3680, batch_acc=0.5625, running_acc=0.7466, grad=19.7203]Training epoch 13:  84%|████████▍ | 137/163 [02:36<00:33,  1.27s/it, loss=1.3680, batch_acc=0.5625, running_acc=0.7466, grad=19.7203]Training epoch 13:  84%|████████▍ | 137/163 [02:36<00:33,  1.27s/it, loss=1.1883, batch_acc=0.6875, running_acc=0.7461, grad=25.6303]Training epoch 13:  85%|████████▍ | 138/163 [02:37<00:28,  1.15s/it, loss=1.1883, batch_acc=0.6875, running_acc=0.7461, grad=25.6303]Training epoch 13:  85%|████████▍ | 138/163 [02:37<00:28,  1.15s/it, loss=0.9261, batch_acc=0.8125, running_acc=0.7466, grad=18.7627]Training epoch 13:  85%|████████▌ | 139/163 [02:38<00:25,  1.07s/it, loss=0.9261, batch_acc=0.8125, running_acc=0.7466, grad=18.7627]Training epoch 13:  85%|████████▌ | 139/163 [02:38<00:25,  1.07s/it, loss=1.1803, batch_acc=0.6875, running_acc=0.7462, grad=23.9836]Training epoch 13:  86%|████████▌ | 140/163 [02:39<00:23,  1.01s/it, loss=1.1803, batch_acc=0.6875, running_acc=0.7462, grad=23.9836]Training epoch 13:  86%|████████▌ | 140/163 [02:39<00:23,  1.01s/it, loss=1.0502, batch_acc=0.8125, running_acc=0.7467, grad=18.3203]Training epoch 13:  87%|████████▋ | 141/163 [02:41<00:30,  1.37s/it, loss=1.0502, batch_acc=0.8125, running_acc=0.7467, grad=18.3203]Training epoch 13:  87%|████████▋ | 141/163 [02:41<00:30,  1.37s/it, loss=1.2487, batch_acc=0.7188, running_acc=0.7465, grad=21.1543]Training epoch 13:  87%|████████▋ | 142/163 [02:42<00:25,  1.23s/it, loss=1.2487, batch_acc=0.7188, running_acc=0.7465, grad=21.1543]Training epoch 13:  87%|████████▋ | 142/163 [02:42<00:25,  1.23s/it, loss=1.2438, batch_acc=0.6875, running_acc=0.7460, grad=39.0568]Training epoch 13:  88%|████████▊ | 143/163 [02:43<00:22,  1.12s/it, loss=1.2438, batch_acc=0.6875, running_acc=0.7460, grad=39.0568]Training epoch 13:  88%|████████▊ | 143/163 [02:43<00:22,  1.12s/it, loss=1.5245, batch_acc=0.6875, running_acc=0.7456, grad=24.1835]Training epoch 13:  88%|████████▊ | 144/163 [02:44<00:19,  1.05s/it, loss=1.5245, batch_acc=0.6875, running_acc=0.7456, grad=24.1835]Training epoch 13:  88%|████████▊ | 144/163 [02:44<00:19,  1.05s/it, loss=1.1520, batch_acc=0.8125, running_acc=0.7461, grad=20.7435]Training epoch 13:  89%|████████▉ | 145/163 [02:45<00:20,  1.14s/it, loss=1.1520, batch_acc=0.8125, running_acc=0.7461, grad=20.7435]Training epoch 13:  89%|████████▉ | 145/163 [02:45<00:20,  1.14s/it, loss=1.1248, batch_acc=0.7188, running_acc=0.7459, grad=22.7535]Training epoch 13:  90%|████████▉ | 146/163 [02:46<00:18,  1.06s/it, loss=1.1248, batch_acc=0.7188, running_acc=0.7459, grad=22.7535]Training epoch 13:  90%|████████▉ | 146/163 [02:46<00:18,  1.06s/it, loss=1.0586, batch_acc=0.8125, running_acc=0.7464, grad=22.0401]Training epoch 13:  90%|█████████ | 147/163 [02:47<00:16,  1.01s/it, loss=1.0586, batch_acc=0.8125, running_acc=0.7464, grad=22.0401]Training epoch 13:  90%|█████████ | 147/163 [02:47<00:16,  1.01s/it, loss=1.1843, batch_acc=0.7188, running_acc=0.7462, grad=22.6470]Training epoch 13:  91%|█████████ | 148/163 [02:48<00:14,  1.03it/s, loss=1.1843, batch_acc=0.7188, running_acc=0.7462, grad=22.6470]Training epoch 13:  91%|█████████ | 148/163 [02:48<00:14,  1.03it/s, loss=1.4597, batch_acc=0.6875, running_acc=0.7458, grad=28.5527]Training epoch 13:  91%|█████████▏| 149/163 [02:49<00:16,  1.15s/it, loss=1.4597, batch_acc=0.6875, running_acc=0.7458, grad=28.5527]Training epoch 13:  91%|█████████▏| 149/163 [02:49<00:16,  1.15s/it, loss=1.2248, batch_acc=0.6875, running_acc=0.7454, grad=26.1055]Training epoch 13:  92%|█████████▏| 150/163 [02:50<00:13,  1.07s/it, loss=1.2248, batch_acc=0.6875, running_acc=0.7454, grad=26.1055]Training epoch 13:  92%|█████████▏| 150/163 [02:50<00:13,  1.07s/it, loss=1.3644, batch_acc=0.6250, running_acc=0.7446, grad=28.8876]Training epoch 13:  93%|█████████▎| 151/163 [02:51<00:12,  1.01s/it, loss=1.3644, batch_acc=0.6250, running_acc=0.7446, grad=28.8876]Training epoch 13:  93%|█████████▎| 151/163 [02:51<00:12,  1.01s/it, loss=1.1045, batch_acc=0.7812, running_acc=0.7448, grad=18.7160]Training epoch 13:  93%|█████████▎| 152/163 [02:52<00:10,  1.03it/s, loss=1.1045, batch_acc=0.7812, running_acc=0.7448, grad=18.7160]Training epoch 13:  93%|█████████▎| 152/163 [02:52<00:10,  1.03it/s, loss=1.2615, batch_acc=0.7188, running_acc=0.7447, grad=27.4732]Training epoch 13:  94%|█████████▍| 153/163 [02:54<00:12,  1.28s/it, loss=1.2615, batch_acc=0.7188, running_acc=0.7447, grad=27.4732]Training epoch 13:  94%|█████████▍| 153/163 [02:54<00:12,  1.28s/it, loss=1.2583, batch_acc=0.7188, running_acc=0.7445, grad=22.5547]Training epoch 13:  94%|█████████▍| 154/163 [02:55<00:10,  1.16s/it, loss=1.2583, batch_acc=0.7188, running_acc=0.7445, grad=22.5547]Training epoch 13:  94%|█████████▍| 154/163 [02:55<00:10,  1.16s/it, loss=1.1424, batch_acc=0.6875, running_acc=0.7441, grad=24.6611]Training epoch 13:  95%|█████████▌| 155/163 [02:56<00:08,  1.08s/it, loss=1.1424, batch_acc=0.6875, running_acc=0.7441, grad=24.6611]Training epoch 13:  95%|█████████▌| 155/163 [02:56<00:08,  1.08s/it, loss=0.7935, batch_acc=0.9375, running_acc=0.7454, grad=20.1457]Training epoch 13:  96%|█████████▌| 156/163 [02:57<00:07,  1.02s/it, loss=0.7935, batch_acc=0.9375, running_acc=0.7454, grad=20.1457]Training epoch 13:  96%|█████████▌| 156/163 [02:57<00:07,  1.02s/it, loss=0.8892, batch_acc=0.7812, running_acc=0.7456, grad=19.4245]Training epoch 13:  96%|█████████▋| 157/163 [02:58<00:06,  1.12s/it, loss=0.8892, batch_acc=0.7812, running_acc=0.7456, grad=19.4245]Training epoch 13:  96%|█████████▋| 157/163 [02:58<00:06,  1.12s/it, loss=1.0746, batch_acc=0.7500, running_acc=0.7456, grad=17.8289]Training epoch 13:  97%|█████████▋| 158/163 [02:59<00:05,  1.05s/it, loss=1.0746, batch_acc=0.7500, running_acc=0.7456, grad=17.8289]Training epoch 13:  97%|█████████▋| 158/163 [02:59<00:05,  1.05s/it, loss=1.0239, batch_acc=0.6875, running_acc=0.7453, grad=22.3900]Training epoch 13:  98%|█████████▊| 159/163 [03:00<00:03,  1.00it/s, loss=1.0239, batch_acc=0.6875, running_acc=0.7453, grad=22.3900]Training epoch 13:  98%|█████████▊| 159/163 [03:00<00:03,  1.00it/s, loss=1.0239, batch_acc=0.8125, running_acc=0.7457, grad=16.7673]Training epoch 13:  98%|█████████▊| 160/163 [03:01<00:02,  1.04it/s, loss=1.0239, batch_acc=0.8125, running_acc=0.7457, grad=16.7673]Training epoch 13:  98%|█████████▊| 160/163 [03:01<00:02,  1.04it/s, loss=0.9764, batch_acc=0.7188, running_acc=0.7455, grad=20.0428]Training epoch 13:  99%|█████████▉| 161/163 [03:02<00:02,  1.04s/it, loss=0.9764, batch_acc=0.7188, running_acc=0.7455, grad=20.0428]Training epoch 13:  99%|█████████▉| 161/163 [03:02<00:02,  1.04s/it, loss=1.4281, batch_acc=0.7188, running_acc=0.7453, grad=24.8609]Training epoch 13:  99%|█████████▉| 162/163 [03:03<00:00,  1.01it/s, loss=1.4281, batch_acc=0.7188, running_acc=0.7453, grad=24.8609]Training epoch 13:  99%|█████████▉| 162/163 [03:03<00:00,  1.01it/s, loss=0.9015, batch_acc=0.7812, running_acc=0.7456, grad=19.1540]Training epoch 13: 100%|██████████| 163/163 [03:03<00:00,  1.13it/s, loss=0.9015, batch_acc=0.7812, running_acc=0.7456, grad=19.1540]Training epoch 13: 100%|██████████| 163/163 [03:03<00:00,  1.13it/s, loss=0.9108, batch_acc=0.8571, running_acc=0.7460, grad=23.5716]Training epoch 13: 100%|██████████| 163/163 [03:03<00:00,  1.13s/it, loss=0.9108, batch_acc=0.8571, running_acc=0.7460, grad=23.5716]
Evaluation epoch 13:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 13:   4%|▎         | 1/28 [00:05<02:21,  5.23s/it]Evaluation epoch 13:   4%|▎         | 1/28 [00:05<02:21,  5.23s/it, loss=1.0210, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 13:   7%|▋         | 2/28 [00:05<00:59,  2.31s/it, loss=1.0210, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 13:   7%|▋         | 2/28 [00:05<00:59,  2.31s/it, loss=0.8903, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 13:  11%|█         | 3/28 [00:05<00:34,  1.37s/it, loss=0.8903, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 13:  11%|█         | 3/28 [00:05<00:34,  1.37s/it, loss=1.0424, batch_acc=0.8125, running_acc=0.8229]Evaluation epoch 13:  14%|█▍        | 4/28 [00:10<01:04,  2.71s/it, loss=1.0424, batch_acc=0.8125, running_acc=0.8229]Evaluation epoch 13:  14%|█▍        | 4/28 [00:10<01:04,  2.71s/it, loss=1.6310, batch_acc=0.5938, running_acc=0.7656]Evaluation epoch 13:  18%|█▊        | 5/28 [00:10<00:41,  1.82s/it, loss=1.6310, batch_acc=0.5938, running_acc=0.7656]Evaluation epoch 13:  18%|█▊        | 5/28 [00:10<00:41,  1.82s/it, loss=1.8841, batch_acc=0.5312, running_acc=0.7188]Evaluation epoch 13:  21%|██▏       | 6/28 [00:11<00:28,  1.29s/it, loss=1.8841, batch_acc=0.5312, running_acc=0.7188]Evaluation epoch 13:  21%|██▏       | 6/28 [00:11<00:28,  1.29s/it, loss=1.7760, batch_acc=0.4688, running_acc=0.6771]Evaluation epoch 13:  25%|██▌       | 7/28 [00:11<00:20,  1.04it/s, loss=1.7760, batch_acc=0.4688, running_acc=0.6771]Evaluation epoch 13:  25%|██▌       | 7/28 [00:11<00:20,  1.04it/s, loss=1.7189, batch_acc=0.5625, running_acc=0.6607]Evaluation epoch 13:  29%|██▊       | 8/28 [00:14<00:35,  1.75s/it, loss=1.7189, batch_acc=0.5625, running_acc=0.6607]Evaluation epoch 13:  29%|██▊       | 8/28 [00:14<00:35,  1.75s/it, loss=1.2915, batch_acc=0.7812, running_acc=0.6758]Evaluation epoch 13:  32%|███▏      | 9/28 [00:15<00:24,  1.31s/it, loss=1.2915, batch_acc=0.7812, running_acc=0.6758]Evaluation epoch 13:  32%|███▏      | 9/28 [00:15<00:24,  1.31s/it, loss=1.5208, batch_acc=0.6562, running_acc=0.6736]Evaluation epoch 13:  36%|███▌      | 10/28 [00:15<00:17,  1.01it/s, loss=1.5208, batch_acc=0.6562, running_acc=0.6736]Evaluation epoch 13:  36%|███▌      | 10/28 [00:15<00:17,  1.01it/s, loss=0.8464, batch_acc=0.8750, running_acc=0.6937]Evaluation epoch 13:  39%|███▉      | 11/28 [00:15<00:13,  1.30it/s, loss=0.8464, batch_acc=0.8750, running_acc=0.6937]Evaluation epoch 13:  39%|███▉      | 11/28 [00:15<00:13,  1.30it/s, loss=1.5112, batch_acc=0.7188, running_acc=0.6960]Evaluation epoch 13:  43%|████▎     | 12/28 [00:21<00:36,  2.30s/it, loss=1.5112, batch_acc=0.7188, running_acc=0.6960]Evaluation epoch 13:  43%|████▎     | 12/28 [00:21<00:36,  2.30s/it, loss=1.5748, batch_acc=0.5938, running_acc=0.6875]Evaluation epoch 13:  46%|████▋     | 13/28 [00:21<00:25,  1.68s/it, loss=1.5748, batch_acc=0.5938, running_acc=0.6875]Evaluation epoch 13:  46%|████▋     | 13/28 [00:21<00:25,  1.68s/it, loss=0.9103, batch_acc=0.8750, running_acc=0.7019]Evaluation epoch 13:  50%|█████     | 14/28 [00:21<00:17,  1.26s/it, loss=0.9103, batch_acc=0.8750, running_acc=0.7019]Evaluation epoch 13:  50%|█████     | 14/28 [00:21<00:17,  1.26s/it, loss=1.7753, batch_acc=0.6562, running_acc=0.6987]Evaluation epoch 13:  54%|█████▎    | 15/28 [00:22<00:12,  1.05it/s, loss=1.7753, batch_acc=0.6562, running_acc=0.6987]Evaluation epoch 13:  54%|█████▎    | 15/28 [00:22<00:12,  1.05it/s, loss=2.3237, batch_acc=0.4375, running_acc=0.6813]Evaluation epoch 13:  57%|█████▋    | 16/28 [00:25<00:18,  1.51s/it, loss=2.3237, batch_acc=0.4375, running_acc=0.6813]Evaluation epoch 13:  57%|█████▋    | 16/28 [00:25<00:18,  1.51s/it, loss=1.3039, batch_acc=0.6875, running_acc=0.6816]Evaluation epoch 13:  61%|██████    | 17/28 [00:25<00:12,  1.14s/it, loss=1.3039, batch_acc=0.6875, running_acc=0.6816]Evaluation epoch 13:  61%|██████    | 17/28 [00:25<00:12,  1.14s/it, loss=1.1297, batch_acc=0.7188, running_acc=0.6838]Evaluation epoch 13:  64%|██████▍   | 18/28 [00:25<00:08,  1.14it/s, loss=1.1297, batch_acc=0.7188, running_acc=0.6838]Evaluation epoch 13:  64%|██████▍   | 18/28 [00:25<00:08,  1.14it/s, loss=1.0847, batch_acc=0.6562, running_acc=0.6823]Evaluation epoch 13:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=1.0847, batch_acc=0.6562, running_acc=0.6823]Evaluation epoch 13:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=1.3533, batch_acc=0.5312, running_acc=0.6743]Evaluation epoch 13:  71%|███████▏  | 20/28 [00:28<00:10,  1.32s/it, loss=1.3533, batch_acc=0.5312, running_acc=0.6743]Evaluation epoch 13:  71%|███████▏  | 20/28 [00:28<00:10,  1.32s/it, loss=1.4044, batch_acc=0.5938, running_acc=0.6703]Evaluation epoch 13:  75%|███████▌  | 21/28 [00:28<00:06,  1.00it/s, loss=1.4044, batch_acc=0.5938, running_acc=0.6703]Evaluation epoch 13:  75%|███████▌  | 21/28 [00:28<00:06,  1.00it/s, loss=1.3725, batch_acc=0.7188, running_acc=0.6726]Evaluation epoch 13:  79%|███████▊  | 22/28 [00:29<00:04,  1.28it/s, loss=1.3725, batch_acc=0.7188, running_acc=0.6726]Evaluation epoch 13:  79%|███████▊  | 22/28 [00:29<00:04,  1.28it/s, loss=1.6033, batch_acc=0.6250, running_acc=0.6705]Evaluation epoch 13:  82%|████████▏ | 23/28 [00:29<00:03,  1.60it/s, loss=1.6033, batch_acc=0.6250, running_acc=0.6705]Evaluation epoch 13:  82%|████████▏ | 23/28 [00:29<00:03,  1.60it/s, loss=1.6231, batch_acc=0.5625, running_acc=0.6658]Evaluation epoch 13:  86%|████████▌ | 24/28 [00:34<00:07,  1.98s/it, loss=1.6231, batch_acc=0.5625, running_acc=0.6658]Evaluation epoch 13:  86%|████████▌ | 24/28 [00:34<00:07,  1.98s/it, loss=0.9914, batch_acc=0.7188, running_acc=0.6680]Evaluation epoch 13:  89%|████████▉ | 25/28 [00:34<00:04,  1.46s/it, loss=0.9914, batch_acc=0.7188, running_acc=0.6680]Evaluation epoch 13:  89%|████████▉ | 25/28 [00:34<00:04,  1.46s/it, loss=0.7833, batch_acc=0.8438, running_acc=0.6750]Evaluation epoch 13:  93%|█████████▎| 26/28 [00:35<00:02,  1.10s/it, loss=0.7833, batch_acc=0.8438, running_acc=0.6750]Evaluation epoch 13:  93%|█████████▎| 26/28 [00:35<00:02,  1.10s/it, loss=1.4605, batch_acc=0.6250, running_acc=0.6731]Evaluation epoch 13:  96%|█████████▋| 27/28 [00:35<00:00,  1.18it/s, loss=1.4605, batch_acc=0.6250, running_acc=0.6731]Evaluation epoch 13:  96%|█████████▋| 27/28 [00:35<00:00,  1.18it/s, loss=1.6002, batch_acc=0.5625, running_acc=0.6690]Evaluation epoch 13: 100%|██████████| 28/28 [00:35<00:00,  1.18it/s, loss=1.4057, batch_acc=0.6667, running_acc=0.6690]Evaluation epoch 13: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.4057, batch_acc=0.6667, running_acc=0.6690]
Training epoch 14:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 14:   1%|          | 1/163 [00:05<15:46,  5.85s/it]Training epoch 14:   1%|          | 1/163 [00:05<15:46,  5.85s/it, loss=1.1067, batch_acc=0.7500, running_acc=0.7500, grad=18.8427]Training epoch 14:   1%|          | 2/163 [00:06<07:50,  2.92s/it, loss=1.1067, batch_acc=0.7500, running_acc=0.7500, grad=18.8427]Training epoch 14:   1%|          | 2/163 [00:06<07:50,  2.92s/it, loss=1.0964, batch_acc=0.8125, running_acc=0.7812, grad=26.2064]Training epoch 14:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=1.0964, batch_acc=0.8125, running_acc=0.7812, grad=26.2064]Training epoch 14:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=1.0216, batch_acc=0.7500, running_acc=0.7708, grad=22.4795]Training epoch 14:   2%|▏         | 4/163 [00:10<05:45,  2.17s/it, loss=1.0216, batch_acc=0.7500, running_acc=0.7708, grad=22.4795]Training epoch 14:   2%|▏         | 4/163 [00:10<05:45,  2.17s/it, loss=0.8815, batch_acc=0.8125, running_acc=0.7812, grad=20.3151]Training epoch 14:   3%|▎         | 5/163 [00:10<04:29,  1.71s/it, loss=0.8815, batch_acc=0.8125, running_acc=0.7812, grad=20.3151]Training epoch 14:   3%|▎         | 5/163 [00:10<04:29,  1.71s/it, loss=1.1116, batch_acc=0.8438, running_acc=0.7937, grad=22.6404]Training epoch 14:   4%|▎         | 6/163 [00:11<03:43,  1.43s/it, loss=1.1116, batch_acc=0.8438, running_acc=0.7937, grad=22.6404]Training epoch 14:   4%|▎         | 6/163 [00:11<03:43,  1.43s/it, loss=1.0869, batch_acc=0.6875, running_acc=0.7760, grad=19.0818]Training epoch 14:   4%|▍         | 7/163 [00:12<03:14,  1.25s/it, loss=1.0869, batch_acc=0.6875, running_acc=0.7760, grad=19.0818]Training epoch 14:   4%|▍         | 7/163 [00:12<03:14,  1.25s/it, loss=1.1237, batch_acc=0.7500, running_acc=0.7723, grad=23.7839]Training epoch 14:   5%|▍         | 8/163 [00:14<03:23,  1.31s/it, loss=1.1237, batch_acc=0.7500, running_acc=0.7723, grad=23.7839]Training epoch 14:   5%|▍         | 8/163 [00:14<03:23,  1.31s/it, loss=1.3346, batch_acc=0.6875, running_acc=0.7617, grad=20.5893]Training epoch 14:   6%|▌         | 9/163 [00:15<03:01,  1.18s/it, loss=1.3346, batch_acc=0.6875, running_acc=0.7617, grad=20.5893]Training epoch 14:   6%|▌         | 9/163 [00:15<03:01,  1.18s/it, loss=1.0595, batch_acc=0.8438, running_acc=0.7708, grad=21.1728]Training epoch 14:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=1.0595, batch_acc=0.8438, running_acc=0.7708, grad=21.1728]Training epoch 14:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=1.2204, batch_acc=0.7188, running_acc=0.7656, grad=22.9525]Training epoch 14:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=1.2204, batch_acc=0.7188, running_acc=0.7656, grad=22.9525]Training epoch 14:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=0.9131, batch_acc=0.8125, running_acc=0.7699, grad=27.6433]Training epoch 14:   7%|▋         | 12/163 [00:18<03:07,  1.24s/it, loss=0.9131, batch_acc=0.8125, running_acc=0.7699, grad=27.6433]Training epoch 14:   7%|▋         | 12/163 [00:18<03:07,  1.24s/it, loss=1.1678, batch_acc=0.7500, running_acc=0.7682, grad=23.4937]Training epoch 14:   8%|▊         | 13/163 [00:19<02:52,  1.15s/it, loss=1.1678, batch_acc=0.7500, running_acc=0.7682, grad=23.4937]Training epoch 14:   8%|▊         | 13/163 [00:19<02:52,  1.15s/it, loss=0.9536, batch_acc=0.8438, running_acc=0.7740, grad=23.1533]Training epoch 14:   9%|▊         | 14/163 [00:20<02:43,  1.10s/it, loss=0.9536, batch_acc=0.8438, running_acc=0.7740, grad=23.1533]Training epoch 14:   9%|▊         | 14/163 [00:20<02:43,  1.10s/it, loss=1.1627, batch_acc=0.8438, running_acc=0.7790, grad=22.4905]Training epoch 14:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=1.1627, batch_acc=0.8438, running_acc=0.7790, grad=22.4905]Training epoch 14:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=1.1795, batch_acc=0.7812, running_acc=0.7792, grad=25.9121]Training epoch 14:  10%|▉         | 16/163 [00:23<03:17,  1.34s/it, loss=1.1795, batch_acc=0.7812, running_acc=0.7792, grad=25.9121]Training epoch 14:  10%|▉         | 16/163 [00:23<03:17,  1.34s/it, loss=1.0713, batch_acc=0.7500, running_acc=0.7773, grad=19.2655]Training epoch 14:  10%|█         | 17/163 [00:24<02:55,  1.20s/it, loss=1.0713, batch_acc=0.7500, running_acc=0.7773, grad=19.2655]Training epoch 14:  10%|█         | 17/163 [00:24<02:55,  1.20s/it, loss=1.2196, batch_acc=0.7188, running_acc=0.7739, grad=22.5102]Training epoch 14:  11%|█         | 18/163 [00:25<02:40,  1.10s/it, loss=1.2196, batch_acc=0.7188, running_acc=0.7739, grad=22.5102]Training epoch 14:  11%|█         | 18/163 [00:25<02:40,  1.10s/it, loss=1.2137, batch_acc=0.7812, running_acc=0.7743, grad=24.4401]Training epoch 14:  12%|█▏        | 19/163 [00:26<02:29,  1.04s/it, loss=1.2137, batch_acc=0.7812, running_acc=0.7743, grad=24.4401]Training epoch 14:  12%|█▏        | 19/163 [00:26<02:29,  1.04s/it, loss=1.1073, batch_acc=0.7812, running_acc=0.7747, grad=34.9976]Training epoch 14:  12%|█▏        | 20/163 [00:28<03:40,  1.54s/it, loss=1.1073, batch_acc=0.7812, running_acc=0.7747, grad=34.9976]Training epoch 14:  12%|█▏        | 20/163 [00:28<03:40,  1.54s/it, loss=1.0213, batch_acc=0.8125, running_acc=0.7766, grad=26.2214]Training epoch 14:  13%|█▎        | 21/163 [00:29<03:10,  1.34s/it, loss=1.0213, batch_acc=0.8125, running_acc=0.7766, grad=26.2214]Training epoch 14:  13%|█▎        | 21/163 [00:29<03:10,  1.34s/it, loss=1.1725, batch_acc=0.7500, running_acc=0.7753, grad=20.6312]Training epoch 14:  13%|█▎        | 22/163 [00:30<02:49,  1.20s/it, loss=1.1725, batch_acc=0.7500, running_acc=0.7753, grad=20.6312]Training epoch 14:  13%|█▎        | 22/163 [00:30<02:49,  1.20s/it, loss=0.9047, batch_acc=0.8438, running_acc=0.7784, grad=30.5624]Training epoch 14:  14%|█▍        | 23/163 [00:31<02:34,  1.11s/it, loss=0.9047, batch_acc=0.8438, running_acc=0.7784, grad=30.5624]Training epoch 14:  14%|█▍        | 23/163 [00:31<02:34,  1.11s/it, loss=1.0554, batch_acc=0.8125, running_acc=0.7799, grad=23.5147]Training epoch 14:  15%|█▍        | 24/163 [00:32<02:42,  1.17s/it, loss=1.0554, batch_acc=0.8125, running_acc=0.7799, grad=23.5147]Training epoch 14:  15%|█▍        | 24/163 [00:32<02:42,  1.17s/it, loss=0.8934, batch_acc=0.8125, running_acc=0.7812, grad=19.5920]Training epoch 14:  15%|█▌        | 25/163 [00:33<02:28,  1.08s/it, loss=0.8934, batch_acc=0.8125, running_acc=0.7812, grad=19.5920]Training epoch 14:  15%|█▌        | 25/163 [00:33<02:28,  1.08s/it, loss=0.8519, batch_acc=0.8750, running_acc=0.7850, grad=20.2818]Training epoch 14:  16%|█▌        | 26/163 [00:34<02:19,  1.02s/it, loss=0.8519, batch_acc=0.8750, running_acc=0.7850, grad=20.2818]Training epoch 14:  16%|█▌        | 26/163 [00:34<02:19,  1.02s/it, loss=1.1542, batch_acc=0.6562, running_acc=0.7800, grad=32.1565]Training epoch 14:  17%|█▋        | 27/163 [00:35<02:12,  1.02it/s, loss=1.1542, batch_acc=0.6562, running_acc=0.7800, grad=32.1565]Training epoch 14:  17%|█▋        | 27/163 [00:35<02:12,  1.02it/s, loss=0.8467, batch_acc=0.8750, running_acc=0.7836, grad=23.1290]Training epoch 14:  17%|█▋        | 28/163 [00:36<02:38,  1.17s/it, loss=0.8467, batch_acc=0.8750, running_acc=0.7836, grad=23.1290]Training epoch 14:  17%|█▋        | 28/163 [00:36<02:38,  1.17s/it, loss=1.0804, batch_acc=0.7188, running_acc=0.7812, grad=26.6785]Training epoch 14:  18%|█▊        | 29/163 [00:37<02:25,  1.08s/it, loss=1.0804, batch_acc=0.7188, running_acc=0.7812, grad=26.6785]Training epoch 14:  18%|█▊        | 29/163 [00:37<02:25,  1.08s/it, loss=1.0822, batch_acc=0.7812, running_acc=0.7812, grad=23.7844]Training epoch 14:  18%|█▊        | 30/163 [00:38<02:15,  1.02s/it, loss=1.0822, batch_acc=0.7812, running_acc=0.7812, grad=23.7844]Training epoch 14:  18%|█▊        | 30/163 [00:38<02:15,  1.02s/it, loss=1.0644, batch_acc=0.7812, running_acc=0.7812, grad=20.0239]Training epoch 14:  19%|█▉        | 31/163 [00:39<02:09,  1.02it/s, loss=1.0644, batch_acc=0.7812, running_acc=0.7812, grad=20.0239]Training epoch 14:  19%|█▉        | 31/163 [00:39<02:09,  1.02it/s, loss=0.8540, batch_acc=0.8438, running_acc=0.7833, grad=19.2510]Training epoch 14:  20%|█▉        | 32/163 [00:41<02:37,  1.20s/it, loss=0.8540, batch_acc=0.8438, running_acc=0.7833, grad=19.2510]Training epoch 14:  20%|█▉        | 32/163 [00:41<02:37,  1.20s/it, loss=0.8344, batch_acc=0.9062, running_acc=0.7871, grad=23.8887]Training epoch 14:  20%|██        | 33/163 [00:42<02:23,  1.10s/it, loss=0.8344, batch_acc=0.9062, running_acc=0.7871, grad=23.8887]Training epoch 14:  20%|██        | 33/163 [00:42<02:23,  1.10s/it, loss=1.2783, batch_acc=0.7812, running_acc=0.7869, grad=27.3346]Training epoch 14:  21%|██        | 34/163 [00:43<02:13,  1.04s/it, loss=1.2783, batch_acc=0.7812, running_acc=0.7869, grad=27.3346]Training epoch 14:  21%|██        | 34/163 [00:43<02:13,  1.04s/it, loss=1.2368, batch_acc=0.6562, running_acc=0.7831, grad=23.5085]Training epoch 14:  21%|██▏       | 35/163 [00:43<02:06,  1.01it/s, loss=1.2368, batch_acc=0.6562, running_acc=0.7831, grad=23.5085]Training epoch 14:  21%|██▏       | 35/163 [00:43<02:06,  1.01it/s, loss=1.0616, batch_acc=0.7812, running_acc=0.7830, grad=25.0588]Training epoch 14:  22%|██▏       | 36/163 [00:45<02:39,  1.25s/it, loss=1.0616, batch_acc=0.7812, running_acc=0.7830, grad=25.0588]Training epoch 14:  22%|██▏       | 36/163 [00:45<02:39,  1.25s/it, loss=0.9700, batch_acc=0.8125, running_acc=0.7839, grad=22.0893]Training epoch 14:  23%|██▎       | 37/163 [00:46<02:23,  1.14s/it, loss=0.9700, batch_acc=0.8125, running_acc=0.7839, grad=22.0893]Training epoch 14:  23%|██▎       | 37/163 [00:46<02:23,  1.14s/it, loss=1.0323, batch_acc=0.8750, running_acc=0.7863, grad=21.4466]Training epoch 14:  23%|██▎       | 38/163 [00:47<02:12,  1.06s/it, loss=1.0323, batch_acc=0.8750, running_acc=0.7863, grad=21.4466]Training epoch 14:  23%|██▎       | 38/163 [00:47<02:12,  1.06s/it, loss=0.6820, batch_acc=0.9062, running_acc=0.7895, grad=21.1952]Training epoch 14:  24%|██▍       | 39/163 [00:48<02:04,  1.01s/it, loss=0.6820, batch_acc=0.9062, running_acc=0.7895, grad=21.1952]Training epoch 14:  24%|██▍       | 39/163 [00:48<02:04,  1.01s/it, loss=1.1905, batch_acc=0.7188, running_acc=0.7877, grad=26.4849]Training epoch 14:  25%|██▍       | 40/163 [00:49<02:15,  1.10s/it, loss=1.1905, batch_acc=0.7188, running_acc=0.7877, grad=26.4849]Training epoch 14:  25%|██▍       | 40/163 [00:49<02:15,  1.10s/it, loss=1.2195, batch_acc=0.6875, running_acc=0.7852, grad=31.8358]Training epoch 14:  25%|██▌       | 41/163 [00:50<02:06,  1.04s/it, loss=1.2195, batch_acc=0.6875, running_acc=0.7852, grad=31.8358]Training epoch 14:  25%|██▌       | 41/163 [00:50<02:06,  1.04s/it, loss=0.9423, batch_acc=0.8438, running_acc=0.7866, grad=20.8233]Training epoch 14:  26%|██▌       | 42/163 [00:51<01:59,  1.01it/s, loss=0.9423, batch_acc=0.8438, running_acc=0.7866, grad=20.8233]Training epoch 14:  26%|██▌       | 42/163 [00:51<01:59,  1.01it/s, loss=1.2857, batch_acc=0.8125, running_acc=0.7872, grad=23.0917]Training epoch 14:  26%|██▋       | 43/163 [00:52<01:54,  1.05it/s, loss=1.2857, batch_acc=0.8125, running_acc=0.7872, grad=23.0917]Training epoch 14:  26%|██▋       | 43/163 [00:52<01:54,  1.05it/s, loss=1.1653, batch_acc=0.7812, running_acc=0.7871, grad=24.8622]Training epoch 14:  27%|██▋       | 44/163 [00:54<02:42,  1.37s/it, loss=1.1653, batch_acc=0.7812, running_acc=0.7871, grad=24.8622]Training epoch 14:  27%|██▋       | 44/163 [00:54<02:42,  1.37s/it, loss=1.1507, batch_acc=0.8438, running_acc=0.7884, grad=26.3382]Training epoch 14:  28%|██▊       | 45/163 [00:55<02:23,  1.22s/it, loss=1.1507, batch_acc=0.8438, running_acc=0.7884, grad=26.3382]Training epoch 14:  28%|██▊       | 45/163 [00:55<02:23,  1.22s/it, loss=1.0623, batch_acc=0.7812, running_acc=0.7882, grad=28.1433]Training epoch 14:  28%|██▊       | 46/163 [00:56<02:10,  1.12s/it, loss=1.0623, batch_acc=0.7812, running_acc=0.7882, grad=28.1433]Training epoch 14:  28%|██▊       | 46/163 [00:56<02:10,  1.12s/it, loss=1.3628, batch_acc=0.7188, running_acc=0.7867, grad=26.5185]Training epoch 14:  29%|██▉       | 47/163 [00:57<02:01,  1.04s/it, loss=1.3628, batch_acc=0.7188, running_acc=0.7867, grad=26.5185]Training epoch 14:  29%|██▉       | 47/163 [00:57<02:01,  1.04s/it, loss=1.2831, batch_acc=0.7188, running_acc=0.7852, grad=23.6216]Training epoch 14:  29%|██▉       | 48/163 [00:59<02:22,  1.24s/it, loss=1.2831, batch_acc=0.7188, running_acc=0.7852, grad=23.6216]Training epoch 14:  29%|██▉       | 48/163 [00:59<02:22,  1.24s/it, loss=1.2673, batch_acc=0.7500, running_acc=0.7845, grad=28.1088]Training epoch 14:  30%|███       | 49/163 [00:59<02:09,  1.13s/it, loss=1.2673, batch_acc=0.7500, running_acc=0.7845, grad=28.1088]Training epoch 14:  30%|███       | 49/163 [00:59<02:09,  1.13s/it, loss=0.9015, batch_acc=0.9062, running_acc=0.7870, grad=29.0541]Training epoch 14:  31%|███       | 50/163 [01:00<01:59,  1.06s/it, loss=0.9015, batch_acc=0.9062, running_acc=0.7870, grad=29.0541]Training epoch 14:  31%|███       | 50/163 [01:00<01:59,  1.06s/it, loss=1.1260, batch_acc=0.8438, running_acc=0.7881, grad=19.0974]Training epoch 14:  31%|███▏      | 51/163 [01:01<01:52,  1.00s/it, loss=1.1260, batch_acc=0.8438, running_acc=0.7881, grad=19.0974]Training epoch 14:  31%|███▏      | 51/163 [01:01<01:52,  1.00s/it, loss=0.9547, batch_acc=0.8438, running_acc=0.7892, grad=21.2359]Training epoch 14:  32%|███▏      | 52/163 [01:03<02:15,  1.22s/it, loss=0.9547, batch_acc=0.8438, running_acc=0.7892, grad=21.2359]Training epoch 14:  32%|███▏      | 52/163 [01:03<02:15,  1.22s/it, loss=1.3473, batch_acc=0.6250, running_acc=0.7861, grad=26.1002]Training epoch 14:  33%|███▎      | 53/163 [01:04<02:03,  1.12s/it, loss=1.3473, batch_acc=0.6250, running_acc=0.7861, grad=26.1002]Training epoch 14:  33%|███▎      | 53/163 [01:04<02:03,  1.12s/it, loss=1.0393, batch_acc=0.7500, running_acc=0.7854, grad=23.4806]Training epoch 14:  33%|███▎      | 54/163 [01:05<01:54,  1.05s/it, loss=1.0393, batch_acc=0.7500, running_acc=0.7854, grad=23.4806]Training epoch 14:  33%|███▎      | 54/163 [01:05<01:54,  1.05s/it, loss=1.2360, batch_acc=0.6562, running_acc=0.7830, grad=26.2478]Training epoch 14:  34%|███▎      | 55/163 [01:06<01:47,  1.00it/s, loss=1.2360, batch_acc=0.6562, running_acc=0.7830, grad=26.2478]Training epoch 14:  34%|███▎      | 55/163 [01:06<01:47,  1.00it/s, loss=0.8883, batch_acc=0.8438, running_acc=0.7841, grad=28.7539]Training epoch 14:  34%|███▍      | 56/163 [01:07<02:12,  1.24s/it, loss=0.8883, batch_acc=0.8438, running_acc=0.7841, grad=28.7539]Training epoch 14:  34%|███▍      | 56/163 [01:07<02:12,  1.24s/it, loss=0.7312, batch_acc=0.8438, running_acc=0.7852, grad=19.0975]Training epoch 14:  35%|███▍      | 57/163 [01:08<02:00,  1.13s/it, loss=0.7312, batch_acc=0.8438, running_acc=0.7852, grad=19.0975]Training epoch 14:  35%|███▍      | 57/163 [01:08<02:00,  1.13s/it, loss=1.1489, batch_acc=0.7500, running_acc=0.7845, grad=21.0349]Training epoch 14:  36%|███▌      | 58/163 [01:09<01:50,  1.06s/it, loss=1.1489, batch_acc=0.7500, running_acc=0.7845, grad=21.0349]Training epoch 14:  36%|███▌      | 58/163 [01:09<01:50,  1.06s/it, loss=1.0859, batch_acc=0.7188, running_acc=0.7834, grad=20.2953]Training epoch 14:  36%|███▌      | 59/163 [01:10<01:44,  1.00s/it, loss=1.0859, batch_acc=0.7188, running_acc=0.7834, grad=20.2953]Training epoch 14:  36%|███▌      | 59/163 [01:10<01:44,  1.00s/it, loss=1.1058, batch_acc=0.7812, running_acc=0.7834, grad=20.4907]Training epoch 14:  37%|███▋      | 60/163 [01:12<02:03,  1.20s/it, loss=1.1058, batch_acc=0.7812, running_acc=0.7834, grad=20.4907]Training epoch 14:  37%|███▋      | 60/163 [01:12<02:03,  1.20s/it, loss=1.0474, batch_acc=0.7812, running_acc=0.7833, grad=25.7379]Training epoch 14:  37%|███▋      | 61/163 [01:13<01:52,  1.10s/it, loss=1.0474, batch_acc=0.7812, running_acc=0.7833, grad=25.7379]Training epoch 14:  37%|███▋      | 61/163 [01:13<01:52,  1.10s/it, loss=1.1026, batch_acc=0.7500, running_acc=0.7828, grad=24.0118]Training epoch 14:  38%|███▊      | 62/163 [01:13<01:44,  1.03s/it, loss=1.1026, batch_acc=0.7500, running_acc=0.7828, grad=24.0118]Training epoch 14:  38%|███▊      | 62/163 [01:13<01:44,  1.03s/it, loss=1.2954, batch_acc=0.6875, running_acc=0.7812, grad=28.3263]Training epoch 14:  39%|███▊      | 63/163 [01:14<01:38,  1.01it/s, loss=1.2954, batch_acc=0.6875, running_acc=0.7812, grad=28.3263]Training epoch 14:  39%|███▊      | 63/163 [01:14<01:38,  1.01it/s, loss=0.9884, batch_acc=0.8125, running_acc=0.7817, grad=26.0917]Training epoch 14:  39%|███▉      | 64/163 [01:16<01:49,  1.11s/it, loss=0.9884, batch_acc=0.8125, running_acc=0.7817, grad=26.0917]Training epoch 14:  39%|███▉      | 64/163 [01:16<01:49,  1.11s/it, loss=1.0050, batch_acc=0.8125, running_acc=0.7822, grad=20.6523]Training epoch 14:  40%|███▉      | 65/163 [01:17<01:41,  1.04s/it, loss=1.0050, batch_acc=0.8125, running_acc=0.7822, grad=20.6523]Training epoch 14:  40%|███▉      | 65/163 [01:17<01:41,  1.04s/it, loss=1.0989, batch_acc=0.7500, running_acc=0.7817, grad=27.2682]Training epoch 14:  40%|████      | 66/163 [01:17<01:36,  1.01it/s, loss=1.0989, batch_acc=0.7500, running_acc=0.7817, grad=27.2682]Training epoch 14:  40%|████      | 66/163 [01:17<01:36,  1.01it/s, loss=0.9518, batch_acc=0.8438, running_acc=0.7827, grad=25.6156]Training epoch 14:  41%|████      | 67/163 [01:18<01:31,  1.05it/s, loss=0.9518, batch_acc=0.8438, running_acc=0.7827, grad=25.6156]Training epoch 14:  41%|████      | 67/163 [01:18<01:31,  1.05it/s, loss=1.0529, batch_acc=0.7500, running_acc=0.7822, grad=21.0103]Training epoch 14:  42%|████▏     | 68/163 [01:20<01:47,  1.14s/it, loss=1.0529, batch_acc=0.7500, running_acc=0.7822, grad=21.0103]Training epoch 14:  42%|████▏     | 68/163 [01:20<01:47,  1.14s/it, loss=0.9680, batch_acc=0.8750, running_acc=0.7835, grad=22.3943]Training epoch 14:  42%|████▏     | 69/163 [01:21<01:39,  1.06s/it, loss=0.9680, batch_acc=0.8750, running_acc=0.7835, grad=22.3943]Training epoch 14:  42%|████▏     | 69/163 [01:21<01:39,  1.06s/it, loss=0.8754, batch_acc=0.8125, running_acc=0.7840, grad=26.5406]Training epoch 14:  43%|████▎     | 70/163 [01:22<01:33,  1.00s/it, loss=0.8754, batch_acc=0.8125, running_acc=0.7840, grad=26.5406]Training epoch 14:  43%|████▎     | 70/163 [01:22<01:33,  1.00s/it, loss=1.2153, batch_acc=0.7500, running_acc=0.7835, grad=19.8950]Training epoch 14:  44%|████▎     | 71/163 [01:23<01:28,  1.04it/s, loss=1.2153, batch_acc=0.7500, running_acc=0.7835, grad=19.8950]Training epoch 14:  44%|████▎     | 71/163 [01:23<01:28,  1.04it/s, loss=1.1271, batch_acc=0.8125, running_acc=0.7839, grad=20.5093]Training epoch 14:  44%|████▍     | 72/163 [01:24<01:52,  1.24s/it, loss=1.1271, batch_acc=0.8125, running_acc=0.7839, grad=20.5093]Training epoch 14:  44%|████▍     | 72/163 [01:24<01:52,  1.24s/it, loss=1.0121, batch_acc=0.8750, running_acc=0.7852, grad=22.0483]Training epoch 14:  45%|████▍     | 73/163 [01:25<01:41,  1.13s/it, loss=1.0121, batch_acc=0.8750, running_acc=0.7852, grad=22.0483]Training epoch 14:  45%|████▍     | 73/163 [01:25<01:41,  1.13s/it, loss=1.0725, batch_acc=0.7188, running_acc=0.7842, grad=22.5009]Training epoch 14:  45%|████▌     | 74/163 [01:26<01:34,  1.06s/it, loss=1.0725, batch_acc=0.7188, running_acc=0.7842, grad=22.5009]Training epoch 14:  45%|████▌     | 74/163 [01:26<01:34,  1.06s/it, loss=0.9066, batch_acc=0.8125, running_acc=0.7846, grad=18.0699]Training epoch 14:  46%|████▌     | 75/163 [01:27<01:28,  1.00s/it, loss=0.9066, batch_acc=0.8125, running_acc=0.7846, grad=18.0699]Training epoch 14:  46%|████▌     | 75/163 [01:27<01:28,  1.00s/it, loss=1.1579, batch_acc=0.7188, running_acc=0.7837, grad=26.3455]Training epoch 14:  47%|████▋     | 76/163 [01:29<01:41,  1.17s/it, loss=1.1579, batch_acc=0.7188, running_acc=0.7837, grad=26.3455]Training epoch 14:  47%|████▋     | 76/163 [01:29<01:41,  1.17s/it, loss=0.9049, batch_acc=0.8438, running_acc=0.7845, grad=30.0084]Training epoch 14:  47%|████▋     | 77/163 [01:29<01:32,  1.08s/it, loss=0.9049, batch_acc=0.8438, running_acc=0.7845, grad=30.0084]Training epoch 14:  47%|████▋     | 77/163 [01:29<01:32,  1.08s/it, loss=1.0491, batch_acc=0.7500, running_acc=0.7841, grad=28.2918]Training epoch 14:  48%|████▊     | 78/163 [01:30<01:26,  1.02s/it, loss=1.0491, batch_acc=0.7500, running_acc=0.7841, grad=28.2918]Training epoch 14:  48%|████▊     | 78/163 [01:30<01:26,  1.02s/it, loss=1.0887, batch_acc=0.7500, running_acc=0.7837, grad=29.8561]Training epoch 14:  48%|████▊     | 79/163 [01:31<01:21,  1.02it/s, loss=1.0887, batch_acc=0.7500, running_acc=0.7837, grad=29.8561]Training epoch 14:  48%|████▊     | 79/163 [01:31<01:21,  1.02it/s, loss=1.1691, batch_acc=0.7500, running_acc=0.7832, grad=30.0189]Training epoch 14:  49%|████▉     | 80/163 [01:32<01:25,  1.03s/it, loss=1.1691, batch_acc=0.7500, running_acc=0.7832, grad=30.0189]Training epoch 14:  49%|████▉     | 80/163 [01:32<01:25,  1.03s/it, loss=0.8378, batch_acc=0.9062, running_acc=0.7848, grad=20.2606]Training epoch 14:  50%|████▉     | 81/163 [01:34<01:28,  1.08s/it, loss=0.8378, batch_acc=0.9062, running_acc=0.7848, grad=20.2606]Training epoch 14:  50%|████▉     | 81/163 [01:34<01:28,  1.08s/it, loss=0.9693, batch_acc=0.7812, running_acc=0.7847, grad=16.6028]Training epoch 14:  50%|█████     | 82/163 [01:34<01:22,  1.02s/it, loss=0.9693, batch_acc=0.7812, running_acc=0.7847, grad=16.6028]Training epoch 14:  50%|█████     | 82/163 [01:34<01:22,  1.02s/it, loss=1.2752, batch_acc=0.6875, running_acc=0.7835, grad=28.2648]Training epoch 14:  51%|█████     | 83/163 [01:35<01:18,  1.02it/s, loss=1.2752, batch_acc=0.6875, running_acc=0.7835, grad=28.2648]Training epoch 14:  51%|█████     | 83/163 [01:35<01:18,  1.02it/s, loss=1.0614, batch_acc=0.7500, running_acc=0.7831, grad=28.3023]Training epoch 14:  52%|█████▏    | 84/163 [01:37<01:24,  1.07s/it, loss=1.0614, batch_acc=0.7500, running_acc=0.7831, grad=28.3023]Training epoch 14:  52%|█████▏    | 84/163 [01:37<01:24,  1.07s/it, loss=1.1916, batch_acc=0.7500, running_acc=0.7827, grad=22.5005]Training epoch 14:  52%|█████▏    | 85/163 [01:38<01:23,  1.07s/it, loss=1.1916, batch_acc=0.7500, running_acc=0.7827, grad=22.5005]Training epoch 14:  52%|█████▏    | 85/163 [01:38<01:23,  1.07s/it, loss=0.8387, batch_acc=0.8750, running_acc=0.7838, grad=20.5457]Training epoch 14:  53%|█████▎    | 86/163 [01:39<01:18,  1.02s/it, loss=0.8387, batch_acc=0.8750, running_acc=0.7838, grad=20.5457]Training epoch 14:  53%|█████▎    | 86/163 [01:39<01:18,  1.02s/it, loss=0.9830, batch_acc=0.7500, running_acc=0.7834, grad=38.6071]Training epoch 14:  53%|█████▎    | 87/163 [01:39<01:14,  1.02it/s, loss=0.9830, batch_acc=0.7500, running_acc=0.7834, grad=38.6071]Training epoch 14:  53%|█████▎    | 87/163 [01:39<01:14,  1.02it/s, loss=1.1349, batch_acc=0.7500, running_acc=0.7830, grad=23.4409]Training epoch 14:  54%|█████▍    | 88/163 [01:41<01:19,  1.06s/it, loss=1.1349, batch_acc=0.7500, running_acc=0.7830, grad=23.4409]Training epoch 14:  54%|█████▍    | 88/163 [01:41<01:19,  1.06s/it, loss=1.2783, batch_acc=0.7188, running_acc=0.7823, grad=34.2183]Training epoch 14:  55%|█████▍    | 89/163 [01:42<01:19,  1.08s/it, loss=1.2783, batch_acc=0.7188, running_acc=0.7823, grad=34.2183]Training epoch 14:  55%|█████▍    | 89/163 [01:42<01:19,  1.08s/it, loss=0.7735, batch_acc=0.8750, running_acc=0.7834, grad=22.1598]Training epoch 14:  55%|█████▌    | 90/163 [01:43<01:14,  1.02s/it, loss=0.7735, batch_acc=0.8750, running_acc=0.7834, grad=22.1598]Training epoch 14:  55%|█████▌    | 90/163 [01:43<01:14,  1.02s/it, loss=1.0761, batch_acc=0.6562, running_acc=0.7819, grad=27.5800]Training epoch 14:  56%|█████▌    | 91/163 [01:44<01:10,  1.02it/s, loss=1.0761, batch_acc=0.6562, running_acc=0.7819, grad=27.5800]Training epoch 14:  56%|█████▌    | 91/163 [01:44<01:10,  1.02it/s, loss=1.2971, batch_acc=0.7500, running_acc=0.7816, grad=26.6424]Training epoch 14:  56%|█████▋    | 92/163 [01:45<01:27,  1.23s/it, loss=1.2971, batch_acc=0.7500, running_acc=0.7816, grad=26.6424]Training epoch 14:  56%|█████▋    | 92/163 [01:45<01:27,  1.23s/it, loss=1.0266, batch_acc=0.8438, running_acc=0.7823, grad=26.0108]Training epoch 14:  57%|█████▋    | 93/163 [01:46<01:18,  1.12s/it, loss=1.0266, batch_acc=0.8438, running_acc=0.7823, grad=26.0108]Training epoch 14:  57%|█████▋    | 93/163 [01:46<01:18,  1.12s/it, loss=1.1529, batch_acc=0.8125, running_acc=0.7826, grad=24.2245]Training epoch 14:  58%|█████▊    | 94/163 [01:47<01:12,  1.05s/it, loss=1.1529, batch_acc=0.8125, running_acc=0.7826, grad=24.2245]Training epoch 14:  58%|█████▊    | 94/163 [01:47<01:12,  1.05s/it, loss=0.9118, batch_acc=0.9375, running_acc=0.7842, grad=31.5504]Training epoch 14:  58%|█████▊    | 95/163 [01:48<01:07,  1.00it/s, loss=0.9118, batch_acc=0.9375, running_acc=0.7842, grad=31.5504]Training epoch 14:  58%|█████▊    | 95/163 [01:48<01:07,  1.00it/s, loss=1.1890, batch_acc=0.7812, running_acc=0.7842, grad=24.1808]Training epoch 14:  59%|█████▉    | 96/163 [01:50<01:27,  1.31s/it, loss=1.1890, batch_acc=0.7812, running_acc=0.7842, grad=24.1808]Training epoch 14:  59%|█████▉    | 96/163 [01:50<01:27,  1.31s/it, loss=0.9966, batch_acc=0.7812, running_acc=0.7842, grad=22.4527]Training epoch 14:  60%|█████▉    | 97/163 [01:51<01:17,  1.18s/it, loss=0.9966, batch_acc=0.7812, running_acc=0.7842, grad=22.4527]Training epoch 14:  60%|█████▉    | 97/163 [01:51<01:17,  1.18s/it, loss=1.0615, batch_acc=0.7188, running_acc=0.7835, grad=24.0245]Training epoch 14:  60%|██████    | 98/163 [01:52<01:10,  1.09s/it, loss=1.0615, batch_acc=0.7188, running_acc=0.7835, grad=24.0245]Training epoch 14:  60%|██████    | 98/163 [01:52<01:10,  1.09s/it, loss=0.8934, batch_acc=0.9062, running_acc=0.7848, grad=20.9356]Training epoch 14:  61%|██████    | 99/163 [01:53<01:05,  1.02s/it, loss=0.8934, batch_acc=0.9062, running_acc=0.7848, grad=20.9356]Training epoch 14:  61%|██████    | 99/163 [01:53<01:05,  1.02s/it, loss=1.1130, batch_acc=0.7812, running_acc=0.7847, grad=29.2091]Training epoch 14:  61%|██████▏   | 100/163 [01:54<01:10,  1.12s/it, loss=1.1130, batch_acc=0.7812, running_acc=0.7847, grad=29.2091]Training epoch 14:  61%|██████▏   | 100/163 [01:54<01:10,  1.12s/it, loss=0.9688, batch_acc=0.8438, running_acc=0.7853, grad=22.8725]Training epoch 14:  62%|██████▏   | 101/163 [01:55<01:05,  1.05s/it, loss=0.9688, batch_acc=0.8438, running_acc=0.7853, grad=22.8725]Training epoch 14:  62%|██████▏   | 101/163 [01:55<01:05,  1.05s/it, loss=1.1544, batch_acc=0.7500, running_acc=0.7850, grad=25.2113]Training epoch 14:  63%|██████▎   | 102/163 [01:56<01:00,  1.00it/s, loss=1.1544, batch_acc=0.7500, running_acc=0.7850, grad=25.2113]Training epoch 14:  63%|██████▎   | 102/163 [01:56<01:00,  1.00it/s, loss=1.2138, batch_acc=0.7188, running_acc=0.7843, grad=22.6646]Training epoch 14:  63%|██████▎   | 103/163 [01:57<00:57,  1.04it/s, loss=1.2138, batch_acc=0.7188, running_acc=0.7843, grad=22.6646]Training epoch 14:  63%|██████▎   | 103/163 [01:57<00:57,  1.04it/s, loss=0.9831, batch_acc=0.6562, running_acc=0.7831, grad=22.1267]Training epoch 14:  64%|██████▍   | 104/163 [01:58<00:57,  1.03it/s, loss=0.9831, batch_acc=0.6562, running_acc=0.7831, grad=22.1267]Training epoch 14:  64%|██████▍   | 104/163 [01:58<00:57,  1.03it/s, loss=0.9014, batch_acc=0.8438, running_acc=0.7837, grad=21.0949]Training epoch 14:  64%|██████▍   | 105/163 [01:59<01:09,  1.20s/it, loss=0.9014, batch_acc=0.8438, running_acc=0.7837, grad=21.0949]Training epoch 14:  64%|██████▍   | 105/163 [01:59<01:09,  1.20s/it, loss=1.2862, batch_acc=0.7812, running_acc=0.7836, grad=28.8146]Training epoch 14:  65%|██████▌   | 106/163 [02:00<01:03,  1.11s/it, loss=1.2862, batch_acc=0.7812, running_acc=0.7836, grad=28.8146]Training epoch 14:  65%|██████▌   | 106/163 [02:00<01:03,  1.11s/it, loss=0.8718, batch_acc=0.9062, running_acc=0.7848, grad=20.5552]Training epoch 14:  66%|██████▌   | 107/163 [02:01<00:58,  1.04s/it, loss=0.8718, batch_acc=0.9062, running_acc=0.7848, grad=20.5552]Training epoch 14:  66%|██████▌   | 107/163 [02:01<00:58,  1.04s/it, loss=1.0013, batch_acc=0.8125, running_acc=0.7850, grad=20.1636]Training epoch 14:  66%|██████▋   | 108/163 [02:02<00:54,  1.01it/s, loss=1.0013, batch_acc=0.8125, running_acc=0.7850, grad=20.1636]Training epoch 14:  66%|██████▋   | 108/163 [02:02<00:54,  1.01it/s, loss=1.0428, batch_acc=0.8438, running_acc=0.7856, grad=21.7322]Training epoch 14:  67%|██████▋   | 109/163 [02:04<01:03,  1.18s/it, loss=1.0428, batch_acc=0.8438, running_acc=0.7856, grad=21.7322]Training epoch 14:  67%|██████▋   | 109/163 [02:04<01:03,  1.18s/it, loss=1.2250, batch_acc=0.6562, running_acc=0.7844, grad=19.9666]Training epoch 14:  67%|██████▋   | 110/163 [02:05<00:57,  1.09s/it, loss=1.2250, batch_acc=0.6562, running_acc=0.7844, grad=19.9666]Training epoch 14:  67%|██████▋   | 110/163 [02:05<00:57,  1.09s/it, loss=0.9390, batch_acc=0.7812, running_acc=0.7844, grad=17.6726]Training epoch 14:  68%|██████▊   | 111/163 [02:05<00:53,  1.03s/it, loss=0.9390, batch_acc=0.7812, running_acc=0.7844, grad=17.6726]Training epoch 14:  68%|██████▊   | 111/163 [02:05<00:53,  1.03s/it, loss=0.7626, batch_acc=0.8125, running_acc=0.7846, grad=22.7623]Training epoch 14:  69%|██████▊   | 112/163 [02:07<00:53,  1.05s/it, loss=0.7626, batch_acc=0.8125, running_acc=0.7846, grad=22.7623]Training epoch 14:  69%|██████▊   | 112/163 [02:07<00:53,  1.05s/it, loss=1.0645, batch_acc=0.8125, running_acc=0.7849, grad=25.3689]Training epoch 14:  69%|██████▉   | 113/163 [02:08<00:52,  1.05s/it, loss=1.0645, batch_acc=0.8125, running_acc=0.7849, grad=25.3689]Training epoch 14:  69%|██████▉   | 113/163 [02:08<00:52,  1.05s/it, loss=1.1695, batch_acc=0.7500, running_acc=0.7846, grad=27.9399]Training epoch 14:  70%|██████▉   | 114/163 [02:09<00:48,  1.00it/s, loss=1.1695, batch_acc=0.7500, running_acc=0.7846, grad=27.9399]Training epoch 14:  70%|██████▉   | 114/163 [02:09<00:48,  1.00it/s, loss=0.8477, batch_acc=0.8438, running_acc=0.7851, grad=19.3318]Training epoch 14:  71%|███████   | 115/163 [02:09<00:46,  1.04it/s, loss=0.8477, batch_acc=0.8438, running_acc=0.7851, grad=19.3318]Training epoch 14:  71%|███████   | 115/163 [02:09<00:46,  1.04it/s, loss=0.9296, batch_acc=0.8750, running_acc=0.7859, grad=20.7202]Training epoch 14:  71%|███████   | 116/163 [02:11<01:01,  1.30s/it, loss=0.9296, batch_acc=0.8750, running_acc=0.7859, grad=20.7202]Training epoch 14:  71%|███████   | 116/163 [02:11<01:01,  1.30s/it, loss=1.1681, batch_acc=0.7500, running_acc=0.7856, grad=18.4814]Training epoch 14:  72%|███████▏  | 117/163 [02:12<00:54,  1.18s/it, loss=1.1681, batch_acc=0.7500, running_acc=0.7856, grad=18.4814]Training epoch 14:  72%|███████▏  | 117/163 [02:12<00:54,  1.18s/it, loss=1.0121, batch_acc=0.9062, running_acc=0.7866, grad=25.9881]Training epoch 14:  72%|███████▏  | 118/163 [02:13<00:48,  1.09s/it, loss=1.0121, batch_acc=0.9062, running_acc=0.7866, grad=25.9881]Training epoch 14:  72%|███████▏  | 118/163 [02:13<00:48,  1.09s/it, loss=1.2363, batch_acc=0.8125, running_acc=0.7868, grad=24.1326]Training epoch 14:  73%|███████▎  | 119/163 [02:14<00:45,  1.02s/it, loss=1.2363, batch_acc=0.8125, running_acc=0.7868, grad=24.1326]Training epoch 14:  73%|███████▎  | 119/163 [02:14<00:45,  1.02s/it, loss=1.2976, batch_acc=0.7188, running_acc=0.7862, grad=25.5185]Training epoch 14:  74%|███████▎  | 120/163 [02:16<00:49,  1.14s/it, loss=1.2976, batch_acc=0.7188, running_acc=0.7862, grad=25.5185]Training epoch 14:  74%|███████▎  | 120/163 [02:16<00:49,  1.14s/it, loss=0.8060, batch_acc=0.8750, running_acc=0.7870, grad=23.8986]Training epoch 14:  74%|███████▍  | 121/163 [02:16<00:44,  1.06s/it, loss=0.8060, batch_acc=0.8750, running_acc=0.7870, grad=23.8986]Training epoch 14:  74%|███████▍  | 121/163 [02:16<00:44,  1.06s/it, loss=1.1916, batch_acc=0.6562, running_acc=0.7859, grad=23.8143]Training epoch 14:  75%|███████▍  | 122/163 [02:17<00:41,  1.01s/it, loss=1.1916, batch_acc=0.6562, running_acc=0.7859, grad=23.8143]Training epoch 14:  75%|███████▍  | 122/163 [02:17<00:41,  1.01s/it, loss=1.3263, batch_acc=0.5938, running_acc=0.7843, grad=28.7541]Training epoch 14:  75%|███████▌  | 123/163 [02:18<00:38,  1.03it/s, loss=1.3263, batch_acc=0.5938, running_acc=0.7843, grad=28.7541]Training epoch 14:  75%|███████▌  | 123/163 [02:18<00:38,  1.03it/s, loss=1.0370, batch_acc=0.7812, running_acc=0.7843, grad=18.6274]Training epoch 14:  76%|███████▌  | 124/163 [02:19<00:41,  1.07s/it, loss=1.0370, batch_acc=0.7812, running_acc=0.7843, grad=18.6274]Training epoch 14:  76%|███████▌  | 124/163 [02:19<00:41,  1.07s/it, loss=1.1693, batch_acc=0.7812, running_acc=0.7843, grad=25.9324]Training epoch 14:  77%|███████▋  | 125/163 [02:21<00:44,  1.17s/it, loss=1.1693, batch_acc=0.7812, running_acc=0.7843, grad=25.9324]Training epoch 14:  77%|███████▋  | 125/163 [02:21<00:44,  1.17s/it, loss=1.0201, batch_acc=0.7812, running_acc=0.7843, grad=23.0251]Training epoch 14:  77%|███████▋  | 126/163 [02:22<00:40,  1.08s/it, loss=1.0201, batch_acc=0.7812, running_acc=0.7843, grad=23.0251]Training epoch 14:  77%|███████▋  | 126/163 [02:22<00:40,  1.08s/it, loss=1.2320, batch_acc=0.7812, running_acc=0.7842, grad=23.8135]Training epoch 14:  78%|███████▊  | 127/163 [02:23<00:36,  1.02s/it, loss=1.2320, batch_acc=0.7812, running_acc=0.7842, grad=23.8135]Training epoch 14:  78%|███████▊  | 127/163 [02:23<00:36,  1.02s/it, loss=1.1701, batch_acc=0.7188, running_acc=0.7837, grad=21.3696]Training epoch 14:  79%|███████▊  | 128/163 [02:24<00:39,  1.14s/it, loss=1.1701, batch_acc=0.7188, running_acc=0.7837, grad=21.3696]Training epoch 14:  79%|███████▊  | 128/163 [02:24<00:39,  1.14s/it, loss=1.2048, batch_acc=0.7812, running_acc=0.7837, grad=22.1500]Training epoch 14:  79%|███████▉  | 129/163 [02:25<00:39,  1.16s/it, loss=1.2048, batch_acc=0.7812, running_acc=0.7837, grad=22.1500]Training epoch 14:  79%|███████▉  | 129/163 [02:25<00:39,  1.16s/it, loss=1.1771, batch_acc=0.7188, running_acc=0.7832, grad=33.0480]Training epoch 14:  80%|███████▉  | 130/163 [02:26<00:35,  1.07s/it, loss=1.1771, batch_acc=0.7188, running_acc=0.7832, grad=33.0480]Training epoch 14:  80%|███████▉  | 130/163 [02:26<00:35,  1.07s/it, loss=1.4066, batch_acc=0.6562, running_acc=0.7822, grad=29.9067]Training epoch 14:  80%|████████  | 131/163 [02:27<00:32,  1.02s/it, loss=1.4066, batch_acc=0.6562, running_acc=0.7822, grad=29.9067]Training epoch 14:  80%|████████  | 131/163 [02:27<00:32,  1.02s/it, loss=0.9795, batch_acc=0.7812, running_acc=0.7822, grad=24.8341]Training epoch 14:  81%|████████  | 132/163 [02:28<00:35,  1.15s/it, loss=0.9795, batch_acc=0.7812, running_acc=0.7822, grad=24.8341]Training epoch 14:  81%|████████  | 132/163 [02:28<00:35,  1.15s/it, loss=0.9457, batch_acc=0.8438, running_acc=0.7827, grad=28.3012]Training epoch 14:  82%|████████▏ | 133/163 [02:29<00:33,  1.11s/it, loss=0.9457, batch_acc=0.8438, running_acc=0.7827, grad=28.3012]Training epoch 14:  82%|████████▏ | 133/163 [02:29<00:33,  1.11s/it, loss=0.8392, batch_acc=0.8438, running_acc=0.7831, grad=22.3430]Training epoch 14:  82%|████████▏ | 134/163 [02:30<00:30,  1.04s/it, loss=0.8392, batch_acc=0.8438, running_acc=0.7831, grad=22.3430]Training epoch 14:  82%|████████▏ | 134/163 [02:30<00:30,  1.04s/it, loss=1.2032, batch_acc=0.7188, running_acc=0.7826, grad=22.0358]Training epoch 14:  83%|████████▎ | 135/163 [02:31<00:27,  1.01it/s, loss=1.2032, batch_acc=0.7188, running_acc=0.7826, grad=22.0358]Training epoch 14:  83%|████████▎ | 135/163 [02:31<00:27,  1.01it/s, loss=1.0428, batch_acc=0.8438, running_acc=0.7831, grad=22.9577]Training epoch 14:  83%|████████▎ | 136/163 [02:33<00:32,  1.22s/it, loss=1.0428, batch_acc=0.8438, running_acc=0.7831, grad=22.9577]Training epoch 14:  83%|████████▎ | 136/163 [02:33<00:32,  1.22s/it, loss=0.9833, batch_acc=0.7188, running_acc=0.7826, grad=21.0122]Training epoch 14:  84%|████████▍ | 137/163 [02:34<00:28,  1.12s/it, loss=0.9833, batch_acc=0.7188, running_acc=0.7826, grad=21.0122]Training epoch 14:  84%|████████▍ | 137/163 [02:34<00:28,  1.12s/it, loss=1.0480, batch_acc=0.7812, running_acc=0.7826, grad=25.4707]Training epoch 14:  85%|████████▍ | 138/163 [02:35<00:26,  1.05s/it, loss=1.0480, batch_acc=0.7812, running_acc=0.7826, grad=25.4707]Training epoch 14:  85%|████████▍ | 138/163 [02:35<00:26,  1.05s/it, loss=0.9055, batch_acc=0.8750, running_acc=0.7833, grad=21.7283]Training epoch 14:  85%|████████▌ | 139/163 [02:36<00:23,  1.01it/s, loss=0.9055, batch_acc=0.8750, running_acc=0.7833, grad=21.7283]Training epoch 14:  85%|████████▌ | 139/163 [02:36<00:23,  1.01it/s, loss=1.0333, batch_acc=0.7500, running_acc=0.7830, grad=23.8795]Training epoch 14:  86%|████████▌ | 140/163 [02:38<00:32,  1.41s/it, loss=1.0333, batch_acc=0.7500, running_acc=0.7830, grad=23.8795]Training epoch 14:  86%|████████▌ | 140/163 [02:38<00:32,  1.41s/it, loss=1.1126, batch_acc=0.8750, running_acc=0.7837, grad=20.5316]Training epoch 14:  87%|████████▋ | 141/163 [02:39<00:27,  1.25s/it, loss=1.1126, batch_acc=0.8750, running_acc=0.7837, grad=20.5316]Training epoch 14:  87%|████████▋ | 141/163 [02:39<00:27,  1.25s/it, loss=1.4304, batch_acc=0.6562, running_acc=0.7828, grad=30.2437]Training epoch 14:  87%|████████▋ | 142/163 [02:40<00:23,  1.14s/it, loss=1.4304, batch_acc=0.6562, running_acc=0.7828, grad=30.2437]Training epoch 14:  87%|████████▋ | 142/163 [02:40<00:23,  1.14s/it, loss=0.9278, batch_acc=0.8750, running_acc=0.7835, grad=23.4277]Training epoch 14:  88%|████████▊ | 143/163 [02:41<00:21,  1.06s/it, loss=0.9278, batch_acc=0.8750, running_acc=0.7835, grad=23.4277]Training epoch 14:  88%|████████▊ | 143/163 [02:41<00:21,  1.06s/it, loss=1.0149, batch_acc=0.7500, running_acc=0.7832, grad=29.6374]Training epoch 14:  88%|████████▊ | 144/163 [02:42<00:23,  1.26s/it, loss=1.0149, batch_acc=0.7500, running_acc=0.7832, grad=29.6374]Training epoch 14:  88%|████████▊ | 144/163 [02:42<00:23,  1.26s/it, loss=0.8859, batch_acc=0.8750, running_acc=0.7839, grad=20.9189]Training epoch 14:  89%|████████▉ | 145/163 [02:43<00:20,  1.15s/it, loss=0.8859, batch_acc=0.8750, running_acc=0.7839, grad=20.9189]Training epoch 14:  89%|████████▉ | 145/163 [02:43<00:20,  1.15s/it, loss=1.0374, batch_acc=0.7812, running_acc=0.7838, grad=31.3722]Training epoch 14:  90%|████████▉ | 146/163 [02:44<00:18,  1.07s/it, loss=1.0374, batch_acc=0.7812, running_acc=0.7838, grad=31.3722]Training epoch 14:  90%|████████▉ | 146/163 [02:44<00:18,  1.07s/it, loss=1.2529, batch_acc=0.6875, running_acc=0.7832, grad=23.3086]Training epoch 14:  90%|█████████ | 147/163 [02:45<00:16,  1.01s/it, loss=1.2529, batch_acc=0.6875, running_acc=0.7832, grad=23.3086]Training epoch 14:  90%|█████████ | 147/163 [02:45<00:16,  1.01s/it, loss=0.8947, batch_acc=0.9062, running_acc=0.7840, grad=25.0169]Training epoch 14:  91%|█████████ | 148/163 [02:47<00:19,  1.33s/it, loss=0.8947, batch_acc=0.9062, running_acc=0.7840, grad=25.0169]Training epoch 14:  91%|█████████ | 148/163 [02:47<00:19,  1.33s/it, loss=1.0710, batch_acc=0.7188, running_acc=0.7836, grad=28.5617]Training epoch 14:  91%|█████████▏| 149/163 [02:48<00:16,  1.20s/it, loss=1.0710, batch_acc=0.7188, running_acc=0.7836, grad=28.5617]Training epoch 14:  91%|█████████▏| 149/163 [02:48<00:16,  1.20s/it, loss=0.9750, batch_acc=0.7812, running_acc=0.7836, grad=20.5793]Training epoch 14:  92%|█████████▏| 150/163 [02:49<00:14,  1.10s/it, loss=0.9750, batch_acc=0.7812, running_acc=0.7836, grad=20.5793]Training epoch 14:  92%|█████████▏| 150/163 [02:49<00:14,  1.10s/it, loss=1.2602, batch_acc=0.6250, running_acc=0.7825, grad=25.9007]Training epoch 14:  93%|█████████▎| 151/163 [02:50<00:12,  1.03s/it, loss=1.2602, batch_acc=0.6250, running_acc=0.7825, grad=25.9007]Training epoch 14:  93%|█████████▎| 151/163 [02:50<00:12,  1.03s/it, loss=1.2224, batch_acc=0.8125, running_acc=0.7827, grad=22.9230]Training epoch 14:  93%|█████████▎| 152/163 [02:52<00:14,  1.30s/it, loss=1.2224, batch_acc=0.8125, running_acc=0.7827, grad=22.9230]Training epoch 14:  93%|█████████▎| 152/163 [02:52<00:14,  1.30s/it, loss=1.0160, batch_acc=0.7500, running_acc=0.7825, grad=25.9528]Training epoch 14:  94%|█████████▍| 153/163 [02:53<00:11,  1.17s/it, loss=1.0160, batch_acc=0.7500, running_acc=0.7825, grad=25.9528]Training epoch 14:  94%|█████████▍| 153/163 [02:53<00:11,  1.17s/it, loss=0.9765, batch_acc=0.8438, running_acc=0.7829, grad=20.6644]Training epoch 14:  94%|█████████▍| 154/163 [02:53<00:09,  1.09s/it, loss=0.9765, batch_acc=0.8438, running_acc=0.7829, grad=20.6644]Training epoch 14:  94%|█████████▍| 154/163 [02:53<00:09,  1.09s/it, loss=1.0386, batch_acc=0.8125, running_acc=0.7831, grad=22.1130]Training epoch 14:  95%|█████████▌| 155/163 [02:54<00:08,  1.02s/it, loss=1.0386, batch_acc=0.8125, running_acc=0.7831, grad=22.1130]Training epoch 14:  95%|█████████▌| 155/163 [02:54<00:08,  1.02s/it, loss=1.0464, batch_acc=0.8125, running_acc=0.7833, grad=23.5879]Training epoch 14:  96%|█████████▌| 156/163 [02:56<00:09,  1.30s/it, loss=1.0464, batch_acc=0.8125, running_acc=0.7833, grad=23.5879]Training epoch 14:  96%|█████████▌| 156/163 [02:56<00:09,  1.30s/it, loss=1.1514, batch_acc=0.8438, running_acc=0.7837, grad=21.4825]Training epoch 14:  96%|█████████▋| 157/163 [02:57<00:07,  1.17s/it, loss=1.1514, batch_acc=0.8438, running_acc=0.7837, grad=21.4825]Training epoch 14:  96%|█████████▋| 157/163 [02:57<00:07,  1.17s/it, loss=1.1271, batch_acc=0.7812, running_acc=0.7836, grad=26.1787]Training epoch 14:  97%|█████████▋| 158/163 [02:58<00:05,  1.09s/it, loss=1.1271, batch_acc=0.7812, running_acc=0.7836, grad=26.1787]Training epoch 14:  97%|█████████▋| 158/163 [02:58<00:05,  1.09s/it, loss=1.3902, batch_acc=0.6562, running_acc=0.7828, grad=31.6596]Training epoch 14:  98%|█████████▊| 159/163 [02:59<00:04,  1.02s/it, loss=1.3902, batch_acc=0.6562, running_acc=0.7828, grad=31.6596]Training epoch 14:  98%|█████████▊| 159/163 [02:59<00:04,  1.02s/it, loss=1.1400, batch_acc=0.7500, running_acc=0.7826, grad=21.3333]Training epoch 14:  98%|█████████▊| 160/163 [03:00<00:03,  1.11s/it, loss=1.1400, batch_acc=0.7500, running_acc=0.7826, grad=21.3333]Training epoch 14:  98%|█████████▊| 160/163 [03:00<00:03,  1.11s/it, loss=0.9828, batch_acc=0.8125, running_acc=0.7828, grad=20.7791]Training epoch 14:  99%|█████████▉| 161/163 [03:01<00:02,  1.04s/it, loss=0.9828, batch_acc=0.8125, running_acc=0.7828, grad=20.7791]Training epoch 14:  99%|█████████▉| 161/163 [03:01<00:02,  1.04s/it, loss=0.9535, batch_acc=0.7812, running_acc=0.7828, grad=32.3593]Training epoch 14:  99%|█████████▉| 162/163 [03:02<00:00,  1.01it/s, loss=0.9535, batch_acc=0.7812, running_acc=0.7828, grad=32.3593]Training epoch 14:  99%|█████████▉| 162/163 [03:02<00:00,  1.01it/s, loss=1.0937, batch_acc=0.8438, running_acc=0.7832, grad=22.8039]Training epoch 14: 100%|██████████| 163/163 [03:03<00:00,  1.13it/s, loss=1.0937, batch_acc=0.8438, running_acc=0.7832, grad=22.8039]Training epoch 14: 100%|██████████| 163/163 [03:03<00:00,  1.13it/s, loss=1.1948, batch_acc=0.7143, running_acc=0.7829, grad=31.9552]Training epoch 14: 100%|██████████| 163/163 [03:03<00:00,  1.12s/it, loss=1.1948, batch_acc=0.7143, running_acc=0.7829, grad=31.9552]
Evaluation epoch 14:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 14:   4%|▎         | 1/28 [00:05<02:17,  5.09s/it]Evaluation epoch 14:   4%|▎         | 1/28 [00:05<02:17,  5.09s/it, loss=0.8995, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 14:   7%|▋         | 2/28 [00:05<00:58,  2.25s/it, loss=0.8995, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 14:   7%|▋         | 2/28 [00:05<00:58,  2.25s/it, loss=1.2726, batch_acc=0.6562, running_acc=0.7500]Evaluation epoch 14:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=1.2726, batch_acc=0.6562, running_acc=0.7500]Evaluation epoch 14:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=1.1874, batch_acc=0.7188, running_acc=0.7396]Evaluation epoch 14:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=1.1874, batch_acc=0.7188, running_acc=0.7396]Evaluation epoch 14:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=1.4907, batch_acc=0.5625, running_acc=0.6953]Evaluation epoch 14:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.4907, batch_acc=0.5625, running_acc=0.6953]Evaluation epoch 14:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=2.2430, batch_acc=0.4062, running_acc=0.6375]Evaluation epoch 14:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=2.2430, batch_acc=0.4062, running_acc=0.6375]Evaluation epoch 14:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.4161, batch_acc=0.7500, running_acc=0.6562]Evaluation epoch 14:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.4161, batch_acc=0.7500, running_acc=0.6562]Evaluation epoch 14:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.4303, batch_acc=0.7188, running_acc=0.6652]Evaluation epoch 14:  29%|██▊       | 8/28 [00:14<00:35,  1.79s/it, loss=1.4303, batch_acc=0.7188, running_acc=0.6652]Evaluation epoch 14:  29%|██▊       | 8/28 [00:14<00:35,  1.79s/it, loss=1.1446, batch_acc=0.7500, running_acc=0.6758]Evaluation epoch 14:  32%|███▏      | 9/28 [00:14<00:24,  1.32s/it, loss=1.1446, batch_acc=0.7500, running_acc=0.6758]Evaluation epoch 14:  32%|███▏      | 9/28 [00:14<00:24,  1.32s/it, loss=1.2584, batch_acc=0.7812, running_acc=0.6875]Evaluation epoch 14:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=1.2584, batch_acc=0.7812, running_acc=0.6875]Evaluation epoch 14:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.7510, batch_acc=0.8750, running_acc=0.7063]Evaluation epoch 14:  39%|███▉      | 11/28 [00:15<00:13,  1.30it/s, loss=0.7510, batch_acc=0.8750, running_acc=0.7063]Evaluation epoch 14:  39%|███▉      | 11/28 [00:15<00:13,  1.30it/s, loss=1.2182, batch_acc=0.7812, running_acc=0.7131]Evaluation epoch 14:  43%|████▎     | 12/28 [00:21<00:37,  2.35s/it, loss=1.2182, batch_acc=0.7812, running_acc=0.7131]Evaluation epoch 14:  43%|████▎     | 12/28 [00:21<00:37,  2.35s/it, loss=1.6428, batch_acc=0.5938, running_acc=0.7031]Evaluation epoch 14:  46%|████▋     | 13/28 [00:21<00:25,  1.71s/it, loss=1.6428, batch_acc=0.5938, running_acc=0.7031]Evaluation epoch 14:  46%|████▋     | 13/28 [00:21<00:25,  1.71s/it, loss=0.9019, batch_acc=0.8438, running_acc=0.7139]Evaluation epoch 14:  50%|█████     | 14/28 [00:21<00:17,  1.28s/it, loss=0.9019, batch_acc=0.8438, running_acc=0.7139]Evaluation epoch 14:  50%|█████     | 14/28 [00:21<00:17,  1.28s/it, loss=1.5073, batch_acc=0.7500, running_acc=0.7165]Evaluation epoch 14:  54%|█████▎    | 15/28 [00:21<00:12,  1.03it/s, loss=1.5073, batch_acc=0.7500, running_acc=0.7165]Evaluation epoch 14:  54%|█████▎    | 15/28 [00:21<00:12,  1.03it/s, loss=2.1461, batch_acc=0.4062, running_acc=0.6958]Evaluation epoch 14:  57%|█████▋    | 16/28 [00:24<00:19,  1.58s/it, loss=2.1461, batch_acc=0.4062, running_acc=0.6958]Evaluation epoch 14:  57%|█████▋    | 16/28 [00:24<00:19,  1.58s/it, loss=1.7477, batch_acc=0.4375, running_acc=0.6797]Evaluation epoch 14:  61%|██████    | 17/28 [00:25<00:13,  1.19s/it, loss=1.7477, batch_acc=0.4375, running_acc=0.6797]Evaluation epoch 14:  61%|██████    | 17/28 [00:25<00:13,  1.19s/it, loss=1.2958, batch_acc=0.6250, running_acc=0.6765]Evaluation epoch 14:  64%|██████▍   | 18/28 [00:25<00:09,  1.10it/s, loss=1.2958, batch_acc=0.6250, running_acc=0.6765]Evaluation epoch 14:  64%|██████▍   | 18/28 [00:25<00:09,  1.10it/s, loss=1.1982, batch_acc=0.5938, running_acc=0.6719]Evaluation epoch 14:  68%|██████▊   | 19/28 [00:25<00:06,  1.40it/s, loss=1.1982, batch_acc=0.5938, running_acc=0.6719]Evaluation epoch 14:  68%|██████▊   | 19/28 [00:25<00:06,  1.40it/s, loss=1.3624, batch_acc=0.7188, running_acc=0.6743]Evaluation epoch 14:  71%|███████▏  | 20/28 [00:28<00:11,  1.44s/it, loss=1.3624, batch_acc=0.7188, running_acc=0.6743]Evaluation epoch 14:  71%|███████▏  | 20/28 [00:28<00:11,  1.44s/it, loss=1.2632, batch_acc=0.6875, running_acc=0.6750]Evaluation epoch 14:  75%|███████▌  | 21/28 [00:29<00:07,  1.09s/it, loss=1.2632, batch_acc=0.6875, running_acc=0.6750]Evaluation epoch 14:  75%|███████▌  | 21/28 [00:29<00:07,  1.09s/it, loss=1.2984, batch_acc=0.7812, running_acc=0.6801]Evaluation epoch 14:  79%|███████▊  | 22/28 [00:29<00:05,  1.19it/s, loss=1.2984, batch_acc=0.7812, running_acc=0.6801]Evaluation epoch 14:  79%|███████▊  | 22/28 [00:29<00:05,  1.19it/s, loss=1.4693, batch_acc=0.6250, running_acc=0.6776]Evaluation epoch 14:  82%|████████▏ | 23/28 [00:29<00:03,  1.50it/s, loss=1.4693, batch_acc=0.6250, running_acc=0.6776]Evaluation epoch 14:  82%|████████▏ | 23/28 [00:29<00:03,  1.50it/s, loss=1.6508, batch_acc=0.5625, running_acc=0.6726]Evaluation epoch 14:  86%|████████▌ | 24/28 [00:35<00:08,  2.09s/it, loss=1.6508, batch_acc=0.5625, running_acc=0.6726]Evaluation epoch 14:  86%|████████▌ | 24/28 [00:35<00:08,  2.09s/it, loss=0.8890, batch_acc=0.8750, running_acc=0.6810]Evaluation epoch 14:  89%|████████▉ | 25/28 [00:35<00:04,  1.54s/it, loss=0.8890, batch_acc=0.8750, running_acc=0.6810]Evaluation epoch 14:  89%|████████▉ | 25/28 [00:35<00:04,  1.54s/it, loss=0.9401, batch_acc=0.8125, running_acc=0.6863]Evaluation epoch 14:  93%|█████████▎| 26/28 [00:35<00:02,  1.16s/it, loss=0.9401, batch_acc=0.8125, running_acc=0.6863]Evaluation epoch 14:  93%|█████████▎| 26/28 [00:35<00:02,  1.16s/it, loss=1.3441, batch_acc=0.6250, running_acc=0.6839]Evaluation epoch 14:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.3441, batch_acc=0.6250, running_acc=0.6839]Evaluation epoch 14:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.4560, batch_acc=0.5625, running_acc=0.6794]Evaluation epoch 14: 100%|██████████| 28/28 [00:35<00:00,  1.13it/s, loss=1.0364, batch_acc=0.6667, running_acc=0.6794]Evaluation epoch 14: 100%|██████████| 28/28 [00:35<00:00,  1.28s/it, loss=1.0364, batch_acc=0.6667, running_acc=0.6794]
Training epoch 15:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 15:   1%|          | 1/163 [00:06<17:29,  6.48s/it]Training epoch 15:   1%|          | 1/163 [00:06<17:29,  6.48s/it, loss=0.9170, batch_acc=0.8438, running_acc=0.8438, grad=21.6971]Training epoch 15:   1%|          | 2/163 [00:07<08:32,  3.19s/it, loss=0.9170, batch_acc=0.8438, running_acc=0.8438, grad=21.6971]Training epoch 15:   1%|          | 2/163 [00:07<08:32,  3.19s/it, loss=1.2691, batch_acc=0.7812, running_acc=0.8125, grad=23.6021]Training epoch 15:   2%|▏         | 3/163 [00:08<05:41,  2.13s/it, loss=1.2691, batch_acc=0.7812, running_acc=0.8125, grad=23.6021]Training epoch 15:   2%|▏         | 3/163 [00:08<05:41,  2.13s/it, loss=0.8115, batch_acc=0.8750, running_acc=0.8333, grad=21.7800]Training epoch 15:   2%|▏         | 4/163 [00:10<05:29,  2.07s/it, loss=0.8115, batch_acc=0.8750, running_acc=0.8333, grad=21.7800]Training epoch 15:   2%|▏         | 4/163 [00:10<05:29,  2.07s/it, loss=0.8249, batch_acc=0.9062, running_acc=0.8516, grad=21.8030]Training epoch 15:   3%|▎         | 5/163 [00:11<04:28,  1.70s/it, loss=0.8249, batch_acc=0.9062, running_acc=0.8516, grad=21.8030]Training epoch 15:   3%|▎         | 5/163 [00:11<04:28,  1.70s/it, loss=0.8456, batch_acc=0.8750, running_acc=0.8562, grad=20.3951]Training epoch 15:   4%|▎         | 6/163 [00:12<03:43,  1.42s/it, loss=0.8456, batch_acc=0.8750, running_acc=0.8562, grad=20.3951]Training epoch 15:   4%|▎         | 6/163 [00:12<03:43,  1.42s/it, loss=0.9005, batch_acc=0.7812, running_acc=0.8438, grad=20.2001]Training epoch 15:   4%|▍         | 7/163 [00:13<03:14,  1.24s/it, loss=0.9005, batch_acc=0.7812, running_acc=0.8438, grad=20.2001]Training epoch 15:   4%|▍         | 7/163 [00:13<03:14,  1.24s/it, loss=1.2103, batch_acc=0.7188, running_acc=0.8259, grad=27.9854]Training epoch 15:   5%|▍         | 8/163 [00:14<03:36,  1.40s/it, loss=1.2103, batch_acc=0.7188, running_acc=0.8259, grad=27.9854]Training epoch 15:   5%|▍         | 8/163 [00:14<03:36,  1.40s/it, loss=0.8670, batch_acc=0.8750, running_acc=0.8320, grad=25.4106]Training epoch 15:   6%|▌         | 9/163 [00:15<03:10,  1.24s/it, loss=0.8670, batch_acc=0.8750, running_acc=0.8320, grad=25.4106]Training epoch 15:   6%|▌         | 9/163 [00:15<03:10,  1.24s/it, loss=1.2044, batch_acc=0.6875, running_acc=0.8160, grad=28.1453]Training epoch 15:   6%|▌         | 10/163 [00:16<02:52,  1.13s/it, loss=1.2044, batch_acc=0.6875, running_acc=0.8160, grad=28.1453]Training epoch 15:   6%|▌         | 10/163 [00:16<02:52,  1.13s/it, loss=0.9338, batch_acc=0.8750, running_acc=0.8219, grad=21.4157]Training epoch 15:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.9338, batch_acc=0.8750, running_acc=0.8219, grad=21.4157]Training epoch 15:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=1.0765, batch_acc=0.7812, running_acc=0.8182, grad=18.1480]Training epoch 15:   7%|▋         | 12/163 [00:19<03:05,  1.23s/it, loss=1.0765, batch_acc=0.7812, running_acc=0.8182, grad=18.1480]Training epoch 15:   7%|▋         | 12/163 [00:19<03:05,  1.23s/it, loss=1.1183, batch_acc=0.7188, running_acc=0.8099, grad=27.6776]Training epoch 15:   8%|▊         | 13/163 [00:20<03:05,  1.24s/it, loss=1.1183, batch_acc=0.7188, running_acc=0.8099, grad=27.6776]Training epoch 15:   8%|▊         | 13/163 [00:20<03:05,  1.24s/it, loss=1.0247, batch_acc=0.8750, running_acc=0.8149, grad=27.7432]Training epoch 15:   9%|▊         | 14/163 [00:21<02:48,  1.13s/it, loss=1.0247, batch_acc=0.8750, running_acc=0.8149, grad=27.7432]Training epoch 15:   9%|▊         | 14/163 [00:21<02:48,  1.13s/it, loss=1.0473, batch_acc=0.7812, running_acc=0.8125, grad=20.2615]Training epoch 15:   9%|▉         | 15/163 [00:22<02:36,  1.05s/it, loss=1.0473, batch_acc=0.7812, running_acc=0.8125, grad=20.2615]Training epoch 15:   9%|▉         | 15/163 [00:22<02:36,  1.05s/it, loss=1.0186, batch_acc=0.8125, running_acc=0.8125, grad=25.7176]Training epoch 15:  10%|▉         | 16/163 [00:23<02:41,  1.10s/it, loss=1.0186, batch_acc=0.8125, running_acc=0.8125, grad=25.7176]Training epoch 15:  10%|▉         | 16/163 [00:23<02:41,  1.10s/it, loss=1.0887, batch_acc=0.7188, running_acc=0.8066, grad=22.8836]Training epoch 15:  10%|█         | 17/163 [00:24<02:43,  1.12s/it, loss=1.0887, batch_acc=0.7188, running_acc=0.8066, grad=22.8836]Training epoch 15:  10%|█         | 17/163 [00:24<02:43,  1.12s/it, loss=0.6243, batch_acc=0.9375, running_acc=0.8143, grad=19.0973]Training epoch 15:  11%|█         | 18/163 [00:25<02:31,  1.05s/it, loss=0.6243, batch_acc=0.9375, running_acc=0.8143, grad=19.0973]Training epoch 15:  11%|█         | 18/163 [00:25<02:31,  1.05s/it, loss=0.9743, batch_acc=0.7500, running_acc=0.8108, grad=20.6483]Training epoch 15:  12%|█▏        | 19/163 [00:26<02:23,  1.00it/s, loss=0.9743, batch_acc=0.7500, running_acc=0.8108, grad=20.6483]Training epoch 15:  12%|█▏        | 19/163 [00:26<02:23,  1.00it/s, loss=1.1802, batch_acc=0.7812, running_acc=0.8092, grad=24.7792]Training epoch 15:  12%|█▏        | 20/163 [00:27<02:40,  1.12s/it, loss=1.1802, batch_acc=0.7812, running_acc=0.8092, grad=24.7792]Training epoch 15:  12%|█▏        | 20/163 [00:27<02:40,  1.12s/it, loss=1.2993, batch_acc=0.5938, running_acc=0.7984, grad=33.1442]Training epoch 15:  13%|█▎        | 21/163 [00:28<02:36,  1.10s/it, loss=1.2993, batch_acc=0.5938, running_acc=0.7984, grad=33.1442]Training epoch 15:  13%|█▎        | 21/163 [00:28<02:36,  1.10s/it, loss=0.9101, batch_acc=0.8438, running_acc=0.8006, grad=27.9008]Training epoch 15:  13%|█▎        | 22/163 [00:29<02:26,  1.04s/it, loss=0.9101, batch_acc=0.8438, running_acc=0.8006, grad=27.9008]Training epoch 15:  13%|█▎        | 22/163 [00:29<02:26,  1.04s/it, loss=0.7924, batch_acc=0.9062, running_acc=0.8054, grad=16.8473]Training epoch 15:  14%|█▍        | 23/163 [00:30<02:18,  1.01it/s, loss=0.7924, batch_acc=0.9062, running_acc=0.8054, grad=16.8473]Training epoch 15:  14%|█▍        | 23/163 [00:30<02:18,  1.01it/s, loss=0.8597, batch_acc=0.8750, running_acc=0.8084, grad=31.5476]Training epoch 15:  15%|█▍        | 24/163 [00:31<02:27,  1.06s/it, loss=0.8597, batch_acc=0.8750, running_acc=0.8084, grad=31.5476]Training epoch 15:  15%|█▍        | 24/163 [00:31<02:27,  1.06s/it, loss=0.7407, batch_acc=0.8438, running_acc=0.8099, grad=23.4659]Training epoch 15:  15%|█▌        | 25/163 [00:32<02:35,  1.13s/it, loss=0.7407, batch_acc=0.8438, running_acc=0.8099, grad=23.4659]Training epoch 15:  15%|█▌        | 25/163 [00:32<02:35,  1.13s/it, loss=1.1274, batch_acc=0.7812, running_acc=0.8087, grad=30.4336]Training epoch 15:  16%|█▌        | 26/163 [00:33<02:24,  1.05s/it, loss=1.1274, batch_acc=0.7812, running_acc=0.8087, grad=30.4336]Training epoch 15:  16%|█▌        | 26/163 [00:33<02:24,  1.05s/it, loss=0.9793, batch_acc=0.8438, running_acc=0.8101, grad=21.3566]Training epoch 15:  17%|█▋        | 27/163 [00:34<02:16,  1.00s/it, loss=0.9793, batch_acc=0.8438, running_acc=0.8101, grad=21.3566]Training epoch 15:  17%|█▋        | 27/163 [00:34<02:16,  1.00s/it, loss=0.8852, batch_acc=0.8125, running_acc=0.8102, grad=21.0823]Training epoch 15:  17%|█▋        | 28/163 [00:35<02:15,  1.00s/it, loss=0.8852, batch_acc=0.8125, running_acc=0.8102, grad=21.0823]Training epoch 15:  17%|█▋        | 28/163 [00:35<02:15,  1.00s/it, loss=0.9257, batch_acc=0.8125, running_acc=0.8103, grad=17.5071]Training epoch 15:  18%|█▊        | 29/163 [00:36<02:13,  1.01it/s, loss=0.9257, batch_acc=0.8125, running_acc=0.8103, grad=17.5071]Training epoch 15:  18%|█▊        | 29/163 [00:36<02:13,  1.01it/s, loss=0.8771, batch_acc=0.7500, running_acc=0.8082, grad=23.9835]Training epoch 15:  18%|█▊        | 30/163 [00:37<02:07,  1.04it/s, loss=0.8771, batch_acc=0.7500, running_acc=0.8082, grad=23.9835]Training epoch 15:  18%|█▊        | 30/163 [00:37<02:07,  1.04it/s, loss=1.2463, batch_acc=0.7500, running_acc=0.8063, grad=29.6529]Training epoch 15:  19%|█▉        | 31/163 [00:38<02:03,  1.07it/s, loss=1.2463, batch_acc=0.7500, running_acc=0.8063, grad=29.6529]Training epoch 15:  19%|█▉        | 31/163 [00:38<02:03,  1.07it/s, loss=1.1316, batch_acc=0.8438, running_acc=0.8075, grad=33.4719]Training epoch 15:  20%|█▉        | 32/163 [00:39<02:22,  1.09s/it, loss=1.1316, batch_acc=0.8438, running_acc=0.8075, grad=33.4719]Training epoch 15:  20%|█▉        | 32/163 [00:39<02:22,  1.09s/it, loss=0.7073, batch_acc=0.9375, running_acc=0.8115, grad=17.3773]Training epoch 15:  20%|██        | 33/163 [00:41<02:26,  1.13s/it, loss=0.7073, batch_acc=0.9375, running_acc=0.8115, grad=17.3773]Training epoch 15:  20%|██        | 33/163 [00:41<02:26,  1.13s/it, loss=0.7435, batch_acc=0.8750, running_acc=0.8134, grad=17.3529]Training epoch 15:  21%|██        | 34/163 [00:41<02:15,  1.05s/it, loss=0.7435, batch_acc=0.8750, running_acc=0.8134, grad=17.3529]Training epoch 15:  21%|██        | 34/163 [00:41<02:15,  1.05s/it, loss=1.1073, batch_acc=0.8125, running_acc=0.8134, grad=24.0069]Training epoch 15:  21%|██▏       | 35/163 [00:42<02:08,  1.00s/it, loss=1.1073, batch_acc=0.8125, running_acc=0.8134, grad=24.0069]Training epoch 15:  21%|██▏       | 35/163 [00:42<02:08,  1.00s/it, loss=0.6971, batch_acc=0.9062, running_acc=0.8161, grad=21.4109]Training epoch 15:  22%|██▏       | 36/163 [00:43<02:12,  1.04s/it, loss=0.6971, batch_acc=0.9062, running_acc=0.8161, grad=21.4109]Training epoch 15:  22%|██▏       | 36/163 [00:43<02:12,  1.04s/it, loss=0.9422, batch_acc=0.9062, running_acc=0.8186, grad=26.0731]Training epoch 15:  23%|██▎       | 37/163 [00:45<02:22,  1.13s/it, loss=0.9422, batch_acc=0.9062, running_acc=0.8186, grad=26.0731]Training epoch 15:  23%|██▎       | 37/163 [00:45<02:22,  1.13s/it, loss=1.1011, batch_acc=0.7500, running_acc=0.8167, grad=21.4876]Training epoch 15:  23%|██▎       | 38/163 [00:46<02:16,  1.09s/it, loss=1.1011, batch_acc=0.7500, running_acc=0.8167, grad=21.4876]Training epoch 15:  23%|██▎       | 38/163 [00:46<02:16,  1.09s/it, loss=1.0215, batch_acc=0.8438, running_acc=0.8174, grad=24.0520]Training epoch 15:  24%|██▍       | 39/163 [00:47<02:07,  1.03s/it, loss=1.0215, batch_acc=0.8438, running_acc=0.8174, grad=24.0520]Training epoch 15:  24%|██▍       | 39/163 [00:47<02:07,  1.03s/it, loss=1.0958, batch_acc=0.7812, running_acc=0.8165, grad=26.3460]Training epoch 15:  25%|██▍       | 40/163 [00:48<02:04,  1.01s/it, loss=1.0958, batch_acc=0.7812, running_acc=0.8165, grad=26.3460]Training epoch 15:  25%|██▍       | 40/163 [00:48<02:04,  1.01s/it, loss=0.9723, batch_acc=0.8125, running_acc=0.8164, grad=33.0382]Training epoch 15:  25%|██▌       | 41/163 [00:49<02:20,  1.15s/it, loss=0.9723, batch_acc=0.8125, running_acc=0.8164, grad=33.0382]Training epoch 15:  25%|██▌       | 41/163 [00:49<02:20,  1.15s/it, loss=0.9138, batch_acc=0.9375, running_acc=0.8194, grad=22.3585]Training epoch 15:  26%|██▌       | 42/163 [00:50<02:10,  1.08s/it, loss=0.9138, batch_acc=0.9375, running_acc=0.8194, grad=22.3585]Training epoch 15:  26%|██▌       | 42/163 [00:50<02:10,  1.08s/it, loss=0.8974, batch_acc=0.8125, running_acc=0.8192, grad=21.2519]Training epoch 15:  26%|██▋       | 43/163 [00:51<02:02,  1.02s/it, loss=0.8974, batch_acc=0.8125, running_acc=0.8192, grad=21.2519]Training epoch 15:  26%|██▋       | 43/163 [00:51<02:02,  1.02s/it, loss=1.1163, batch_acc=0.7500, running_acc=0.8176, grad=24.5892]Training epoch 15:  27%|██▋       | 44/163 [00:52<02:00,  1.02s/it, loss=1.1163, batch_acc=0.7500, running_acc=0.8176, grad=24.5892]Training epoch 15:  27%|██▋       | 44/163 [00:52<02:00,  1.02s/it, loss=0.9386, batch_acc=0.8438, running_acc=0.8182, grad=20.6191]Training epoch 15:  28%|██▊       | 45/163 [00:53<02:13,  1.13s/it, loss=0.9386, batch_acc=0.8438, running_acc=0.8182, grad=20.6191]Training epoch 15:  28%|██▊       | 45/163 [00:53<02:13,  1.13s/it, loss=1.0178, batch_acc=0.7500, running_acc=0.8167, grad=31.4513]Training epoch 15:  28%|██▊       | 46/163 [00:54<02:03,  1.05s/it, loss=1.0178, batch_acc=0.7500, running_acc=0.8167, grad=31.4513]Training epoch 15:  28%|██▊       | 46/163 [00:54<02:03,  1.05s/it, loss=0.9698, batch_acc=0.8125, running_acc=0.8166, grad=23.0960]Training epoch 15:  29%|██▉       | 47/163 [00:55<01:56,  1.00s/it, loss=0.9698, batch_acc=0.8125, running_acc=0.8166, grad=23.0960]Training epoch 15:  29%|██▉       | 47/163 [00:55<01:56,  1.00s/it, loss=1.0643, batch_acc=0.7812, running_acc=0.8158, grad=33.4780]Training epoch 15:  29%|██▉       | 48/163 [00:57<02:26,  1.27s/it, loss=1.0643, batch_acc=0.7812, running_acc=0.8158, grad=33.4780]Training epoch 15:  29%|██▉       | 48/163 [00:57<02:26,  1.27s/it, loss=0.9354, batch_acc=0.8125, running_acc=0.8158, grad=18.4020]Training epoch 15:  30%|███       | 49/163 [00:58<02:18,  1.21s/it, loss=0.9354, batch_acc=0.8125, running_acc=0.8158, grad=18.4020]Training epoch 15:  30%|███       | 49/163 [00:58<02:18,  1.21s/it, loss=1.0712, batch_acc=0.7188, running_acc=0.8138, grad=29.7138]Training epoch 15:  31%|███       | 50/163 [00:59<02:05,  1.11s/it, loss=1.0712, batch_acc=0.7188, running_acc=0.8138, grad=29.7138]Training epoch 15:  31%|███       | 50/163 [00:59<02:05,  1.11s/it, loss=1.1479, batch_acc=0.6875, running_acc=0.8113, grad=23.6301]Training epoch 15:  31%|███▏      | 51/163 [01:00<01:56,  1.04s/it, loss=1.1479, batch_acc=0.6875, running_acc=0.8113, grad=23.6301]Training epoch 15:  31%|███▏      | 51/163 [01:00<01:56,  1.04s/it, loss=0.8548, batch_acc=0.8750, running_acc=0.8125, grad=26.9274]Training epoch 15:  32%|███▏      | 52/163 [01:01<02:05,  1.13s/it, loss=0.8548, batch_acc=0.8750, running_acc=0.8125, grad=26.9274]Training epoch 15:  32%|███▏      | 52/163 [01:01<02:05,  1.13s/it, loss=0.9509, batch_acc=0.8438, running_acc=0.8131, grad=24.2083]Training epoch 15:  33%|███▎      | 53/163 [01:02<01:55,  1.05s/it, loss=0.9509, batch_acc=0.8438, running_acc=0.8131, grad=24.2083]Training epoch 15:  33%|███▎      | 53/163 [01:02<01:55,  1.05s/it, loss=0.7497, batch_acc=0.8750, running_acc=0.8143, grad=21.2481]Training epoch 15:  33%|███▎      | 54/163 [01:03<01:49,  1.00s/it, loss=0.7497, batch_acc=0.8750, running_acc=0.8143, grad=21.2481]Training epoch 15:  33%|███▎      | 54/163 [01:03<01:49,  1.00s/it, loss=0.9709, batch_acc=0.8125, running_acc=0.8142, grad=22.4229]Training epoch 15:  34%|███▎      | 55/163 [01:04<01:44,  1.03it/s, loss=0.9709, batch_acc=0.8125, running_acc=0.8142, grad=22.4229]Training epoch 15:  34%|███▎      | 55/163 [01:04<01:44,  1.03it/s, loss=0.8604, batch_acc=0.8438, running_acc=0.8148, grad=20.9384]Training epoch 15:  34%|███▍      | 56/163 [01:05<02:01,  1.14s/it, loss=0.8604, batch_acc=0.8438, running_acc=0.8148, grad=20.9384]Training epoch 15:  34%|███▍      | 56/163 [01:05<02:01,  1.14s/it, loss=0.9538, batch_acc=0.8125, running_acc=0.8147, grad=22.5238]Training epoch 15:  35%|███▍      | 57/163 [01:06<01:52,  1.06s/it, loss=0.9538, batch_acc=0.8125, running_acc=0.8147, grad=22.5238]Training epoch 15:  35%|███▍      | 57/163 [01:06<01:52,  1.06s/it, loss=0.8433, batch_acc=0.8750, running_acc=0.8158, grad=19.7858]Training epoch 15:  36%|███▌      | 58/163 [01:07<01:45,  1.01s/it, loss=0.8433, batch_acc=0.8750, running_acc=0.8158, grad=19.7858]Training epoch 15:  36%|███▌      | 58/163 [01:07<01:45,  1.01s/it, loss=0.7861, batch_acc=0.9062, running_acc=0.8173, grad=20.9350]Training epoch 15:  36%|███▌      | 59/163 [01:08<01:40,  1.03it/s, loss=0.7861, batch_acc=0.9062, running_acc=0.8173, grad=20.9350]Training epoch 15:  36%|███▌      | 59/163 [01:08<01:40,  1.03it/s, loss=0.8201, batch_acc=0.8125, running_acc=0.8173, grad=20.6071]Training epoch 15:  37%|███▋      | 60/163 [01:10<01:57,  1.14s/it, loss=0.8201, batch_acc=0.8125, running_acc=0.8173, grad=20.6071]Training epoch 15:  37%|███▋      | 60/163 [01:10<01:57,  1.14s/it, loss=1.0459, batch_acc=0.8125, running_acc=0.8172, grad=27.0946]Training epoch 15:  37%|███▋      | 61/163 [01:10<01:48,  1.06s/it, loss=1.0459, batch_acc=0.8125, running_acc=0.8172, grad=27.0946]Training epoch 15:  37%|███▋      | 61/163 [01:10<01:48,  1.06s/it, loss=1.1559, batch_acc=0.6875, running_acc=0.8151, grad=24.7544]Training epoch 15:  38%|███▊      | 62/163 [01:11<01:41,  1.01s/it, loss=1.1559, batch_acc=0.6875, running_acc=0.8151, grad=24.7544]Training epoch 15:  38%|███▊      | 62/163 [01:11<01:41,  1.01s/it, loss=0.6813, batch_acc=0.8750, running_acc=0.8160, grad=22.5530]Training epoch 15:  39%|███▊      | 63/163 [01:12<01:36,  1.03it/s, loss=0.6813, batch_acc=0.8750, running_acc=0.8160, grad=22.5530]Training epoch 15:  39%|███▊      | 63/163 [01:12<01:36,  1.03it/s, loss=1.0956, batch_acc=0.6875, running_acc=0.8140, grad=27.4223]Training epoch 15:  39%|███▉      | 64/163 [01:14<02:01,  1.23s/it, loss=1.0956, batch_acc=0.6875, running_acc=0.8140, grad=27.4223]Training epoch 15:  39%|███▉      | 64/163 [01:14<02:01,  1.23s/it, loss=1.1322, batch_acc=0.8125, running_acc=0.8140, grad=23.4358]Training epoch 15:  40%|███▉      | 65/163 [01:15<01:50,  1.13s/it, loss=1.1322, batch_acc=0.8125, running_acc=0.8140, grad=23.4358]Training epoch 15:  40%|███▉      | 65/163 [01:15<01:50,  1.13s/it, loss=1.0101, batch_acc=0.8750, running_acc=0.8149, grad=19.6180]Training epoch 15:  40%|████      | 66/163 [01:16<01:42,  1.05s/it, loss=1.0101, batch_acc=0.8750, running_acc=0.8149, grad=19.6180]Training epoch 15:  40%|████      | 66/163 [01:16<01:42,  1.05s/it, loss=1.0203, batch_acc=0.6875, running_acc=0.8130, grad=23.1301]Training epoch 15:  41%|████      | 67/163 [01:17<01:36,  1.00s/it, loss=1.0203, batch_acc=0.6875, running_acc=0.8130, grad=23.1301]Training epoch 15:  41%|████      | 67/163 [01:17<01:36,  1.00s/it, loss=0.9516, batch_acc=0.7500, running_acc=0.8120, grad=34.1543]Training epoch 15:  42%|████▏     | 68/163 [01:18<01:59,  1.26s/it, loss=0.9516, batch_acc=0.7500, running_acc=0.8120, grad=34.1543]Training epoch 15:  42%|████▏     | 68/163 [01:18<01:59,  1.26s/it, loss=1.0494, batch_acc=0.7500, running_acc=0.8111, grad=25.0920]Training epoch 15:  42%|████▏     | 69/163 [01:19<01:47,  1.14s/it, loss=1.0494, batch_acc=0.7500, running_acc=0.8111, grad=25.0920]Training epoch 15:  42%|████▏     | 69/163 [01:19<01:47,  1.14s/it, loss=0.8178, batch_acc=0.8438, running_acc=0.8116, grad=24.7346]Training epoch 15:  43%|████▎     | 70/163 [01:20<01:38,  1.06s/it, loss=0.8178, batch_acc=0.8438, running_acc=0.8116, grad=24.7346]Training epoch 15:  43%|████▎     | 70/163 [01:20<01:38,  1.06s/it, loss=1.1827, batch_acc=0.7500, running_acc=0.8107, grad=31.3400]Training epoch 15:  44%|████▎     | 71/163 [01:21<01:32,  1.01s/it, loss=1.1827, batch_acc=0.7500, running_acc=0.8107, grad=31.3400]Training epoch 15:  44%|████▎     | 71/163 [01:21<01:32,  1.01s/it, loss=0.9307, batch_acc=0.9062, running_acc=0.8121, grad=28.0618]Training epoch 15:  44%|████▍     | 72/163 [01:23<01:45,  1.16s/it, loss=0.9307, batch_acc=0.9062, running_acc=0.8121, grad=28.0618]Training epoch 15:  44%|████▍     | 72/163 [01:23<01:45,  1.16s/it, loss=1.0719, batch_acc=0.8125, running_acc=0.8121, grad=29.1652]Training epoch 15:  45%|████▍     | 73/163 [01:24<01:37,  1.08s/it, loss=1.0719, batch_acc=0.8125, running_acc=0.8121, grad=29.1652]Training epoch 15:  45%|████▍     | 73/163 [01:24<01:37,  1.08s/it, loss=1.0218, batch_acc=0.7188, running_acc=0.8108, grad=23.7474]Training epoch 15:  45%|████▌     | 74/163 [01:25<01:33,  1.05s/it, loss=1.0218, batch_acc=0.7188, running_acc=0.8108, grad=23.7474]Training epoch 15:  45%|████▌     | 74/163 [01:25<01:33,  1.05s/it, loss=0.7777, batch_acc=0.8750, running_acc=0.8117, grad=23.9060]Training epoch 15:  46%|████▌     | 75/163 [01:25<01:27,  1.00it/s, loss=0.7777, batch_acc=0.8750, running_acc=0.8117, grad=23.9060]Training epoch 15:  46%|████▌     | 75/163 [01:25<01:27,  1.00it/s, loss=1.1514, batch_acc=0.7812, running_acc=0.8113, grad=32.4220]Training epoch 15:  47%|████▋     | 76/163 [01:26<01:27,  1.01s/it, loss=1.1514, batch_acc=0.7812, running_acc=0.8113, grad=32.4220]Training epoch 15:  47%|████▋     | 76/163 [01:26<01:27,  1.01s/it, loss=1.0201, batch_acc=0.8125, running_acc=0.8113, grad=24.5740]Training epoch 15:  47%|████▋     | 77/163 [01:27<01:23,  1.03it/s, loss=1.0201, batch_acc=0.8125, running_acc=0.8113, grad=24.5740]Training epoch 15:  47%|████▋     | 77/163 [01:27<01:23,  1.03it/s, loss=1.1877, batch_acc=0.7500, running_acc=0.8105, grad=30.4530]Training epoch 15:  48%|████▊     | 78/163 [01:28<01:20,  1.06it/s, loss=1.1877, batch_acc=0.7500, running_acc=0.8105, grad=30.4530]Training epoch 15:  48%|████▊     | 78/163 [01:28<01:20,  1.06it/s, loss=0.8302, batch_acc=0.9375, running_acc=0.8121, grad=21.0871]Training epoch 15:  48%|████▊     | 79/163 [01:29<01:25,  1.02s/it, loss=0.8302, batch_acc=0.9375, running_acc=0.8121, grad=21.0871]Training epoch 15:  48%|████▊     | 79/163 [01:29<01:25,  1.02s/it, loss=1.1567, batch_acc=0.7188, running_acc=0.8109, grad=27.3678]Training epoch 15:  49%|████▉     | 80/163 [01:31<01:33,  1.13s/it, loss=1.1567, batch_acc=0.7188, running_acc=0.8109, grad=27.3678]Training epoch 15:  49%|████▉     | 80/163 [01:31<01:33,  1.13s/it, loss=1.1334, batch_acc=0.7500, running_acc=0.8102, grad=27.5765]Training epoch 15:  50%|████▉     | 81/163 [01:32<01:35,  1.16s/it, loss=1.1334, batch_acc=0.7500, running_acc=0.8102, grad=27.5765]Training epoch 15:  50%|████▉     | 81/163 [01:32<01:35,  1.16s/it, loss=0.9803, batch_acc=0.8438, running_acc=0.8106, grad=20.7650]Training epoch 15:  50%|█████     | 82/163 [01:33<01:27,  1.08s/it, loss=0.9803, batch_acc=0.8438, running_acc=0.8106, grad=20.7650]Training epoch 15:  50%|█████     | 82/163 [01:33<01:27,  1.08s/it, loss=1.0037, batch_acc=0.8125, running_acc=0.8106, grad=19.3397]Training epoch 15:  51%|█████     | 83/163 [01:34<01:23,  1.05s/it, loss=1.0037, batch_acc=0.8125, running_acc=0.8106, grad=19.3397]Training epoch 15:  51%|█████     | 83/163 [01:34<01:23,  1.05s/it, loss=0.9356, batch_acc=0.7812, running_acc=0.8102, grad=21.6996]Training epoch 15:  52%|█████▏    | 84/163 [01:36<01:36,  1.23s/it, loss=0.9356, batch_acc=0.7812, running_acc=0.8102, grad=21.6996]Training epoch 15:  52%|█████▏    | 84/163 [01:36<01:36,  1.23s/it, loss=1.0868, batch_acc=0.7812, running_acc=0.8099, grad=21.0310]Training epoch 15:  52%|█████▏    | 85/163 [01:36<01:27,  1.12s/it, loss=1.0868, batch_acc=0.7812, running_acc=0.8099, grad=21.0310]Training epoch 15:  52%|█████▏    | 85/163 [01:36<01:27,  1.12s/it, loss=1.1759, batch_acc=0.7812, running_acc=0.8096, grad=24.3521]Training epoch 15:  53%|█████▎    | 86/163 [01:37<01:20,  1.05s/it, loss=1.1759, batch_acc=0.7812, running_acc=0.8096, grad=24.3521]Training epoch 15:  53%|█████▎    | 86/163 [01:37<01:20,  1.05s/it, loss=1.1523, batch_acc=0.7188, running_acc=0.8085, grad=26.1482]Training epoch 15:  53%|█████▎    | 87/163 [01:38<01:15,  1.00it/s, loss=1.1523, batch_acc=0.7188, running_acc=0.8085, grad=26.1482]Training epoch 15:  53%|█████▎    | 87/163 [01:38<01:15,  1.00it/s, loss=1.0229, batch_acc=0.7500, running_acc=0.8078, grad=29.9602]Training epoch 15:  54%|█████▍    | 88/163 [01:40<01:23,  1.12s/it, loss=1.0229, batch_acc=0.7500, running_acc=0.8078, grad=29.9602]Training epoch 15:  54%|█████▍    | 88/163 [01:40<01:23,  1.12s/it, loss=0.8480, batch_acc=0.8750, running_acc=0.8086, grad=20.2422]Training epoch 15:  55%|█████▍    | 89/163 [01:40<01:17,  1.05s/it, loss=0.8480, batch_acc=0.8750, running_acc=0.8086, grad=20.2422]Training epoch 15:  55%|█████▍    | 89/163 [01:40<01:17,  1.05s/it, loss=0.8500, batch_acc=0.8438, running_acc=0.8090, grad=28.7874]Training epoch 15:  55%|█████▌    | 90/163 [01:41<01:12,  1.00it/s, loss=0.8500, batch_acc=0.8438, running_acc=0.8090, grad=28.7874]Training epoch 15:  55%|█████▌    | 90/163 [01:41<01:12,  1.00it/s, loss=1.0257, batch_acc=0.8125, running_acc=0.8090, grad=23.7084]Training epoch 15:  56%|█████▌    | 91/163 [01:42<01:09,  1.03it/s, loss=1.0257, batch_acc=0.8125, running_acc=0.8090, grad=23.7084]Training epoch 15:  56%|█████▌    | 91/163 [01:42<01:09,  1.03it/s, loss=0.7686, batch_acc=0.8750, running_acc=0.8098, grad=19.8785]Training epoch 15:  56%|█████▋    | 92/163 [01:44<01:21,  1.15s/it, loss=0.7686, batch_acc=0.8750, running_acc=0.8098, grad=19.8785]Training epoch 15:  56%|█████▋    | 92/163 [01:44<01:21,  1.15s/it, loss=0.9433, batch_acc=0.8438, running_acc=0.8101, grad=25.7967]Training epoch 15:  57%|█████▋    | 93/163 [01:45<01:14,  1.07s/it, loss=0.9433, batch_acc=0.8438, running_acc=0.8101, grad=25.7967]Training epoch 15:  57%|█████▋    | 93/163 [01:45<01:14,  1.07s/it, loss=1.2265, batch_acc=0.7188, running_acc=0.8091, grad=27.1961]Training epoch 15:  58%|█████▊    | 94/163 [01:46<01:09,  1.01s/it, loss=1.2265, batch_acc=0.7188, running_acc=0.8091, grad=27.1961]Training epoch 15:  58%|█████▊    | 94/163 [01:46<01:09,  1.01s/it, loss=0.8185, batch_acc=0.8750, running_acc=0.8098, grad=34.3445]Training epoch 15:  58%|█████▊    | 95/163 [01:47<01:12,  1.06s/it, loss=0.8185, batch_acc=0.8750, running_acc=0.8098, grad=34.3445]Training epoch 15:  58%|█████▊    | 95/163 [01:47<01:12,  1.06s/it, loss=0.9027, batch_acc=0.8750, running_acc=0.8105, grad=22.3895]Training epoch 15:  59%|█████▉    | 96/163 [01:48<01:17,  1.15s/it, loss=0.9027, batch_acc=0.8750, running_acc=0.8105, grad=22.3895]Training epoch 15:  59%|█████▉    | 96/163 [01:48<01:17,  1.15s/it, loss=0.7820, batch_acc=0.8750, running_acc=0.8112, grad=25.8046]Training epoch 15:  60%|█████▉    | 97/163 [01:49<01:10,  1.07s/it, loss=0.7820, batch_acc=0.8750, running_acc=0.8112, grad=25.8046]Training epoch 15:  60%|█████▉    | 97/163 [01:49<01:10,  1.07s/it, loss=1.0279, batch_acc=0.8438, running_acc=0.8115, grad=23.6671]Training epoch 15:  60%|██████    | 98/163 [01:50<01:05,  1.01s/it, loss=1.0279, batch_acc=0.8438, running_acc=0.8115, grad=23.6671]Training epoch 15:  60%|██████    | 98/163 [01:50<01:05,  1.01s/it, loss=0.9715, batch_acc=0.9375, running_acc=0.8128, grad=36.5667]Training epoch 15:  61%|██████    | 99/163 [01:51<01:09,  1.09s/it, loss=0.9715, batch_acc=0.9375, running_acc=0.8128, grad=36.5667]Training epoch 15:  61%|██████    | 99/163 [01:51<01:09,  1.09s/it, loss=0.9650, batch_acc=0.9375, running_acc=0.8141, grad=21.6977]Training epoch 15:  61%|██████▏   | 100/163 [01:53<01:18,  1.24s/it, loss=0.9650, batch_acc=0.9375, running_acc=0.8141, grad=21.6977]Training epoch 15:  61%|██████▏   | 100/163 [01:53<01:18,  1.24s/it, loss=1.1483, batch_acc=0.7500, running_acc=0.8134, grad=30.8468]Training epoch 15:  62%|██████▏   | 101/163 [01:54<01:10,  1.13s/it, loss=1.1483, batch_acc=0.7500, running_acc=0.8134, grad=30.8468]Training epoch 15:  62%|██████▏   | 101/163 [01:54<01:10,  1.13s/it, loss=0.8467, batch_acc=0.9688, running_acc=0.8150, grad=34.9010]Training epoch 15:  63%|██████▎   | 102/163 [01:54<01:04,  1.05s/it, loss=0.8467, batch_acc=0.9688, running_acc=0.8150, grad=34.9010]Training epoch 15:  63%|██████▎   | 102/163 [01:54<01:04,  1.05s/it, loss=1.0657, batch_acc=0.7188, running_acc=0.8140, grad=28.5236]Training epoch 15:  63%|██████▎   | 103/163 [01:56<01:11,  1.19s/it, loss=1.0657, batch_acc=0.7188, running_acc=0.8140, grad=28.5236]Training epoch 15:  63%|██████▎   | 103/163 [01:56<01:11,  1.19s/it, loss=1.0170, batch_acc=0.7812, running_acc=0.8137, grad=26.0541]Training epoch 15:  64%|██████▍   | 104/163 [01:57<01:05,  1.11s/it, loss=1.0170, batch_acc=0.7812, running_acc=0.8137, grad=26.0541]Training epoch 15:  64%|██████▍   | 104/163 [01:57<01:05,  1.11s/it, loss=1.1002, batch_acc=0.7812, running_acc=0.8134, grad=26.4488]Training epoch 15:  64%|██████▍   | 105/163 [01:58<01:01,  1.07s/it, loss=1.1002, batch_acc=0.7812, running_acc=0.8134, grad=26.4488]Training epoch 15:  64%|██████▍   | 105/163 [01:58<01:01,  1.07s/it, loss=1.0254, batch_acc=0.8125, running_acc=0.8134, grad=22.3265]Training epoch 15:  65%|██████▌   | 106/163 [01:59<00:57,  1.01s/it, loss=1.0254, batch_acc=0.8125, running_acc=0.8134, grad=22.3265]Training epoch 15:  65%|██████▌   | 106/163 [01:59<00:57,  1.01s/it, loss=0.9428, batch_acc=0.8125, running_acc=0.8134, grad=24.9741]Training epoch 15:  66%|██████▌   | 107/163 [02:00<01:04,  1.16s/it, loss=0.9428, batch_acc=0.8125, running_acc=0.8134, grad=24.9741]Training epoch 15:  66%|██████▌   | 107/163 [02:00<01:04,  1.16s/it, loss=0.9256, batch_acc=0.8438, running_acc=0.8137, grad=23.2146]Training epoch 15:  66%|██████▋   | 108/163 [02:01<00:59,  1.08s/it, loss=0.9256, batch_acc=0.8438, running_acc=0.8137, grad=23.2146]Training epoch 15:  66%|██████▋   | 108/163 [02:01<00:59,  1.08s/it, loss=0.7044, batch_acc=0.8750, running_acc=0.8142, grad=23.5207]Training epoch 15:  67%|██████▋   | 109/163 [02:02<00:54,  1.02s/it, loss=0.7044, batch_acc=0.8750, running_acc=0.8142, grad=23.5207]Training epoch 15:  67%|██████▋   | 109/163 [02:02<00:54,  1.02s/it, loss=1.0683, batch_acc=0.8125, running_acc=0.8142, grad=24.9525]Training epoch 15:  67%|██████▋   | 110/163 [02:03<00:51,  1.02it/s, loss=1.0683, batch_acc=0.8125, running_acc=0.8142, grad=24.9525]Training epoch 15:  67%|██████▋   | 110/163 [02:03<00:51,  1.02it/s, loss=1.1511, batch_acc=0.7812, running_acc=0.8139, grad=28.4304]Training epoch 15:  68%|██████▊   | 111/163 [02:04<00:53,  1.02s/it, loss=1.1511, batch_acc=0.7812, running_acc=0.8139, grad=28.4304]Training epoch 15:  68%|██████▊   | 111/163 [02:04<00:53,  1.02s/it, loss=1.0372, batch_acc=0.7500, running_acc=0.8133, grad=24.7823]Training epoch 15:  69%|██████▊   | 112/163 [02:05<00:54,  1.08s/it, loss=1.0372, batch_acc=0.7500, running_acc=0.8133, grad=24.7823]Training epoch 15:  69%|██████▊   | 112/163 [02:05<00:54,  1.08s/it, loss=1.0371, batch_acc=0.8438, running_acc=0.8136, grad=29.7966]Training epoch 15:  69%|██████▉   | 113/163 [02:06<00:50,  1.02s/it, loss=1.0371, batch_acc=0.8438, running_acc=0.8136, grad=29.7966]Training epoch 15:  69%|██████▉   | 113/163 [02:06<00:50,  1.02s/it, loss=1.1955, batch_acc=0.7188, running_acc=0.8128, grad=25.2718]Training epoch 15:  70%|██████▉   | 114/163 [02:07<00:47,  1.02it/s, loss=1.1955, batch_acc=0.7188, running_acc=0.8128, grad=25.2718]Training epoch 15:  70%|██████▉   | 114/163 [02:07<00:47,  1.02it/s, loss=1.1704, batch_acc=0.7188, running_acc=0.8120, grad=23.7472]Training epoch 15:  71%|███████   | 115/163 [02:08<00:51,  1.08s/it, loss=1.1704, batch_acc=0.7188, running_acc=0.8120, grad=23.7472]Training epoch 15:  71%|███████   | 115/163 [02:08<00:51,  1.08s/it, loss=0.7136, batch_acc=0.9062, running_acc=0.8128, grad=14.4909]Training epoch 15:  71%|███████   | 116/163 [02:09<00:52,  1.11s/it, loss=0.7136, batch_acc=0.9062, running_acc=0.8128, grad=14.4909]Training epoch 15:  71%|███████   | 116/163 [02:09<00:52,  1.11s/it, loss=0.9955, batch_acc=0.8125, running_acc=0.8128, grad=20.5157]Training epoch 15:  72%|███████▏  | 117/163 [02:10<00:47,  1.04s/it, loss=0.9955, batch_acc=0.8125, running_acc=0.8128, grad=20.5157]Training epoch 15:  72%|███████▏  | 117/163 [02:10<00:47,  1.04s/it, loss=0.8233, batch_acc=0.8438, running_acc=0.8130, grad=21.6519]Training epoch 15:  72%|███████▏  | 118/163 [02:11<00:44,  1.01it/s, loss=0.8233, batch_acc=0.8438, running_acc=0.8130, grad=21.6519]Training epoch 15:  72%|███████▏  | 118/163 [02:11<00:44,  1.01it/s, loss=0.7321, batch_acc=0.9062, running_acc=0.8138, grad=17.1897]Training epoch 15:  73%|███████▎  | 119/163 [02:13<00:51,  1.17s/it, loss=0.7321, batch_acc=0.9062, running_acc=0.8138, grad=17.1897]Training epoch 15:  73%|███████▎  | 119/163 [02:13<00:51,  1.17s/it, loss=1.0843, batch_acc=0.7500, running_acc=0.8133, grad=24.0366]Training epoch 15:  74%|███████▎  | 120/163 [02:14<00:48,  1.12s/it, loss=1.0843, batch_acc=0.7500, running_acc=0.8133, grad=24.0366]Training epoch 15:  74%|███████▎  | 120/163 [02:14<00:48,  1.12s/it, loss=0.7962, batch_acc=0.8750, running_acc=0.8138, grad=18.9158]Training epoch 15:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=0.7962, batch_acc=0.8750, running_acc=0.8138, grad=18.9158]Training epoch 15:  74%|███████▍  | 121/163 [02:15<00:43,  1.04s/it, loss=0.7848, batch_acc=0.9062, running_acc=0.8146, grad=21.3413]Training epoch 15:  75%|███████▍  | 122/163 [02:16<00:40,  1.00it/s, loss=0.7848, batch_acc=0.9062, running_acc=0.8146, grad=21.3413]Training epoch 15:  75%|███████▍  | 122/163 [02:16<00:40,  1.00it/s, loss=0.7885, batch_acc=0.8438, running_acc=0.8148, grad=21.3941]Training epoch 15:  75%|███████▌  | 123/163 [02:18<00:52,  1.30s/it, loss=0.7885, batch_acc=0.8438, running_acc=0.8148, grad=21.3941]Training epoch 15:  75%|███████▌  | 123/163 [02:18<00:52,  1.30s/it, loss=1.3000, batch_acc=0.6875, running_acc=0.8138, grad=25.0347]Training epoch 15:  76%|███████▌  | 124/163 [02:18<00:45,  1.18s/it, loss=1.3000, batch_acc=0.6875, running_acc=0.8138, grad=25.0347]Training epoch 15:  76%|███████▌  | 124/163 [02:18<00:45,  1.18s/it, loss=0.8970, batch_acc=0.9062, running_acc=0.8145, grad=22.2009]Training epoch 15:  77%|███████▋  | 125/163 [02:19<00:41,  1.09s/it, loss=0.8970, batch_acc=0.9062, running_acc=0.8145, grad=22.2009]Training epoch 15:  77%|███████▋  | 125/163 [02:19<00:41,  1.09s/it, loss=0.9810, batch_acc=0.7500, running_acc=0.8140, grad=20.2731]Training epoch 15:  77%|███████▋  | 126/163 [02:20<00:37,  1.03s/it, loss=0.9810, batch_acc=0.7500, running_acc=0.8140, grad=20.2731]Training epoch 15:  77%|███████▋  | 126/163 [02:20<00:37,  1.03s/it, loss=0.8260, batch_acc=0.7812, running_acc=0.8137, grad=16.8201]Training epoch 15:  78%|███████▊  | 127/163 [02:22<00:45,  1.26s/it, loss=0.8260, batch_acc=0.7812, running_acc=0.8137, grad=16.8201]Training epoch 15:  78%|███████▊  | 127/163 [02:22<00:45,  1.26s/it, loss=0.9563, batch_acc=0.6250, running_acc=0.8123, grad=33.8201]Training epoch 15:  79%|███████▊  | 128/163 [02:23<00:40,  1.15s/it, loss=0.9563, batch_acc=0.6250, running_acc=0.8123, grad=33.8201]Training epoch 15:  79%|███████▊  | 128/163 [02:23<00:40,  1.15s/it, loss=1.1021, batch_acc=0.8125, running_acc=0.8123, grad=24.2795]Training epoch 15:  79%|███████▉  | 129/163 [02:24<00:36,  1.07s/it, loss=1.1021, batch_acc=0.8125, running_acc=0.8123, grad=24.2795]Training epoch 15:  79%|███████▉  | 129/163 [02:24<00:36,  1.07s/it, loss=0.6885, batch_acc=0.9688, running_acc=0.8135, grad=15.6767]Training epoch 15:  80%|███████▉  | 130/163 [02:25<00:33,  1.01s/it, loss=0.6885, batch_acc=0.9688, running_acc=0.8135, grad=15.6767]Training epoch 15:  80%|███████▉  | 130/163 [02:25<00:33,  1.01s/it, loss=0.9167, batch_acc=0.8438, running_acc=0.8137, grad=22.3593]Training epoch 15:  80%|████████  | 131/163 [02:27<00:40,  1.26s/it, loss=0.9167, batch_acc=0.8438, running_acc=0.8137, grad=22.3593]Training epoch 15:  80%|████████  | 131/163 [02:27<00:40,  1.26s/it, loss=0.8004, batch_acc=0.8438, running_acc=0.8139, grad=24.2219]Training epoch 15:  81%|████████  | 132/163 [02:27<00:35,  1.15s/it, loss=0.8004, batch_acc=0.8438, running_acc=0.8139, grad=24.2219]Training epoch 15:  81%|████████  | 132/163 [02:27<00:35,  1.15s/it, loss=0.9013, batch_acc=0.8125, running_acc=0.8139, grad=21.7286]Training epoch 15:  82%|████████▏ | 133/163 [02:28<00:32,  1.07s/it, loss=0.9013, batch_acc=0.8125, running_acc=0.8139, grad=21.7286]Training epoch 15:  82%|████████▏ | 133/163 [02:28<00:32,  1.07s/it, loss=1.0238, batch_acc=0.7500, running_acc=0.8134, grad=21.4901]Training epoch 15:  82%|████████▏ | 134/163 [02:29<00:29,  1.01s/it, loss=1.0238, batch_acc=0.7500, running_acc=0.8134, grad=21.4901]Training epoch 15:  82%|████████▏ | 134/163 [02:29<00:29,  1.01s/it, loss=0.7998, batch_acc=0.8750, running_acc=0.8139, grad=19.9522]Training epoch 15:  83%|████████▎ | 135/163 [02:31<00:36,  1.31s/it, loss=0.7998, batch_acc=0.8750, running_acc=0.8139, grad=19.9522]Training epoch 15:  83%|████████▎ | 135/163 [02:31<00:36,  1.31s/it, loss=1.1432, batch_acc=0.8438, running_acc=0.8141, grad=22.6512]Training epoch 15:  83%|████████▎ | 136/163 [02:32<00:31,  1.18s/it, loss=1.1432, batch_acc=0.8438, running_acc=0.8141, grad=22.6512]Training epoch 15:  83%|████████▎ | 136/163 [02:32<00:31,  1.18s/it, loss=1.0660, batch_acc=0.7500, running_acc=0.8136, grad=28.6399]Training epoch 15:  84%|████████▍ | 137/163 [02:33<00:28,  1.09s/it, loss=1.0660, batch_acc=0.7500, running_acc=0.8136, grad=28.6399]Training epoch 15:  84%|████████▍ | 137/163 [02:33<00:28,  1.09s/it, loss=0.8548, batch_acc=0.9062, running_acc=0.8143, grad=20.4802]Training epoch 15:  85%|████████▍ | 138/163 [02:34<00:25,  1.03s/it, loss=0.8548, batch_acc=0.9062, running_acc=0.8143, grad=20.4802]Training epoch 15:  85%|████████▍ | 138/163 [02:34<00:25,  1.03s/it, loss=1.1589, batch_acc=0.7188, running_acc=0.8136, grad=22.9790]Training epoch 15:  85%|████████▌ | 139/163 [02:36<00:32,  1.35s/it, loss=1.1589, batch_acc=0.7188, running_acc=0.8136, grad=22.9790]Training epoch 15:  85%|████████▌ | 139/163 [02:36<00:32,  1.35s/it, loss=1.1364, batch_acc=0.7188, running_acc=0.8129, grad=31.3919]Training epoch 15:  86%|████████▌ | 140/163 [02:37<00:27,  1.21s/it, loss=1.1364, batch_acc=0.7188, running_acc=0.8129, grad=31.3919]Training epoch 15:  86%|████████▌ | 140/163 [02:37<00:27,  1.21s/it, loss=0.7278, batch_acc=0.8125, running_acc=0.8129, grad=15.7369]Training epoch 15:  87%|████████▋ | 141/163 [02:38<00:24,  1.11s/it, loss=0.7278, batch_acc=0.8125, running_acc=0.8129, grad=15.7369]Training epoch 15:  87%|████████▋ | 141/163 [02:38<00:24,  1.11s/it, loss=1.0874, batch_acc=0.7812, running_acc=0.8127, grad=21.5421]Training epoch 15:  87%|████████▋ | 142/163 [02:39<00:21,  1.04s/it, loss=1.0874, batch_acc=0.7812, running_acc=0.8127, grad=21.5421]Training epoch 15:  87%|████████▋ | 142/163 [02:39<00:21,  1.04s/it, loss=0.9513, batch_acc=0.8438, running_acc=0.8129, grad=21.6491]Training epoch 15:  88%|████████▊ | 143/163 [02:40<00:24,  1.20s/it, loss=0.9513, batch_acc=0.8438, running_acc=0.8129, grad=21.6491]Training epoch 15:  88%|████████▊ | 143/163 [02:40<00:24,  1.20s/it, loss=0.7309, batch_acc=0.9062, running_acc=0.8136, grad=18.1472]Training epoch 15:  88%|████████▊ | 144/163 [02:41<00:21,  1.11s/it, loss=0.7309, batch_acc=0.9062, running_acc=0.8136, grad=18.1472]Training epoch 15:  88%|████████▊ | 144/163 [02:41<00:21,  1.11s/it, loss=1.3331, batch_acc=0.7500, running_acc=0.8132, grad=44.8550]Training epoch 15:  89%|████████▉ | 145/163 [02:42<00:18,  1.04s/it, loss=1.3331, batch_acc=0.7500, running_acc=0.8132, grad=44.8550]Training epoch 15:  89%|████████▉ | 145/163 [02:42<00:18,  1.04s/it, loss=1.0595, batch_acc=0.7500, running_acc=0.8127, grad=26.4320]Training epoch 15:  90%|████████▉ | 146/163 [02:43<00:16,  1.01it/s, loss=1.0595, batch_acc=0.7500, running_acc=0.8127, grad=26.4320]Training epoch 15:  90%|████████▉ | 146/163 [02:43<00:16,  1.01it/s, loss=0.9390, batch_acc=0.8125, running_acc=0.8127, grad=19.3675]Training epoch 15:  90%|█████████ | 147/163 [02:44<00:19,  1.21s/it, loss=0.9390, batch_acc=0.8125, running_acc=0.8127, grad=19.3675]Training epoch 15:  90%|█████████ | 147/163 [02:44<00:19,  1.21s/it, loss=0.7034, batch_acc=0.9062, running_acc=0.8134, grad=22.2274]Training epoch 15:  91%|█████████ | 148/163 [02:45<00:16,  1.11s/it, loss=0.7034, batch_acc=0.9062, running_acc=0.8134, grad=22.2274]Training epoch 15:  91%|█████████ | 148/163 [02:45<00:16,  1.11s/it, loss=0.9407, batch_acc=0.7812, running_acc=0.8131, grad=20.5824]Training epoch 15:  91%|█████████▏| 149/163 [02:46<00:14,  1.04s/it, loss=0.9407, batch_acc=0.7812, running_acc=0.8131, grad=20.5824]Training epoch 15:  91%|█████████▏| 149/163 [02:46<00:14,  1.04s/it, loss=1.0511, batch_acc=0.7500, running_acc=0.8127, grad=22.2005]Training epoch 15:  92%|█████████▏| 150/163 [02:47<00:12,  1.01it/s, loss=1.0511, batch_acc=0.7500, running_acc=0.8127, grad=22.2005]Training epoch 15:  92%|█████████▏| 150/163 [02:47<00:12,  1.01it/s, loss=0.9928, batch_acc=0.8125, running_acc=0.8127, grad=17.9756]Training epoch 15:  93%|█████████▎| 151/163 [02:49<00:15,  1.28s/it, loss=0.9928, batch_acc=0.8125, running_acc=0.8127, grad=17.9756]Training epoch 15:  93%|█████████▎| 151/163 [02:49<00:15,  1.28s/it, loss=1.2960, batch_acc=0.6875, running_acc=0.8119, grad=28.2071]Training epoch 15:  93%|█████████▎| 152/163 [02:50<00:12,  1.16s/it, loss=1.2960, batch_acc=0.6875, running_acc=0.8119, grad=28.2071]Training epoch 15:  93%|█████████▎| 152/163 [02:50<00:12,  1.16s/it, loss=0.8445, batch_acc=0.8750, running_acc=0.8123, grad=19.8430]Training epoch 15:  94%|█████████▍| 153/163 [02:51<00:10,  1.08s/it, loss=0.8445, batch_acc=0.8750, running_acc=0.8123, grad=19.8430]Training epoch 15:  94%|█████████▍| 153/163 [02:51<00:10,  1.08s/it, loss=0.9279, batch_acc=0.7812, running_acc=0.8121, grad=18.1090]Training epoch 15:  94%|█████████▍| 154/163 [02:52<00:09,  1.02s/it, loss=0.9279, batch_acc=0.7812, running_acc=0.8121, grad=18.1090]Training epoch 15:  94%|█████████▍| 154/163 [02:52<00:09,  1.02s/it, loss=0.8003, batch_acc=0.9062, running_acc=0.8127, grad=26.1269]Training epoch 15:  95%|█████████▌| 155/163 [02:53<00:08,  1.12s/it, loss=0.8003, batch_acc=0.9062, running_acc=0.8127, grad=26.1269]Training epoch 15:  95%|█████████▌| 155/163 [02:53<00:08,  1.12s/it, loss=0.8689, batch_acc=0.8750, running_acc=0.8131, grad=22.3271]Training epoch 15:  96%|█████████▌| 156/163 [02:54<00:07,  1.05s/it, loss=0.8689, batch_acc=0.8750, running_acc=0.8131, grad=22.3271]Training epoch 15:  96%|█████████▌| 156/163 [02:54<00:07,  1.05s/it, loss=0.8273, batch_acc=0.8125, running_acc=0.8131, grad=28.5971]Training epoch 15:  96%|█████████▋| 157/163 [02:55<00:05,  1.00it/s, loss=0.8273, batch_acc=0.8125, running_acc=0.8131, grad=28.5971]Training epoch 15:  96%|█████████▋| 157/163 [02:55<00:05,  1.00it/s, loss=0.9562, batch_acc=0.8125, running_acc=0.8131, grad=25.2646]Training epoch 15:  97%|█████████▋| 158/163 [02:56<00:04,  1.04it/s, loss=0.9562, batch_acc=0.8125, running_acc=0.8131, grad=25.2646]Training epoch 15:  97%|█████████▋| 158/163 [02:56<00:04,  1.04it/s, loss=0.9236, batch_acc=0.8125, running_acc=0.8131, grad=23.2317]Training epoch 15:  98%|█████████▊| 159/163 [02:57<00:03,  1.02it/s, loss=0.9236, batch_acc=0.8125, running_acc=0.8131, grad=23.2317]Training epoch 15:  98%|█████████▊| 159/163 [02:57<00:03,  1.02it/s, loss=1.0017, batch_acc=0.7812, running_acc=0.8129, grad=24.4827]Training epoch 15:  98%|█████████▊| 160/163 [02:58<00:02,  1.06it/s, loss=1.0017, batch_acc=0.7812, running_acc=0.8129, grad=24.4827]Training epoch 15:  98%|█████████▊| 160/163 [02:58<00:02,  1.06it/s, loss=0.8172, batch_acc=0.8750, running_acc=0.8133, grad=18.2832]Training epoch 15:  99%|█████████▉| 161/163 [02:58<00:01,  1.08it/s, loss=0.8172, batch_acc=0.8750, running_acc=0.8133, grad=18.2832]Training epoch 15:  99%|█████████▉| 161/163 [02:58<00:01,  1.08it/s, loss=0.8956, batch_acc=0.8438, running_acc=0.8135, grad=25.6712]Training epoch 15:  99%|█████████▉| 162/163 [02:59<00:00,  1.10it/s, loss=0.8956, batch_acc=0.8438, running_acc=0.8135, grad=25.6712]Training epoch 15:  99%|█████████▉| 162/163 [02:59<00:00,  1.10it/s, loss=1.1759, batch_acc=0.6875, running_acc=0.8127, grad=28.1826]Training epoch 15: 100%|██████████| 163/163 [03:00<00:00,  1.20it/s, loss=1.1759, batch_acc=0.6875, running_acc=0.8127, grad=28.1826]Training epoch 15: 100%|██████████| 163/163 [03:00<00:00,  1.20it/s, loss=0.8306, batch_acc=0.7619, running_acc=0.8125, grad=27.9729]Training epoch 15: 100%|██████████| 163/163 [03:00<00:00,  1.11s/it, loss=0.8306, batch_acc=0.7619, running_acc=0.8125, grad=27.9729]
Evaluation epoch 15:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 15:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it]Evaluation epoch 15:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it, loss=0.8555, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 15:   7%|▋         | 2/28 [00:05<00:59,  2.31s/it, loss=0.8555, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 15:   7%|▋         | 2/28 [00:05<00:59,  2.31s/it, loss=0.6377, batch_acc=0.9688, running_acc=0.8906]Evaluation epoch 15:  11%|█         | 3/28 [00:05<00:34,  1.37s/it, loss=0.6377, batch_acc=0.9688, running_acc=0.8906]Evaluation epoch 15:  11%|█         | 3/28 [00:05<00:34,  1.37s/it, loss=0.7937, batch_acc=0.8750, running_acc=0.8854]Evaluation epoch 15:  14%|█▍        | 4/28 [00:09<00:58,  2.42s/it, loss=0.7937, batch_acc=0.8750, running_acc=0.8854]Evaluation epoch 15:  14%|█▍        | 4/28 [00:09<00:58,  2.42s/it, loss=1.5905, batch_acc=0.5938, running_acc=0.8125]Evaluation epoch 15:  18%|█▊        | 5/28 [00:09<00:37,  1.64s/it, loss=1.5905, batch_acc=0.5938, running_acc=0.8125]Evaluation epoch 15:  18%|█▊        | 5/28 [00:09<00:37,  1.64s/it, loss=1.7191, batch_acc=0.5625, running_acc=0.7625]Evaluation epoch 15:  21%|██▏       | 6/28 [00:10<00:25,  1.17s/it, loss=1.7191, batch_acc=0.5625, running_acc=0.7625]Evaluation epoch 15:  21%|██▏       | 6/28 [00:10<00:25,  1.17s/it, loss=1.4816, batch_acc=0.7188, running_acc=0.7552]Evaluation epoch 15:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=1.4816, batch_acc=0.7188, running_acc=0.7552]Evaluation epoch 15:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=1.5129, batch_acc=0.6562, running_acc=0.7411]Evaluation epoch 15:  29%|██▊       | 8/28 [00:13<00:32,  1.62s/it, loss=1.5129, batch_acc=0.6562, running_acc=0.7411]Evaluation epoch 15:  29%|██▊       | 8/28 [00:13<00:32,  1.62s/it, loss=1.1410, batch_acc=0.7812, running_acc=0.7461]Evaluation epoch 15:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=1.1410, batch_acc=0.7812, running_acc=0.7461]Evaluation epoch 15:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=1.3428, batch_acc=0.7500, running_acc=0.7465]Evaluation epoch 15:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=1.3428, batch_acc=0.7500, running_acc=0.7465]Evaluation epoch 15:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.8069, batch_acc=0.9062, running_acc=0.7625]Evaluation epoch 15:  39%|███▉      | 11/28 [00:14<00:13,  1.27it/s, loss=0.8069, batch_acc=0.9062, running_acc=0.7625]Evaluation epoch 15:  39%|███▉      | 11/28 [00:14<00:13,  1.27it/s, loss=1.0824, batch_acc=0.7812, running_acc=0.7642]Evaluation epoch 15:  43%|████▎     | 12/28 [00:20<00:33,  2.11s/it, loss=1.0824, batch_acc=0.7812, running_acc=0.7642]Evaluation epoch 15:  43%|████▎     | 12/28 [00:20<00:33,  2.11s/it, loss=1.3324, batch_acc=0.6875, running_acc=0.7578]Evaluation epoch 15:  46%|████▋     | 13/28 [00:20<00:23,  1.55s/it, loss=1.3324, batch_acc=0.6875, running_acc=0.7578]Evaluation epoch 15:  46%|████▋     | 13/28 [00:20<00:23,  1.55s/it, loss=0.8786, batch_acc=0.8750, running_acc=0.7668]Evaluation epoch 15:  50%|█████     | 14/28 [00:20<00:16,  1.16s/it, loss=0.8786, batch_acc=0.8750, running_acc=0.7668]Evaluation epoch 15:  50%|█████     | 14/28 [00:20<00:16,  1.16s/it, loss=1.9550, batch_acc=0.5312, running_acc=0.7500]Evaluation epoch 15:  54%|█████▎    | 15/28 [00:20<00:11,  1.12it/s, loss=1.9550, batch_acc=0.5312, running_acc=0.7500]Evaluation epoch 15:  54%|█████▎    | 15/28 [00:20<00:11,  1.12it/s, loss=2.0089, batch_acc=0.4688, running_acc=0.7312]Evaluation epoch 15:  57%|█████▋    | 16/28 [00:23<00:17,  1.48s/it, loss=2.0089, batch_acc=0.4688, running_acc=0.7312]Evaluation epoch 15:  57%|█████▋    | 16/28 [00:23<00:17,  1.48s/it, loss=1.4676, batch_acc=0.4688, running_acc=0.7148]Evaluation epoch 15:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=1.4676, batch_acc=0.4688, running_acc=0.7148]Evaluation epoch 15:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=1.2885, batch_acc=0.6562, running_acc=0.7114]Evaluation epoch 15:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=1.2885, batch_acc=0.6562, running_acc=0.7114]Evaluation epoch 15:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.8581, batch_acc=0.8125, running_acc=0.7170]Evaluation epoch 15:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=0.8581, batch_acc=0.8125, running_acc=0.7170]Evaluation epoch 15:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=1.3899, batch_acc=0.5000, running_acc=0.7056]Evaluation epoch 15:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=1.3899, batch_acc=0.5000, running_acc=0.7056]Evaluation epoch 15:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=1.2281, batch_acc=0.6250, running_acc=0.7016]Evaluation epoch 15:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=1.2281, batch_acc=0.6250, running_acc=0.7016]Evaluation epoch 15:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=1.3407, batch_acc=0.7500, running_acc=0.7039]Evaluation epoch 15:  79%|███████▊  | 22/28 [00:27<00:04,  1.27it/s, loss=1.3407, batch_acc=0.7500, running_acc=0.7039]Evaluation epoch 15:  79%|███████▊  | 22/28 [00:27<00:04,  1.27it/s, loss=1.7361, batch_acc=0.5000, running_acc=0.6946]Evaluation epoch 15:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=1.7361, batch_acc=0.5000, running_acc=0.6946]Evaluation epoch 15:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=1.5364, batch_acc=0.5938, running_acc=0.6902]Evaluation epoch 15:  86%|████████▌ | 24/28 [00:33<00:08,  2.07s/it, loss=1.5364, batch_acc=0.5938, running_acc=0.6902]Evaluation epoch 15:  86%|████████▌ | 24/28 [00:33<00:08,  2.07s/it, loss=0.9214, batch_acc=0.9062, running_acc=0.6992]Evaluation epoch 15:  89%|████████▉ | 25/28 [00:33<00:04,  1.53s/it, loss=0.9214, batch_acc=0.9062, running_acc=0.6992]Evaluation epoch 15:  89%|████████▉ | 25/28 [00:33<00:04,  1.53s/it, loss=0.7329, batch_acc=0.8750, running_acc=0.7063]Evaluation epoch 15:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.7329, batch_acc=0.8750, running_acc=0.7063]Evaluation epoch 15:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.3731, batch_acc=0.6250, running_acc=0.7031]Evaluation epoch 15:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=1.3731, batch_acc=0.6250, running_acc=0.7031]Evaluation epoch 15:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=1.7460, batch_acc=0.4375, running_acc=0.6933]Evaluation epoch 15: 100%|██████████| 28/28 [00:34<00:00,  1.13it/s, loss=2.3420, batch_acc=0.3333, running_acc=0.6920]Evaluation epoch 15: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=2.3420, batch_acc=0.3333, running_acc=0.6920]
Training epoch 16:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 16:   1%|          | 1/163 [00:06<17:03,  6.32s/it]Training epoch 16:   1%|          | 1/163 [00:06<17:03,  6.32s/it, loss=0.8186, batch_acc=0.8438, running_acc=0.8438, grad=24.9413]Training epoch 16:   1%|          | 2/163 [00:07<08:22,  3.12s/it, loss=0.8186, batch_acc=0.8438, running_acc=0.8438, grad=24.9413]Training epoch 16:   1%|          | 2/163 [00:07<08:22,  3.12s/it, loss=0.8591, batch_acc=0.8438, running_acc=0.8438, grad=21.3315]Training epoch 16:   2%|▏         | 3/163 [00:08<05:35,  2.10s/it, loss=0.8591, batch_acc=0.8438, running_acc=0.8438, grad=21.3315]Training epoch 16:   2%|▏         | 3/163 [00:08<05:35,  2.10s/it, loss=0.7949, batch_acc=0.8438, running_acc=0.8438, grad=19.8066]Training epoch 16:   2%|▏         | 4/163 [00:11<06:35,  2.49s/it, loss=0.7949, batch_acc=0.8438, running_acc=0.8438, grad=19.8066]Training epoch 16:   2%|▏         | 4/163 [00:11<06:35,  2.49s/it, loss=0.7183, batch_acc=0.9375, running_acc=0.8672, grad=23.0058]Training epoch 16:   3%|▎         | 5/163 [00:12<05:01,  1.91s/it, loss=0.7183, batch_acc=0.9375, running_acc=0.8672, grad=23.0058]Training epoch 16:   3%|▎         | 5/163 [00:12<05:01,  1.91s/it, loss=0.8158, batch_acc=0.8438, running_acc=0.8625, grad=21.2801]Training epoch 16:   4%|▎         | 6/163 [00:12<04:04,  1.56s/it, loss=0.8158, batch_acc=0.8438, running_acc=0.8625, grad=21.2801]Training epoch 16:   4%|▎         | 6/163 [00:12<04:04,  1.56s/it, loss=0.9072, batch_acc=0.9062, running_acc=0.8698, grad=20.4215]Training epoch 16:   4%|▍         | 7/163 [00:13<03:28,  1.34s/it, loss=0.9072, batch_acc=0.9062, running_acc=0.8698, grad=20.4215]Training epoch 16:   4%|▍         | 7/163 [00:13<03:28,  1.34s/it, loss=0.9207, batch_acc=0.8438, running_acc=0.8661, grad=23.3529]Training epoch 16:   5%|▍         | 8/163 [00:15<03:27,  1.34s/it, loss=0.9207, batch_acc=0.8438, running_acc=0.8661, grad=23.3529]Training epoch 16:   5%|▍         | 8/163 [00:15<03:27,  1.34s/it, loss=0.8814, batch_acc=0.7812, running_acc=0.8555, grad=19.6976]Training epoch 16:   6%|▌         | 9/163 [00:16<03:03,  1.19s/it, loss=0.8814, batch_acc=0.7812, running_acc=0.8555, grad=19.6976]Training epoch 16:   6%|▌         | 9/163 [00:16<03:03,  1.19s/it, loss=1.0076, batch_acc=0.7812, running_acc=0.8472, grad=29.1812]Training epoch 16:   6%|▌         | 10/163 [00:16<02:48,  1.10s/it, loss=1.0076, batch_acc=0.7812, running_acc=0.8472, grad=29.1812]Training epoch 16:   6%|▌         | 10/163 [00:16<02:48,  1.10s/it, loss=0.8230, batch_acc=0.8750, running_acc=0.8500, grad=26.6118]Training epoch 16:   7%|▋         | 11/163 [00:17<02:36,  1.03s/it, loss=0.8230, batch_acc=0.8750, running_acc=0.8500, grad=26.6118]Training epoch 16:   7%|▋         | 11/163 [00:17<02:36,  1.03s/it, loss=0.8683, batch_acc=0.8438, running_acc=0.8494, grad=21.8289]Training epoch 16:   7%|▋         | 12/163 [00:19<03:09,  1.25s/it, loss=0.8683, batch_acc=0.8438, running_acc=0.8494, grad=21.8289]Training epoch 16:   7%|▋         | 12/163 [00:19<03:09,  1.25s/it, loss=1.0521, batch_acc=0.7812, running_acc=0.8438, grad=24.2080]Training epoch 16:   8%|▊         | 13/163 [00:20<02:51,  1.14s/it, loss=1.0521, batch_acc=0.7812, running_acc=0.8438, grad=24.2080]Training epoch 16:   8%|▊         | 13/163 [00:20<02:51,  1.14s/it, loss=0.8191, batch_acc=0.8125, running_acc=0.8413, grad=24.1839]Training epoch 16:   9%|▊         | 14/163 [00:21<02:38,  1.06s/it, loss=0.8191, batch_acc=0.8125, running_acc=0.8413, grad=24.1839]Training epoch 16:   9%|▊         | 14/163 [00:21<02:38,  1.06s/it, loss=1.0343, batch_acc=0.8750, running_acc=0.8438, grad=21.4238]Training epoch 16:   9%|▉         | 15/163 [00:22<02:28,  1.01s/it, loss=1.0343, batch_acc=0.8750, running_acc=0.8438, grad=21.4238]Training epoch 16:   9%|▉         | 15/163 [00:22<02:28,  1.01s/it, loss=0.8518, batch_acc=0.8750, running_acc=0.8458, grad=25.1626]Training epoch 16:  10%|▉         | 16/163 [00:23<02:44,  1.12s/it, loss=0.8518, batch_acc=0.8750, running_acc=0.8458, grad=25.1626]Training epoch 16:  10%|▉         | 16/163 [00:23<02:44,  1.12s/it, loss=0.7998, batch_acc=0.8438, running_acc=0.8457, grad=20.4831]Training epoch 16:  10%|█         | 17/163 [00:24<02:32,  1.05s/it, loss=0.7998, batch_acc=0.8438, running_acc=0.8457, grad=20.4831]Training epoch 16:  10%|█         | 17/163 [00:24<02:32,  1.05s/it, loss=0.7444, batch_acc=0.8438, running_acc=0.8456, grad=30.8043]Training epoch 16:  11%|█         | 18/163 [00:25<02:24,  1.00it/s, loss=0.7444, batch_acc=0.8438, running_acc=0.8456, grad=30.8043]Training epoch 16:  11%|█         | 18/163 [00:25<02:24,  1.00it/s, loss=0.8212, batch_acc=0.9062, running_acc=0.8490, grad=20.1197]Training epoch 16:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.8212, batch_acc=0.9062, running_acc=0.8490, grad=20.1197]Training epoch 16:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.8379, batch_acc=0.8750, running_acc=0.8503, grad=20.6817]Training epoch 16:  12%|█▏        | 20/163 [00:28<02:56,  1.23s/it, loss=0.8379, batch_acc=0.8750, running_acc=0.8503, grad=20.6817]Training epoch 16:  12%|█▏        | 20/163 [00:28<02:56,  1.23s/it, loss=0.9584, batch_acc=0.7812, running_acc=0.8469, grad=23.7086]Training epoch 16:  13%|█▎        | 21/163 [00:28<02:39,  1.13s/it, loss=0.9584, batch_acc=0.7812, running_acc=0.8469, grad=23.7086]Training epoch 16:  13%|█▎        | 21/163 [00:28<02:39,  1.13s/it, loss=0.8843, batch_acc=0.8438, running_acc=0.8467, grad=23.6838]Training epoch 16:  13%|█▎        | 22/163 [00:29<02:28,  1.05s/it, loss=0.8843, batch_acc=0.8438, running_acc=0.8467, grad=23.6838]Training epoch 16:  13%|█▎        | 22/163 [00:29<02:28,  1.05s/it, loss=1.0374, batch_acc=0.8125, running_acc=0.8452, grad=27.7792]Training epoch 16:  14%|█▍        | 23/163 [00:30<02:20,  1.00s/it, loss=1.0374, batch_acc=0.8125, running_acc=0.8452, grad=27.7792]Training epoch 16:  14%|█▍        | 23/163 [00:30<02:20,  1.00s/it, loss=0.9618, batch_acc=0.7812, running_acc=0.8424, grad=26.5384]Training epoch 16:  15%|█▍        | 24/163 [00:32<03:08,  1.36s/it, loss=0.9618, batch_acc=0.7812, running_acc=0.8424, grad=26.5384]Training epoch 16:  15%|█▍        | 24/163 [00:32<03:08,  1.36s/it, loss=0.8745, batch_acc=0.8125, running_acc=0.8411, grad=24.9493]Training epoch 16:  15%|█▌        | 25/163 [00:33<02:47,  1.21s/it, loss=0.8745, batch_acc=0.8125, running_acc=0.8411, grad=24.9493]Training epoch 16:  15%|█▌        | 25/163 [00:33<02:47,  1.21s/it, loss=0.9095, batch_acc=0.8750, running_acc=0.8425, grad=23.8089]Training epoch 16:  16%|█▌        | 26/163 [00:34<02:32,  1.11s/it, loss=0.9095, batch_acc=0.8750, running_acc=0.8425, grad=23.8089]Training epoch 16:  16%|█▌        | 26/163 [00:34<02:32,  1.11s/it, loss=0.9277, batch_acc=0.8438, running_acc=0.8425, grad=25.3224]Training epoch 16:  17%|█▋        | 27/163 [00:35<02:21,  1.04s/it, loss=0.9277, batch_acc=0.8438, running_acc=0.8425, grad=25.3224]Training epoch 16:  17%|█▋        | 27/163 [00:35<02:21,  1.04s/it, loss=0.8411, batch_acc=0.8125, running_acc=0.8414, grad=20.2972]Training epoch 16:  17%|█▋        | 28/163 [00:36<02:30,  1.11s/it, loss=0.8411, batch_acc=0.8125, running_acc=0.8414, grad=20.2972]Training epoch 16:  17%|█▋        | 28/163 [00:36<02:30,  1.11s/it, loss=1.0022, batch_acc=0.8438, running_acc=0.8415, grad=30.4956]Training epoch 16:  18%|█▊        | 29/163 [00:37<02:19,  1.04s/it, loss=1.0022, batch_acc=0.8438, running_acc=0.8415, grad=30.4956]Training epoch 16:  18%|█▊        | 29/163 [00:37<02:19,  1.04s/it, loss=0.7203, batch_acc=0.8438, running_acc=0.8416, grad=19.4213]Training epoch 16:  18%|█▊        | 30/163 [00:38<02:12,  1.01it/s, loss=0.7203, batch_acc=0.8438, running_acc=0.8416, grad=19.4213]Training epoch 16:  18%|█▊        | 30/163 [00:38<02:12,  1.01it/s, loss=0.8702, batch_acc=0.6875, running_acc=0.8365, grad=25.7939]Training epoch 16:  19%|█▉        | 31/163 [00:39<02:08,  1.03it/s, loss=0.8702, batch_acc=0.6875, running_acc=0.8365, grad=25.7939]Training epoch 16:  19%|█▉        | 31/163 [00:39<02:08,  1.03it/s, loss=0.8860, batch_acc=0.8750, running_acc=0.8377, grad=22.7484]Training epoch 16:  20%|█▉        | 32/163 [00:41<02:39,  1.21s/it, loss=0.8860, batch_acc=0.8750, running_acc=0.8377, grad=22.7484]Training epoch 16:  20%|█▉        | 32/163 [00:41<02:39,  1.21s/it, loss=0.7403, batch_acc=0.9375, running_acc=0.8408, grad=21.8240]Training epoch 16:  20%|██        | 33/163 [00:42<02:24,  1.11s/it, loss=0.7403, batch_acc=0.9375, running_acc=0.8408, grad=21.8240]Training epoch 16:  20%|██        | 33/163 [00:42<02:24,  1.11s/it, loss=0.7843, batch_acc=0.9062, running_acc=0.8428, grad=23.3038]Training epoch 16:  21%|██        | 34/163 [00:43<02:14,  1.04s/it, loss=0.7843, batch_acc=0.9062, running_acc=0.8428, grad=23.3038]Training epoch 16:  21%|██        | 34/163 [00:43<02:14,  1.04s/it, loss=0.9616, batch_acc=0.7812, running_acc=0.8410, grad=24.4765]Training epoch 16:  21%|██▏       | 35/163 [00:43<02:07,  1.01it/s, loss=0.9616, batch_acc=0.7812, running_acc=0.8410, grad=24.4765]Training epoch 16:  21%|██▏       | 35/163 [00:43<02:07,  1.01it/s, loss=0.7815, batch_acc=0.8750, running_acc=0.8420, grad=21.6817]Training epoch 16:  22%|██▏       | 36/163 [00:46<02:53,  1.37s/it, loss=0.7815, batch_acc=0.8750, running_acc=0.8420, grad=21.6817]Training epoch 16:  22%|██▏       | 36/163 [00:46<02:53,  1.37s/it, loss=0.7325, batch_acc=0.9688, running_acc=0.8455, grad=20.4819]Training epoch 16:  23%|██▎       | 37/163 [00:47<02:33,  1.22s/it, loss=0.7325, batch_acc=0.9688, running_acc=0.8455, grad=20.4819]Training epoch 16:  23%|██▎       | 37/163 [00:47<02:33,  1.22s/it, loss=1.0398, batch_acc=0.7500, running_acc=0.8429, grad=27.0436]Training epoch 16:  23%|██▎       | 38/163 [00:47<02:19,  1.12s/it, loss=1.0398, batch_acc=0.7500, running_acc=0.8429, grad=27.0436]Training epoch 16:  23%|██▎       | 38/163 [00:47<02:19,  1.12s/it, loss=0.7291, batch_acc=0.9062, running_acc=0.8446, grad=17.6174]Training epoch 16:  24%|██▍       | 39/163 [00:48<02:09,  1.05s/it, loss=0.7291, batch_acc=0.9062, running_acc=0.8446, grad=17.6174]Training epoch 16:  24%|██▍       | 39/163 [00:48<02:09,  1.05s/it, loss=0.7381, batch_acc=0.9062, running_acc=0.8462, grad=19.1707]Training epoch 16:  25%|██▍       | 40/163 [00:50<02:32,  1.24s/it, loss=0.7381, batch_acc=0.9062, running_acc=0.8462, grad=19.1707]Training epoch 16:  25%|██▍       | 40/163 [00:50<02:32,  1.24s/it, loss=1.0352, batch_acc=0.6250, running_acc=0.8406, grad=21.4952]Training epoch 16:  25%|██▌       | 41/163 [00:51<02:18,  1.13s/it, loss=1.0352, batch_acc=0.6250, running_acc=0.8406, grad=21.4952]Training epoch 16:  25%|██▌       | 41/163 [00:51<02:18,  1.13s/it, loss=0.9360, batch_acc=0.9375, running_acc=0.8430, grad=24.6648]Training epoch 16:  26%|██▌       | 42/163 [00:52<02:08,  1.06s/it, loss=0.9360, batch_acc=0.9375, running_acc=0.8430, grad=24.6648]Training epoch 16:  26%|██▌       | 42/163 [00:52<02:08,  1.06s/it, loss=0.7864, batch_acc=0.8438, running_acc=0.8430, grad=24.6793]Training epoch 16:  26%|██▋       | 43/163 [00:53<02:00,  1.00s/it, loss=0.7864, batch_acc=0.8438, running_acc=0.8430, grad=24.6793]Training epoch 16:  26%|██▋       | 43/163 [00:53<02:00,  1.00s/it, loss=0.7767, batch_acc=0.9375, running_acc=0.8452, grad=18.7756]Training epoch 16:  27%|██▋       | 44/163 [00:54<02:19,  1.17s/it, loss=0.7767, batch_acc=0.9375, running_acc=0.8452, grad=18.7756]Training epoch 16:  27%|██▋       | 44/163 [00:54<02:19,  1.17s/it, loss=1.2579, batch_acc=0.6562, running_acc=0.8409, grad=27.6292]Training epoch 16:  28%|██▊       | 45/163 [00:55<02:07,  1.08s/it, loss=1.2579, batch_acc=0.6562, running_acc=0.8409, grad=27.6292]Training epoch 16:  28%|██▊       | 45/163 [00:55<02:07,  1.08s/it, loss=0.9047, batch_acc=0.7812, running_acc=0.8396, grad=25.2745]Training epoch 16:  28%|██▊       | 46/163 [00:56<01:59,  1.02s/it, loss=0.9047, batch_acc=0.7812, running_acc=0.8396, grad=25.2745]Training epoch 16:  28%|██▊       | 46/163 [00:56<01:59,  1.02s/it, loss=0.6474, batch_acc=1.0000, running_acc=0.8431, grad=20.6193]Training epoch 16:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.6474, batch_acc=1.0000, running_acc=0.8431, grad=20.6193]Training epoch 16:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.8037, batch_acc=0.8750, running_acc=0.8438, grad=21.0791]Training epoch 16:  29%|██▉       | 48/163 [00:59<02:21,  1.23s/it, loss=0.8037, batch_acc=0.8750, running_acc=0.8438, grad=21.0791]Training epoch 16:  29%|██▉       | 48/163 [00:59<02:21,  1.23s/it, loss=0.8090, batch_acc=0.8750, running_acc=0.8444, grad=19.6000]Training epoch 16:  30%|███       | 49/163 [01:00<02:08,  1.13s/it, loss=0.8090, batch_acc=0.8750, running_acc=0.8444, grad=19.6000]Training epoch 16:  30%|███       | 49/163 [01:00<02:08,  1.13s/it, loss=0.7589, batch_acc=0.9062, running_acc=0.8457, grad=22.3279]Training epoch 16:  31%|███       | 50/163 [01:00<01:59,  1.05s/it, loss=0.7589, batch_acc=0.9062, running_acc=0.8457, grad=22.3279]Training epoch 16:  31%|███       | 50/163 [01:00<01:59,  1.05s/it, loss=1.0201, batch_acc=0.7500, running_acc=0.8438, grad=21.4054]Training epoch 16:  31%|███▏      | 51/163 [01:01<01:52,  1.00s/it, loss=1.0201, batch_acc=0.7500, running_acc=0.8438, grad=21.4054]Training epoch 16:  31%|███▏      | 51/163 [01:01<01:52,  1.00s/it, loss=0.9039, batch_acc=0.8125, running_acc=0.8431, grad=22.8112]Training epoch 16:  32%|███▏      | 52/163 [01:03<02:26,  1.32s/it, loss=0.9039, batch_acc=0.8125, running_acc=0.8431, grad=22.8112]Training epoch 16:  32%|███▏      | 52/163 [01:03<02:26,  1.32s/it, loss=1.0620, batch_acc=0.8438, running_acc=0.8431, grad=33.3871]Training epoch 16:  33%|███▎      | 53/163 [01:04<02:10,  1.19s/it, loss=1.0620, batch_acc=0.8438, running_acc=0.8431, grad=33.3871]Training epoch 16:  33%|███▎      | 53/163 [01:04<02:10,  1.19s/it, loss=0.7761, batch_acc=0.8750, running_acc=0.8438, grad=23.5206]Training epoch 16:  33%|███▎      | 54/163 [01:05<01:59,  1.10s/it, loss=0.7761, batch_acc=0.8750, running_acc=0.8438, grad=23.5206]Training epoch 16:  33%|███▎      | 54/163 [01:05<01:59,  1.10s/it, loss=1.1976, batch_acc=0.7188, running_acc=0.8414, grad=27.3827]Training epoch 16:  34%|███▎      | 55/163 [01:06<01:51,  1.03s/it, loss=1.1976, batch_acc=0.7188, running_acc=0.8414, grad=27.3827]Training epoch 16:  34%|███▎      | 55/163 [01:06<01:51,  1.03s/it, loss=0.9311, batch_acc=0.8125, running_acc=0.8409, grad=28.3602]Training epoch 16:  34%|███▍      | 56/163 [01:08<02:16,  1.27s/it, loss=0.9311, batch_acc=0.8125, running_acc=0.8409, grad=28.3602]Training epoch 16:  34%|███▍      | 56/163 [01:08<02:16,  1.27s/it, loss=0.9515, batch_acc=0.8438, running_acc=0.8410, grad=24.9705]Training epoch 16:  35%|███▍      | 57/163 [01:09<02:02,  1.15s/it, loss=0.9515, batch_acc=0.8438, running_acc=0.8410, grad=24.9705]Training epoch 16:  35%|███▍      | 57/163 [01:09<02:02,  1.15s/it, loss=0.9793, batch_acc=0.8438, running_acc=0.8410, grad=22.1916]Training epoch 16:  36%|███▌      | 58/163 [01:10<01:52,  1.07s/it, loss=0.9793, batch_acc=0.8438, running_acc=0.8410, grad=22.1916]Training epoch 16:  36%|███▌      | 58/163 [01:10<01:52,  1.07s/it, loss=0.8004, batch_acc=0.8438, running_acc=0.8411, grad=19.6149]Training epoch 16:  36%|███▌      | 59/163 [01:10<01:45,  1.01s/it, loss=0.8004, batch_acc=0.8438, running_acc=0.8411, grad=19.6149]Training epoch 16:  36%|███▌      | 59/163 [01:10<01:45,  1.01s/it, loss=0.9012, batch_acc=0.8125, running_acc=0.8406, grad=22.3491]Training epoch 16:  37%|███▋      | 60/163 [01:13<02:25,  1.41s/it, loss=0.9012, batch_acc=0.8125, running_acc=0.8406, grad=22.3491]Training epoch 16:  37%|███▋      | 60/163 [01:13<02:25,  1.41s/it, loss=0.7790, batch_acc=0.8750, running_acc=0.8411, grad=24.9627]Training epoch 16:  37%|███▋      | 61/163 [01:14<02:07,  1.25s/it, loss=0.7790, batch_acc=0.8750, running_acc=0.8411, grad=24.9627]Training epoch 16:  37%|███▋      | 61/163 [01:14<02:07,  1.25s/it, loss=1.1509, batch_acc=0.7812, running_acc=0.8402, grad=36.2690]Training epoch 16:  38%|███▊      | 62/163 [01:15<01:55,  1.14s/it, loss=1.1509, batch_acc=0.7812, running_acc=0.8402, grad=36.2690]Training epoch 16:  38%|███▊      | 62/163 [01:15<01:55,  1.14s/it, loss=0.9783, batch_acc=0.8125, running_acc=0.8397, grad=23.7076]Training epoch 16:  39%|███▊      | 63/163 [01:15<01:45,  1.06s/it, loss=0.9783, batch_acc=0.8125, running_acc=0.8397, grad=23.7076]Training epoch 16:  39%|███▊      | 63/163 [01:15<01:45,  1.06s/it, loss=0.9606, batch_acc=0.7812, running_acc=0.8388, grad=33.9991]Training epoch 16:  39%|███▉      | 64/163 [01:17<02:11,  1.33s/it, loss=0.9606, batch_acc=0.7812, running_acc=0.8388, grad=33.9991]Training epoch 16:  39%|███▉      | 64/163 [01:17<02:11,  1.33s/it, loss=0.9426, batch_acc=0.7812, running_acc=0.8379, grad=25.4000]Training epoch 16:  40%|███▉      | 65/163 [01:18<01:56,  1.19s/it, loss=0.9426, batch_acc=0.7812, running_acc=0.8379, grad=25.4000]Training epoch 16:  40%|███▉      | 65/163 [01:18<01:56,  1.19s/it, loss=1.0539, batch_acc=0.7812, running_acc=0.8370, grad=26.0276]Training epoch 16:  40%|████      | 66/163 [01:19<01:46,  1.10s/it, loss=1.0539, batch_acc=0.7812, running_acc=0.8370, grad=26.0276]Training epoch 16:  40%|████      | 66/163 [01:19<01:46,  1.10s/it, loss=0.8487, batch_acc=0.9375, running_acc=0.8385, grad=23.1250]Training epoch 16:  41%|████      | 67/163 [01:20<01:39,  1.03s/it, loss=0.8487, batch_acc=0.9375, running_acc=0.8385, grad=23.1250]Training epoch 16:  41%|████      | 67/163 [01:20<01:39,  1.03s/it, loss=0.7281, batch_acc=0.9062, running_acc=0.8396, grad=17.1792]Training epoch 16:  42%|████▏     | 68/163 [01:22<01:52,  1.18s/it, loss=0.7281, batch_acc=0.9062, running_acc=0.8396, grad=17.1792]Training epoch 16:  42%|████▏     | 68/163 [01:22<01:52,  1.18s/it, loss=1.0832, batch_acc=0.7812, running_acc=0.8387, grad=30.7047]Training epoch 16:  42%|████▏     | 69/163 [01:22<01:42,  1.09s/it, loss=1.0832, batch_acc=0.7812, running_acc=0.8387, grad=30.7047]Training epoch 16:  42%|████▏     | 69/163 [01:22<01:42,  1.09s/it, loss=1.1386, batch_acc=0.7812, running_acc=0.8379, grad=29.2206]Training epoch 16:  43%|████▎     | 70/163 [01:23<01:35,  1.03s/it, loss=1.1386, batch_acc=0.7812, running_acc=0.8379, grad=29.2206]Training epoch 16:  43%|████▎     | 70/163 [01:23<01:35,  1.03s/it, loss=0.7034, batch_acc=0.9062, running_acc=0.8388, grad=24.8712]Training epoch 16:  44%|████▎     | 71/163 [01:24<01:30,  1.02it/s, loss=0.7034, batch_acc=0.9062, running_acc=0.8388, grad=24.8712]Training epoch 16:  44%|████▎     | 71/163 [01:24<01:30,  1.02it/s, loss=0.6102, batch_acc=0.9375, running_acc=0.8402, grad=20.1174]Training epoch 16:  44%|████▍     | 72/163 [01:26<01:40,  1.11s/it, loss=0.6102, batch_acc=0.9375, running_acc=0.8402, grad=20.1174]Training epoch 16:  44%|████▍     | 72/163 [01:26<01:40,  1.11s/it, loss=0.9503, batch_acc=0.7812, running_acc=0.8394, grad=22.1431]Training epoch 16:  45%|████▍     | 73/163 [01:26<01:33,  1.04s/it, loss=0.9503, batch_acc=0.7812, running_acc=0.8394, grad=22.1431]Training epoch 16:  45%|████▍     | 73/163 [01:26<01:33,  1.04s/it, loss=0.8391, batch_acc=0.9062, running_acc=0.8403, grad=27.2470]Training epoch 16:  45%|████▌     | 74/163 [01:27<01:28,  1.01it/s, loss=0.8391, batch_acc=0.9062, running_acc=0.8403, grad=27.2470]Training epoch 16:  45%|████▌     | 74/163 [01:27<01:28,  1.01it/s, loss=0.5997, batch_acc=0.9375, running_acc=0.8416, grad=22.3689]Training epoch 16:  46%|████▌     | 75/163 [01:28<01:24,  1.05it/s, loss=0.5997, batch_acc=0.9375, running_acc=0.8416, grad=22.3689]Training epoch 16:  46%|████▌     | 75/163 [01:28<01:24,  1.05it/s, loss=0.8252, batch_acc=0.8750, running_acc=0.8421, grad=23.3988]Training epoch 16:  47%|████▋     | 76/163 [01:30<01:44,  1.21s/it, loss=0.8252, batch_acc=0.8750, running_acc=0.8421, grad=23.3988]Training epoch 16:  47%|████▋     | 76/163 [01:30<01:44,  1.21s/it, loss=0.9709, batch_acc=0.8438, running_acc=0.8421, grad=24.8129]Training epoch 16:  47%|████▋     | 77/163 [01:31<01:35,  1.11s/it, loss=0.9709, batch_acc=0.8438, running_acc=0.8421, grad=24.8129]Training epoch 16:  47%|████▋     | 77/163 [01:31<01:35,  1.11s/it, loss=0.9916, batch_acc=0.8125, running_acc=0.8417, grad=31.1446]Training epoch 16:  48%|████▊     | 78/163 [01:32<01:28,  1.04s/it, loss=0.9916, batch_acc=0.8125, running_acc=0.8417, grad=31.1446]Training epoch 16:  48%|████▊     | 78/163 [01:32<01:28,  1.04s/it, loss=0.9896, batch_acc=0.8438, running_acc=0.8417, grad=19.5794]Training epoch 16:  48%|████▊     | 79/163 [01:33<01:23,  1.01it/s, loss=0.9896, batch_acc=0.8438, running_acc=0.8417, grad=19.5794]Training epoch 16:  48%|████▊     | 79/163 [01:33<01:23,  1.01it/s, loss=0.8198, batch_acc=0.8750, running_acc=0.8422, grad=23.2148]Training epoch 16:  49%|████▉     | 80/163 [01:34<01:35,  1.15s/it, loss=0.8198, batch_acc=0.8750, running_acc=0.8422, grad=23.2148]Training epoch 16:  49%|████▉     | 80/163 [01:34<01:35,  1.15s/it, loss=0.8929, batch_acc=0.8125, running_acc=0.8418, grad=29.2199]Training epoch 16:  50%|████▉     | 81/163 [01:35<01:27,  1.07s/it, loss=0.8929, batch_acc=0.8125, running_acc=0.8418, grad=29.2199]Training epoch 16:  50%|████▉     | 81/163 [01:35<01:27,  1.07s/it, loss=0.9882, batch_acc=0.8125, running_acc=0.8414, grad=29.9665]Training epoch 16:  50%|█████     | 82/163 [01:36<01:21,  1.01s/it, loss=0.9882, batch_acc=0.8125, running_acc=0.8414, grad=29.9665]Training epoch 16:  50%|█████     | 82/163 [01:36<01:21,  1.01s/it, loss=0.8200, batch_acc=0.8125, running_acc=0.8411, grad=27.7662]Training epoch 16:  51%|█████     | 83/163 [01:37<01:17,  1.03it/s, loss=0.8200, batch_acc=0.8125, running_acc=0.8411, grad=27.7662]Training epoch 16:  51%|█████     | 83/163 [01:37<01:17,  1.03it/s, loss=0.9625, batch_acc=0.8750, running_acc=0.8415, grad=29.1425]Training epoch 16:  52%|█████▏    | 84/163 [01:38<01:29,  1.13s/it, loss=0.9625, batch_acc=0.8750, running_acc=0.8415, grad=29.1425]Training epoch 16:  52%|█████▏    | 84/163 [01:38<01:29,  1.13s/it, loss=0.7629, batch_acc=0.8750, running_acc=0.8419, grad=21.1325]Training epoch 16:  52%|█████▏    | 85/163 [01:39<01:22,  1.05s/it, loss=0.7629, batch_acc=0.8750, running_acc=0.8419, grad=21.1325]Training epoch 16:  52%|█████▏    | 85/163 [01:39<01:22,  1.05s/it, loss=1.0390, batch_acc=0.8125, running_acc=0.8415, grad=23.6830]Training epoch 16:  53%|█████▎    | 86/163 [01:40<01:17,  1.00s/it, loss=1.0390, batch_acc=0.8125, running_acc=0.8415, grad=23.6830]Training epoch 16:  53%|█████▎    | 86/163 [01:40<01:17,  1.00s/it, loss=1.0075, batch_acc=0.8438, running_acc=0.8416, grad=28.5556]Training epoch 16:  53%|█████▎    | 87/163 [01:41<01:13,  1.04it/s, loss=1.0075, batch_acc=0.8438, running_acc=0.8416, grad=28.5556]Training epoch 16:  53%|█████▎    | 87/163 [01:41<01:13,  1.04it/s, loss=0.9962, batch_acc=0.7812, running_acc=0.8409, grad=27.3402]Training epoch 16:  54%|█████▍    | 88/163 [01:42<01:23,  1.11s/it, loss=0.9962, batch_acc=0.7812, running_acc=0.8409, grad=27.3402]Training epoch 16:  54%|█████▍    | 88/163 [01:42<01:23,  1.11s/it, loss=0.6099, batch_acc=0.9688, running_acc=0.8423, grad=24.0287]Training epoch 16:  55%|█████▍    | 89/163 [01:43<01:17,  1.04s/it, loss=0.6099, batch_acc=0.9688, running_acc=0.8423, grad=24.0287]Training epoch 16:  55%|█████▍    | 89/163 [01:43<01:17,  1.04s/it, loss=1.0823, batch_acc=0.7188, running_acc=0.8409, grad=28.8490]Training epoch 16:  55%|█████▌    | 90/163 [01:44<01:12,  1.01it/s, loss=1.0823, batch_acc=0.7188, running_acc=0.8409, grad=28.8490]Training epoch 16:  55%|█████▌    | 90/163 [01:44<01:12,  1.01it/s, loss=1.1586, batch_acc=0.8125, running_acc=0.8406, grad=28.5018]Training epoch 16:  56%|█████▌    | 91/163 [01:45<01:08,  1.04it/s, loss=1.1586, batch_acc=0.8125, running_acc=0.8406, grad=28.5018]Training epoch 16:  56%|█████▌    | 91/163 [01:45<01:08,  1.04it/s, loss=0.6812, batch_acc=0.9375, running_acc=0.8417, grad=16.3364]Training epoch 16:  56%|█████▋    | 92/163 [01:47<01:28,  1.25s/it, loss=0.6812, batch_acc=0.9375, running_acc=0.8417, grad=16.3364]Training epoch 16:  56%|█████▋    | 92/163 [01:47<01:28,  1.25s/it, loss=0.7499, batch_acc=0.8438, running_acc=0.8417, grad=19.0659]Training epoch 16:  57%|█████▋    | 93/163 [01:48<01:19,  1.14s/it, loss=0.7499, batch_acc=0.8438, running_acc=0.8417, grad=19.0659]Training epoch 16:  57%|█████▋    | 93/163 [01:48<01:19,  1.14s/it, loss=0.7969, batch_acc=0.9062, running_acc=0.8424, grad=20.4928]Training epoch 16:  58%|█████▊    | 94/163 [01:49<01:13,  1.06s/it, loss=0.7969, batch_acc=0.9062, running_acc=0.8424, grad=20.4928]Training epoch 16:  58%|█████▊    | 94/163 [01:49<01:13,  1.06s/it, loss=0.7445, batch_acc=0.8750, running_acc=0.8428, grad=18.3925]Training epoch 16:  58%|█████▊    | 95/163 [01:50<01:08,  1.01s/it, loss=0.7445, batch_acc=0.8750, running_acc=0.8428, grad=18.3925]Training epoch 16:  58%|█████▊    | 95/163 [01:50<01:08,  1.01s/it, loss=0.7480, batch_acc=0.8438, running_acc=0.8428, grad=27.0518]Training epoch 16:  59%|█████▉    | 96/163 [01:52<01:25,  1.28s/it, loss=0.7480, batch_acc=0.8438, running_acc=0.8428, grad=27.0518]Training epoch 16:  59%|█████▉    | 96/163 [01:52<01:25,  1.28s/it, loss=0.6210, batch_acc=0.8750, running_acc=0.8431, grad=20.5058]Training epoch 16:  60%|█████▉    | 97/163 [01:52<01:16,  1.16s/it, loss=0.6210, batch_acc=0.8750, running_acc=0.8431, grad=20.5058]Training epoch 16:  60%|█████▉    | 97/163 [01:52<01:16,  1.16s/it, loss=0.8308, batch_acc=0.7812, running_acc=0.8425, grad=22.5876]Training epoch 16:  60%|██████    | 98/163 [01:53<01:09,  1.08s/it, loss=0.8308, batch_acc=0.7812, running_acc=0.8425, grad=22.5876]Training epoch 16:  60%|██████    | 98/163 [01:53<01:09,  1.08s/it, loss=0.7301, batch_acc=0.8438, running_acc=0.8425, grad=26.6965]Training epoch 16:  61%|██████    | 99/163 [01:54<01:05,  1.02s/it, loss=0.7301, batch_acc=0.8438, running_acc=0.8425, grad=26.6965]Training epoch 16:  61%|██████    | 99/163 [01:54<01:05,  1.02s/it, loss=0.9168, batch_acc=0.8438, running_acc=0.8425, grad=29.9869]Training epoch 16:  61%|██████▏   | 100/163 [01:56<01:12,  1.15s/it, loss=0.9168, batch_acc=0.8438, running_acc=0.8425, grad=29.9869]Training epoch 16:  61%|██████▏   | 100/163 [01:56<01:12,  1.15s/it, loss=0.7895, batch_acc=0.8438, running_acc=0.8425, grad=20.1859]Training epoch 16:  62%|██████▏   | 101/163 [01:57<01:06,  1.07s/it, loss=0.7895, batch_acc=0.8438, running_acc=0.8425, grad=20.1859]Training epoch 16:  62%|██████▏   | 101/163 [01:57<01:06,  1.07s/it, loss=0.8619, batch_acc=0.8438, running_acc=0.8425, grad=29.5891]Training epoch 16:  63%|██████▎   | 102/163 [01:57<01:01,  1.01s/it, loss=0.8619, batch_acc=0.8438, running_acc=0.8425, grad=29.5891]Training epoch 16:  63%|██████▎   | 102/163 [01:57<01:01,  1.01s/it, loss=0.8231, batch_acc=0.8438, running_acc=0.8425, grad=24.6834]Training epoch 16:  63%|██████▎   | 103/163 [01:58<00:58,  1.03it/s, loss=0.8231, batch_acc=0.8438, running_acc=0.8425, grad=24.6834]Training epoch 16:  63%|██████▎   | 103/163 [01:58<00:58,  1.03it/s, loss=0.7366, batch_acc=0.7812, running_acc=0.8419, grad=20.4903]Training epoch 16:  64%|██████▍   | 104/163 [02:00<01:16,  1.29s/it, loss=0.7366, batch_acc=0.7812, running_acc=0.8419, grad=20.4903]Training epoch 16:  64%|██████▍   | 104/163 [02:00<01:16,  1.29s/it, loss=0.8389, batch_acc=0.9062, running_acc=0.8425, grad=21.9792]Training epoch 16:  64%|██████▍   | 105/163 [02:01<01:07,  1.17s/it, loss=0.8389, batch_acc=0.9062, running_acc=0.8425, grad=21.9792]Training epoch 16:  64%|██████▍   | 105/163 [02:01<01:07,  1.17s/it, loss=0.7403, batch_acc=0.8750, running_acc=0.8429, grad=21.1824]Training epoch 16:  65%|██████▌   | 106/163 [02:02<01:01,  1.08s/it, loss=0.7403, batch_acc=0.8750, running_acc=0.8429, grad=21.1824]Training epoch 16:  65%|██████▌   | 106/163 [02:02<01:01,  1.08s/it, loss=1.1307, batch_acc=0.7812, running_acc=0.8423, grad=22.8094]Training epoch 16:  66%|██████▌   | 107/163 [02:03<00:57,  1.02s/it, loss=1.1307, batch_acc=0.7812, running_acc=0.8423, grad=22.8094]Training epoch 16:  66%|██████▌   | 107/163 [02:03<00:57,  1.02s/it, loss=0.9988, batch_acc=0.8125, running_acc=0.8420, grad=29.4461]Training epoch 16:  66%|██████▋   | 108/163 [02:05<01:07,  1.22s/it, loss=0.9988, batch_acc=0.8125, running_acc=0.8420, grad=29.4461]Training epoch 16:  66%|██████▋   | 108/163 [02:05<01:07,  1.22s/it, loss=1.0628, batch_acc=0.7500, running_acc=0.8411, grad=37.5822]Training epoch 16:  67%|██████▋   | 109/163 [02:06<01:00,  1.12s/it, loss=1.0628, batch_acc=0.7500, running_acc=0.8411, grad=37.5822]Training epoch 16:  67%|██████▋   | 109/163 [02:06<01:00,  1.12s/it, loss=0.8660, batch_acc=0.8750, running_acc=0.8415, grad=25.6496]Training epoch 16:  67%|██████▋   | 110/163 [02:06<00:55,  1.05s/it, loss=0.8660, batch_acc=0.8750, running_acc=0.8415, grad=25.6496]Training epoch 16:  67%|██████▋   | 110/163 [02:06<00:55,  1.05s/it, loss=0.7428, batch_acc=0.9375, running_acc=0.8423, grad=20.8200]Training epoch 16:  68%|██████▊   | 111/163 [02:07<00:51,  1.00it/s, loss=0.7428, batch_acc=0.9375, running_acc=0.8423, grad=20.8200]Training epoch 16:  68%|██████▊   | 111/163 [02:07<00:51,  1.00it/s, loss=0.9056, batch_acc=0.8438, running_acc=0.8423, grad=22.1661]Training epoch 16:  69%|██████▊   | 112/163 [02:10<01:10,  1.38s/it, loss=0.9056, batch_acc=0.8438, running_acc=0.8423, grad=22.1661]Training epoch 16:  69%|██████▊   | 112/163 [02:10<01:10,  1.38s/it, loss=0.7517, batch_acc=0.9375, running_acc=0.8432, grad=22.5160]Training epoch 16:  69%|██████▉   | 113/163 [02:10<01:01,  1.23s/it, loss=0.7517, batch_acc=0.9375, running_acc=0.8432, grad=22.5160]Training epoch 16:  69%|██████▉   | 113/163 [02:10<01:01,  1.23s/it, loss=0.8002, batch_acc=0.8750, running_acc=0.8435, grad=17.9815]Training epoch 16:  70%|██████▉   | 114/163 [02:11<00:55,  1.13s/it, loss=0.8002, batch_acc=0.8750, running_acc=0.8435, grad=17.9815]Training epoch 16:  70%|██████▉   | 114/163 [02:11<00:55,  1.13s/it, loss=0.7409, batch_acc=0.9062, running_acc=0.8440, grad=20.0696]Training epoch 16:  71%|███████   | 115/163 [02:12<00:50,  1.05s/it, loss=0.7409, batch_acc=0.9062, running_acc=0.8440, grad=20.0696]Training epoch 16:  71%|███████   | 115/163 [02:12<00:50,  1.05s/it, loss=0.7554, batch_acc=0.8750, running_acc=0.8443, grad=21.1218]Training epoch 16:  71%|███████   | 116/163 [02:14<00:57,  1.22s/it, loss=0.7554, batch_acc=0.8750, running_acc=0.8443, grad=21.1218]Training epoch 16:  71%|███████   | 116/163 [02:14<00:57,  1.22s/it, loss=1.1275, batch_acc=0.7812, running_acc=0.8438, grad=27.6161]Training epoch 16:  72%|███████▏  | 117/163 [02:15<00:51,  1.12s/it, loss=1.1275, batch_acc=0.7812, running_acc=0.8438, grad=27.6161]Training epoch 16:  72%|███████▏  | 117/163 [02:15<00:51,  1.12s/it, loss=0.9398, batch_acc=0.7812, running_acc=0.8432, grad=19.7126]Training epoch 16:  72%|███████▏  | 118/163 [02:16<00:47,  1.05s/it, loss=0.9398, batch_acc=0.7812, running_acc=0.8432, grad=19.7126]Training epoch 16:  72%|███████▏  | 118/163 [02:16<00:47,  1.05s/it, loss=1.0644, batch_acc=0.7500, running_acc=0.8424, grad=45.5115]Training epoch 16:  73%|███████▎  | 119/163 [02:16<00:43,  1.00it/s, loss=1.0644, batch_acc=0.7500, running_acc=0.8424, grad=45.5115]Training epoch 16:  73%|███████▎  | 119/163 [02:16<00:43,  1.00it/s, loss=0.6571, batch_acc=0.9062, running_acc=0.8430, grad=18.6566]Training epoch 16:  74%|███████▎  | 120/163 [02:18<00:50,  1.18s/it, loss=0.6571, batch_acc=0.9062, running_acc=0.8430, grad=18.6566]Training epoch 16:  74%|███████▎  | 120/163 [02:18<00:50,  1.18s/it, loss=0.7063, batch_acc=0.9062, running_acc=0.8435, grad=21.0830]Training epoch 16:  74%|███████▍  | 121/163 [02:19<00:45,  1.09s/it, loss=0.7063, batch_acc=0.9062, running_acc=0.8435, grad=21.0830]Training epoch 16:  74%|███████▍  | 121/163 [02:19<00:45,  1.09s/it, loss=1.2400, batch_acc=0.8125, running_acc=0.8432, grad=28.3111]Training epoch 16:  75%|███████▍  | 122/163 [02:20<00:42,  1.03s/it, loss=1.2400, batch_acc=0.8125, running_acc=0.8432, grad=28.3111]Training epoch 16:  75%|███████▍  | 122/163 [02:20<00:42,  1.03s/it, loss=0.9567, batch_acc=0.9062, running_acc=0.8438, grad=26.5721]Training epoch 16:  75%|███████▌  | 123/163 [02:21<00:39,  1.02it/s, loss=0.9567, batch_acc=0.9062, running_acc=0.8438, grad=26.5721]Training epoch 16:  75%|███████▌  | 123/163 [02:21<00:39,  1.02it/s, loss=1.0765, batch_acc=0.7812, running_acc=0.8432, grad=27.4693]Training epoch 16:  76%|███████▌  | 124/163 [02:23<00:49,  1.28s/it, loss=1.0765, batch_acc=0.7812, running_acc=0.8432, grad=27.4693]Training epoch 16:  76%|███████▌  | 124/163 [02:23<00:49,  1.28s/it, loss=0.7862, batch_acc=0.8750, running_acc=0.8435, grad=19.6541]Training epoch 16:  77%|███████▋  | 125/163 [02:24<00:44,  1.16s/it, loss=0.7862, batch_acc=0.8750, running_acc=0.8435, grad=19.6541]Training epoch 16:  77%|███████▋  | 125/163 [02:24<00:44,  1.16s/it, loss=0.8561, batch_acc=0.8438, running_acc=0.8435, grad=47.8813]Training epoch 16:  77%|███████▋  | 126/163 [02:24<00:39,  1.08s/it, loss=0.8561, batch_acc=0.8438, running_acc=0.8435, grad=47.8813]Training epoch 16:  77%|███████▋  | 126/163 [02:24<00:39,  1.08s/it, loss=0.9844, batch_acc=0.8125, running_acc=0.8433, grad=34.4844]Training epoch 16:  78%|███████▊  | 127/163 [02:25<00:36,  1.02s/it, loss=0.9844, batch_acc=0.8125, running_acc=0.8433, grad=34.4844]Training epoch 16:  78%|███████▊  | 127/163 [02:25<00:36,  1.02s/it, loss=0.7787, batch_acc=0.9688, running_acc=0.8442, grad=27.0546]Training epoch 16:  79%|███████▊  | 128/163 [02:27<00:44,  1.28s/it, loss=0.7787, batch_acc=0.9688, running_acc=0.8442, grad=27.0546]Training epoch 16:  79%|███████▊  | 128/163 [02:27<00:44,  1.28s/it, loss=0.7302, batch_acc=0.9062, running_acc=0.8447, grad=22.9381]Training epoch 16:  79%|███████▉  | 129/163 [02:28<00:39,  1.16s/it, loss=0.7302, batch_acc=0.9062, running_acc=0.8447, grad=22.9381]Training epoch 16:  79%|███████▉  | 129/163 [02:28<00:39,  1.16s/it, loss=0.8500, batch_acc=0.8750, running_acc=0.8450, grad=23.2650]Training epoch 16:  80%|███████▉  | 130/163 [02:29<00:35,  1.08s/it, loss=0.8500, batch_acc=0.8750, running_acc=0.8450, grad=23.2650]Training epoch 16:  80%|███████▉  | 130/163 [02:29<00:35,  1.08s/it, loss=1.0783, batch_acc=0.8125, running_acc=0.8447, grad=24.8022]Training epoch 16:  80%|████████  | 131/163 [02:30<00:32,  1.02s/it, loss=1.0783, batch_acc=0.8125, running_acc=0.8447, grad=24.8022]Training epoch 16:  80%|████████  | 131/163 [02:30<00:32,  1.02s/it, loss=0.8606, batch_acc=0.8438, running_acc=0.8447, grad=21.0299]Training epoch 16:  81%|████████  | 132/163 [02:32<00:44,  1.44s/it, loss=0.8606, batch_acc=0.8438, running_acc=0.8447, grad=21.0299]Training epoch 16:  81%|████████  | 132/163 [02:32<00:44,  1.44s/it, loss=0.7952, batch_acc=0.8125, running_acc=0.8445, grad=25.3082]Training epoch 16:  82%|████████▏ | 133/163 [02:33<00:38,  1.27s/it, loss=0.7952, batch_acc=0.8125, running_acc=0.8445, grad=25.3082]Training epoch 16:  82%|████████▏ | 133/163 [02:33<00:38,  1.27s/it, loss=0.8783, batch_acc=0.8125, running_acc=0.8442, grad=22.3668]Training epoch 16:  82%|████████▏ | 134/163 [02:34<00:33,  1.16s/it, loss=0.8783, batch_acc=0.8125, running_acc=0.8442, grad=22.3668]Training epoch 16:  82%|████████▏ | 134/163 [02:34<00:33,  1.16s/it, loss=0.9452, batch_acc=0.7812, running_acc=0.8438, grad=26.0130]Training epoch 16:  83%|████████▎ | 135/163 [02:35<00:30,  1.07s/it, loss=0.9452, batch_acc=0.7812, running_acc=0.8438, grad=26.0130]Training epoch 16:  83%|████████▎ | 135/163 [02:35<00:30,  1.07s/it, loss=0.9844, batch_acc=0.7500, running_acc=0.8431, grad=30.6084]Training epoch 16:  83%|████████▎ | 136/163 [02:37<00:33,  1.24s/it, loss=0.9844, batch_acc=0.7500, running_acc=0.8431, grad=30.6084]Training epoch 16:  83%|████████▎ | 136/163 [02:37<00:33,  1.24s/it, loss=0.7381, batch_acc=0.8750, running_acc=0.8433, grad=27.2734]Training epoch 16:  84%|████████▍ | 137/163 [02:37<00:29,  1.14s/it, loss=0.7381, batch_acc=0.8750, running_acc=0.8433, grad=27.2734]Training epoch 16:  84%|████████▍ | 137/163 [02:37<00:29,  1.14s/it, loss=0.7933, batch_acc=0.9062, running_acc=0.8438, grad=34.7206]Training epoch 16:  85%|████████▍ | 138/163 [02:38<00:26,  1.06s/it, loss=0.7933, batch_acc=0.9062, running_acc=0.8438, grad=34.7206]Training epoch 16:  85%|████████▍ | 138/163 [02:38<00:26,  1.06s/it, loss=0.9063, batch_acc=0.8125, running_acc=0.8435, grad=28.9706]Training epoch 16:  85%|████████▌ | 139/163 [02:39<00:24,  1.00s/it, loss=0.9063, batch_acc=0.8125, running_acc=0.8435, grad=28.9706]Training epoch 16:  85%|████████▌ | 139/163 [02:39<00:24,  1.00s/it, loss=0.8115, batch_acc=0.9062, running_acc=0.8440, grad=23.3555]Training epoch 16:  86%|████████▌ | 140/163 [02:41<00:26,  1.17s/it, loss=0.8115, batch_acc=0.9062, running_acc=0.8440, grad=23.3555]Training epoch 16:  86%|████████▌ | 140/163 [02:41<00:26,  1.17s/it, loss=0.6808, batch_acc=0.8750, running_acc=0.8442, grad=20.0688]Training epoch 16:  87%|████████▋ | 141/163 [02:42<00:23,  1.08s/it, loss=0.6808, batch_acc=0.8750, running_acc=0.8442, grad=20.0688]Training epoch 16:  87%|████████▋ | 141/163 [02:42<00:23,  1.08s/it, loss=0.9109, batch_acc=0.7500, running_acc=0.8435, grad=22.6756]Training epoch 16:  87%|████████▋ | 142/163 [02:43<00:21,  1.02s/it, loss=0.9109, batch_acc=0.7500, running_acc=0.8435, grad=22.6756]Training epoch 16:  87%|████████▋ | 142/163 [02:43<00:21,  1.02s/it, loss=0.8190, batch_acc=0.8125, running_acc=0.8433, grad=21.6842]Training epoch 16:  88%|████████▊ | 143/163 [02:43<00:19,  1.02it/s, loss=0.8190, batch_acc=0.8125, running_acc=0.8433, grad=21.6842]Training epoch 16:  88%|████████▊ | 143/163 [02:43<00:19,  1.02it/s, loss=1.3230, batch_acc=0.6875, running_acc=0.8422, grad=41.9732]Training epoch 16:  88%|████████▊ | 144/163 [02:45<00:23,  1.22s/it, loss=1.3230, batch_acc=0.6875, running_acc=0.8422, grad=41.9732]Training epoch 16:  88%|████████▊ | 144/163 [02:45<00:23,  1.22s/it, loss=0.7522, batch_acc=0.8750, running_acc=0.8424, grad=34.0409]Training epoch 16:  89%|████████▉ | 145/163 [02:46<00:20,  1.12s/it, loss=0.7522, batch_acc=0.8750, running_acc=0.8424, grad=34.0409]Training epoch 16:  89%|████████▉ | 145/163 [02:46<00:20,  1.12s/it, loss=1.0864, batch_acc=0.7500, running_acc=0.8418, grad=33.4019]Training epoch 16:  90%|████████▉ | 146/163 [02:47<00:17,  1.05s/it, loss=1.0864, batch_acc=0.7500, running_acc=0.8418, grad=33.4019]Training epoch 16:  90%|████████▉ | 146/163 [02:47<00:17,  1.05s/it, loss=0.7087, batch_acc=0.8750, running_acc=0.8420, grad=23.0302]Training epoch 16:  90%|█████████ | 147/163 [02:48<00:15,  1.00it/s, loss=0.7087, batch_acc=0.8750, running_acc=0.8420, grad=23.0302]Training epoch 16:  90%|█████████ | 147/163 [02:48<00:15,  1.00it/s, loss=1.0213, batch_acc=0.6875, running_acc=0.8410, grad=24.0855]Training epoch 16:  91%|█████████ | 148/163 [02:50<00:19,  1.30s/it, loss=1.0213, batch_acc=0.6875, running_acc=0.8410, grad=24.0855]Training epoch 16:  91%|█████████ | 148/163 [02:50<00:19,  1.30s/it, loss=0.9880, batch_acc=0.8438, running_acc=0.8410, grad=26.0024]Training epoch 16:  91%|█████████▏| 149/163 [02:51<00:16,  1.17s/it, loss=0.9880, batch_acc=0.8438, running_acc=0.8410, grad=26.0024]Training epoch 16:  91%|█████████▏| 149/163 [02:51<00:16,  1.17s/it, loss=0.8003, batch_acc=0.8125, running_acc=0.8408, grad=31.1836]Training epoch 16:  92%|█████████▏| 150/163 [02:52<00:14,  1.08s/it, loss=0.8003, batch_acc=0.8125, running_acc=0.8408, grad=31.1836]Training epoch 16:  92%|█████████▏| 150/163 [02:52<00:14,  1.08s/it, loss=1.1583, batch_acc=0.7500, running_acc=0.8402, grad=27.6589]Training epoch 16:  93%|█████████▎| 151/163 [02:52<00:12,  1.02s/it, loss=1.1583, batch_acc=0.7500, running_acc=0.8402, grad=27.6589]Training epoch 16:  93%|█████████▎| 151/163 [02:52<00:12,  1.02s/it, loss=0.9738, batch_acc=0.7500, running_acc=0.8396, grad=25.8630]Training epoch 16:  93%|█████████▎| 152/163 [02:54<00:13,  1.20s/it, loss=0.9738, batch_acc=0.7500, running_acc=0.8396, grad=25.8630]Training epoch 16:  93%|█████████▎| 152/163 [02:54<00:13,  1.20s/it, loss=0.6458, batch_acc=0.9375, running_acc=0.8403, grad=22.0981]Training epoch 16:  94%|█████████▍| 153/163 [02:55<00:11,  1.11s/it, loss=0.6458, batch_acc=0.9375, running_acc=0.8403, grad=22.0981]Training epoch 16:  94%|█████████▍| 153/163 [02:55<00:11,  1.11s/it, loss=0.8696, batch_acc=0.8750, running_acc=0.8405, grad=22.0261]Training epoch 16:  94%|█████████▍| 154/163 [02:56<00:09,  1.04s/it, loss=0.8696, batch_acc=0.8750, running_acc=0.8405, grad=22.0261]Training epoch 16:  94%|█████████▍| 154/163 [02:56<00:09,  1.04s/it, loss=0.8573, batch_acc=0.7812, running_acc=0.8401, grad=22.7553]Training epoch 16:  95%|█████████▌| 155/163 [02:57<00:07,  1.01it/s, loss=0.8573, batch_acc=0.7812, running_acc=0.8401, grad=22.7553]Training epoch 16:  95%|█████████▌| 155/163 [02:57<00:07,  1.01it/s, loss=1.0119, batch_acc=0.8438, running_acc=0.8401, grad=29.7622]Training epoch 16:  96%|█████████▌| 156/163 [02:58<00:07,  1.08s/it, loss=1.0119, batch_acc=0.8438, running_acc=0.8401, grad=29.7622]Training epoch 16:  96%|█████████▌| 156/163 [02:58<00:07,  1.08s/it, loss=0.7434, batch_acc=0.9375, running_acc=0.8407, grad=18.5661]Training epoch 16:  96%|█████████▋| 157/163 [02:59<00:06,  1.02s/it, loss=0.7434, batch_acc=0.9375, running_acc=0.8407, grad=18.5661]Training epoch 16:  96%|█████████▋| 157/163 [02:59<00:06,  1.02s/it, loss=0.7382, batch_acc=0.8438, running_acc=0.8408, grad=23.3412]Training epoch 16:  97%|█████████▋| 158/163 [03:00<00:04,  1.02it/s, loss=0.7382, batch_acc=0.8438, running_acc=0.8408, grad=23.3412]Training epoch 16:  97%|█████████▋| 158/163 [03:00<00:04,  1.02it/s, loss=0.7198, batch_acc=0.9375, running_acc=0.8414, grad=20.0972]Training epoch 16:  98%|█████████▊| 159/163 [03:01<00:03,  1.06it/s, loss=0.7198, batch_acc=0.9375, running_acc=0.8414, grad=20.0972]Training epoch 16:  98%|█████████▊| 159/163 [03:01<00:03,  1.06it/s, loss=1.0585, batch_acc=0.7188, running_acc=0.8406, grad=28.1346]Training epoch 16:  98%|█████████▊| 160/163 [03:02<00:03,  1.01s/it, loss=1.0585, batch_acc=0.7188, running_acc=0.8406, grad=28.1346]Training epoch 16:  98%|█████████▊| 160/163 [03:02<00:03,  1.01s/it, loss=0.7919, batch_acc=0.9062, running_acc=0.8410, grad=27.4028]Training epoch 16:  99%|█████████▉| 161/163 [03:03<00:01,  1.03it/s, loss=0.7919, batch_acc=0.9062, running_acc=0.8410, grad=27.4028]Training epoch 16:  99%|█████████▉| 161/163 [03:03<00:01,  1.03it/s, loss=0.7783, batch_acc=0.8750, running_acc=0.8412, grad=23.6911]Training epoch 16:  99%|█████████▉| 162/163 [03:04<00:00,  1.06it/s, loss=0.7783, batch_acc=0.8750, running_acc=0.8412, grad=23.6911]Training epoch 16:  99%|█████████▉| 162/163 [03:04<00:00,  1.06it/s, loss=0.9407, batch_acc=0.7812, running_acc=0.8409, grad=27.9569]Training epoch 16: 100%|██████████| 163/163 [03:04<00:00,  1.17it/s, loss=0.9407, batch_acc=0.7812, running_acc=0.8409, grad=27.9569]Training epoch 16: 100%|██████████| 163/163 [03:04<00:00,  1.17it/s, loss=0.7527, batch_acc=0.9048, running_acc=0.8411, grad=30.1673]Training epoch 16: 100%|██████████| 163/163 [03:04<00:00,  1.13s/it, loss=0.7527, batch_acc=0.9048, running_acc=0.8411, grad=30.1673]
Evaluation epoch 16:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 16:   4%|▎         | 1/28 [00:04<02:12,  4.92s/it]Evaluation epoch 16:   4%|▎         | 1/28 [00:04<02:12,  4.92s/it, loss=0.8552, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 16:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.8552, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 16:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.9190, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 16:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.9190, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 16:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.8057, batch_acc=0.8750, running_acc=0.8438]Evaluation epoch 16:  14%|█▍        | 4/28 [00:09<01:00,  2.52s/it, loss=0.8057, batch_acc=0.8750, running_acc=0.8438]Evaluation epoch 16:  14%|█▍        | 4/28 [00:09<01:00,  2.52s/it, loss=1.2042, batch_acc=0.7812, running_acc=0.8281]Evaluation epoch 16:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.2042, batch_acc=0.7812, running_acc=0.8281]Evaluation epoch 16:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.7332, batch_acc=0.5000, running_acc=0.7625]Evaluation epoch 16:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.7332, batch_acc=0.5000, running_acc=0.7625]Evaluation epoch 16:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.1642, batch_acc=0.8125, running_acc=0.7708]Evaluation epoch 16:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.1642, batch_acc=0.8125, running_acc=0.7708]Evaluation epoch 16:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.3210, batch_acc=0.7500, running_acc=0.7679]Evaluation epoch 16:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=1.3210, batch_acc=0.7500, running_acc=0.7679]Evaluation epoch 16:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=0.8482, batch_acc=0.8125, running_acc=0.7734]Evaluation epoch 16:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.8482, batch_acc=0.8125, running_acc=0.7734]Evaluation epoch 16:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=1.0683, batch_acc=0.8125, running_acc=0.7778]Evaluation epoch 16:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=1.0683, batch_acc=0.8125, running_acc=0.7778]Evaluation epoch 16:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.7413, batch_acc=0.8750, running_acc=0.7875]Evaluation epoch 16:  39%|███▉      | 11/28 [00:14<00:12,  1.36it/s, loss=0.7413, batch_acc=0.8750, running_acc=0.7875]Evaluation epoch 16:  39%|███▉      | 11/28 [00:14<00:12,  1.36it/s, loss=1.1337, batch_acc=0.7500, running_acc=0.7841]Evaluation epoch 16:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=1.1337, batch_acc=0.7500, running_acc=0.7841]Evaluation epoch 16:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=1.4309, batch_acc=0.5938, running_acc=0.7682]Evaluation epoch 16:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=1.4309, batch_acc=0.5938, running_acc=0.7682]Evaluation epoch 16:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=0.6820, batch_acc=0.9062, running_acc=0.7788]Evaluation epoch 16:  50%|█████     | 14/28 [00:20<00:17,  1.22s/it, loss=0.6820, batch_acc=0.9062, running_acc=0.7788]Evaluation epoch 16:  50%|█████     | 14/28 [00:20<00:17,  1.22s/it, loss=1.4742, batch_acc=0.6875, running_acc=0.7723]Evaluation epoch 16:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.4742, batch_acc=0.6875, running_acc=0.7723]Evaluation epoch 16:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.9988, batch_acc=0.4375, running_acc=0.7500]Evaluation epoch 16:  57%|█████▋    | 16/28 [00:23<00:17,  1.46s/it, loss=1.9988, batch_acc=0.4375, running_acc=0.7500]Evaluation epoch 16:  57%|█████▋    | 16/28 [00:23<00:17,  1.46s/it, loss=1.2511, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 16:  61%|██████    | 17/28 [00:24<00:12,  1.10s/it, loss=1.2511, batch_acc=0.7500, running_acc=0.7500]Evaluation epoch 16:  61%|██████    | 17/28 [00:24<00:12,  1.10s/it, loss=0.8354, batch_acc=0.7812, running_acc=0.7518]Evaluation epoch 16:  64%|██████▍   | 18/28 [00:24<00:08,  1.18it/s, loss=0.8354, batch_acc=0.7812, running_acc=0.7518]Evaluation epoch 16:  64%|██████▍   | 18/28 [00:24<00:08,  1.18it/s, loss=1.0913, batch_acc=0.7188, running_acc=0.7500]Evaluation epoch 16:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=1.0913, batch_acc=0.7188, running_acc=0.7500]Evaluation epoch 16:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=1.1095, batch_acc=0.6875, running_acc=0.7467]Evaluation epoch 16:  71%|███████▏  | 20/28 [00:27<00:10,  1.28s/it, loss=1.1095, batch_acc=0.6875, running_acc=0.7467]Evaluation epoch 16:  71%|███████▏  | 20/28 [00:27<00:10,  1.28s/it, loss=1.0655, batch_acc=0.6875, running_acc=0.7438]Evaluation epoch 16:  75%|███████▌  | 21/28 [00:27<00:06,  1.03it/s, loss=1.0655, batch_acc=0.6875, running_acc=0.7438]Evaluation epoch 16:  75%|███████▌  | 21/28 [00:27<00:06,  1.03it/s, loss=1.2353, batch_acc=0.7188, running_acc=0.7426]Evaluation epoch 16:  79%|███████▊  | 22/28 [00:27<00:04,  1.32it/s, loss=1.2353, batch_acc=0.7188, running_acc=0.7426]Evaluation epoch 16:  79%|███████▊  | 22/28 [00:27<00:04,  1.32it/s, loss=1.5378, batch_acc=0.5625, running_acc=0.7344]Evaluation epoch 16:  82%|████████▏ | 23/28 [00:28<00:03,  1.64it/s, loss=1.5378, batch_acc=0.5625, running_acc=0.7344]Evaluation epoch 16:  82%|████████▏ | 23/28 [00:28<00:03,  1.64it/s, loss=1.6840, batch_acc=0.5312, running_acc=0.7255]Evaluation epoch 16:  86%|████████▌ | 24/28 [00:33<00:07,  1.99s/it, loss=1.6840, batch_acc=0.5312, running_acc=0.7255]Evaluation epoch 16:  86%|████████▌ | 24/28 [00:33<00:07,  1.99s/it, loss=0.7867, batch_acc=0.8438, running_acc=0.7305]Evaluation epoch 16:  89%|████████▉ | 25/28 [00:33<00:04,  1.47s/it, loss=0.7867, batch_acc=0.8438, running_acc=0.7305]Evaluation epoch 16:  89%|████████▉ | 25/28 [00:33<00:04,  1.47s/it, loss=0.6739, batch_acc=0.9062, running_acc=0.7375]Evaluation epoch 16:  93%|█████████▎| 26/28 [00:33<00:02,  1.11s/it, loss=0.6739, batch_acc=0.9062, running_acc=0.7375]Evaluation epoch 16:  93%|█████████▎| 26/28 [00:33<00:02,  1.11s/it, loss=1.2991, batch_acc=0.5938, running_acc=0.7320]Evaluation epoch 16:  96%|█████████▋| 27/28 [00:34<00:00,  1.17it/s, loss=1.2991, batch_acc=0.5938, running_acc=0.7320]Evaluation epoch 16:  96%|█████████▋| 27/28 [00:34<00:00,  1.17it/s, loss=1.4086, batch_acc=0.5938, running_acc=0.7269]Evaluation epoch 16: 100%|██████████| 28/28 [00:34<00:00,  1.17it/s, loss=1.5276, batch_acc=0.6667, running_acc=0.7266]Evaluation epoch 16: 100%|██████████| 28/28 [00:34<00:00,  1.22s/it, loss=1.5276, batch_acc=0.6667, running_acc=0.7266]
Training epoch 17:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 17:   1%|          | 1/163 [00:05<15:36,  5.78s/it]Training epoch 17:   1%|          | 1/163 [00:05<15:36,  5.78s/it, loss=0.6648, batch_acc=0.8750, running_acc=0.8750, grad=18.1311]Training epoch 17:   1%|          | 2/163 [00:06<07:46,  2.90s/it, loss=0.6648, batch_acc=0.8750, running_acc=0.8750, grad=18.1311]Training epoch 17:   1%|          | 2/163 [00:06<07:46,  2.90s/it, loss=0.5570, batch_acc=0.8750, running_acc=0.8750, grad=20.4945]Training epoch 17:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.5570, batch_acc=0.8750, running_acc=0.8750, grad=20.4945]Training epoch 17:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.6356, batch_acc=0.9062, running_acc=0.8854, grad=22.0902]Training epoch 17:   2%|▏         | 4/163 [00:10<06:01,  2.27s/it, loss=0.6356, batch_acc=0.9062, running_acc=0.8854, grad=22.0902]Training epoch 17:   2%|▏         | 4/163 [00:10<06:01,  2.27s/it, loss=0.9112, batch_acc=0.7500, running_acc=0.8516, grad=26.8471]Training epoch 17:   3%|▎         | 5/163 [00:11<04:39,  1.77s/it, loss=0.9112, batch_acc=0.7500, running_acc=0.8516, grad=26.8471]Training epoch 17:   3%|▎         | 5/163 [00:11<04:39,  1.77s/it, loss=0.6327, batch_acc=0.9688, running_acc=0.8750, grad=19.7827]Training epoch 17:   4%|▎         | 6/163 [00:12<03:50,  1.47s/it, loss=0.6327, batch_acc=0.9688, running_acc=0.8750, grad=19.7827]Training epoch 17:   4%|▎         | 6/163 [00:12<03:50,  1.47s/it, loss=0.7151, batch_acc=0.8750, running_acc=0.8750, grad=18.7162]Training epoch 17:   4%|▍         | 7/163 [00:12<03:19,  1.28s/it, loss=0.7151, batch_acc=0.8750, running_acc=0.8750, grad=18.7162]Training epoch 17:   4%|▍         | 7/163 [00:12<03:19,  1.28s/it, loss=0.9701, batch_acc=0.8125, running_acc=0.8661, grad=26.3094]Training epoch 17:   5%|▍         | 8/163 [00:14<03:32,  1.37s/it, loss=0.9701, batch_acc=0.8125, running_acc=0.8661, grad=26.3094]Training epoch 17:   5%|▍         | 8/163 [00:14<03:32,  1.37s/it, loss=0.7689, batch_acc=0.8750, running_acc=0.8672, grad=19.1993]Training epoch 17:   6%|▌         | 9/163 [00:15<03:07,  1.22s/it, loss=0.7689, batch_acc=0.8750, running_acc=0.8672, grad=19.1993]Training epoch 17:   6%|▌         | 9/163 [00:15<03:07,  1.22s/it, loss=0.9066, batch_acc=0.9062, running_acc=0.8715, grad=28.9158]Training epoch 17:   6%|▌         | 10/163 [00:16<02:50,  1.11s/it, loss=0.9066, batch_acc=0.9062, running_acc=0.8715, grad=28.9158]Training epoch 17:   6%|▌         | 10/163 [00:16<02:50,  1.11s/it, loss=0.6156, batch_acc=0.9375, running_acc=0.8781, grad=20.2618]Training epoch 17:   7%|▋         | 11/163 [00:17<02:38,  1.04s/it, loss=0.6156, batch_acc=0.9375, running_acc=0.8781, grad=20.2618]Training epoch 17:   7%|▋         | 11/163 [00:17<02:38,  1.04s/it, loss=0.9585, batch_acc=0.8438, running_acc=0.8750, grad=45.6985]Training epoch 17:   7%|▋         | 12/163 [00:18<03:08,  1.25s/it, loss=0.9585, batch_acc=0.8438, running_acc=0.8750, grad=45.6985]Training epoch 17:   7%|▋         | 12/163 [00:18<03:08,  1.25s/it, loss=0.8050, batch_acc=0.9062, running_acc=0.8776, grad=30.8544]Training epoch 17:   8%|▊         | 13/163 [00:19<02:50,  1.14s/it, loss=0.8050, batch_acc=0.9062, running_acc=0.8776, grad=30.8544]Training epoch 17:   8%|▊         | 13/163 [00:19<02:50,  1.14s/it, loss=0.7678, batch_acc=0.7500, running_acc=0.8678, grad=25.1121]Training epoch 17:   9%|▊         | 14/163 [00:20<02:37,  1.06s/it, loss=0.7678, batch_acc=0.7500, running_acc=0.8678, grad=25.1121]Training epoch 17:   9%|▊         | 14/163 [00:20<02:37,  1.06s/it, loss=0.9897, batch_acc=0.8438, running_acc=0.8661, grad=35.3868]Training epoch 17:   9%|▉         | 15/163 [00:21<02:28,  1.01s/it, loss=0.9897, batch_acc=0.8438, running_acc=0.8661, grad=35.3868]Training epoch 17:   9%|▉         | 15/163 [00:21<02:28,  1.01s/it, loss=0.7558, batch_acc=0.8125, running_acc=0.8625, grad=20.7594]Training epoch 17:  10%|▉         | 16/163 [00:23<03:00,  1.23s/it, loss=0.7558, batch_acc=0.8125, running_acc=0.8625, grad=20.7594]Training epoch 17:  10%|▉         | 16/163 [00:23<03:00,  1.23s/it, loss=0.8459, batch_acc=0.8125, running_acc=0.8594, grad=28.7394]Training epoch 17:  10%|█         | 17/163 [00:24<02:43,  1.12s/it, loss=0.8459, batch_acc=0.8125, running_acc=0.8594, grad=28.7394]Training epoch 17:  10%|█         | 17/163 [00:24<02:43,  1.12s/it, loss=0.8255, batch_acc=0.8750, running_acc=0.8603, grad=22.1547]Training epoch 17:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.8255, batch_acc=0.8750, running_acc=0.8603, grad=22.1547]Training epoch 17:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.9567, batch_acc=0.8750, running_acc=0.8611, grad=23.5502]Training epoch 17:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.9567, batch_acc=0.8750, running_acc=0.8611, grad=23.5502]Training epoch 17:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.7715, batch_acc=0.9062, running_acc=0.8635, grad=25.5683]Training epoch 17:  12%|█▏        | 20/163 [00:27<02:44,  1.15s/it, loss=0.7715, batch_acc=0.9062, running_acc=0.8635, grad=25.5683]Training epoch 17:  12%|█▏        | 20/163 [00:27<02:44,  1.15s/it, loss=0.6683, batch_acc=0.9375, running_acc=0.8672, grad=24.2248]Training epoch 17:  13%|█▎        | 21/163 [00:28<02:32,  1.07s/it, loss=0.6683, batch_acc=0.9375, running_acc=0.8672, grad=24.2248]Training epoch 17:  13%|█▎        | 21/163 [00:28<02:32,  1.07s/it, loss=1.1256, batch_acc=0.6875, running_acc=0.8586, grad=33.8771]Training epoch 17:  13%|█▎        | 22/163 [00:29<02:23,  1.01s/it, loss=1.1256, batch_acc=0.6875, running_acc=0.8586, grad=33.8771]Training epoch 17:  13%|█▎        | 22/163 [00:29<02:23,  1.01s/it, loss=1.1370, batch_acc=0.6250, running_acc=0.8480, grad=34.2498]Training epoch 17:  14%|█▍        | 23/163 [00:30<02:16,  1.03it/s, loss=1.1370, batch_acc=0.6250, running_acc=0.8480, grad=34.2498]Training epoch 17:  14%|█▍        | 23/163 [00:30<02:16,  1.03it/s, loss=0.8157, batch_acc=0.8125, running_acc=0.8465, grad=21.9782]Training epoch 17:  15%|█▍        | 24/163 [00:31<02:48,  1.21s/it, loss=0.8157, batch_acc=0.8125, running_acc=0.8465, grad=21.9782]Training epoch 17:  15%|█▍        | 24/163 [00:31<02:48,  1.21s/it, loss=0.9883, batch_acc=0.7500, running_acc=0.8424, grad=24.1988]Training epoch 17:  15%|█▌        | 25/163 [00:32<02:33,  1.12s/it, loss=0.9883, batch_acc=0.7500, running_acc=0.8424, grad=24.1988]Training epoch 17:  15%|█▌        | 25/163 [00:32<02:33,  1.12s/it, loss=0.9755, batch_acc=0.7188, running_acc=0.8375, grad=26.7371]Training epoch 17:  16%|█▌        | 26/163 [00:33<02:23,  1.04s/it, loss=0.9755, batch_acc=0.7188, running_acc=0.8375, grad=26.7371]Training epoch 17:  16%|█▌        | 26/163 [00:33<02:23,  1.04s/it, loss=0.8508, batch_acc=0.8438, running_acc=0.8377, grad=31.6318]Training epoch 17:  17%|█▋        | 27/163 [00:34<02:15,  1.00it/s, loss=0.8508, batch_acc=0.8438, running_acc=0.8377, grad=31.6318]Training epoch 17:  17%|█▋        | 27/163 [00:34<02:15,  1.00it/s, loss=0.8065, batch_acc=0.8438, running_acc=0.8380, grad=26.6486]Training epoch 17:  17%|█▋        | 28/163 [00:35<02:36,  1.16s/it, loss=0.8065, batch_acc=0.8438, running_acc=0.8380, grad=26.6486]Training epoch 17:  17%|█▋        | 28/163 [00:35<02:36,  1.16s/it, loss=0.9121, batch_acc=0.8438, running_acc=0.8382, grad=25.3578]Training epoch 17:  18%|█▊        | 29/163 [00:36<02:23,  1.07s/it, loss=0.9121, batch_acc=0.8438, running_acc=0.8382, grad=25.3578]Training epoch 17:  18%|█▊        | 29/163 [00:36<02:23,  1.07s/it, loss=0.9276, batch_acc=0.8438, running_acc=0.8384, grad=27.0394]Training epoch 17:  18%|█▊        | 30/163 [00:37<02:15,  1.02s/it, loss=0.9276, batch_acc=0.8438, running_acc=0.8384, grad=27.0394]Training epoch 17:  18%|█▊        | 30/163 [00:37<02:15,  1.02s/it, loss=0.8412, batch_acc=0.9062, running_acc=0.8406, grad=22.5609]Training epoch 17:  19%|█▉        | 31/163 [00:38<02:08,  1.02it/s, loss=0.8412, batch_acc=0.9062, running_acc=0.8406, grad=22.5609]Training epoch 17:  19%|█▉        | 31/163 [00:38<02:08,  1.02it/s, loss=0.8833, batch_acc=0.8125, running_acc=0.8397, grad=31.8957]Training epoch 17:  20%|█▉        | 32/163 [00:40<02:57,  1.36s/it, loss=0.8833, batch_acc=0.8125, running_acc=0.8397, grad=31.8957]Training epoch 17:  20%|█▉        | 32/163 [00:40<02:57,  1.36s/it, loss=0.5351, batch_acc=0.9688, running_acc=0.8438, grad=15.7242]Training epoch 17:  20%|██        | 33/163 [00:41<02:37,  1.21s/it, loss=0.5351, batch_acc=0.9688, running_acc=0.8438, grad=15.7242]Training epoch 17:  20%|██        | 33/163 [00:41<02:37,  1.21s/it, loss=0.7619, batch_acc=0.9062, running_acc=0.8456, grad=30.8920]Training epoch 17:  21%|██        | 34/163 [00:42<02:23,  1.11s/it, loss=0.7619, batch_acc=0.9062, running_acc=0.8456, grad=30.8920]Training epoch 17:  21%|██        | 34/163 [00:42<02:23,  1.11s/it, loss=0.9504, batch_acc=0.8125, running_acc=0.8447, grad=25.8832]Training epoch 17:  21%|██▏       | 35/163 [00:43<02:13,  1.04s/it, loss=0.9504, batch_acc=0.8125, running_acc=0.8447, grad=25.8832]Training epoch 17:  21%|██▏       | 35/163 [00:43<02:13,  1.04s/it, loss=0.7413, batch_acc=0.8750, running_acc=0.8455, grad=17.3758]Training epoch 17:  22%|██▏       | 36/163 [00:45<02:35,  1.22s/it, loss=0.7413, batch_acc=0.8750, running_acc=0.8455, grad=17.3758]Training epoch 17:  22%|██▏       | 36/163 [00:45<02:35,  1.22s/it, loss=0.6273, batch_acc=0.9688, running_acc=0.8490, grad=20.6289]Training epoch 17:  23%|██▎       | 37/163 [00:46<02:21,  1.12s/it, loss=0.6273, batch_acc=0.9688, running_acc=0.8490, grad=20.6289]Training epoch 17:  23%|██▎       | 37/163 [00:46<02:21,  1.12s/it, loss=0.8543, batch_acc=0.8125, running_acc=0.8480, grad=25.8797]Training epoch 17:  23%|██▎       | 38/163 [00:46<02:10,  1.05s/it, loss=0.8543, batch_acc=0.8125, running_acc=0.8480, grad=25.8797]Training epoch 17:  23%|██▎       | 38/163 [00:46<02:10,  1.05s/it, loss=0.8281, batch_acc=0.7812, running_acc=0.8462, grad=26.6622]Training epoch 17:  24%|██▍       | 39/163 [00:47<02:03,  1.00it/s, loss=0.8281, batch_acc=0.7812, running_acc=0.8462, grad=26.6622]Training epoch 17:  24%|██▍       | 39/163 [00:47<02:03,  1.00it/s, loss=0.9751, batch_acc=0.7812, running_acc=0.8446, grad=25.4527]Training epoch 17:  25%|██▍       | 40/163 [00:49<02:47,  1.36s/it, loss=0.9751, batch_acc=0.7812, running_acc=0.8446, grad=25.4527]Training epoch 17:  25%|██▍       | 40/163 [00:49<02:47,  1.36s/it, loss=0.8233, batch_acc=0.9062, running_acc=0.8461, grad=31.3947]Training epoch 17:  25%|██▌       | 41/163 [00:50<02:28,  1.22s/it, loss=0.8233, batch_acc=0.9062, running_acc=0.8461, grad=31.3947]Training epoch 17:  25%|██▌       | 41/163 [00:50<02:28,  1.22s/it, loss=0.8427, batch_acc=0.8438, running_acc=0.8460, grad=24.9945]Training epoch 17:  26%|██▌       | 42/163 [00:51<02:14,  1.12s/it, loss=0.8427, batch_acc=0.8438, running_acc=0.8460, grad=24.9945]Training epoch 17:  26%|██▌       | 42/163 [00:51<02:14,  1.12s/it, loss=0.7140, batch_acc=0.8438, running_acc=0.8460, grad=25.3978]Training epoch 17:  26%|██▋       | 43/163 [00:52<02:05,  1.05s/it, loss=0.7140, batch_acc=0.8438, running_acc=0.8460, grad=25.3978]Training epoch 17:  26%|██▋       | 43/163 [00:52<02:05,  1.05s/it, loss=0.8065, batch_acc=0.8438, running_acc=0.8459, grad=26.8100]Training epoch 17:  27%|██▋       | 44/163 [00:54<02:41,  1.35s/it, loss=0.8065, batch_acc=0.8438, running_acc=0.8459, grad=26.8100]Training epoch 17:  27%|██▋       | 44/163 [00:54<02:41,  1.35s/it, loss=0.8354, batch_acc=0.8438, running_acc=0.8459, grad=26.0676]Training epoch 17:  28%|██▊       | 45/163 [00:55<02:22,  1.21s/it, loss=0.8354, batch_acc=0.8438, running_acc=0.8459, grad=26.0676]Training epoch 17:  28%|██▊       | 45/163 [00:55<02:22,  1.21s/it, loss=0.7269, batch_acc=0.8438, running_acc=0.8458, grad=18.7660]Training epoch 17:  28%|██▊       | 46/163 [00:56<02:10,  1.11s/it, loss=0.7269, batch_acc=0.8438, running_acc=0.8458, grad=18.7660]Training epoch 17:  28%|██▊       | 46/163 [00:56<02:10,  1.11s/it, loss=0.7273, batch_acc=0.9062, running_acc=0.8471, grad=29.8947]Training epoch 17:  29%|██▉       | 47/163 [00:57<02:00,  1.04s/it, loss=0.7273, batch_acc=0.9062, running_acc=0.8471, grad=29.8947]Training epoch 17:  29%|██▉       | 47/163 [00:57<02:00,  1.04s/it, loss=0.7715, batch_acc=0.8750, running_acc=0.8477, grad=20.2200]Training epoch 17:  29%|██▉       | 48/163 [00:58<02:07,  1.11s/it, loss=0.7715, batch_acc=0.8750, running_acc=0.8477, grad=20.2200]Training epoch 17:  29%|██▉       | 48/163 [00:58<02:07,  1.11s/it, loss=0.6755, batch_acc=0.9062, running_acc=0.8490, grad=17.1265]Training epoch 17:  30%|███       | 49/163 [00:59<01:58,  1.04s/it, loss=0.6755, batch_acc=0.9062, running_acc=0.8490, grad=17.1265]Training epoch 17:  30%|███       | 49/163 [00:59<01:58,  1.04s/it, loss=1.2037, batch_acc=0.6875, running_acc=0.8457, grad=35.4141]Training epoch 17:  31%|███       | 50/163 [01:00<01:52,  1.01it/s, loss=1.2037, batch_acc=0.6875, running_acc=0.8457, grad=35.4141]Training epoch 17:  31%|███       | 50/163 [01:00<01:52,  1.01it/s, loss=0.5870, batch_acc=0.9688, running_acc=0.8481, grad=17.2400]Training epoch 17:  31%|███▏      | 51/163 [01:01<01:47,  1.04it/s, loss=0.5870, batch_acc=0.9688, running_acc=0.8481, grad=17.2400]Training epoch 17:  31%|███▏      | 51/163 [01:01<01:47,  1.04it/s, loss=0.9377, batch_acc=0.7812, running_acc=0.8468, grad=23.2120]Training epoch 17:  32%|███▏      | 52/163 [01:03<02:30,  1.36s/it, loss=0.9377, batch_acc=0.7812, running_acc=0.8468, grad=23.2120]Training epoch 17:  32%|███▏      | 52/163 [01:03<02:30,  1.36s/it, loss=0.6565, batch_acc=0.8750, running_acc=0.8474, grad=23.4631]Training epoch 17:  33%|███▎      | 53/163 [01:04<02:13,  1.21s/it, loss=0.6565, batch_acc=0.8750, running_acc=0.8474, grad=23.4631]Training epoch 17:  33%|███▎      | 53/163 [01:04<02:13,  1.21s/it, loss=1.0569, batch_acc=0.7500, running_acc=0.8455, grad=26.6332]Training epoch 17:  33%|███▎      | 54/163 [01:05<02:01,  1.11s/it, loss=1.0569, batch_acc=0.7500, running_acc=0.8455, grad=26.6332]Training epoch 17:  33%|███▎      | 54/163 [01:05<02:01,  1.11s/it, loss=0.7637, batch_acc=0.8750, running_acc=0.8461, grad=27.7640]Training epoch 17:  34%|███▎      | 55/163 [01:06<01:52,  1.04s/it, loss=0.7637, batch_acc=0.8750, running_acc=0.8461, grad=27.7640]Training epoch 17:  34%|███▎      | 55/163 [01:06<01:52,  1.04s/it, loss=0.8825, batch_acc=0.7812, running_acc=0.8449, grad=22.9689]Training epoch 17:  34%|███▍      | 56/163 [01:07<02:06,  1.18s/it, loss=0.8825, batch_acc=0.7812, running_acc=0.8449, grad=22.9689]Training epoch 17:  34%|███▍      | 56/163 [01:07<02:06,  1.18s/it, loss=0.6733, batch_acc=0.9375, running_acc=0.8465, grad=24.5095]Training epoch 17:  35%|███▍      | 57/163 [01:08<01:55,  1.09s/it, loss=0.6733, batch_acc=0.9375, running_acc=0.8465, grad=24.5095]Training epoch 17:  35%|███▍      | 57/163 [01:08<01:55,  1.09s/it, loss=0.7983, batch_acc=0.9062, running_acc=0.8476, grad=23.9455]Training epoch 17:  36%|███▌      | 58/163 [01:09<01:47,  1.03s/it, loss=0.7983, batch_acc=0.9062, running_acc=0.8476, grad=23.9455]Training epoch 17:  36%|███▌      | 58/163 [01:09<01:47,  1.03s/it, loss=0.6957, batch_acc=0.8438, running_acc=0.8475, grad=27.3210]Training epoch 17:  36%|███▌      | 59/163 [01:10<01:42,  1.02it/s, loss=0.6957, batch_acc=0.8438, running_acc=0.8475, grad=27.3210]Training epoch 17:  36%|███▌      | 59/163 [01:10<01:42,  1.02it/s, loss=0.9432, batch_acc=0.8438, running_acc=0.8475, grad=31.2528]Training epoch 17:  37%|███▋      | 60/163 [01:12<02:05,  1.22s/it, loss=0.9432, batch_acc=0.8438, running_acc=0.8475, grad=31.2528]Training epoch 17:  37%|███▋      | 60/163 [01:12<02:05,  1.22s/it, loss=0.8844, batch_acc=0.7812, running_acc=0.8464, grad=33.9996]Training epoch 17:  37%|███▋      | 61/163 [01:12<01:53,  1.12s/it, loss=0.8844, batch_acc=0.7812, running_acc=0.8464, grad=33.9996]Training epoch 17:  37%|███▋      | 61/163 [01:12<01:53,  1.12s/it, loss=0.8848, batch_acc=0.8750, running_acc=0.8468, grad=26.0455]Training epoch 17:  38%|███▊      | 62/163 [01:13<01:45,  1.05s/it, loss=0.8848, batch_acc=0.8750, running_acc=0.8468, grad=26.0455]Training epoch 17:  38%|███▊      | 62/163 [01:13<01:45,  1.05s/it, loss=0.6921, batch_acc=0.9062, running_acc=0.8478, grad=21.3079]Training epoch 17:  39%|███▊      | 63/163 [01:14<01:39,  1.00it/s, loss=0.6921, batch_acc=0.9062, running_acc=0.8478, grad=21.3079]Training epoch 17:  39%|███▊      | 63/163 [01:14<01:39,  1.00it/s, loss=0.7417, batch_acc=0.9062, running_acc=0.8487, grad=21.2670]Training epoch 17:  39%|███▉      | 64/163 [01:16<02:10,  1.32s/it, loss=0.7417, batch_acc=0.9062, running_acc=0.8487, grad=21.2670]Training epoch 17:  39%|███▉      | 64/163 [01:16<02:10,  1.32s/it, loss=0.8156, batch_acc=0.8750, running_acc=0.8491, grad=22.5717]Training epoch 17:  40%|███▉      | 65/163 [01:17<01:56,  1.19s/it, loss=0.8156, batch_acc=0.8750, running_acc=0.8491, grad=22.5717]Training epoch 17:  40%|███▉      | 65/163 [01:17<01:56,  1.19s/it, loss=0.6254, batch_acc=0.9062, running_acc=0.8500, grad=24.2771]Training epoch 17:  40%|████      | 66/163 [01:18<01:46,  1.09s/it, loss=0.6254, batch_acc=0.9062, running_acc=0.8500, grad=24.2771]Training epoch 17:  40%|████      | 66/163 [01:18<01:46,  1.09s/it, loss=0.6723, batch_acc=0.8750, running_acc=0.8504, grad=22.6162]Training epoch 17:  41%|████      | 67/163 [01:19<01:38,  1.03s/it, loss=0.6723, batch_acc=0.8750, running_acc=0.8504, grad=22.6162]Training epoch 17:  41%|████      | 67/163 [01:19<01:38,  1.03s/it, loss=0.7388, batch_acc=0.8750, running_acc=0.8507, grad=22.7160]Training epoch 17:  42%|████▏     | 68/163 [01:21<01:55,  1.21s/it, loss=0.7388, batch_acc=0.8750, running_acc=0.8507, grad=22.7160]Training epoch 17:  42%|████▏     | 68/163 [01:21<01:55,  1.21s/it, loss=0.8459, batch_acc=0.8438, running_acc=0.8506, grad=31.1864]Training epoch 17:  42%|████▏     | 69/163 [01:21<01:44,  1.11s/it, loss=0.8459, batch_acc=0.8438, running_acc=0.8506, grad=31.1864]Training epoch 17:  42%|████▏     | 69/163 [01:21<01:44,  1.11s/it, loss=0.7684, batch_acc=0.8125, running_acc=0.8501, grad=20.3875]Training epoch 17:  43%|████▎     | 70/163 [01:22<01:36,  1.04s/it, loss=0.7684, batch_acc=0.8125, running_acc=0.8501, grad=20.3875]Training epoch 17:  43%|████▎     | 70/163 [01:22<01:36,  1.04s/it, loss=0.9915, batch_acc=0.7812, running_acc=0.8491, grad=25.7856]Training epoch 17:  44%|████▎     | 71/163 [01:23<01:31,  1.01it/s, loss=0.9915, batch_acc=0.7812, running_acc=0.8491, grad=25.7856]Training epoch 17:  44%|████▎     | 71/163 [01:23<01:31,  1.01it/s, loss=0.7765, batch_acc=0.7812, running_acc=0.8482, grad=23.5479]Training epoch 17:  44%|████▍     | 72/163 [01:25<01:50,  1.22s/it, loss=0.7765, batch_acc=0.7812, running_acc=0.8482, grad=23.5479]Training epoch 17:  44%|████▍     | 72/163 [01:25<01:50,  1.22s/it, loss=0.7126, batch_acc=0.8750, running_acc=0.8485, grad=23.5378]Training epoch 17:  45%|████▍     | 73/163 [01:26<01:40,  1.12s/it, loss=0.7126, batch_acc=0.8750, running_acc=0.8485, grad=23.5378]Training epoch 17:  45%|████▍     | 73/163 [01:26<01:40,  1.12s/it, loss=0.7795, batch_acc=0.8750, running_acc=0.8489, grad=20.9719]Training epoch 17:  45%|████▌     | 74/163 [01:27<01:33,  1.05s/it, loss=0.7795, batch_acc=0.8750, running_acc=0.8489, grad=20.9719]Training epoch 17:  45%|████▌     | 74/163 [01:27<01:33,  1.05s/it, loss=0.5945, batch_acc=0.9062, running_acc=0.8497, grad=15.5452]Training epoch 17:  46%|████▌     | 75/163 [01:28<01:27,  1.00it/s, loss=0.5945, batch_acc=0.9062, running_acc=0.8497, grad=15.5452]Training epoch 17:  46%|████▌     | 75/163 [01:28<01:27,  1.00it/s, loss=1.0310, batch_acc=0.8125, running_acc=0.8492, grad=27.5886]Training epoch 17:  47%|████▋     | 76/163 [01:29<01:50,  1.27s/it, loss=1.0310, batch_acc=0.8125, running_acc=0.8492, grad=27.5886]Training epoch 17:  47%|████▋     | 76/163 [01:29<01:50,  1.27s/it, loss=0.9214, batch_acc=0.7812, running_acc=0.8483, grad=31.4752]Training epoch 17:  47%|████▋     | 77/163 [01:30<01:39,  1.15s/it, loss=0.9214, batch_acc=0.7812, running_acc=0.8483, grad=31.4752]Training epoch 17:  47%|████▋     | 77/163 [01:30<01:39,  1.15s/it, loss=0.7622, batch_acc=0.9375, running_acc=0.8494, grad=17.7788]Training epoch 17:  48%|████▊     | 78/163 [01:31<01:31,  1.07s/it, loss=0.7622, batch_acc=0.9375, running_acc=0.8494, grad=17.7788]Training epoch 17:  48%|████▊     | 78/163 [01:31<01:31,  1.07s/it, loss=0.6917, batch_acc=0.8750, running_acc=0.8498, grad=25.1877]Training epoch 17:  48%|████▊     | 79/163 [01:32<01:25,  1.01s/it, loss=0.6917, batch_acc=0.8750, running_acc=0.8498, grad=25.1877]Training epoch 17:  48%|████▊     | 79/163 [01:32<01:25,  1.01s/it, loss=0.8368, batch_acc=0.8438, running_acc=0.8497, grad=31.7649]Training epoch 17:  49%|████▉     | 80/163 [01:33<01:32,  1.12s/it, loss=0.8368, batch_acc=0.8438, running_acc=0.8497, grad=31.7649]Training epoch 17:  49%|████▉     | 80/163 [01:33<01:32,  1.12s/it, loss=0.8875, batch_acc=0.8438, running_acc=0.8496, grad=33.6570]Training epoch 17:  50%|████▉     | 81/163 [01:34<01:25,  1.05s/it, loss=0.8875, batch_acc=0.8438, running_acc=0.8496, grad=33.6570]Training epoch 17:  50%|████▉     | 81/163 [01:34<01:25,  1.05s/it, loss=0.7739, batch_acc=0.8750, running_acc=0.8499, grad=29.6188]Training epoch 17:  50%|█████     | 82/163 [01:35<01:20,  1.00it/s, loss=0.7739, batch_acc=0.8750, running_acc=0.8499, grad=29.6188]Training epoch 17:  50%|█████     | 82/163 [01:35<01:20,  1.00it/s, loss=0.8474, batch_acc=0.7500, running_acc=0.8487, grad=27.0095]Training epoch 17:  51%|█████     | 83/163 [01:36<01:16,  1.04it/s, loss=0.8474, batch_acc=0.7500, running_acc=0.8487, grad=27.0095]Training epoch 17:  51%|█████     | 83/163 [01:36<01:16,  1.04it/s, loss=0.8929, batch_acc=0.8750, running_acc=0.8490, grad=31.0696]Training epoch 17:  52%|█████▏    | 84/163 [01:38<01:32,  1.17s/it, loss=0.8929, batch_acc=0.8750, running_acc=0.8490, grad=31.0696]Training epoch 17:  52%|█████▏    | 84/163 [01:38<01:32,  1.17s/it, loss=0.9263, batch_acc=0.8438, running_acc=0.8490, grad=27.1358]Training epoch 17:  52%|█████▏    | 85/163 [01:39<01:24,  1.08s/it, loss=0.9263, batch_acc=0.8438, running_acc=0.8490, grad=27.1358]Training epoch 17:  52%|█████▏    | 85/163 [01:39<01:24,  1.08s/it, loss=0.7704, batch_acc=0.7500, running_acc=0.8478, grad=19.9071]Training epoch 17:  53%|█████▎    | 86/163 [01:40<01:18,  1.02s/it, loss=0.7704, batch_acc=0.7500, running_acc=0.8478, grad=19.9071]Training epoch 17:  53%|█████▎    | 86/163 [01:40<01:18,  1.02s/it, loss=0.8792, batch_acc=0.8750, running_acc=0.8481, grad=23.3633]Training epoch 17:  53%|█████▎    | 87/163 [01:40<01:14,  1.02it/s, loss=0.8792, batch_acc=0.8750, running_acc=0.8481, grad=23.3633]Training epoch 17:  53%|█████▎    | 87/163 [01:40<01:14,  1.02it/s, loss=0.8434, batch_acc=0.8750, running_acc=0.8484, grad=21.6882]Training epoch 17:  54%|█████▍    | 88/163 [01:42<01:27,  1.16s/it, loss=0.8434, batch_acc=0.8750, running_acc=0.8484, grad=21.6882]Training epoch 17:  54%|█████▍    | 88/163 [01:42<01:27,  1.16s/it, loss=0.7169, batch_acc=0.8750, running_acc=0.8487, grad=29.3668]Training epoch 17:  55%|█████▍    | 89/163 [01:43<01:19,  1.08s/it, loss=0.7169, batch_acc=0.8750, running_acc=0.8487, grad=29.3668]Training epoch 17:  55%|█████▍    | 89/163 [01:43<01:19,  1.08s/it, loss=0.8222, batch_acc=0.8125, running_acc=0.8483, grad=24.9228]Training epoch 17:  55%|█████▌    | 90/163 [01:44<01:14,  1.02s/it, loss=0.8222, batch_acc=0.8125, running_acc=0.8483, grad=24.9228]Training epoch 17:  55%|█████▌    | 90/163 [01:44<01:14,  1.02s/it, loss=0.8742, batch_acc=0.8125, running_acc=0.8479, grad=30.4727]Training epoch 17:  56%|█████▌    | 91/163 [01:45<01:10,  1.02it/s, loss=0.8742, batch_acc=0.8125, running_acc=0.8479, grad=30.4727]Training epoch 17:  56%|█████▌    | 91/163 [01:45<01:10,  1.02it/s, loss=0.9230, batch_acc=0.7500, running_acc=0.8468, grad=26.5618]Training epoch 17:  56%|█████▋    | 92/163 [01:46<01:27,  1.23s/it, loss=0.9230, batch_acc=0.7500, running_acc=0.8468, grad=26.5618]Training epoch 17:  56%|█████▋    | 92/163 [01:46<01:27,  1.23s/it, loss=0.5847, batch_acc=0.8750, running_acc=0.8471, grad=18.6657]Training epoch 17:  57%|█████▋    | 93/163 [01:47<01:18,  1.13s/it, loss=0.5847, batch_acc=0.8750, running_acc=0.8471, grad=18.6657]Training epoch 17:  57%|█████▋    | 93/163 [01:47<01:18,  1.13s/it, loss=0.8686, batch_acc=0.8438, running_acc=0.8471, grad=25.3017]Training epoch 17:  58%|█████▊    | 94/163 [01:48<01:12,  1.05s/it, loss=0.8686, batch_acc=0.8438, running_acc=0.8471, grad=25.3017]Training epoch 17:  58%|█████▊    | 94/163 [01:48<01:12,  1.05s/it, loss=1.1588, batch_acc=0.6875, running_acc=0.8454, grad=24.3090]Training epoch 17:  58%|█████▊    | 95/163 [01:49<01:08,  1.00s/it, loss=1.1588, batch_acc=0.6875, running_acc=0.8454, grad=24.3090]Training epoch 17:  58%|█████▊    | 95/163 [01:49<01:08,  1.00s/it, loss=0.9364, batch_acc=0.8438, running_acc=0.8454, grad=26.5898]Training epoch 17:  59%|█████▉    | 96/163 [01:51<01:21,  1.22s/it, loss=0.9364, batch_acc=0.8438, running_acc=0.8454, grad=26.5898]Training epoch 17:  59%|█████▉    | 96/163 [01:51<01:21,  1.22s/it, loss=0.8434, batch_acc=0.8750, running_acc=0.8457, grad=26.4813]Training epoch 17:  60%|█████▉    | 97/163 [01:52<01:13,  1.12s/it, loss=0.8434, batch_acc=0.8750, running_acc=0.8457, grad=26.4813]Training epoch 17:  60%|█████▉    | 97/163 [01:52<01:13,  1.12s/it, loss=0.6155, batch_acc=0.9062, running_acc=0.8463, grad=25.2951]Training epoch 17:  60%|██████    | 98/163 [01:53<01:08,  1.05s/it, loss=0.6155, batch_acc=0.9062, running_acc=0.8463, grad=25.2951]Training epoch 17:  60%|██████    | 98/163 [01:53<01:08,  1.05s/it, loss=0.7877, batch_acc=0.8750, running_acc=0.8466, grad=23.8859]Training epoch 17:  61%|██████    | 99/163 [01:54<01:03,  1.00it/s, loss=0.7877, batch_acc=0.8750, running_acc=0.8466, grad=23.8859]Training epoch 17:  61%|██████    | 99/163 [01:54<01:03,  1.00it/s, loss=0.9433, batch_acc=0.8125, running_acc=0.8463, grad=32.3105]Training epoch 17:  61%|██████▏   | 100/163 [01:55<01:11,  1.13s/it, loss=0.9433, batch_acc=0.8125, running_acc=0.8463, grad=32.3105]Training epoch 17:  61%|██████▏   | 100/163 [01:55<01:11,  1.13s/it, loss=0.7619, batch_acc=0.8750, running_acc=0.8466, grad=22.6901]Training epoch 17:  62%|██████▏   | 101/163 [01:56<01:05,  1.06s/it, loss=0.7619, batch_acc=0.8750, running_acc=0.8466, grad=22.6901]Training epoch 17:  62%|██████▏   | 101/163 [01:56<01:05,  1.06s/it, loss=1.0192, batch_acc=0.7812, running_acc=0.8459, grad=26.0908]Training epoch 17:  63%|██████▎   | 102/163 [01:57<01:01,  1.00s/it, loss=1.0192, batch_acc=0.7812, running_acc=0.8459, grad=26.0908]Training epoch 17:  63%|██████▎   | 102/163 [01:57<01:01,  1.00s/it, loss=0.6827, batch_acc=0.8750, running_acc=0.8462, grad=29.4692]Training epoch 17:  63%|██████▎   | 103/163 [01:58<00:58,  1.03it/s, loss=0.6827, batch_acc=0.8750, running_acc=0.8462, grad=29.4692]Training epoch 17:  63%|██████▎   | 103/163 [01:58<00:58,  1.03it/s, loss=0.6075, batch_acc=0.9062, running_acc=0.8468, grad=19.7761]Training epoch 17:  64%|██████▍   | 104/163 [01:59<01:08,  1.16s/it, loss=0.6075, batch_acc=0.9062, running_acc=0.8468, grad=19.7761]Training epoch 17:  64%|██████▍   | 104/163 [01:59<01:08,  1.16s/it, loss=0.8302, batch_acc=0.9062, running_acc=0.8474, grad=20.6793]Training epoch 17:  64%|██████▍   | 105/163 [02:00<01:02,  1.08s/it, loss=0.8302, batch_acc=0.9062, running_acc=0.8474, grad=20.6793]Training epoch 17:  64%|██████▍   | 105/163 [02:00<01:02,  1.08s/it, loss=0.9249, batch_acc=0.8125, running_acc=0.8470, grad=29.6696]Training epoch 17:  65%|██████▌   | 106/163 [02:01<00:58,  1.02s/it, loss=0.9249, batch_acc=0.8125, running_acc=0.8470, grad=29.6696]Training epoch 17:  65%|██████▌   | 106/163 [02:01<00:58,  1.02s/it, loss=0.7423, batch_acc=0.8125, running_acc=0.8467, grad=23.3919]Training epoch 17:  66%|██████▌   | 107/163 [02:02<00:54,  1.02it/s, loss=0.7423, batch_acc=0.8125, running_acc=0.8467, grad=23.3919]Training epoch 17:  66%|██████▌   | 107/163 [02:02<00:54,  1.02it/s, loss=0.7496, batch_acc=0.8438, running_acc=0.8467, grad=22.8540]Training epoch 17:  66%|██████▋   | 108/163 [02:04<01:09,  1.26s/it, loss=0.7496, batch_acc=0.8438, running_acc=0.8467, grad=22.8540]Training epoch 17:  66%|██████▋   | 108/163 [02:04<01:09,  1.26s/it, loss=0.6649, batch_acc=0.9375, running_acc=0.8475, grad=20.2304]Training epoch 17:  67%|██████▋   | 109/163 [02:05<01:01,  1.15s/it, loss=0.6649, batch_acc=0.9375, running_acc=0.8475, grad=20.2304]Training epoch 17:  67%|██████▋   | 109/163 [02:05<01:01,  1.15s/it, loss=0.7703, batch_acc=0.9062, running_acc=0.8481, grad=23.8246]Training epoch 17:  67%|██████▋   | 110/163 [02:06<00:56,  1.07s/it, loss=0.7703, batch_acc=0.9062, running_acc=0.8481, grad=23.8246]Training epoch 17:  67%|██████▋   | 110/163 [02:06<00:56,  1.07s/it, loss=0.8622, batch_acc=0.8125, running_acc=0.8477, grad=26.2179]Training epoch 17:  68%|██████▊   | 111/163 [02:06<00:52,  1.01s/it, loss=0.8622, batch_acc=0.8125, running_acc=0.8477, grad=26.2179]Training epoch 17:  68%|██████▊   | 111/163 [02:06<00:52,  1.01s/it, loss=0.9614, batch_acc=0.8438, running_acc=0.8477, grad=27.3012]Training epoch 17:  69%|██████▊   | 112/163 [02:08<01:05,  1.28s/it, loss=0.9614, batch_acc=0.8438, running_acc=0.8477, grad=27.3012]Training epoch 17:  69%|██████▊   | 112/163 [02:08<01:05,  1.28s/it, loss=0.9891, batch_acc=0.7188, running_acc=0.8465, grad=25.9527]Training epoch 17:  69%|██████▉   | 113/163 [02:09<00:58,  1.16s/it, loss=0.9891, batch_acc=0.7188, running_acc=0.8465, grad=25.9527]Training epoch 17:  69%|██████▉   | 113/163 [02:09<00:58,  1.16s/it, loss=0.6438, batch_acc=0.9375, running_acc=0.8473, grad=17.1711]Training epoch 17:  70%|██████▉   | 114/163 [02:10<00:52,  1.08s/it, loss=0.6438, batch_acc=0.9375, running_acc=0.8473, grad=17.1711]Training epoch 17:  70%|██████▉   | 114/163 [02:10<00:52,  1.08s/it, loss=0.7673, batch_acc=0.8438, running_acc=0.8473, grad=23.5941]Training epoch 17:  71%|███████   | 115/163 [02:11<00:48,  1.02s/it, loss=0.7673, batch_acc=0.8438, running_acc=0.8473, grad=23.5941]Training epoch 17:  71%|███████   | 115/163 [02:11<00:48,  1.02s/it, loss=0.8918, batch_acc=0.8438, running_acc=0.8473, grad=26.8904]Training epoch 17:  71%|███████   | 116/163 [02:13<00:55,  1.18s/it, loss=0.8918, batch_acc=0.8438, running_acc=0.8473, grad=26.8904]Training epoch 17:  71%|███████   | 116/163 [02:13<00:55,  1.18s/it, loss=0.7109, batch_acc=0.8438, running_acc=0.8473, grad=19.9645]Training epoch 17:  72%|███████▏  | 117/163 [02:13<00:50,  1.09s/it, loss=0.7109, batch_acc=0.8438, running_acc=0.8473, grad=19.9645]Training epoch 17:  72%|███████▏  | 117/163 [02:13<00:50,  1.09s/it, loss=0.8778, batch_acc=0.9062, running_acc=0.8478, grad=27.7220]Training epoch 17:  72%|███████▏  | 118/163 [02:14<00:46,  1.03s/it, loss=0.8778, batch_acc=0.9062, running_acc=0.8478, grad=27.7220]Training epoch 17:  72%|███████▏  | 118/163 [02:14<00:46,  1.03s/it, loss=0.6397, batch_acc=0.9062, running_acc=0.8483, grad=19.3858]Training epoch 17:  73%|███████▎  | 119/163 [02:15<00:43,  1.02it/s, loss=0.6397, batch_acc=0.9062, running_acc=0.8483, grad=19.3858]Training epoch 17:  73%|███████▎  | 119/163 [02:15<00:43,  1.02it/s, loss=0.6953, batch_acc=0.8750, running_acc=0.8485, grad=23.4057]Training epoch 17:  74%|███████▎  | 120/163 [02:17<00:49,  1.15s/it, loss=0.6953, batch_acc=0.8750, running_acc=0.8485, grad=23.4057]Training epoch 17:  74%|███████▎  | 120/163 [02:17<00:49,  1.15s/it, loss=0.7446, batch_acc=0.9062, running_acc=0.8490, grad=21.2021]Training epoch 17:  74%|███████▍  | 121/163 [02:18<00:44,  1.07s/it, loss=0.7446, batch_acc=0.9062, running_acc=0.8490, grad=21.2021]Training epoch 17:  74%|███████▍  | 121/163 [02:18<00:44,  1.07s/it, loss=0.6232, batch_acc=0.9375, running_acc=0.8497, grad=23.0726]Training epoch 17:  75%|███████▍  | 122/163 [02:18<00:41,  1.01s/it, loss=0.6232, batch_acc=0.9375, running_acc=0.8497, grad=23.0726]Training epoch 17:  75%|███████▍  | 122/163 [02:18<00:41,  1.01s/it, loss=0.9547, batch_acc=0.8750, running_acc=0.8499, grad=31.0685]Training epoch 17:  75%|███████▌  | 123/163 [02:19<00:38,  1.03it/s, loss=0.9547, batch_acc=0.8750, running_acc=0.8499, grad=31.0685]Training epoch 17:  75%|███████▌  | 123/163 [02:19<00:38,  1.03it/s, loss=0.6727, batch_acc=0.9062, running_acc=0.8504, grad=21.8424]Training epoch 17:  76%|███████▌  | 124/163 [02:21<00:45,  1.17s/it, loss=0.6727, batch_acc=0.9062, running_acc=0.8504, grad=21.8424]Training epoch 17:  76%|███████▌  | 124/163 [02:21<00:45,  1.17s/it, loss=0.8474, batch_acc=0.8438, running_acc=0.8503, grad=23.3078]Training epoch 17:  77%|███████▋  | 125/163 [02:22<00:41,  1.08s/it, loss=0.8474, batch_acc=0.8438, running_acc=0.8503, grad=23.3078]Training epoch 17:  77%|███████▋  | 125/163 [02:22<00:41,  1.08s/it, loss=0.7614, batch_acc=0.8750, running_acc=0.8505, grad=22.1463]Training epoch 17:  77%|███████▋  | 126/163 [02:23<00:37,  1.02s/it, loss=0.7614, batch_acc=0.8750, running_acc=0.8505, grad=22.1463]Training epoch 17:  77%|███████▋  | 126/163 [02:23<00:37,  1.02s/it, loss=0.8706, batch_acc=0.8438, running_acc=0.8504, grad=29.1086]Training epoch 17:  78%|███████▊  | 127/163 [02:24<00:35,  1.02it/s, loss=0.8706, batch_acc=0.8438, running_acc=0.8504, grad=29.1086]Training epoch 17:  78%|███████▊  | 127/163 [02:24<00:35,  1.02it/s, loss=0.7748, batch_acc=0.8750, running_acc=0.8506, grad=19.7614]Training epoch 17:  79%|███████▊  | 128/163 [02:25<00:42,  1.20s/it, loss=0.7748, batch_acc=0.8750, running_acc=0.8506, grad=19.7614]Training epoch 17:  79%|███████▊  | 128/163 [02:25<00:42,  1.20s/it, loss=0.8548, batch_acc=0.8750, running_acc=0.8508, grad=30.8948]Training epoch 17:  79%|███████▉  | 129/163 [02:26<00:37,  1.11s/it, loss=0.8548, batch_acc=0.8750, running_acc=0.8508, grad=30.8948]Training epoch 17:  79%|███████▉  | 129/163 [02:26<00:37,  1.11s/it, loss=0.9190, batch_acc=0.8125, running_acc=0.8505, grad=30.5696]Training epoch 17:  80%|███████▉  | 130/163 [02:27<00:34,  1.04s/it, loss=0.9190, batch_acc=0.8125, running_acc=0.8505, grad=30.5696]Training epoch 17:  80%|███████▉  | 130/163 [02:27<00:34,  1.04s/it, loss=0.5029, batch_acc=0.9375, running_acc=0.8512, grad=16.2901]Training epoch 17:  80%|████████  | 131/163 [02:28<00:31,  1.01it/s, loss=0.5029, batch_acc=0.9375, running_acc=0.8512, grad=16.2901]Training epoch 17:  80%|████████  | 131/163 [02:28<00:31,  1.01it/s, loss=0.7415, batch_acc=0.8438, running_acc=0.8511, grad=23.2518]Training epoch 17:  81%|████████  | 132/163 [02:29<00:34,  1.12s/it, loss=0.7415, batch_acc=0.8438, running_acc=0.8511, grad=23.2518]Training epoch 17:  81%|████████  | 132/163 [02:29<00:34,  1.12s/it, loss=0.7438, batch_acc=0.9062, running_acc=0.8516, grad=26.0376]Training epoch 17:  82%|████████▏ | 133/163 [02:30<00:31,  1.05s/it, loss=0.7438, batch_acc=0.9062, running_acc=0.8516, grad=26.0376]Training epoch 17:  82%|████████▏ | 133/163 [02:30<00:31,  1.05s/it, loss=0.7148, batch_acc=0.9062, running_acc=0.8520, grad=22.6385]Training epoch 17:  82%|████████▏ | 134/163 [02:31<00:28,  1.00it/s, loss=0.7148, batch_acc=0.9062, running_acc=0.8520, grad=22.6385]Training epoch 17:  82%|████████▏ | 134/163 [02:31<00:28,  1.00it/s, loss=0.7405, batch_acc=0.8438, running_acc=0.8519, grad=22.0726]Training epoch 17:  83%|████████▎ | 135/163 [02:32<00:26,  1.04it/s, loss=0.7405, batch_acc=0.8438, running_acc=0.8519, grad=22.0726]Training epoch 17:  83%|████████▎ | 135/163 [02:32<00:26,  1.04it/s, loss=0.8976, batch_acc=0.8438, running_acc=0.8519, grad=24.6873]Training epoch 17:  83%|████████▎ | 136/163 [02:34<00:31,  1.18s/it, loss=0.8976, batch_acc=0.8438, running_acc=0.8519, grad=24.6873]Training epoch 17:  83%|████████▎ | 136/163 [02:34<00:31,  1.18s/it, loss=0.7464, batch_acc=0.8438, running_acc=0.8518, grad=28.5800]Training epoch 17:  84%|████████▍ | 137/163 [02:35<00:28,  1.09s/it, loss=0.7464, batch_acc=0.8438, running_acc=0.8518, grad=28.5800]Training epoch 17:  84%|████████▍ | 137/163 [02:35<00:28,  1.09s/it, loss=0.8752, batch_acc=0.7188, running_acc=0.8508, grad=28.4407]Training epoch 17:  85%|████████▍ | 138/163 [02:35<00:25,  1.03s/it, loss=0.8752, batch_acc=0.7188, running_acc=0.8508, grad=28.4407]Training epoch 17:  85%|████████▍ | 138/163 [02:35<00:25,  1.03s/it, loss=0.8710, batch_acc=0.8438, running_acc=0.8508, grad=26.9874]Training epoch 17:  85%|████████▌ | 139/163 [02:36<00:23,  1.02it/s, loss=0.8710, batch_acc=0.8438, running_acc=0.8508, grad=26.9874]Training epoch 17:  85%|████████▌ | 139/163 [02:36<00:23,  1.02it/s, loss=0.8141, batch_acc=0.7812, running_acc=0.8503, grad=40.2019]Training epoch 17:  86%|████████▌ | 140/163 [02:38<00:28,  1.26s/it, loss=0.8141, batch_acc=0.7812, running_acc=0.8503, grad=40.2019]Training epoch 17:  86%|████████▌ | 140/163 [02:38<00:28,  1.26s/it, loss=0.6598, batch_acc=0.9062, running_acc=0.8507, grad=22.9116]Training epoch 17:  87%|████████▋ | 141/163 [02:39<00:25,  1.14s/it, loss=0.6598, batch_acc=0.9062, running_acc=0.8507, grad=22.9116]Training epoch 17:  87%|████████▋ | 141/163 [02:39<00:25,  1.14s/it, loss=0.9405, batch_acc=0.7812, running_acc=0.8502, grad=24.7363]Training epoch 17:  87%|████████▋ | 142/163 [02:40<00:22,  1.07s/it, loss=0.9405, batch_acc=0.7812, running_acc=0.8502, grad=24.7363]Training epoch 17:  87%|████████▋ | 142/163 [02:40<00:22,  1.07s/it, loss=0.8270, batch_acc=0.8750, running_acc=0.8504, grad=27.1859]Training epoch 17:  88%|████████▊ | 143/163 [02:41<00:20,  1.01s/it, loss=0.8270, batch_acc=0.8750, running_acc=0.8504, grad=27.1859]Training epoch 17:  88%|████████▊ | 143/163 [02:41<00:20,  1.01s/it, loss=0.6857, batch_acc=0.8750, running_acc=0.8505, grad=19.2391]Training epoch 17:  88%|████████▊ | 144/163 [02:43<00:25,  1.32s/it, loss=0.6857, batch_acc=0.8750, running_acc=0.8505, grad=19.2391]Training epoch 17:  88%|████████▊ | 144/163 [02:43<00:25,  1.32s/it, loss=0.6789, batch_acc=0.9062, running_acc=0.8509, grad=21.7548]Training epoch 17:  89%|████████▉ | 145/163 [02:44<00:21,  1.19s/it, loss=0.6789, batch_acc=0.9062, running_acc=0.8509, grad=21.7548]Training epoch 17:  89%|████████▉ | 145/163 [02:44<00:21,  1.19s/it, loss=0.9395, batch_acc=0.7188, running_acc=0.8500, grad=28.8352]Training epoch 17:  90%|████████▉ | 146/163 [02:45<00:18,  1.09s/it, loss=0.9395, batch_acc=0.7188, running_acc=0.8500, grad=28.8352]Training epoch 17:  90%|████████▉ | 146/163 [02:45<00:18,  1.09s/it, loss=0.7290, batch_acc=0.8750, running_acc=0.8502, grad=25.6526]Training epoch 17:  90%|█████████ | 147/163 [02:46<00:16,  1.03s/it, loss=0.7290, batch_acc=0.8750, running_acc=0.8502, grad=25.6526]Training epoch 17:  90%|█████████ | 147/163 [02:46<00:16,  1.03s/it, loss=0.6879, batch_acc=0.8750, running_acc=0.8503, grad=23.4775]Training epoch 17:  91%|█████████ | 148/163 [02:47<00:19,  1.30s/it, loss=0.6879, batch_acc=0.8750, running_acc=0.8503, grad=23.4775]Training epoch 17:  91%|█████████ | 148/163 [02:47<00:19,  1.30s/it, loss=0.7077, batch_acc=0.8750, running_acc=0.8505, grad=25.4913]Training epoch 17:  91%|█████████▏| 149/163 [02:48<00:16,  1.17s/it, loss=0.7077, batch_acc=0.8750, running_acc=0.8505, grad=25.4913]Training epoch 17:  91%|█████████▏| 149/163 [02:48<00:16,  1.17s/it, loss=0.7451, batch_acc=0.8438, running_acc=0.8505, grad=20.7072]Training epoch 17:  92%|█████████▏| 150/163 [02:49<00:14,  1.08s/it, loss=0.7451, batch_acc=0.8438, running_acc=0.8505, grad=20.7072]Training epoch 17:  92%|█████████▏| 150/163 [02:49<00:14,  1.08s/it, loss=0.7226, batch_acc=0.8438, running_acc=0.8504, grad=23.2090]Training epoch 17:  93%|█████████▎| 151/163 [02:50<00:12,  1.02s/it, loss=0.7226, batch_acc=0.8438, running_acc=0.8504, grad=23.2090]Training epoch 17:  93%|█████████▎| 151/163 [02:50<00:12,  1.02s/it, loss=0.8502, batch_acc=0.8125, running_acc=0.8502, grad=24.7978]Training epoch 17:  93%|█████████▎| 152/163 [02:52<00:13,  1.20s/it, loss=0.8502, batch_acc=0.8125, running_acc=0.8502, grad=24.7978]Training epoch 17:  93%|█████████▎| 152/163 [02:52<00:13,  1.20s/it, loss=0.5697, batch_acc=0.9375, running_acc=0.8507, grad=20.5440]Training epoch 17:  94%|█████████▍| 153/163 [02:53<00:11,  1.11s/it, loss=0.5697, batch_acc=0.9375, running_acc=0.8507, grad=20.5440]Training epoch 17:  94%|█████████▍| 153/163 [02:53<00:11,  1.11s/it, loss=0.7824, batch_acc=0.8438, running_acc=0.8507, grad=26.3830]Training epoch 17:  94%|█████████▍| 154/163 [02:54<00:09,  1.04s/it, loss=0.7824, batch_acc=0.8438, running_acc=0.8507, grad=26.3830]Training epoch 17:  94%|█████████▍| 154/163 [02:54<00:09,  1.04s/it, loss=0.8225, batch_acc=0.8438, running_acc=0.8506, grad=22.6258]Training epoch 17:  95%|█████████▌| 155/163 [02:54<00:07,  1.01it/s, loss=0.8225, batch_acc=0.8438, running_acc=0.8506, grad=22.6258]Training epoch 17:  95%|█████████▌| 155/163 [02:54<00:07,  1.01it/s, loss=0.9544, batch_acc=0.7812, running_acc=0.8502, grad=39.2599]Training epoch 17:  96%|█████████▌| 156/163 [02:56<00:08,  1.18s/it, loss=0.9544, batch_acc=0.7812, running_acc=0.8502, grad=39.2599]Training epoch 17:  96%|█████████▌| 156/163 [02:56<00:08,  1.18s/it, loss=0.4955, batch_acc=0.9062, running_acc=0.8506, grad=20.4604]Training epoch 17:  96%|█████████▋| 157/163 [02:57<00:06,  1.09s/it, loss=0.4955, batch_acc=0.9062, running_acc=0.8506, grad=20.4604]Training epoch 17:  96%|█████████▋| 157/163 [02:57<00:06,  1.09s/it, loss=0.8462, batch_acc=0.8438, running_acc=0.8505, grad=24.9316]Training epoch 17:  97%|█████████▋| 158/163 [02:58<00:05,  1.03s/it, loss=0.8462, batch_acc=0.8438, running_acc=0.8505, grad=24.9316]Training epoch 17:  97%|█████████▋| 158/163 [02:58<00:05,  1.03s/it, loss=0.6904, batch_acc=0.8750, running_acc=0.8507, grad=22.7521]Training epoch 17:  98%|█████████▊| 159/163 [02:59<00:03,  1.02it/s, loss=0.6904, batch_acc=0.8750, running_acc=0.8507, grad=22.7521]Training epoch 17:  98%|█████████▊| 159/163 [02:59<00:03,  1.02it/s, loss=0.8057, batch_acc=0.8750, running_acc=0.8508, grad=31.2027]Training epoch 17:  98%|█████████▊| 160/163 [03:01<00:04,  1.35s/it, loss=0.8057, batch_acc=0.8750, running_acc=0.8508, grad=31.2027]Training epoch 17:  98%|█████████▊| 160/163 [03:01<00:04,  1.35s/it, loss=0.6543, batch_acc=0.8750, running_acc=0.8510, grad=19.6386]Training epoch 17:  99%|█████████▉| 161/163 [03:02<00:02,  1.21s/it, loss=0.6543, batch_acc=0.8750, running_acc=0.8510, grad=19.6386]Training epoch 17:  99%|█████████▉| 161/163 [03:02<00:02,  1.21s/it, loss=0.9191, batch_acc=0.7812, running_acc=0.8505, grad=22.8084]Training epoch 17:  99%|█████████▉| 162/163 [03:03<00:01,  1.11s/it, loss=0.9191, batch_acc=0.7812, running_acc=0.8505, grad=22.8084]Training epoch 17:  99%|█████████▉| 162/163 [03:03<00:01,  1.11s/it, loss=0.9802, batch_acc=0.7812, running_acc=0.8501, grad=30.7610]Training epoch 17: 100%|██████████| 163/163 [03:03<00:00,  1.03it/s, loss=0.9802, batch_acc=0.7812, running_acc=0.8501, grad=30.7610]Training epoch 17: 100%|██████████| 163/163 [03:03<00:00,  1.03it/s, loss=0.6894, batch_acc=0.9524, running_acc=0.8505, grad=33.8386]Training epoch 17: 100%|██████████| 163/163 [03:03<00:00,  1.13s/it, loss=0.6894, batch_acc=0.9524, running_acc=0.8505, grad=33.8386]
Evaluation epoch 17:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 17:   4%|▎         | 1/28 [00:05<02:21,  5.26s/it]Evaluation epoch 17:   4%|▎         | 1/28 [00:05<02:21,  5.26s/it, loss=0.7858, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 17:   7%|▋         | 2/28 [00:05<01:00,  2.32s/it, loss=0.7858, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 17:   7%|▋         | 2/28 [00:05<01:00,  2.32s/it, loss=0.9165, batch_acc=0.8750, running_acc=0.8594]Evaluation epoch 17:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=0.9165, batch_acc=0.8750, running_acc=0.8594]Evaluation epoch 17:  11%|█         | 3/28 [00:05<00:34,  1.38s/it, loss=0.8282, batch_acc=0.8438, running_acc=0.8542]Evaluation epoch 17:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=0.8282, batch_acc=0.8438, running_acc=0.8542]Evaluation epoch 17:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=1.3170, batch_acc=0.6250, running_acc=0.7969]Evaluation epoch 17:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.3170, batch_acc=0.6250, running_acc=0.7969]Evaluation epoch 17:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.7093, batch_acc=0.5312, running_acc=0.7438]Evaluation epoch 17:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.7093, batch_acc=0.5312, running_acc=0.7438]Evaluation epoch 17:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.0373, batch_acc=0.8125, running_acc=0.7552]Evaluation epoch 17:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=1.0373, batch_acc=0.8125, running_acc=0.7552]Evaluation epoch 17:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=1.3242, batch_acc=0.7188, running_acc=0.7500]Evaluation epoch 17:  29%|██▊       | 8/28 [00:14<00:35,  1.76s/it, loss=1.3242, batch_acc=0.7188, running_acc=0.7500]Evaluation epoch 17:  29%|██▊       | 8/28 [00:14<00:35,  1.76s/it, loss=0.7599, batch_acc=0.7812, running_acc=0.7539]Evaluation epoch 17:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.7599, batch_acc=0.7812, running_acc=0.7539]Evaluation epoch 17:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=1.2144, batch_acc=0.7812, running_acc=0.7569]Evaluation epoch 17:  36%|███▌      | 10/28 [00:15<00:17,  1.02it/s, loss=1.2144, batch_acc=0.7812, running_acc=0.7569]Evaluation epoch 17:  36%|███▌      | 10/28 [00:15<00:17,  1.02it/s, loss=0.7130, batch_acc=0.9062, running_acc=0.7719]Evaluation epoch 17:  39%|███▉      | 11/28 [00:15<00:12,  1.32it/s, loss=0.7130, batch_acc=0.9062, running_acc=0.7719]Evaluation epoch 17:  39%|███▉      | 11/28 [00:15<00:12,  1.32it/s, loss=0.9176, batch_acc=0.8125, running_acc=0.7756]Evaluation epoch 17:  43%|████▎     | 12/28 [00:20<00:36,  2.25s/it, loss=0.9176, batch_acc=0.8125, running_acc=0.7756]Evaluation epoch 17:  43%|████▎     | 12/28 [00:20<00:36,  2.25s/it, loss=1.3888, batch_acc=0.5938, running_acc=0.7604]Evaluation epoch 17:  46%|████▋     | 13/28 [00:21<00:24,  1.65s/it, loss=1.3888, batch_acc=0.5938, running_acc=0.7604]Evaluation epoch 17:  46%|████▋     | 13/28 [00:21<00:24,  1.65s/it, loss=0.7066, batch_acc=0.8750, running_acc=0.7692]Evaluation epoch 17:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=0.7066, batch_acc=0.8750, running_acc=0.7692]Evaluation epoch 17:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=1.6791, batch_acc=0.6562, running_acc=0.7612]Evaluation epoch 17:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.6791, batch_acc=0.6562, running_acc=0.7612]Evaluation epoch 17:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.9779, batch_acc=0.4062, running_acc=0.7375]Evaluation epoch 17:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=1.9779, batch_acc=0.4062, running_acc=0.7375]Evaluation epoch 17:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=1.5636, batch_acc=0.5312, running_acc=0.7246]Evaluation epoch 17:  61%|██████    | 17/28 [00:25<00:12,  1.17s/it, loss=1.5636, batch_acc=0.5312, running_acc=0.7246]Evaluation epoch 17:  61%|██████    | 17/28 [00:25<00:12,  1.17s/it, loss=1.2538, batch_acc=0.5312, running_acc=0.7132]Evaluation epoch 17:  64%|██████▍   | 18/28 [00:25<00:08,  1.11it/s, loss=1.2538, batch_acc=0.5312, running_acc=0.7132]Evaluation epoch 17:  64%|██████▍   | 18/28 [00:25<00:08,  1.11it/s, loss=0.8717, batch_acc=0.7812, running_acc=0.7170]Evaluation epoch 17:  68%|██████▊   | 19/28 [00:25<00:06,  1.41it/s, loss=0.8717, batch_acc=0.7812, running_acc=0.7170]Evaluation epoch 17:  68%|██████▊   | 19/28 [00:25<00:06,  1.41it/s, loss=1.1520, batch_acc=0.7188, running_acc=0.7171]Evaluation epoch 17:  71%|███████▏  | 20/28 [00:28<00:11,  1.38s/it, loss=1.1520, batch_acc=0.7188, running_acc=0.7171]Evaluation epoch 17:  71%|███████▏  | 20/28 [00:28<00:11,  1.38s/it, loss=1.0223, batch_acc=0.8125, running_acc=0.7219]Evaluation epoch 17:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=1.0223, batch_acc=0.8125, running_acc=0.7219]Evaluation epoch 17:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=1.1850, batch_acc=0.7500, running_acc=0.7232]Evaluation epoch 17:  79%|███████▊  | 22/28 [00:29<00:04,  1.24it/s, loss=1.1850, batch_acc=0.7500, running_acc=0.7232]Evaluation epoch 17:  79%|███████▊  | 22/28 [00:29<00:04,  1.24it/s, loss=1.4014, batch_acc=0.6562, running_acc=0.7202]Evaluation epoch 17:  82%|████████▏ | 23/28 [00:29<00:03,  1.55it/s, loss=1.4014, batch_acc=0.6562, running_acc=0.7202]Evaluation epoch 17:  82%|████████▏ | 23/28 [00:29<00:03,  1.55it/s, loss=1.3087, batch_acc=0.6562, running_acc=0.7174]Evaluation epoch 17:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=1.3087, batch_acc=0.6562, running_acc=0.7174]Evaluation epoch 17:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=0.6495, batch_acc=0.8438, running_acc=0.7227]Evaluation epoch 17:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.6495, batch_acc=0.8438, running_acc=0.7227]Evaluation epoch 17:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.5625, batch_acc=0.9062, running_acc=0.7300]Evaluation epoch 17:  93%|█████████▎| 26/28 [00:35<00:02,  1.15s/it, loss=0.5625, batch_acc=0.9062, running_acc=0.7300]Evaluation epoch 17:  93%|█████████▎| 26/28 [00:35<00:02,  1.15s/it, loss=1.0597, batch_acc=0.6562, running_acc=0.7272]Evaluation epoch 17:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.0597, batch_acc=0.6562, running_acc=0.7272]Evaluation epoch 17:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.3946, batch_acc=0.5938, running_acc=0.7222]Evaluation epoch 17: 100%|██████████| 28/28 [00:35<00:00,  1.13it/s, loss=1.8611, batch_acc=0.3333, running_acc=0.7209]Evaluation epoch 17: 100%|██████████| 28/28 [00:35<00:00,  1.27s/it, loss=1.8611, batch_acc=0.3333, running_acc=0.7209]
Training epoch 18:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 18:   1%|          | 1/163 [00:05<15:14,  5.64s/it]Training epoch 18:   1%|          | 1/163 [00:05<15:14,  5.64s/it, loss=1.0133, batch_acc=0.7812, running_acc=0.7812, grad=23.2213]Training epoch 18:   1%|          | 2/163 [00:06<07:37,  2.84s/it, loss=1.0133, batch_acc=0.7812, running_acc=0.7812, grad=23.2213]Training epoch 18:   1%|          | 2/163 [00:06<07:37,  2.84s/it, loss=0.6330, batch_acc=0.8750, running_acc=0.8281, grad=21.3534]Training epoch 18:   2%|▏         | 3/163 [00:07<05:11,  1.95s/it, loss=0.6330, batch_acc=0.8750, running_acc=0.8281, grad=21.3534]Training epoch 18:   2%|▏         | 3/163 [00:07<05:11,  1.95s/it, loss=0.7698, batch_acc=0.9062, running_acc=0.8542, grad=21.8885]Training epoch 18:   2%|▏         | 4/163 [00:10<06:11,  2.34s/it, loss=0.7698, batch_acc=0.9062, running_acc=0.8542, grad=21.8885]Training epoch 18:   2%|▏         | 4/163 [00:10<06:11,  2.34s/it, loss=0.6790, batch_acc=0.9062, running_acc=0.8672, grad=22.9851]Training epoch 18:   3%|▎         | 5/163 [00:11<04:46,  1.81s/it, loss=0.6790, batch_acc=0.9062, running_acc=0.8672, grad=22.9851]Training epoch 18:   3%|▎         | 5/163 [00:11<04:46,  1.81s/it, loss=0.5467, batch_acc=0.9062, running_acc=0.8750, grad=17.1160]Training epoch 18:   4%|▎         | 6/163 [00:12<03:59,  1.53s/it, loss=0.5467, batch_acc=0.9062, running_acc=0.8750, grad=17.1160]Training epoch 18:   4%|▎         | 6/163 [00:12<03:59,  1.53s/it, loss=0.7727, batch_acc=0.8438, running_acc=0.8698, grad=26.4989]Training epoch 18:   4%|▍         | 7/163 [00:13<03:25,  1.31s/it, loss=0.7727, batch_acc=0.8438, running_acc=0.8698, grad=26.4989]Training epoch 18:   4%|▍         | 7/163 [00:13<03:25,  1.31s/it, loss=0.7861, batch_acc=0.8750, running_acc=0.8705, grad=22.7589]Training epoch 18:   5%|▍         | 8/163 [00:14<03:50,  1.49s/it, loss=0.7861, batch_acc=0.8750, running_acc=0.8705, grad=22.7589]Training epoch 18:   5%|▍         | 8/163 [00:14<03:50,  1.49s/it, loss=0.7388, batch_acc=0.8125, running_acc=0.8633, grad=25.8703]Training epoch 18:   6%|▌         | 9/163 [00:15<03:19,  1.30s/it, loss=0.7388, batch_acc=0.8125, running_acc=0.8633, grad=25.8703]Training epoch 18:   6%|▌         | 9/163 [00:15<03:19,  1.30s/it, loss=0.7921, batch_acc=0.8125, running_acc=0.8576, grad=22.8165]Training epoch 18:   6%|▌         | 10/163 [00:16<02:58,  1.17s/it, loss=0.7921, batch_acc=0.8125, running_acc=0.8576, grad=22.8165]Training epoch 18:   6%|▌         | 10/163 [00:16<02:58,  1.17s/it, loss=0.8723, batch_acc=0.7812, running_acc=0.8500, grad=23.9761]Training epoch 18:   7%|▋         | 11/163 [00:17<02:44,  1.08s/it, loss=0.8723, batch_acc=0.7812, running_acc=0.8500, grad=23.9761]Training epoch 18:   7%|▋         | 11/163 [00:17<02:44,  1.08s/it, loss=0.6989, batch_acc=0.9062, running_acc=0.8551, grad=21.0693]Training epoch 18:   7%|▋         | 12/163 [00:19<03:13,  1.28s/it, loss=0.6989, batch_acc=0.9062, running_acc=0.8551, grad=21.0693]Training epoch 18:   7%|▋         | 12/163 [00:19<03:13,  1.28s/it, loss=0.7870, batch_acc=0.8438, running_acc=0.8542, grad=28.8966]Training epoch 18:   8%|▊         | 13/163 [00:20<02:53,  1.16s/it, loss=0.7870, batch_acc=0.8438, running_acc=0.8542, grad=28.8966]Training epoch 18:   8%|▊         | 13/163 [00:20<02:53,  1.16s/it, loss=0.6921, batch_acc=0.8750, running_acc=0.8558, grad=24.9042]Training epoch 18:   9%|▊         | 14/163 [00:21<02:40,  1.07s/it, loss=0.6921, batch_acc=0.8750, running_acc=0.8558, grad=24.9042]Training epoch 18:   9%|▊         | 14/163 [00:21<02:40,  1.07s/it, loss=0.5234, batch_acc=0.9688, running_acc=0.8638, grad=15.2927]Training epoch 18:   9%|▉         | 15/163 [00:21<02:30,  1.02s/it, loss=0.5234, batch_acc=0.9688, running_acc=0.8638, grad=15.2927]Training epoch 18:   9%|▉         | 15/163 [00:21<02:30,  1.02s/it, loss=0.6670, batch_acc=0.8438, running_acc=0.8625, grad=24.7643]Training epoch 18:  10%|▉         | 16/163 [00:23<02:59,  1.22s/it, loss=0.6670, batch_acc=0.8438, running_acc=0.8625, grad=24.7643]Training epoch 18:  10%|▉         | 16/163 [00:23<02:59,  1.22s/it, loss=0.6173, batch_acc=0.9375, running_acc=0.8672, grad=17.5605]Training epoch 18:  10%|█         | 17/163 [00:24<02:43,  1.12s/it, loss=0.6173, batch_acc=0.9375, running_acc=0.8672, grad=17.5605]Training epoch 18:  10%|█         | 17/163 [00:24<02:43,  1.12s/it, loss=0.8590, batch_acc=0.8438, running_acc=0.8658, grad=24.5931]Training epoch 18:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.8590, batch_acc=0.8438, running_acc=0.8658, grad=24.5931]Training epoch 18:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.7194, batch_acc=0.7812, running_acc=0.8611, grad=25.2702]Training epoch 18:  12%|█▏        | 19/163 [00:26<02:23,  1.00it/s, loss=0.7194, batch_acc=0.7812, running_acc=0.8611, grad=25.2702]Training epoch 18:  12%|█▏        | 19/163 [00:26<02:23,  1.00it/s, loss=0.5982, batch_acc=0.8438, running_acc=0.8602, grad=25.1595]Training epoch 18:  12%|█▏        | 20/163 [00:28<03:06,  1.30s/it, loss=0.5982, batch_acc=0.8438, running_acc=0.8602, grad=25.1595]Training epoch 18:  12%|█▏        | 20/163 [00:28<03:06,  1.30s/it, loss=0.9879, batch_acc=0.7812, running_acc=0.8562, grad=30.0631]Training epoch 18:  13%|█▎        | 21/163 [00:29<02:47,  1.18s/it, loss=0.9879, batch_acc=0.7812, running_acc=0.8562, grad=30.0631]Training epoch 18:  13%|█▎        | 21/163 [00:29<02:47,  1.18s/it, loss=0.6275, batch_acc=0.9375, running_acc=0.8601, grad=24.8214]Training epoch 18:  13%|█▎        | 22/163 [00:30<02:33,  1.09s/it, loss=0.6275, batch_acc=0.9375, running_acc=0.8601, grad=24.8214]Training epoch 18:  13%|█▎        | 22/163 [00:30<02:33,  1.09s/it, loss=0.7703, batch_acc=0.8750, running_acc=0.8608, grad=30.7244]Training epoch 18:  14%|█▍        | 23/163 [00:30<02:23,  1.03s/it, loss=0.7703, batch_acc=0.8750, running_acc=0.8608, grad=30.7244]Training epoch 18:  14%|█▍        | 23/163 [00:30<02:23,  1.03s/it, loss=0.6863, batch_acc=0.9688, running_acc=0.8655, grad=21.8128]Training epoch 18:  15%|█▍        | 24/163 [00:33<03:20,  1.44s/it, loss=0.6863, batch_acc=0.9688, running_acc=0.8655, grad=21.8128]Training epoch 18:  15%|█▍        | 24/163 [00:33<03:20,  1.44s/it, loss=0.8026, batch_acc=0.9062, running_acc=0.8672, grad=24.6315]Training epoch 18:  15%|█▌        | 25/163 [00:34<02:55,  1.27s/it, loss=0.8026, batch_acc=0.9062, running_acc=0.8672, grad=24.6315]Training epoch 18:  15%|█▌        | 25/163 [00:34<02:55,  1.27s/it, loss=0.7785, batch_acc=0.8750, running_acc=0.8675, grad=24.1349]Training epoch 18:  16%|█▌        | 26/163 [00:35<02:38,  1.15s/it, loss=0.7785, batch_acc=0.8750, running_acc=0.8675, grad=24.1349]Training epoch 18:  16%|█▌        | 26/163 [00:35<02:38,  1.15s/it, loss=0.6032, batch_acc=0.9375, running_acc=0.8702, grad=23.9136]Training epoch 18:  17%|█▋        | 27/163 [00:35<02:25,  1.07s/it, loss=0.6032, batch_acc=0.9375, running_acc=0.8702, grad=23.9136]Training epoch 18:  17%|█▋        | 27/163 [00:35<02:25,  1.07s/it, loss=0.5118, batch_acc=0.9688, running_acc=0.8738, grad=18.2119]Training epoch 18:  17%|█▋        | 28/163 [00:37<02:55,  1.30s/it, loss=0.5118, batch_acc=0.9688, running_acc=0.8738, grad=18.2119]Training epoch 18:  17%|█▋        | 28/163 [00:37<02:55,  1.30s/it, loss=0.6048, batch_acc=0.8750, running_acc=0.8739, grad=18.8531]Training epoch 18:  18%|█▊        | 29/163 [00:38<02:37,  1.18s/it, loss=0.6048, batch_acc=0.8750, running_acc=0.8739, grad=18.8531]Training epoch 18:  18%|█▊        | 29/163 [00:38<02:37,  1.18s/it, loss=0.6557, batch_acc=0.9062, running_acc=0.8750, grad=21.0983]Training epoch 18:  18%|█▊        | 30/163 [00:39<02:24,  1.09s/it, loss=0.6557, batch_acc=0.9062, running_acc=0.8750, grad=21.0983]Training epoch 18:  18%|█▊        | 30/163 [00:39<02:24,  1.09s/it, loss=0.7627, batch_acc=0.9062, running_acc=0.8760, grad=24.1455]Training epoch 18:  19%|█▉        | 31/163 [00:40<02:15,  1.02s/it, loss=0.7627, batch_acc=0.9062, running_acc=0.8760, grad=24.1455]Training epoch 18:  19%|█▉        | 31/163 [00:40<02:15,  1.02s/it, loss=0.8886, batch_acc=0.8125, running_acc=0.8740, grad=30.1021]Training epoch 18:  20%|█▉        | 32/163 [00:42<02:56,  1.35s/it, loss=0.8886, batch_acc=0.8125, running_acc=0.8740, grad=30.1021]Training epoch 18:  20%|█▉        | 32/163 [00:42<02:56,  1.35s/it, loss=0.5951, batch_acc=0.9062, running_acc=0.8750, grad=24.7828]Training epoch 18:  20%|██        | 33/163 [00:43<02:37,  1.21s/it, loss=0.5951, batch_acc=0.9062, running_acc=0.8750, grad=24.7828]Training epoch 18:  20%|██        | 33/163 [00:43<02:37,  1.21s/it, loss=0.5971, batch_acc=0.9375, running_acc=0.8769, grad=18.7696]Training epoch 18:  21%|██        | 34/163 [00:44<02:23,  1.11s/it, loss=0.5971, batch_acc=0.9375, running_acc=0.8769, grad=18.7696]Training epoch 18:  21%|██        | 34/163 [00:44<02:23,  1.11s/it, loss=0.8735, batch_acc=0.8438, running_acc=0.8759, grad=23.1954]Training epoch 18:  21%|██▏       | 35/163 [00:45<02:13,  1.04s/it, loss=0.8735, batch_acc=0.8438, running_acc=0.8759, grad=23.1954]Training epoch 18:  21%|██▏       | 35/163 [00:45<02:13,  1.04s/it, loss=0.6990, batch_acc=0.8438, running_acc=0.8750, grad=24.8620]Training epoch 18:  22%|██▏       | 36/163 [00:47<02:56,  1.39s/it, loss=0.6990, batch_acc=0.8438, running_acc=0.8750, grad=24.8620]Training epoch 18:  22%|██▏       | 36/163 [00:47<02:56,  1.39s/it, loss=0.9303, batch_acc=0.8125, running_acc=0.8733, grad=23.2127]Training epoch 18:  23%|██▎       | 37/163 [00:48<02:35,  1.24s/it, loss=0.9303, batch_acc=0.8125, running_acc=0.8733, grad=23.2127]Training epoch 18:  23%|██▎       | 37/163 [00:48<02:35,  1.24s/it, loss=0.7070, batch_acc=0.8750, running_acc=0.8733, grad=22.2007]Training epoch 18:  23%|██▎       | 38/163 [00:49<02:21,  1.13s/it, loss=0.7070, batch_acc=0.8750, running_acc=0.8733, grad=22.2007]Training epoch 18:  23%|██▎       | 38/163 [00:49<02:21,  1.13s/it, loss=0.6892, batch_acc=0.8750, running_acc=0.8734, grad=28.8275]Training epoch 18:  24%|██▍       | 39/163 [00:50<02:10,  1.05s/it, loss=0.6892, batch_acc=0.8750, running_acc=0.8734, grad=28.8275]Training epoch 18:  24%|██▍       | 39/163 [00:50<02:10,  1.05s/it, loss=0.8561, batch_acc=0.8750, running_acc=0.8734, grad=27.3485]Training epoch 18:  25%|██▍       | 40/163 [00:51<02:26,  1.19s/it, loss=0.8561, batch_acc=0.8750, running_acc=0.8734, grad=27.3485]Training epoch 18:  25%|██▍       | 40/163 [00:51<02:26,  1.19s/it, loss=0.8042, batch_acc=0.8438, running_acc=0.8727, grad=24.5204]Training epoch 18:  25%|██▌       | 41/163 [00:52<02:14,  1.10s/it, loss=0.8042, batch_acc=0.8438, running_acc=0.8727, grad=24.5204]Training epoch 18:  25%|██▌       | 41/163 [00:52<02:14,  1.10s/it, loss=0.6835, batch_acc=0.9062, running_acc=0.8735, grad=21.8404]Training epoch 18:  26%|██▌       | 42/163 [00:53<02:05,  1.03s/it, loss=0.6835, batch_acc=0.9062, running_acc=0.8735, grad=21.8404]Training epoch 18:  26%|██▌       | 42/163 [00:53<02:05,  1.03s/it, loss=0.7711, batch_acc=0.8750, running_acc=0.8735, grad=25.6183]Training epoch 18:  26%|██▋       | 43/163 [00:54<01:58,  1.01it/s, loss=0.7711, batch_acc=0.8750, running_acc=0.8735, grad=25.6183]Training epoch 18:  26%|██▋       | 43/163 [00:54<01:58,  1.01it/s, loss=0.7201, batch_acc=0.8750, running_acc=0.8735, grad=20.8928]Training epoch 18:  27%|██▋       | 44/163 [00:56<02:41,  1.36s/it, loss=0.7201, batch_acc=0.8750, running_acc=0.8735, grad=20.8928]Training epoch 18:  27%|██▋       | 44/163 [00:56<02:41,  1.36s/it, loss=0.6161, batch_acc=0.9062, running_acc=0.8743, grad=26.7024]Training epoch 18:  28%|██▊       | 45/163 [00:57<02:23,  1.22s/it, loss=0.6161, batch_acc=0.9062, running_acc=0.8743, grad=26.7024]Training epoch 18:  28%|██▊       | 45/163 [00:57<02:23,  1.22s/it, loss=0.7174, batch_acc=0.8750, running_acc=0.8743, grad=21.0874]Training epoch 18:  28%|██▊       | 46/163 [00:58<02:10,  1.12s/it, loss=0.7174, batch_acc=0.8750, running_acc=0.8743, grad=21.0874]Training epoch 18:  28%|██▊       | 46/163 [00:58<02:10,  1.12s/it, loss=0.5602, batch_acc=0.9688, running_acc=0.8764, grad=19.4450]Training epoch 18:  29%|██▉       | 47/163 [00:59<02:01,  1.05s/it, loss=0.5602, batch_acc=0.9688, running_acc=0.8764, grad=19.4450]Training epoch 18:  29%|██▉       | 47/163 [00:59<02:01,  1.05s/it, loss=0.6110, batch_acc=0.9062, running_acc=0.8770, grad=20.7313]Training epoch 18:  29%|██▉       | 48/163 [01:00<02:24,  1.25s/it, loss=0.6110, batch_acc=0.9062, running_acc=0.8770, grad=20.7313]Training epoch 18:  29%|██▉       | 48/163 [01:00<02:24,  1.25s/it, loss=0.7517, batch_acc=0.8438, running_acc=0.8763, grad=23.8410]Training epoch 18:  30%|███       | 49/163 [01:01<02:10,  1.14s/it, loss=0.7517, batch_acc=0.8438, running_acc=0.8763, grad=23.8410]Training epoch 18:  30%|███       | 49/163 [01:01<02:10,  1.14s/it, loss=0.6241, batch_acc=0.8750, running_acc=0.8763, grad=20.1670]Training epoch 18:  31%|███       | 50/163 [01:02<02:00,  1.06s/it, loss=0.6241, batch_acc=0.8750, running_acc=0.8763, grad=20.1670]Training epoch 18:  31%|███       | 50/163 [01:02<02:00,  1.06s/it, loss=0.6105, batch_acc=0.9062, running_acc=0.8769, grad=24.4262]Training epoch 18:  31%|███▏      | 51/163 [01:03<01:52,  1.01s/it, loss=0.6105, batch_acc=0.9062, running_acc=0.8769, grad=24.4262]Training epoch 18:  31%|███▏      | 51/163 [01:03<01:52,  1.01s/it, loss=0.7938, batch_acc=0.8750, running_acc=0.8768, grad=24.4593]Training epoch 18:  32%|███▏      | 52/163 [01:05<02:24,  1.30s/it, loss=0.7938, batch_acc=0.8750, running_acc=0.8768, grad=24.4593]Training epoch 18:  32%|███▏      | 52/163 [01:05<02:24,  1.30s/it, loss=0.6740, batch_acc=0.9062, running_acc=0.8774, grad=22.4668]Training epoch 18:  33%|███▎      | 53/163 [01:06<02:08,  1.17s/it, loss=0.6740, batch_acc=0.9062, running_acc=0.8774, grad=22.4668]Training epoch 18:  33%|███▎      | 53/163 [01:06<02:08,  1.17s/it, loss=0.9310, batch_acc=0.7812, running_acc=0.8756, grad=24.7020]Training epoch 18:  33%|███▎      | 54/163 [01:07<01:58,  1.08s/it, loss=0.9310, batch_acc=0.7812, running_acc=0.8756, grad=24.7020]Training epoch 18:  33%|███▎      | 54/163 [01:07<01:58,  1.08s/it, loss=0.9460, batch_acc=0.8125, running_acc=0.8744, grad=23.6535]Training epoch 18:  34%|███▎      | 55/163 [01:08<01:50,  1.02s/it, loss=0.9460, batch_acc=0.8125, running_acc=0.8744, grad=23.6535]Training epoch 18:  34%|███▎      | 55/163 [01:08<01:50,  1.02s/it, loss=0.5885, batch_acc=0.8438, running_acc=0.8739, grad=17.5605]Training epoch 18:  34%|███▍      | 56/163 [01:10<02:19,  1.30s/it, loss=0.5885, batch_acc=0.8438, running_acc=0.8739, grad=17.5605]Training epoch 18:  34%|███▍      | 56/163 [01:10<02:19,  1.30s/it, loss=0.7103, batch_acc=0.8750, running_acc=0.8739, grad=26.0077]Training epoch 18:  35%|███▍      | 57/163 [01:10<02:04,  1.17s/it, loss=0.7103, batch_acc=0.8750, running_acc=0.8739, grad=26.0077]Training epoch 18:  35%|███▍      | 57/163 [01:10<02:04,  1.17s/it, loss=0.5639, batch_acc=0.9688, running_acc=0.8755, grad=20.8424]Training epoch 18:  36%|███▌      | 58/163 [01:11<01:54,  1.09s/it, loss=0.5639, batch_acc=0.9688, running_acc=0.8755, grad=20.8424]Training epoch 18:  36%|███▌      | 58/163 [01:11<01:54,  1.09s/it, loss=0.8512, batch_acc=0.7500, running_acc=0.8734, grad=26.8734]Training epoch 18:  36%|███▌      | 59/163 [01:12<01:46,  1.02s/it, loss=0.8512, batch_acc=0.7500, running_acc=0.8734, grad=26.8734]Training epoch 18:  36%|███▌      | 59/163 [01:12<01:46,  1.02s/it, loss=0.7144, batch_acc=0.8125, running_acc=0.8724, grad=21.8452]Training epoch 18:  37%|███▋      | 60/163 [01:14<02:11,  1.27s/it, loss=0.7144, batch_acc=0.8125, running_acc=0.8724, grad=21.8452]Training epoch 18:  37%|███▋      | 60/163 [01:14<02:11,  1.27s/it, loss=0.8197, batch_acc=0.8750, running_acc=0.8724, grad=22.5977]Training epoch 18:  37%|███▋      | 61/163 [01:15<01:57,  1.15s/it, loss=0.8197, batch_acc=0.8750, running_acc=0.8724, grad=22.5977]Training epoch 18:  37%|███▋      | 61/163 [01:15<01:57,  1.15s/it, loss=0.4410, batch_acc=0.9688, running_acc=0.8740, grad=18.9602]Training epoch 18:  38%|███▊      | 62/163 [01:16<01:48,  1.07s/it, loss=0.4410, batch_acc=0.9688, running_acc=0.8740, grad=18.9602]Training epoch 18:  38%|███▊      | 62/163 [01:16<01:48,  1.07s/it, loss=0.7939, batch_acc=0.8750, running_acc=0.8740, grad=26.0269]Training epoch 18:  39%|███▊      | 63/163 [01:17<01:41,  1.01s/it, loss=0.7939, batch_acc=0.8750, running_acc=0.8740, grad=26.0269]Training epoch 18:  39%|███▊      | 63/163 [01:17<01:41,  1.01s/it, loss=0.8973, batch_acc=0.7812, running_acc=0.8725, grad=35.9810]Training epoch 18:  39%|███▉      | 64/163 [01:18<01:57,  1.19s/it, loss=0.8973, batch_acc=0.7812, running_acc=0.8725, grad=35.9810]Training epoch 18:  39%|███▉      | 64/163 [01:18<01:57,  1.19s/it, loss=0.6938, batch_acc=0.9062, running_acc=0.8730, grad=25.3629]Training epoch 18:  40%|███▉      | 65/163 [01:19<01:47,  1.10s/it, loss=0.6938, batch_acc=0.9062, running_acc=0.8730, grad=25.3629]Training epoch 18:  40%|███▉      | 65/163 [01:19<01:47,  1.10s/it, loss=1.0465, batch_acc=0.8125, running_acc=0.8721, grad=28.7343]Training epoch 18:  40%|████      | 66/163 [01:20<01:40,  1.03s/it, loss=1.0465, batch_acc=0.8125, running_acc=0.8721, grad=28.7343]Training epoch 18:  40%|████      | 66/163 [01:20<01:40,  1.03s/it, loss=0.6789, batch_acc=0.8750, running_acc=0.8722, grad=22.7262]Training epoch 18:  41%|████      | 67/163 [01:21<01:34,  1.01it/s, loss=0.6789, batch_acc=0.8750, running_acc=0.8722, grad=22.7262]Training epoch 18:  41%|████      | 67/163 [01:21<01:34,  1.01it/s, loss=0.8723, batch_acc=0.8125, running_acc=0.8713, grad=30.1937]Training epoch 18:  42%|████▏     | 68/163 [01:23<01:51,  1.18s/it, loss=0.8723, batch_acc=0.8125, running_acc=0.8713, grad=30.1937]Training epoch 18:  42%|████▏     | 68/163 [01:23<01:51,  1.18s/it, loss=0.9097, batch_acc=0.8125, running_acc=0.8704, grad=29.7069]Training epoch 18:  42%|████▏     | 69/163 [01:23<01:42,  1.09s/it, loss=0.9097, batch_acc=0.8125, running_acc=0.8704, grad=29.7069]Training epoch 18:  42%|████▏     | 69/163 [01:23<01:42,  1.09s/it, loss=0.9336, batch_acc=0.8125, running_acc=0.8696, grad=27.1142]Training epoch 18:  43%|████▎     | 70/163 [01:24<01:35,  1.03s/it, loss=0.9336, batch_acc=0.8125, running_acc=0.8696, grad=27.1142]Training epoch 18:  43%|████▎     | 70/163 [01:24<01:35,  1.03s/it, loss=0.7882, batch_acc=0.8438, running_acc=0.8692, grad=24.3187]Training epoch 18:  44%|████▎     | 71/163 [01:25<01:30,  1.02it/s, loss=0.7882, batch_acc=0.8438, running_acc=0.8692, grad=24.3187]Training epoch 18:  44%|████▎     | 71/163 [01:25<01:30,  1.02it/s, loss=0.7620, batch_acc=0.8750, running_acc=0.8693, grad=24.1143]Training epoch 18:  44%|████▍     | 72/163 [01:27<01:54,  1.25s/it, loss=0.7620, batch_acc=0.8750, running_acc=0.8693, grad=24.1143]Training epoch 18:  44%|████▍     | 72/163 [01:27<01:54,  1.25s/it, loss=0.7392, batch_acc=0.9062, running_acc=0.8698, grad=27.0537]Training epoch 18:  45%|████▍     | 73/163 [01:28<01:42,  1.14s/it, loss=0.7392, batch_acc=0.9062, running_acc=0.8698, grad=27.0537]Training epoch 18:  45%|████▍     | 73/163 [01:28<01:42,  1.14s/it, loss=0.9664, batch_acc=0.9062, running_acc=0.8703, grad=29.9256]Training epoch 18:  45%|████▌     | 74/163 [01:29<01:34,  1.06s/it, loss=0.9664, batch_acc=0.9062, running_acc=0.8703, grad=29.9256]Training epoch 18:  45%|████▌     | 74/163 [01:29<01:34,  1.06s/it, loss=0.6157, batch_acc=0.9375, running_acc=0.8712, grad=23.3028]Training epoch 18:  46%|████▌     | 75/163 [01:30<01:28,  1.01s/it, loss=0.6157, batch_acc=0.9375, running_acc=0.8712, grad=23.3028]Training epoch 18:  46%|████▌     | 75/163 [01:30<01:28,  1.01s/it, loss=0.5425, batch_acc=0.9375, running_acc=0.8721, grad=19.4337]Training epoch 18:  47%|████▋     | 76/163 [01:31<01:47,  1.24s/it, loss=0.5425, batch_acc=0.9375, running_acc=0.8721, grad=19.4337]Training epoch 18:  47%|████▋     | 76/163 [01:31<01:47,  1.24s/it, loss=0.7040, batch_acc=0.9375, running_acc=0.8729, grad=25.1208]Training epoch 18:  47%|████▋     | 77/163 [01:32<01:37,  1.13s/it, loss=0.7040, batch_acc=0.9375, running_acc=0.8729, grad=25.1208]Training epoch 18:  47%|████▋     | 77/163 [01:32<01:37,  1.13s/it, loss=0.7012, batch_acc=0.8750, running_acc=0.8730, grad=27.3135]Training epoch 18:  48%|████▊     | 78/163 [01:33<01:29,  1.06s/it, loss=0.7012, batch_acc=0.8750, running_acc=0.8730, grad=27.3135]Training epoch 18:  48%|████▊     | 78/163 [01:33<01:29,  1.06s/it, loss=0.7331, batch_acc=0.8125, running_acc=0.8722, grad=26.2872]Training epoch 18:  48%|████▊     | 79/163 [01:34<01:24,  1.00s/it, loss=0.7331, batch_acc=0.8125, running_acc=0.8722, grad=26.2872]Training epoch 18:  48%|████▊     | 79/163 [01:34<01:24,  1.00s/it, loss=0.4791, batch_acc=0.9375, running_acc=0.8730, grad=17.2134]Training epoch 18:  49%|████▉     | 80/163 [01:36<01:37,  1.18s/it, loss=0.4791, batch_acc=0.9375, running_acc=0.8730, grad=17.2134]Training epoch 18:  49%|████▉     | 80/163 [01:36<01:37,  1.18s/it, loss=0.8576, batch_acc=0.8438, running_acc=0.8727, grad=24.2018]Training epoch 18:  50%|████▉     | 81/163 [01:37<01:29,  1.09s/it, loss=0.8576, batch_acc=0.8438, running_acc=0.8727, grad=24.2018]Training epoch 18:  50%|████▉     | 81/163 [01:37<01:29,  1.09s/it, loss=0.8416, batch_acc=0.8750, running_acc=0.8727, grad=31.3275]Training epoch 18:  50%|█████     | 82/163 [01:37<01:22,  1.02s/it, loss=0.8416, batch_acc=0.8750, running_acc=0.8727, grad=31.3275]Training epoch 18:  50%|█████     | 82/163 [01:37<01:22,  1.02s/it, loss=0.6790, batch_acc=0.9062, running_acc=0.8731, grad=18.6274]Training epoch 18:  51%|█████     | 83/163 [01:38<01:18,  1.02it/s, loss=0.6790, batch_acc=0.9062, running_acc=0.8731, grad=18.6274]Training epoch 18:  51%|█████     | 83/163 [01:38<01:18,  1.02it/s, loss=0.5454, batch_acc=0.9375, running_acc=0.8739, grad=19.6046]Training epoch 18:  52%|█████▏    | 84/163 [01:40<01:34,  1.20s/it, loss=0.5454, batch_acc=0.9375, running_acc=0.8739, grad=19.6046]Training epoch 18:  52%|█████▏    | 84/163 [01:40<01:34,  1.20s/it, loss=0.5894, batch_acc=0.9375, running_acc=0.8746, grad=21.5671]Training epoch 18:  52%|█████▏    | 85/163 [01:41<01:25,  1.10s/it, loss=0.5894, batch_acc=0.9375, running_acc=0.8746, grad=21.5671]Training epoch 18:  52%|█████▏    | 85/163 [01:41<01:25,  1.10s/it, loss=0.6234, batch_acc=0.9375, running_acc=0.8754, grad=24.7087]Training epoch 18:  53%|█████▎    | 86/163 [01:42<01:19,  1.04s/it, loss=0.6234, batch_acc=0.9375, running_acc=0.8754, grad=24.7087]Training epoch 18:  53%|█████▎    | 86/163 [01:42<01:19,  1.04s/it, loss=0.8446, batch_acc=0.8438, running_acc=0.8750, grad=21.2846]Training epoch 18:  53%|█████▎    | 87/163 [01:43<01:15,  1.01it/s, loss=0.8446, batch_acc=0.8438, running_acc=0.8750, grad=21.2846]Training epoch 18:  53%|█████▎    | 87/163 [01:43<01:15,  1.01it/s, loss=0.6060, batch_acc=0.9375, running_acc=0.8757, grad=20.4346]Training epoch 18:  54%|█████▍    | 88/163 [01:44<01:29,  1.20s/it, loss=0.6060, batch_acc=0.9375, running_acc=0.8757, grad=20.4346]Training epoch 18:  54%|█████▍    | 88/163 [01:44<01:29,  1.20s/it, loss=0.6881, batch_acc=0.8750, running_acc=0.8757, grad=33.6294]Training epoch 18:  55%|█████▍    | 89/163 [01:45<01:21,  1.10s/it, loss=0.6881, batch_acc=0.8750, running_acc=0.8757, grad=33.6294]Training epoch 18:  55%|█████▍    | 89/163 [01:45<01:21,  1.10s/it, loss=0.7244, batch_acc=0.9688, running_acc=0.8768, grad=28.3654]Training epoch 18:  55%|█████▌    | 90/163 [01:46<01:15,  1.04s/it, loss=0.7244, batch_acc=0.9688, running_acc=0.8768, grad=28.3654]Training epoch 18:  55%|█████▌    | 90/163 [01:46<01:15,  1.04s/it, loss=0.4467, batch_acc=0.9688, running_acc=0.8778, grad=16.6547]Training epoch 18:  56%|█████▌    | 91/163 [01:47<01:11,  1.01it/s, loss=0.4467, batch_acc=0.9688, running_acc=0.8778, grad=16.6547]Training epoch 18:  56%|█████▌    | 91/163 [01:47<01:11,  1.01it/s, loss=0.6949, batch_acc=0.9062, running_acc=0.8781, grad=26.0897]Training epoch 18:  56%|█████▋    | 92/163 [01:49<01:31,  1.29s/it, loss=0.6949, batch_acc=0.9062, running_acc=0.8781, grad=26.0897]Training epoch 18:  56%|█████▋    | 92/163 [01:49<01:31,  1.29s/it, loss=0.6813, batch_acc=0.9375, running_acc=0.8787, grad=23.7699]Training epoch 18:  57%|█████▋    | 93/163 [01:50<01:21,  1.16s/it, loss=0.6813, batch_acc=0.9375, running_acc=0.8787, grad=23.7699]Training epoch 18:  57%|█████▋    | 93/163 [01:50<01:21,  1.16s/it, loss=0.8040, batch_acc=0.8125, running_acc=0.8780, grad=28.8967]Training epoch 18:  58%|█████▊    | 94/163 [01:51<01:14,  1.08s/it, loss=0.8040, batch_acc=0.8125, running_acc=0.8780, grad=28.8967]Training epoch 18:  58%|█████▊    | 94/163 [01:51<01:14,  1.08s/it, loss=0.8811, batch_acc=0.8750, running_acc=0.8780, grad=27.3264]Training epoch 18:  58%|█████▊    | 95/163 [01:52<01:09,  1.02s/it, loss=0.8811, batch_acc=0.8750, running_acc=0.8780, grad=27.3264]Training epoch 18:  58%|█████▊    | 95/163 [01:52<01:09,  1.02s/it, loss=0.5643, batch_acc=0.9688, running_acc=0.8789, grad=18.3737]Training epoch 18:  59%|█████▉    | 96/163 [01:54<01:35,  1.43s/it, loss=0.5643, batch_acc=0.9688, running_acc=0.8789, grad=18.3737]Training epoch 18:  59%|█████▉    | 96/163 [01:54<01:35,  1.43s/it, loss=0.6368, batch_acc=0.8750, running_acc=0.8789, grad=21.7655]Training epoch 18:  60%|█████▉    | 97/163 [01:55<01:23,  1.26s/it, loss=0.6368, batch_acc=0.8750, running_acc=0.8789, grad=21.7655]Training epoch 18:  60%|█████▉    | 97/163 [01:55<01:23,  1.26s/it, loss=0.6615, batch_acc=0.8750, running_acc=0.8789, grad=24.2706]Training epoch 18:  60%|██████    | 98/163 [01:56<01:14,  1.15s/it, loss=0.6615, batch_acc=0.8750, running_acc=0.8789, grad=24.2706]Training epoch 18:  60%|██████    | 98/163 [01:56<01:14,  1.15s/it, loss=0.7421, batch_acc=0.8438, running_acc=0.8785, grad=22.6150]Training epoch 18:  61%|██████    | 99/163 [01:57<01:08,  1.07s/it, loss=0.7421, batch_acc=0.8438, running_acc=0.8785, grad=22.6150]Training epoch 18:  61%|██████    | 99/163 [01:57<01:08,  1.07s/it, loss=0.6523, batch_acc=0.8750, running_acc=0.8785, grad=18.7226]Training epoch 18:  61%|██████▏   | 100/163 [01:59<01:26,  1.38s/it, loss=0.6523, batch_acc=0.8750, running_acc=0.8785, grad=18.7226]Training epoch 18:  61%|██████▏   | 100/163 [01:59<01:26,  1.38s/it, loss=0.8030, batch_acc=0.8438, running_acc=0.8781, grad=22.4821]Training epoch 18:  62%|██████▏   | 101/163 [02:00<01:16,  1.23s/it, loss=0.8030, batch_acc=0.8438, running_acc=0.8781, grad=22.4821]Training epoch 18:  62%|██████▏   | 101/163 [02:00<01:16,  1.23s/it, loss=0.7277, batch_acc=0.8750, running_acc=0.8781, grad=22.4496]Training epoch 18:  63%|██████▎   | 102/163 [02:01<01:08,  1.12s/it, loss=0.7277, batch_acc=0.8750, running_acc=0.8781, grad=22.4496]Training epoch 18:  63%|██████▎   | 102/163 [02:01<01:08,  1.12s/it, loss=0.7317, batch_acc=0.8750, running_acc=0.8781, grad=22.9449]Training epoch 18:  63%|██████▎   | 103/163 [02:01<01:02,  1.05s/it, loss=0.7317, batch_acc=0.8750, running_acc=0.8781, grad=22.9449]Training epoch 18:  63%|██████▎   | 103/163 [02:01<01:02,  1.05s/it, loss=0.6972, batch_acc=0.9062, running_acc=0.8783, grad=24.3865]Training epoch 18:  64%|██████▍   | 104/163 [02:05<01:40,  1.70s/it, loss=0.6972, batch_acc=0.9062, running_acc=0.8783, grad=24.3865]Training epoch 18:  64%|██████▍   | 104/163 [02:05<01:40,  1.70s/it, loss=0.9496, batch_acc=0.8125, running_acc=0.8777, grad=23.9940]Training epoch 18:  64%|██████▍   | 105/163 [02:05<01:24,  1.45s/it, loss=0.9496, batch_acc=0.8125, running_acc=0.8777, grad=23.9940]Training epoch 18:  64%|██████▍   | 105/163 [02:05<01:24,  1.45s/it, loss=0.6605, batch_acc=0.8750, running_acc=0.8777, grad=21.9274]Training epoch 18:  65%|██████▌   | 106/163 [02:06<01:13,  1.28s/it, loss=0.6605, batch_acc=0.8750, running_acc=0.8777, grad=21.9274]Training epoch 18:  65%|██████▌   | 106/163 [02:06<01:13,  1.28s/it, loss=0.6033, batch_acc=0.8750, running_acc=0.8777, grad=18.6958]Training epoch 18:  66%|██████▌   | 107/163 [02:07<01:04,  1.16s/it, loss=0.6033, batch_acc=0.8750, running_acc=0.8777, grad=18.6958]Training epoch 18:  66%|██████▌   | 107/163 [02:07<01:04,  1.16s/it, loss=0.8034, batch_acc=0.9062, running_acc=0.8779, grad=23.5198]Training epoch 18:  66%|██████▋   | 108/163 [02:09<01:11,  1.31s/it, loss=0.8034, batch_acc=0.9062, running_acc=0.8779, grad=23.5198]Training epoch 18:  66%|██████▋   | 108/163 [02:09<01:11,  1.31s/it, loss=0.8403, batch_acc=0.8438, running_acc=0.8776, grad=25.1535]Training epoch 18:  67%|██████▋   | 109/163 [02:10<01:03,  1.18s/it, loss=0.8403, batch_acc=0.8438, running_acc=0.8776, grad=25.1535]Training epoch 18:  67%|██████▋   | 109/163 [02:10<01:03,  1.18s/it, loss=0.7303, batch_acc=0.8125, running_acc=0.8770, grad=23.3175]Training epoch 18:  67%|██████▋   | 110/163 [02:11<00:57,  1.09s/it, loss=0.7303, batch_acc=0.8125, running_acc=0.8770, grad=23.3175]Training epoch 18:  67%|██████▋   | 110/163 [02:11<00:57,  1.09s/it, loss=0.8314, batch_acc=0.8125, running_acc=0.8764, grad=23.0411]Training epoch 18:  68%|██████▊   | 111/163 [02:12<00:53,  1.03s/it, loss=0.8314, batch_acc=0.8125, running_acc=0.8764, grad=23.0411]Training epoch 18:  68%|██████▊   | 111/163 [02:12<00:53,  1.03s/it, loss=0.6853, batch_acc=0.8438, running_acc=0.8761, grad=20.0926]Training epoch 18:  69%|██████▊   | 112/163 [02:14<01:07,  1.32s/it, loss=0.6853, batch_acc=0.8438, running_acc=0.8761, grad=20.0926]Training epoch 18:  69%|██████▊   | 112/163 [02:14<01:07,  1.32s/it, loss=0.6384, batch_acc=0.8750, running_acc=0.8761, grad=21.2995]Training epoch 18:  69%|██████▉   | 113/163 [02:14<00:59,  1.18s/it, loss=0.6384, batch_acc=0.8750, running_acc=0.8761, grad=21.2995]Training epoch 18:  69%|██████▉   | 113/163 [02:14<00:59,  1.18s/it, loss=0.5940, batch_acc=0.9688, running_acc=0.8769, grad=22.1842]Training epoch 18:  70%|██████▉   | 114/163 [02:15<00:53,  1.09s/it, loss=0.5940, batch_acc=0.9688, running_acc=0.8769, grad=22.1842]Training epoch 18:  70%|██████▉   | 114/163 [02:15<00:53,  1.09s/it, loss=0.8391, batch_acc=0.8125, running_acc=0.8764, grad=32.3043]Training epoch 18:  71%|███████   | 115/163 [02:16<00:49,  1.03s/it, loss=0.8391, batch_acc=0.8125, running_acc=0.8764, grad=32.3043]Training epoch 18:  71%|███████   | 115/163 [02:16<00:49,  1.03s/it, loss=0.8673, batch_acc=0.8125, running_acc=0.8758, grad=27.2128]Training epoch 18:  71%|███████   | 116/163 [02:18<01:03,  1.36s/it, loss=0.8673, batch_acc=0.8125, running_acc=0.8758, grad=27.2128]Training epoch 18:  71%|███████   | 116/163 [02:18<01:03,  1.36s/it, loss=0.5700, batch_acc=0.9688, running_acc=0.8766, grad=21.2046]Training epoch 18:  72%|███████▏  | 117/163 [02:19<00:55,  1.21s/it, loss=0.5700, batch_acc=0.9688, running_acc=0.8766, grad=21.2046]Training epoch 18:  72%|███████▏  | 117/163 [02:19<00:55,  1.21s/it, loss=0.5333, batch_acc=0.9375, running_acc=0.8771, grad=17.3510]Training epoch 18:  72%|███████▏  | 118/163 [02:20<00:50,  1.11s/it, loss=0.5333, batch_acc=0.9375, running_acc=0.8771, grad=17.3510]Training epoch 18:  72%|███████▏  | 118/163 [02:20<00:50,  1.11s/it, loss=0.9259, batch_acc=0.7812, running_acc=0.8763, grad=29.3374]Training epoch 18:  73%|███████▎  | 119/163 [02:21<00:45,  1.04s/it, loss=0.9259, batch_acc=0.7812, running_acc=0.8763, grad=29.3374]Training epoch 18:  73%|███████▎  | 119/163 [02:21<00:45,  1.04s/it, loss=0.7511, batch_acc=0.8125, running_acc=0.8758, grad=21.2414]Training epoch 18:  74%|███████▎  | 120/163 [02:22<00:48,  1.12s/it, loss=0.7511, batch_acc=0.8125, running_acc=0.8758, grad=21.2414]Training epoch 18:  74%|███████▎  | 120/163 [02:22<00:48,  1.12s/it, loss=0.5452, batch_acc=1.0000, running_acc=0.8768, grad=18.6122]Training epoch 18:  74%|███████▍  | 121/163 [02:23<00:43,  1.05s/it, loss=0.5452, batch_acc=1.0000, running_acc=0.8768, grad=18.6122]Training epoch 18:  74%|███████▍  | 121/163 [02:23<00:43,  1.05s/it, loss=0.7312, batch_acc=0.8438, running_acc=0.8765, grad=24.3046]Training epoch 18:  75%|███████▍  | 122/163 [02:24<00:40,  1.00it/s, loss=0.7312, batch_acc=0.8438, running_acc=0.8765, grad=24.3046]Training epoch 18:  75%|███████▍  | 122/163 [02:24<00:40,  1.00it/s, loss=0.7435, batch_acc=0.8750, running_acc=0.8765, grad=28.3867]Training epoch 18:  75%|███████▌  | 123/163 [02:25<00:38,  1.04it/s, loss=0.7435, batch_acc=0.8750, running_acc=0.8765, grad=28.3867]Training epoch 18:  75%|███████▌  | 123/163 [02:25<00:38,  1.04it/s, loss=0.8005, batch_acc=0.8438, running_acc=0.8763, grad=25.8611]Training epoch 18:  76%|███████▌  | 124/163 [02:26<00:43,  1.12s/it, loss=0.8005, batch_acc=0.8438, running_acc=0.8763, grad=25.8611]Training epoch 18:  76%|███████▌  | 124/163 [02:26<00:43,  1.12s/it, loss=0.6509, batch_acc=0.9375, running_acc=0.8768, grad=23.1063]Training epoch 18:  77%|███████▋  | 125/163 [02:27<00:39,  1.05s/it, loss=0.6509, batch_acc=0.9375, running_acc=0.8768, grad=23.1063]Training epoch 18:  77%|███████▋  | 125/163 [02:27<00:39,  1.05s/it, loss=0.7990, batch_acc=0.9062, running_acc=0.8770, grad=25.7866]Training epoch 18:  77%|███████▋  | 126/163 [02:28<00:36,  1.00it/s, loss=0.7990, batch_acc=0.9062, running_acc=0.8770, grad=25.7866]Training epoch 18:  77%|███████▋  | 126/163 [02:28<00:36,  1.00it/s, loss=0.6953, batch_acc=0.8750, running_acc=0.8770, grad=21.3254]Training epoch 18:  78%|███████▊  | 127/163 [02:29<00:34,  1.04it/s, loss=0.6953, batch_acc=0.8750, running_acc=0.8770, grad=21.3254]Training epoch 18:  78%|███████▊  | 127/163 [02:29<00:34,  1.04it/s, loss=0.8852, batch_acc=0.8125, running_acc=0.8765, grad=28.3887]Training epoch 18:  79%|███████▊  | 128/163 [02:30<00:37,  1.06s/it, loss=0.8852, batch_acc=0.8125, running_acc=0.8765, grad=28.3887]Training epoch 18:  79%|███████▊  | 128/163 [02:30<00:37,  1.06s/it, loss=1.0099, batch_acc=0.8125, running_acc=0.8760, grad=36.6193]Training epoch 18:  79%|███████▉  | 129/163 [02:31<00:34,  1.00s/it, loss=1.0099, batch_acc=0.8125, running_acc=0.8760, grad=36.6193]Training epoch 18:  79%|███████▉  | 129/163 [02:31<00:34,  1.00s/it, loss=0.6946, batch_acc=0.8750, running_acc=0.8760, grad=21.8598]Training epoch 18:  80%|███████▉  | 130/163 [02:32<00:31,  1.04it/s, loss=0.6946, batch_acc=0.8750, running_acc=0.8760, grad=21.8598]Training epoch 18:  80%|███████▉  | 130/163 [02:32<00:31,  1.04it/s, loss=0.7038, batch_acc=0.8125, running_acc=0.8755, grad=25.6262]Training epoch 18:  80%|████████  | 131/163 [02:33<00:30,  1.06it/s, loss=0.7038, batch_acc=0.8125, running_acc=0.8755, grad=25.6262]Training epoch 18:  80%|████████  | 131/163 [02:33<00:30,  1.06it/s, loss=0.6586, batch_acc=0.9062, running_acc=0.8757, grad=22.4261]Training epoch 18:  81%|████████  | 132/163 [02:35<00:38,  1.25s/it, loss=0.6586, batch_acc=0.9062, running_acc=0.8757, grad=22.4261]Training epoch 18:  81%|████████  | 132/163 [02:35<00:38,  1.25s/it, loss=0.8899, batch_acc=0.7812, running_acc=0.8750, grad=34.5174]Training epoch 18:  82%|████████▏ | 133/163 [02:36<00:34,  1.14s/it, loss=0.8899, batch_acc=0.7812, running_acc=0.8750, grad=34.5174]Training epoch 18:  82%|████████▏ | 133/163 [02:36<00:34,  1.14s/it, loss=0.8467, batch_acc=0.8438, running_acc=0.8748, grad=27.2560]Training epoch 18:  82%|████████▏ | 134/163 [02:37<00:30,  1.06s/it, loss=0.8467, batch_acc=0.8438, running_acc=0.8748, grad=27.2560]Training epoch 18:  82%|████████▏ | 134/163 [02:37<00:30,  1.06s/it, loss=0.7871, batch_acc=0.8750, running_acc=0.8748, grad=34.8392]Training epoch 18:  83%|████████▎ | 135/163 [02:38<00:28,  1.01s/it, loss=0.7871, batch_acc=0.8750, running_acc=0.8748, grad=34.8392]Training epoch 18:  83%|████████▎ | 135/163 [02:38<00:28,  1.01s/it, loss=0.6713, batch_acc=0.8750, running_acc=0.8748, grad=21.5695]Training epoch 18:  83%|████████▎ | 136/163 [02:39<00:32,  1.21s/it, loss=0.6713, batch_acc=0.8750, running_acc=0.8748, grad=21.5695]Training epoch 18:  83%|████████▎ | 136/163 [02:39<00:32,  1.21s/it, loss=0.5231, batch_acc=0.9688, running_acc=0.8755, grad=17.9764]Training epoch 18:  84%|████████▍ | 137/163 [02:40<00:28,  1.11s/it, loss=0.5231, batch_acc=0.9688, running_acc=0.8755, grad=17.9764]Training epoch 18:  84%|████████▍ | 137/163 [02:40<00:28,  1.11s/it, loss=0.5644, batch_acc=0.9062, running_acc=0.8757, grad=16.7610]Training epoch 18:  85%|████████▍ | 138/163 [02:41<00:26,  1.04s/it, loss=0.5644, batch_acc=0.9062, running_acc=0.8757, grad=16.7610]Training epoch 18:  85%|████████▍ | 138/163 [02:41<00:26,  1.04s/it, loss=0.8591, batch_acc=0.8750, running_acc=0.8757, grad=22.9324]Training epoch 18:  85%|████████▌ | 139/163 [02:42<00:23,  1.01it/s, loss=0.8591, batch_acc=0.8750, running_acc=0.8757, grad=22.9324]Training epoch 18:  85%|████████▌ | 139/163 [02:42<00:23,  1.01it/s, loss=0.9578, batch_acc=0.9375, running_acc=0.8761, grad=32.8331]Training epoch 18:  86%|████████▌ | 140/163 [02:43<00:26,  1.17s/it, loss=0.9578, batch_acc=0.9375, running_acc=0.8761, grad=32.8331]Training epoch 18:  86%|████████▌ | 140/163 [02:43<00:26,  1.17s/it, loss=0.7193, batch_acc=0.9062, running_acc=0.8763, grad=22.5561]Training epoch 18:  87%|████████▋ | 141/163 [02:44<00:23,  1.08s/it, loss=0.7193, batch_acc=0.9062, running_acc=0.8763, grad=22.5561]Training epoch 18:  87%|████████▋ | 141/163 [02:44<00:23,  1.08s/it, loss=0.8626, batch_acc=0.8438, running_acc=0.8761, grad=25.3011]Training epoch 18:  87%|████████▋ | 142/163 [02:45<00:21,  1.02s/it, loss=0.8626, batch_acc=0.8438, running_acc=0.8761, grad=25.3011]Training epoch 18:  87%|████████▋ | 142/163 [02:45<00:21,  1.02s/it, loss=0.6389, batch_acc=0.8438, running_acc=0.8759, grad=21.2017]Training epoch 18:  88%|████████▊ | 143/163 [02:46<00:19,  1.02it/s, loss=0.6389, batch_acc=0.8438, running_acc=0.8759, grad=21.2017]Training epoch 18:  88%|████████▊ | 143/163 [02:46<00:19,  1.02it/s, loss=0.6309, batch_acc=0.9688, running_acc=0.8765, grad=20.8983]Training epoch 18:  88%|████████▊ | 144/163 [02:48<00:21,  1.15s/it, loss=0.6309, batch_acc=0.9688, running_acc=0.8765, grad=20.8983]Training epoch 18:  88%|████████▊ | 144/163 [02:48<00:21,  1.15s/it, loss=0.7421, batch_acc=0.7812, running_acc=0.8759, grad=29.1265]Training epoch 18:  89%|████████▉ | 145/163 [02:48<00:19,  1.07s/it, loss=0.7421, batch_acc=0.7812, running_acc=0.8759, grad=29.1265]Training epoch 18:  89%|████████▉ | 145/163 [02:48<00:19,  1.07s/it, loss=0.6196, batch_acc=0.9062, running_acc=0.8761, grad=16.9366]Training epoch 18:  90%|████████▉ | 146/163 [02:49<00:17,  1.01s/it, loss=0.6196, batch_acc=0.9062, running_acc=0.8761, grad=16.9366]Training epoch 18:  90%|████████▉ | 146/163 [02:49<00:17,  1.01s/it, loss=0.7165, batch_acc=0.9375, running_acc=0.8765, grad=24.8721]Training epoch 18:  90%|█████████ | 147/163 [02:50<00:15,  1.03it/s, loss=0.7165, batch_acc=0.9375, running_acc=0.8765, grad=24.8721]Training epoch 18:  90%|█████████ | 147/163 [02:50<00:15,  1.03it/s, loss=0.7623, batch_acc=0.8438, running_acc=0.8763, grad=29.4682]Training epoch 18:  91%|█████████ | 148/163 [02:52<00:16,  1.08s/it, loss=0.7623, batch_acc=0.8438, running_acc=0.8763, grad=29.4682]Training epoch 18:  91%|█████████ | 148/163 [02:52<00:16,  1.08s/it, loss=0.4621, batch_acc=0.9375, running_acc=0.8767, grad=18.4831]Training epoch 18:  91%|█████████▏| 149/163 [02:52<00:14,  1.02s/it, loss=0.4621, batch_acc=0.9375, running_acc=0.8767, grad=18.4831]Training epoch 18:  91%|█████████▏| 149/163 [02:52<00:14,  1.02s/it, loss=0.6172, batch_acc=0.8750, running_acc=0.8767, grad=17.5179]Training epoch 18:  92%|█████████▏| 150/163 [02:53<00:12,  1.02it/s, loss=0.6172, batch_acc=0.8750, running_acc=0.8767, grad=17.5179]Training epoch 18:  92%|█████████▏| 150/163 [02:53<00:12,  1.02it/s, loss=0.9493, batch_acc=0.7500, running_acc=0.8758, grad=23.4533]Training epoch 18:  93%|█████████▎| 151/163 [02:54<00:11,  1.05it/s, loss=0.9493, batch_acc=0.7500, running_acc=0.8758, grad=23.4533]Training epoch 18:  93%|█████████▎| 151/163 [02:54<00:11,  1.05it/s, loss=0.5613, batch_acc=0.9375, running_acc=0.8762, grad=24.8036]Training epoch 18:  93%|█████████▎| 152/163 [02:57<00:15,  1.40s/it, loss=0.5613, batch_acc=0.9375, running_acc=0.8762, grad=24.8036]Training epoch 18:  93%|█████████▎| 152/163 [02:57<00:15,  1.40s/it, loss=0.8495, batch_acc=0.8125, running_acc=0.8758, grad=23.6898]Training epoch 18:  94%|█████████▍| 153/163 [02:58<00:12,  1.24s/it, loss=0.8495, batch_acc=0.8125, running_acc=0.8758, grad=23.6898]Training epoch 18:  94%|█████████▍| 153/163 [02:58<00:12,  1.24s/it, loss=0.5675, batch_acc=0.8750, running_acc=0.8758, grad=24.0735]Training epoch 18:  94%|█████████▍| 154/163 [02:58<00:10,  1.13s/it, loss=0.5675, batch_acc=0.8750, running_acc=0.8758, grad=24.0735]Training epoch 18:  94%|█████████▍| 154/163 [02:58<00:10,  1.13s/it, loss=0.6635, batch_acc=0.9062, running_acc=0.8760, grad=20.9168]Training epoch 18:  95%|█████████▌| 155/163 [02:59<00:08,  1.06s/it, loss=0.6635, batch_acc=0.9062, running_acc=0.8760, grad=20.9168]Training epoch 18:  95%|█████████▌| 155/163 [02:59<00:08,  1.06s/it, loss=0.6339, batch_acc=0.8750, running_acc=0.8760, grad=26.9805]Training epoch 18:  96%|█████████▌| 156/163 [03:01<00:08,  1.26s/it, loss=0.6339, batch_acc=0.8750, running_acc=0.8760, grad=26.9805]Training epoch 18:  96%|█████████▌| 156/163 [03:01<00:08,  1.26s/it, loss=0.7041, batch_acc=0.8438, running_acc=0.8758, grad=25.1859]Training epoch 18:  96%|█████████▋| 157/163 [03:02<00:06,  1.15s/it, loss=0.7041, batch_acc=0.8438, running_acc=0.8758, grad=25.1859]Training epoch 18:  96%|█████████▋| 157/163 [03:02<00:06,  1.15s/it, loss=0.7275, batch_acc=0.8750, running_acc=0.8758, grad=29.7659]Training epoch 18:  97%|█████████▋| 158/163 [03:03<00:05,  1.07s/it, loss=0.7275, batch_acc=0.8750, running_acc=0.8758, grad=29.7659]Training epoch 18:  97%|█████████▋| 158/163 [03:03<00:05,  1.07s/it, loss=0.6569, batch_acc=0.9375, running_acc=0.8762, grad=24.4212]Training epoch 18:  98%|█████████▊| 159/163 [03:04<00:04,  1.01s/it, loss=0.6569, batch_acc=0.9375, running_acc=0.8762, grad=24.4212]Training epoch 18:  98%|█████████▊| 159/163 [03:04<00:04,  1.01s/it, loss=0.7686, batch_acc=0.8125, running_acc=0.8758, grad=33.1522]Training epoch 18:  98%|█████████▊| 160/163 [03:05<00:03,  1.24s/it, loss=0.7686, batch_acc=0.8125, running_acc=0.8758, grad=33.1522]Training epoch 18:  98%|█████████▊| 160/163 [03:05<00:03,  1.24s/it, loss=0.8479, batch_acc=0.7188, running_acc=0.8748, grad=25.0515]Training epoch 18:  99%|█████████▉| 161/163 [03:06<00:02,  1.13s/it, loss=0.8479, batch_acc=0.7188, running_acc=0.8748, grad=25.0515]Training epoch 18:  99%|█████████▉| 161/163 [03:06<00:02,  1.13s/it, loss=0.6106, batch_acc=0.8750, running_acc=0.8748, grad=22.8521]Training epoch 18:  99%|█████████▉| 162/163 [03:07<00:01,  1.06s/it, loss=0.6106, batch_acc=0.8750, running_acc=0.8748, grad=22.8521]Training epoch 18:  99%|█████████▉| 162/163 [03:07<00:01,  1.06s/it, loss=0.7693, batch_acc=0.8750, running_acc=0.8748, grad=24.7475]Training epoch 18: 100%|██████████| 163/163 [03:08<00:00,  1.07it/s, loss=0.7693, batch_acc=0.8750, running_acc=0.8748, grad=24.7475]Training epoch 18: 100%|██████████| 163/163 [03:08<00:00,  1.07it/s, loss=0.4117, batch_acc=1.0000, running_acc=0.8753, grad=24.6602]Training epoch 18: 100%|██████████| 163/163 [03:08<00:00,  1.16s/it, loss=0.4117, batch_acc=1.0000, running_acc=0.8753, grad=24.6602]
Evaluation epoch 18:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 18:   4%|▎         | 1/28 [00:05<02:15,  5.02s/it]Evaluation epoch 18:   4%|▎         | 1/28 [00:05<02:15,  5.02s/it, loss=0.8658, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 18:   7%|▋         | 2/28 [00:05<00:58,  2.24s/it, loss=0.8658, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 18:   7%|▋         | 2/28 [00:05<00:58,  2.24s/it, loss=0.4622, batch_acc=1.0000, running_acc=0.9062]Evaluation epoch 18:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.4622, batch_acc=1.0000, running_acc=0.9062]Evaluation epoch 18:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.5982, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 18:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=0.5982, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 18:  14%|█▍        | 4/28 [00:09<01:00,  2.53s/it, loss=1.2568, batch_acc=0.6875, running_acc=0.8516]Evaluation epoch 18:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.2568, batch_acc=0.6875, running_acc=0.8516]Evaluation epoch 18:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.5135, batch_acc=0.6250, running_acc=0.8063]Evaluation epoch 18:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.5135, batch_acc=0.6250, running_acc=0.8063]Evaluation epoch 18:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.2034, batch_acc=0.7812, running_acc=0.8021]Evaluation epoch 18:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.2034, batch_acc=0.7812, running_acc=0.8021]Evaluation epoch 18:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=1.3495, batch_acc=0.7500, running_acc=0.7946]Evaluation epoch 18:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=1.3495, batch_acc=0.7500, running_acc=0.7946]Evaluation epoch 18:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=0.8630, batch_acc=0.7188, running_acc=0.7852]Evaluation epoch 18:  32%|███▏      | 9/28 [00:15<00:29,  1.54s/it, loss=0.8630, batch_acc=0.7188, running_acc=0.7852]Evaluation epoch 18:  32%|███▏      | 9/28 [00:15<00:29,  1.54s/it, loss=1.1863, batch_acc=0.8125, running_acc=0.7882]Evaluation epoch 18:  36%|███▌      | 10/28 [00:15<00:20,  1.14s/it, loss=1.1863, batch_acc=0.8125, running_acc=0.7882]Evaluation epoch 18:  36%|███▌      | 10/28 [00:15<00:20,  1.14s/it, loss=0.6904, batch_acc=0.9062, running_acc=0.8000]Evaluation epoch 18:  39%|███▉      | 11/28 [00:15<00:14,  1.14it/s, loss=0.6904, batch_acc=0.9062, running_acc=0.8000]Evaluation epoch 18:  39%|███▉      | 11/28 [00:15<00:14,  1.14it/s, loss=0.9657, batch_acc=0.7812, running_acc=0.7983]Evaluation epoch 18:  43%|████▎     | 12/28 [00:20<00:32,  2.03s/it, loss=0.9657, batch_acc=0.7812, running_acc=0.7983]Evaluation epoch 18:  43%|████▎     | 12/28 [00:20<00:32,  2.03s/it, loss=1.1583, batch_acc=0.7812, running_acc=0.7969]Evaluation epoch 18:  46%|████▋     | 13/28 [00:20<00:22,  1.50s/it, loss=1.1583, batch_acc=0.7812, running_acc=0.7969]Evaluation epoch 18:  46%|████▋     | 13/28 [00:20<00:22,  1.50s/it, loss=0.6693, batch_acc=0.8750, running_acc=0.8029]Evaluation epoch 18:  50%|█████     | 14/28 [00:20<00:15,  1.13s/it, loss=0.6693, batch_acc=0.8750, running_acc=0.8029]Evaluation epoch 18:  50%|█████     | 14/28 [00:20<00:15,  1.13s/it, loss=1.2940, batch_acc=0.7812, running_acc=0.8013]Evaluation epoch 18:  54%|█████▎    | 15/28 [00:21<00:11,  1.16it/s, loss=1.2940, batch_acc=0.7812, running_acc=0.8013]Evaluation epoch 18:  54%|█████▎    | 15/28 [00:21<00:11,  1.16it/s, loss=1.8542, batch_acc=0.5000, running_acc=0.7812]Evaluation epoch 18:  57%|█████▋    | 16/28 [00:24<00:17,  1.49s/it, loss=1.8542, batch_acc=0.5000, running_acc=0.7812]Evaluation epoch 18:  57%|█████▋    | 16/28 [00:24<00:17,  1.49s/it, loss=1.4360, batch_acc=0.6250, running_acc=0.7715]Evaluation epoch 18:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=1.4360, batch_acc=0.6250, running_acc=0.7715]Evaluation epoch 18:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=1.0302, batch_acc=0.5938, running_acc=0.7610]Evaluation epoch 18:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=1.0302, batch_acc=0.5938, running_acc=0.7610]Evaluation epoch 18:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.9142, batch_acc=0.6875, running_acc=0.7569]Evaluation epoch 18:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=0.9142, batch_acc=0.6875, running_acc=0.7569]Evaluation epoch 18:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=0.9218, batch_acc=0.7188, running_acc=0.7549]Evaluation epoch 18:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=0.9218, batch_acc=0.7188, running_acc=0.7549]Evaluation epoch 18:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=0.8649, batch_acc=0.8125, running_acc=0.7578]Evaluation epoch 18:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.8649, batch_acc=0.8125, running_acc=0.7578]Evaluation epoch 18:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=1.0608, batch_acc=0.7188, running_acc=0.7560]Evaluation epoch 18:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=1.0608, batch_acc=0.7188, running_acc=0.7560]Evaluation epoch 18:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=1.3367, batch_acc=0.5938, running_acc=0.7486]Evaluation epoch 18:  82%|████████▏ | 23/28 [00:28<00:03,  1.53it/s, loss=1.3367, batch_acc=0.5938, running_acc=0.7486]Evaluation epoch 18:  82%|████████▏ | 23/28 [00:28<00:03,  1.53it/s, loss=1.5211, batch_acc=0.6250, running_acc=0.7432]Evaluation epoch 18:  86%|████████▌ | 24/28 [00:34<00:08,  2.05s/it, loss=1.5211, batch_acc=0.6250, running_acc=0.7432]Evaluation epoch 18:  86%|████████▌ | 24/28 [00:34<00:08,  2.05s/it, loss=0.7865, batch_acc=0.8750, running_acc=0.7487]Evaluation epoch 18:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.7865, batch_acc=0.8750, running_acc=0.7487]Evaluation epoch 18:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.4384, batch_acc=0.9375, running_acc=0.7562]Evaluation epoch 18:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.4384, batch_acc=0.9375, running_acc=0.7562]Evaluation epoch 18:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=1.1530, batch_acc=0.6562, running_acc=0.7524]Evaluation epoch 18:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=1.1530, batch_acc=0.6562, running_acc=0.7524]Evaluation epoch 18:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=1.3147, batch_acc=0.6562, running_acc=0.7488]Evaluation epoch 18: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.3598, batch_acc=0.6667, running_acc=0.7486]Evaluation epoch 18: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=1.3598, batch_acc=0.6667, running_acc=0.7486]
Training epoch 19:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 19:   1%|          | 1/163 [00:05<15:21,  5.69s/it]Training epoch 19:   1%|          | 1/163 [00:05<15:21,  5.69s/it, loss=0.7722, batch_acc=0.8438, running_acc=0.8438, grad=24.3108]Training epoch 19:   1%|          | 2/163 [00:06<07:40,  2.86s/it, loss=0.7722, batch_acc=0.8438, running_acc=0.8438, grad=24.3108]Training epoch 19:   1%|          | 2/163 [00:06<07:40,  2.86s/it, loss=0.8549, batch_acc=0.8125, running_acc=0.8281, grad=36.5524]Training epoch 19:   2%|▏         | 3/163 [00:07<05:12,  1.96s/it, loss=0.8549, batch_acc=0.8125, running_acc=0.8281, grad=36.5524]Training epoch 19:   2%|▏         | 3/163 [00:07<05:12,  1.96s/it, loss=0.8484, batch_acc=0.8438, running_acc=0.8333, grad=23.0886]Training epoch 19:   2%|▏         | 4/163 [00:09<05:22,  2.03s/it, loss=0.8484, batch_acc=0.8438, running_acc=0.8333, grad=23.0886]Training epoch 19:   2%|▏         | 4/163 [00:09<05:22,  2.03s/it, loss=0.6836, batch_acc=0.8750, running_acc=0.8438, grad=29.5529]Training epoch 19:   3%|▎         | 5/163 [00:10<04:14,  1.61s/it, loss=0.6836, batch_acc=0.8750, running_acc=0.8438, grad=29.5529]Training epoch 19:   3%|▎         | 5/163 [00:10<04:14,  1.61s/it, loss=0.6561, batch_acc=0.9688, running_acc=0.8688, grad=27.9067]Training epoch 19:   4%|▎         | 6/163 [00:11<03:34,  1.36s/it, loss=0.6561, batch_acc=0.9688, running_acc=0.8688, grad=27.9067]Training epoch 19:   4%|▎         | 6/163 [00:11<03:34,  1.36s/it, loss=0.6765, batch_acc=0.9062, running_acc=0.8750, grad=23.2316]Training epoch 19:   4%|▍         | 7/163 [00:12<03:08,  1.21s/it, loss=0.6765, batch_acc=0.9062, running_acc=0.8750, grad=23.2316]Training epoch 19:   4%|▍         | 7/163 [00:12<03:08,  1.21s/it, loss=0.8918, batch_acc=0.7500, running_acc=0.8571, grad=33.7204]Training epoch 19:   5%|▍         | 8/163 [00:13<03:31,  1.37s/it, loss=0.8918, batch_acc=0.7500, running_acc=0.8571, grad=33.7204]Training epoch 19:   5%|▍         | 8/163 [00:13<03:31,  1.37s/it, loss=0.7324, batch_acc=0.8750, running_acc=0.8594, grad=25.0855]Training epoch 19:   6%|▌         | 9/163 [00:14<03:06,  1.21s/it, loss=0.7324, batch_acc=0.8750, running_acc=0.8594, grad=25.0855]Training epoch 19:   6%|▌         | 9/163 [00:14<03:06,  1.21s/it, loss=0.6961, batch_acc=0.9375, running_acc=0.8681, grad=20.8622]Training epoch 19:   6%|▌         | 10/163 [00:15<02:49,  1.11s/it, loss=0.6961, batch_acc=0.9375, running_acc=0.8681, grad=20.8622]Training epoch 19:   6%|▌         | 10/163 [00:15<02:49,  1.11s/it, loss=0.5136, batch_acc=0.9688, running_acc=0.8781, grad=20.8704]Training epoch 19:   7%|▋         | 11/163 [00:16<02:37,  1.04s/it, loss=0.5136, batch_acc=0.9688, running_acc=0.8781, grad=20.8704]Training epoch 19:   7%|▋         | 11/163 [00:16<02:37,  1.04s/it, loss=0.6224, batch_acc=0.9375, running_acc=0.8835, grad=21.2000]Training epoch 19:   7%|▋         | 12/163 [00:18<03:10,  1.26s/it, loss=0.6224, batch_acc=0.9375, running_acc=0.8835, grad=21.2000]Training epoch 19:   7%|▋         | 12/163 [00:18<03:10,  1.26s/it, loss=0.6682, batch_acc=0.9062, running_acc=0.8854, grad=23.1549]Training epoch 19:   8%|▊         | 13/163 [00:19<02:51,  1.15s/it, loss=0.6682, batch_acc=0.9062, running_acc=0.8854, grad=23.1549]Training epoch 19:   8%|▊         | 13/163 [00:19<02:51,  1.15s/it, loss=0.6681, batch_acc=0.9062, running_acc=0.8870, grad=23.0775]Training epoch 19:   9%|▊         | 14/163 [00:20<02:38,  1.07s/it, loss=0.6681, batch_acc=0.9062, running_acc=0.8870, grad=23.0775]Training epoch 19:   9%|▊         | 14/163 [00:20<02:38,  1.07s/it, loss=0.8282, batch_acc=0.7500, running_acc=0.8772, grad=28.4132]Training epoch 19:   9%|▉         | 15/163 [00:20<02:29,  1.01s/it, loss=0.8282, batch_acc=0.7500, running_acc=0.8772, grad=28.4132]Training epoch 19:   9%|▉         | 15/163 [00:20<02:29,  1.01s/it, loss=0.7746, batch_acc=0.8438, running_acc=0.8750, grad=30.6478]Training epoch 19:  10%|▉         | 16/163 [00:22<03:11,  1.30s/it, loss=0.7746, batch_acc=0.8438, running_acc=0.8750, grad=30.6478]Training epoch 19:  10%|▉         | 16/163 [00:22<03:11,  1.30s/it, loss=0.5405, batch_acc=0.9375, running_acc=0.8789, grad=18.2955]Training epoch 19:  10%|█         | 17/163 [00:23<02:51,  1.17s/it, loss=0.5405, batch_acc=0.9375, running_acc=0.8789, grad=18.2955]Training epoch 19:  10%|█         | 17/163 [00:23<02:51,  1.17s/it, loss=0.9249, batch_acc=0.9062, running_acc=0.8805, grad=25.1396]Training epoch 19:  11%|█         | 18/163 [00:24<02:37,  1.09s/it, loss=0.9249, batch_acc=0.9062, running_acc=0.8805, grad=25.1396]Training epoch 19:  11%|█         | 18/163 [00:24<02:37,  1.09s/it, loss=0.5443, batch_acc=0.9375, running_acc=0.8837, grad=15.5064]Training epoch 19:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=0.5443, batch_acc=0.9375, running_acc=0.8837, grad=15.5064]Training epoch 19:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=0.5446, batch_acc=0.9375, running_acc=0.8865, grad=20.2311]Training epoch 19:  12%|█▏        | 20/163 [00:27<03:08,  1.32s/it, loss=0.5446, batch_acc=0.9375, running_acc=0.8865, grad=20.2311]Training epoch 19:  12%|█▏        | 20/163 [00:27<03:08,  1.32s/it, loss=0.7662, batch_acc=0.8438, running_acc=0.8844, grad=33.5395]Training epoch 19:  13%|█▎        | 21/163 [00:28<02:48,  1.18s/it, loss=0.7662, batch_acc=0.8438, running_acc=0.8844, grad=33.5395]Training epoch 19:  13%|█▎        | 21/163 [00:28<02:48,  1.18s/it, loss=0.5828, batch_acc=0.8438, running_acc=0.8824, grad=19.0269]Training epoch 19:  13%|█▎        | 22/163 [00:29<02:34,  1.09s/it, loss=0.5828, batch_acc=0.8438, running_acc=0.8824, grad=19.0269]Training epoch 19:  13%|█▎        | 22/163 [00:29<02:34,  1.09s/it, loss=0.8220, batch_acc=0.8125, running_acc=0.8793, grad=31.2498]Training epoch 19:  14%|█▍        | 23/163 [00:30<02:23,  1.03s/it, loss=0.8220, batch_acc=0.8125, running_acc=0.8793, grad=31.2498]Training epoch 19:  14%|█▍        | 23/163 [00:30<02:23,  1.03s/it, loss=0.6798, batch_acc=0.9375, running_acc=0.8818, grad=19.1380]Training epoch 19:  15%|█▍        | 24/163 [00:31<02:50,  1.23s/it, loss=0.6798, batch_acc=0.9375, running_acc=0.8818, grad=19.1380]Training epoch 19:  15%|█▍        | 24/163 [00:31<02:50,  1.23s/it, loss=0.8192, batch_acc=0.8125, running_acc=0.8789, grad=26.7583]Training epoch 19:  15%|█▌        | 25/163 [00:32<02:34,  1.12s/it, loss=0.8192, batch_acc=0.8125, running_acc=0.8789, grad=26.7583]Training epoch 19:  15%|█▌        | 25/163 [00:32<02:34,  1.12s/it, loss=0.3523, batch_acc=1.0000, running_acc=0.8838, grad=14.7107]Training epoch 19:  16%|█▌        | 26/163 [00:33<02:23,  1.05s/it, loss=0.3523, batch_acc=1.0000, running_acc=0.8838, grad=14.7107]Training epoch 19:  16%|█▌        | 26/163 [00:33<02:23,  1.05s/it, loss=0.5622, batch_acc=0.9062, running_acc=0.8846, grad=20.0660]Training epoch 19:  17%|█▋        | 27/163 [00:34<02:18,  1.01s/it, loss=0.5622, batch_acc=0.9062, running_acc=0.8846, grad=20.0660]Training epoch 19:  17%|█▋        | 27/163 [00:34<02:18,  1.01s/it, loss=0.5622, batch_acc=0.9062, running_acc=0.8854, grad=19.3252]Training epoch 19:  17%|█▋        | 28/163 [00:35<02:31,  1.12s/it, loss=0.5622, batch_acc=0.9062, running_acc=0.8854, grad=19.3252]Training epoch 19:  17%|█▋        | 28/163 [00:35<02:31,  1.12s/it, loss=0.6366, batch_acc=0.8438, running_acc=0.8839, grad=19.2919]Training epoch 19:  18%|█▊        | 29/163 [00:36<02:20,  1.05s/it, loss=0.6366, batch_acc=0.8438, running_acc=0.8839, grad=19.2919]Training epoch 19:  18%|█▊        | 29/163 [00:36<02:20,  1.05s/it, loss=0.6963, batch_acc=0.9062, running_acc=0.8847, grad=21.5885]Training epoch 19:  18%|█▊        | 30/163 [00:37<02:12,  1.00it/s, loss=0.6963, batch_acc=0.9062, running_acc=0.8847, grad=21.5885]Training epoch 19:  18%|█▊        | 30/163 [00:37<02:12,  1.00it/s, loss=0.8814, batch_acc=0.8125, running_acc=0.8823, grad=23.0669]Training epoch 19:  19%|█▉        | 31/163 [00:38<02:06,  1.04it/s, loss=0.8814, batch_acc=0.8125, running_acc=0.8823, grad=23.0669]Training epoch 19:  19%|█▉        | 31/163 [00:38<02:06,  1.04it/s, loss=0.5654, batch_acc=0.9062, running_acc=0.8831, grad=20.4854]Training epoch 19:  20%|█▉        | 32/163 [00:40<02:49,  1.30s/it, loss=0.5654, batch_acc=0.9062, running_acc=0.8831, grad=20.4854]Training epoch 19:  20%|█▉        | 32/163 [00:40<02:49,  1.30s/it, loss=0.6358, batch_acc=0.8438, running_acc=0.8818, grad=23.4835]Training epoch 19:  20%|██        | 33/163 [00:41<02:32,  1.17s/it, loss=0.6358, batch_acc=0.8438, running_acc=0.8818, grad=23.4835]Training epoch 19:  20%|██        | 33/163 [00:41<02:32,  1.17s/it, loss=0.6234, batch_acc=0.9375, running_acc=0.8835, grad=29.4101]Training epoch 19:  21%|██        | 34/163 [00:42<02:19,  1.08s/it, loss=0.6234, batch_acc=0.9375, running_acc=0.8835, grad=29.4101]Training epoch 19:  21%|██        | 34/163 [00:42<02:19,  1.08s/it, loss=0.4820, batch_acc=0.9062, running_acc=0.8842, grad=21.3818]Training epoch 19:  21%|██▏       | 35/163 [00:43<02:14,  1.05s/it, loss=0.4820, batch_acc=0.9062, running_acc=0.8842, grad=21.3818]Training epoch 19:  21%|██▏       | 35/163 [00:43<02:14,  1.05s/it, loss=0.5846, batch_acc=0.9062, running_acc=0.8848, grad=19.1525]Training epoch 19:  22%|██▏       | 36/163 [00:45<02:45,  1.30s/it, loss=0.5846, batch_acc=0.9062, running_acc=0.8848, grad=19.1525]Training epoch 19:  22%|██▏       | 36/163 [00:45<02:45,  1.30s/it, loss=0.7612, batch_acc=0.8438, running_acc=0.8837, grad=22.2007]Training epoch 19:  23%|██▎       | 37/163 [00:46<02:27,  1.17s/it, loss=0.7612, batch_acc=0.8438, running_acc=0.8837, grad=22.2007]Training epoch 19:  23%|██▎       | 37/163 [00:46<02:27,  1.17s/it, loss=0.6650, batch_acc=0.9375, running_acc=0.8851, grad=24.8142]Training epoch 19:  23%|██▎       | 38/163 [00:47<02:15,  1.08s/it, loss=0.6650, batch_acc=0.9375, running_acc=0.8851, grad=24.8142]Training epoch 19:  23%|██▎       | 38/163 [00:47<02:15,  1.08s/it, loss=0.8010, batch_acc=0.9062, running_acc=0.8857, grad=22.4943]Training epoch 19:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=0.8010, batch_acc=0.9062, running_acc=0.8857, grad=22.4943]Training epoch 19:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=0.6200, batch_acc=0.9062, running_acc=0.8862, grad=19.3835]Training epoch 19:  25%|██▍       | 40/163 [00:49<02:28,  1.21s/it, loss=0.6200, batch_acc=0.9062, running_acc=0.8862, grad=19.3835]Training epoch 19:  25%|██▍       | 40/163 [00:49<02:28,  1.21s/it, loss=0.7056, batch_acc=0.8125, running_acc=0.8844, grad=27.1830]Training epoch 19:  25%|██▌       | 41/163 [00:50<02:15,  1.11s/it, loss=0.7056, batch_acc=0.8125, running_acc=0.8844, grad=27.1830]Training epoch 19:  25%|██▌       | 41/163 [00:50<02:15,  1.11s/it, loss=0.7164, batch_acc=0.8125, running_acc=0.8826, grad=22.1837]Training epoch 19:  26%|██▌       | 42/163 [00:51<02:05,  1.04s/it, loss=0.7164, batch_acc=0.8125, running_acc=0.8826, grad=22.1837]Training epoch 19:  26%|██▌       | 42/163 [00:51<02:05,  1.04s/it, loss=0.6236, batch_acc=0.9062, running_acc=0.8832, grad=22.4001]Training epoch 19:  26%|██▋       | 43/163 [00:52<01:58,  1.01it/s, loss=0.6236, batch_acc=0.9062, running_acc=0.8832, grad=22.4001]Training epoch 19:  26%|██▋       | 43/163 [00:52<01:58,  1.01it/s, loss=0.5989, batch_acc=0.9375, running_acc=0.8844, grad=18.5089]Training epoch 19:  27%|██▋       | 44/163 [00:53<02:16,  1.14s/it, loss=0.5989, batch_acc=0.9375, running_acc=0.8844, grad=18.5089]Training epoch 19:  27%|██▋       | 44/163 [00:53<02:16,  1.14s/it, loss=0.5292, batch_acc=0.8750, running_acc=0.8842, grad=16.6024]Training epoch 19:  28%|██▊       | 45/163 [00:54<02:05,  1.06s/it, loss=0.5292, batch_acc=0.8750, running_acc=0.8842, grad=16.6024]Training epoch 19:  28%|██▊       | 45/163 [00:54<02:05,  1.06s/it, loss=0.8258, batch_acc=0.8125, running_acc=0.8826, grad=32.2550]Training epoch 19:  28%|██▊       | 46/163 [00:55<01:57,  1.01s/it, loss=0.8258, batch_acc=0.8125, running_acc=0.8826, grad=32.2550]Training epoch 19:  28%|██▊       | 46/163 [00:55<01:57,  1.01s/it, loss=0.4924, batch_acc=0.9688, running_acc=0.8845, grad=20.6455]Training epoch 19:  29%|██▉       | 47/163 [00:56<01:52,  1.03it/s, loss=0.4924, batch_acc=0.9688, running_acc=0.8845, grad=20.6455]Training epoch 19:  29%|██▉       | 47/163 [00:56<01:52,  1.03it/s, loss=0.7439, batch_acc=0.8438, running_acc=0.8836, grad=27.6276]Training epoch 19:  29%|██▉       | 48/163 [00:58<02:30,  1.31s/it, loss=0.7439, batch_acc=0.8438, running_acc=0.8836, grad=27.6276]Training epoch 19:  29%|██▉       | 48/163 [00:58<02:30,  1.31s/it, loss=0.6553, batch_acc=0.8438, running_acc=0.8828, grad=26.0900]Training epoch 19:  30%|███       | 49/163 [00:59<02:14,  1.18s/it, loss=0.6553, batch_acc=0.8438, running_acc=0.8828, grad=26.0900]Training epoch 19:  30%|███       | 49/163 [00:59<02:14,  1.18s/it, loss=0.5637, batch_acc=0.9688, running_acc=0.8846, grad=28.3525]Training epoch 19:  31%|███       | 50/163 [01:00<02:02,  1.09s/it, loss=0.5637, batch_acc=0.9688, running_acc=0.8846, grad=28.3525]Training epoch 19:  31%|███       | 50/163 [01:00<02:02,  1.09s/it, loss=0.5567, batch_acc=0.9375, running_acc=0.8856, grad=30.7218]Training epoch 19:  31%|███▏      | 51/163 [01:01<01:54,  1.02s/it, loss=0.5567, batch_acc=0.9375, running_acc=0.8856, grad=30.7218]Training epoch 19:  31%|███▏      | 51/163 [01:01<01:54,  1.02s/it, loss=0.6898, batch_acc=0.9375, running_acc=0.8866, grad=19.4701]Training epoch 19:  32%|███▏      | 52/163 [01:02<02:12,  1.20s/it, loss=0.6898, batch_acc=0.9375, running_acc=0.8866, grad=19.4701]Training epoch 19:  32%|███▏      | 52/163 [01:02<02:12,  1.20s/it, loss=0.7774, batch_acc=0.7812, running_acc=0.8846, grad=20.1620]Training epoch 19:  33%|███▎      | 53/163 [01:03<02:01,  1.10s/it, loss=0.7774, batch_acc=0.7812, running_acc=0.8846, grad=20.1620]Training epoch 19:  33%|███▎      | 53/163 [01:03<02:01,  1.10s/it, loss=0.6835, batch_acc=0.9062, running_acc=0.8850, grad=35.0313]Training epoch 19:  33%|███▎      | 54/163 [01:04<01:52,  1.04s/it, loss=0.6835, batch_acc=0.9062, running_acc=0.8850, grad=35.0313]Training epoch 19:  33%|███▎      | 54/163 [01:04<01:52,  1.04s/it, loss=0.5880, batch_acc=0.9375, running_acc=0.8860, grad=23.1457]Training epoch 19:  34%|███▎      | 55/163 [01:05<01:46,  1.01it/s, loss=0.5880, batch_acc=0.9375, running_acc=0.8860, grad=23.1457]Training epoch 19:  34%|███▎      | 55/163 [01:05<01:46,  1.01it/s, loss=0.6633, batch_acc=0.8750, running_acc=0.8858, grad=25.3802]Training epoch 19:  34%|███▍      | 56/163 [01:06<02:03,  1.16s/it, loss=0.6633, batch_acc=0.8750, running_acc=0.8858, grad=25.3802]Training epoch 19:  34%|███▍      | 56/163 [01:06<02:03,  1.16s/it, loss=0.5478, batch_acc=0.9375, running_acc=0.8867, grad=21.8931]Training epoch 19:  35%|███▍      | 57/163 [01:07<01:53,  1.07s/it, loss=0.5478, batch_acc=0.9375, running_acc=0.8867, grad=21.8931]Training epoch 19:  35%|███▍      | 57/163 [01:07<01:53,  1.07s/it, loss=0.6728, batch_acc=0.8750, running_acc=0.8865, grad=34.8616]Training epoch 19:  36%|███▌      | 58/163 [01:08<01:46,  1.01s/it, loss=0.6728, batch_acc=0.8750, running_acc=0.8865, grad=34.8616]Training epoch 19:  36%|███▌      | 58/163 [01:08<01:46,  1.01s/it, loss=0.7594, batch_acc=0.8438, running_acc=0.8858, grad=23.2553]Training epoch 19:  36%|███▌      | 59/163 [01:09<01:41,  1.03it/s, loss=0.7594, batch_acc=0.8438, running_acc=0.8858, grad=23.2553]Training epoch 19:  36%|███▌      | 59/163 [01:09<01:41,  1.03it/s, loss=0.5551, batch_acc=0.9688, running_acc=0.8872, grad=25.4196]Training epoch 19:  37%|███▋      | 60/163 [01:10<01:44,  1.02s/it, loss=0.5551, batch_acc=0.9688, running_acc=0.8872, grad=25.4196]Training epoch 19:  37%|███▋      | 60/163 [01:10<01:44,  1.02s/it, loss=0.8127, batch_acc=0.8125, running_acc=0.8859, grad=28.6138]Training epoch 19:  37%|███▋      | 61/163 [01:11<01:39,  1.02it/s, loss=0.8127, batch_acc=0.8125, running_acc=0.8859, grad=28.6138]Training epoch 19:  37%|███▋      | 61/163 [01:11<01:39,  1.02it/s, loss=0.6094, batch_acc=0.9375, running_acc=0.8868, grad=18.4870]Training epoch 19:  38%|███▊      | 62/163 [01:12<01:35,  1.06it/s, loss=0.6094, batch_acc=0.9375, running_acc=0.8868, grad=18.4870]Training epoch 19:  38%|███▊      | 62/163 [01:12<01:35,  1.06it/s, loss=0.5224, batch_acc=0.9375, running_acc=0.8876, grad=17.6728]Training epoch 19:  39%|███▊      | 63/163 [01:13<01:32,  1.08it/s, loss=0.5224, batch_acc=0.9375, running_acc=0.8876, grad=17.6728]Training epoch 19:  39%|███▊      | 63/163 [01:13<01:32,  1.08it/s, loss=0.7285, batch_acc=0.9062, running_acc=0.8879, grad=22.9969]Training epoch 19:  39%|███▉      | 64/163 [01:14<01:49,  1.10s/it, loss=0.7285, batch_acc=0.9062, running_acc=0.8879, grad=22.9969]Training epoch 19:  39%|███▉      | 64/163 [01:14<01:49,  1.10s/it, loss=0.7187, batch_acc=0.8438, running_acc=0.8872, grad=24.8445]Training epoch 19:  40%|███▉      | 65/163 [01:15<01:41,  1.04s/it, loss=0.7187, batch_acc=0.8438, running_acc=0.8872, grad=24.8445]Training epoch 19:  40%|███▉      | 65/163 [01:15<01:41,  1.04s/it, loss=0.7318, batch_acc=0.8125, running_acc=0.8861, grad=34.5728]Training epoch 19:  40%|████      | 66/163 [01:16<01:35,  1.01it/s, loss=0.7318, batch_acc=0.8125, running_acc=0.8861, grad=34.5728]Training epoch 19:  40%|████      | 66/163 [01:16<01:35,  1.01it/s, loss=0.6848, batch_acc=0.8438, running_acc=0.8854, grad=28.1394]Training epoch 19:  41%|████      | 67/163 [01:17<01:31,  1.05it/s, loss=0.6848, batch_acc=0.8438, running_acc=0.8854, grad=28.1394]Training epoch 19:  41%|████      | 67/163 [01:17<01:31,  1.05it/s, loss=0.8234, batch_acc=0.8125, running_acc=0.8843, grad=28.2446]Training epoch 19:  42%|████▏     | 68/163 [01:18<01:43,  1.09s/it, loss=0.8234, batch_acc=0.8125, running_acc=0.8843, grad=28.2446]Training epoch 19:  42%|████▏     | 68/163 [01:18<01:43,  1.09s/it, loss=0.5447, batch_acc=0.9062, running_acc=0.8847, grad=23.4645]Training epoch 19:  42%|████▏     | 69/163 [01:19<01:44,  1.11s/it, loss=0.5447, batch_acc=0.9062, running_acc=0.8847, grad=23.4645]Training epoch 19:  42%|████▏     | 69/163 [01:19<01:44,  1.11s/it, loss=0.7087, batch_acc=0.9688, running_acc=0.8859, grad=29.8188]Training epoch 19:  43%|████▎     | 70/163 [01:20<01:37,  1.04s/it, loss=0.7087, batch_acc=0.9688, running_acc=0.8859, grad=29.8188]Training epoch 19:  43%|████▎     | 70/163 [01:20<01:37,  1.04s/it, loss=0.7332, batch_acc=0.8750, running_acc=0.8857, grad=32.4314]Training epoch 19:  44%|████▎     | 71/163 [01:21<01:31,  1.00it/s, loss=0.7332, batch_acc=0.8750, running_acc=0.8857, grad=32.4314]Training epoch 19:  44%|████▎     | 71/163 [01:21<01:31,  1.00it/s, loss=0.6506, batch_acc=0.9062, running_acc=0.8860, grad=26.5726]Training epoch 19:  44%|████▍     | 72/163 [01:23<01:42,  1.12s/it, loss=0.6506, batch_acc=0.9062, running_acc=0.8860, grad=26.5726]Training epoch 19:  44%|████▍     | 72/163 [01:23<01:42,  1.12s/it, loss=0.8742, batch_acc=0.8750, running_acc=0.8859, grad=29.4629]Training epoch 19:  45%|████▍     | 73/163 [01:24<01:34,  1.05s/it, loss=0.8742, batch_acc=0.8750, running_acc=0.8859, grad=29.4629]Training epoch 19:  45%|████▍     | 73/163 [01:24<01:34,  1.05s/it, loss=0.6766, batch_acc=0.9062, running_acc=0.8861, grad=20.3699]Training epoch 19:  45%|████▌     | 74/163 [01:24<01:28,  1.00it/s, loss=0.6766, batch_acc=0.9062, running_acc=0.8861, grad=20.3699]Training epoch 19:  45%|████▌     | 74/163 [01:24<01:28,  1.00it/s, loss=0.6475, batch_acc=0.8750, running_acc=0.8860, grad=29.8359]Training epoch 19:  46%|████▌     | 75/163 [01:25<01:24,  1.04it/s, loss=0.6475, batch_acc=0.8750, running_acc=0.8860, grad=29.8359]Training epoch 19:  46%|████▌     | 75/163 [01:25<01:24,  1.04it/s, loss=0.6498, batch_acc=0.9062, running_acc=0.8862, grad=19.0005]Training epoch 19:  47%|████▋     | 76/163 [01:27<01:32,  1.07s/it, loss=0.6498, batch_acc=0.9062, running_acc=0.8862, grad=19.0005]Training epoch 19:  47%|████▋     | 76/163 [01:27<01:32,  1.07s/it, loss=0.6642, batch_acc=0.8750, running_acc=0.8861, grad=24.1662]Training epoch 19:  47%|████▋     | 77/163 [01:27<01:26,  1.01s/it, loss=0.6642, batch_acc=0.8750, running_acc=0.8861, grad=24.1662]Training epoch 19:  47%|████▋     | 77/163 [01:27<01:26,  1.01s/it, loss=0.5215, batch_acc=0.9688, running_acc=0.8872, grad=17.7792]Training epoch 19:  48%|████▊     | 78/163 [01:28<01:22,  1.03it/s, loss=0.5215, batch_acc=0.9688, running_acc=0.8872, grad=17.7792]Training epoch 19:  48%|████▊     | 78/163 [01:28<01:22,  1.03it/s, loss=0.5987, batch_acc=0.9062, running_acc=0.8874, grad=23.1691]Training epoch 19:  48%|████▊     | 79/163 [01:29<01:19,  1.06it/s, loss=0.5987, batch_acc=0.9062, running_acc=0.8874, grad=23.1691]Training epoch 19:  48%|████▊     | 79/163 [01:29<01:19,  1.06it/s, loss=0.4911, batch_acc=1.0000, running_acc=0.8888, grad=23.3179]Training epoch 19:  49%|████▉     | 80/163 [01:31<01:40,  1.21s/it, loss=0.4911, batch_acc=1.0000, running_acc=0.8888, grad=23.3179]Training epoch 19:  49%|████▉     | 80/163 [01:31<01:40,  1.21s/it, loss=0.5029, batch_acc=0.9062, running_acc=0.8891, grad=21.1352]Training epoch 19:  50%|████▉     | 81/163 [01:32<01:30,  1.11s/it, loss=0.5029, batch_acc=0.9062, running_acc=0.8891, grad=21.1352]Training epoch 19:  50%|████▉     | 81/163 [01:32<01:30,  1.11s/it, loss=0.5546, batch_acc=0.8750, running_acc=0.8889, grad=28.0395]Training epoch 19:  50%|█████     | 82/163 [01:33<01:24,  1.04s/it, loss=0.5546, batch_acc=0.8750, running_acc=0.8889, grad=28.0395]Training epoch 19:  50%|█████     | 82/163 [01:33<01:24,  1.04s/it, loss=0.6065, batch_acc=0.9062, running_acc=0.8891, grad=22.0136]Training epoch 19:  51%|█████     | 83/163 [01:34<01:19,  1.01it/s, loss=0.6065, batch_acc=0.9062, running_acc=0.8891, grad=22.0136]Training epoch 19:  51%|█████     | 83/163 [01:34<01:19,  1.01it/s, loss=0.7703, batch_acc=0.8750, running_acc=0.8889, grad=28.7751]Training epoch 19:  52%|█████▏    | 84/163 [01:35<01:25,  1.08s/it, loss=0.7703, batch_acc=0.8750, running_acc=0.8889, grad=28.7751]Training epoch 19:  52%|█████▏    | 84/163 [01:35<01:25,  1.08s/it, loss=0.4863, batch_acc=0.9688, running_acc=0.8899, grad=18.3912]Training epoch 19:  52%|█████▏    | 85/163 [01:36<01:19,  1.02s/it, loss=0.4863, batch_acc=0.9688, running_acc=0.8899, grad=18.3912]Training epoch 19:  52%|█████▏    | 85/163 [01:36<01:19,  1.02s/it, loss=0.7157, batch_acc=0.8750, running_acc=0.8897, grad=22.8322]Training epoch 19:  53%|█████▎    | 86/163 [01:37<01:15,  1.02it/s, loss=0.7157, batch_acc=0.8750, running_acc=0.8897, grad=22.8322]Training epoch 19:  53%|█████▎    | 86/163 [01:37<01:15,  1.02it/s, loss=0.5040, batch_acc=1.0000, running_acc=0.8910, grad=25.8893]Training epoch 19:  53%|█████▎    | 87/163 [01:38<01:25,  1.12s/it, loss=0.5040, batch_acc=1.0000, running_acc=0.8910, grad=25.8893]Training epoch 19:  53%|█████▎    | 87/163 [01:38<01:25,  1.12s/it, loss=0.4035, batch_acc=1.0000, running_acc=0.8922, grad=20.0900]Training epoch 19:  54%|█████▍    | 88/163 [01:39<01:19,  1.06s/it, loss=0.4035, batch_acc=1.0000, running_acc=0.8922, grad=20.0900]Training epoch 19:  54%|█████▍    | 88/163 [01:39<01:19,  1.06s/it, loss=0.8936, batch_acc=0.7812, running_acc=0.8910, grad=30.3696]Training epoch 19:  55%|█████▍    | 89/163 [01:40<01:25,  1.16s/it, loss=0.8936, batch_acc=0.7812, running_acc=0.8910, grad=30.3696]Training epoch 19:  55%|█████▍    | 89/163 [01:40<01:25,  1.16s/it, loss=0.8599, batch_acc=0.8438, running_acc=0.8904, grad=33.3868]Training epoch 19:  55%|█████▌    | 90/163 [01:41<01:18,  1.08s/it, loss=0.8599, batch_acc=0.8438, running_acc=0.8904, grad=33.3868]Training epoch 19:  55%|█████▌    | 90/163 [01:41<01:18,  1.08s/it, loss=0.6759, batch_acc=0.8438, running_acc=0.8899, grad=22.4263]Training epoch 19:  56%|█████▌    | 91/163 [01:43<01:23,  1.16s/it, loss=0.6759, batch_acc=0.8438, running_acc=0.8899, grad=22.4263]Training epoch 19:  56%|█████▌    | 91/163 [01:43<01:23,  1.16s/it, loss=0.4919, batch_acc=0.9375, running_acc=0.8905, grad=17.9010]Training epoch 19:  56%|█████▋    | 92/163 [01:44<01:17,  1.09s/it, loss=0.4919, batch_acc=0.9375, running_acc=0.8905, grad=17.9010]Training epoch 19:  56%|█████▋    | 92/163 [01:44<01:17,  1.09s/it, loss=0.7051, batch_acc=0.9062, running_acc=0.8906, grad=23.0157]Training epoch 19:  57%|█████▋    | 93/163 [01:45<01:12,  1.03s/it, loss=0.7051, batch_acc=0.9062, running_acc=0.8906, grad=23.0157]Training epoch 19:  57%|█████▋    | 93/163 [01:45<01:12,  1.03s/it, loss=0.6464, batch_acc=0.8750, running_acc=0.8905, grad=31.4617]Training epoch 19:  58%|█████▊    | 94/163 [01:45<01:08,  1.01it/s, loss=0.6464, batch_acc=0.8750, running_acc=0.8905, grad=31.4617]Training epoch 19:  58%|█████▊    | 94/163 [01:45<01:08,  1.01it/s, loss=0.5680, batch_acc=0.9062, running_acc=0.8906, grad=22.5842]Training epoch 19:  58%|█████▊    | 95/163 [01:47<01:24,  1.24s/it, loss=0.5680, batch_acc=0.9062, running_acc=0.8906, grad=22.5842]Training epoch 19:  58%|█████▊    | 95/163 [01:47<01:24,  1.24s/it, loss=0.8256, batch_acc=0.7812, running_acc=0.8895, grad=26.3315]Training epoch 19:  59%|█████▉    | 96/163 [01:48<01:15,  1.13s/it, loss=0.8256, batch_acc=0.7812, running_acc=0.8895, grad=26.3315]Training epoch 19:  59%|█████▉    | 96/163 [01:48<01:15,  1.13s/it, loss=0.6587, batch_acc=0.9375, running_acc=0.8900, grad=24.8680]Training epoch 19:  60%|█████▉    | 97/163 [01:49<01:09,  1.06s/it, loss=0.6587, batch_acc=0.9375, running_acc=0.8900, grad=24.8680]Training epoch 19:  60%|█████▉    | 97/163 [01:49<01:09,  1.06s/it, loss=0.5398, batch_acc=0.9688, running_acc=0.8908, grad=22.0240]Training epoch 19:  60%|██████    | 98/163 [01:50<01:05,  1.00s/it, loss=0.5398, batch_acc=0.9688, running_acc=0.8908, grad=22.0240]Training epoch 19:  60%|██████    | 98/163 [01:50<01:05,  1.00s/it, loss=0.5351, batch_acc=0.9688, running_acc=0.8916, grad=21.2805]Training epoch 19:  61%|██████    | 99/163 [01:51<01:05,  1.02s/it, loss=0.5351, batch_acc=0.9688, running_acc=0.8916, grad=21.2805]Training epoch 19:  61%|██████    | 99/163 [01:51<01:05,  1.02s/it, loss=0.6474, batch_acc=0.8750, running_acc=0.8914, grad=35.0011]Training epoch 19:  61%|██████▏   | 100/163 [01:52<01:01,  1.02it/s, loss=0.6474, batch_acc=0.8750, running_acc=0.8914, grad=35.0011]Training epoch 19:  61%|██████▏   | 100/163 [01:52<01:01,  1.02it/s, loss=0.7176, batch_acc=0.8750, running_acc=0.8912, grad=32.8663]Training epoch 19:  62%|██████▏   | 101/163 [01:53<01:06,  1.08s/it, loss=0.7176, batch_acc=0.8750, running_acc=0.8912, grad=32.8663]Training epoch 19:  62%|██████▏   | 101/163 [01:53<01:06,  1.08s/it, loss=0.9565, batch_acc=0.7812, running_acc=0.8902, grad=28.7570]Training epoch 19:  63%|██████▎   | 102/163 [01:54<01:02,  1.02s/it, loss=0.9565, batch_acc=0.7812, running_acc=0.8902, grad=28.7570]Training epoch 19:  63%|██████▎   | 102/163 [01:54<01:02,  1.02s/it, loss=0.6893, batch_acc=0.8750, running_acc=0.8900, grad=29.7447]Training epoch 19:  63%|██████▎   | 103/163 [01:56<01:09,  1.16s/it, loss=0.6893, batch_acc=0.8750, running_acc=0.8900, grad=29.7447]Training epoch 19:  63%|██████▎   | 103/163 [01:56<01:09,  1.16s/it, loss=0.6686, batch_acc=0.8750, running_acc=0.8899, grad=22.3142]Training epoch 19:  64%|██████▍   | 104/163 [01:56<01:03,  1.08s/it, loss=0.6686, batch_acc=0.8750, running_acc=0.8899, grad=22.3142]Training epoch 19:  64%|██████▍   | 104/163 [01:56<01:03,  1.08s/it, loss=0.6747, batch_acc=0.9375, running_acc=0.8903, grad=21.6652]Training epoch 19:  64%|██████▍   | 105/163 [01:58<01:11,  1.23s/it, loss=0.6747, batch_acc=0.9375, running_acc=0.8903, grad=21.6652]Training epoch 19:  64%|██████▍   | 105/163 [01:58<01:11,  1.23s/it, loss=0.7375, batch_acc=0.8438, running_acc=0.8899, grad=23.4267]Training epoch 19:  65%|██████▌   | 106/163 [01:59<01:04,  1.13s/it, loss=0.7375, batch_acc=0.8438, running_acc=0.8899, grad=23.4267]Training epoch 19:  65%|██████▌   | 106/163 [01:59<01:04,  1.13s/it, loss=0.7086, batch_acc=0.8750, running_acc=0.8897, grad=20.7140]Training epoch 19:  66%|██████▌   | 107/163 [02:00<01:00,  1.08s/it, loss=0.7086, batch_acc=0.8750, running_acc=0.8897, grad=20.7140]Training epoch 19:  66%|██████▌   | 107/163 [02:00<01:00,  1.08s/it, loss=0.4851, batch_acc=0.9688, running_acc=0.8905, grad=17.6303]Training epoch 19:  66%|██████▋   | 108/163 [02:01<00:56,  1.02s/it, loss=0.4851, batch_acc=0.9688, running_acc=0.8905, grad=17.6303]Training epoch 19:  66%|██████▋   | 108/163 [02:01<00:56,  1.02s/it, loss=0.5431, batch_acc=0.9062, running_acc=0.8906, grad=20.8900]Training epoch 19:  67%|██████▋   | 109/163 [02:02<01:01,  1.14s/it, loss=0.5431, batch_acc=0.9062, running_acc=0.8906, grad=20.8900]Training epoch 19:  67%|██████▋   | 109/163 [02:02<01:01,  1.14s/it, loss=0.7763, batch_acc=0.8750, running_acc=0.8905, grad=33.4731]Training epoch 19:  67%|██████▋   | 110/163 [02:03<00:56,  1.06s/it, loss=0.7763, batch_acc=0.8750, running_acc=0.8905, grad=33.4731]Training epoch 19:  67%|██████▋   | 110/163 [02:03<00:56,  1.06s/it, loss=0.4860, batch_acc=0.9688, running_acc=0.8912, grad=20.8712]Training epoch 19:  68%|██████▊   | 111/163 [02:04<00:56,  1.09s/it, loss=0.4860, batch_acc=0.9688, running_acc=0.8912, grad=20.8712]Training epoch 19:  68%|██████▊   | 111/163 [02:04<00:56,  1.09s/it, loss=0.7451, batch_acc=0.9062, running_acc=0.8913, grad=22.9862]Training epoch 19:  69%|██████▊   | 112/163 [02:05<00:52,  1.03s/it, loss=0.7451, batch_acc=0.9062, running_acc=0.8913, grad=22.9862]Training epoch 19:  69%|██████▊   | 112/163 [02:05<00:52,  1.03s/it, loss=0.7559, batch_acc=0.9375, running_acc=0.8917, grad=23.5190]Training epoch 19:  69%|██████▉   | 113/163 [02:07<01:00,  1.21s/it, loss=0.7559, batch_acc=0.9375, running_acc=0.8917, grad=23.5190]Training epoch 19:  69%|██████▉   | 113/163 [02:07<01:00,  1.21s/it, loss=0.7321, batch_acc=0.9062, running_acc=0.8919, grad=30.3222]Training epoch 19:  70%|██████▉   | 114/163 [02:08<00:54,  1.11s/it, loss=0.7321, batch_acc=0.9062, running_acc=0.8919, grad=30.3222]Training epoch 19:  70%|██████▉   | 114/163 [02:08<00:54,  1.11s/it, loss=0.8018, batch_acc=0.7812, running_acc=0.8909, grad=28.9534]Training epoch 19:  71%|███████   | 115/163 [02:08<00:50,  1.04s/it, loss=0.8018, batch_acc=0.7812, running_acc=0.8909, grad=28.9534]Training epoch 19:  71%|███████   | 115/163 [02:08<00:50,  1.04s/it, loss=0.5923, batch_acc=0.9375, running_acc=0.8913, grad=20.1911]Training epoch 19:  71%|███████   | 116/163 [02:09<00:46,  1.01it/s, loss=0.5923, batch_acc=0.9375, running_acc=0.8913, grad=20.1911]Training epoch 19:  71%|███████   | 116/163 [02:09<00:46,  1.01it/s, loss=0.5834, batch_acc=0.9062, running_acc=0.8914, grad=19.5471]Training epoch 19:  72%|███████▏  | 117/163 [02:11<00:54,  1.19s/it, loss=0.5834, batch_acc=0.9062, running_acc=0.8914, grad=19.5471]Training epoch 19:  72%|███████▏  | 117/163 [02:11<00:54,  1.19s/it, loss=0.8346, batch_acc=0.8438, running_acc=0.8910, grad=25.3155]Training epoch 19:  72%|███████▏  | 118/163 [02:12<00:49,  1.10s/it, loss=0.8346, batch_acc=0.8438, running_acc=0.8910, grad=25.3155]Training epoch 19:  72%|███████▏  | 118/163 [02:12<00:49,  1.10s/it, loss=0.7808, batch_acc=0.9062, running_acc=0.8912, grad=22.5281]Training epoch 19:  73%|███████▎  | 119/163 [02:13<00:45,  1.03s/it, loss=0.7808, batch_acc=0.9062, running_acc=0.8912, grad=22.5281]Training epoch 19:  73%|███████▎  | 119/163 [02:13<00:45,  1.03s/it, loss=0.4957, batch_acc=0.9688, running_acc=0.8918, grad=21.8943]Training epoch 19:  74%|███████▎  | 120/163 [02:14<00:42,  1.01it/s, loss=0.4957, batch_acc=0.9688, running_acc=0.8918, grad=21.8943]Training epoch 19:  74%|███████▎  | 120/163 [02:14<00:42,  1.01it/s, loss=0.4878, batch_acc=0.9062, running_acc=0.8919, grad=19.4161]Training epoch 19:  74%|███████▍  | 121/163 [02:15<00:48,  1.16s/it, loss=0.4878, batch_acc=0.9062, running_acc=0.8919, grad=19.4161]Training epoch 19:  74%|███████▍  | 121/163 [02:15<00:48,  1.16s/it, loss=0.6629, batch_acc=0.9062, running_acc=0.8920, grad=22.0567]Training epoch 19:  75%|███████▍  | 122/163 [02:16<00:44,  1.08s/it, loss=0.6629, batch_acc=0.9062, running_acc=0.8920, grad=22.0567]Training epoch 19:  75%|███████▍  | 122/163 [02:16<00:44,  1.08s/it, loss=0.4776, batch_acc=0.9375, running_acc=0.8924, grad=16.6549]Training epoch 19:  75%|███████▌  | 123/163 [02:17<00:40,  1.02s/it, loss=0.4776, batch_acc=0.9375, running_acc=0.8924, grad=16.6549]Training epoch 19:  75%|███████▌  | 123/163 [02:17<00:40,  1.02s/it, loss=0.7100, batch_acc=0.8125, running_acc=0.8918, grad=22.3784]Training epoch 19:  76%|███████▌  | 124/163 [02:18<00:38,  1.02it/s, loss=0.7100, batch_acc=0.8125, running_acc=0.8918, grad=22.3784]Training epoch 19:  76%|███████▌  | 124/163 [02:18<00:38,  1.02it/s, loss=0.4820, batch_acc=0.9062, running_acc=0.8919, grad=18.1989]Training epoch 19:  77%|███████▋  | 125/163 [02:19<00:42,  1.13s/it, loss=0.4820, batch_acc=0.9062, running_acc=0.8919, grad=18.1989]Training epoch 19:  77%|███████▋  | 125/163 [02:19<00:42,  1.13s/it, loss=0.6413, batch_acc=0.8750, running_acc=0.8918, grad=20.1270]Training epoch 19:  77%|███████▋  | 126/163 [02:20<00:38,  1.05s/it, loss=0.6413, batch_acc=0.8750, running_acc=0.8918, grad=20.1270]Training epoch 19:  77%|███████▋  | 126/163 [02:20<00:38,  1.05s/it, loss=0.9658, batch_acc=0.7812, running_acc=0.8909, grad=41.1659]Training epoch 19:  78%|███████▊  | 127/163 [02:21<00:36,  1.00s/it, loss=0.9658, batch_acc=0.7812, running_acc=0.8909, grad=41.1659]Training epoch 19:  78%|███████▊  | 127/163 [02:21<00:36,  1.00s/it, loss=0.7803, batch_acc=0.8438, running_acc=0.8905, grad=36.5629]Training epoch 19:  79%|███████▊  | 128/163 [02:22<00:33,  1.04it/s, loss=0.7803, batch_acc=0.8438, running_acc=0.8905, grad=36.5629]Training epoch 19:  79%|███████▊  | 128/163 [02:22<00:33,  1.04it/s, loss=0.5874, batch_acc=0.8438, running_acc=0.8901, grad=21.9835]Training epoch 19:  79%|███████▉  | 129/163 [02:24<00:42,  1.26s/it, loss=0.5874, batch_acc=0.8438, running_acc=0.8901, grad=21.9835]Training epoch 19:  79%|███████▉  | 129/163 [02:24<00:42,  1.26s/it, loss=0.5300, batch_acc=0.9375, running_acc=0.8905, grad=20.3455]Training epoch 19:  80%|███████▉  | 130/163 [02:25<00:37,  1.14s/it, loss=0.5300, batch_acc=0.9375, running_acc=0.8905, grad=20.3455]Training epoch 19:  80%|███████▉  | 130/163 [02:25<00:37,  1.14s/it, loss=0.6211, batch_acc=0.9062, running_acc=0.8906, grad=30.6136]Training epoch 19:  80%|████████  | 131/163 [02:26<00:34,  1.07s/it, loss=0.6211, batch_acc=0.9062, running_acc=0.8906, grad=30.6136]Training epoch 19:  80%|████████  | 131/163 [02:26<00:34,  1.07s/it, loss=0.7332, batch_acc=0.8750, running_acc=0.8905, grad=28.6639]Training epoch 19:  81%|████████  | 132/163 [02:27<00:31,  1.01s/it, loss=0.7332, batch_acc=0.8750, running_acc=0.8905, grad=28.6639]Training epoch 19:  81%|████████  | 132/163 [02:27<00:31,  1.01s/it, loss=0.3410, batch_acc=1.0000, running_acc=0.8913, grad=16.5272]Training epoch 19:  82%|████████▏ | 133/163 [02:28<00:37,  1.26s/it, loss=0.3410, batch_acc=1.0000, running_acc=0.8913, grad=16.5272]Training epoch 19:  82%|████████▏ | 133/163 [02:28<00:37,  1.26s/it, loss=0.7021, batch_acc=0.8125, running_acc=0.8907, grad=23.0510]Training epoch 19:  82%|████████▏ | 134/163 [02:29<00:33,  1.14s/it, loss=0.7021, batch_acc=0.8125, running_acc=0.8907, grad=23.0510]Training epoch 19:  82%|████████▏ | 134/163 [02:29<00:33,  1.14s/it, loss=0.4855, batch_acc=0.9375, running_acc=0.8911, grad=22.2732]Training epoch 19:  83%|████████▎ | 135/163 [02:30<00:29,  1.07s/it, loss=0.4855, batch_acc=0.9375, running_acc=0.8911, grad=22.2732]Training epoch 19:  83%|████████▎ | 135/163 [02:30<00:29,  1.07s/it, loss=0.5125, batch_acc=0.9688, running_acc=0.8917, grad=22.7404]Training epoch 19:  83%|████████▎ | 136/163 [02:31<00:27,  1.01s/it, loss=0.5125, batch_acc=0.9688, running_acc=0.8917, grad=22.7404]Training epoch 19:  83%|████████▎ | 136/163 [02:31<00:27,  1.01s/it, loss=0.6679, batch_acc=0.8750, running_acc=0.8915, grad=23.1588]Training epoch 19:  84%|████████▍ | 137/163 [02:32<00:28,  1.11s/it, loss=0.6679, batch_acc=0.8750, running_acc=0.8915, grad=23.1588]Training epoch 19:  84%|████████▍ | 137/163 [02:32<00:28,  1.11s/it, loss=0.7583, batch_acc=0.8125, running_acc=0.8910, grad=23.5471]Training epoch 19:  85%|████████▍ | 138/163 [02:33<00:26,  1.04s/it, loss=0.7583, batch_acc=0.8125, running_acc=0.8910, grad=23.5471]Training epoch 19:  85%|████████▍ | 138/163 [02:33<00:26,  1.04s/it, loss=0.5821, batch_acc=0.9062, running_acc=0.8911, grad=17.1341]Training epoch 19:  85%|████████▌ | 139/163 [02:34<00:25,  1.07s/it, loss=0.5821, batch_acc=0.9062, running_acc=0.8911, grad=17.1341]Training epoch 19:  85%|████████▌ | 139/163 [02:34<00:25,  1.07s/it, loss=0.5725, batch_acc=0.9375, running_acc=0.8914, grad=16.0797]Training epoch 19:  86%|████████▌ | 140/163 [02:35<00:23,  1.01s/it, loss=0.5725, batch_acc=0.9375, running_acc=0.8914, grad=16.0797]Training epoch 19:  86%|████████▌ | 140/163 [02:35<00:23,  1.01s/it, loss=0.6474, batch_acc=0.9375, running_acc=0.8917, grad=27.3995]Training epoch 19:  87%|████████▋ | 141/163 [02:37<00:24,  1.12s/it, loss=0.6474, batch_acc=0.9375, running_acc=0.8917, grad=27.3995]Training epoch 19:  87%|████████▋ | 141/163 [02:37<00:24,  1.12s/it, loss=0.6870, batch_acc=0.8125, running_acc=0.8912, grad=18.4745]Training epoch 19:  87%|████████▋ | 142/163 [02:38<00:22,  1.05s/it, loss=0.6870, batch_acc=0.8125, running_acc=0.8912, grad=18.4745]Training epoch 19:  87%|████████▋ | 142/163 [02:38<00:22,  1.05s/it, loss=0.7659, batch_acc=0.8438, running_acc=0.8908, grad=25.2980]Training epoch 19:  88%|████████▊ | 143/163 [02:38<00:20,  1.02s/it, loss=0.7659, batch_acc=0.8438, running_acc=0.8908, grad=25.2980]Training epoch 19:  88%|████████▊ | 143/163 [02:38<00:20,  1.02s/it, loss=0.8052, batch_acc=0.8750, running_acc=0.8907, grad=26.0448]Training epoch 19:  88%|████████▊ | 144/163 [02:39<00:18,  1.02it/s, loss=0.8052, batch_acc=0.8750, running_acc=0.8907, grad=26.0448]Training epoch 19:  88%|████████▊ | 144/163 [02:39<00:18,  1.02it/s, loss=0.8177, batch_acc=0.8438, running_acc=0.8904, grad=33.7132]Training epoch 19:  89%|████████▉ | 145/163 [02:41<00:19,  1.07s/it, loss=0.8177, batch_acc=0.8438, running_acc=0.8904, grad=33.7132]Training epoch 19:  89%|████████▉ | 145/163 [02:41<00:19,  1.07s/it, loss=0.8035, batch_acc=0.8750, running_acc=0.8903, grad=35.3765]Training epoch 19:  90%|████████▉ | 146/163 [02:42<00:17,  1.01s/it, loss=0.8035, batch_acc=0.8750, running_acc=0.8903, grad=35.3765]Training epoch 19:  90%|████████▉ | 146/163 [02:42<00:17,  1.01s/it, loss=0.6430, batch_acc=0.9062, running_acc=0.8904, grad=23.6217]Training epoch 19:  90%|█████████ | 147/163 [02:43<00:17,  1.10s/it, loss=0.6430, batch_acc=0.9062, running_acc=0.8904, grad=23.6217]Training epoch 19:  90%|█████████ | 147/163 [02:43<00:17,  1.10s/it, loss=0.7971, batch_acc=0.8125, running_acc=0.8899, grad=24.9061]Training epoch 19:  91%|█████████ | 148/163 [02:44<00:15,  1.03s/it, loss=0.7971, batch_acc=0.8125, running_acc=0.8899, grad=24.9061]Training epoch 19:  91%|█████████ | 148/163 [02:44<00:15,  1.03s/it, loss=0.6152, batch_acc=0.9375, running_acc=0.8902, grad=25.1557]Training epoch 19:  91%|█████████▏| 149/163 [02:45<00:13,  1.01it/s, loss=0.6152, batch_acc=0.9375, running_acc=0.8902, grad=25.1557]Training epoch 19:  91%|█████████▏| 149/163 [02:45<00:13,  1.01it/s, loss=0.6559, batch_acc=0.9375, running_acc=0.8905, grad=22.8797]Training epoch 19:  92%|█████████▏| 150/163 [02:45<00:12,  1.05it/s, loss=0.6559, batch_acc=0.9375, running_acc=0.8905, grad=22.8797]Training epoch 19:  92%|█████████▏| 150/163 [02:45<00:12,  1.05it/s, loss=0.7391, batch_acc=0.9062, running_acc=0.8906, grad=37.5554]Training epoch 19:  93%|█████████▎| 151/163 [02:48<00:15,  1.29s/it, loss=0.7391, batch_acc=0.9062, running_acc=0.8906, grad=37.5554]Training epoch 19:  93%|█████████▎| 151/163 [02:48<00:15,  1.29s/it, loss=0.5864, batch_acc=0.8750, running_acc=0.8905, grad=24.3011]Training epoch 19:  93%|█████████▎| 152/163 [02:48<00:12,  1.17s/it, loss=0.5864, batch_acc=0.8750, running_acc=0.8905, grad=24.3011]Training epoch 19:  93%|█████████▎| 152/163 [02:48<00:12,  1.17s/it, loss=0.6669, batch_acc=0.8438, running_acc=0.8902, grad=25.1571]Training epoch 19:  94%|█████████▍| 153/163 [02:49<00:10,  1.08s/it, loss=0.6669, batch_acc=0.8438, running_acc=0.8902, grad=25.1571]Training epoch 19:  94%|█████████▍| 153/163 [02:49<00:10,  1.08s/it, loss=0.4672, batch_acc=0.9375, running_acc=0.8905, grad=19.2964]Training epoch 19:  94%|█████████▍| 154/163 [02:50<00:09,  1.02s/it, loss=0.4672, batch_acc=0.9375, running_acc=0.8905, grad=19.2964]Training epoch 19:  94%|█████████▍| 154/163 [02:50<00:09,  1.02s/it, loss=0.6251, batch_acc=0.9375, running_acc=0.8908, grad=17.4518]Training epoch 19:  95%|█████████▌| 155/163 [02:52<00:10,  1.25s/it, loss=0.6251, batch_acc=0.9375, running_acc=0.8908, grad=17.4518]Training epoch 19:  95%|█████████▌| 155/163 [02:52<00:10,  1.25s/it, loss=0.6763, batch_acc=0.8438, running_acc=0.8905, grad=21.5924]Training epoch 19:  96%|█████████▌| 156/163 [02:53<00:07,  1.14s/it, loss=0.6763, batch_acc=0.8438, running_acc=0.8905, grad=21.5924]Training epoch 19:  96%|█████████▌| 156/163 [02:53<00:07,  1.14s/it, loss=0.6631, batch_acc=0.9062, running_acc=0.8906, grad=26.9177]Training epoch 19:  96%|█████████▋| 157/163 [02:54<00:06,  1.08s/it, loss=0.6631, batch_acc=0.9062, running_acc=0.8906, grad=26.9177]Training epoch 19:  96%|█████████▋| 157/163 [02:54<00:06,  1.08s/it, loss=0.6885, batch_acc=0.8438, running_acc=0.8903, grad=27.7070]Training epoch 19:  97%|█████████▋| 158/163 [02:55<00:05,  1.02s/it, loss=0.6885, batch_acc=0.8438, running_acc=0.8903, grad=27.7070]Training epoch 19:  97%|█████████▋| 158/163 [02:55<00:05,  1.02s/it, loss=0.5772, batch_acc=0.9688, running_acc=0.8908, grad=23.7532]Training epoch 19:  98%|█████████▊| 159/163 [02:56<00:04,  1.09s/it, loss=0.5772, batch_acc=0.9688, running_acc=0.8908, grad=23.7532]Training epoch 19:  98%|█████████▊| 159/163 [02:56<00:04,  1.09s/it, loss=0.6168, batch_acc=0.8438, running_acc=0.8905, grad=22.0505]Training epoch 19:  98%|█████████▊| 160/163 [02:57<00:03,  1.03s/it, loss=0.6168, batch_acc=0.8438, running_acc=0.8905, grad=22.0505]Training epoch 19:  98%|█████████▊| 160/163 [02:57<00:03,  1.03s/it, loss=0.5793, batch_acc=0.9688, running_acc=0.8910, grad=26.1025]Training epoch 19:  99%|█████████▉| 161/163 [02:58<00:02,  1.02s/it, loss=0.5793, batch_acc=0.9688, running_acc=0.8910, grad=26.1025]Training epoch 19:  99%|█████████▉| 161/163 [02:58<00:02,  1.02s/it, loss=0.6904, batch_acc=0.8438, running_acc=0.8907, grad=22.9824]Training epoch 19:  99%|█████████▉| 162/163 [02:59<00:00,  1.03it/s, loss=0.6904, batch_acc=0.8438, running_acc=0.8907, grad=22.9824]Training epoch 19:  99%|█████████▉| 162/163 [02:59<00:00,  1.03it/s, loss=0.6811, batch_acc=0.9062, running_acc=0.8908, grad=23.1585]Training epoch 19: 100%|██████████| 163/163 [02:59<00:00,  1.14it/s, loss=0.6811, batch_acc=0.9062, running_acc=0.8908, grad=23.1585]Training epoch 19: 100%|██████████| 163/163 [02:59<00:00,  1.14it/s, loss=0.5316, batch_acc=0.8571, running_acc=0.8907, grad=29.4062]Training epoch 19: 100%|██████████| 163/163 [02:59<00:00,  1.10s/it, loss=0.5316, batch_acc=0.8571, running_acc=0.8907, grad=29.4062]
Evaluation epoch 19:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 19:   4%|▎         | 1/28 [00:04<02:10,  4.85s/it]Evaluation epoch 19:   4%|▎         | 1/28 [00:04<02:10,  4.85s/it, loss=0.6945, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 19:   7%|▋         | 2/28 [00:05<00:55,  2.15s/it, loss=0.6945, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 19:   7%|▋         | 2/28 [00:05<00:55,  2.15s/it, loss=0.5816, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 19:  11%|█         | 3/28 [00:05<00:32,  1.29s/it, loss=0.5816, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 19:  11%|█         | 3/28 [00:05<00:32,  1.29s/it, loss=0.7021, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 19:  14%|█▍        | 4/28 [00:10<01:02,  2.62s/it, loss=0.7021, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 19:  14%|█▍        | 4/28 [00:10<01:02,  2.62s/it, loss=1.0812, batch_acc=0.8125, running_acc=0.9062]Evaluation epoch 19:  18%|█▊        | 5/28 [00:10<00:40,  1.77s/it, loss=1.0812, batch_acc=0.8125, running_acc=0.9062]Evaluation epoch 19:  18%|█▊        | 5/28 [00:10<00:40,  1.77s/it, loss=1.7068, batch_acc=0.5625, running_acc=0.8375]Evaluation epoch 19:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=1.7068, batch_acc=0.5625, running_acc=0.8375]Evaluation epoch 19:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=0.8968, batch_acc=0.8438, running_acc=0.8385]Evaluation epoch 19:  25%|██▌       | 7/28 [00:10<00:19,  1.07it/s, loss=0.8968, batch_acc=0.8438, running_acc=0.8385]Evaluation epoch 19:  25%|██▌       | 7/28 [00:10<00:19,  1.07it/s, loss=1.2174, batch_acc=0.7500, running_acc=0.8259]Evaluation epoch 19:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=1.2174, batch_acc=0.7500, running_acc=0.8259]Evaluation epoch 19:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=0.6856, batch_acc=0.8125, running_acc=0.8242]Evaluation epoch 19:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=0.6856, batch_acc=0.8125, running_acc=0.8242]Evaluation epoch 19:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=0.9518, batch_acc=0.8125, running_acc=0.8229]Evaluation epoch 19:  36%|███▌      | 10/28 [00:15<00:18,  1.02s/it, loss=0.9518, batch_acc=0.8125, running_acc=0.8229]Evaluation epoch 19:  36%|███▌      | 10/28 [00:15<00:18,  1.02s/it, loss=0.7004, batch_acc=0.9062, running_acc=0.8313]Evaluation epoch 19:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.7004, batch_acc=0.9062, running_acc=0.8313]Evaluation epoch 19:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.8937, batch_acc=0.7812, running_acc=0.8267]Evaluation epoch 19:  43%|████▎     | 12/28 [00:20<00:33,  2.12s/it, loss=0.8937, batch_acc=0.7812, running_acc=0.8267]Evaluation epoch 19:  43%|████▎     | 12/28 [00:20<00:33,  2.12s/it, loss=1.2438, batch_acc=0.7188, running_acc=0.8177]Evaluation epoch 19:  46%|████▋     | 13/28 [00:20<00:23,  1.56s/it, loss=1.2438, batch_acc=0.7188, running_acc=0.8177]Evaluation epoch 19:  46%|████▋     | 13/28 [00:20<00:23,  1.56s/it, loss=0.4916, batch_acc=0.9062, running_acc=0.8245]Evaluation epoch 19:  50%|█████     | 14/28 [00:20<00:16,  1.17s/it, loss=0.4916, batch_acc=0.9062, running_acc=0.8245]Evaluation epoch 19:  50%|█████     | 14/28 [00:20<00:16,  1.17s/it, loss=1.3408, batch_acc=0.7500, running_acc=0.8192]Evaluation epoch 19:  54%|█████▎    | 15/28 [00:21<00:11,  1.12it/s, loss=1.3408, batch_acc=0.7500, running_acc=0.8192]Evaluation epoch 19:  54%|█████▎    | 15/28 [00:21<00:11,  1.12it/s, loss=1.8248, batch_acc=0.4688, running_acc=0.7958]Evaluation epoch 19:  57%|█████▋    | 16/28 [00:24<00:17,  1.48s/it, loss=1.8248, batch_acc=0.4688, running_acc=0.7958]Evaluation epoch 19:  57%|█████▋    | 16/28 [00:24<00:17,  1.48s/it, loss=1.1393, batch_acc=0.7500, running_acc=0.7930]Evaluation epoch 19:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=1.1393, batch_acc=0.7500, running_acc=0.7930]Evaluation epoch 19:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=0.9355, batch_acc=0.7188, running_acc=0.7886]Evaluation epoch 19:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.9355, batch_acc=0.7188, running_acc=0.7886]Evaluation epoch 19:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=1.0433, batch_acc=0.6875, running_acc=0.7830]Evaluation epoch 19:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=1.0433, batch_acc=0.6875, running_acc=0.7830]Evaluation epoch 19:  68%|██████▊   | 19/28 [00:24<00:06,  1.47it/s, loss=1.0395, batch_acc=0.6562, running_acc=0.7763]Evaluation epoch 19:  71%|███████▏  | 20/28 [00:27<00:10,  1.36s/it, loss=1.0395, batch_acc=0.6562, running_acc=0.7763]Evaluation epoch 19:  71%|███████▏  | 20/28 [00:27<00:10,  1.36s/it, loss=0.8567, batch_acc=0.6875, running_acc=0.7719]Evaluation epoch 19:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.8567, batch_acc=0.6875, running_acc=0.7719]Evaluation epoch 19:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=1.0317, batch_acc=0.7500, running_acc=0.7708]Evaluation epoch 19:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=1.0317, batch_acc=0.7500, running_acc=0.7708]Evaluation epoch 19:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=1.2792, batch_acc=0.6562, running_acc=0.7656]Evaluation epoch 19:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=1.2792, batch_acc=0.6562, running_acc=0.7656]Evaluation epoch 19:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=1.6074, batch_acc=0.5312, running_acc=0.7554]Evaluation epoch 19:  86%|████████▌ | 24/28 [00:33<00:08,  2.06s/it, loss=1.6074, batch_acc=0.5312, running_acc=0.7554]Evaluation epoch 19:  86%|████████▌ | 24/28 [00:33<00:08,  2.06s/it, loss=0.5948, batch_acc=0.9062, running_acc=0.7617]Evaluation epoch 19:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.5948, batch_acc=0.9062, running_acc=0.7617]Evaluation epoch 19:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.4835, batch_acc=0.9375, running_acc=0.7688]Evaluation epoch 19:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.4835, batch_acc=0.9375, running_acc=0.7688]Evaluation epoch 19:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=1.1297, batch_acc=0.6875, running_acc=0.7656]Evaluation epoch 19:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=1.1297, batch_acc=0.6875, running_acc=0.7656]Evaluation epoch 19:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.9915, batch_acc=0.7188, running_acc=0.7639]Evaluation epoch 19: 100%|██████████| 28/28 [00:34<00:00,  1.14it/s, loss=1.3032, batch_acc=0.6667, running_acc=0.7636]Evaluation epoch 19: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.3032, batch_acc=0.6667, running_acc=0.7636]
Training epoch 20:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 20:   1%|          | 1/163 [00:05<15:43,  5.82s/it]Training epoch 20:   1%|          | 1/163 [00:05<15:43,  5.82s/it, loss=0.5071, batch_acc=0.9688, running_acc=0.9688, grad=22.4896]Training epoch 20:   1%|          | 2/163 [00:06<07:54,  2.94s/it, loss=0.5071, batch_acc=0.9688, running_acc=0.9688, grad=22.4896]Training epoch 20:   1%|          | 2/163 [00:06<07:54,  2.94s/it, loss=0.4131, batch_acc=0.8750, running_acc=0.9219, grad=12.4974]Training epoch 20:   2%|▏         | 3/163 [00:07<05:20,  2.00s/it, loss=0.4131, batch_acc=0.8750, running_acc=0.9219, grad=12.4974]Training epoch 20:   2%|▏         | 3/163 [00:07<05:20,  2.00s/it, loss=0.4421, batch_acc=1.0000, running_acc=0.9479, grad=16.2756]Training epoch 20:   2%|▏         | 4/163 [00:10<06:08,  2.32s/it, loss=0.4421, batch_acc=1.0000, running_acc=0.9479, grad=16.2756]Training epoch 20:   2%|▏         | 4/163 [00:10<06:08,  2.32s/it, loss=0.6431, batch_acc=0.9062, running_acc=0.9375, grad=20.7580]Training epoch 20:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=0.6431, batch_acc=0.9062, running_acc=0.9375, grad=20.7580]Training epoch 20:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=0.5196, batch_acc=0.9688, running_acc=0.9437, grad=25.0391]Training epoch 20:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=0.5196, batch_acc=0.9688, running_acc=0.9437, grad=25.0391]Training epoch 20:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=0.7287, batch_acc=0.8750, running_acc=0.9323, grad=30.0606]Training epoch 20:   4%|▍         | 7/163 [00:13<03:20,  1.29s/it, loss=0.7287, batch_acc=0.8750, running_acc=0.9323, grad=30.0606]Training epoch 20:   4%|▍         | 7/163 [00:13<03:20,  1.29s/it, loss=0.5399, batch_acc=0.9375, running_acc=0.9330, grad=17.8600]Training epoch 20:   5%|▍         | 8/163 [00:14<03:35,  1.39s/it, loss=0.5399, batch_acc=0.9375, running_acc=0.9330, grad=17.8600]Training epoch 20:   5%|▍         | 8/163 [00:14<03:35,  1.39s/it, loss=0.6516, batch_acc=0.8750, running_acc=0.9258, grad=22.5834]Training epoch 20:   6%|▌         | 9/163 [00:15<03:09,  1.23s/it, loss=0.6516, batch_acc=0.8750, running_acc=0.9258, grad=22.5834]Training epoch 20:   6%|▌         | 9/163 [00:15<03:09,  1.23s/it, loss=0.7635, batch_acc=0.8438, running_acc=0.9167, grad=28.3549]Training epoch 20:   6%|▌         | 10/163 [00:16<02:51,  1.12s/it, loss=0.7635, batch_acc=0.8438, running_acc=0.9167, grad=28.3549]Training epoch 20:   6%|▌         | 10/163 [00:16<02:51,  1.12s/it, loss=0.5885, batch_acc=0.9375, running_acc=0.9187, grad=17.5719]Training epoch 20:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.5885, batch_acc=0.9375, running_acc=0.9187, grad=17.5719]Training epoch 20:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.7391, batch_acc=0.8750, running_acc=0.9148, grad=22.1357]Training epoch 20:   7%|▋         | 12/163 [00:19<03:16,  1.30s/it, loss=0.7391, batch_acc=0.8750, running_acc=0.9148, grad=22.1357]Training epoch 20:   7%|▋         | 12/163 [00:19<03:16,  1.30s/it, loss=0.6591, batch_acc=0.8125, running_acc=0.9062, grad=21.0293]Training epoch 20:   8%|▊         | 13/163 [00:20<02:56,  1.17s/it, loss=0.6591, batch_acc=0.8125, running_acc=0.9062, grad=21.0293]Training epoch 20:   8%|▊         | 13/163 [00:20<02:56,  1.17s/it, loss=0.4679, batch_acc=1.0000, running_acc=0.9135, grad=20.4854]Training epoch 20:   9%|▊         | 14/163 [00:20<02:41,  1.09s/it, loss=0.4679, batch_acc=1.0000, running_acc=0.9135, grad=20.4854]Training epoch 20:   9%|▊         | 14/163 [00:20<02:41,  1.09s/it, loss=0.6717, batch_acc=0.9375, running_acc=0.9152, grad=24.2112]Training epoch 20:   9%|▉         | 15/163 [00:21<02:31,  1.02s/it, loss=0.6717, batch_acc=0.9375, running_acc=0.9152, grad=24.2112]Training epoch 20:   9%|▉         | 15/163 [00:21<02:31,  1.02s/it, loss=0.6109, batch_acc=0.9688, running_acc=0.9187, grad=24.3216]Training epoch 20:  10%|▉         | 16/163 [00:23<03:03,  1.25s/it, loss=0.6109, batch_acc=0.9688, running_acc=0.9187, grad=24.3216]Training epoch 20:  10%|▉         | 16/163 [00:23<03:03,  1.25s/it, loss=0.5077, batch_acc=0.9062, running_acc=0.9180, grad=20.4880]Training epoch 20:  10%|█         | 17/163 [00:24<02:45,  1.14s/it, loss=0.5077, batch_acc=0.9062, running_acc=0.9180, grad=20.4880]Training epoch 20:  10%|█         | 17/163 [00:24<02:45,  1.14s/it, loss=0.6678, batch_acc=0.9375, running_acc=0.9191, grad=28.8476]Training epoch 20:  11%|█         | 18/163 [00:25<02:34,  1.06s/it, loss=0.6678, batch_acc=0.9375, running_acc=0.9191, grad=28.8476]Training epoch 20:  11%|█         | 18/163 [00:25<02:34,  1.06s/it, loss=0.7468, batch_acc=0.8750, running_acc=0.9167, grad=24.9906]Training epoch 20:  12%|█▏        | 19/163 [00:26<02:25,  1.01s/it, loss=0.7468, batch_acc=0.8750, running_acc=0.9167, grad=24.9906]Training epoch 20:  12%|█▏        | 19/163 [00:26<02:25,  1.01s/it, loss=0.6734, batch_acc=0.9062, running_acc=0.9161, grad=25.8759]Training epoch 20:  12%|█▏        | 20/163 [00:27<02:48,  1.18s/it, loss=0.6734, batch_acc=0.9062, running_acc=0.9161, grad=25.8759]Training epoch 20:  12%|█▏        | 20/163 [00:27<02:48,  1.18s/it, loss=0.6791, batch_acc=0.7812, running_acc=0.9094, grad=25.4783]Training epoch 20:  13%|█▎        | 21/163 [00:28<02:34,  1.09s/it, loss=0.6791, batch_acc=0.7812, running_acc=0.9094, grad=25.4783]Training epoch 20:  13%|█▎        | 21/163 [00:28<02:34,  1.09s/it, loss=0.4568, batch_acc=0.9688, running_acc=0.9122, grad=18.4639]Training epoch 20:  13%|█▎        | 22/163 [00:29<02:24,  1.03s/it, loss=0.4568, batch_acc=0.9688, running_acc=0.9122, grad=18.4639]Training epoch 20:  13%|█▎        | 22/163 [00:29<02:24,  1.03s/it, loss=0.4812, batch_acc=0.9062, running_acc=0.9119, grad=23.6250]Training epoch 20:  14%|█▍        | 23/163 [00:30<02:17,  1.02it/s, loss=0.4812, batch_acc=0.9062, running_acc=0.9119, grad=23.6250]Training epoch 20:  14%|█▍        | 23/163 [00:30<02:17,  1.02it/s, loss=0.7218, batch_acc=0.9062, running_acc=0.9117, grad=20.5359]Training epoch 20:  15%|█▍        | 24/163 [00:31<02:36,  1.13s/it, loss=0.7218, batch_acc=0.9062, running_acc=0.9117, grad=20.5359]Training epoch 20:  15%|█▍        | 24/163 [00:31<02:36,  1.13s/it, loss=0.5925, batch_acc=0.8750, running_acc=0.9102, grad=27.1334]Training epoch 20:  15%|█▌        | 25/163 [00:32<02:25,  1.05s/it, loss=0.5925, batch_acc=0.8750, running_acc=0.9102, grad=27.1334]Training epoch 20:  15%|█▌        | 25/163 [00:32<02:25,  1.05s/it, loss=0.5298, batch_acc=0.9375, running_acc=0.9113, grad=17.4534]Training epoch 20:  16%|█▌        | 26/163 [00:33<02:17,  1.00s/it, loss=0.5298, batch_acc=0.9375, running_acc=0.9113, grad=17.4534]Training epoch 20:  16%|█▌        | 26/163 [00:33<02:17,  1.00s/it, loss=0.6019, batch_acc=0.9375, running_acc=0.9123, grad=27.4364]Training epoch 20:  17%|█▋        | 27/163 [00:34<02:11,  1.04it/s, loss=0.6019, batch_acc=0.9375, running_acc=0.9123, grad=27.4364]Training epoch 20:  17%|█▋        | 27/163 [00:34<02:11,  1.04it/s, loss=0.8709, batch_acc=0.8438, running_acc=0.9097, grad=22.8181]Training epoch 20:  17%|█▋        | 28/163 [00:37<03:11,  1.42s/it, loss=0.8709, batch_acc=0.8438, running_acc=0.9097, grad=22.8181]Training epoch 20:  17%|█▋        | 28/163 [00:37<03:11,  1.42s/it, loss=0.5842, batch_acc=0.9062, running_acc=0.9096, grad=25.1736]Training epoch 20:  18%|█▊        | 29/163 [00:37<02:48,  1.26s/it, loss=0.5842, batch_acc=0.9062, running_acc=0.9096, grad=25.1736]Training epoch 20:  18%|█▊        | 29/163 [00:37<02:48,  1.26s/it, loss=0.6315, batch_acc=0.9062, running_acc=0.9095, grad=23.0071]Training epoch 20:  18%|█▊        | 30/163 [00:38<02:32,  1.14s/it, loss=0.6315, batch_acc=0.9062, running_acc=0.9095, grad=23.0071]Training epoch 20:  18%|█▊        | 30/163 [00:38<02:32,  1.14s/it, loss=0.5254, batch_acc=0.9688, running_acc=0.9115, grad=24.6837]Training epoch 20:  19%|█▉        | 31/163 [00:39<02:20,  1.06s/it, loss=0.5254, batch_acc=0.9688, running_acc=0.9115, grad=24.6837]Training epoch 20:  19%|█▉        | 31/163 [00:39<02:20,  1.06s/it, loss=0.7034, batch_acc=0.8750, running_acc=0.9103, grad=23.2445]Training epoch 20:  20%|█▉        | 32/163 [00:41<02:38,  1.21s/it, loss=0.7034, batch_acc=0.8750, running_acc=0.9103, grad=23.2445]Training epoch 20:  20%|█▉        | 32/163 [00:41<02:38,  1.21s/it, loss=0.5302, batch_acc=0.9688, running_acc=0.9121, grad=22.3654]Training epoch 20:  20%|██        | 33/163 [00:42<02:24,  1.11s/it, loss=0.5302, batch_acc=0.9688, running_acc=0.9121, grad=22.3654]Training epoch 20:  20%|██        | 33/163 [00:42<02:24,  1.11s/it, loss=0.4776, batch_acc=0.9688, running_acc=0.9138, grad=20.6229]Training epoch 20:  21%|██        | 34/163 [00:43<02:14,  1.04s/it, loss=0.4776, batch_acc=0.9688, running_acc=0.9138, grad=20.6229]Training epoch 20:  21%|██        | 34/163 [00:43<02:14,  1.04s/it, loss=0.4741, batch_acc=0.9062, running_acc=0.9136, grad=15.8381]Training epoch 20:  21%|██▏       | 35/163 [00:43<02:07,  1.01it/s, loss=0.4741, batch_acc=0.9062, running_acc=0.9136, grad=15.8381]Training epoch 20:  21%|██▏       | 35/163 [00:43<02:07,  1.01it/s, loss=0.6072, batch_acc=0.8750, running_acc=0.9125, grad=26.9719]Training epoch 20:  22%|██▏       | 36/163 [00:45<02:43,  1.29s/it, loss=0.6072, batch_acc=0.8750, running_acc=0.9125, grad=26.9719]Training epoch 20:  22%|██▏       | 36/163 [00:45<02:43,  1.29s/it, loss=0.5815, batch_acc=0.9688, running_acc=0.9141, grad=23.3210]Training epoch 20:  23%|██▎       | 37/163 [00:46<02:26,  1.17s/it, loss=0.5815, batch_acc=0.9688, running_acc=0.9141, grad=23.3210]Training epoch 20:  23%|██▎       | 37/163 [00:46<02:26,  1.17s/it, loss=0.5579, batch_acc=0.9688, running_acc=0.9155, grad=22.9059]Training epoch 20:  23%|██▎       | 38/163 [00:47<02:15,  1.08s/it, loss=0.5579, batch_acc=0.9688, running_acc=0.9155, grad=22.9059]Training epoch 20:  23%|██▎       | 38/163 [00:47<02:15,  1.08s/it, loss=0.7589, batch_acc=0.8750, running_acc=0.9145, grad=27.3536]Training epoch 20:  24%|██▍       | 39/163 [00:48<02:06,  1.02s/it, loss=0.7589, batch_acc=0.8750, running_acc=0.9145, grad=27.3536]Training epoch 20:  24%|██▍       | 39/163 [00:48<02:06,  1.02s/it, loss=0.5188, batch_acc=0.9062, running_acc=0.9143, grad=22.9544]Training epoch 20:  25%|██▍       | 40/163 [00:49<02:18,  1.13s/it, loss=0.5188, batch_acc=0.9062, running_acc=0.9143, grad=22.9544]Training epoch 20:  25%|██▍       | 40/163 [00:49<02:18,  1.13s/it, loss=0.4554, batch_acc=0.9688, running_acc=0.9156, grad=16.6421]Training epoch 20:  25%|██▌       | 41/163 [00:50<02:08,  1.05s/it, loss=0.4554, batch_acc=0.9688, running_acc=0.9156, grad=16.6421]Training epoch 20:  25%|██▌       | 41/163 [00:50<02:08,  1.05s/it, loss=0.5733, batch_acc=0.9375, running_acc=0.9162, grad=21.7860]Training epoch 20:  26%|██▌       | 42/163 [00:51<02:01,  1.00s/it, loss=0.5733, batch_acc=0.9375, running_acc=0.9162, grad=21.7860]Training epoch 20:  26%|██▌       | 42/163 [00:51<02:01,  1.00s/it, loss=0.7397, batch_acc=0.8125, running_acc=0.9137, grad=18.7824]Training epoch 20:  26%|██▋       | 43/163 [00:52<01:55,  1.04it/s, loss=0.7397, batch_acc=0.8125, running_acc=0.9137, grad=18.7824]Training epoch 20:  26%|██▋       | 43/163 [00:52<01:55,  1.04it/s, loss=0.4952, batch_acc=0.9375, running_acc=0.9142, grad=17.5055]Training epoch 20:  27%|██▋       | 44/163 [00:53<02:07,  1.07s/it, loss=0.4952, batch_acc=0.9375, running_acc=0.9142, grad=17.5055]Training epoch 20:  27%|██▋       | 44/163 [00:53<02:07,  1.07s/it, loss=0.4908, batch_acc=0.9375, running_acc=0.9148, grad=19.0125]Training epoch 20:  28%|██▊       | 45/163 [00:54<01:59,  1.02s/it, loss=0.4908, batch_acc=0.9375, running_acc=0.9148, grad=19.0125]Training epoch 20:  28%|██▊       | 45/163 [00:54<01:59,  1.02s/it, loss=0.6270, batch_acc=0.8750, running_acc=0.9139, grad=26.7232]Training epoch 20:  28%|██▊       | 46/163 [00:55<01:54,  1.03it/s, loss=0.6270, batch_acc=0.8750, running_acc=0.9139, grad=26.7232]Training epoch 20:  28%|██▊       | 46/163 [00:55<01:54,  1.03it/s, loss=0.7016, batch_acc=0.8750, running_acc=0.9130, grad=24.5315]Training epoch 20:  29%|██▉       | 47/163 [00:56<01:49,  1.06it/s, loss=0.7016, batch_acc=0.8750, running_acc=0.9130, grad=24.5315]Training epoch 20:  29%|██▉       | 47/163 [00:56<01:49,  1.06it/s, loss=0.5612, batch_acc=0.9375, running_acc=0.9136, grad=21.7325]Training epoch 20:  29%|██▉       | 48/163 [00:57<02:00,  1.05s/it, loss=0.5612, batch_acc=0.9375, running_acc=0.9136, grad=21.7325]Training epoch 20:  29%|██▉       | 48/163 [00:57<02:00,  1.05s/it, loss=0.4322, batch_acc=0.9688, running_acc=0.9147, grad=18.5776]Training epoch 20:  30%|███       | 49/163 [00:58<01:53,  1.00it/s, loss=0.4322, batch_acc=0.9688, running_acc=0.9147, grad=18.5776]Training epoch 20:  30%|███       | 49/163 [00:58<01:53,  1.00it/s, loss=0.5557, batch_acc=0.8750, running_acc=0.9139, grad=22.7565]Training epoch 20:  31%|███       | 50/163 [00:59<01:48,  1.04it/s, loss=0.5557, batch_acc=0.8750, running_acc=0.9139, grad=22.7565]Training epoch 20:  31%|███       | 50/163 [00:59<01:48,  1.04it/s, loss=0.5559, batch_acc=0.9375, running_acc=0.9144, grad=20.9898]Training epoch 20:  31%|███▏      | 51/163 [01:00<01:45,  1.06it/s, loss=0.5559, batch_acc=0.9375, running_acc=0.9144, grad=20.9898]Training epoch 20:  31%|███▏      | 51/163 [01:00<01:45,  1.06it/s, loss=0.7679, batch_acc=0.9375, running_acc=0.9148, grad=28.7136]Training epoch 20:  32%|███▏      | 52/163 [01:02<02:15,  1.22s/it, loss=0.7679, batch_acc=0.9375, running_acc=0.9148, grad=28.7136]Training epoch 20:  32%|███▏      | 52/163 [01:02<02:15,  1.22s/it, loss=0.6067, batch_acc=0.8750, running_acc=0.9141, grad=23.9301]Training epoch 20:  33%|███▎      | 53/163 [01:03<02:03,  1.12s/it, loss=0.6067, batch_acc=0.8750, running_acc=0.9141, grad=23.9301]Training epoch 20:  33%|███▎      | 53/163 [01:03<02:03,  1.12s/it, loss=0.4832, batch_acc=0.9375, running_acc=0.9145, grad=19.9977]Training epoch 20:  33%|███▎      | 54/163 [01:04<01:54,  1.05s/it, loss=0.4832, batch_acc=0.9375, running_acc=0.9145, grad=19.9977]Training epoch 20:  33%|███▎      | 54/163 [01:04<01:54,  1.05s/it, loss=0.6834, batch_acc=0.9375, running_acc=0.9149, grad=22.7006]Training epoch 20:  34%|███▎      | 55/163 [01:04<01:47,  1.00it/s, loss=0.6834, batch_acc=0.9375, running_acc=0.9149, grad=22.7006]Training epoch 20:  34%|███▎      | 55/163 [01:04<01:47,  1.00it/s, loss=0.5540, batch_acc=0.9062, running_acc=0.9148, grad=20.9116]Training epoch 20:  34%|███▍      | 56/163 [01:06<01:51,  1.04s/it, loss=0.5540, batch_acc=0.9062, running_acc=0.9148, grad=20.9116]Training epoch 20:  34%|███▍      | 56/163 [01:06<01:51,  1.04s/it, loss=0.5168, batch_acc=0.9062, running_acc=0.9146, grad=18.4762]Training epoch 20:  35%|███▍      | 57/163 [01:06<01:45,  1.00it/s, loss=0.5168, batch_acc=0.9062, running_acc=0.9146, grad=18.4762]Training epoch 20:  35%|███▍      | 57/163 [01:06<01:45,  1.00it/s, loss=0.8045, batch_acc=0.8125, running_acc=0.9128, grad=34.5958]Training epoch 20:  36%|███▌      | 58/163 [01:07<01:40,  1.04it/s, loss=0.8045, batch_acc=0.8125, running_acc=0.9128, grad=34.5958]Training epoch 20:  36%|███▌      | 58/163 [01:07<01:40,  1.04it/s, loss=0.6620, batch_acc=0.9062, running_acc=0.9127, grad=20.3125]Training epoch 20:  36%|███▌      | 59/163 [01:08<01:37,  1.07it/s, loss=0.6620, batch_acc=0.9062, running_acc=0.9127, grad=20.3125]Training epoch 20:  36%|███▌      | 59/163 [01:08<01:37,  1.07it/s, loss=0.5686, batch_acc=0.8750, running_acc=0.9121, grad=18.5885]Training epoch 20:  37%|███▋      | 60/163 [01:10<02:10,  1.26s/it, loss=0.5686, batch_acc=0.8750, running_acc=0.9121, grad=18.5885]Training epoch 20:  37%|███▋      | 60/163 [01:10<02:10,  1.26s/it, loss=0.7818, batch_acc=0.8438, running_acc=0.9109, grad=26.9230]Training epoch 20:  37%|███▋      | 61/163 [01:11<01:57,  1.15s/it, loss=0.7818, batch_acc=0.8438, running_acc=0.9109, grad=26.9230]Training epoch 20:  37%|███▋      | 61/163 [01:11<01:57,  1.15s/it, loss=0.5870, batch_acc=0.8125, running_acc=0.9093, grad=20.4759]Training epoch 20:  38%|███▊      | 62/163 [01:12<01:47,  1.07s/it, loss=0.5870, batch_acc=0.8125, running_acc=0.9093, grad=20.4759]Training epoch 20:  38%|███▊      | 62/163 [01:12<01:47,  1.07s/it, loss=0.4774, batch_acc=0.9375, running_acc=0.9098, grad=19.8024]Training epoch 20:  39%|███▊      | 63/163 [01:13<01:42,  1.03s/it, loss=0.4774, batch_acc=0.9375, running_acc=0.9098, grad=19.8024]Training epoch 20:  39%|███▊      | 63/163 [01:13<01:42,  1.03s/it, loss=0.9143, batch_acc=0.8438, running_acc=0.9087, grad=31.2997]Training epoch 20:  39%|███▉      | 64/163 [01:15<02:19,  1.41s/it, loss=0.9143, batch_acc=0.8438, running_acc=0.9087, grad=31.2997]Training epoch 20:  39%|███▉      | 64/163 [01:15<02:19,  1.41s/it, loss=0.5830, batch_acc=0.9062, running_acc=0.9087, grad=30.1213]Training epoch 20:  40%|███▉      | 65/163 [01:16<02:02,  1.25s/it, loss=0.5830, batch_acc=0.9062, running_acc=0.9087, grad=30.1213]Training epoch 20:  40%|███▉      | 65/163 [01:16<02:02,  1.25s/it, loss=0.7019, batch_acc=0.8438, running_acc=0.9077, grad=25.5659]Training epoch 20:  40%|████      | 66/163 [01:17<01:50,  1.14s/it, loss=0.7019, batch_acc=0.8438, running_acc=0.9077, grad=25.5659]Training epoch 20:  40%|████      | 66/163 [01:17<01:50,  1.14s/it, loss=0.6498, batch_acc=0.9062, running_acc=0.9077, grad=25.7153]Training epoch 20:  41%|████      | 67/163 [01:18<01:41,  1.06s/it, loss=0.6498, batch_acc=0.9062, running_acc=0.9077, grad=25.7153]Training epoch 20:  41%|████      | 67/163 [01:18<01:41,  1.06s/it, loss=0.6709, batch_acc=0.9062, running_acc=0.9076, grad=24.9392]Training epoch 20:  42%|████▏     | 68/163 [01:20<02:15,  1.43s/it, loss=0.6709, batch_acc=0.9062, running_acc=0.9076, grad=24.9392]Training epoch 20:  42%|████▏     | 68/163 [01:20<02:15,  1.43s/it, loss=0.5283, batch_acc=0.9062, running_acc=0.9076, grad=20.5934]Training epoch 20:  42%|████▏     | 69/163 [01:21<01:58,  1.27s/it, loss=0.5283, batch_acc=0.9062, running_acc=0.9076, grad=20.5934]Training epoch 20:  42%|████▏     | 69/163 [01:21<01:58,  1.27s/it, loss=0.5496, batch_acc=1.0000, running_acc=0.9090, grad=22.8833]Training epoch 20:  43%|████▎     | 70/163 [01:22<01:46,  1.15s/it, loss=0.5496, batch_acc=1.0000, running_acc=0.9090, grad=22.8833]Training epoch 20:  43%|████▎     | 70/163 [01:22<01:46,  1.15s/it, loss=0.5014, batch_acc=0.9688, running_acc=0.9098, grad=23.4682]Training epoch 20:  44%|████▎     | 71/163 [01:23<01:38,  1.07s/it, loss=0.5014, batch_acc=0.9688, running_acc=0.9098, grad=23.4682]Training epoch 20:  44%|████▎     | 71/163 [01:23<01:38,  1.07s/it, loss=0.5666, batch_acc=0.8438, running_acc=0.9089, grad=23.8280]Training epoch 20:  44%|████▍     | 72/163 [01:25<02:12,  1.46s/it, loss=0.5666, batch_acc=0.8438, running_acc=0.9089, grad=23.8280]Training epoch 20:  44%|████▍     | 72/163 [01:25<02:12,  1.46s/it, loss=0.6460, batch_acc=0.8750, running_acc=0.9084, grad=28.2749]Training epoch 20:  45%|████▍     | 73/163 [01:26<01:55,  1.28s/it, loss=0.6460, batch_acc=0.8750, running_acc=0.9084, grad=28.2749]Training epoch 20:  45%|████▍     | 73/163 [01:26<01:55,  1.28s/it, loss=0.5795, batch_acc=0.8438, running_acc=0.9075, grad=21.7107]Training epoch 20:  45%|████▌     | 74/163 [01:27<01:43,  1.16s/it, loss=0.5795, batch_acc=0.8438, running_acc=0.9075, grad=21.7107]Training epoch 20:  45%|████▌     | 74/163 [01:27<01:43,  1.16s/it, loss=0.7646, batch_acc=0.8438, running_acc=0.9067, grad=27.3964]Training epoch 20:  46%|████▌     | 75/163 [01:28<01:34,  1.08s/it, loss=0.7646, batch_acc=0.8438, running_acc=0.9067, grad=27.3964]Training epoch 20:  46%|████▌     | 75/163 [01:28<01:34,  1.08s/it, loss=0.4359, batch_acc=1.0000, running_acc=0.9079, grad=18.1071]Training epoch 20:  47%|████▋     | 76/163 [01:30<01:52,  1.30s/it, loss=0.4359, batch_acc=1.0000, running_acc=0.9079, grad=18.1071]Training epoch 20:  47%|████▋     | 76/163 [01:30<01:52,  1.30s/it, loss=0.6821, batch_acc=0.9062, running_acc=0.9079, grad=18.6229]Training epoch 20:  47%|████▋     | 77/163 [01:31<01:40,  1.17s/it, loss=0.6821, batch_acc=0.9062, running_acc=0.9079, grad=18.6229]Training epoch 20:  47%|████▋     | 77/163 [01:31<01:40,  1.17s/it, loss=0.6626, batch_acc=0.9375, running_acc=0.9083, grad=25.8917]Training epoch 20:  48%|████▊     | 78/163 [01:31<01:32,  1.08s/it, loss=0.6626, batch_acc=0.9375, running_acc=0.9083, grad=25.8917]Training epoch 20:  48%|████▊     | 78/163 [01:31<01:32,  1.08s/it, loss=0.7427, batch_acc=0.7500, running_acc=0.9062, grad=30.0780]Training epoch 20:  48%|████▊     | 79/163 [01:32<01:25,  1.02s/it, loss=0.7427, batch_acc=0.7500, running_acc=0.9062, grad=30.0780]Training epoch 20:  48%|████▊     | 79/163 [01:32<01:25,  1.02s/it, loss=0.6156, batch_acc=0.9688, running_acc=0.9070, grad=22.1877]Training epoch 20:  49%|████▉     | 80/163 [01:34<01:49,  1.32s/it, loss=0.6156, batch_acc=0.9688, running_acc=0.9070, grad=22.1877]Training epoch 20:  49%|████▉     | 80/163 [01:34<01:49,  1.32s/it, loss=0.8402, batch_acc=0.8750, running_acc=0.9066, grad=29.1457]Training epoch 20:  50%|████▉     | 81/163 [01:35<01:37,  1.19s/it, loss=0.8402, batch_acc=0.8750, running_acc=0.9066, grad=29.1457]Training epoch 20:  50%|████▉     | 81/163 [01:35<01:37,  1.19s/it, loss=0.5392, batch_acc=0.9062, running_acc=0.9066, grad=20.6213]Training epoch 20:  50%|█████     | 82/163 [01:36<01:28,  1.10s/it, loss=0.5392, batch_acc=0.9062, running_acc=0.9066, grad=20.6213]Training epoch 20:  50%|█████     | 82/163 [01:36<01:28,  1.10s/it, loss=0.6393, batch_acc=0.8750, running_acc=0.9062, grad=30.0385]Training epoch 20:  51%|█████     | 83/163 [01:37<01:22,  1.03s/it, loss=0.6393, batch_acc=0.8750, running_acc=0.9062, grad=30.0385]Training epoch 20:  51%|█████     | 83/163 [01:37<01:22,  1.03s/it, loss=0.6100, batch_acc=0.9062, running_acc=0.9062, grad=24.1042]Training epoch 20:  52%|█████▏    | 84/163 [01:39<01:43,  1.31s/it, loss=0.6100, batch_acc=0.9062, running_acc=0.9062, grad=24.1042]Training epoch 20:  52%|█████▏    | 84/163 [01:39<01:43,  1.31s/it, loss=0.5666, batch_acc=0.9375, running_acc=0.9066, grad=25.1537]Training epoch 20:  52%|█████▏    | 85/163 [01:40<01:31,  1.18s/it, loss=0.5666, batch_acc=0.9375, running_acc=0.9066, grad=25.1537]Training epoch 20:  52%|█████▏    | 85/163 [01:40<01:31,  1.18s/it, loss=0.6468, batch_acc=0.8438, running_acc=0.9059, grad=34.2261]Training epoch 20:  53%|█████▎    | 86/163 [01:41<01:23,  1.09s/it, loss=0.6468, batch_acc=0.8438, running_acc=0.9059, grad=34.2261]Training epoch 20:  53%|█████▎    | 86/163 [01:41<01:23,  1.09s/it, loss=0.6406, batch_acc=0.9375, running_acc=0.9062, grad=21.8769]Training epoch 20:  53%|█████▎    | 87/163 [01:42<01:18,  1.03s/it, loss=0.6406, batch_acc=0.9375, running_acc=0.9062, grad=21.8769]Training epoch 20:  53%|█████▎    | 87/163 [01:42<01:18,  1.03s/it, loss=0.5557, batch_acc=0.9062, running_acc=0.9062, grad=21.2590]Training epoch 20:  54%|█████▍    | 88/163 [01:43<01:37,  1.30s/it, loss=0.5557, batch_acc=0.9062, running_acc=0.9062, grad=21.2590]Training epoch 20:  54%|█████▍    | 88/163 [01:43<01:37,  1.30s/it, loss=0.5570, batch_acc=0.9375, running_acc=0.9066, grad=27.1688]Training epoch 20:  55%|█████▍    | 89/163 [01:44<01:26,  1.17s/it, loss=0.5570, batch_acc=0.9375, running_acc=0.9066, grad=27.1688]Training epoch 20:  55%|█████▍    | 89/163 [01:44<01:26,  1.17s/it, loss=0.5616, batch_acc=0.9375, running_acc=0.9070, grad=23.3577]Training epoch 20:  55%|█████▌    | 90/163 [01:45<01:19,  1.08s/it, loss=0.5616, batch_acc=0.9375, running_acc=0.9070, grad=23.3577]Training epoch 20:  55%|█████▌    | 90/163 [01:45<01:19,  1.08s/it, loss=0.6885, batch_acc=0.8750, running_acc=0.9066, grad=25.0862]Training epoch 20:  56%|█████▌    | 91/163 [01:46<01:13,  1.02s/it, loss=0.6885, batch_acc=0.8750, running_acc=0.9066, grad=25.0862]Training epoch 20:  56%|█████▌    | 91/163 [01:46<01:13,  1.02s/it, loss=0.7566, batch_acc=0.8750, running_acc=0.9062, grad=32.8915]Training epoch 20:  56%|█████▋    | 92/163 [01:47<01:18,  1.11s/it, loss=0.7566, batch_acc=0.8750, running_acc=0.9062, grad=32.8915]Training epoch 20:  56%|█████▋    | 92/163 [01:47<01:18,  1.11s/it, loss=0.5186, batch_acc=0.8750, running_acc=0.9059, grad=24.5268]Training epoch 20:  57%|█████▋    | 93/163 [01:48<01:12,  1.04s/it, loss=0.5186, batch_acc=0.8750, running_acc=0.9059, grad=24.5268]Training epoch 20:  57%|█████▋    | 93/163 [01:48<01:12,  1.04s/it, loss=0.5112, batch_acc=0.9375, running_acc=0.9062, grad=16.1413]Training epoch 20:  58%|█████▊    | 94/163 [01:49<01:08,  1.01it/s, loss=0.5112, batch_acc=0.9375, running_acc=0.9062, grad=16.1413]Training epoch 20:  58%|█████▊    | 94/163 [01:49<01:08,  1.01it/s, loss=0.5892, batch_acc=0.8125, running_acc=0.9053, grad=24.5863]Training epoch 20:  58%|█████▊    | 95/163 [01:50<01:05,  1.04it/s, loss=0.5892, batch_acc=0.8125, running_acc=0.9053, grad=24.5863]Training epoch 20:  58%|█████▊    | 95/163 [01:50<01:05,  1.04it/s, loss=0.5614, batch_acc=0.9062, running_acc=0.9053, grad=21.9137]Training epoch 20:  59%|█████▉    | 96/163 [01:51<01:13,  1.10s/it, loss=0.5614, batch_acc=0.9062, running_acc=0.9053, grad=21.9137]Training epoch 20:  59%|█████▉    | 96/163 [01:51<01:13,  1.10s/it, loss=0.6522, batch_acc=0.9062, running_acc=0.9053, grad=26.4510]Training epoch 20:  60%|█████▉    | 97/163 [01:52<01:08,  1.04s/it, loss=0.6522, batch_acc=0.9062, running_acc=0.9053, grad=26.4510]Training epoch 20:  60%|█████▉    | 97/163 [01:52<01:08,  1.04s/it, loss=0.5463, batch_acc=0.8438, running_acc=0.9046, grad=20.5665]Training epoch 20:  60%|██████    | 98/163 [01:53<01:04,  1.01it/s, loss=0.5463, batch_acc=0.8438, running_acc=0.9046, grad=20.5665]Training epoch 20:  60%|██████    | 98/163 [01:53<01:04,  1.01it/s, loss=0.7519, batch_acc=0.8438, running_acc=0.9040, grad=22.8175]Training epoch 20:  61%|██████    | 99/163 [01:54<01:01,  1.05it/s, loss=0.7519, batch_acc=0.8438, running_acc=0.9040, grad=22.8175]Training epoch 20:  61%|██████    | 99/163 [01:54<01:01,  1.05it/s, loss=0.4914, batch_acc=0.9375, running_acc=0.9044, grad=22.0350]Training epoch 20:  61%|██████▏   | 100/163 [01:55<01:06,  1.05s/it, loss=0.4914, batch_acc=0.9375, running_acc=0.9044, grad=22.0350]Training epoch 20:  61%|██████▏   | 100/163 [01:55<01:06,  1.05s/it, loss=0.4234, batch_acc=0.9375, running_acc=0.9047, grad=15.2425]Training epoch 20:  62%|██████▏   | 101/163 [01:56<01:02,  1.00s/it, loss=0.4234, batch_acc=0.9375, running_acc=0.9047, grad=15.2425]Training epoch 20:  62%|██████▏   | 101/163 [01:56<01:02,  1.00s/it, loss=0.5369, batch_acc=0.8750, running_acc=0.9044, grad=21.0676]Training epoch 20:  63%|██████▎   | 102/163 [01:57<00:58,  1.04it/s, loss=0.5369, batch_acc=0.8750, running_acc=0.9044, grad=21.0676]Training epoch 20:  63%|██████▎   | 102/163 [01:57<00:58,  1.04it/s, loss=0.6960, batch_acc=0.9375, running_acc=0.9047, grad=38.4933]Training epoch 20:  63%|██████▎   | 103/163 [01:58<00:56,  1.06it/s, loss=0.6960, batch_acc=0.9375, running_acc=0.9047, grad=38.4933]Training epoch 20:  63%|██████▎   | 103/163 [01:58<00:56,  1.06it/s, loss=0.6073, batch_acc=0.9062, running_acc=0.9047, grad=28.7201]Training epoch 20:  64%|██████▍   | 104/163 [02:00<01:07,  1.14s/it, loss=0.6073, batch_acc=0.9062, running_acc=0.9047, grad=28.7201]Training epoch 20:  64%|██████▍   | 104/163 [02:00<01:07,  1.14s/it, loss=0.5539, batch_acc=0.9688, running_acc=0.9053, grad=33.9520]Training epoch 20:  64%|██████▍   | 105/163 [02:01<01:01,  1.06s/it, loss=0.5539, batch_acc=0.9688, running_acc=0.9053, grad=33.9520]Training epoch 20:  64%|██████▍   | 105/163 [02:01<01:01,  1.06s/it, loss=0.3803, batch_acc=0.9688, running_acc=0.9060, grad=14.8864]Training epoch 20:  65%|██████▌   | 106/163 [02:01<00:57,  1.01s/it, loss=0.3803, batch_acc=0.9688, running_acc=0.9060, grad=14.8864]Training epoch 20:  65%|██████▌   | 106/163 [02:01<00:57,  1.01s/it, loss=0.6731, batch_acc=0.8438, running_acc=0.9054, grad=25.6785]Training epoch 20:  66%|██████▌   | 107/163 [02:02<00:54,  1.03it/s, loss=0.6731, batch_acc=0.8438, running_acc=0.9054, grad=25.6785]Training epoch 20:  66%|██████▌   | 107/163 [02:02<00:54,  1.03it/s, loss=0.6475, batch_acc=0.9062, running_acc=0.9054, grad=22.1205]Training epoch 20:  66%|██████▋   | 108/163 [02:04<01:07,  1.24s/it, loss=0.6475, batch_acc=0.9062, running_acc=0.9054, grad=22.1205]Training epoch 20:  66%|██████▋   | 108/163 [02:04<01:07,  1.24s/it, loss=0.5960, batch_acc=0.9375, running_acc=0.9057, grad=31.2976]Training epoch 20:  67%|██████▋   | 109/163 [02:05<01:00,  1.13s/it, loss=0.5960, batch_acc=0.9375, running_acc=0.9057, grad=31.2976]Training epoch 20:  67%|██████▋   | 109/163 [02:05<01:00,  1.13s/it, loss=0.5328, batch_acc=0.9375, running_acc=0.9060, grad=21.4270]Training epoch 20:  67%|██████▋   | 110/163 [02:06<00:55,  1.05s/it, loss=0.5328, batch_acc=0.9375, running_acc=0.9060, grad=21.4270]Training epoch 20:  67%|██████▋   | 110/163 [02:06<00:55,  1.05s/it, loss=0.4943, batch_acc=0.9688, running_acc=0.9065, grad=16.2054]Training epoch 20:  68%|██████▊   | 111/163 [02:07<00:53,  1.04s/it, loss=0.4943, batch_acc=0.9688, running_acc=0.9065, grad=16.2054]Training epoch 20:  68%|██████▊   | 111/163 [02:07<00:53,  1.04s/it, loss=0.5858, batch_acc=0.9062, running_acc=0.9065, grad=22.4489]Training epoch 20:  69%|██████▊   | 112/163 [02:08<00:59,  1.17s/it, loss=0.5858, batch_acc=0.9062, running_acc=0.9065, grad=22.4489]Training epoch 20:  69%|██████▊   | 112/163 [02:08<00:59,  1.17s/it, loss=0.6131, batch_acc=0.9062, running_acc=0.9065, grad=23.6589]Training epoch 20:  69%|██████▉   | 113/163 [02:09<00:54,  1.08s/it, loss=0.6131, batch_acc=0.9062, running_acc=0.9065, grad=23.6589]Training epoch 20:  69%|██████▉   | 113/163 [02:09<00:54,  1.08s/it, loss=0.5117, batch_acc=0.9062, running_acc=0.9065, grad=17.5063]Training epoch 20:  70%|██████▉   | 114/163 [02:10<00:50,  1.02s/it, loss=0.5117, batch_acc=0.9062, running_acc=0.9065, grad=17.5063]Training epoch 20:  70%|██████▉   | 114/163 [02:10<00:50,  1.02s/it, loss=0.3931, batch_acc=0.9688, running_acc=0.9071, grad=16.5286]Training epoch 20:  71%|███████   | 115/163 [02:11<00:47,  1.02it/s, loss=0.3931, batch_acc=0.9688, running_acc=0.9071, grad=16.5286]Training epoch 20:  71%|███████   | 115/163 [02:11<00:47,  1.02it/s, loss=0.5378, batch_acc=0.8750, running_acc=0.9068, grad=28.0858]Training epoch 20:  71%|███████   | 116/163 [02:13<00:58,  1.25s/it, loss=0.5378, batch_acc=0.8750, running_acc=0.9068, grad=28.0858]Training epoch 20:  71%|███████   | 116/163 [02:13<00:58,  1.25s/it, loss=0.4282, batch_acc=0.9375, running_acc=0.9071, grad=17.5014]Training epoch 20:  72%|███████▏  | 117/163 [02:14<00:52,  1.14s/it, loss=0.4282, batch_acc=0.9375, running_acc=0.9071, grad=17.5014]Training epoch 20:  72%|███████▏  | 117/163 [02:14<00:52,  1.14s/it, loss=0.6292, batch_acc=0.8750, running_acc=0.9068, grad=28.4599]Training epoch 20:  72%|███████▏  | 118/163 [02:15<00:47,  1.06s/it, loss=0.6292, batch_acc=0.8750, running_acc=0.9068, grad=28.4599]Training epoch 20:  72%|███████▏  | 118/163 [02:15<00:47,  1.06s/it, loss=0.7851, batch_acc=0.8125, running_acc=0.9060, grad=23.1479]Training epoch 20:  73%|███████▎  | 119/163 [02:16<00:44,  1.01s/it, loss=0.7851, batch_acc=0.8125, running_acc=0.9060, grad=23.1479]Training epoch 20:  73%|███████▎  | 119/163 [02:16<00:44,  1.01s/it, loss=0.5692, batch_acc=0.9062, running_acc=0.9060, grad=24.1304]Training epoch 20:  74%|███████▎  | 120/163 [02:18<00:55,  1.30s/it, loss=0.5692, batch_acc=0.9062, running_acc=0.9060, grad=24.1304]Training epoch 20:  74%|███████▎  | 120/163 [02:18<00:55,  1.30s/it, loss=0.4012, batch_acc=1.0000, running_acc=0.9068, grad=16.9454]Training epoch 20:  74%|███████▍  | 121/163 [02:18<00:49,  1.17s/it, loss=0.4012, batch_acc=1.0000, running_acc=0.9068, grad=16.9454]Training epoch 20:  74%|███████▍  | 121/163 [02:18<00:49,  1.17s/it, loss=0.4610, batch_acc=0.9688, running_acc=0.9073, grad=21.7176]Training epoch 20:  75%|███████▍  | 122/163 [02:19<00:44,  1.08s/it, loss=0.4610, batch_acc=0.9688, running_acc=0.9073, grad=21.7176]Training epoch 20:  75%|███████▍  | 122/163 [02:19<00:44,  1.08s/it, loss=0.5916, batch_acc=0.9688, running_acc=0.9078, grad=21.2054]Training epoch 20:  75%|███████▌  | 123/163 [02:20<00:40,  1.02s/it, loss=0.5916, batch_acc=0.9688, running_acc=0.9078, grad=21.2054]Training epoch 20:  75%|███████▌  | 123/163 [02:20<00:40,  1.02s/it, loss=0.4988, batch_acc=0.9688, running_acc=0.9083, grad=17.9163]Training epoch 20:  76%|███████▌  | 124/163 [02:22<00:50,  1.29s/it, loss=0.4988, batch_acc=0.9688, running_acc=0.9083, grad=17.9163]Training epoch 20:  76%|███████▌  | 124/163 [02:22<00:50,  1.29s/it, loss=0.5198, batch_acc=0.9375, running_acc=0.9085, grad=22.9224]Training epoch 20:  77%|███████▋  | 125/163 [02:23<00:44,  1.17s/it, loss=0.5198, batch_acc=0.9375, running_acc=0.9085, grad=22.9224]Training epoch 20:  77%|███████▋  | 125/163 [02:23<00:44,  1.17s/it, loss=0.7060, batch_acc=0.8438, running_acc=0.9080, grad=25.7652]Training epoch 20:  77%|███████▋  | 126/163 [02:24<00:39,  1.08s/it, loss=0.7060, batch_acc=0.8438, running_acc=0.9080, grad=25.7652]Training epoch 20:  77%|███████▋  | 126/163 [02:24<00:39,  1.08s/it, loss=0.4275, batch_acc=0.9375, running_acc=0.9082, grad=12.7065]Training epoch 20:  78%|███████▊  | 127/163 [02:25<00:36,  1.02s/it, loss=0.4275, batch_acc=0.9375, running_acc=0.9082, grad=12.7065]Training epoch 20:  78%|███████▊  | 127/163 [02:25<00:36,  1.02s/it, loss=0.5542, batch_acc=0.9062, running_acc=0.9082, grad=18.2712]Training epoch 20:  79%|███████▊  | 128/163 [02:27<00:45,  1.31s/it, loss=0.5542, batch_acc=0.9062, running_acc=0.9082, grad=18.2712]Training epoch 20:  79%|███████▊  | 128/163 [02:27<00:45,  1.31s/it, loss=0.5950, batch_acc=0.9375, running_acc=0.9084, grad=19.7672]Training epoch 20:  79%|███████▉  | 129/163 [02:28<00:40,  1.18s/it, loss=0.5950, batch_acc=0.9375, running_acc=0.9084, grad=19.7672]Training epoch 20:  79%|███████▉  | 129/163 [02:28<00:40,  1.18s/it, loss=0.5126, batch_acc=0.9688, running_acc=0.9089, grad=16.9846]Training epoch 20:  80%|███████▉  | 130/163 [02:28<00:35,  1.09s/it, loss=0.5126, batch_acc=0.9688, running_acc=0.9089, grad=16.9846]Training epoch 20:  80%|███████▉  | 130/163 [02:28<00:35,  1.09s/it, loss=0.5466, batch_acc=0.9688, running_acc=0.9094, grad=20.0454]Training epoch 20:  80%|████████  | 131/163 [02:29<00:32,  1.03s/it, loss=0.5466, batch_acc=0.9688, running_acc=0.9094, grad=20.0454]Training epoch 20:  80%|████████  | 131/163 [02:29<00:32,  1.03s/it, loss=0.6997, batch_acc=0.9062, running_acc=0.9094, grad=28.7684]Training epoch 20:  81%|████████  | 132/163 [02:31<00:36,  1.17s/it, loss=0.6997, batch_acc=0.9062, running_acc=0.9094, grad=28.7684]Training epoch 20:  81%|████████  | 132/163 [02:31<00:36,  1.17s/it, loss=0.7422, batch_acc=0.9062, running_acc=0.9093, grad=26.9780]Training epoch 20:  82%|████████▏ | 133/163 [02:32<00:32,  1.08s/it, loss=0.7422, batch_acc=0.9062, running_acc=0.9093, grad=26.9780]Training epoch 20:  82%|████████▏ | 133/163 [02:32<00:32,  1.08s/it, loss=0.7057, batch_acc=0.8438, running_acc=0.9088, grad=22.3520]Training epoch 20:  82%|████████▏ | 134/163 [02:33<00:29,  1.02s/it, loss=0.7057, batch_acc=0.8438, running_acc=0.9088, grad=22.3520]Training epoch 20:  82%|████████▏ | 134/163 [02:33<00:29,  1.02s/it, loss=0.6730, batch_acc=0.8438, running_acc=0.9083, grad=25.0481]Training epoch 20:  83%|████████▎ | 135/163 [02:33<00:27,  1.02it/s, loss=0.6730, batch_acc=0.8438, running_acc=0.9083, grad=25.0481]Training epoch 20:  83%|████████▎ | 135/163 [02:33<00:27,  1.02it/s, loss=0.7431, batch_acc=0.8750, running_acc=0.9081, grad=30.4650]Training epoch 20:  83%|████████▎ | 136/163 [02:35<00:31,  1.18s/it, loss=0.7431, batch_acc=0.8750, running_acc=0.9081, grad=30.4650]Training epoch 20:  83%|████████▎ | 136/163 [02:35<00:31,  1.18s/it, loss=0.6500, batch_acc=0.9062, running_acc=0.9081, grad=24.0002]Training epoch 20:  84%|████████▍ | 137/163 [02:36<00:28,  1.09s/it, loss=0.6500, batch_acc=0.9062, running_acc=0.9081, grad=24.0002]Training epoch 20:  84%|████████▍ | 137/163 [02:36<00:28,  1.09s/it, loss=0.7987, batch_acc=0.8438, running_acc=0.9076, grad=24.2690]Training epoch 20:  85%|████████▍ | 138/163 [02:37<00:25,  1.03s/it, loss=0.7987, batch_acc=0.8438, running_acc=0.9076, grad=24.2690]Training epoch 20:  85%|████████▍ | 138/163 [02:37<00:25,  1.03s/it, loss=0.5682, batch_acc=0.9688, running_acc=0.9081, grad=28.8112]Training epoch 20:  85%|████████▌ | 139/163 [02:38<00:23,  1.02it/s, loss=0.5682, batch_acc=0.9688, running_acc=0.9081, grad=28.8112]Training epoch 20:  85%|████████▌ | 139/163 [02:38<00:23,  1.02it/s, loss=0.4071, batch_acc=1.0000, running_acc=0.9087, grad=14.2069]Training epoch 20:  86%|████████▌ | 140/163 [02:40<00:28,  1.24s/it, loss=0.4071, batch_acc=1.0000, running_acc=0.9087, grad=14.2069]Training epoch 20:  86%|████████▌ | 140/163 [02:40<00:28,  1.24s/it, loss=0.5294, batch_acc=0.8438, running_acc=0.9083, grad=26.2114]Training epoch 20:  87%|████████▋ | 141/163 [02:41<00:24,  1.13s/it, loss=0.5294, batch_acc=0.8438, running_acc=0.9083, grad=26.2114]Training epoch 20:  87%|████████▋ | 141/163 [02:41<00:24,  1.13s/it, loss=0.5086, batch_acc=0.9375, running_acc=0.9085, grad=20.6470]Training epoch 20:  87%|████████▋ | 142/163 [02:41<00:22,  1.06s/it, loss=0.5086, batch_acc=0.9375, running_acc=0.9085, grad=20.6470]Training epoch 20:  87%|████████▋ | 142/163 [02:41<00:22,  1.06s/it, loss=0.7603, batch_acc=0.9375, running_acc=0.9087, grad=28.1543]Training epoch 20:  88%|████████▊ | 143/163 [02:42<00:20,  1.00s/it, loss=0.7603, batch_acc=0.9375, running_acc=0.9087, grad=28.1543]Training epoch 20:  88%|████████▊ | 143/163 [02:42<00:20,  1.00s/it, loss=0.5851, batch_acc=0.9375, running_acc=0.9089, grad=22.1979]Training epoch 20:  88%|████████▊ | 144/163 [02:44<00:24,  1.29s/it, loss=0.5851, batch_acc=0.9375, running_acc=0.9089, grad=22.1979]Training epoch 20:  88%|████████▊ | 144/163 [02:44<00:24,  1.29s/it, loss=0.4594, batch_acc=0.9375, running_acc=0.9091, grad=15.3310]Training epoch 20:  89%|████████▉ | 145/163 [02:45<00:21,  1.17s/it, loss=0.4594, batch_acc=0.9375, running_acc=0.9091, grad=15.3310]Training epoch 20:  89%|████████▉ | 145/163 [02:45<00:21,  1.17s/it, loss=0.4746, batch_acc=0.9688, running_acc=0.9095, grad=19.0764]Training epoch 20:  90%|████████▉ | 146/163 [02:46<00:18,  1.08s/it, loss=0.4746, batch_acc=0.9688, running_acc=0.9095, grad=19.0764]Training epoch 20:  90%|████████▉ | 146/163 [02:46<00:18,  1.08s/it, loss=0.6490, batch_acc=0.8438, running_acc=0.9090, grad=24.5195]Training epoch 20:  90%|█████████ | 147/163 [02:47<00:16,  1.02s/it, loss=0.6490, batch_acc=0.8438, running_acc=0.9090, grad=24.5195]Training epoch 20:  90%|█████████ | 147/163 [02:47<00:16,  1.02s/it, loss=0.4216, batch_acc=1.0000, running_acc=0.9097, grad=21.4543]Training epoch 20:  91%|█████████ | 148/163 [02:49<00:18,  1.23s/it, loss=0.4216, batch_acc=1.0000, running_acc=0.9097, grad=21.4543]Training epoch 20:  91%|█████████ | 148/163 [02:49<00:18,  1.23s/it, loss=0.6126, batch_acc=0.9062, running_acc=0.9096, grad=20.6323]Training epoch 20:  91%|█████████▏| 149/163 [02:49<00:15,  1.13s/it, loss=0.6126, batch_acc=0.9062, running_acc=0.9096, grad=20.6323]Training epoch 20:  91%|█████████▏| 149/163 [02:49<00:15,  1.13s/it, loss=0.5356, batch_acc=0.9375, running_acc=0.9098, grad=21.6496]Training epoch 20:  92%|█████████▏| 150/163 [02:50<00:13,  1.05s/it, loss=0.5356, batch_acc=0.9375, running_acc=0.9098, grad=21.6496]Training epoch 20:  92%|█████████▏| 150/163 [02:50<00:13,  1.05s/it, loss=0.6434, batch_acc=0.9062, running_acc=0.9098, grad=28.2896]Training epoch 20:  93%|█████████▎| 151/163 [02:51<00:12,  1.00s/it, loss=0.6434, batch_acc=0.9062, running_acc=0.9098, grad=28.2896]Training epoch 20:  93%|█████████▎| 151/163 [02:51<00:12,  1.00s/it, loss=0.4612, batch_acc=0.9375, running_acc=0.9100, grad=18.6425]Training epoch 20:  93%|█████████▎| 152/163 [02:53<00:14,  1.28s/it, loss=0.4612, batch_acc=0.9375, running_acc=0.9100, grad=18.6425]Training epoch 20:  93%|█████████▎| 152/163 [02:53<00:14,  1.28s/it, loss=0.6694, batch_acc=0.9062, running_acc=0.9100, grad=28.1328]Training epoch 20:  94%|█████████▍| 153/163 [02:54<00:11,  1.16s/it, loss=0.6694, batch_acc=0.9062, running_acc=0.9100, grad=28.1328]Training epoch 20:  94%|█████████▍| 153/163 [02:54<00:11,  1.16s/it, loss=0.7602, batch_acc=0.7812, running_acc=0.9091, grad=22.0023]Training epoch 20:  94%|█████████▍| 154/163 [02:55<00:09,  1.08s/it, loss=0.7602, batch_acc=0.7812, running_acc=0.9091, grad=22.0023]Training epoch 20:  94%|█████████▍| 154/163 [02:55<00:09,  1.08s/it, loss=0.6011, batch_acc=0.9062, running_acc=0.9091, grad=21.6865]Training epoch 20:  95%|█████████▌| 155/163 [02:56<00:08,  1.02s/it, loss=0.6011, batch_acc=0.9062, running_acc=0.9091, grad=21.6865]Training epoch 20:  95%|█████████▌| 155/163 [02:56<00:08,  1.02s/it, loss=0.5972, batch_acc=0.9062, running_acc=0.9091, grad=23.0151]Training epoch 20:  96%|█████████▌| 156/163 [02:58<00:09,  1.29s/it, loss=0.5972, batch_acc=0.9062, running_acc=0.9091, grad=23.0151]Training epoch 20:  96%|█████████▌| 156/163 [02:58<00:09,  1.29s/it, loss=0.7342, batch_acc=0.8750, running_acc=0.9089, grad=29.3898]Training epoch 20:  96%|█████████▋| 157/163 [02:59<00:06,  1.16s/it, loss=0.7342, batch_acc=0.8750, running_acc=0.9089, grad=29.3898]Training epoch 20:  96%|█████████▋| 157/163 [02:59<00:06,  1.16s/it, loss=0.6959, batch_acc=0.9062, running_acc=0.9088, grad=18.4673]Training epoch 20:  97%|█████████▋| 158/163 [03:00<00:05,  1.08s/it, loss=0.6959, batch_acc=0.9062, running_acc=0.9088, grad=18.4673]Training epoch 20:  97%|█████████▋| 158/163 [03:00<00:05,  1.08s/it, loss=0.5372, batch_acc=0.9688, running_acc=0.9092, grad=21.6562]Training epoch 20:  98%|█████████▊| 159/163 [03:00<00:04,  1.02s/it, loss=0.5372, batch_acc=0.9688, running_acc=0.9092, grad=21.6562]Training epoch 20:  98%|█████████▊| 159/163 [03:00<00:04,  1.02s/it, loss=0.4687, batch_acc=0.9375, running_acc=0.9094, grad=18.9217]Training epoch 20:  98%|█████████▊| 160/163 [03:02<00:03,  1.12s/it, loss=0.4687, batch_acc=0.9375, running_acc=0.9094, grad=18.9217]Training epoch 20:  98%|█████████▊| 160/163 [03:02<00:03,  1.12s/it, loss=0.6680, batch_acc=0.9062, running_acc=0.9094, grad=28.4418]Training epoch 20:  99%|█████████▉| 161/163 [03:03<00:02,  1.05s/it, loss=0.6680, batch_acc=0.9062, running_acc=0.9094, grad=28.4418]Training epoch 20:  99%|█████████▉| 161/163 [03:03<00:02,  1.05s/it, loss=0.5752, batch_acc=0.9375, running_acc=0.9095, grad=19.0098]Training epoch 20:  99%|█████████▉| 162/163 [03:03<00:00,  1.00it/s, loss=0.5752, batch_acc=0.9375, running_acc=0.9095, grad=19.0098]Training epoch 20:  99%|█████████▉| 162/163 [03:03<00:00,  1.00it/s, loss=0.4827, batch_acc=0.9688, running_acc=0.9099, grad=22.0158]Training epoch 20: 100%|██████████| 163/163 [03:04<00:00,  1.12it/s, loss=0.4827, batch_acc=0.9688, running_acc=0.9099, grad=22.0158]Training epoch 20: 100%|██████████| 163/163 [03:04<00:00,  1.12it/s, loss=0.4906, batch_acc=0.9048, running_acc=0.9099, grad=24.4946]Training epoch 20: 100%|██████████| 163/163 [03:04<00:00,  1.13s/it, loss=0.4906, batch_acc=0.9048, running_acc=0.9099, grad=24.4946]
Evaluation epoch 20:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 20:   4%|▎         | 1/28 [00:04<02:13,  4.96s/it]Evaluation epoch 20:   4%|▎         | 1/28 [00:04<02:13,  4.96s/it, loss=0.6191, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 20:   7%|▋         | 2/28 [00:05<00:57,  2.19s/it, loss=0.6191, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 20:   7%|▋         | 2/28 [00:05<00:57,  2.19s/it, loss=0.6217, batch_acc=0.9688, running_acc=0.9062]Evaluation epoch 20:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.6217, batch_acc=0.9688, running_acc=0.9062]Evaluation epoch 20:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.6772, batch_acc=0.9375, running_acc=0.9167]Evaluation epoch 20:  14%|█▍        | 4/28 [00:09<01:00,  2.54s/it, loss=0.6772, batch_acc=0.9375, running_acc=0.9167]Evaluation epoch 20:  14%|█▍        | 4/28 [00:09<01:00,  2.54s/it, loss=1.0706, batch_acc=0.7812, running_acc=0.8828]Evaluation epoch 20:  18%|█▊        | 5/28 [00:10<00:39,  1.72s/it, loss=1.0706, batch_acc=0.7812, running_acc=0.8828]Evaluation epoch 20:  18%|█▊        | 5/28 [00:10<00:39,  1.72s/it, loss=1.9468, batch_acc=0.5938, running_acc=0.8250]Evaluation epoch 20:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.9468, batch_acc=0.5938, running_acc=0.8250]Evaluation epoch 20:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=0.9886, batch_acc=0.7500, running_acc=0.8125]Evaluation epoch 20:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.9886, batch_acc=0.7500, running_acc=0.8125]Evaluation epoch 20:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.9953, batch_acc=0.8438, running_acc=0.8170]Evaluation epoch 20:  29%|██▊       | 8/28 [00:14<00:33,  1.69s/it, loss=0.9953, batch_acc=0.8438, running_acc=0.8170]Evaluation epoch 20:  29%|██▊       | 8/28 [00:14<00:33,  1.69s/it, loss=0.9748, batch_acc=0.7812, running_acc=0.8125]Evaluation epoch 20:  32%|███▏      | 9/28 [00:15<00:28,  1.49s/it, loss=0.9748, batch_acc=0.7812, running_acc=0.8125]Evaluation epoch 20:  32%|███▏      | 9/28 [00:15<00:28,  1.49s/it, loss=0.9965, batch_acc=0.8438, running_acc=0.8160]Evaluation epoch 20:  36%|███▌      | 10/28 [00:15<00:19,  1.11s/it, loss=0.9965, batch_acc=0.8438, running_acc=0.8160]Evaluation epoch 20:  36%|███▌      | 10/28 [00:15<00:19,  1.11s/it, loss=0.6077, batch_acc=0.9062, running_acc=0.8250]Evaluation epoch 20:  39%|███▉      | 11/28 [00:15<00:14,  1.18it/s, loss=0.6077, batch_acc=0.9062, running_acc=0.8250]Evaluation epoch 20:  39%|███▉      | 11/28 [00:15<00:14,  1.18it/s, loss=0.7705, batch_acc=0.8125, running_acc=0.8239]Evaluation epoch 20:  43%|████▎     | 12/28 [00:20<00:34,  2.16s/it, loss=0.7705, batch_acc=0.8125, running_acc=0.8239]Evaluation epoch 20:  43%|████▎     | 12/28 [00:20<00:34,  2.16s/it, loss=1.2200, batch_acc=0.6562, running_acc=0.8099]Evaluation epoch 20:  46%|████▋     | 13/28 [00:21<00:23,  1.58s/it, loss=1.2200, batch_acc=0.6562, running_acc=0.8099]Evaluation epoch 20:  46%|████▋     | 13/28 [00:21<00:23,  1.58s/it, loss=0.6623, batch_acc=0.9062, running_acc=0.8173]Evaluation epoch 20:  50%|█████     | 14/28 [00:21<00:16,  1.18s/it, loss=0.6623, batch_acc=0.9062, running_acc=0.8173]Evaluation epoch 20:  50%|█████     | 14/28 [00:21<00:16,  1.18s/it, loss=1.2503, batch_acc=0.7812, running_acc=0.8147]Evaluation epoch 20:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.2503, batch_acc=0.7812, running_acc=0.8147]Evaluation epoch 20:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.8140, batch_acc=0.5000, running_acc=0.7937]Evaluation epoch 20:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.8140, batch_acc=0.5000, running_acc=0.7937]Evaluation epoch 20:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.0939, batch_acc=0.7188, running_acc=0.7891]Evaluation epoch 20:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=1.0939, batch_acc=0.7188, running_acc=0.7891]Evaluation epoch 20:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.9146, batch_acc=0.6562, running_acc=0.7812]Evaluation epoch 20:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.9146, batch_acc=0.6562, running_acc=0.7812]Evaluation epoch 20:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=1.0772, batch_acc=0.6250, running_acc=0.7726]Evaluation epoch 20:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=1.0772, batch_acc=0.6250, running_acc=0.7726]Evaluation epoch 20:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=0.9668, batch_acc=0.6875, running_acc=0.7681]Evaluation epoch 20:  71%|███████▏  | 20/28 [00:28<00:11,  1.41s/it, loss=0.9668, batch_acc=0.6875, running_acc=0.7681]Evaluation epoch 20:  71%|███████▏  | 20/28 [00:28<00:11,  1.41s/it, loss=0.6300, batch_acc=0.8750, running_acc=0.7734]Evaluation epoch 20:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.6300, batch_acc=0.8750, running_acc=0.7734]Evaluation epoch 20:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.8999, batch_acc=0.8438, running_acc=0.7768]Evaluation epoch 20:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=0.8999, batch_acc=0.8438, running_acc=0.7768]Evaluation epoch 20:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=1.2306, batch_acc=0.6875, running_acc=0.7727]Evaluation epoch 20:  82%|████████▏ | 23/28 [00:29<00:03,  1.53it/s, loss=1.2306, batch_acc=0.6875, running_acc=0.7727]Evaluation epoch 20:  82%|████████▏ | 23/28 [00:29<00:03,  1.53it/s, loss=1.2076, batch_acc=0.6562, running_acc=0.7677]Evaluation epoch 20:  86%|████████▌ | 24/28 [00:34<00:08,  2.09s/it, loss=1.2076, batch_acc=0.6562, running_acc=0.7677]Evaluation epoch 20:  86%|████████▌ | 24/28 [00:34<00:08,  2.09s/it, loss=0.4327, batch_acc=0.9375, running_acc=0.7747]Evaluation epoch 20:  89%|████████▉ | 25/28 [00:34<00:04,  1.54s/it, loss=0.4327, batch_acc=0.9375, running_acc=0.7747]Evaluation epoch 20:  89%|████████▉ | 25/28 [00:34<00:04,  1.54s/it, loss=0.4076, batch_acc=0.9375, running_acc=0.7812]Evaluation epoch 20:  93%|█████████▎| 26/28 [00:35<00:02,  1.16s/it, loss=0.4076, batch_acc=0.9375, running_acc=0.7812]Evaluation epoch 20:  93%|█████████▎| 26/28 [00:35<00:02,  1.16s/it, loss=1.1400, batch_acc=0.6875, running_acc=0.7776]Evaluation epoch 20:  96%|█████████▋| 27/28 [00:35<00:00,  1.12it/s, loss=1.1400, batch_acc=0.6875, running_acc=0.7776]Evaluation epoch 20:  96%|█████████▋| 27/28 [00:35<00:00,  1.12it/s, loss=0.9612, batch_acc=0.7188, running_acc=0.7755]Evaluation epoch 20: 100%|██████████| 28/28 [00:35<00:00,  1.12it/s, loss=1.5996, batch_acc=0.3333, running_acc=0.7739]Evaluation epoch 20: 100%|██████████| 28/28 [00:35<00:00,  1.27s/it, loss=1.5996, batch_acc=0.3333, running_acc=0.7739]
Training epoch 21:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 21:   1%|          | 1/163 [00:06<17:27,  6.46s/it]Training epoch 21:   1%|          | 1/163 [00:06<17:27,  6.46s/it, loss=0.4520, batch_acc=0.9688, running_acc=0.9688, grad=15.5397]Training epoch 21:   1%|          | 2/163 [00:07<08:32,  3.18s/it, loss=0.4520, batch_acc=0.9688, running_acc=0.9688, grad=15.5397]Training epoch 21:   1%|          | 2/163 [00:07<08:32,  3.18s/it, loss=0.3851, batch_acc=1.0000, running_acc=0.9844, grad=16.2098]Training epoch 21:   2%|▏         | 3/163 [00:08<05:40,  2.13s/it, loss=0.3851, batch_acc=1.0000, running_acc=0.9844, grad=16.2098]Training epoch 21:   2%|▏         | 3/163 [00:08<05:40,  2.13s/it, loss=0.6184, batch_acc=0.9375, running_acc=0.9688, grad=24.0334]Training epoch 21:   2%|▏         | 4/163 [00:11<06:35,  2.49s/it, loss=0.6184, batch_acc=0.9375, running_acc=0.9688, grad=24.0334]Training epoch 21:   2%|▏         | 4/163 [00:11<06:35,  2.49s/it, loss=0.8239, batch_acc=0.8750, running_acc=0.9453, grad=28.0623]Training epoch 21:   3%|▎         | 5/163 [00:12<05:01,  1.91s/it, loss=0.8239, batch_acc=0.8750, running_acc=0.9453, grad=28.0623]Training epoch 21:   3%|▎         | 5/163 [00:12<05:01,  1.91s/it, loss=0.4392, batch_acc=0.9688, running_acc=0.9500, grad=18.2651]Training epoch 21:   4%|▎         | 6/163 [00:13<04:04,  1.56s/it, loss=0.4392, batch_acc=0.9688, running_acc=0.9500, grad=18.2651]Training epoch 21:   4%|▎         | 6/163 [00:13<04:04,  1.56s/it, loss=0.6274, batch_acc=0.9375, running_acc=0.9479, grad=22.7595]Training epoch 21:   4%|▍         | 7/163 [00:13<03:28,  1.34s/it, loss=0.6274, batch_acc=0.9375, running_acc=0.9479, grad=22.7595]Training epoch 21:   4%|▍         | 7/163 [00:13<03:28,  1.34s/it, loss=0.4524, batch_acc=0.9688, running_acc=0.9509, grad=15.2424]Training epoch 21:   5%|▍         | 8/163 [00:15<04:04,  1.58s/it, loss=0.4524, batch_acc=0.9688, running_acc=0.9509, grad=15.2424]Training epoch 21:   5%|▍         | 8/163 [00:15<04:04,  1.58s/it, loss=0.6544, batch_acc=0.8750, running_acc=0.9414, grad=25.6134]Training epoch 21:   6%|▌         | 9/163 [00:16<03:29,  1.36s/it, loss=0.6544, batch_acc=0.8750, running_acc=0.9414, grad=25.6134]Training epoch 21:   6%|▌         | 9/163 [00:16<03:29,  1.36s/it, loss=0.4962, batch_acc=0.9688, running_acc=0.9444, grad=20.6091]Training epoch 21:   6%|▌         | 10/163 [00:17<03:05,  1.21s/it, loss=0.4962, batch_acc=0.9688, running_acc=0.9444, grad=20.6091]Training epoch 21:   6%|▌         | 10/163 [00:17<03:05,  1.21s/it, loss=0.5501, batch_acc=0.9375, running_acc=0.9437, grad=23.8353]Training epoch 21:   7%|▋         | 11/163 [00:18<02:48,  1.11s/it, loss=0.5501, batch_acc=0.9375, running_acc=0.9437, grad=23.8353]Training epoch 21:   7%|▋         | 11/163 [00:18<02:48,  1.11s/it, loss=0.6573, batch_acc=0.8438, running_acc=0.9347, grad=22.9982]Training epoch 21:   7%|▋         | 12/163 [00:20<03:41,  1.47s/it, loss=0.6573, batch_acc=0.8438, running_acc=0.9347, grad=22.9982]Training epoch 21:   7%|▋         | 12/163 [00:20<03:41,  1.47s/it, loss=0.6046, batch_acc=0.8750, running_acc=0.9297, grad=20.8341]Training epoch 21:   8%|▊         | 13/163 [00:21<03:13,  1.29s/it, loss=0.6046, batch_acc=0.8750, running_acc=0.9297, grad=20.8341]Training epoch 21:   8%|▊         | 13/163 [00:21<03:13,  1.29s/it, loss=0.4410, batch_acc=0.9062, running_acc=0.9279, grad=17.3720]Training epoch 21:   9%|▊         | 14/163 [00:22<02:53,  1.16s/it, loss=0.4410, batch_acc=0.9062, running_acc=0.9279, grad=17.3720]Training epoch 21:   9%|▊         | 14/163 [00:22<02:53,  1.16s/it, loss=0.6267, batch_acc=0.8750, running_acc=0.9241, grad=22.8246]Training epoch 21:   9%|▉         | 15/163 [00:23<02:39,  1.08s/it, loss=0.6267, batch_acc=0.8750, running_acc=0.9241, grad=22.8246]Training epoch 21:   9%|▉         | 15/163 [00:23<02:39,  1.08s/it, loss=0.4776, batch_acc=1.0000, running_acc=0.9292, grad=23.7209]Training epoch 21:  10%|▉         | 16/163 [00:25<03:22,  1.38s/it, loss=0.4776, batch_acc=1.0000, running_acc=0.9292, grad=23.7209]Training epoch 21:  10%|▉         | 16/163 [00:25<03:22,  1.38s/it, loss=0.4558, batch_acc=0.9062, running_acc=0.9277, grad=19.1106]Training epoch 21:  10%|█         | 17/163 [00:26<02:59,  1.23s/it, loss=0.4558, batch_acc=0.9062, running_acc=0.9277, grad=19.1106]Training epoch 21:  10%|█         | 17/163 [00:26<02:59,  1.23s/it, loss=0.5017, batch_acc=0.9688, running_acc=0.9301, grad=25.3395]Training epoch 21:  11%|█         | 18/163 [00:27<02:42,  1.12s/it, loss=0.5017, batch_acc=0.9688, running_acc=0.9301, grad=25.3395]Training epoch 21:  11%|█         | 18/163 [00:27<02:42,  1.12s/it, loss=0.5644, batch_acc=0.9062, running_acc=0.9288, grad=27.8796]Training epoch 21:  12%|█▏        | 19/163 [00:28<02:31,  1.05s/it, loss=0.5644, batch_acc=0.9062, running_acc=0.9288, grad=27.8796]Training epoch 21:  12%|█▏        | 19/163 [00:28<02:31,  1.05s/it, loss=0.7898, batch_acc=0.8125, running_acc=0.9227, grad=30.2046]Training epoch 21:  12%|█▏        | 20/163 [00:30<03:09,  1.32s/it, loss=0.7898, batch_acc=0.8125, running_acc=0.9227, grad=30.2046]Training epoch 21:  12%|█▏        | 20/163 [00:30<03:09,  1.32s/it, loss=0.5751, batch_acc=0.9375, running_acc=0.9234, grad=21.9701]Training epoch 21:  13%|█▎        | 21/163 [00:31<02:49,  1.19s/it, loss=0.5751, batch_acc=0.9375, running_acc=0.9234, grad=21.9701]Training epoch 21:  13%|█▎        | 21/163 [00:31<02:49,  1.19s/it, loss=0.5774, batch_acc=0.9375, running_acc=0.9241, grad=18.8036]Training epoch 21:  13%|█▎        | 22/163 [00:31<02:34,  1.10s/it, loss=0.5774, batch_acc=0.9375, running_acc=0.9241, grad=18.8036]Training epoch 21:  13%|█▎        | 22/163 [00:31<02:34,  1.10s/it, loss=0.5763, batch_acc=0.9375, running_acc=0.9247, grad=21.4048]Training epoch 21:  14%|█▍        | 23/163 [00:32<02:24,  1.03s/it, loss=0.5763, batch_acc=0.9375, running_acc=0.9247, grad=21.4048]Training epoch 21:  14%|█▍        | 23/163 [00:32<02:24,  1.03s/it, loss=0.3863, batch_acc=0.9688, running_acc=0.9266, grad=15.4078]Training epoch 21:  15%|█▍        | 24/163 [00:34<02:45,  1.19s/it, loss=0.3863, batch_acc=0.9688, running_acc=0.9266, grad=15.4078]Training epoch 21:  15%|█▍        | 24/163 [00:34<02:45,  1.19s/it, loss=0.6897, batch_acc=0.8438, running_acc=0.9232, grad=24.5857]Training epoch 21:  15%|█▌        | 25/163 [00:35<02:31,  1.09s/it, loss=0.6897, batch_acc=0.8438, running_acc=0.9232, grad=24.5857]Training epoch 21:  15%|█▌        | 25/163 [00:35<02:31,  1.09s/it, loss=0.4875, batch_acc=0.9062, running_acc=0.9225, grad=20.2998]Training epoch 21:  16%|█▌        | 26/163 [00:36<02:21,  1.03s/it, loss=0.4875, batch_acc=0.9062, running_acc=0.9225, grad=20.2998]Training epoch 21:  16%|█▌        | 26/163 [00:36<02:21,  1.03s/it, loss=0.6580, batch_acc=0.8438, running_acc=0.9195, grad=27.6542]Training epoch 21:  17%|█▋        | 27/163 [00:37<02:13,  1.02it/s, loss=0.6580, batch_acc=0.8438, running_acc=0.9195, grad=27.6542]Training epoch 21:  17%|█▋        | 27/163 [00:37<02:13,  1.02it/s, loss=0.5052, batch_acc=0.9062, running_acc=0.9190, grad=26.3522]Training epoch 21:  17%|█▋        | 28/163 [00:39<03:17,  1.46s/it, loss=0.5052, batch_acc=0.9062, running_acc=0.9190, grad=26.3522]Training epoch 21:  17%|█▋        | 28/163 [00:39<03:17,  1.46s/it, loss=0.5568, batch_acc=0.9062, running_acc=0.9185, grad=23.5116]Training epoch 21:  18%|█▊        | 29/163 [00:40<02:52,  1.29s/it, loss=0.5568, batch_acc=0.9062, running_acc=0.9185, grad=23.5116]Training epoch 21:  18%|█▊        | 29/163 [00:40<02:52,  1.29s/it, loss=0.6292, batch_acc=0.8750, running_acc=0.9170, grad=29.7639]Training epoch 21:  18%|█▊        | 30/163 [00:41<02:35,  1.17s/it, loss=0.6292, batch_acc=0.8750, running_acc=0.9170, grad=29.7639]Training epoch 21:  18%|█▊        | 30/163 [00:41<02:35,  1.17s/it, loss=0.7164, batch_acc=0.9062, running_acc=0.9167, grad=24.1687]Training epoch 21:  19%|█▉        | 31/163 [00:42<02:22,  1.08s/it, loss=0.7164, batch_acc=0.9062, running_acc=0.9167, grad=24.1687]Training epoch 21:  19%|█▉        | 31/163 [00:42<02:22,  1.08s/it, loss=0.7221, batch_acc=0.9062, running_acc=0.9163, grad=32.8335]Training epoch 21:  20%|█▉        | 32/163 [00:43<02:28,  1.13s/it, loss=0.7221, batch_acc=0.9062, running_acc=0.9163, grad=32.8335]Training epoch 21:  20%|█▉        | 32/163 [00:43<02:28,  1.13s/it, loss=0.5610, batch_acc=0.9062, running_acc=0.9160, grad=21.9971]Training epoch 21:  20%|██        | 33/163 [00:44<02:17,  1.06s/it, loss=0.5610, batch_acc=0.9062, running_acc=0.9160, grad=21.9971]Training epoch 21:  20%|██        | 33/163 [00:44<02:17,  1.06s/it, loss=0.5527, batch_acc=0.9062, running_acc=0.9157, grad=24.1437]Training epoch 21:  21%|██        | 34/163 [00:45<02:09,  1.00s/it, loss=0.5527, batch_acc=0.9062, running_acc=0.9157, grad=24.1437]Training epoch 21:  21%|██        | 34/163 [00:45<02:09,  1.00s/it, loss=0.4830, batch_acc=0.9375, running_acc=0.9164, grad=17.4278]Training epoch 21:  21%|██▏       | 35/163 [00:46<02:03,  1.03it/s, loss=0.4830, batch_acc=0.9375, running_acc=0.9164, grad=17.4278]Training epoch 21:  21%|██▏       | 35/163 [00:46<02:03,  1.03it/s, loss=0.6484, batch_acc=0.9062, running_acc=0.9161, grad=20.5370]Training epoch 21:  22%|██▏       | 36/163 [00:47<02:27,  1.16s/it, loss=0.6484, batch_acc=0.9062, running_acc=0.9161, grad=20.5370]Training epoch 21:  22%|██▏       | 36/163 [00:47<02:27,  1.16s/it, loss=0.6404, batch_acc=0.9062, running_acc=0.9158, grad=26.7056]Training epoch 21:  23%|██▎       | 37/163 [00:48<02:15,  1.08s/it, loss=0.6404, batch_acc=0.9062, running_acc=0.9158, grad=26.7056]Training epoch 21:  23%|██▎       | 37/163 [00:48<02:15,  1.08s/it, loss=0.5369, batch_acc=0.9062, running_acc=0.9155, grad=27.9214]Training epoch 21:  23%|██▎       | 38/163 [00:49<02:07,  1.02s/it, loss=0.5369, batch_acc=0.9062, running_acc=0.9155, grad=27.9214]Training epoch 21:  23%|██▎       | 38/163 [00:49<02:07,  1.02s/it, loss=0.5761, batch_acc=0.8125, running_acc=0.9128, grad=33.3319]Training epoch 21:  24%|██▍       | 39/163 [00:50<02:01,  1.02it/s, loss=0.5761, batch_acc=0.8125, running_acc=0.9128, grad=33.3319]Training epoch 21:  24%|██▍       | 39/163 [00:50<02:01,  1.02it/s, loss=0.6946, batch_acc=0.9375, running_acc=0.9135, grad=19.0284]Training epoch 21:  25%|██▍       | 40/163 [00:52<02:34,  1.26s/it, loss=0.6946, batch_acc=0.9375, running_acc=0.9135, grad=19.0284]Training epoch 21:  25%|██▍       | 40/163 [00:52<02:34,  1.26s/it, loss=0.5864, batch_acc=0.9375, running_acc=0.9141, grad=26.3025]Training epoch 21:  25%|██▌       | 41/163 [00:53<02:19,  1.14s/it, loss=0.5864, batch_acc=0.9375, running_acc=0.9141, grad=26.3025]Training epoch 21:  25%|██▌       | 41/163 [00:53<02:19,  1.14s/it, loss=0.5285, batch_acc=0.9062, running_acc=0.9139, grad=23.0603]Training epoch 21:  26%|██▌       | 42/163 [00:54<02:08,  1.06s/it, loss=0.5285, batch_acc=0.9062, running_acc=0.9139, grad=23.0603]Training epoch 21:  26%|██▌       | 42/163 [00:54<02:08,  1.06s/it, loss=0.5882, batch_acc=0.9375, running_acc=0.9144, grad=27.7325]Training epoch 21:  26%|██▋       | 43/163 [00:54<02:01,  1.01s/it, loss=0.5882, batch_acc=0.9375, running_acc=0.9144, grad=27.7325]Training epoch 21:  26%|██▋       | 43/163 [00:54<02:01,  1.01s/it, loss=0.7103, batch_acc=0.9062, running_acc=0.9142, grad=22.7704]Training epoch 21:  27%|██▋       | 44/163 [00:56<02:24,  1.21s/it, loss=0.7103, batch_acc=0.9062, running_acc=0.9142, grad=22.7704]Training epoch 21:  27%|██▋       | 44/163 [00:56<02:24,  1.21s/it, loss=0.4341, batch_acc=0.9688, running_acc=0.9155, grad=15.2646]Training epoch 21:  28%|██▊       | 45/163 [00:57<02:11,  1.11s/it, loss=0.4341, batch_acc=0.9688, running_acc=0.9155, grad=15.2646]Training epoch 21:  28%|██▊       | 45/163 [00:57<02:11,  1.11s/it, loss=0.4658, batch_acc=0.9375, running_acc=0.9160, grad=18.3300]Training epoch 21:  28%|██▊       | 46/163 [00:58<02:02,  1.04s/it, loss=0.4658, batch_acc=0.9375, running_acc=0.9160, grad=18.3300]Training epoch 21:  28%|██▊       | 46/163 [00:58<02:02,  1.04s/it, loss=0.6392, batch_acc=0.8438, running_acc=0.9144, grad=29.3703]Training epoch 21:  29%|██▉       | 47/163 [00:59<01:55,  1.00it/s, loss=0.6392, batch_acc=0.8438, running_acc=0.9144, grad=29.3703]Training epoch 21:  29%|██▉       | 47/163 [00:59<01:55,  1.00it/s, loss=0.4457, batch_acc=0.9062, running_acc=0.9142, grad=21.8027]Training epoch 21:  29%|██▉       | 48/163 [01:01<02:30,  1.31s/it, loss=0.4457, batch_acc=0.9062, running_acc=0.9142, grad=21.8027]Training epoch 21:  29%|██▉       | 48/163 [01:01<02:30,  1.31s/it, loss=0.7312, batch_acc=0.8750, running_acc=0.9134, grad=27.9254]Training epoch 21:  30%|███       | 49/163 [01:02<02:14,  1.18s/it, loss=0.7312, batch_acc=0.8750, running_acc=0.9134, grad=27.9254]Training epoch 21:  30%|███       | 49/163 [01:02<02:14,  1.18s/it, loss=0.5761, batch_acc=0.8438, running_acc=0.9120, grad=24.1580]Training epoch 21:  31%|███       | 50/163 [01:03<02:03,  1.09s/it, loss=0.5761, batch_acc=0.8438, running_acc=0.9120, grad=24.1580]Training epoch 21:  31%|███       | 50/163 [01:03<02:03,  1.09s/it, loss=0.3191, batch_acc=1.0000, running_acc=0.9137, grad=14.9772]Training epoch 21:  31%|███▏      | 51/163 [01:03<01:54,  1.03s/it, loss=0.3191, batch_acc=1.0000, running_acc=0.9137, grad=14.9772]Training epoch 21:  31%|███▏      | 51/163 [01:03<01:54,  1.03s/it, loss=0.5603, batch_acc=0.9375, running_acc=0.9142, grad=21.5479]Training epoch 21:  32%|███▏      | 52/163 [01:05<02:14,  1.21s/it, loss=0.5603, batch_acc=0.9375, running_acc=0.9142, grad=21.5479]Training epoch 21:  32%|███▏      | 52/163 [01:05<02:14,  1.21s/it, loss=0.4587, batch_acc=0.9375, running_acc=0.9147, grad=17.7511]Training epoch 21:  33%|███▎      | 53/163 [01:06<02:02,  1.11s/it, loss=0.4587, batch_acc=0.9375, running_acc=0.9147, grad=17.7511]Training epoch 21:  33%|███▎      | 53/163 [01:06<02:02,  1.11s/it, loss=0.4903, batch_acc=0.9688, running_acc=0.9157, grad=17.6704]Training epoch 21:  33%|███▎      | 54/163 [01:07<01:53,  1.04s/it, loss=0.4903, batch_acc=0.9688, running_acc=0.9157, grad=17.6704]Training epoch 21:  33%|███▎      | 54/163 [01:07<01:53,  1.04s/it, loss=0.3131, batch_acc=1.0000, running_acc=0.9172, grad=13.5451]Training epoch 21:  34%|███▎      | 55/163 [01:08<01:47,  1.01it/s, loss=0.3131, batch_acc=1.0000, running_acc=0.9172, grad=13.5451]Training epoch 21:  34%|███▎      | 55/163 [01:08<01:47,  1.01it/s, loss=0.4526, batch_acc=0.9375, running_acc=0.9176, grad=15.8764]Training epoch 21:  34%|███▍      | 56/163 [01:10<02:12,  1.24s/it, loss=0.4526, batch_acc=0.9375, running_acc=0.9176, grad=15.8764]Training epoch 21:  34%|███▍      | 56/163 [01:10<02:12,  1.24s/it, loss=0.6033, batch_acc=0.8750, running_acc=0.9169, grad=24.7932]Training epoch 21:  35%|███▍      | 57/163 [01:10<01:59,  1.13s/it, loss=0.6033, batch_acc=0.8750, running_acc=0.9169, grad=24.7932]Training epoch 21:  35%|███▍      | 57/163 [01:10<01:59,  1.13s/it, loss=0.6614, batch_acc=0.9062, running_acc=0.9167, grad=22.5226]Training epoch 21:  36%|███▌      | 58/163 [01:11<01:50,  1.06s/it, loss=0.6614, batch_acc=0.9062, running_acc=0.9167, grad=22.5226]Training epoch 21:  36%|███▌      | 58/163 [01:11<01:50,  1.06s/it, loss=0.5642, batch_acc=0.8750, running_acc=0.9159, grad=25.4775]Training epoch 21:  36%|███▌      | 59/163 [01:12<01:44,  1.00s/it, loss=0.5642, batch_acc=0.8750, running_acc=0.9159, grad=25.4775]Training epoch 21:  36%|███▌      | 59/163 [01:12<01:44,  1.00s/it, loss=0.4951, batch_acc=0.9688, running_acc=0.9168, grad=21.8602]Training epoch 21:  37%|███▋      | 60/163 [01:14<02:22,  1.38s/it, loss=0.4951, batch_acc=0.9688, running_acc=0.9168, grad=21.8602]Training epoch 21:  37%|███▋      | 60/163 [01:14<02:22,  1.38s/it, loss=0.5135, batch_acc=0.9375, running_acc=0.9172, grad=20.1705]Training epoch 21:  37%|███▋      | 61/163 [01:15<02:05,  1.23s/it, loss=0.5135, batch_acc=0.9375, running_acc=0.9172, grad=20.1705]Training epoch 21:  37%|███▋      | 61/163 [01:15<02:05,  1.23s/it, loss=0.4452, batch_acc=1.0000, running_acc=0.9185, grad=18.6690]Training epoch 21:  38%|███▊      | 62/163 [01:16<01:53,  1.13s/it, loss=0.4452, batch_acc=1.0000, running_acc=0.9185, grad=18.6690]Training epoch 21:  38%|███▊      | 62/163 [01:16<01:53,  1.13s/it, loss=0.4808, batch_acc=0.9375, running_acc=0.9189, grad=20.8968]Training epoch 21:  39%|███▊      | 63/163 [01:17<01:45,  1.05s/it, loss=0.4808, batch_acc=0.9375, running_acc=0.9189, grad=20.8968]Training epoch 21:  39%|███▊      | 63/163 [01:17<01:45,  1.05s/it, loss=0.4596, batch_acc=0.9688, running_acc=0.9196, grad=23.1549]Training epoch 21:  39%|███▉      | 64/163 [01:20<02:25,  1.47s/it, loss=0.4596, batch_acc=0.9688, running_acc=0.9196, grad=23.1549]Training epoch 21:  39%|███▉      | 64/163 [01:20<02:25,  1.47s/it, loss=0.5214, batch_acc=0.8750, running_acc=0.9189, grad=17.7224]Training epoch 21:  40%|███▉      | 65/163 [01:21<02:12,  1.35s/it, loss=0.5214, batch_acc=0.8750, running_acc=0.9189, grad=17.7224]Training epoch 21:  40%|███▉      | 65/163 [01:21<02:12,  1.35s/it, loss=0.6528, batch_acc=0.8750, running_acc=0.9183, grad=29.6152]Training epoch 21:  40%|████      | 66/163 [01:22<01:57,  1.21s/it, loss=0.6528, batch_acc=0.8750, running_acc=0.9183, grad=29.6152]Training epoch 21:  40%|████      | 66/163 [01:22<01:57,  1.21s/it, loss=0.5014, batch_acc=0.9375, running_acc=0.9186, grad=28.1323]Training epoch 21:  41%|████      | 67/163 [01:22<01:46,  1.11s/it, loss=0.5014, batch_acc=0.9375, running_acc=0.9186, grad=28.1323]Training epoch 21:  41%|████      | 67/163 [01:22<01:46,  1.11s/it, loss=0.5639, batch_acc=0.9062, running_acc=0.9184, grad=23.5287]Training epoch 21:  42%|████▏     | 68/163 [01:24<01:56,  1.23s/it, loss=0.5639, batch_acc=0.9062, running_acc=0.9184, grad=23.5287]Training epoch 21:  42%|████▏     | 68/163 [01:24<01:56,  1.23s/it, loss=0.6458, batch_acc=0.8125, running_acc=0.9168, grad=36.1854]Training epoch 21:  42%|████▏     | 69/163 [01:25<01:55,  1.23s/it, loss=0.6458, batch_acc=0.8125, running_acc=0.9168, grad=36.1854]Training epoch 21:  42%|████▏     | 69/163 [01:25<01:55,  1.23s/it, loss=0.5640, batch_acc=0.8750, running_acc=0.9162, grad=28.0946]Training epoch 21:  43%|████▎     | 70/163 [01:26<01:44,  1.13s/it, loss=0.5640, batch_acc=0.8750, running_acc=0.9162, grad=28.0946]Training epoch 21:  43%|████▎     | 70/163 [01:26<01:44,  1.13s/it, loss=0.7626, batch_acc=0.8438, running_acc=0.9152, grad=27.7811]Training epoch 21:  44%|████▎     | 71/163 [01:27<01:36,  1.05s/it, loss=0.7626, batch_acc=0.8438, running_acc=0.9152, grad=27.7811]Training epoch 21:  44%|████▎     | 71/163 [01:27<01:36,  1.05s/it, loss=0.4803, batch_acc=0.9375, running_acc=0.9155, grad=19.4282]Training epoch 21:  44%|████▍     | 72/163 [01:28<01:45,  1.16s/it, loss=0.4803, batch_acc=0.9375, running_acc=0.9155, grad=19.4282]Training epoch 21:  44%|████▍     | 72/163 [01:28<01:45,  1.16s/it, loss=0.5566, batch_acc=0.9062, running_acc=0.9154, grad=24.1777]Training epoch 21:  45%|████▍     | 73/163 [01:30<01:47,  1.19s/it, loss=0.5566, batch_acc=0.9062, running_acc=0.9154, grad=24.1777]Training epoch 21:  45%|████▍     | 73/163 [01:30<01:47,  1.19s/it, loss=0.4255, batch_acc=0.9688, running_acc=0.9161, grad=23.6159]Training epoch 21:  45%|████▌     | 74/163 [01:30<01:37,  1.10s/it, loss=0.4255, batch_acc=0.9688, running_acc=0.9161, grad=23.6159]Training epoch 21:  45%|████▌     | 74/163 [01:30<01:37,  1.10s/it, loss=0.5946, batch_acc=0.9062, running_acc=0.9160, grad=27.3403]Training epoch 21:  46%|████▌     | 75/163 [01:31<01:30,  1.03s/it, loss=0.5946, batch_acc=0.9062, running_acc=0.9160, grad=27.3403]Training epoch 21:  46%|████▌     | 75/163 [01:31<01:30,  1.03s/it, loss=0.6246, batch_acc=0.9062, running_acc=0.9158, grad=20.3362]Training epoch 21:  47%|████▋     | 76/163 [01:33<01:42,  1.18s/it, loss=0.6246, batch_acc=0.9062, running_acc=0.9158, grad=20.3362]Training epoch 21:  47%|████▋     | 76/163 [01:33<01:42,  1.18s/it, loss=0.4880, batch_acc=0.9062, running_acc=0.9157, grad=22.4789]Training epoch 21:  47%|████▋     | 77/163 [01:34<01:48,  1.26s/it, loss=0.4880, batch_acc=0.9062, running_acc=0.9157, grad=22.4789]Training epoch 21:  47%|████▋     | 77/163 [01:34<01:48,  1.26s/it, loss=0.4065, batch_acc=0.9062, running_acc=0.9156, grad=15.4854]Training epoch 21:  48%|████▊     | 78/163 [01:35<01:37,  1.15s/it, loss=0.4065, batch_acc=0.9062, running_acc=0.9156, grad=15.4854]Training epoch 21:  48%|████▊     | 78/163 [01:35<01:37,  1.15s/it, loss=0.5808, batch_acc=0.9375, running_acc=0.9159, grad=25.4556]Training epoch 21:  48%|████▊     | 79/163 [01:36<01:29,  1.07s/it, loss=0.5808, batch_acc=0.9375, running_acc=0.9159, grad=25.4556]Training epoch 21:  48%|████▊     | 79/163 [01:36<01:29,  1.07s/it, loss=0.5230, batch_acc=0.9375, running_acc=0.9161, grad=19.6021]Training epoch 21:  49%|████▉     | 80/163 [01:38<01:57,  1.41s/it, loss=0.5230, batch_acc=0.9375, running_acc=0.9161, grad=19.6021]Training epoch 21:  49%|████▉     | 80/163 [01:38<01:57,  1.41s/it, loss=0.4641, batch_acc=0.9062, running_acc=0.9160, grad=17.1666]Training epoch 21:  50%|████▉     | 81/163 [01:39<01:42,  1.25s/it, loss=0.4641, batch_acc=0.9062, running_acc=0.9160, grad=17.1666]Training epoch 21:  50%|████▉     | 81/163 [01:39<01:42,  1.25s/it, loss=0.5120, batch_acc=0.9688, running_acc=0.9167, grad=20.3231]Training epoch 21:  50%|█████     | 82/163 [01:40<01:32,  1.14s/it, loss=0.5120, batch_acc=0.9688, running_acc=0.9167, grad=20.3231]Training epoch 21:  50%|█████     | 82/163 [01:40<01:32,  1.14s/it, loss=0.5405, batch_acc=0.8750, running_acc=0.9162, grad=23.4109]Training epoch 21:  51%|█████     | 83/163 [01:41<01:24,  1.06s/it, loss=0.5405, batch_acc=0.8750, running_acc=0.9162, grad=23.4109]Training epoch 21:  51%|█████     | 83/163 [01:41<01:24,  1.06s/it, loss=0.4844, batch_acc=0.9375, running_acc=0.9164, grad=21.8551]Training epoch 21:  52%|█████▏    | 84/163 [01:43<01:39,  1.26s/it, loss=0.4844, batch_acc=0.9375, running_acc=0.9164, grad=21.8551]Training epoch 21:  52%|█████▏    | 84/163 [01:43<01:39,  1.26s/it, loss=0.6491, batch_acc=0.9375, running_acc=0.9167, grad=26.9107]Training epoch 21:  52%|█████▏    | 85/163 [01:44<01:36,  1.23s/it, loss=0.6491, batch_acc=0.9375, running_acc=0.9167, grad=26.9107]Training epoch 21:  52%|█████▏    | 85/163 [01:44<01:36,  1.23s/it, loss=0.4810, batch_acc=0.9688, running_acc=0.9173, grad=23.4399]Training epoch 21:  53%|█████▎    | 86/163 [01:45<01:26,  1.13s/it, loss=0.4810, batch_acc=0.9688, running_acc=0.9173, grad=23.4399]Training epoch 21:  53%|█████▎    | 86/163 [01:45<01:26,  1.13s/it, loss=0.4271, batch_acc=1.0000, running_acc=0.9182, grad=21.4571]Training epoch 21:  53%|█████▎    | 87/163 [01:46<01:20,  1.05s/it, loss=0.4271, batch_acc=1.0000, running_acc=0.9182, grad=21.4571]Training epoch 21:  53%|█████▎    | 87/163 [01:46<01:20,  1.05s/it, loss=0.5488, batch_acc=0.8750, running_acc=0.9177, grad=24.4250]Training epoch 21:  54%|█████▍    | 88/163 [01:47<01:36,  1.29s/it, loss=0.5488, batch_acc=0.8750, running_acc=0.9177, grad=24.4250]Training epoch 21:  54%|█████▍    | 88/163 [01:47<01:36,  1.29s/it, loss=0.3696, batch_acc=0.9375, running_acc=0.9180, grad=16.0847]Training epoch 21:  55%|█████▍    | 89/163 [01:48<01:26,  1.17s/it, loss=0.3696, batch_acc=0.9375, running_acc=0.9180, grad=16.0847]Training epoch 21:  55%|█████▍    | 89/163 [01:48<01:26,  1.17s/it, loss=0.7719, batch_acc=0.8125, running_acc=0.9168, grad=26.1818]Training epoch 21:  55%|█████▌    | 90/163 [01:49<01:18,  1.08s/it, loss=0.7719, batch_acc=0.8125, running_acc=0.9168, grad=26.1818]Training epoch 21:  55%|█████▌    | 90/163 [01:49<01:18,  1.08s/it, loss=0.6170, batch_acc=0.8750, running_acc=0.9163, grad=25.6490]Training epoch 21:  56%|█████▌    | 91/163 [01:50<01:13,  1.02s/it, loss=0.6170, batch_acc=0.8750, running_acc=0.9163, grad=25.6490]Training epoch 21:  56%|█████▌    | 91/163 [01:50<01:13,  1.02s/it, loss=0.4721, batch_acc=0.9375, running_acc=0.9166, grad=26.4398]Training epoch 21:  56%|█████▋    | 92/163 [01:52<01:31,  1.29s/it, loss=0.4721, batch_acc=0.9375, running_acc=0.9166, grad=26.4398]Training epoch 21:  56%|█████▋    | 92/163 [01:52<01:31,  1.29s/it, loss=0.4963, batch_acc=0.8750, running_acc=0.9161, grad=25.6106]Training epoch 21:  57%|█████▋    | 93/163 [01:53<01:21,  1.16s/it, loss=0.4963, batch_acc=0.8750, running_acc=0.9161, grad=25.6106]Training epoch 21:  57%|█████▋    | 93/163 [01:53<01:21,  1.16s/it, loss=0.5810, batch_acc=0.8750, running_acc=0.9157, grad=22.1978]Training epoch 21:  58%|█████▊    | 94/163 [01:54<01:14,  1.08s/it, loss=0.5810, batch_acc=0.8750, running_acc=0.9157, grad=22.1978]Training epoch 21:  58%|█████▊    | 94/163 [01:54<01:14,  1.08s/it, loss=0.5169, batch_acc=0.9062, running_acc=0.9156, grad=22.2690]Training epoch 21:  58%|█████▊    | 95/163 [01:55<01:09,  1.02s/it, loss=0.5169, batch_acc=0.9062, running_acc=0.9156, grad=22.2690]Training epoch 21:  58%|█████▊    | 95/163 [01:55<01:09,  1.02s/it, loss=0.4639, batch_acc=0.9688, running_acc=0.9161, grad=17.8760]Training epoch 21:  59%|█████▉    | 96/163 [01:56<01:16,  1.15s/it, loss=0.4639, batch_acc=0.9688, running_acc=0.9161, grad=17.8760]Training epoch 21:  59%|█████▉    | 96/163 [01:56<01:16,  1.15s/it, loss=0.4281, batch_acc=0.9375, running_acc=0.9163, grad=20.9355]Training epoch 21:  60%|█████▉    | 97/163 [01:57<01:10,  1.07s/it, loss=0.4281, batch_acc=0.9375, running_acc=0.9163, grad=20.9355]Training epoch 21:  60%|█████▉    | 97/163 [01:57<01:10,  1.07s/it, loss=0.4890, batch_acc=0.9375, running_acc=0.9166, grad=25.1817]Training epoch 21:  60%|██████    | 98/163 [01:58<01:05,  1.01s/it, loss=0.4890, batch_acc=0.9375, running_acc=0.9166, grad=25.1817]Training epoch 21:  60%|██████    | 98/163 [01:58<01:05,  1.01s/it, loss=0.4346, batch_acc=0.9375, running_acc=0.9168, grad=18.5488]Training epoch 21:  61%|██████    | 99/163 [01:59<01:02,  1.03it/s, loss=0.4346, batch_acc=0.9375, running_acc=0.9168, grad=18.5488]Training epoch 21:  61%|██████    | 99/163 [01:59<01:02,  1.03it/s, loss=0.5605, batch_acc=0.8750, running_acc=0.9164, grad=21.9817]Training epoch 21:  61%|██████▏   | 100/163 [02:01<01:20,  1.28s/it, loss=0.5605, batch_acc=0.8750, running_acc=0.9164, grad=21.9817]Training epoch 21:  61%|██████▏   | 100/163 [02:01<01:20,  1.28s/it, loss=0.5157, batch_acc=0.9375, running_acc=0.9166, grad=27.8120]Training epoch 21:  62%|██████▏   | 101/163 [02:02<01:11,  1.16s/it, loss=0.5157, batch_acc=0.9375, running_acc=0.9166, grad=27.8120]Training epoch 21:  62%|██████▏   | 101/163 [02:02<01:11,  1.16s/it, loss=0.4770, batch_acc=0.9375, running_acc=0.9168, grad=24.6909]Training epoch 21:  63%|██████▎   | 102/163 [02:02<01:05,  1.07s/it, loss=0.4770, batch_acc=0.9375, running_acc=0.9168, grad=24.6909]Training epoch 21:  63%|██████▎   | 102/163 [02:02<01:05,  1.07s/it, loss=0.5419, batch_acc=0.9062, running_acc=0.9167, grad=29.8792]Training epoch 21:  63%|██████▎   | 103/163 [02:03<01:00,  1.02s/it, loss=0.5419, batch_acc=0.9062, running_acc=0.9167, grad=29.8792]Training epoch 21:  63%|██████▎   | 103/163 [02:03<01:00,  1.02s/it, loss=0.5075, batch_acc=0.9062, running_acc=0.9166, grad=28.3364]Training epoch 21:  64%|██████▍   | 104/163 [02:05<01:17,  1.31s/it, loss=0.5075, batch_acc=0.9062, running_acc=0.9166, grad=28.3364]Training epoch 21:  64%|██████▍   | 104/163 [02:05<01:17,  1.31s/it, loss=0.5461, batch_acc=0.8750, running_acc=0.9162, grad=24.3039]Training epoch 21:  64%|██████▍   | 105/163 [02:06<01:08,  1.18s/it, loss=0.5461, batch_acc=0.8750, running_acc=0.9162, grad=24.3039]Training epoch 21:  64%|██████▍   | 105/163 [02:06<01:08,  1.18s/it, loss=0.4738, batch_acc=0.9375, running_acc=0.9164, grad=24.0862]Training epoch 21:  65%|██████▌   | 106/163 [02:07<01:02,  1.09s/it, loss=0.4738, batch_acc=0.9375, running_acc=0.9164, grad=24.0862]Training epoch 21:  65%|██████▌   | 106/163 [02:07<01:02,  1.09s/it, loss=0.4835, batch_acc=0.9688, running_acc=0.9169, grad=20.3637]Training epoch 21:  66%|██████▌   | 107/163 [02:08<00:57,  1.03s/it, loss=0.4835, batch_acc=0.9688, running_acc=0.9169, grad=20.3637]Training epoch 21:  66%|██████▌   | 107/163 [02:08<00:57,  1.03s/it, loss=0.5532, batch_acc=0.8750, running_acc=0.9165, grad=21.3609]Training epoch 21:  66%|██████▋   | 108/163 [02:10<01:12,  1.32s/it, loss=0.5532, batch_acc=0.8750, running_acc=0.9165, grad=21.3609]Training epoch 21:  66%|██████▋   | 108/163 [02:10<01:12,  1.32s/it, loss=0.5985, batch_acc=0.8750, running_acc=0.9161, grad=21.0810]Training epoch 21:  67%|██████▋   | 109/163 [02:11<01:04,  1.19s/it, loss=0.5985, batch_acc=0.8750, running_acc=0.9161, grad=21.0810]Training epoch 21:  67%|██████▋   | 109/163 [02:11<01:04,  1.19s/it, loss=0.4614, batch_acc=0.9375, running_acc=0.9163, grad=19.5005]Training epoch 21:  67%|██████▋   | 110/163 [02:12<00:57,  1.09s/it, loss=0.4614, batch_acc=0.9375, running_acc=0.9163, grad=19.5005]Training epoch 21:  67%|██████▋   | 110/163 [02:12<00:57,  1.09s/it, loss=0.6413, batch_acc=0.9375, running_acc=0.9165, grad=25.2284]Training epoch 21:  68%|██████▊   | 111/163 [02:13<00:53,  1.03s/it, loss=0.6413, batch_acc=0.9375, running_acc=0.9165, grad=25.2284]Training epoch 21:  68%|██████▊   | 111/163 [02:13<00:53,  1.03s/it, loss=0.5301, batch_acc=0.9062, running_acc=0.9164, grad=20.5855]Training epoch 21:  69%|██████▊   | 112/163 [02:14<01:02,  1.23s/it, loss=0.5301, batch_acc=0.9062, running_acc=0.9164, grad=20.5855]Training epoch 21:  69%|██████▊   | 112/163 [02:14<01:02,  1.23s/it, loss=0.4486, batch_acc=0.9375, running_acc=0.9166, grad=18.1044]Training epoch 21:  69%|██████▉   | 113/163 [02:15<00:56,  1.13s/it, loss=0.4486, batch_acc=0.9375, running_acc=0.9166, grad=18.1044]Training epoch 21:  69%|██████▉   | 113/163 [02:15<00:56,  1.13s/it, loss=0.5024, batch_acc=0.9062, running_acc=0.9165, grad=25.6965]Training epoch 21:  70%|██████▉   | 114/163 [02:16<00:51,  1.05s/it, loss=0.5024, batch_acc=0.9062, running_acc=0.9165, grad=25.6965]Training epoch 21:  70%|██████▉   | 114/163 [02:16<00:51,  1.05s/it, loss=0.5023, batch_acc=0.8750, running_acc=0.9161, grad=19.9922]Training epoch 21:  71%|███████   | 115/163 [02:17<00:48,  1.00s/it, loss=0.5023, batch_acc=0.8750, running_acc=0.9161, grad=19.9922]Training epoch 21:  71%|███████   | 115/163 [02:17<00:48,  1.00s/it, loss=0.4939, batch_acc=0.8750, running_acc=0.9158, grad=23.1679]Training epoch 21:  71%|███████   | 116/163 [02:19<01:02,  1.33s/it, loss=0.4939, batch_acc=0.8750, running_acc=0.9158, grad=23.1679]Training epoch 21:  71%|███████   | 116/163 [02:19<01:02,  1.33s/it, loss=0.6212, batch_acc=0.8125, running_acc=0.9149, grad=29.2384]Training epoch 21:  72%|███████▏  | 117/163 [02:20<00:55,  1.20s/it, loss=0.6212, batch_acc=0.8125, running_acc=0.9149, grad=29.2384]Training epoch 21:  72%|███████▏  | 117/163 [02:20<00:55,  1.20s/it, loss=0.6499, batch_acc=0.9062, running_acc=0.9148, grad=20.4437]Training epoch 21:  72%|███████▏  | 118/163 [02:21<00:49,  1.10s/it, loss=0.6499, batch_acc=0.9062, running_acc=0.9148, grad=20.4437]Training epoch 21:  72%|███████▏  | 118/163 [02:21<00:49,  1.10s/it, loss=0.4531, batch_acc=0.9375, running_acc=0.9150, grad=19.7787]Training epoch 21:  73%|███████▎  | 119/163 [02:22<00:45,  1.04s/it, loss=0.4531, batch_acc=0.9375, running_acc=0.9150, grad=19.7787]Training epoch 21:  73%|███████▎  | 119/163 [02:22<00:45,  1.04s/it, loss=0.6990, batch_acc=0.7812, running_acc=0.9139, grad=23.4669]Training epoch 21:  74%|███████▎  | 120/163 [02:24<00:56,  1.32s/it, loss=0.6990, batch_acc=0.7812, running_acc=0.9139, grad=23.4669]Training epoch 21:  74%|███████▎  | 120/163 [02:24<00:56,  1.32s/it, loss=0.6616, batch_acc=0.9375, running_acc=0.9141, grad=28.2985]Training epoch 21:  74%|███████▍  | 121/163 [02:25<00:49,  1.19s/it, loss=0.6616, batch_acc=0.9375, running_acc=0.9141, grad=28.2985]Training epoch 21:  74%|███████▍  | 121/163 [02:25<00:49,  1.19s/it, loss=0.6976, batch_acc=0.8438, running_acc=0.9135, grad=22.6929]Training epoch 21:  75%|███████▍  | 122/163 [02:25<00:44,  1.10s/it, loss=0.6976, batch_acc=0.8438, running_acc=0.9135, grad=22.6929]Training epoch 21:  75%|███████▍  | 122/163 [02:25<00:44,  1.10s/it, loss=0.4585, batch_acc=0.9375, running_acc=0.9137, grad=19.5464]Training epoch 21:  75%|███████▌  | 123/163 [02:26<00:41,  1.03s/it, loss=0.4585, batch_acc=0.9375, running_acc=0.9137, grad=19.5464]Training epoch 21:  75%|███████▌  | 123/163 [02:26<00:41,  1.03s/it, loss=0.5692, batch_acc=0.9375, running_acc=0.9139, grad=28.3221]Training epoch 21:  76%|███████▌  | 124/163 [02:28<00:43,  1.12s/it, loss=0.5692, batch_acc=0.9375, running_acc=0.9139, grad=28.3221]Training epoch 21:  76%|███████▌  | 124/163 [02:28<00:43,  1.12s/it, loss=0.3459, batch_acc=0.9375, running_acc=0.9141, grad=18.5787]Training epoch 21:  77%|███████▋  | 125/163 [02:29<00:39,  1.05s/it, loss=0.3459, batch_acc=0.9375, running_acc=0.9141, grad=18.5787]Training epoch 21:  77%|███████▋  | 125/163 [02:29<00:39,  1.05s/it, loss=0.6238, batch_acc=0.9062, running_acc=0.9140, grad=28.5733]Training epoch 21:  77%|███████▋  | 126/163 [02:29<00:36,  1.00it/s, loss=0.6238, batch_acc=0.9062, running_acc=0.9140, grad=28.5733]Training epoch 21:  77%|███████▋  | 126/163 [02:29<00:36,  1.00it/s, loss=0.6668, batch_acc=0.8750, running_acc=0.9137, grad=29.3639]Training epoch 21:  78%|███████▊  | 127/163 [02:30<00:34,  1.04it/s, loss=0.6668, batch_acc=0.8750, running_acc=0.9137, grad=29.3639]Training epoch 21:  78%|███████▊  | 127/163 [02:30<00:34,  1.04it/s, loss=0.4134, batch_acc=1.0000, running_acc=0.9144, grad=19.1092]Training epoch 21:  79%|███████▊  | 128/163 [02:32<00:42,  1.20s/it, loss=0.4134, batch_acc=1.0000, running_acc=0.9144, grad=19.1092]Training epoch 21:  79%|███████▊  | 128/163 [02:32<00:42,  1.20s/it, loss=0.6305, batch_acc=0.9375, running_acc=0.9146, grad=25.9656]Training epoch 21:  79%|███████▉  | 129/163 [02:33<00:37,  1.11s/it, loss=0.6305, batch_acc=0.9375, running_acc=0.9146, grad=25.9656]Training epoch 21:  79%|███████▉  | 129/163 [02:33<00:37,  1.11s/it, loss=0.6212, batch_acc=0.9375, running_acc=0.9147, grad=32.1155]Training epoch 21:  80%|███████▉  | 130/163 [02:34<00:34,  1.04s/it, loss=0.6212, batch_acc=0.9375, running_acc=0.9147, grad=32.1155]Training epoch 21:  80%|███████▉  | 130/163 [02:34<00:34,  1.04s/it, loss=0.6049, batch_acc=0.8125, running_acc=0.9139, grad=20.8175]Training epoch 21:  80%|████████  | 131/163 [02:35<00:31,  1.01it/s, loss=0.6049, batch_acc=0.8125, running_acc=0.9139, grad=20.8175]Training epoch 21:  80%|████████  | 131/163 [02:35<00:31,  1.01it/s, loss=0.6111, batch_acc=0.8438, running_acc=0.9134, grad=26.8308]Training epoch 21:  81%|████████  | 132/163 [02:36<00:37,  1.20s/it, loss=0.6111, batch_acc=0.8438, running_acc=0.9134, grad=26.8308]Training epoch 21:  81%|████████  | 132/163 [02:36<00:37,  1.20s/it, loss=0.6736, batch_acc=0.8750, running_acc=0.9131, grad=21.6935]Training epoch 21:  82%|████████▏ | 133/163 [02:37<00:33,  1.10s/it, loss=0.6736, batch_acc=0.8750, running_acc=0.9131, grad=21.6935]Training epoch 21:  82%|████████▏ | 133/163 [02:37<00:33,  1.10s/it, loss=0.6397, batch_acc=0.8750, running_acc=0.9128, grad=19.8310]Training epoch 21:  82%|████████▏ | 134/163 [02:38<00:30,  1.04s/it, loss=0.6397, batch_acc=0.8750, running_acc=0.9128, grad=19.8310]Training epoch 21:  82%|████████▏ | 134/163 [02:38<00:30,  1.04s/it, loss=0.4872, batch_acc=0.9062, running_acc=0.9128, grad=22.6964]Training epoch 21:  83%|████████▎ | 135/163 [02:39<00:27,  1.01it/s, loss=0.4872, batch_acc=0.9062, running_acc=0.9128, grad=22.6964]Training epoch 21:  83%|████████▎ | 135/163 [02:39<00:27,  1.01it/s, loss=0.5138, batch_acc=0.9062, running_acc=0.9127, grad=19.1463]Training epoch 21:  83%|████████▎ | 136/163 [02:40<00:28,  1.06s/it, loss=0.5138, batch_acc=0.9062, running_acc=0.9127, grad=19.1463]Training epoch 21:  83%|████████▎ | 136/163 [02:40<00:28,  1.06s/it, loss=0.3847, batch_acc=1.0000, running_acc=0.9134, grad=31.8401]Training epoch 21:  84%|████████▍ | 137/163 [02:41<00:26,  1.01s/it, loss=0.3847, batch_acc=1.0000, running_acc=0.9134, grad=31.8401]Training epoch 21:  84%|████████▍ | 137/163 [02:41<00:26,  1.01s/it, loss=0.7977, batch_acc=0.9062, running_acc=0.9133, grad=23.0583]Training epoch 21:  85%|████████▍ | 138/163 [02:42<00:24,  1.03it/s, loss=0.7977, batch_acc=0.9062, running_acc=0.9133, grad=23.0583]Training epoch 21:  85%|████████▍ | 138/163 [02:42<00:24,  1.03it/s, loss=0.5201, batch_acc=0.9062, running_acc=0.9133, grad=19.8317]Training epoch 21:  85%|████████▌ | 139/163 [02:43<00:22,  1.06it/s, loss=0.5201, batch_acc=0.9062, running_acc=0.9133, grad=19.8317]Training epoch 21:  85%|████████▌ | 139/163 [02:43<00:22,  1.06it/s, loss=0.6987, batch_acc=0.8438, running_acc=0.9128, grad=31.9368]Training epoch 21:  86%|████████▌ | 140/163 [02:44<00:25,  1.11s/it, loss=0.6987, batch_acc=0.8438, running_acc=0.9128, grad=31.9368]Training epoch 21:  86%|████████▌ | 140/163 [02:44<00:25,  1.11s/it, loss=0.5834, batch_acc=0.8750, running_acc=0.9125, grad=26.6614]Training epoch 21:  87%|████████▋ | 141/163 [02:45<00:22,  1.04s/it, loss=0.5834, batch_acc=0.8750, running_acc=0.9125, grad=26.6614]Training epoch 21:  87%|████████▋ | 141/163 [02:45<00:22,  1.04s/it, loss=0.5616, batch_acc=0.9688, running_acc=0.9129, grad=25.0610]Training epoch 21:  87%|████████▋ | 142/163 [02:46<00:20,  1.01it/s, loss=0.5616, batch_acc=0.9688, running_acc=0.9129, grad=25.0610]Training epoch 21:  87%|████████▋ | 142/163 [02:46<00:20,  1.01it/s, loss=0.4020, batch_acc=0.9688, running_acc=0.9133, grad=15.4879]Training epoch 21:  88%|████████▊ | 143/163 [02:47<00:19,  1.04it/s, loss=0.4020, batch_acc=0.9688, running_acc=0.9133, grad=15.4879]Training epoch 21:  88%|████████▊ | 143/163 [02:47<00:19,  1.04it/s, loss=0.3977, batch_acc=0.9688, running_acc=0.9137, grad=19.4163]Training epoch 21:  88%|████████▊ | 144/163 [02:49<00:21,  1.15s/it, loss=0.3977, batch_acc=0.9688, running_acc=0.9137, grad=19.4163]Training epoch 21:  88%|████████▊ | 144/163 [02:49<00:21,  1.15s/it, loss=0.4242, batch_acc=1.0000, running_acc=0.9143, grad=19.8245]Training epoch 21:  89%|████████▉ | 145/163 [02:49<00:19,  1.07s/it, loss=0.4242, batch_acc=1.0000, running_acc=0.9143, grad=19.8245]Training epoch 21:  89%|████████▉ | 145/163 [02:49<00:19,  1.07s/it, loss=0.5108, batch_acc=0.9375, running_acc=0.9144, grad=17.0224]Training epoch 21:  90%|████████▉ | 146/163 [02:50<00:17,  1.01s/it, loss=0.5108, batch_acc=0.9375, running_acc=0.9144, grad=17.0224]Training epoch 21:  90%|████████▉ | 146/163 [02:50<00:17,  1.01s/it, loss=0.6162, batch_acc=0.8438, running_acc=0.9140, grad=27.8247]Training epoch 21:  90%|█████████ | 147/163 [02:51<00:15,  1.03it/s, loss=0.6162, batch_acc=0.8438, running_acc=0.9140, grad=27.8247]Training epoch 21:  90%|█████████ | 147/163 [02:51<00:15,  1.03it/s, loss=0.3724, batch_acc=0.8750, running_acc=0.9137, grad=16.3816]Training epoch 21:  91%|█████████ | 148/163 [02:52<00:15,  1.03s/it, loss=0.3724, batch_acc=0.8750, running_acc=0.9137, grad=16.3816]Training epoch 21:  91%|█████████ | 148/163 [02:52<00:15,  1.03s/it, loss=0.4660, batch_acc=0.9062, running_acc=0.9136, grad=21.9799]Training epoch 21:  91%|█████████▏| 149/163 [02:53<00:14,  1.00s/it, loss=0.4660, batch_acc=0.9062, running_acc=0.9136, grad=21.9799]Training epoch 21:  91%|█████████▏| 149/163 [02:53<00:14,  1.00s/it, loss=0.5144, batch_acc=0.8750, running_acc=0.9134, grad=19.9000]Training epoch 21:  92%|█████████▏| 150/163 [02:54<00:12,  1.04it/s, loss=0.5144, batch_acc=0.8750, running_acc=0.9134, grad=19.9000]Training epoch 21:  92%|█████████▏| 150/163 [02:54<00:12,  1.04it/s, loss=0.7006, batch_acc=0.8438, running_acc=0.9129, grad=26.6876]Training epoch 21:  93%|█████████▎| 151/163 [02:55<00:11,  1.06it/s, loss=0.7006, batch_acc=0.8438, running_acc=0.9129, grad=26.6876]Training epoch 21:  93%|█████████▎| 151/163 [02:55<00:11,  1.06it/s, loss=0.3986, batch_acc=0.9688, running_acc=0.9133, grad=18.9546]Training epoch 21:  93%|█████████▎| 152/163 [02:56<00:11,  1.07s/it, loss=0.3986, batch_acc=0.9688, running_acc=0.9133, grad=18.9546]Training epoch 21:  93%|█████████▎| 152/163 [02:56<00:11,  1.07s/it, loss=0.4205, batch_acc=0.9375, running_acc=0.9134, grad=19.0321]Training epoch 21:  94%|█████████▍| 153/163 [02:58<00:12,  1.22s/it, loss=0.4205, batch_acc=0.9375, running_acc=0.9134, grad=19.0321]Training epoch 21:  94%|█████████▍| 153/163 [02:58<00:12,  1.22s/it, loss=0.6124, batch_acc=0.8750, running_acc=0.9132, grad=20.6326]Training epoch 21:  94%|█████████▍| 154/163 [02:59<00:10,  1.12s/it, loss=0.6124, batch_acc=0.8750, running_acc=0.9132, grad=20.6326]Training epoch 21:  94%|█████████▍| 154/163 [02:59<00:10,  1.12s/it, loss=0.4534, batch_acc=0.9688, running_acc=0.9136, grad=28.7256]Training epoch 21:  95%|█████████▌| 155/163 [03:00<00:08,  1.05s/it, loss=0.4534, batch_acc=0.9688, running_acc=0.9136, grad=28.7256]Training epoch 21:  95%|█████████▌| 155/163 [03:00<00:08,  1.05s/it, loss=0.4595, batch_acc=0.9688, running_acc=0.9139, grad=18.0979]Training epoch 21:  96%|█████████▌| 156/163 [03:01<00:07,  1.00s/it, loss=0.4595, batch_acc=0.9688, running_acc=0.9139, grad=18.0979]Training epoch 21:  96%|█████████▌| 156/163 [03:01<00:07,  1.00s/it, loss=0.5000, batch_acc=0.9062, running_acc=0.9139, grad=21.2092]Training epoch 21:  96%|█████████▋| 157/163 [03:02<00:06,  1.16s/it, loss=0.5000, batch_acc=0.9062, running_acc=0.9139, grad=21.2092]Training epoch 21:  96%|█████████▋| 157/163 [03:02<00:06,  1.16s/it, loss=0.4776, batch_acc=0.9375, running_acc=0.9140, grad=24.1587]Training epoch 21:  97%|█████████▋| 158/163 [03:03<00:05,  1.08s/it, loss=0.4776, batch_acc=0.9375, running_acc=0.9140, grad=24.1587]Training epoch 21:  97%|█████████▋| 158/163 [03:03<00:05,  1.08s/it, loss=0.6104, batch_acc=0.9062, running_acc=0.9140, grad=31.8986]Training epoch 21:  98%|█████████▊| 159/163 [03:04<00:04,  1.02s/it, loss=0.6104, batch_acc=0.9062, running_acc=0.9140, grad=31.8986]Training epoch 21:  98%|█████████▊| 159/163 [03:04<00:04,  1.02s/it, loss=0.4097, batch_acc=0.9375, running_acc=0.9141, grad=18.0559]Training epoch 21:  98%|█████████▊| 160/163 [03:05<00:02,  1.03it/s, loss=0.4097, batch_acc=0.9375, running_acc=0.9141, grad=18.0559]Training epoch 21:  98%|█████████▊| 160/163 [03:05<00:02,  1.03it/s, loss=0.6416, batch_acc=0.8438, running_acc=0.9137, grad=33.7711]Training epoch 21:  99%|█████████▉| 161/163 [03:06<00:02,  1.14s/it, loss=0.6416, batch_acc=0.8438, running_acc=0.9137, grad=33.7711]Training epoch 21:  99%|█████████▉| 161/163 [03:06<00:02,  1.14s/it, loss=0.4589, batch_acc=0.9062, running_acc=0.9136, grad=21.3813]Training epoch 21:  99%|█████████▉| 162/163 [03:07<00:01,  1.06s/it, loss=0.4589, batch_acc=0.9062, running_acc=0.9136, grad=21.3813]Training epoch 21:  99%|█████████▉| 162/163 [03:07<00:01,  1.06s/it, loss=0.5561, batch_acc=0.9375, running_acc=0.9138, grad=25.4309]Training epoch 21: 100%|██████████| 163/163 [03:08<00:00,  1.07it/s, loss=0.5561, batch_acc=0.9375, running_acc=0.9138, grad=25.4309]Training epoch 21: 100%|██████████| 163/163 [03:08<00:00,  1.07it/s, loss=0.4439, batch_acc=1.0000, running_acc=0.9141, grad=25.7762]Training epoch 21: 100%|██████████| 163/163 [03:08<00:00,  1.16s/it, loss=0.4439, batch_acc=1.0000, running_acc=0.9141, grad=25.7762]
Evaluation epoch 21:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 21:   4%|▎         | 1/28 [00:05<02:15,  5.00s/it]Evaluation epoch 21:   4%|▎         | 1/28 [00:05<02:15,  5.00s/it, loss=0.8112, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 21:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.8112, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 21:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.4742, batch_acc=0.9688, running_acc=0.8906]Evaluation epoch 21:  11%|█         | 3/28 [00:05<00:33,  1.32s/it, loss=0.4742, batch_acc=0.9688, running_acc=0.8906]Evaluation epoch 21:  11%|█         | 3/28 [00:05<00:33,  1.32s/it, loss=0.6437, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 21:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.6437, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 21:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.8617, batch_acc=0.8438, running_acc=0.8828]Evaluation epoch 21:  18%|█▊        | 5/28 [00:10<00:38,  1.67s/it, loss=0.8617, batch_acc=0.8438, running_acc=0.8828]Evaluation epoch 21:  18%|█▊        | 5/28 [00:10<00:38,  1.67s/it, loss=1.5360, batch_acc=0.5938, running_acc=0.8250]Evaluation epoch 21:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=1.5360, batch_acc=0.5938, running_acc=0.8250]Evaluation epoch 21:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=0.8946, batch_acc=0.8438, running_acc=0.8281]Evaluation epoch 21:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.8946, batch_acc=0.8438, running_acc=0.8281]Evaluation epoch 21:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.9846, batch_acc=0.8438, running_acc=0.8304]Evaluation epoch 21:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.9846, batch_acc=0.8438, running_acc=0.8304]Evaluation epoch 21:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.8140, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 21:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.8140, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 21:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.8191, batch_acc=0.8750, running_acc=0.8333]Evaluation epoch 21:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.8191, batch_acc=0.8750, running_acc=0.8333]Evaluation epoch 21:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.6538, batch_acc=0.9062, running_acc=0.8406]Evaluation epoch 21:  39%|███▉      | 11/28 [00:14<00:12,  1.35it/s, loss=0.6538, batch_acc=0.9062, running_acc=0.8406]Evaluation epoch 21:  39%|███▉      | 11/28 [00:14<00:12,  1.35it/s, loss=0.7497, batch_acc=0.8750, running_acc=0.8438]Evaluation epoch 21:  43%|████▎     | 12/28 [00:20<00:35,  2.24s/it, loss=0.7497, batch_acc=0.8750, running_acc=0.8438]Evaluation epoch 21:  43%|████▎     | 12/28 [00:20<00:35,  2.24s/it, loss=1.1304, batch_acc=0.7500, running_acc=0.8359]Evaluation epoch 21:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=1.1304, batch_acc=0.7500, running_acc=0.8359]Evaluation epoch 21:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=0.6173, batch_acc=0.9062, running_acc=0.8413]Evaluation epoch 21:  50%|█████     | 14/28 [00:20<00:17,  1.22s/it, loss=0.6173, batch_acc=0.9062, running_acc=0.8413]Evaluation epoch 21:  50%|█████     | 14/28 [00:20<00:17,  1.22s/it, loss=1.4248, batch_acc=0.6875, running_acc=0.8304]Evaluation epoch 21:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.4248, batch_acc=0.6875, running_acc=0.8304]Evaluation epoch 21:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.5497, batch_acc=0.5625, running_acc=0.8125]Evaluation epoch 21:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.5497, batch_acc=0.5625, running_acc=0.8125]Evaluation epoch 21:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=0.9930, batch_acc=0.7812, running_acc=0.8105]Evaluation epoch 21:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.9930, batch_acc=0.7812, running_acc=0.8105]Evaluation epoch 21:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.9140, batch_acc=0.6875, running_acc=0.8033]Evaluation epoch 21:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.9140, batch_acc=0.6875, running_acc=0.8033]Evaluation epoch 21:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.8481, batch_acc=0.7188, running_acc=0.7986]Evaluation epoch 21:  68%|██████▊   | 19/28 [00:24<00:06,  1.44it/s, loss=0.8481, batch_acc=0.7188, running_acc=0.7986]Evaluation epoch 21:  68%|██████▊   | 19/28 [00:24<00:06,  1.44it/s, loss=1.0451, batch_acc=0.5938, running_acc=0.7878]Evaluation epoch 21:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=1.0451, batch_acc=0.5938, running_acc=0.7878]Evaluation epoch 21:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=0.8199, batch_acc=0.7188, running_acc=0.7844]Evaluation epoch 21:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.8199, batch_acc=0.7188, running_acc=0.7844]Evaluation epoch 21:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.9738, batch_acc=0.7812, running_acc=0.7842]Evaluation epoch 21:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.9738, batch_acc=0.7812, running_acc=0.7842]Evaluation epoch 21:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=1.0819, batch_acc=0.7812, running_acc=0.7841]Evaluation epoch 21:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.0819, batch_acc=0.7812, running_acc=0.7841]Evaluation epoch 21:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=1.2171, batch_acc=0.6875, running_acc=0.7799]Evaluation epoch 21:  86%|████████▌ | 24/28 [00:33<00:07,  1.98s/it, loss=1.2171, batch_acc=0.6875, running_acc=0.7799]Evaluation epoch 21:  86%|████████▌ | 24/28 [00:33<00:07,  1.98s/it, loss=0.4763, batch_acc=0.9375, running_acc=0.7865]Evaluation epoch 21:  89%|████████▉ | 25/28 [00:33<00:04,  1.47s/it, loss=0.4763, batch_acc=0.9375, running_acc=0.7865]Evaluation epoch 21:  89%|████████▉ | 25/28 [00:33<00:04,  1.47s/it, loss=0.4168, batch_acc=0.9375, running_acc=0.7925]Evaluation epoch 21:  93%|█████████▎| 26/28 [00:34<00:02,  1.11s/it, loss=0.4168, batch_acc=0.9375, running_acc=0.7925]Evaluation epoch 21:  93%|█████████▎| 26/28 [00:34<00:02,  1.11s/it, loss=1.0169, batch_acc=0.7188, running_acc=0.7897]Evaluation epoch 21:  96%|█████████▋| 27/28 [00:34<00:00,  1.17it/s, loss=1.0169, batch_acc=0.7188, running_acc=0.7897]Evaluation epoch 21:  96%|█████████▋| 27/28 [00:34<00:00,  1.17it/s, loss=1.1827, batch_acc=0.7188, running_acc=0.7870]Evaluation epoch 21: 100%|██████████| 28/28 [00:34<00:00,  1.17it/s, loss=1.5762, batch_acc=0.6667, running_acc=0.7866]Evaluation epoch 21: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.5762, batch_acc=0.6667, running_acc=0.7866]
Training epoch 22:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 22:   1%|          | 1/163 [00:06<16:31,  6.12s/it]Training epoch 22:   1%|          | 1/163 [00:06<16:31,  6.12s/it, loss=0.4436, batch_acc=0.9688, running_acc=0.9688, grad=23.5658]Training epoch 22:   1%|          | 2/163 [00:07<08:09,  3.04s/it, loss=0.4436, batch_acc=0.9688, running_acc=0.9688, grad=23.5658]Training epoch 22:   1%|          | 2/163 [00:07<08:09,  3.04s/it, loss=0.3910, batch_acc=0.9688, running_acc=0.9688, grad=22.5314]Training epoch 22:   2%|▏         | 3/163 [00:07<05:28,  2.05s/it, loss=0.3910, batch_acc=0.9688, running_acc=0.9688, grad=22.5314]Training epoch 22:   2%|▏         | 3/163 [00:07<05:28,  2.05s/it, loss=0.3120, batch_acc=1.0000, running_acc=0.9792, grad=13.5683]Training epoch 22:   2%|▏         | 4/163 [00:10<05:57,  2.25s/it, loss=0.3120, batch_acc=1.0000, running_acc=0.9792, grad=13.5683]Training epoch 22:   2%|▏         | 4/163 [00:10<05:57,  2.25s/it, loss=0.6239, batch_acc=0.9062, running_acc=0.9609, grad=26.5594]Training epoch 22:   3%|▎         | 5/163 [00:11<04:37,  1.75s/it, loss=0.6239, batch_acc=0.9062, running_acc=0.9609, grad=26.5594]Training epoch 22:   3%|▎         | 5/163 [00:11<04:37,  1.75s/it, loss=0.5380, batch_acc=0.9062, running_acc=0.9500, grad=21.9504]Training epoch 22:   4%|▎         | 6/163 [00:12<03:48,  1.46s/it, loss=0.5380, batch_acc=0.9062, running_acc=0.9500, grad=21.9504]Training epoch 22:   4%|▎         | 6/163 [00:12<03:48,  1.46s/it, loss=0.4893, batch_acc=0.8750, running_acc=0.9375, grad=19.7476]Training epoch 22:   4%|▍         | 7/163 [00:13<03:17,  1.27s/it, loss=0.4893, batch_acc=0.8750, running_acc=0.9375, grad=19.7476]Training epoch 22:   4%|▍         | 7/163 [00:13<03:17,  1.27s/it, loss=0.5246, batch_acc=0.9375, running_acc=0.9375, grad=21.5940]Training epoch 22:   5%|▍         | 8/163 [00:14<03:35,  1.39s/it, loss=0.5246, batch_acc=0.9375, running_acc=0.9375, grad=21.5940]Training epoch 22:   5%|▍         | 8/163 [00:14<03:35,  1.39s/it, loss=0.8089, batch_acc=0.8125, running_acc=0.9219, grad=25.8320]Training epoch 22:   6%|▌         | 9/163 [00:15<03:09,  1.23s/it, loss=0.8089, batch_acc=0.8125, running_acc=0.9219, grad=25.8320]Training epoch 22:   6%|▌         | 9/163 [00:15<03:09,  1.23s/it, loss=0.5897, batch_acc=0.9375, running_acc=0.9236, grad=23.7585]Training epoch 22:   6%|▌         | 10/163 [00:16<02:51,  1.12s/it, loss=0.5897, batch_acc=0.9375, running_acc=0.9236, grad=23.7585]Training epoch 22:   6%|▌         | 10/163 [00:16<02:51,  1.12s/it, loss=0.4941, batch_acc=0.9688, running_acc=0.9281, grad=24.9884]Training epoch 22:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.4941, batch_acc=0.9688, running_acc=0.9281, grad=24.9884]Training epoch 22:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.4208, batch_acc=0.9375, running_acc=0.9290, grad=16.2899]Training epoch 22:   7%|▋         | 12/163 [00:19<03:19,  1.32s/it, loss=0.4208, batch_acc=0.9375, running_acc=0.9290, grad=16.2899]Training epoch 22:   7%|▋         | 12/163 [00:19<03:19,  1.32s/it, loss=0.4911, batch_acc=0.9688, running_acc=0.9323, grad=23.5703]Training epoch 22:   8%|▊         | 13/163 [00:20<02:58,  1.19s/it, loss=0.4911, batch_acc=0.9688, running_acc=0.9323, grad=23.5703]Training epoch 22:   8%|▊         | 13/163 [00:20<02:58,  1.19s/it, loss=0.3653, batch_acc=1.0000, running_acc=0.9375, grad=18.8022]Training epoch 22:   9%|▊         | 14/163 [00:21<02:43,  1.10s/it, loss=0.3653, batch_acc=1.0000, running_acc=0.9375, grad=18.8022]Training epoch 22:   9%|▊         | 14/163 [00:21<02:43,  1.10s/it, loss=0.6078, batch_acc=0.9375, running_acc=0.9375, grad=25.9693]Training epoch 22:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=0.6078, batch_acc=0.9375, running_acc=0.9375, grad=25.9693]Training epoch 22:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=0.5664, batch_acc=0.9375, running_acc=0.9375, grad=27.4903]Training epoch 22:  10%|▉         | 16/163 [00:23<03:02,  1.24s/it, loss=0.5664, batch_acc=0.9375, running_acc=0.9375, grad=27.4903]Training epoch 22:  10%|▉         | 16/163 [00:23<03:02,  1.24s/it, loss=0.4850, batch_acc=0.8750, running_acc=0.9336, grad=18.8249]Training epoch 22:  10%|█         | 17/163 [00:24<02:45,  1.13s/it, loss=0.4850, batch_acc=0.8750, running_acc=0.9336, grad=18.8249]Training epoch 22:  10%|█         | 17/163 [00:24<02:45,  1.13s/it, loss=0.6094, batch_acc=0.9062, running_acc=0.9320, grad=27.0878]Training epoch 22:  11%|█         | 18/163 [00:25<02:33,  1.06s/it, loss=0.6094, batch_acc=0.9062, running_acc=0.9320, grad=27.0878]Training epoch 22:  11%|█         | 18/163 [00:25<02:33,  1.06s/it, loss=0.3998, batch_acc=1.0000, running_acc=0.9358, grad=17.2958]Training epoch 22:  12%|█▏        | 19/163 [00:26<02:24,  1.00s/it, loss=0.3998, batch_acc=1.0000, running_acc=0.9358, grad=17.2958]Training epoch 22:  12%|█▏        | 19/163 [00:26<02:24,  1.00s/it, loss=0.4459, batch_acc=0.8750, running_acc=0.9326, grad=19.6541]Training epoch 22:  12%|█▏        | 20/163 [00:28<03:03,  1.29s/it, loss=0.4459, batch_acc=0.8750, running_acc=0.9326, grad=19.6541]Training epoch 22:  12%|█▏        | 20/163 [00:28<03:03,  1.29s/it, loss=0.4455, batch_acc=0.9688, running_acc=0.9344, grad=18.4327]Training epoch 22:  13%|█▎        | 21/163 [00:29<02:45,  1.16s/it, loss=0.4455, batch_acc=0.9688, running_acc=0.9344, grad=18.4327]Training epoch 22:  13%|█▎        | 21/163 [00:29<02:45,  1.16s/it, loss=0.3401, batch_acc=0.9375, running_acc=0.9345, grad=16.8889]Training epoch 22:  13%|█▎        | 22/163 [00:30<02:32,  1.08s/it, loss=0.3401, batch_acc=0.9375, running_acc=0.9345, grad=16.8889]Training epoch 22:  13%|█▎        | 22/163 [00:30<02:32,  1.08s/it, loss=0.5632, batch_acc=0.9062, running_acc=0.9332, grad=22.3426]Training epoch 22:  14%|█▍        | 23/163 [00:30<02:22,  1.02s/it, loss=0.5632, batch_acc=0.9062, running_acc=0.9332, grad=22.3426]Training epoch 22:  14%|█▍        | 23/163 [00:30<02:22,  1.02s/it, loss=0.4601, batch_acc=0.9375, running_acc=0.9334, grad=18.8556]Training epoch 22:  15%|█▍        | 24/163 [00:32<03:04,  1.32s/it, loss=0.4601, batch_acc=0.9375, running_acc=0.9334, grad=18.8556]Training epoch 22:  15%|█▍        | 24/163 [00:32<03:04,  1.32s/it, loss=0.4469, batch_acc=0.9688, running_acc=0.9349, grad=22.7566]Training epoch 22:  15%|█▌        | 25/163 [00:33<02:44,  1.19s/it, loss=0.4469, batch_acc=0.9688, running_acc=0.9349, grad=22.7566]Training epoch 22:  15%|█▌        | 25/163 [00:33<02:44,  1.19s/it, loss=0.3573, batch_acc=1.0000, running_acc=0.9375, grad=17.3434]Training epoch 22:  16%|█▌        | 26/163 [00:34<02:30,  1.10s/it, loss=0.3573, batch_acc=1.0000, running_acc=0.9375, grad=17.3434]Training epoch 22:  16%|█▌        | 26/163 [00:34<02:30,  1.10s/it, loss=0.6464, batch_acc=0.9062, running_acc=0.9363, grad=26.1285]Training epoch 22:  17%|█▋        | 27/163 [00:35<02:20,  1.03s/it, loss=0.6464, batch_acc=0.9062, running_acc=0.9363, grad=26.1285]Training epoch 22:  17%|█▋        | 27/163 [00:35<02:20,  1.03s/it, loss=0.6124, batch_acc=0.8750, running_acc=0.9340, grad=27.8176]Training epoch 22:  17%|█▋        | 28/163 [00:37<03:05,  1.37s/it, loss=0.6124, batch_acc=0.8750, running_acc=0.9340, grad=27.8176]Training epoch 22:  17%|█▋        | 28/163 [00:37<03:05,  1.37s/it, loss=0.6731, batch_acc=0.8438, running_acc=0.9308, grad=31.3078]Training epoch 22:  18%|█▊        | 29/163 [00:38<02:43,  1.22s/it, loss=0.6731, batch_acc=0.8438, running_acc=0.9308, grad=31.3078]Training epoch 22:  18%|█▊        | 29/163 [00:38<02:43,  1.22s/it, loss=0.4592, batch_acc=0.9375, running_acc=0.9310, grad=25.9913]Training epoch 22:  18%|█▊        | 30/163 [00:39<02:28,  1.12s/it, loss=0.4592, batch_acc=0.9375, running_acc=0.9310, grad=25.9913]Training epoch 22:  18%|█▊        | 30/163 [00:39<02:28,  1.12s/it, loss=0.5059, batch_acc=0.8750, running_acc=0.9292, grad=28.3979]Training epoch 22:  19%|█▉        | 31/163 [00:40<02:18,  1.05s/it, loss=0.5059, batch_acc=0.8750, running_acc=0.9292, grad=28.3979]Training epoch 22:  19%|█▉        | 31/163 [00:40<02:18,  1.05s/it, loss=0.4798, batch_acc=0.9375, running_acc=0.9294, grad=20.1134]Training epoch 22:  20%|█▉        | 32/163 [00:41<02:27,  1.13s/it, loss=0.4798, batch_acc=0.9375, running_acc=0.9294, grad=20.1134]Training epoch 22:  20%|█▉        | 32/163 [00:41<02:27,  1.13s/it, loss=0.5988, batch_acc=0.8438, running_acc=0.9268, grad=32.3746]Training epoch 22:  20%|██        | 33/163 [00:42<02:16,  1.05s/it, loss=0.5988, batch_acc=0.8438, running_acc=0.9268, grad=32.3746]Training epoch 22:  20%|██        | 33/163 [00:42<02:16,  1.05s/it, loss=0.5461, batch_acc=0.8750, running_acc=0.9252, grad=17.1805]Training epoch 22:  21%|██        | 34/163 [00:43<02:09,  1.00s/it, loss=0.5461, batch_acc=0.8750, running_acc=0.9252, grad=17.1805]Training epoch 22:  21%|██        | 34/163 [00:43<02:09,  1.00s/it, loss=0.2905, batch_acc=1.0000, running_acc=0.9274, grad=17.9051]Training epoch 22:  21%|██▏       | 35/163 [00:44<02:03,  1.04it/s, loss=0.2905, batch_acc=1.0000, running_acc=0.9274, grad=17.9051]Training epoch 22:  21%|██▏       | 35/163 [00:44<02:03,  1.04it/s, loss=0.5440, batch_acc=0.9062, running_acc=0.9268, grad=22.2291]Training epoch 22:  22%|██▏       | 36/163 [00:45<02:07,  1.01s/it, loss=0.5440, batch_acc=0.9062, running_acc=0.9268, grad=22.2291]Training epoch 22:  22%|██▏       | 36/163 [00:45<02:07,  1.01s/it, loss=0.3470, batch_acc=1.0000, running_acc=0.9288, grad=16.4363]Training epoch 22:  23%|██▎       | 37/163 [00:46<02:01,  1.03it/s, loss=0.3470, batch_acc=1.0000, running_acc=0.9288, grad=16.4363]Training epoch 22:  23%|██▎       | 37/163 [00:46<02:01,  1.03it/s, loss=0.5864, batch_acc=0.9375, running_acc=0.9291, grad=30.6015]Training epoch 22:  23%|██▎       | 38/163 [00:47<01:57,  1.06it/s, loss=0.5864, batch_acc=0.9375, running_acc=0.9291, grad=30.6015]Training epoch 22:  23%|██▎       | 38/163 [00:47<01:57,  1.06it/s, loss=0.5383, batch_acc=0.9375, running_acc=0.9293, grad=29.9168]Training epoch 22:  24%|██▍       | 39/163 [00:48<01:54,  1.09it/s, loss=0.5383, batch_acc=0.9375, running_acc=0.9293, grad=29.9168]Training epoch 22:  24%|██▍       | 39/163 [00:48<01:54,  1.09it/s, loss=0.5794, batch_acc=0.9688, running_acc=0.9303, grad=26.0871]Training epoch 22:  25%|██▍       | 40/163 [00:49<02:12,  1.07s/it, loss=0.5794, batch_acc=0.9688, running_acc=0.9303, grad=26.0871]Training epoch 22:  25%|██▍       | 40/163 [00:49<02:12,  1.07s/it, loss=0.8330, batch_acc=0.7812, running_acc=0.9266, grad=34.9742]Training epoch 22:  25%|██▌       | 41/163 [00:50<02:03,  1.01s/it, loss=0.8330, batch_acc=0.7812, running_acc=0.9266, grad=34.9742]Training epoch 22:  25%|██▌       | 41/163 [00:50<02:03,  1.01s/it, loss=0.4593, batch_acc=1.0000, running_acc=0.9284, grad=24.3747]Training epoch 22:  26%|██▌       | 42/163 [00:51<01:57,  1.03it/s, loss=0.4593, batch_acc=1.0000, running_acc=0.9284, grad=24.3747]Training epoch 22:  26%|██▌       | 42/163 [00:51<01:57,  1.03it/s, loss=0.3881, batch_acc=0.9062, running_acc=0.9278, grad=20.0595]Training epoch 22:  26%|██▋       | 43/163 [00:52<01:53,  1.06it/s, loss=0.3881, batch_acc=0.9062, running_acc=0.9278, grad=20.0595]Training epoch 22:  26%|██▋       | 43/163 [00:52<01:53,  1.06it/s, loss=0.4566, batch_acc=0.9688, running_acc=0.9288, grad=19.4962]Training epoch 22:  27%|██▋       | 44/163 [00:53<01:52,  1.06it/s, loss=0.4566, batch_acc=0.9688, running_acc=0.9288, grad=19.4962]Training epoch 22:  27%|██▋       | 44/163 [00:53<01:52,  1.06it/s, loss=0.4785, batch_acc=0.9375, running_acc=0.9290, grad=17.2398]Training epoch 22:  28%|██▊       | 45/163 [00:53<01:49,  1.08it/s, loss=0.4785, batch_acc=0.9375, running_acc=0.9290, grad=17.2398]Training epoch 22:  28%|██▊       | 45/163 [00:53<01:49,  1.08it/s, loss=0.4126, batch_acc=0.9375, running_acc=0.9292, grad=19.6981]Training epoch 22:  28%|██▊       | 46/163 [00:54<01:46,  1.10it/s, loss=0.4126, batch_acc=0.9375, running_acc=0.9292, grad=19.6981]Training epoch 22:  28%|██▊       | 46/163 [00:54<01:46,  1.10it/s, loss=0.5066, batch_acc=0.9062, running_acc=0.9287, grad=19.8385]Training epoch 22:  29%|██▉       | 47/163 [00:55<01:44,  1.11it/s, loss=0.5066, batch_acc=0.9062, running_acc=0.9287, grad=19.8385]Training epoch 22:  29%|██▉       | 47/163 [00:55<01:44,  1.11it/s, loss=0.3162, batch_acc=0.9688, running_acc=0.9295, grad=18.7823]Training epoch 22:  29%|██▉       | 48/163 [00:57<02:23,  1.25s/it, loss=0.3162, batch_acc=0.9688, running_acc=0.9295, grad=18.7823]Training epoch 22:  29%|██▉       | 48/163 [00:57<02:23,  1.25s/it, loss=0.3423, batch_acc=1.0000, running_acc=0.9310, grad=16.7058]Training epoch 22:  30%|███       | 49/163 [00:58<02:09,  1.14s/it, loss=0.3423, batch_acc=1.0000, running_acc=0.9310, grad=16.7058]Training epoch 22:  30%|███       | 49/163 [00:58<02:09,  1.14s/it, loss=0.5694, batch_acc=0.8750, running_acc=0.9298, grad=20.6768]Training epoch 22:  31%|███       | 50/163 [00:59<01:59,  1.06s/it, loss=0.5694, batch_acc=0.8750, running_acc=0.9298, grad=20.6768]Training epoch 22:  31%|███       | 50/163 [00:59<01:59,  1.06s/it, loss=0.3934, batch_acc=0.9062, running_acc=0.9294, grad=15.4284]Training epoch 22:  31%|███▏      | 51/163 [01:00<01:52,  1.00s/it, loss=0.3934, batch_acc=0.9062, running_acc=0.9294, grad=15.4284]Training epoch 22:  31%|███▏      | 51/163 [01:00<01:52,  1.00s/it, loss=0.4960, batch_acc=0.9375, running_acc=0.9295, grad=23.5875]Training epoch 22:  32%|███▏      | 52/163 [01:01<02:10,  1.17s/it, loss=0.4960, batch_acc=0.9375, running_acc=0.9295, grad=23.5875]Training epoch 22:  32%|███▏      | 52/163 [01:01<02:10,  1.17s/it, loss=0.5783, batch_acc=0.9375, running_acc=0.9297, grad=22.3352]Training epoch 22:  33%|███▎      | 53/163 [01:02<01:59,  1.08s/it, loss=0.5783, batch_acc=0.9375, running_acc=0.9297, grad=22.3352]Training epoch 22:  33%|███▎      | 53/163 [01:02<01:59,  1.08s/it, loss=0.4675, batch_acc=0.8750, running_acc=0.9287, grad=22.0370]Training epoch 22:  33%|███▎      | 54/163 [01:03<01:51,  1.02s/it, loss=0.4675, batch_acc=0.8750, running_acc=0.9287, grad=22.0370]Training epoch 22:  33%|███▎      | 54/163 [01:03<01:51,  1.02s/it, loss=0.3899, batch_acc=0.9688, running_acc=0.9294, grad=23.5262]Training epoch 22:  34%|███▎      | 55/163 [01:04<01:45,  1.02it/s, loss=0.3899, batch_acc=0.9688, running_acc=0.9294, grad=23.5262]Training epoch 22:  34%|███▎      | 55/163 [01:04<01:45,  1.02it/s, loss=0.7397, batch_acc=0.8438, running_acc=0.9278, grad=27.7591]Training epoch 22:  34%|███▍      | 56/163 [01:05<01:49,  1.02s/it, loss=0.7397, batch_acc=0.8438, running_acc=0.9278, grad=27.7591]Training epoch 22:  34%|███▍      | 56/163 [01:05<01:49,  1.02s/it, loss=0.3275, batch_acc=1.0000, running_acc=0.9291, grad=17.2021]Training epoch 22:  35%|███▍      | 57/163 [01:06<01:43,  1.02it/s, loss=0.3275, batch_acc=1.0000, running_acc=0.9291, grad=17.2021]Training epoch 22:  35%|███▍      | 57/163 [01:06<01:43,  1.02it/s, loss=0.5350, batch_acc=0.9688, running_acc=0.9298, grad=21.3173]Training epoch 22:  36%|███▌      | 58/163 [01:07<01:39,  1.05it/s, loss=0.5350, batch_acc=0.9688, running_acc=0.9298, grad=21.3173]Training epoch 22:  36%|███▌      | 58/163 [01:07<01:39,  1.05it/s, loss=0.3737, batch_acc=0.9688, running_acc=0.9305, grad=15.8898]Training epoch 22:  36%|███▌      | 59/163 [01:08<01:36,  1.08it/s, loss=0.3737, batch_acc=0.9688, running_acc=0.9305, grad=15.8898]Training epoch 22:  36%|███▌      | 59/163 [01:08<01:36,  1.08it/s, loss=0.5403, batch_acc=0.9375, running_acc=0.9306, grad=22.3127]Training epoch 22:  37%|███▋      | 60/163 [01:09<01:51,  1.08s/it, loss=0.5403, batch_acc=0.9375, running_acc=0.9306, grad=22.3127]Training epoch 22:  37%|███▋      | 60/163 [01:09<01:51,  1.08s/it, loss=0.5584, batch_acc=0.9688, running_acc=0.9313, grad=20.9514]Training epoch 22:  37%|███▋      | 61/163 [01:10<01:44,  1.02s/it, loss=0.5584, batch_acc=0.9688, running_acc=0.9313, grad=20.9514]Training epoch 22:  37%|███▋      | 61/163 [01:10<01:44,  1.02s/it, loss=0.6516, batch_acc=0.8750, running_acc=0.9303, grad=28.8394]Training epoch 22:  38%|███▊      | 62/163 [01:11<01:38,  1.02it/s, loss=0.6516, batch_acc=0.8750, running_acc=0.9303, grad=28.8394]Training epoch 22:  38%|███▊      | 62/163 [01:11<01:38,  1.02it/s, loss=0.6561, batch_acc=0.8750, running_acc=0.9294, grad=28.8302]Training epoch 22:  39%|███▊      | 63/163 [01:12<01:37,  1.03it/s, loss=0.6561, batch_acc=0.8750, running_acc=0.9294, grad=28.8302]Training epoch 22:  39%|███▊      | 63/163 [01:12<01:37,  1.03it/s, loss=0.6152, batch_acc=0.8750, running_acc=0.9286, grad=28.0241]Training epoch 22:  39%|███▉      | 64/163 [01:14<01:58,  1.20s/it, loss=0.6152, batch_acc=0.8750, running_acc=0.9286, grad=28.0241]Training epoch 22:  39%|███▉      | 64/163 [01:14<01:58,  1.20s/it, loss=0.3702, batch_acc=1.0000, running_acc=0.9297, grad=18.3594]Training epoch 22:  40%|███▉      | 65/163 [01:15<01:47,  1.10s/it, loss=0.3702, batch_acc=1.0000, running_acc=0.9297, grad=18.3594]Training epoch 22:  40%|███▉      | 65/163 [01:15<01:47,  1.10s/it, loss=0.6235, batch_acc=0.9062, running_acc=0.9293, grad=23.5257]Training epoch 22:  40%|████      | 66/163 [01:15<01:40,  1.03s/it, loss=0.6235, batch_acc=0.9062, running_acc=0.9293, grad=23.5257]Training epoch 22:  40%|████      | 66/163 [01:15<01:40,  1.03s/it, loss=0.5218, batch_acc=0.9062, running_acc=0.9290, grad=23.3030]Training epoch 22:  41%|████      | 67/163 [01:16<01:34,  1.01it/s, loss=0.5218, batch_acc=0.9062, running_acc=0.9290, grad=23.3030]Training epoch 22:  41%|████      | 67/163 [01:16<01:34,  1.01it/s, loss=0.4147, batch_acc=0.9688, running_acc=0.9296, grad=35.8693]Training epoch 22:  42%|████▏     | 68/163 [01:18<01:38,  1.04s/it, loss=0.4147, batch_acc=0.9688, running_acc=0.9296, grad=35.8693]Training epoch 22:  42%|████▏     | 68/163 [01:18<01:38,  1.04s/it, loss=0.4523, batch_acc=0.9062, running_acc=0.9292, grad=32.4837]Training epoch 22:  42%|████▏     | 69/163 [01:18<01:32,  1.01it/s, loss=0.4523, batch_acc=0.9062, running_acc=0.9292, grad=32.4837]Training epoch 22:  42%|████▏     | 69/163 [01:18<01:32,  1.01it/s, loss=0.5044, batch_acc=0.8750, running_acc=0.9284, grad=27.4373]Training epoch 22:  43%|████▎     | 70/163 [01:19<01:28,  1.05it/s, loss=0.5044, batch_acc=0.8750, running_acc=0.9284, grad=27.4373]Training epoch 22:  43%|████▎     | 70/163 [01:19<01:28,  1.05it/s, loss=0.4913, batch_acc=0.9688, running_acc=0.9290, grad=20.3690]Training epoch 22:  44%|████▎     | 71/163 [01:20<01:25,  1.07it/s, loss=0.4913, batch_acc=0.9688, running_acc=0.9290, grad=20.3690]Training epoch 22:  44%|████▎     | 71/163 [01:20<01:25,  1.07it/s, loss=0.3923, batch_acc=0.9062, running_acc=0.9287, grad=18.7312]Training epoch 22:  44%|████▍     | 72/163 [01:22<01:40,  1.10s/it, loss=0.3923, batch_acc=0.9062, running_acc=0.9287, grad=18.7312]Training epoch 22:  44%|████▍     | 72/163 [01:22<01:40,  1.10s/it, loss=0.4945, batch_acc=0.9375, running_acc=0.9288, grad=28.5839]Training epoch 22:  45%|████▍     | 73/163 [01:23<01:33,  1.04s/it, loss=0.4945, batch_acc=0.9375, running_acc=0.9288, grad=28.5839]Training epoch 22:  45%|████▍     | 73/163 [01:23<01:33,  1.04s/it, loss=0.4949, batch_acc=0.9375, running_acc=0.9289, grad=26.0252]Training epoch 22:  45%|████▌     | 74/163 [01:23<01:28,  1.01it/s, loss=0.4949, batch_acc=0.9375, running_acc=0.9289, grad=26.0252]Training epoch 22:  45%|████▌     | 74/163 [01:23<01:28,  1.01it/s, loss=0.6452, batch_acc=0.9375, running_acc=0.9291, grad=34.4146]Training epoch 22:  46%|████▌     | 75/163 [01:24<01:24,  1.05it/s, loss=0.6452, batch_acc=0.9375, running_acc=0.9291, grad=34.4146]Training epoch 22:  46%|████▌     | 75/163 [01:24<01:24,  1.05it/s, loss=0.4416, batch_acc=0.9375, running_acc=0.9292, grad=24.4669]Training epoch 22:  47%|████▋     | 76/163 [01:26<01:46,  1.22s/it, loss=0.4416, batch_acc=0.9375, running_acc=0.9292, grad=24.4669]Training epoch 22:  47%|████▋     | 76/163 [01:26<01:46,  1.22s/it, loss=0.5335, batch_acc=0.9375, running_acc=0.9293, grad=23.8600]Training epoch 22:  47%|████▋     | 77/163 [01:27<01:36,  1.12s/it, loss=0.5335, batch_acc=0.9375, running_acc=0.9293, grad=23.8600]Training epoch 22:  47%|████▋     | 77/163 [01:27<01:36,  1.12s/it, loss=0.4275, batch_acc=0.9375, running_acc=0.9294, grad=21.4453]Training epoch 22:  48%|████▊     | 78/163 [01:28<01:29,  1.05s/it, loss=0.4275, batch_acc=0.9375, running_acc=0.9294, grad=21.4453]Training epoch 22:  48%|████▊     | 78/163 [01:28<01:29,  1.05s/it, loss=0.5416, batch_acc=0.9375, running_acc=0.9295, grad=24.7529]Training epoch 22:  48%|████▊     | 79/163 [01:29<01:23,  1.00it/s, loss=0.5416, batch_acc=0.9375, running_acc=0.9295, grad=24.7529]Training epoch 22:  48%|████▊     | 79/163 [01:29<01:23,  1.00it/s, loss=0.3574, batch_acc=0.9375, running_acc=0.9296, grad=14.2450]Training epoch 22:  49%|████▉     | 80/163 [01:30<01:39,  1.20s/it, loss=0.3574, batch_acc=0.9375, running_acc=0.9296, grad=14.2450]Training epoch 22:  49%|████▉     | 80/163 [01:30<01:39,  1.20s/it, loss=0.3906, batch_acc=0.9688, running_acc=0.9301, grad=18.5385]Training epoch 22:  50%|████▉     | 81/163 [01:31<01:30,  1.10s/it, loss=0.3906, batch_acc=0.9688, running_acc=0.9301, grad=18.5385]Training epoch 22:  50%|████▉     | 81/163 [01:31<01:30,  1.10s/it, loss=0.4764, batch_acc=0.9688, running_acc=0.9306, grad=24.0672]Training epoch 22:  50%|█████     | 82/163 [01:32<01:23,  1.03s/it, loss=0.4764, batch_acc=0.9688, running_acc=0.9306, grad=24.0672]Training epoch 22:  50%|█████     | 82/163 [01:32<01:23,  1.03s/it, loss=0.4656, batch_acc=1.0000, running_acc=0.9314, grad=23.7958]Training epoch 22:  51%|█████     | 83/163 [01:33<01:18,  1.01it/s, loss=0.4656, batch_acc=1.0000, running_acc=0.9314, grad=23.7958]Training epoch 22:  51%|█████     | 83/163 [01:33<01:18,  1.01it/s, loss=0.5194, batch_acc=0.9375, running_acc=0.9315, grad=19.2580]Training epoch 22:  52%|█████▏    | 84/163 [01:35<01:31,  1.16s/it, loss=0.5194, batch_acc=0.9375, running_acc=0.9315, grad=19.2580]Training epoch 22:  52%|█████▏    | 84/163 [01:35<01:31,  1.16s/it, loss=0.5756, batch_acc=0.8125, running_acc=0.9301, grad=26.2964]Training epoch 22:  52%|█████▏    | 85/163 [01:36<01:23,  1.07s/it, loss=0.5756, batch_acc=0.8125, running_acc=0.9301, grad=26.2964]Training epoch 22:  52%|█████▏    | 85/163 [01:36<01:23,  1.07s/it, loss=0.4996, batch_acc=0.9375, running_acc=0.9301, grad=23.0485]Training epoch 22:  53%|█████▎    | 86/163 [01:36<01:18,  1.02s/it, loss=0.4996, batch_acc=0.9375, running_acc=0.9301, grad=23.0485]Training epoch 22:  53%|█████▎    | 86/163 [01:36<01:18,  1.02s/it, loss=0.5866, batch_acc=0.9375, running_acc=0.9302, grad=26.7545]Training epoch 22:  53%|█████▎    | 87/163 [01:37<01:14,  1.03it/s, loss=0.5866, batch_acc=0.9375, running_acc=0.9302, grad=26.7545]Training epoch 22:  53%|█████▎    | 87/163 [01:37<01:14,  1.03it/s, loss=0.4247, batch_acc=0.9375, running_acc=0.9303, grad=15.7077]Training epoch 22:  54%|█████▍    | 88/163 [01:39<01:22,  1.10s/it, loss=0.4247, batch_acc=0.9375, running_acc=0.9303, grad=15.7077]Training epoch 22:  54%|█████▍    | 88/163 [01:39<01:22,  1.10s/it, loss=0.6870, batch_acc=0.8750, running_acc=0.9297, grad=26.2515]Training epoch 22:  55%|█████▍    | 89/163 [01:40<01:16,  1.03s/it, loss=0.6870, batch_acc=0.8750, running_acc=0.9297, grad=26.2515]Training epoch 22:  55%|█████▍    | 89/163 [01:40<01:16,  1.03s/it, loss=0.2828, batch_acc=0.9688, running_acc=0.9301, grad=14.3385]Training epoch 22:  55%|█████▌    | 90/163 [01:40<01:11,  1.02it/s, loss=0.2828, batch_acc=0.9688, running_acc=0.9301, grad=14.3385]Training epoch 22:  55%|█████▌    | 90/163 [01:40<01:11,  1.02it/s, loss=0.3931, batch_acc=0.9375, running_acc=0.9302, grad=17.7418]Training epoch 22:  56%|█████▌    | 91/163 [01:41<01:08,  1.05it/s, loss=0.3931, batch_acc=0.9375, running_acc=0.9302, grad=17.7418]Training epoch 22:  56%|█████▌    | 91/163 [01:41<01:08,  1.05it/s, loss=0.4762, batch_acc=0.9375, running_acc=0.9303, grad=23.2836]Training epoch 22:  56%|█████▋    | 92/163 [01:43<01:21,  1.15s/it, loss=0.4762, batch_acc=0.9375, running_acc=0.9303, grad=23.2836]Training epoch 22:  56%|█████▋    | 92/163 [01:43<01:21,  1.15s/it, loss=0.4329, batch_acc=0.9375, running_acc=0.9304, grad=24.8509]Training epoch 22:  57%|█████▋    | 93/163 [01:44<01:14,  1.06s/it, loss=0.4329, batch_acc=0.9375, running_acc=0.9304, grad=24.8509]Training epoch 22:  57%|█████▋    | 93/163 [01:44<01:14,  1.06s/it, loss=0.3938, batch_acc=0.9062, running_acc=0.9301, grad=14.8864]Training epoch 22:  58%|█████▊    | 94/163 [01:45<01:09,  1.01s/it, loss=0.3938, batch_acc=0.9062, running_acc=0.9301, grad=14.8864]Training epoch 22:  58%|█████▊    | 94/163 [01:45<01:09,  1.01s/it, loss=0.4808, batch_acc=0.9375, running_acc=0.9302, grad=26.7865]Training epoch 22:  58%|█████▊    | 95/163 [01:46<01:05,  1.03it/s, loss=0.4808, batch_acc=0.9375, running_acc=0.9302, grad=26.7865]Training epoch 22:  58%|█████▊    | 95/163 [01:46<01:05,  1.03it/s, loss=0.4015, batch_acc=1.0000, running_acc=0.9309, grad=29.9075]Training epoch 22:  59%|█████▉    | 96/163 [01:47<01:10,  1.06s/it, loss=0.4015, batch_acc=1.0000, running_acc=0.9309, grad=29.9075]Training epoch 22:  59%|█████▉    | 96/163 [01:47<01:10,  1.06s/it, loss=0.4242, batch_acc=0.9375, running_acc=0.9310, grad=18.5462]Training epoch 22:  60%|█████▉    | 97/163 [01:48<01:06,  1.00s/it, loss=0.4242, batch_acc=0.9375, running_acc=0.9310, grad=18.5462]Training epoch 22:  60%|█████▉    | 97/163 [01:48<01:06,  1.00s/it, loss=0.4131, batch_acc=0.9062, running_acc=0.9307, grad=23.2955]Training epoch 22:  60%|██████    | 98/163 [01:49<01:02,  1.04it/s, loss=0.4131, batch_acc=0.9062, running_acc=0.9307, grad=23.2955]Training epoch 22:  60%|██████    | 98/163 [01:49<01:02,  1.04it/s, loss=0.2948, batch_acc=1.0000, running_acc=0.9314, grad=23.2798]Training epoch 22:  61%|██████    | 99/163 [01:49<01:00,  1.06it/s, loss=0.2948, batch_acc=1.0000, running_acc=0.9314, grad=23.2798]Training epoch 22:  61%|██████    | 99/163 [01:49<01:00,  1.06it/s, loss=0.3779, batch_acc=0.9375, running_acc=0.9315, grad=18.7869]Training epoch 22:  61%|██████▏   | 100/163 [01:51<01:08,  1.09s/it, loss=0.3779, batch_acc=0.9375, running_acc=0.9315, grad=18.7869]Training epoch 22:  61%|██████▏   | 100/163 [01:51<01:08,  1.09s/it, loss=0.4819, batch_acc=0.9062, running_acc=0.9313, grad=19.1234]Training epoch 22:  62%|██████▏   | 101/163 [01:52<01:03,  1.03s/it, loss=0.4819, batch_acc=0.9062, running_acc=0.9313, grad=19.1234]Training epoch 22:  62%|██████▏   | 101/163 [01:52<01:03,  1.03s/it, loss=0.5334, batch_acc=0.8438, running_acc=0.9304, grad=21.0857]Training epoch 22:  63%|██████▎   | 102/163 [01:53<01:00,  1.02it/s, loss=0.5334, batch_acc=0.8438, running_acc=0.9304, grad=21.0857]Training epoch 22:  63%|██████▎   | 102/163 [01:53<01:00,  1.02it/s, loss=0.4034, batch_acc=0.9688, running_acc=0.9308, grad=16.7224]Training epoch 22:  63%|██████▎   | 103/163 [01:53<00:57,  1.05it/s, loss=0.4034, batch_acc=0.9688, running_acc=0.9308, grad=16.7224]Training epoch 22:  63%|██████▎   | 103/163 [01:53<00:57,  1.05it/s, loss=0.3040, batch_acc=1.0000, running_acc=0.9314, grad=12.9688]Training epoch 22:  64%|██████▍   | 104/163 [01:55<01:10,  1.19s/it, loss=0.3040, batch_acc=1.0000, running_acc=0.9314, grad=12.9688]Training epoch 22:  64%|██████▍   | 104/163 [01:55<01:10,  1.19s/it, loss=0.4151, batch_acc=0.9375, running_acc=0.9315, grad=19.1239]Training epoch 22:  64%|██████▍   | 105/163 [01:56<01:03,  1.09s/it, loss=0.4151, batch_acc=0.9375, running_acc=0.9315, grad=19.1239]Training epoch 22:  64%|██████▍   | 105/163 [01:56<01:03,  1.09s/it, loss=0.4628, batch_acc=0.9062, running_acc=0.9313, grad=19.9695]Training epoch 22:  65%|██████▌   | 106/163 [01:57<00:58,  1.03s/it, loss=0.4628, batch_acc=0.9062, running_acc=0.9313, grad=19.9695]Training epoch 22:  65%|██████▌   | 106/163 [01:57<00:58,  1.03s/it, loss=0.5384, batch_acc=0.8750, running_acc=0.9307, grad=17.9971]Training epoch 22:  66%|██████▌   | 107/163 [01:58<00:55,  1.02it/s, loss=0.5384, batch_acc=0.8750, running_acc=0.9307, grad=17.9971]Training epoch 22:  66%|██████▌   | 107/163 [01:58<00:55,  1.02it/s, loss=0.3023, batch_acc=0.9688, running_acc=0.9311, grad=15.0782]Training epoch 22:  66%|██████▋   | 108/163 [01:59<01:02,  1.13s/it, loss=0.3023, batch_acc=0.9688, running_acc=0.9311, grad=15.0782]Training epoch 22:  66%|██████▋   | 108/163 [01:59<01:02,  1.13s/it, loss=0.5912, batch_acc=0.8750, running_acc=0.9306, grad=31.5406]Training epoch 22:  67%|██████▋   | 109/163 [02:00<00:57,  1.06s/it, loss=0.5912, batch_acc=0.8750, running_acc=0.9306, grad=31.5406]Training epoch 22:  67%|██████▋   | 109/163 [02:00<00:57,  1.06s/it, loss=0.4731, batch_acc=0.9688, running_acc=0.9309, grad=16.5877]Training epoch 22:  67%|██████▋   | 110/163 [02:01<00:53,  1.00s/it, loss=0.4731, batch_acc=0.9688, running_acc=0.9309, grad=16.5877]Training epoch 22:  67%|██████▋   | 110/163 [02:01<00:53,  1.00s/it, loss=0.4663, batch_acc=0.9062, running_acc=0.9307, grad=18.3665]Training epoch 22:  68%|██████▊   | 111/163 [02:02<00:50,  1.04it/s, loss=0.4663, batch_acc=0.9062, running_acc=0.9307, grad=18.3665]Training epoch 22:  68%|██████▊   | 111/163 [02:02<00:50,  1.04it/s, loss=0.6817, batch_acc=0.8438, running_acc=0.9299, grad=21.3382]Training epoch 22:  69%|██████▊   | 112/163 [02:04<01:11,  1.40s/it, loss=0.6817, batch_acc=0.8438, running_acc=0.9299, grad=21.3382]Training epoch 22:  69%|██████▊   | 112/163 [02:04<01:11,  1.40s/it, loss=0.6270, batch_acc=0.8750, running_acc=0.9294, grad=22.6026]Training epoch 22:  69%|██████▉   | 113/163 [02:05<01:02,  1.24s/it, loss=0.6270, batch_acc=0.8750, running_acc=0.9294, grad=22.6026]Training epoch 22:  69%|██████▉   | 113/163 [02:05<01:02,  1.24s/it, loss=0.5593, batch_acc=0.9375, running_acc=0.9295, grad=31.0494]Training epoch 22:  70%|██████▉   | 114/163 [02:06<00:55,  1.13s/it, loss=0.5593, batch_acc=0.9375, running_acc=0.9295, grad=31.0494]Training epoch 22:  70%|██████▉   | 114/163 [02:06<00:55,  1.13s/it, loss=0.5631, batch_acc=0.9375, running_acc=0.9296, grad=29.3491]Training epoch 22:  71%|███████   | 115/163 [02:07<00:50,  1.06s/it, loss=0.5631, batch_acc=0.9375, running_acc=0.9296, grad=29.3491]Training epoch 22:  71%|███████   | 115/163 [02:07<00:50,  1.06s/it, loss=0.5119, batch_acc=0.9375, running_acc=0.9296, grad=20.9574]Training epoch 22:  71%|███████   | 116/163 [02:09<00:57,  1.22s/it, loss=0.5119, batch_acc=0.9375, running_acc=0.9296, grad=20.9574]Training epoch 22:  71%|███████   | 116/163 [02:09<00:57,  1.22s/it, loss=0.6885, batch_acc=0.8438, running_acc=0.9289, grad=23.1006]Training epoch 22:  72%|███████▏  | 117/163 [02:09<00:51,  1.11s/it, loss=0.6885, batch_acc=0.8438, running_acc=0.9289, grad=23.1006]Training epoch 22:  72%|███████▏  | 117/163 [02:09<00:51,  1.11s/it, loss=0.6837, batch_acc=0.8125, running_acc=0.9279, grad=28.9015]Training epoch 22:  72%|███████▏  | 118/163 [02:10<00:46,  1.04s/it, loss=0.6837, batch_acc=0.8125, running_acc=0.9279, grad=28.9015]Training epoch 22:  72%|███████▏  | 118/163 [02:10<00:46,  1.04s/it, loss=0.4440, batch_acc=0.9375, running_acc=0.9280, grad=24.4827]Training epoch 22:  73%|███████▎  | 119/163 [02:11<00:43,  1.01it/s, loss=0.4440, batch_acc=0.9375, running_acc=0.9280, grad=24.4827]Training epoch 22:  73%|███████▎  | 119/163 [02:11<00:43,  1.01it/s, loss=0.3185, batch_acc=1.0000, running_acc=0.9286, grad=15.8032]Training epoch 22:  74%|███████▎  | 120/163 [02:14<00:59,  1.38s/it, loss=0.3185, batch_acc=1.0000, running_acc=0.9286, grad=15.8032]Training epoch 22:  74%|███████▎  | 120/163 [02:14<00:59,  1.38s/it, loss=0.4607, batch_acc=0.9375, running_acc=0.9286, grad=22.1671]Training epoch 22:  74%|███████▍  | 121/163 [02:14<00:51,  1.23s/it, loss=0.4607, batch_acc=0.9375, running_acc=0.9286, grad=22.1671]Training epoch 22:  74%|███████▍  | 121/163 [02:14<00:51,  1.23s/it, loss=0.4065, batch_acc=1.0000, running_acc=0.9292, grad=17.8761]Training epoch 22:  75%|███████▍  | 122/163 [02:15<00:46,  1.12s/it, loss=0.4065, batch_acc=1.0000, running_acc=0.9292, grad=17.8761]Training epoch 22:  75%|███████▍  | 122/163 [02:15<00:46,  1.12s/it, loss=0.4921, batch_acc=0.9062, running_acc=0.9290, grad=24.3443]Training epoch 22:  75%|███████▌  | 123/163 [02:16<00:41,  1.05s/it, loss=0.4921, batch_acc=0.9062, running_acc=0.9290, grad=24.3443]Training epoch 22:  75%|███████▌  | 123/163 [02:16<00:41,  1.05s/it, loss=0.4625, batch_acc=0.9688, running_acc=0.9294, grad=23.4368]Training epoch 22:  76%|███████▌  | 124/163 [02:18<00:50,  1.28s/it, loss=0.4625, batch_acc=0.9688, running_acc=0.9294, grad=23.4368]Training epoch 22:  76%|███████▌  | 124/163 [02:18<00:50,  1.28s/it, loss=0.6067, batch_acc=0.8750, running_acc=0.9289, grad=22.9355]Training epoch 22:  77%|███████▋  | 125/163 [02:19<00:44,  1.16s/it, loss=0.6067, batch_acc=0.8750, running_acc=0.9289, grad=22.9355]Training epoch 22:  77%|███████▋  | 125/163 [02:19<00:44,  1.16s/it, loss=0.3262, batch_acc=1.0000, running_acc=0.9295, grad=18.6438]Training epoch 22:  77%|███████▋  | 126/163 [02:20<00:39,  1.08s/it, loss=0.3262, batch_acc=1.0000, running_acc=0.9295, grad=18.6438]Training epoch 22:  77%|███████▋  | 126/163 [02:20<00:39,  1.08s/it, loss=0.5245, batch_acc=0.9062, running_acc=0.9293, grad=26.9555]Training epoch 22:  78%|███████▊  | 127/163 [02:21<00:36,  1.02s/it, loss=0.5245, batch_acc=0.9062, running_acc=0.9293, grad=26.9555]Training epoch 22:  78%|███████▊  | 127/163 [02:21<00:36,  1.02s/it, loss=0.4097, batch_acc=0.9062, running_acc=0.9291, grad=20.7418]Training epoch 22:  79%|███████▊  | 128/163 [02:22<00:40,  1.15s/it, loss=0.4097, batch_acc=0.9062, running_acc=0.9291, grad=20.7418]Training epoch 22:  79%|███████▊  | 128/163 [02:22<00:40,  1.15s/it, loss=0.4913, batch_acc=0.9375, running_acc=0.9292, grad=16.6861]Training epoch 22:  79%|███████▉  | 129/163 [02:23<00:36,  1.07s/it, loss=0.4913, batch_acc=0.9375, running_acc=0.9292, grad=16.6861]Training epoch 22:  79%|███████▉  | 129/163 [02:23<00:36,  1.07s/it, loss=0.5206, batch_acc=0.9688, running_acc=0.9295, grad=22.0861]Training epoch 22:  80%|███████▉  | 130/163 [02:24<00:33,  1.01s/it, loss=0.5206, batch_acc=0.9688, running_acc=0.9295, grad=22.0861]Training epoch 22:  80%|███████▉  | 130/163 [02:24<00:33,  1.01s/it, loss=0.4065, batch_acc=0.9375, running_acc=0.9296, grad=24.0141]Training epoch 22:  80%|████████  | 131/163 [02:25<00:31,  1.03it/s, loss=0.4065, batch_acc=0.9375, running_acc=0.9296, grad=24.0141]Training epoch 22:  80%|████████  | 131/163 [02:25<00:31,  1.03it/s, loss=0.5149, batch_acc=0.9062, running_acc=0.9294, grad=29.6724]Training epoch 22:  81%|████████  | 132/163 [02:26<00:30,  1.02it/s, loss=0.5149, batch_acc=0.9062, running_acc=0.9294, grad=29.6724]Training epoch 22:  81%|████████  | 132/163 [02:26<00:30,  1.02it/s, loss=0.3056, batch_acc=1.0000, running_acc=0.9299, grad=15.1364]Training epoch 22:  82%|████████▏ | 133/163 [02:27<00:28,  1.06it/s, loss=0.3056, batch_acc=1.0000, running_acc=0.9299, grad=15.1364]Training epoch 22:  82%|████████▏ | 133/163 [02:27<00:28,  1.06it/s, loss=0.5558, batch_acc=0.9062, running_acc=0.9297, grad=22.5805]Training epoch 22:  82%|████████▏ | 134/163 [02:27<00:26,  1.08it/s, loss=0.5558, batch_acc=0.9062, running_acc=0.9297, grad=22.5805]Training epoch 22:  82%|████████▏ | 134/163 [02:27<00:26,  1.08it/s, loss=0.7177, batch_acc=0.8438, running_acc=0.9291, grad=34.5183]Training epoch 22:  83%|████████▎ | 135/163 [02:28<00:25,  1.10it/s, loss=0.7177, batch_acc=0.8438, running_acc=0.9291, grad=34.5183]Training epoch 22:  83%|████████▎ | 135/163 [02:28<00:25,  1.10it/s, loss=0.4593, batch_acc=0.9375, running_acc=0.9292, grad=24.4089]Training epoch 22:  83%|████████▎ | 136/163 [02:30<00:33,  1.23s/it, loss=0.4593, batch_acc=0.9375, running_acc=0.9292, grad=24.4089]Training epoch 22:  83%|████████▎ | 136/163 [02:30<00:33,  1.23s/it, loss=0.4065, batch_acc=0.9688, running_acc=0.9295, grad=19.4980]Training epoch 22:  84%|████████▍ | 137/163 [02:31<00:29,  1.13s/it, loss=0.4065, batch_acc=0.9688, running_acc=0.9295, grad=19.4980]Training epoch 22:  84%|████████▍ | 137/163 [02:31<00:29,  1.13s/it, loss=0.5946, batch_acc=0.8438, running_acc=0.9288, grad=27.0586]Training epoch 22:  85%|████████▍ | 138/163 [02:32<00:26,  1.05s/it, loss=0.5946, batch_acc=0.8438, running_acc=0.9288, grad=27.0586]Training epoch 22:  85%|████████▍ | 138/163 [02:32<00:26,  1.05s/it, loss=0.4925, batch_acc=0.9375, running_acc=0.9289, grad=22.8204]Training epoch 22:  85%|████████▌ | 139/163 [02:33<00:23,  1.00it/s, loss=0.4925, batch_acc=0.9375, running_acc=0.9289, grad=22.8204]Training epoch 22:  85%|████████▌ | 139/163 [02:33<00:23,  1.00it/s, loss=0.4338, batch_acc=0.9062, running_acc=0.9287, grad=22.3030]Training epoch 22:  86%|████████▌ | 140/163 [02:35<00:29,  1.29s/it, loss=0.4338, batch_acc=0.9062, running_acc=0.9287, grad=22.3030]Training epoch 22:  86%|████████▌ | 140/163 [02:35<00:29,  1.29s/it, loss=0.5704, batch_acc=0.9375, running_acc=0.9288, grad=20.6252]Training epoch 22:  87%|████████▋ | 141/163 [02:36<00:25,  1.16s/it, loss=0.5704, batch_acc=0.9375, running_acc=0.9288, grad=20.6252]Training epoch 22:  87%|████████▋ | 141/163 [02:36<00:25,  1.16s/it, loss=0.4517, batch_acc=0.9375, running_acc=0.9289, grad=19.5740]Training epoch 22:  87%|████████▋ | 142/163 [02:37<00:22,  1.08s/it, loss=0.4517, batch_acc=0.9375, running_acc=0.9289, grad=19.5740]Training epoch 22:  87%|████████▋ | 142/163 [02:37<00:22,  1.08s/it, loss=0.6303, batch_acc=0.8750, running_acc=0.9285, grad=28.1012]Training epoch 22:  88%|████████▊ | 143/163 [02:38<00:20,  1.02s/it, loss=0.6303, batch_acc=0.8750, running_acc=0.9285, grad=28.1012]Training epoch 22:  88%|████████▊ | 143/163 [02:38<00:20,  1.02s/it, loss=0.3208, batch_acc=0.9688, running_acc=0.9288, grad=17.4846]Training epoch 22:  88%|████████▊ | 144/163 [02:39<00:19,  1.05s/it, loss=0.3208, batch_acc=0.9688, running_acc=0.9288, grad=17.4846]Training epoch 22:  88%|████████▊ | 144/163 [02:39<00:19,  1.05s/it, loss=0.3972, batch_acc=1.0000, running_acc=0.9293, grad=21.5898]Training epoch 22:  89%|████████▉ | 145/163 [02:40<00:17,  1.00it/s, loss=0.3972, batch_acc=1.0000, running_acc=0.9293, grad=21.5898]Training epoch 22:  89%|████████▉ | 145/163 [02:40<00:17,  1.00it/s, loss=0.4911, batch_acc=0.9375, running_acc=0.9293, grad=19.2722]Training epoch 22:  90%|████████▉ | 146/163 [02:40<00:16,  1.04it/s, loss=0.4911, batch_acc=0.9375, running_acc=0.9293, grad=19.2722]Training epoch 22:  90%|████████▉ | 146/163 [02:40<00:16,  1.04it/s, loss=0.3800, batch_acc=0.9688, running_acc=0.9296, grad=13.6923]Training epoch 22:  90%|█████████ | 147/163 [02:41<00:14,  1.07it/s, loss=0.3800, batch_acc=0.9688, running_acc=0.9296, grad=13.6923]Training epoch 22:  90%|█████████ | 147/163 [02:41<00:14,  1.07it/s, loss=0.5562, batch_acc=0.8750, running_acc=0.9292, grad=22.1374]Training epoch 22:  91%|█████████ | 148/163 [02:43<00:15,  1.05s/it, loss=0.5562, batch_acc=0.8750, running_acc=0.9292, grad=22.1374]Training epoch 22:  91%|█████████ | 148/163 [02:43<00:15,  1.05s/it, loss=0.4205, batch_acc=1.0000, running_acc=0.9297, grad=23.6818]Training epoch 22:  91%|█████████▏| 149/163 [02:43<00:13,  1.01it/s, loss=0.4205, batch_acc=1.0000, running_acc=0.9297, grad=23.6818]Training epoch 22:  91%|█████████▏| 149/163 [02:43<00:13,  1.01it/s, loss=0.5155, batch_acc=0.8750, running_acc=0.9293, grad=18.8091]Training epoch 22:  92%|█████████▏| 150/163 [02:44<00:12,  1.04it/s, loss=0.5155, batch_acc=0.8750, running_acc=0.9293, grad=18.8091]Training epoch 22:  92%|█████████▏| 150/163 [02:44<00:12,  1.04it/s, loss=0.5670, batch_acc=0.9062, running_acc=0.9292, grad=27.1480]Training epoch 22:  93%|█████████▎| 151/163 [02:45<00:11,  1.07it/s, loss=0.5670, batch_acc=0.9062, running_acc=0.9292, grad=27.1480]Training epoch 22:  93%|█████████▎| 151/163 [02:45<00:11,  1.07it/s, loss=0.5489, batch_acc=0.8750, running_acc=0.9288, grad=33.7795]Training epoch 22:  93%|█████████▎| 152/163 [02:46<00:11,  1.03s/it, loss=0.5489, batch_acc=0.8750, running_acc=0.9288, grad=33.7795]Training epoch 22:  93%|█████████▎| 152/163 [02:46<00:11,  1.03s/it, loss=0.5754, batch_acc=0.8750, running_acc=0.9285, grad=21.7162]Training epoch 22:  94%|█████████▍| 153/163 [02:47<00:09,  1.02it/s, loss=0.5754, batch_acc=0.8750, running_acc=0.9285, grad=21.7162]Training epoch 22:  94%|█████████▍| 153/163 [02:47<00:09,  1.02it/s, loss=0.4171, batch_acc=0.9688, running_acc=0.9287, grad=19.5659]Training epoch 22:  94%|█████████▍| 154/163 [02:48<00:08,  1.05it/s, loss=0.4171, batch_acc=0.9688, running_acc=0.9287, grad=19.5659]Training epoch 22:  94%|█████████▍| 154/163 [02:48<00:08,  1.05it/s, loss=0.5456, batch_acc=0.8750, running_acc=0.9284, grad=20.2674]Training epoch 22:  95%|█████████▌| 155/163 [02:49<00:07,  1.08it/s, loss=0.5456, batch_acc=0.8750, running_acc=0.9284, grad=20.2674]Training epoch 22:  95%|█████████▌| 155/163 [02:49<00:07,  1.08it/s, loss=0.5764, batch_acc=0.9062, running_acc=0.9282, grad=28.0197]Training epoch 22:  96%|█████████▌| 156/163 [02:50<00:07,  1.02s/it, loss=0.5764, batch_acc=0.9062, running_acc=0.9282, grad=28.0197]Training epoch 22:  96%|█████████▌| 156/163 [02:50<00:07,  1.02s/it, loss=0.4328, batch_acc=0.9688, running_acc=0.9285, grad=22.1093]Training epoch 22:  96%|█████████▋| 157/163 [02:51<00:05,  1.02it/s, loss=0.4328, batch_acc=0.9688, running_acc=0.9285, grad=22.1093]Training epoch 22:  96%|█████████▋| 157/163 [02:51<00:05,  1.02it/s, loss=0.4008, batch_acc=0.9688, running_acc=0.9287, grad=21.2716]Training epoch 22:  97%|█████████▋| 158/163 [02:52<00:04,  1.05it/s, loss=0.4008, batch_acc=0.9688, running_acc=0.9287, grad=21.2716]Training epoch 22:  97%|█████████▋| 158/163 [02:52<00:04,  1.05it/s, loss=0.3889, batch_acc=0.9375, running_acc=0.9288, grad=14.1046]Training epoch 22:  98%|█████████▊| 159/163 [02:53<00:03,  1.08it/s, loss=0.3889, batch_acc=0.9375, running_acc=0.9288, grad=14.1046]Training epoch 22:  98%|█████████▊| 159/163 [02:53<00:03,  1.08it/s, loss=0.5224, batch_acc=0.9062, running_acc=0.9287, grad=22.5788]Training epoch 22:  98%|█████████▊| 160/163 [02:55<00:03,  1.11s/it, loss=0.5224, batch_acc=0.9062, running_acc=0.9287, grad=22.5788]Training epoch 22:  98%|█████████▊| 160/163 [02:55<00:03,  1.11s/it, loss=0.4222, batch_acc=0.9375, running_acc=0.9287, grad=24.1478]Training epoch 22:  99%|█████████▉| 161/163 [02:55<00:02,  1.04s/it, loss=0.4222, batch_acc=0.9375, running_acc=0.9287, grad=24.1478]Training epoch 22:  99%|█████████▉| 161/163 [02:55<00:02,  1.04s/it, loss=0.6676, batch_acc=0.8438, running_acc=0.9282, grad=34.3781]Training epoch 22:  99%|█████████▉| 162/163 [02:56<00:00,  1.01it/s, loss=0.6676, batch_acc=0.8438, running_acc=0.9282, grad=34.3781]Training epoch 22:  99%|█████████▉| 162/163 [02:56<00:00,  1.01it/s, loss=0.5446, batch_acc=0.9375, running_acc=0.9282, grad=26.1606]Training epoch 22: 100%|██████████| 163/163 [02:57<00:00,  1.13it/s, loss=0.5446, batch_acc=0.9375, running_acc=0.9282, grad=26.1606]Training epoch 22: 100%|██████████| 163/163 [02:57<00:00,  1.13it/s, loss=0.4451, batch_acc=0.9048, running_acc=0.9281, grad=31.9298]Training epoch 22: 100%|██████████| 163/163 [02:57<00:00,  1.09s/it, loss=0.4451, batch_acc=0.9048, running_acc=0.9281, grad=31.9298]
Evaluation epoch 22:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 22:   4%|▎         | 1/28 [00:05<02:19,  5.16s/it]Evaluation epoch 22:   4%|▎         | 1/28 [00:05<02:19,  5.16s/it, loss=0.5949, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 22:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=0.5949, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 22:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=0.5609, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 22:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=0.5609, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 22:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=0.6513, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 22:  14%|█▍        | 4/28 [00:10<01:03,  2.64s/it, loss=0.6513, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 22:  14%|█▍        | 4/28 [00:10<01:03,  2.64s/it, loss=0.7801, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 22:  18%|█▊        | 5/28 [00:10<00:41,  1.79s/it, loss=0.7801, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 22:  18%|█▊        | 5/28 [00:10<00:41,  1.79s/it, loss=1.6425, batch_acc=0.5938, running_acc=0.8750]Evaluation epoch 22:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=1.6425, batch_acc=0.5938, running_acc=0.8750]Evaluation epoch 22:  21%|██▏       | 6/28 [00:10<00:27,  1.27s/it, loss=0.8364, batch_acc=0.8125, running_acc=0.8646]Evaluation epoch 22:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=0.8364, batch_acc=0.8125, running_acc=0.8646]Evaluation epoch 22:  25%|██▌       | 7/28 [00:11<00:19,  1.06it/s, loss=0.9999, batch_acc=0.7812, running_acc=0.8527]Evaluation epoch 22:  29%|██▊       | 8/28 [00:14<00:34,  1.72s/it, loss=0.9999, batch_acc=0.7812, running_acc=0.8527]Evaluation epoch 22:  29%|██▊       | 8/28 [00:14<00:34,  1.72s/it, loss=0.6340, batch_acc=0.8125, running_acc=0.8477]Evaluation epoch 22:  32%|███▏      | 9/28 [00:14<00:24,  1.27s/it, loss=0.6340, batch_acc=0.8125, running_acc=0.8477]Evaluation epoch 22:  32%|███▏      | 9/28 [00:14<00:24,  1.27s/it, loss=0.7167, batch_acc=0.9062, running_acc=0.8542]Evaluation epoch 22:  36%|███▌      | 10/28 [00:15<00:17,  1.04it/s, loss=0.7167, batch_acc=0.9062, running_acc=0.8542]Evaluation epoch 22:  36%|███▌      | 10/28 [00:15<00:17,  1.04it/s, loss=0.5807, batch_acc=0.9062, running_acc=0.8594]Evaluation epoch 22:  39%|███▉      | 11/28 [00:15<00:12,  1.34it/s, loss=0.5807, batch_acc=0.9062, running_acc=0.8594]Evaluation epoch 22:  39%|███▉      | 11/28 [00:15<00:12,  1.34it/s, loss=0.6649, batch_acc=0.8125, running_acc=0.8551]Evaluation epoch 22:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=0.6649, batch_acc=0.8125, running_acc=0.8551]Evaluation epoch 22:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=1.2781, batch_acc=0.6250, running_acc=0.8359]Evaluation epoch 22:  46%|████▋     | 13/28 [00:21<00:24,  1.64s/it, loss=1.2781, batch_acc=0.6250, running_acc=0.8359]Evaluation epoch 22:  46%|████▋     | 13/28 [00:21<00:24,  1.64s/it, loss=0.5177, batch_acc=0.9062, running_acc=0.8413]Evaluation epoch 22:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=0.5177, batch_acc=0.9062, running_acc=0.8413]Evaluation epoch 22:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=1.2997, batch_acc=0.7500, running_acc=0.8348]Evaluation epoch 22:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.2997, batch_acc=0.7500, running_acc=0.8348]Evaluation epoch 22:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=1.7387, batch_acc=0.5312, running_acc=0.8146]Evaluation epoch 22:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.7387, batch_acc=0.5312, running_acc=0.8146]Evaluation epoch 22:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.0316, batch_acc=0.6562, running_acc=0.8047]Evaluation epoch 22:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=1.0316, batch_acc=0.6562, running_acc=0.8047]Evaluation epoch 22:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.7554, batch_acc=0.7188, running_acc=0.7996]Evaluation epoch 22:  64%|██████▍   | 18/28 [00:25<00:08,  1.14it/s, loss=0.7554, batch_acc=0.7188, running_acc=0.7996]Evaluation epoch 22:  64%|██████▍   | 18/28 [00:25<00:08,  1.14it/s, loss=0.9348, batch_acc=0.6875, running_acc=0.7934]Evaluation epoch 22:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=0.9348, batch_acc=0.6875, running_acc=0.7934]Evaluation epoch 22:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=0.9634, batch_acc=0.6875, running_acc=0.7878]Evaluation epoch 22:  71%|███████▏  | 20/28 [00:28<00:10,  1.35s/it, loss=0.9634, batch_acc=0.6875, running_acc=0.7878]Evaluation epoch 22:  71%|███████▏  | 20/28 [00:28<00:10,  1.35s/it, loss=0.7201, batch_acc=0.8125, running_acc=0.7891]Evaluation epoch 22:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=0.7201, batch_acc=0.8125, running_acc=0.7891]Evaluation epoch 22:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=0.7758, batch_acc=0.8438, running_acc=0.7917]Evaluation epoch 22:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=0.7758, batch_acc=0.8438, running_acc=0.7917]Evaluation epoch 22:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=1.1114, batch_acc=0.7500, running_acc=0.7898]Evaluation epoch 22:  82%|████████▏ | 23/28 [00:29<00:03,  1.57it/s, loss=1.1114, batch_acc=0.7500, running_acc=0.7898]Evaluation epoch 22:  82%|████████▏ | 23/28 [00:29<00:03,  1.57it/s, loss=1.2450, batch_acc=0.6875, running_acc=0.7853]Evaluation epoch 22:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=1.2450, batch_acc=0.6875, running_acc=0.7853]Evaluation epoch 22:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.5861, batch_acc=0.9062, running_acc=0.7904]Evaluation epoch 22:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.5861, batch_acc=0.9062, running_acc=0.7904]Evaluation epoch 22:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.2526, batch_acc=0.9688, running_acc=0.7975]Evaluation epoch 22:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.2526, batch_acc=0.9688, running_acc=0.7975]Evaluation epoch 22:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=1.0601, batch_acc=0.6875, running_acc=0.7933]Evaluation epoch 22:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=1.0601, batch_acc=0.6875, running_acc=0.7933]Evaluation epoch 22:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=1.3388, batch_acc=0.6250, running_acc=0.7870]Evaluation epoch 22: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=2.0186, batch_acc=0.3333, running_acc=0.7855]Evaluation epoch 22: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=2.0186, batch_acc=0.3333, running_acc=0.7855]
Training epoch 23:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 23:   1%|          | 1/163 [00:05<15:25,  5.71s/it]Training epoch 23:   1%|          | 1/163 [00:05<15:25,  5.71s/it, loss=0.4070, batch_acc=0.9375, running_acc=0.9375, grad=17.3087]Training epoch 23:   1%|          | 2/163 [00:06<07:42,  2.87s/it, loss=0.4070, batch_acc=0.9375, running_acc=0.9375, grad=17.3087]Training epoch 23:   1%|          | 2/163 [00:06<07:42,  2.87s/it, loss=0.3070, batch_acc=1.0000, running_acc=0.9688, grad=17.8056]Training epoch 23:   2%|▏         | 3/163 [00:07<05:13,  1.96s/it, loss=0.3070, batch_acc=1.0000, running_acc=0.9688, grad=17.8056]Training epoch 23:   2%|▏         | 3/163 [00:07<05:13,  1.96s/it, loss=0.4412, batch_acc=0.9375, running_acc=0.9583, grad=19.4080]Training epoch 23:   2%|▏         | 4/163 [00:09<05:46,  2.18s/it, loss=0.4412, batch_acc=0.9375, running_acc=0.9583, grad=19.4080]Training epoch 23:   2%|▏         | 4/163 [00:09<05:46,  2.18s/it, loss=0.5138, batch_acc=0.9062, running_acc=0.9453, grad=27.3929]Training epoch 23:   3%|▎         | 5/163 [00:10<04:30,  1.71s/it, loss=0.5138, batch_acc=0.9062, running_acc=0.9453, grad=27.3929]Training epoch 23:   3%|▎         | 5/163 [00:10<04:30,  1.71s/it, loss=0.4988, batch_acc=0.9688, running_acc=0.9500, grad=21.8501]Training epoch 23:   4%|▎         | 6/163 [00:11<03:44,  1.43s/it, loss=0.4988, batch_acc=0.9688, running_acc=0.9500, grad=21.8501]Training epoch 23:   4%|▎         | 6/163 [00:11<03:44,  1.43s/it, loss=0.4133, batch_acc=0.9062, running_acc=0.9427, grad=22.6566]Training epoch 23:   4%|▍         | 7/163 [00:12<03:14,  1.25s/it, loss=0.4133, batch_acc=0.9062, running_acc=0.9427, grad=22.6566]Training epoch 23:   4%|▍         | 7/163 [00:12<03:14,  1.25s/it, loss=0.4003, batch_acc=1.0000, running_acc=0.9509, grad=18.7047]Training epoch 23:   5%|▍         | 8/163 [00:14<03:46,  1.46s/it, loss=0.4003, batch_acc=1.0000, running_acc=0.9509, grad=18.7047]Training epoch 23:   5%|▍         | 8/163 [00:14<03:46,  1.46s/it, loss=0.4697, batch_acc=0.9688, running_acc=0.9531, grad=20.3341]Training epoch 23:   6%|▌         | 9/163 [00:15<03:17,  1.28s/it, loss=0.4697, batch_acc=0.9688, running_acc=0.9531, grad=20.3341]Training epoch 23:   6%|▌         | 9/163 [00:15<03:17,  1.28s/it, loss=0.4168, batch_acc=1.0000, running_acc=0.9583, grad=17.8391]Training epoch 23:   6%|▌         | 10/163 [00:16<02:56,  1.16s/it, loss=0.4168, batch_acc=1.0000, running_acc=0.9583, grad=17.8391]Training epoch 23:   6%|▌         | 10/163 [00:16<02:56,  1.16s/it, loss=0.5247, batch_acc=0.9062, running_acc=0.9531, grad=20.6313]Training epoch 23:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=0.5247, batch_acc=0.9062, running_acc=0.9531, grad=20.6313]Training epoch 23:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=0.4464, batch_acc=0.9688, running_acc=0.9545, grad=20.8682]Training epoch 23:   7%|▋         | 12/163 [00:19<03:29,  1.39s/it, loss=0.4464, batch_acc=0.9688, running_acc=0.9545, grad=20.8682]Training epoch 23:   7%|▋         | 12/163 [00:19<03:29,  1.39s/it, loss=0.3746, batch_acc=0.9688, running_acc=0.9557, grad=16.8581]Training epoch 23:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.3746, batch_acc=0.9688, running_acc=0.9557, grad=16.8581]Training epoch 23:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.4229, batch_acc=0.9375, running_acc=0.9543, grad=28.3280]Training epoch 23:   9%|▊         | 14/163 [00:21<02:47,  1.13s/it, loss=0.4229, batch_acc=0.9375, running_acc=0.9543, grad=28.3280]Training epoch 23:   9%|▊         | 14/163 [00:21<02:47,  1.13s/it, loss=0.4702, batch_acc=0.9062, running_acc=0.9509, grad=23.4812]Training epoch 23:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.4702, batch_acc=0.9062, running_acc=0.9509, grad=23.4812]Training epoch 23:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.3051, batch_acc=1.0000, running_acc=0.9542, grad=13.9711]Training epoch 23:  10%|▉         | 16/163 [00:23<02:36,  1.06s/it, loss=0.3051, batch_acc=1.0000, running_acc=0.9542, grad=13.9711]Training epoch 23:  10%|▉         | 16/163 [00:23<02:36,  1.06s/it, loss=0.6235, batch_acc=0.9062, running_acc=0.9512, grad=26.2797]Training epoch 23:  10%|█         | 17/163 [00:23<02:27,  1.01s/it, loss=0.6235, batch_acc=0.9062, running_acc=0.9512, grad=26.2797]Training epoch 23:  10%|█         | 17/163 [00:23<02:27,  1.01s/it, loss=0.4045, batch_acc=1.0000, running_acc=0.9540, grad=16.4961]Training epoch 23:  11%|█         | 18/163 [00:24<02:20,  1.03it/s, loss=0.4045, batch_acc=1.0000, running_acc=0.9540, grad=16.4961]Training epoch 23:  11%|█         | 18/163 [00:24<02:20,  1.03it/s, loss=0.5057, batch_acc=0.8125, running_acc=0.9462, grad=20.1999]Training epoch 23:  12%|█▏        | 19/163 [00:25<02:15,  1.06it/s, loss=0.5057, batch_acc=0.8125, running_acc=0.9462, grad=20.1999]Training epoch 23:  12%|█▏        | 19/163 [00:25<02:15,  1.06it/s, loss=0.3250, batch_acc=0.9688, running_acc=0.9474, grad=19.8253]Training epoch 23:  12%|█▏        | 20/163 [00:27<03:10,  1.33s/it, loss=0.3250, batch_acc=0.9688, running_acc=0.9474, grad=19.8253]Training epoch 23:  12%|█▏        | 20/163 [00:27<03:10,  1.33s/it, loss=0.3672, batch_acc=0.9375, running_acc=0.9469, grad=17.1428]Training epoch 23:  13%|█▎        | 21/163 [00:28<02:50,  1.20s/it, loss=0.3672, batch_acc=0.9375, running_acc=0.9469, grad=17.1428]Training epoch 23:  13%|█▎        | 21/163 [00:28<02:50,  1.20s/it, loss=0.3492, batch_acc=0.9688, running_acc=0.9479, grad=22.7524]Training epoch 23:  13%|█▎        | 22/163 [00:29<02:39,  1.13s/it, loss=0.3492, batch_acc=0.9688, running_acc=0.9479, grad=22.7524]Training epoch 23:  13%|█▎        | 22/163 [00:29<02:39,  1.13s/it, loss=0.5110, batch_acc=0.9688, running_acc=0.9489, grad=28.9365]Training epoch 23:  14%|█▍        | 23/163 [00:30<02:27,  1.05s/it, loss=0.5110, batch_acc=0.9688, running_acc=0.9489, grad=28.9365]Training epoch 23:  14%|█▍        | 23/163 [00:30<02:27,  1.05s/it, loss=0.4720, batch_acc=0.9688, running_acc=0.9497, grad=22.1355]Training epoch 23:  15%|█▍        | 24/163 [00:31<02:34,  1.11s/it, loss=0.4720, batch_acc=0.9688, running_acc=0.9497, grad=22.1355]Training epoch 23:  15%|█▍        | 24/163 [00:31<02:34,  1.11s/it, loss=0.4142, batch_acc=1.0000, running_acc=0.9518, grad=21.0389]Training epoch 23:  15%|█▌        | 25/163 [00:32<02:24,  1.04s/it, loss=0.4142, batch_acc=1.0000, running_acc=0.9518, grad=21.0389]Training epoch 23:  15%|█▌        | 25/163 [00:32<02:24,  1.04s/it, loss=0.4968, batch_acc=0.9375, running_acc=0.9513, grad=20.2159]Training epoch 23:  16%|█▌        | 26/163 [00:33<02:16,  1.00it/s, loss=0.4968, batch_acc=0.9375, running_acc=0.9513, grad=20.2159]Training epoch 23:  16%|█▌        | 26/163 [00:33<02:16,  1.00it/s, loss=0.5776, batch_acc=0.8750, running_acc=0.9483, grad=22.8944]Training epoch 23:  17%|█▋        | 27/163 [00:34<02:10,  1.04it/s, loss=0.5776, batch_acc=0.8750, running_acc=0.9483, grad=22.8944]Training epoch 23:  17%|█▋        | 27/163 [00:34<02:10,  1.04it/s, loss=0.4883, batch_acc=0.9062, running_acc=0.9468, grad=22.8272]Training epoch 23:  17%|█▋        | 28/163 [00:35<02:21,  1.05s/it, loss=0.4883, batch_acc=0.9062, running_acc=0.9468, grad=22.8272]Training epoch 23:  17%|█▋        | 28/163 [00:35<02:21,  1.05s/it, loss=0.4503, batch_acc=0.9062, running_acc=0.9453, grad=21.2765]Training epoch 23:  18%|█▊        | 29/163 [00:36<02:13,  1.00it/s, loss=0.4503, batch_acc=0.9062, running_acc=0.9453, grad=21.2765]Training epoch 23:  18%|█▊        | 29/163 [00:36<02:13,  1.00it/s, loss=0.4791, batch_acc=0.9688, running_acc=0.9461, grad=20.5710]Training epoch 23:  18%|█▊        | 30/163 [00:37<02:08,  1.03it/s, loss=0.4791, batch_acc=0.9688, running_acc=0.9461, grad=20.5710]Training epoch 23:  18%|█▊        | 30/163 [00:37<02:08,  1.03it/s, loss=0.5421, batch_acc=0.9062, running_acc=0.9448, grad=20.1335]Training epoch 23:  19%|█▉        | 31/163 [00:38<02:03,  1.06it/s, loss=0.5421, batch_acc=0.9062, running_acc=0.9448, grad=20.1335]Training epoch 23:  19%|█▉        | 31/163 [00:38<02:03,  1.06it/s, loss=0.3760, batch_acc=1.0000, running_acc=0.9466, grad=17.1285]Training epoch 23:  20%|█▉        | 32/163 [00:40<02:47,  1.28s/it, loss=0.3760, batch_acc=1.0000, running_acc=0.9466, grad=17.1285]Training epoch 23:  20%|█▉        | 32/163 [00:40<02:47,  1.28s/it, loss=0.4770, batch_acc=0.9062, running_acc=0.9453, grad=22.6225]Training epoch 23:  20%|██        | 33/163 [00:41<02:30,  1.16s/it, loss=0.4770, batch_acc=0.9062, running_acc=0.9453, grad=22.6225]Training epoch 23:  20%|██        | 33/163 [00:41<02:30,  1.16s/it, loss=0.4846, batch_acc=0.9688, running_acc=0.9460, grad=24.7769]Training epoch 23:  21%|██        | 34/163 [00:42<02:18,  1.07s/it, loss=0.4846, batch_acc=0.9688, running_acc=0.9460, grad=24.7769]Training epoch 23:  21%|██        | 34/163 [00:42<02:18,  1.07s/it, loss=0.4052, batch_acc=0.9688, running_acc=0.9467, grad=15.6389]Training epoch 23:  21%|██▏       | 35/163 [00:43<02:10,  1.02s/it, loss=0.4052, batch_acc=0.9688, running_acc=0.9467, grad=15.6389]Training epoch 23:  21%|██▏       | 35/163 [00:43<02:10,  1.02s/it, loss=0.5076, batch_acc=0.9062, running_acc=0.9455, grad=20.1156]Training epoch 23:  22%|██▏       | 36/163 [00:44<02:11,  1.03s/it, loss=0.5076, batch_acc=0.9062, running_acc=0.9455, grad=20.1156]Training epoch 23:  22%|██▏       | 36/163 [00:44<02:11,  1.03s/it, loss=0.4159, batch_acc=0.9375, running_acc=0.9453, grad=23.2226]Training epoch 23:  23%|██▎       | 37/163 [00:45<02:04,  1.01it/s, loss=0.4159, batch_acc=0.9375, running_acc=0.9453, grad=23.2226]Training epoch 23:  23%|██▎       | 37/163 [00:45<02:04,  1.01it/s, loss=0.5819, batch_acc=0.7812, running_acc=0.9409, grad=24.5632]Training epoch 23:  23%|██▎       | 38/163 [00:45<01:59,  1.05it/s, loss=0.5819, batch_acc=0.7812, running_acc=0.9409, grad=24.5632]Training epoch 23:  23%|██▎       | 38/163 [00:45<01:59,  1.05it/s, loss=0.3178, batch_acc=0.9688, running_acc=0.9416, grad=18.2320]Training epoch 23:  24%|██▍       | 39/163 [00:46<01:55,  1.07it/s, loss=0.3178, batch_acc=0.9688, running_acc=0.9416, grad=18.2320]Training epoch 23:  24%|██▍       | 39/163 [00:46<01:55,  1.07it/s, loss=0.5775, batch_acc=0.8750, running_acc=0.9399, grad=27.0863]Training epoch 23:  25%|██▍       | 40/163 [00:48<02:09,  1.05s/it, loss=0.5775, batch_acc=0.8750, running_acc=0.9399, grad=27.0863]Training epoch 23:  25%|██▍       | 40/163 [00:48<02:09,  1.05s/it, loss=0.6026, batch_acc=0.8438, running_acc=0.9375, grad=28.0928]Training epoch 23:  25%|██▌       | 41/163 [00:49<02:01,  1.00it/s, loss=0.6026, batch_acc=0.8438, running_acc=0.9375, grad=28.0928]Training epoch 23:  25%|██▌       | 41/163 [00:49<02:01,  1.00it/s, loss=0.3997, batch_acc=0.9688, running_acc=0.9383, grad=16.9945]Training epoch 23:  26%|██▌       | 42/163 [00:50<02:06,  1.04s/it, loss=0.3997, batch_acc=0.9688, running_acc=0.9383, grad=16.9945]Training epoch 23:  26%|██▌       | 42/163 [00:50<02:06,  1.04s/it, loss=0.4248, batch_acc=0.9375, running_acc=0.9382, grad=22.0850]Training epoch 23:  26%|██▋       | 43/163 [00:51<01:59,  1.01it/s, loss=0.4248, batch_acc=0.9375, running_acc=0.9382, grad=22.0850]Training epoch 23:  26%|██▋       | 43/163 [00:51<01:59,  1.01it/s, loss=0.5147, batch_acc=0.9062, running_acc=0.9375, grad=24.9292]Training epoch 23:  27%|██▋       | 44/163 [00:52<02:24,  1.22s/it, loss=0.5147, batch_acc=0.9062, running_acc=0.9375, grad=24.9292]Training epoch 23:  27%|██▋       | 44/163 [00:52<02:24,  1.22s/it, loss=0.6172, batch_acc=0.9062, running_acc=0.9368, grad=24.1037]Training epoch 23:  28%|██▊       | 45/163 [00:53<02:11,  1.12s/it, loss=0.6172, batch_acc=0.9062, running_acc=0.9368, grad=24.1037]Training epoch 23:  28%|██▊       | 45/163 [00:53<02:11,  1.12s/it, loss=0.3818, batch_acc=0.9688, running_acc=0.9375, grad=16.9226]Training epoch 23:  28%|██▊       | 46/163 [00:54<02:02,  1.05s/it, loss=0.3818, batch_acc=0.9688, running_acc=0.9375, grad=16.9226]Training epoch 23:  28%|██▊       | 46/163 [00:54<02:02,  1.05s/it, loss=0.5433, batch_acc=0.9375, running_acc=0.9375, grad=29.2183]Training epoch 23:  29%|██▉       | 47/163 [00:55<01:55,  1.00it/s, loss=0.5433, batch_acc=0.9375, running_acc=0.9375, grad=29.2183]Training epoch 23:  29%|██▉       | 47/163 [00:55<01:55,  1.00it/s, loss=0.3807, batch_acc=0.9688, running_acc=0.9382, grad=19.0454]Training epoch 23:  29%|██▉       | 48/163 [00:57<02:34,  1.34s/it, loss=0.3807, batch_acc=0.9688, running_acc=0.9382, grad=19.0454]Training epoch 23:  29%|██▉       | 48/163 [00:57<02:34,  1.34s/it, loss=0.5024, batch_acc=0.9062, running_acc=0.9375, grad=19.7548]Training epoch 23:  30%|███       | 49/163 [00:58<02:17,  1.20s/it, loss=0.5024, batch_acc=0.9062, running_acc=0.9375, grad=19.7548]Training epoch 23:  30%|███       | 49/163 [00:58<02:17,  1.20s/it, loss=0.4242, batch_acc=0.9375, running_acc=0.9375, grad=18.4535]Training epoch 23:  31%|███       | 50/163 [00:59<02:05,  1.11s/it, loss=0.4242, batch_acc=0.9375, running_acc=0.9375, grad=18.4535]Training epoch 23:  31%|███       | 50/163 [00:59<02:05,  1.11s/it, loss=0.4300, batch_acc=0.9375, running_acc=0.9375, grad=20.5860]Training epoch 23:  31%|███▏      | 51/163 [01:00<01:56,  1.04s/it, loss=0.4300, batch_acc=0.9375, running_acc=0.9375, grad=20.5860]Training epoch 23:  31%|███▏      | 51/163 [01:00<01:56,  1.04s/it, loss=0.3375, batch_acc=1.0000, running_acc=0.9387, grad=22.5006]Training epoch 23:  32%|███▏      | 52/163 [01:02<02:20,  1.27s/it, loss=0.3375, batch_acc=1.0000, running_acc=0.9387, grad=22.5006]Training epoch 23:  32%|███▏      | 52/163 [01:02<02:20,  1.27s/it, loss=0.3068, batch_acc=0.9688, running_acc=0.9393, grad=14.5482]Training epoch 23:  33%|███▎      | 53/163 [01:02<02:06,  1.15s/it, loss=0.3068, batch_acc=0.9688, running_acc=0.9393, grad=14.5482]Training epoch 23:  33%|███▎      | 53/163 [01:02<02:06,  1.15s/it, loss=0.2755, batch_acc=1.0000, running_acc=0.9404, grad=15.3916]Training epoch 23:  33%|███▎      | 54/163 [01:03<01:56,  1.07s/it, loss=0.2755, batch_acc=1.0000, running_acc=0.9404, grad=15.3916]Training epoch 23:  33%|███▎      | 54/163 [01:03<01:56,  1.07s/it, loss=0.3515, batch_acc=0.9375, running_acc=0.9404, grad=18.0516]Training epoch 23:  34%|███▎      | 55/163 [01:04<01:49,  1.01s/it, loss=0.3515, batch_acc=0.9375, running_acc=0.9404, grad=18.0516]Training epoch 23:  34%|███▎      | 55/163 [01:04<01:49,  1.01s/it, loss=0.5338, batch_acc=0.8750, running_acc=0.9392, grad=28.1057]Training epoch 23:  34%|███▍      | 56/163 [01:06<02:05,  1.18s/it, loss=0.5338, batch_acc=0.8750, running_acc=0.9392, grad=28.1057]Training epoch 23:  34%|███▍      | 56/163 [01:06<02:05,  1.18s/it, loss=0.3236, batch_acc=1.0000, running_acc=0.9403, grad=16.9428]Training epoch 23:  35%|███▍      | 57/163 [01:07<01:55,  1.09s/it, loss=0.3236, batch_acc=1.0000, running_acc=0.9403, grad=16.9428]Training epoch 23:  35%|███▍      | 57/163 [01:07<01:55,  1.09s/it, loss=0.4806, batch_acc=0.9375, running_acc=0.9402, grad=22.2422]Training epoch 23:  36%|███▌      | 58/163 [01:08<01:47,  1.03s/it, loss=0.4806, batch_acc=0.9375, running_acc=0.9402, grad=22.2422]Training epoch 23:  36%|███▌      | 58/163 [01:08<01:47,  1.03s/it, loss=0.5239, batch_acc=0.9062, running_acc=0.9397, grad=28.1762]Training epoch 23:  36%|███▌      | 59/163 [01:08<01:42,  1.02it/s, loss=0.5239, batch_acc=0.9062, running_acc=0.9397, grad=28.1762]Training epoch 23:  36%|███▌      | 59/163 [01:08<01:42,  1.02it/s, loss=0.5713, batch_acc=0.9062, running_acc=0.9391, grad=22.0787]Training epoch 23:  37%|███▋      | 60/163 [01:10<02:00,  1.17s/it, loss=0.5713, batch_acc=0.9062, running_acc=0.9391, grad=22.0787]Training epoch 23:  37%|███▋      | 60/163 [01:10<02:00,  1.17s/it, loss=0.3909, batch_acc=0.9688, running_acc=0.9396, grad=16.4891]Training epoch 23:  37%|███▋      | 61/163 [01:11<01:50,  1.08s/it, loss=0.3909, batch_acc=0.9688, running_acc=0.9396, grad=16.4891]Training epoch 23:  37%|███▋      | 61/163 [01:11<01:50,  1.08s/it, loss=0.3211, batch_acc=0.9688, running_acc=0.9401, grad=17.2672]Training epoch 23:  38%|███▊      | 62/163 [01:12<01:43,  1.02s/it, loss=0.3211, batch_acc=0.9688, running_acc=0.9401, grad=17.2672]Training epoch 23:  38%|███▊      | 62/163 [01:12<01:43,  1.02s/it, loss=0.3353, batch_acc=0.9375, running_acc=0.9400, grad=22.6241]Training epoch 23:  39%|███▊      | 63/163 [01:13<01:37,  1.02it/s, loss=0.3353, batch_acc=0.9375, running_acc=0.9400, grad=22.6241]Training epoch 23:  39%|███▊      | 63/163 [01:13<01:37,  1.02it/s, loss=0.4132, batch_acc=0.9688, running_acc=0.9405, grad=20.3305]Training epoch 23:  39%|███▉      | 64/163 [01:14<02:00,  1.22s/it, loss=0.4132, batch_acc=0.9688, running_acc=0.9405, grad=20.3305]Training epoch 23:  39%|███▉      | 64/163 [01:14<02:00,  1.22s/it, loss=0.4995, batch_acc=0.8750, running_acc=0.9395, grad=22.6033]Training epoch 23:  40%|███▉      | 65/163 [01:15<01:49,  1.12s/it, loss=0.4995, batch_acc=0.8750, running_acc=0.9395, grad=22.6033]Training epoch 23:  40%|███▉      | 65/163 [01:15<01:49,  1.12s/it, loss=0.4070, batch_acc=0.9688, running_acc=0.9399, grad=17.7606]Training epoch 23:  40%|████      | 66/163 [01:16<01:41,  1.05s/it, loss=0.4070, batch_acc=0.9688, running_acc=0.9399, grad=17.7606]Training epoch 23:  40%|████      | 66/163 [01:16<01:41,  1.05s/it, loss=0.3758, batch_acc=0.9688, running_acc=0.9403, grad=18.5986]Training epoch 23:  41%|████      | 67/163 [01:17<01:35,  1.00it/s, loss=0.3758, batch_acc=0.9688, running_acc=0.9403, grad=18.5986]Training epoch 23:  41%|████      | 67/163 [01:17<01:35,  1.00it/s, loss=0.4032, batch_acc=0.9688, running_acc=0.9408, grad=18.0632]Training epoch 23:  42%|████▏     | 68/163 [01:19<01:54,  1.20s/it, loss=0.4032, batch_acc=0.9688, running_acc=0.9408, grad=18.0632]Training epoch 23:  42%|████▏     | 68/163 [01:19<01:54,  1.20s/it, loss=0.3880, batch_acc=1.0000, running_acc=0.9416, grad=22.6500]Training epoch 23:  42%|████▏     | 69/163 [01:20<01:44,  1.11s/it, loss=0.3880, batch_acc=1.0000, running_acc=0.9416, grad=22.6500]Training epoch 23:  42%|████▏     | 69/163 [01:20<01:44,  1.11s/it, loss=0.2752, batch_acc=1.0000, running_acc=0.9425, grad=13.9913]Training epoch 23:  43%|████▎     | 70/163 [01:21<01:36,  1.04s/it, loss=0.2752, batch_acc=1.0000, running_acc=0.9425, grad=13.9913]Training epoch 23:  43%|████▎     | 70/163 [01:21<01:36,  1.04s/it, loss=0.4542, batch_acc=0.9688, running_acc=0.9429, grad=20.4024]Training epoch 23:  44%|████▎     | 71/163 [01:21<01:31,  1.01it/s, loss=0.4542, batch_acc=0.9688, running_acc=0.9429, grad=20.4024]Training epoch 23:  44%|████▎     | 71/163 [01:21<01:31,  1.01it/s, loss=0.6204, batch_acc=0.9375, running_acc=0.9428, grad=26.4471]Training epoch 23:  44%|████▍     | 72/163 [01:23<01:51,  1.23s/it, loss=0.6204, batch_acc=0.9375, running_acc=0.9428, grad=26.4471]Training epoch 23:  44%|████▍     | 72/163 [01:23<01:51,  1.23s/it, loss=0.4527, batch_acc=0.9375, running_acc=0.9427, grad=15.8583]Training epoch 23:  45%|████▍     | 73/163 [01:24<01:41,  1.13s/it, loss=0.4527, batch_acc=0.9375, running_acc=0.9427, grad=15.8583]Training epoch 23:  45%|████▍     | 73/163 [01:24<01:41,  1.13s/it, loss=0.3871, batch_acc=0.9062, running_acc=0.9422, grad=19.4751]Training epoch 23:  45%|████▌     | 74/163 [01:25<01:33,  1.05s/it, loss=0.3871, batch_acc=0.9062, running_acc=0.9422, grad=19.4751]Training epoch 23:  45%|████▌     | 74/163 [01:25<01:33,  1.05s/it, loss=0.4939, batch_acc=0.9375, running_acc=0.9421, grad=21.3235]Training epoch 23:  46%|████▌     | 75/163 [01:26<01:28,  1.00s/it, loss=0.4939, batch_acc=0.9375, running_acc=0.9421, grad=21.3235]Training epoch 23:  46%|████▌     | 75/163 [01:26<01:28,  1.00s/it, loss=0.4121, batch_acc=0.9062, running_acc=0.9417, grad=19.3195]Training epoch 23:  47%|████▋     | 76/163 [01:27<01:28,  1.02s/it, loss=0.4121, batch_acc=0.9062, running_acc=0.9417, grad=19.3195]Training epoch 23:  47%|████▋     | 76/163 [01:27<01:28,  1.02s/it, loss=0.4700, batch_acc=0.9375, running_acc=0.9416, grad=21.3202]Training epoch 23:  47%|████▋     | 77/163 [01:28<01:25,  1.00it/s, loss=0.4700, batch_acc=0.9375, running_acc=0.9416, grad=21.3202]Training epoch 23:  47%|████▋     | 77/163 [01:28<01:25,  1.00it/s, loss=0.4703, batch_acc=0.9688, running_acc=0.9420, grad=20.0808]Training epoch 23:  48%|████▊     | 78/163 [01:29<01:21,  1.04it/s, loss=0.4703, batch_acc=0.9688, running_acc=0.9420, grad=20.0808]Training epoch 23:  48%|████▊     | 78/163 [01:29<01:21,  1.04it/s, loss=0.4366, batch_acc=1.0000, running_acc=0.9427, grad=22.7230]Training epoch 23:  48%|████▊     | 79/163 [01:30<01:18,  1.07it/s, loss=0.4366, batch_acc=1.0000, running_acc=0.9427, grad=22.7230]Training epoch 23:  48%|████▊     | 79/163 [01:30<01:18,  1.07it/s, loss=0.6148, batch_acc=0.8438, running_acc=0.9415, grad=30.6988]Training epoch 23:  49%|████▉     | 80/163 [01:32<01:45,  1.28s/it, loss=0.6148, batch_acc=0.8438, running_acc=0.9415, grad=30.6988]Training epoch 23:  49%|████▉     | 80/163 [01:32<01:45,  1.28s/it, loss=0.2797, batch_acc=1.0000, running_acc=0.9422, grad=16.8745]Training epoch 23:  50%|████▉     | 81/163 [01:33<01:34,  1.16s/it, loss=0.2797, batch_acc=1.0000, running_acc=0.9422, grad=16.8745]Training epoch 23:  50%|████▉     | 81/163 [01:33<01:34,  1.16s/it, loss=0.6567, batch_acc=0.8125, running_acc=0.9406, grad=31.5171]Training epoch 23:  50%|█████     | 82/163 [01:33<01:27,  1.08s/it, loss=0.6567, batch_acc=0.8125, running_acc=0.9406, grad=31.5171]Training epoch 23:  50%|█████     | 82/163 [01:33<01:27,  1.08s/it, loss=0.3787, batch_acc=0.9688, running_acc=0.9409, grad=16.3690]Training epoch 23:  51%|█████     | 83/163 [01:34<01:21,  1.02s/it, loss=0.3787, batch_acc=0.9688, running_acc=0.9409, grad=16.3690]Training epoch 23:  51%|█████     | 83/163 [01:34<01:21,  1.02s/it, loss=0.4785, batch_acc=0.9375, running_acc=0.9409, grad=21.9738]Training epoch 23:  52%|█████▏    | 84/163 [01:36<01:38,  1.25s/it, loss=0.4785, batch_acc=0.9375, running_acc=0.9409, grad=21.9738]Training epoch 23:  52%|█████▏    | 84/163 [01:36<01:38,  1.25s/it, loss=0.4216, batch_acc=0.9688, running_acc=0.9412, grad=20.0380]Training epoch 23:  52%|█████▏    | 85/163 [01:37<01:30,  1.16s/it, loss=0.4216, batch_acc=0.9688, running_acc=0.9412, grad=20.0380]Training epoch 23:  52%|█████▏    | 85/163 [01:37<01:30,  1.16s/it, loss=0.3593, batch_acc=0.9062, running_acc=0.9408, grad=23.4131]Training epoch 23:  53%|█████▎    | 86/163 [01:38<01:31,  1.19s/it, loss=0.3593, batch_acc=0.9062, running_acc=0.9408, grad=23.4131]Training epoch 23:  53%|█████▎    | 86/163 [01:38<01:31,  1.19s/it, loss=0.4885, batch_acc=0.8750, running_acc=0.9400, grad=22.6579]Training epoch 23:  53%|█████▎    | 87/163 [01:39<01:23,  1.10s/it, loss=0.4885, batch_acc=0.8750, running_acc=0.9400, grad=22.6579]Training epoch 23:  53%|█████▎    | 87/163 [01:39<01:23,  1.10s/it, loss=0.4607, batch_acc=0.9688, running_acc=0.9404, grad=21.4316]Training epoch 23:  54%|█████▍    | 88/163 [01:41<01:31,  1.22s/it, loss=0.4607, batch_acc=0.9688, running_acc=0.9404, grad=21.4316]Training epoch 23:  54%|█████▍    | 88/163 [01:41<01:31,  1.22s/it, loss=0.5379, batch_acc=0.9062, running_acc=0.9400, grad=28.1040]Training epoch 23:  55%|█████▍    | 89/163 [01:42<01:22,  1.12s/it, loss=0.5379, batch_acc=0.9062, running_acc=0.9400, grad=28.1040]Training epoch 23:  55%|█████▍    | 89/163 [01:42<01:22,  1.12s/it, loss=0.5481, batch_acc=0.8750, running_acc=0.9393, grad=24.5485]Training epoch 23:  55%|█████▌    | 90/163 [01:42<01:16,  1.05s/it, loss=0.5481, batch_acc=0.8750, running_acc=0.9393, grad=24.5485]Training epoch 23:  55%|█████▌    | 90/163 [01:42<01:16,  1.05s/it, loss=0.3746, batch_acc=0.9688, running_acc=0.9396, grad=16.3753]Training epoch 23:  56%|█████▌    | 91/163 [01:43<01:11,  1.00it/s, loss=0.3746, batch_acc=0.9688, running_acc=0.9396, grad=16.3753]Training epoch 23:  56%|█████▌    | 91/163 [01:43<01:11,  1.00it/s, loss=0.6874, batch_acc=0.8438, running_acc=0.9385, grad=28.5248]Training epoch 23:  56%|█████▋    | 92/163 [01:45<01:22,  1.16s/it, loss=0.6874, batch_acc=0.8438, running_acc=0.9385, grad=28.5248]Training epoch 23:  56%|█████▋    | 92/163 [01:45<01:22,  1.16s/it, loss=0.4806, batch_acc=0.9062, running_acc=0.9382, grad=22.6995]Training epoch 23:  57%|█████▋    | 93/163 [01:46<01:15,  1.08s/it, loss=0.4806, batch_acc=0.9062, running_acc=0.9382, grad=22.6995]Training epoch 23:  57%|█████▋    | 93/163 [01:46<01:15,  1.08s/it, loss=0.4056, batch_acc=0.9688, running_acc=0.9385, grad=20.2150]Training epoch 23:  58%|█████▊    | 94/163 [01:47<01:10,  1.02s/it, loss=0.4056, batch_acc=0.9688, running_acc=0.9385, grad=20.2150]Training epoch 23:  58%|█████▊    | 94/163 [01:47<01:10,  1.02s/it, loss=0.6326, batch_acc=0.8438, running_acc=0.9375, grad=28.4047]Training epoch 23:  58%|█████▊    | 95/163 [01:48<01:06,  1.02it/s, loss=0.6326, batch_acc=0.8438, running_acc=0.9375, grad=28.4047]Training epoch 23:  58%|█████▊    | 95/163 [01:48<01:06,  1.02it/s, loss=0.4112, batch_acc=0.9688, running_acc=0.9378, grad=22.8491]Training epoch 23:  59%|█████▉    | 96/163 [01:49<01:23,  1.24s/it, loss=0.4112, batch_acc=0.9688, running_acc=0.9378, grad=22.8491]Training epoch 23:  59%|█████▉    | 96/163 [01:49<01:23,  1.24s/it, loss=0.5996, batch_acc=0.8438, running_acc=0.9368, grad=24.8867]Training epoch 23:  60%|█████▉    | 97/163 [01:50<01:14,  1.13s/it, loss=0.5996, batch_acc=0.8438, running_acc=0.9368, grad=24.8867]Training epoch 23:  60%|█████▉    | 97/163 [01:50<01:14,  1.13s/it, loss=0.4618, batch_acc=0.9062, running_acc=0.9365, grad=19.5150]Training epoch 23:  60%|██████    | 98/163 [01:51<01:08,  1.06s/it, loss=0.4618, batch_acc=0.9062, running_acc=0.9365, grad=19.5150]Training epoch 23:  60%|██████    | 98/163 [01:51<01:08,  1.06s/it, loss=0.3596, batch_acc=0.9062, running_acc=0.9362, grad=16.3977]Training epoch 23:  61%|██████    | 99/163 [01:52<01:04,  1.00s/it, loss=0.3596, batch_acc=0.9062, running_acc=0.9362, grad=16.3977]Training epoch 23:  61%|██████    | 99/163 [01:52<01:04,  1.00s/it, loss=0.3795, batch_acc=0.9062, running_acc=0.9359, grad=20.5474]Training epoch 23:  61%|██████▏   | 100/163 [01:54<01:13,  1.17s/it, loss=0.3795, batch_acc=0.9062, running_acc=0.9359, grad=20.5474]Training epoch 23:  61%|██████▏   | 100/163 [01:54<01:13,  1.17s/it, loss=0.3969, batch_acc=0.9062, running_acc=0.9356, grad=22.5016]Training epoch 23:  62%|██████▏   | 101/163 [01:54<01:07,  1.09s/it, loss=0.3969, batch_acc=0.9062, running_acc=0.9356, grad=22.5016]Training epoch 23:  62%|██████▏   | 101/163 [01:54<01:07,  1.09s/it, loss=0.4772, batch_acc=0.9375, running_acc=0.9356, grad=21.9408]Training epoch 23:  63%|██████▎   | 102/163 [01:55<01:02,  1.02s/it, loss=0.4772, batch_acc=0.9375, running_acc=0.9356, grad=21.9408]Training epoch 23:  63%|██████▎   | 102/163 [01:55<01:02,  1.02s/it, loss=0.3702, batch_acc=0.9688, running_acc=0.9360, grad=21.7266]Training epoch 23:  63%|██████▎   | 103/163 [01:56<00:58,  1.02it/s, loss=0.3702, batch_acc=0.9688, running_acc=0.9360, grad=21.7266]Training epoch 23:  63%|██████▎   | 103/163 [01:56<00:58,  1.02it/s, loss=0.3040, batch_acc=0.9688, running_acc=0.9363, grad=17.3144]Training epoch 23:  64%|██████▍   | 104/163 [01:58<01:04,  1.09s/it, loss=0.3040, batch_acc=0.9688, running_acc=0.9363, grad=17.3144]Training epoch 23:  64%|██████▍   | 104/163 [01:58<01:04,  1.09s/it, loss=0.4684, batch_acc=0.9062, running_acc=0.9360, grad=18.3737]Training epoch 23:  64%|██████▍   | 105/163 [01:59<01:00,  1.04s/it, loss=0.4684, batch_acc=0.9062, running_acc=0.9360, grad=18.3737]Training epoch 23:  64%|██████▍   | 105/163 [01:59<01:00,  1.04s/it, loss=0.4703, batch_acc=0.8750, running_acc=0.9354, grad=22.5104]Training epoch 23:  65%|██████▌   | 106/163 [01:59<00:57,  1.01s/it, loss=0.4703, batch_acc=0.8750, running_acc=0.9354, grad=22.5104]Training epoch 23:  65%|██████▌   | 106/163 [01:59<00:57,  1.01s/it, loss=0.4799, batch_acc=0.9062, running_acc=0.9351, grad=20.1101]Training epoch 23:  66%|██████▌   | 107/163 [02:00<00:54,  1.03it/s, loss=0.4799, batch_acc=0.9062, running_acc=0.9351, grad=20.1101]Training epoch 23:  66%|██████▌   | 107/163 [02:00<00:54,  1.03it/s, loss=0.4332, batch_acc=0.9375, running_acc=0.9352, grad=17.9436]Training epoch 23:  66%|██████▋   | 108/163 [02:02<01:05,  1.19s/it, loss=0.4332, batch_acc=0.9375, running_acc=0.9352, grad=17.9436]Training epoch 23:  66%|██████▋   | 108/163 [02:02<01:05,  1.19s/it, loss=0.3882, batch_acc=0.9375, running_acc=0.9352, grad=16.6139]Training epoch 23:  67%|██████▋   | 109/163 [02:03<00:59,  1.10s/it, loss=0.3882, batch_acc=0.9375, running_acc=0.9352, grad=16.6139]Training epoch 23:  67%|██████▋   | 109/163 [02:03<00:59,  1.10s/it, loss=0.3343, batch_acc=1.0000, running_acc=0.9358, grad=19.1122]Training epoch 23:  67%|██████▋   | 110/163 [02:04<00:54,  1.03s/it, loss=0.3343, batch_acc=1.0000, running_acc=0.9358, grad=19.1122]Training epoch 23:  67%|██████▋   | 110/163 [02:04<00:54,  1.03s/it, loss=0.3489, batch_acc=1.0000, running_acc=0.9364, grad=20.0670]Training epoch 23:  68%|██████▊   | 111/163 [02:05<00:51,  1.01it/s, loss=0.3489, batch_acc=1.0000, running_acc=0.9364, grad=20.0670]Training epoch 23:  68%|██████▊   | 111/163 [02:05<00:51,  1.01it/s, loss=0.6586, batch_acc=0.8750, running_acc=0.9358, grad=30.6919]Training epoch 23:  69%|██████▊   | 112/163 [02:06<00:59,  1.18s/it, loss=0.6586, batch_acc=0.8750, running_acc=0.9358, grad=30.6919]Training epoch 23:  69%|██████▊   | 112/163 [02:06<00:59,  1.18s/it, loss=0.5325, batch_acc=0.9062, running_acc=0.9355, grad=24.7909]Training epoch 23:  69%|██████▉   | 113/163 [02:07<00:54,  1.10s/it, loss=0.5325, batch_acc=0.9062, running_acc=0.9355, grad=24.7909]Training epoch 23:  69%|██████▉   | 113/163 [02:07<00:54,  1.10s/it, loss=0.4513, batch_acc=0.9688, running_acc=0.9358, grad=17.5500]Training epoch 23:  70%|██████▉   | 114/163 [02:08<00:50,  1.03s/it, loss=0.4513, batch_acc=0.9688, running_acc=0.9358, grad=17.5500]Training epoch 23:  70%|██████▉   | 114/163 [02:08<00:50,  1.03s/it, loss=0.5783, batch_acc=0.8750, running_acc=0.9353, grad=19.0672]Training epoch 23:  71%|███████   | 115/163 [02:09<00:47,  1.01it/s, loss=0.5783, batch_acc=0.8750, running_acc=0.9353, grad=19.0672]Training epoch 23:  71%|███████   | 115/163 [02:09<00:47,  1.01it/s, loss=0.4541, batch_acc=0.9375, running_acc=0.9353, grad=26.6146]Training epoch 23:  71%|███████   | 116/163 [02:11<00:58,  1.24s/it, loss=0.4541, batch_acc=0.9375, running_acc=0.9353, grad=26.6146]Training epoch 23:  71%|███████   | 116/163 [02:11<00:58,  1.24s/it, loss=0.5236, batch_acc=0.9375, running_acc=0.9353, grad=23.4357]Training epoch 23:  72%|███████▏  | 117/163 [02:12<00:52,  1.15s/it, loss=0.5236, batch_acc=0.9375, running_acc=0.9353, grad=23.4357]Training epoch 23:  72%|███████▏  | 117/163 [02:12<00:52,  1.15s/it, loss=0.4337, batch_acc=0.9688, running_acc=0.9356, grad=29.4564]Training epoch 23:  72%|███████▏  | 118/163 [02:13<00:48,  1.07s/it, loss=0.4337, batch_acc=0.9688, running_acc=0.9356, grad=29.4564]Training epoch 23:  72%|███████▏  | 118/163 [02:13<00:48,  1.07s/it, loss=0.3421, batch_acc=0.9688, running_acc=0.9359, grad=25.9200]Training epoch 23:  73%|███████▎  | 119/163 [02:13<00:44,  1.01s/it, loss=0.3421, batch_acc=0.9688, running_acc=0.9359, grad=25.9200]Training epoch 23:  73%|███████▎  | 119/163 [02:13<00:44,  1.01s/it, loss=0.4263, batch_acc=1.0000, running_acc=0.9364, grad=21.0851]Training epoch 23:  74%|███████▎  | 120/163 [02:15<00:51,  1.20s/it, loss=0.4263, batch_acc=1.0000, running_acc=0.9364, grad=21.0851]Training epoch 23:  74%|███████▎  | 120/163 [02:15<00:51,  1.20s/it, loss=0.4605, batch_acc=0.8750, running_acc=0.9359, grad=17.6048]Training epoch 23:  74%|███████▍  | 121/163 [02:16<00:46,  1.10s/it, loss=0.4605, batch_acc=0.8750, running_acc=0.9359, grad=17.6048]Training epoch 23:  74%|███████▍  | 121/163 [02:16<00:46,  1.10s/it, loss=0.4507, batch_acc=0.9688, running_acc=0.9362, grad=17.4336]Training epoch 23:  75%|███████▍  | 122/163 [02:17<00:43,  1.07s/it, loss=0.4507, batch_acc=0.9688, running_acc=0.9362, grad=17.4336]Training epoch 23:  75%|███████▍  | 122/163 [02:17<00:43,  1.07s/it, loss=0.4580, batch_acc=0.8750, running_acc=0.9357, grad=21.7969]Training epoch 23:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.4580, batch_acc=0.8750, running_acc=0.9357, grad=21.7969]Training epoch 23:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.4626, batch_acc=0.9688, running_acc=0.9360, grad=18.9243]Training epoch 23:  76%|███████▌  | 124/163 [02:19<00:46,  1.20s/it, loss=0.4626, batch_acc=0.9688, running_acc=0.9360, grad=18.9243]Training epoch 23:  76%|███████▌  | 124/163 [02:19<00:46,  1.20s/it, loss=0.5431, batch_acc=0.9375, running_acc=0.9360, grad=30.1196]Training epoch 23:  77%|███████▋  | 125/163 [02:20<00:41,  1.10s/it, loss=0.5431, batch_acc=0.9375, running_acc=0.9360, grad=30.1196]Training epoch 23:  77%|███████▋  | 125/163 [02:20<00:41,  1.10s/it, loss=0.4361, batch_acc=0.9688, running_acc=0.9363, grad=19.8669]Training epoch 23:  77%|███████▋  | 126/163 [02:21<00:38,  1.04s/it, loss=0.4361, batch_acc=0.9688, running_acc=0.9363, grad=19.8669]Training epoch 23:  77%|███████▋  | 126/163 [02:21<00:38,  1.04s/it, loss=0.4927, batch_acc=0.9375, running_acc=0.9363, grad=27.4291]Training epoch 23:  78%|███████▊  | 127/163 [02:22<00:35,  1.01it/s, loss=0.4927, batch_acc=0.9375, running_acc=0.9363, grad=27.4291]Training epoch 23:  78%|███████▊  | 127/163 [02:22<00:35,  1.01it/s, loss=0.6796, batch_acc=0.8438, running_acc=0.9355, grad=24.7717]Training epoch 23:  79%|███████▊  | 128/163 [02:24<00:41,  1.18s/it, loss=0.6796, batch_acc=0.8438, running_acc=0.9355, grad=24.7717]Training epoch 23:  79%|███████▊  | 128/163 [02:24<00:41,  1.18s/it, loss=0.4752, batch_acc=0.9375, running_acc=0.9355, grad=22.5868]Training epoch 23:  79%|███████▉  | 129/163 [02:25<00:37,  1.09s/it, loss=0.4752, batch_acc=0.9375, running_acc=0.9355, grad=22.5868]Training epoch 23:  79%|███████▉  | 129/163 [02:25<00:37,  1.09s/it, loss=0.4234, batch_acc=0.9688, running_acc=0.9358, grad=21.3962]Training epoch 23:  80%|███████▉  | 130/163 [02:26<00:33,  1.03s/it, loss=0.4234, batch_acc=0.9688, running_acc=0.9358, grad=21.3962]Training epoch 23:  80%|███████▉  | 130/163 [02:26<00:33,  1.03s/it, loss=0.3317, batch_acc=0.9062, running_acc=0.9356, grad=14.8251]Training epoch 23:  80%|████████  | 131/163 [02:26<00:31,  1.01it/s, loss=0.3317, batch_acc=0.9062, running_acc=0.9356, grad=14.8251]Training epoch 23:  80%|████████  | 131/163 [02:26<00:31,  1.01it/s, loss=0.5092, batch_acc=0.9375, running_acc=0.9356, grad=24.6507]Training epoch 23:  81%|████████  | 132/163 [02:28<00:38,  1.24s/it, loss=0.5092, batch_acc=0.9375, running_acc=0.9356, grad=24.6507]Training epoch 23:  81%|████████  | 132/163 [02:28<00:38,  1.24s/it, loss=0.2670, batch_acc=1.0000, running_acc=0.9361, grad=18.0592]Training epoch 23:  82%|████████▏ | 133/163 [02:29<00:33,  1.13s/it, loss=0.2670, batch_acc=1.0000, running_acc=0.9361, grad=18.0592]Training epoch 23:  82%|████████▏ | 133/163 [02:29<00:33,  1.13s/it, loss=0.4682, batch_acc=0.9375, running_acc=0.9361, grad=19.6952]Training epoch 23:  82%|████████▏ | 134/163 [02:30<00:30,  1.06s/it, loss=0.4682, batch_acc=0.9375, running_acc=0.9361, grad=19.6952]Training epoch 23:  82%|████████▏ | 134/163 [02:30<00:30,  1.06s/it, loss=0.4727, batch_acc=0.8750, running_acc=0.9356, grad=18.0854]Training epoch 23:  83%|████████▎ | 135/163 [02:31<00:28,  1.00s/it, loss=0.4727, batch_acc=0.8750, running_acc=0.9356, grad=18.0854]Training epoch 23:  83%|████████▎ | 135/163 [02:31<00:28,  1.00s/it, loss=0.4763, batch_acc=0.9375, running_acc=0.9356, grad=25.2974]Training epoch 23:  83%|████████▎ | 136/163 [02:33<00:34,  1.29s/it, loss=0.4763, batch_acc=0.9375, running_acc=0.9356, grad=25.2974]Training epoch 23:  83%|████████▎ | 136/163 [02:33<00:34,  1.29s/it, loss=0.5217, batch_acc=0.9375, running_acc=0.9357, grad=22.1631]Training epoch 23:  84%|████████▍ | 137/163 [02:34<00:30,  1.16s/it, loss=0.5217, batch_acc=0.9375, running_acc=0.9357, grad=22.1631]Training epoch 23:  84%|████████▍ | 137/163 [02:34<00:30,  1.16s/it, loss=0.4524, batch_acc=0.9375, running_acc=0.9357, grad=19.8508]Training epoch 23:  85%|████████▍ | 138/163 [02:35<00:26,  1.08s/it, loss=0.4524, batch_acc=0.9375, running_acc=0.9357, grad=19.8508]Training epoch 23:  85%|████████▍ | 138/163 [02:35<00:26,  1.08s/it, loss=0.3201, batch_acc=1.0000, running_acc=0.9361, grad=20.5778]Training epoch 23:  85%|████████▌ | 139/163 [02:35<00:24,  1.02s/it, loss=0.3201, batch_acc=1.0000, running_acc=0.9361, grad=20.5778]Training epoch 23:  85%|████████▌ | 139/163 [02:35<00:24,  1.02s/it, loss=0.2904, batch_acc=0.9688, running_acc=0.9364, grad=20.1334]Training epoch 23:  86%|████████▌ | 140/163 [02:37<00:27,  1.22s/it, loss=0.2904, batch_acc=0.9688, running_acc=0.9364, grad=20.1334]Training epoch 23:  86%|████████▌ | 140/163 [02:37<00:27,  1.22s/it, loss=0.4314, batch_acc=0.9375, running_acc=0.9364, grad=24.0772]Training epoch 23:  87%|████████▋ | 141/163 [02:38<00:24,  1.11s/it, loss=0.4314, batch_acc=0.9375, running_acc=0.9364, grad=24.0772]Training epoch 23:  87%|████████▋ | 141/163 [02:38<00:24,  1.11s/it, loss=0.4532, batch_acc=0.9688, running_acc=0.9366, grad=29.1597]Training epoch 23:  87%|████████▋ | 142/163 [02:39<00:21,  1.04s/it, loss=0.4532, batch_acc=0.9688, running_acc=0.9366, grad=29.1597]Training epoch 23:  87%|████████▋ | 142/163 [02:39<00:21,  1.04s/it, loss=0.4414, batch_acc=0.9688, running_acc=0.9368, grad=23.8458]Training epoch 23:  88%|████████▊ | 143/163 [02:40<00:19,  1.00it/s, loss=0.4414, batch_acc=0.9688, running_acc=0.9368, grad=23.8458]Training epoch 23:  88%|████████▊ | 143/163 [02:40<00:19,  1.00it/s, loss=0.3333, batch_acc=0.9688, running_acc=0.9371, grad=14.3575]Training epoch 23:  88%|████████▊ | 144/163 [02:42<00:23,  1.22s/it, loss=0.3333, batch_acc=0.9688, running_acc=0.9371, grad=14.3575]Training epoch 23:  88%|████████▊ | 144/163 [02:42<00:23,  1.22s/it, loss=0.5175, batch_acc=0.8750, running_acc=0.9366, grad=18.6211]Training epoch 23:  89%|████████▉ | 145/163 [02:42<00:20,  1.12s/it, loss=0.5175, batch_acc=0.8750, running_acc=0.9366, grad=18.6211]Training epoch 23:  89%|████████▉ | 145/163 [02:42<00:20,  1.12s/it, loss=0.3207, batch_acc=1.0000, running_acc=0.9371, grad=22.8244]Training epoch 23:  90%|████████▉ | 146/163 [02:43<00:17,  1.05s/it, loss=0.3207, batch_acc=1.0000, running_acc=0.9371, grad=22.8244]Training epoch 23:  90%|████████▉ | 146/163 [02:43<00:17,  1.05s/it, loss=0.5543, batch_acc=0.9062, running_acc=0.9369, grad=27.1121]Training epoch 23:  90%|█████████ | 147/163 [02:44<00:15,  1.00it/s, loss=0.5543, batch_acc=0.9062, running_acc=0.9369, grad=27.1121]Training epoch 23:  90%|█████████ | 147/163 [02:44<00:15,  1.00it/s, loss=0.3287, batch_acc=1.0000, running_acc=0.9373, grad=21.0529]Training epoch 23:  91%|█████████ | 148/163 [02:47<00:21,  1.46s/it, loss=0.3287, batch_acc=1.0000, running_acc=0.9373, grad=21.0529]Training epoch 23:  91%|█████████ | 148/163 [02:47<00:21,  1.46s/it, loss=0.4998, batch_acc=0.9062, running_acc=0.9371, grad=20.4118]Training epoch 23:  91%|█████████▏| 149/163 [02:48<00:17,  1.28s/it, loss=0.4998, batch_acc=0.9062, running_acc=0.9371, grad=20.4118]Training epoch 23:  91%|█████████▏| 149/163 [02:48<00:17,  1.28s/it, loss=0.4317, batch_acc=0.9062, running_acc=0.9369, grad=21.9014]Training epoch 23:  92%|█████████▏| 150/163 [02:48<00:15,  1.16s/it, loss=0.4317, batch_acc=0.9062, running_acc=0.9369, grad=21.9014]Training epoch 23:  92%|█████████▏| 150/163 [02:48<00:15,  1.16s/it, loss=0.4138, batch_acc=0.9375, running_acc=0.9369, grad=19.0048]Training epoch 23:  93%|█████████▎| 151/163 [02:49<00:12,  1.08s/it, loss=0.4138, batch_acc=0.9375, running_acc=0.9369, grad=19.0048]Training epoch 23:  93%|█████████▎| 151/163 [02:49<00:12,  1.08s/it, loss=0.3470, batch_acc=0.9375, running_acc=0.9369, grad=20.8664]Training epoch 23:  93%|█████████▎| 152/163 [02:51<00:13,  1.21s/it, loss=0.3470, batch_acc=0.9375, running_acc=0.9369, grad=20.8664]Training epoch 23:  93%|█████████▎| 152/163 [02:51<00:13,  1.21s/it, loss=0.2799, batch_acc=1.0000, running_acc=0.9373, grad=18.6479]Training epoch 23:  94%|█████████▍| 153/163 [02:52<00:11,  1.11s/it, loss=0.2799, batch_acc=1.0000, running_acc=0.9373, grad=18.6479]Training epoch 23:  94%|█████████▍| 153/163 [02:52<00:11,  1.11s/it, loss=0.4523, batch_acc=0.9688, running_acc=0.9375, grad=29.2829]Training epoch 23:  94%|█████████▍| 154/163 [02:53<00:09,  1.04s/it, loss=0.4523, batch_acc=0.9688, running_acc=0.9375, grad=29.2829]Training epoch 23:  94%|█████████▍| 154/163 [02:53<00:09,  1.04s/it, loss=0.5244, batch_acc=0.8750, running_acc=0.9371, grad=26.7335]Training epoch 23:  95%|█████████▌| 155/163 [02:54<00:07,  1.00it/s, loss=0.5244, batch_acc=0.8750, running_acc=0.9371, grad=26.7335]Training epoch 23:  95%|█████████▌| 155/163 [02:54<00:07,  1.00it/s, loss=0.4892, batch_acc=0.8438, running_acc=0.9365, grad=19.9444]Training epoch 23:  96%|█████████▌| 156/163 [02:55<00:07,  1.14s/it, loss=0.4892, batch_acc=0.8438, running_acc=0.9365, grad=19.9444]Training epoch 23:  96%|█████████▌| 156/163 [02:55<00:07,  1.14s/it, loss=0.5051, batch_acc=0.9375, running_acc=0.9365, grad=22.2570]Training epoch 23:  96%|█████████▋| 157/163 [02:56<00:06,  1.09s/it, loss=0.5051, batch_acc=0.9375, running_acc=0.9365, grad=22.2570]Training epoch 23:  96%|█████████▋| 157/163 [02:56<00:06,  1.09s/it, loss=0.5649, batch_acc=0.9375, running_acc=0.9365, grad=30.9356]Training epoch 23:  97%|█████████▋| 158/163 [02:57<00:05,  1.02s/it, loss=0.5649, batch_acc=0.9375, running_acc=0.9365, grad=30.9356]Training epoch 23:  97%|█████████▋| 158/163 [02:57<00:05,  1.02s/it, loss=0.3911, batch_acc=0.9375, running_acc=0.9365, grad=16.1006]Training epoch 23:  98%|█████████▊| 159/163 [02:58<00:03,  1.02it/s, loss=0.3911, batch_acc=0.9375, running_acc=0.9365, grad=16.1006]Training epoch 23:  98%|█████████▊| 159/163 [02:58<00:03,  1.02it/s, loss=0.3270, batch_acc=1.0000, running_acc=0.9369, grad=24.4557]Training epoch 23:  98%|█████████▊| 160/163 [03:00<00:03,  1.27s/it, loss=0.3270, batch_acc=1.0000, running_acc=0.9369, grad=24.4557]Training epoch 23:  98%|█████████▊| 160/163 [03:00<00:03,  1.27s/it, loss=0.4474, batch_acc=0.9375, running_acc=0.9369, grad=22.1658]Training epoch 23:  99%|█████████▉| 161/163 [03:01<00:02,  1.15s/it, loss=0.4474, batch_acc=0.9375, running_acc=0.9369, grad=22.1658]Training epoch 23:  99%|█████████▉| 161/163 [03:01<00:02,  1.15s/it, loss=0.4687, batch_acc=0.9062, running_acc=0.9367, grad=21.0881]Training epoch 23:  99%|█████████▉| 162/163 [03:01<00:01,  1.07s/it, loss=0.4687, batch_acc=0.9062, running_acc=0.9367, grad=21.0881]Training epoch 23:  99%|█████████▉| 162/163 [03:01<00:01,  1.07s/it, loss=0.3905, batch_acc=0.9688, running_acc=0.9369, grad=20.3935]Training epoch 23: 100%|██████████| 163/163 [03:02<00:00,  1.06it/s, loss=0.3905, batch_acc=0.9688, running_acc=0.9369, grad=20.3935]Training epoch 23: 100%|██████████| 163/163 [03:02<00:00,  1.06it/s, loss=0.3290, batch_acc=0.9524, running_acc=0.9370, grad=27.6526]Training epoch 23: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.3290, batch_acc=0.9524, running_acc=0.9370, grad=27.6526]
Evaluation epoch 23:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 23:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it]Evaluation epoch 23:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it, loss=0.4989, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 23:   7%|▋         | 2/28 [00:05<00:56,  2.17s/it, loss=0.4989, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 23:   7%|▋         | 2/28 [00:05<00:56,  2.17s/it, loss=0.5004, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 23:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.5004, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 23:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.6852, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 23:  14%|█▍        | 4/28 [00:09<01:00,  2.51s/it, loss=0.6852, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 23:  14%|█▍        | 4/28 [00:09<01:00,  2.51s/it, loss=0.8319, batch_acc=0.9062, running_acc=0.9297]Evaluation epoch 23:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=0.8319, batch_acc=0.9062, running_acc=0.9297]Evaluation epoch 23:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=1.7585, batch_acc=0.5625, running_acc=0.8562]Evaluation epoch 23:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=1.7585, batch_acc=0.5625, running_acc=0.8562]Evaluation epoch 23:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=0.7543, batch_acc=0.8125, running_acc=0.8490]Evaluation epoch 23:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.7543, batch_acc=0.8125, running_acc=0.8490]Evaluation epoch 23:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=1.1911, batch_acc=0.7500, running_acc=0.8348]Evaluation epoch 23:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=1.1911, batch_acc=0.7500, running_acc=0.8348]Evaluation epoch 23:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.7497, batch_acc=0.8750, running_acc=0.8398]Evaluation epoch 23:  32%|███▏      | 9/28 [00:14<00:25,  1.32s/it, loss=0.7497, batch_acc=0.8750, running_acc=0.8398]Evaluation epoch 23:  32%|███▏      | 9/28 [00:14<00:25,  1.32s/it, loss=0.7669, batch_acc=0.9062, running_acc=0.8472]Evaluation epoch 23:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.7669, batch_acc=0.9062, running_acc=0.8472]Evaluation epoch 23:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.6188, batch_acc=0.9062, running_acc=0.8531]Evaluation epoch 23:  39%|███▉      | 11/28 [00:14<00:13,  1.30it/s, loss=0.6188, batch_acc=0.9062, running_acc=0.8531]Evaluation epoch 23:  39%|███▉      | 11/28 [00:14<00:13,  1.30it/s, loss=0.6307, batch_acc=0.8438, running_acc=0.8523]Evaluation epoch 23:  43%|████▎     | 12/28 [00:20<00:35,  2.21s/it, loss=0.6307, batch_acc=0.8438, running_acc=0.8523]Evaluation epoch 23:  43%|████▎     | 12/28 [00:20<00:35,  2.21s/it, loss=1.0827, batch_acc=0.7812, running_acc=0.8464]Evaluation epoch 23:  46%|████▋     | 13/28 [00:20<00:24,  1.62s/it, loss=1.0827, batch_acc=0.7812, running_acc=0.8464]Evaluation epoch 23:  46%|████▋     | 13/28 [00:20<00:24,  1.62s/it, loss=0.4562, batch_acc=0.9375, running_acc=0.8534]Evaluation epoch 23:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=0.4562, batch_acc=0.9375, running_acc=0.8534]Evaluation epoch 23:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=0.9783, batch_acc=0.8125, running_acc=0.8504]Evaluation epoch 23:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=0.9783, batch_acc=0.8125, running_acc=0.8504]Evaluation epoch 23:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=1.4376, batch_acc=0.6250, running_acc=0.8354]Evaluation epoch 23:  57%|█████▋    | 16/28 [00:24<00:18,  1.55s/it, loss=1.4376, batch_acc=0.6250, running_acc=0.8354]Evaluation epoch 23:  57%|█████▋    | 16/28 [00:24<00:18,  1.55s/it, loss=0.9828, batch_acc=0.7812, running_acc=0.8320]Evaluation epoch 23:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=0.9828, batch_acc=0.7812, running_acc=0.8320]Evaluation epoch 23:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=0.8210, batch_acc=0.8125, running_acc=0.8309]Evaluation epoch 23:  64%|██████▍   | 18/28 [00:24<00:08,  1.12it/s, loss=0.8210, batch_acc=0.8125, running_acc=0.8309]Evaluation epoch 23:  64%|██████▍   | 18/28 [00:24<00:08,  1.12it/s, loss=1.0522, batch_acc=0.7500, running_acc=0.8264]Evaluation epoch 23:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=1.0522, batch_acc=0.7500, running_acc=0.8264]Evaluation epoch 23:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=1.1205, batch_acc=0.5938, running_acc=0.8141]Evaluation epoch 23:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=1.1205, batch_acc=0.5938, running_acc=0.8141]Evaluation epoch 23:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=0.8229, batch_acc=0.6875, running_acc=0.8078]Evaluation epoch 23:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.8229, batch_acc=0.6875, running_acc=0.8078]Evaluation epoch 23:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.7733, batch_acc=0.8438, running_acc=0.8095]Evaluation epoch 23:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=0.7733, batch_acc=0.8438, running_acc=0.8095]Evaluation epoch 23:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=0.7777, batch_acc=0.9062, running_acc=0.8139]Evaluation epoch 23:  82%|████████▏ | 23/28 [00:28<00:03,  1.53it/s, loss=0.7777, batch_acc=0.9062, running_acc=0.8139]Evaluation epoch 23:  82%|████████▏ | 23/28 [00:28<00:03,  1.53it/s, loss=1.4632, batch_acc=0.6250, running_acc=0.8057]Evaluation epoch 23:  86%|████████▌ | 24/28 [00:34<00:08,  2.08s/it, loss=1.4632, batch_acc=0.6250, running_acc=0.8057]Evaluation epoch 23:  86%|████████▌ | 24/28 [00:34<00:08,  2.08s/it, loss=0.5847, batch_acc=0.9062, running_acc=0.8099]Evaluation epoch 23:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.5847, batch_acc=0.9062, running_acc=0.8099]Evaluation epoch 23:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.2396, batch_acc=1.0000, running_acc=0.8175]Evaluation epoch 23:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.2396, batch_acc=1.0000, running_acc=0.8175]Evaluation epoch 23:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=1.1024, batch_acc=0.6875, running_acc=0.8125]Evaluation epoch 23:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=1.1024, batch_acc=0.6875, running_acc=0.8125]Evaluation epoch 23:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=0.9230, batch_acc=0.7500, running_acc=0.8102]Evaluation epoch 23: 100%|██████████| 28/28 [00:35<00:00,  1.13it/s, loss=1.4603, batch_acc=0.6667, running_acc=0.8097]Evaluation epoch 23: 100%|██████████| 28/28 [00:35<00:00,  1.25s/it, loss=1.4603, batch_acc=0.6667, running_acc=0.8097]
Training epoch 24:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 24:   1%|          | 1/163 [00:05<14:39,  5.43s/it]Training epoch 24:   1%|          | 1/163 [00:05<14:39,  5.43s/it, loss=0.3343, batch_acc=0.9375, running_acc=0.9375, grad=21.6004]Training epoch 24:   1%|          | 2/163 [00:06<07:23,  2.75s/it, loss=0.3343, batch_acc=0.9375, running_acc=0.9375, grad=21.6004]Training epoch 24:   1%|          | 2/163 [00:06<07:23,  2.75s/it, loss=0.4002, batch_acc=0.9375, running_acc=0.9375, grad=20.2564]Training epoch 24:   2%|▏         | 3/163 [00:07<05:03,  1.90s/it, loss=0.4002, batch_acc=0.9375, running_acc=0.9375, grad=20.2564]Training epoch 24:   2%|▏         | 3/163 [00:07<05:03,  1.90s/it, loss=0.5111, batch_acc=0.9375, running_acc=0.9375, grad=22.1484]Training epoch 24:   2%|▏         | 4/163 [00:09<05:40,  2.14s/it, loss=0.5111, batch_acc=0.9375, running_acc=0.9375, grad=22.1484]Training epoch 24:   2%|▏         | 4/163 [00:09<05:40,  2.14s/it, loss=0.4339, batch_acc=0.9375, running_acc=0.9375, grad=22.1220]Training epoch 24:   3%|▎         | 5/163 [00:10<04:29,  1.70s/it, loss=0.4339, batch_acc=0.9375, running_acc=0.9375, grad=22.1220]Training epoch 24:   3%|▎         | 5/163 [00:10<04:29,  1.70s/it, loss=0.3138, batch_acc=1.0000, running_acc=0.9500, grad=19.5924]Training epoch 24:   4%|▎         | 6/163 [00:11<03:43,  1.42s/it, loss=0.3138, batch_acc=1.0000, running_acc=0.9500, grad=19.5924]Training epoch 24:   4%|▎         | 6/163 [00:11<03:43,  1.42s/it, loss=0.4385, batch_acc=0.9688, running_acc=0.9531, grad=22.9039]Training epoch 24:   4%|▍         | 7/163 [00:12<03:14,  1.25s/it, loss=0.4385, batch_acc=0.9688, running_acc=0.9531, grad=22.9039]Training epoch 24:   4%|▍         | 7/163 [00:12<03:14,  1.25s/it, loss=0.4178, batch_acc=1.0000, running_acc=0.9598, grad=16.8109]Training epoch 24:   5%|▍         | 8/163 [00:14<03:40,  1.42s/it, loss=0.4178, batch_acc=1.0000, running_acc=0.9598, grad=16.8109]Training epoch 24:   5%|▍         | 8/163 [00:14<03:40,  1.42s/it, loss=0.4117, batch_acc=0.9375, running_acc=0.9570, grad=26.7608]Training epoch 24:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.4117, batch_acc=0.9375, running_acc=0.9570, grad=26.7608]Training epoch 24:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.4757, batch_acc=0.9375, running_acc=0.9549, grad=21.1943]Training epoch 24:   6%|▌         | 10/163 [00:15<02:54,  1.14s/it, loss=0.4757, batch_acc=0.9375, running_acc=0.9549, grad=21.1943]Training epoch 24:   6%|▌         | 10/163 [00:15<02:54,  1.14s/it, loss=0.4158, batch_acc=0.9375, running_acc=0.9531, grad=20.1336]Training epoch 24:   7%|▋         | 11/163 [00:16<02:40,  1.06s/it, loss=0.4158, batch_acc=0.9375, running_acc=0.9531, grad=20.1336]Training epoch 24:   7%|▋         | 11/163 [00:16<02:40,  1.06s/it, loss=0.4824, batch_acc=0.8750, running_acc=0.9460, grad=26.0995]Training epoch 24:   7%|▋         | 12/163 [00:18<02:59,  1.19s/it, loss=0.4824, batch_acc=0.8750, running_acc=0.9460, grad=26.0995]Training epoch 24:   7%|▋         | 12/163 [00:18<02:59,  1.19s/it, loss=0.4293, batch_acc=0.9688, running_acc=0.9479, grad=22.0503]Training epoch 24:   8%|▊         | 13/163 [00:19<02:44,  1.10s/it, loss=0.4293, batch_acc=0.9688, running_acc=0.9479, grad=22.0503]Training epoch 24:   8%|▊         | 13/163 [00:19<02:44,  1.10s/it, loss=0.3830, batch_acc=0.9375, running_acc=0.9471, grad=22.3636]Training epoch 24:   9%|▊         | 14/163 [00:20<02:33,  1.03s/it, loss=0.3830, batch_acc=0.9375, running_acc=0.9471, grad=22.3636]Training epoch 24:   9%|▊         | 14/163 [00:20<02:33,  1.03s/it, loss=0.3281, batch_acc=0.9688, running_acc=0.9487, grad=15.8403]Training epoch 24:   9%|▉         | 15/163 [00:20<02:26,  1.01it/s, loss=0.3281, batch_acc=0.9688, running_acc=0.9487, grad=15.8403]Training epoch 24:   9%|▉         | 15/163 [00:20<02:26,  1.01it/s, loss=0.4285, batch_acc=0.9375, running_acc=0.9479, grad=17.7385]Training epoch 24:  10%|▉         | 16/163 [00:22<03:10,  1.29s/it, loss=0.4285, batch_acc=0.9375, running_acc=0.9479, grad=17.7385]Training epoch 24:  10%|▉         | 16/163 [00:22<03:10,  1.29s/it, loss=0.3272, batch_acc=0.9688, running_acc=0.9492, grad=13.7139]Training epoch 24:  10%|█         | 17/163 [00:23<02:50,  1.17s/it, loss=0.3272, batch_acc=0.9688, running_acc=0.9492, grad=13.7139]Training epoch 24:  10%|█         | 17/163 [00:23<02:50,  1.17s/it, loss=0.4998, batch_acc=0.9062, running_acc=0.9467, grad=22.3616]Training epoch 24:  11%|█         | 18/163 [00:24<02:36,  1.08s/it, loss=0.4998, batch_acc=0.9062, running_acc=0.9467, grad=22.3616]Training epoch 24:  11%|█         | 18/163 [00:24<02:36,  1.08s/it, loss=0.3876, batch_acc=0.9688, running_acc=0.9479, grad=18.7216]Training epoch 24:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=0.3876, batch_acc=0.9688, running_acc=0.9479, grad=18.7216]Training epoch 24:  12%|█▏        | 19/163 [00:25<02:27,  1.02s/it, loss=0.4558, batch_acc=0.9062, running_acc=0.9457, grad=24.1881]Training epoch 24:  12%|█▏        | 20/163 [00:26<02:33,  1.08s/it, loss=0.4558, batch_acc=0.9062, running_acc=0.9457, grad=24.1881]Training epoch 24:  12%|█▏        | 20/163 [00:26<02:33,  1.08s/it, loss=0.3785, batch_acc=0.9375, running_acc=0.9453, grad=18.6330]Training epoch 24:  13%|█▎        | 21/163 [00:28<02:42,  1.15s/it, loss=0.3785, batch_acc=0.9375, running_acc=0.9453, grad=18.6330]Training epoch 24:  13%|█▎        | 21/163 [00:28<02:42,  1.15s/it, loss=0.3509, batch_acc=0.9062, running_acc=0.9435, grad=18.3865]Training epoch 24:  13%|█▎        | 22/163 [00:29<02:30,  1.07s/it, loss=0.3509, batch_acc=0.9062, running_acc=0.9435, grad=18.3865]Training epoch 24:  13%|█▎        | 22/163 [00:29<02:30,  1.07s/it, loss=0.2738, batch_acc=1.0000, running_acc=0.9460, grad=11.8350]Training epoch 24:  14%|█▍        | 23/163 [00:29<02:21,  1.01s/it, loss=0.2738, batch_acc=1.0000, running_acc=0.9460, grad=11.8350]Training epoch 24:  14%|█▍        | 23/163 [00:29<02:21,  1.01s/it, loss=0.3761, batch_acc=1.0000, running_acc=0.9484, grad=17.1765]Training epoch 24:  15%|█▍        | 24/163 [00:30<02:15,  1.03it/s, loss=0.3761, batch_acc=1.0000, running_acc=0.9484, grad=17.1765]Training epoch 24:  15%|█▍        | 24/163 [00:30<02:15,  1.03it/s, loss=0.4829, batch_acc=0.9062, running_acc=0.9466, grad=26.4760]Training epoch 24:  15%|█▌        | 25/163 [00:32<02:37,  1.14s/it, loss=0.4829, batch_acc=0.9062, running_acc=0.9466, grad=26.4760]Training epoch 24:  15%|█▌        | 25/163 [00:32<02:37,  1.14s/it, loss=0.3283, batch_acc=0.9375, running_acc=0.9463, grad=15.0089]Training epoch 24:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.3283, batch_acc=0.9375, running_acc=0.9463, grad=15.0089]Training epoch 24:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.2672, batch_acc=0.9688, running_acc=0.9471, grad=13.0830]Training epoch 24:  17%|█▋        | 27/163 [00:34<02:16,  1.01s/it, loss=0.2672, batch_acc=0.9688, running_acc=0.9471, grad=13.0830]Training epoch 24:  17%|█▋        | 27/163 [00:34<02:16,  1.01s/it, loss=0.3787, batch_acc=0.8750, running_acc=0.9444, grad=19.0104]Training epoch 24:  17%|█▋        | 28/163 [00:34<02:10,  1.03it/s, loss=0.3787, batch_acc=0.8750, running_acc=0.9444, grad=19.0104]Training epoch 24:  17%|█▋        | 28/163 [00:34<02:10,  1.03it/s, loss=0.3346, batch_acc=0.9375, running_acc=0.9442, grad=18.4188]Training epoch 24:  18%|█▊        | 29/163 [00:36<02:34,  1.15s/it, loss=0.3346, batch_acc=0.9375, running_acc=0.9442, grad=18.4188]Training epoch 24:  18%|█▊        | 29/163 [00:36<02:34,  1.15s/it, loss=0.4038, batch_acc=0.9375, running_acc=0.9440, grad=20.3188]Training epoch 24:  18%|█▊        | 30/163 [00:37<02:22,  1.07s/it, loss=0.4038, batch_acc=0.9375, running_acc=0.9440, grad=20.3188]Training epoch 24:  18%|█▊        | 30/163 [00:37<02:22,  1.07s/it, loss=0.4620, batch_acc=0.9062, running_acc=0.9427, grad=18.2151]Training epoch 24:  19%|█▉        | 31/163 [00:38<02:13,  1.01s/it, loss=0.4620, batch_acc=0.9062, running_acc=0.9427, grad=18.2151]Training epoch 24:  19%|█▉        | 31/163 [00:38<02:13,  1.01s/it, loss=0.4472, batch_acc=0.9062, running_acc=0.9415, grad=19.4587]Training epoch 24:  20%|█▉        | 32/163 [00:39<02:16,  1.04s/it, loss=0.4472, batch_acc=0.9062, running_acc=0.9415, grad=19.4587]Training epoch 24:  20%|█▉        | 32/163 [00:39<02:16,  1.04s/it, loss=0.5313, batch_acc=0.8750, running_acc=0.9395, grad=24.0006]Training epoch 24:  20%|██        | 33/163 [00:40<02:37,  1.21s/it, loss=0.5313, batch_acc=0.8750, running_acc=0.9395, grad=24.0006]Training epoch 24:  20%|██        | 33/163 [00:40<02:37,  1.21s/it, loss=0.3181, batch_acc=0.9375, running_acc=0.9394, grad=16.2305]Training epoch 24:  21%|██        | 34/163 [00:41<02:23,  1.11s/it, loss=0.3181, batch_acc=0.9375, running_acc=0.9394, grad=16.2305]Training epoch 24:  21%|██        | 34/163 [00:41<02:23,  1.11s/it, loss=0.3399, batch_acc=0.9375, running_acc=0.9393, grad=26.5838]Training epoch 24:  21%|██▏       | 35/163 [00:42<02:13,  1.04s/it, loss=0.3399, batch_acc=0.9375, running_acc=0.9393, grad=26.5838]Training epoch 24:  21%|██▏       | 35/163 [00:42<02:13,  1.04s/it, loss=0.3352, batch_acc=1.0000, running_acc=0.9411, grad=21.0770]Training epoch 24:  22%|██▏       | 36/163 [00:43<02:18,  1.09s/it, loss=0.3352, batch_acc=1.0000, running_acc=0.9411, grad=21.0770]Training epoch 24:  22%|██▏       | 36/163 [00:43<02:18,  1.09s/it, loss=0.7437, batch_acc=0.8750, running_acc=0.9392, grad=37.0529]Training epoch 24:  23%|██▎       | 37/163 [00:44<02:14,  1.07s/it, loss=0.7437, batch_acc=0.8750, running_acc=0.9392, grad=37.0529]Training epoch 24:  23%|██▎       | 37/163 [00:44<02:14,  1.07s/it, loss=0.3659, batch_acc=0.9688, running_acc=0.9400, grad=22.3603]Training epoch 24:  23%|██▎       | 38/163 [00:45<02:06,  1.01s/it, loss=0.3659, batch_acc=0.9688, running_acc=0.9400, grad=22.3603]Training epoch 24:  23%|██▎       | 38/163 [00:45<02:06,  1.01s/it, loss=0.4892, batch_acc=0.8750, running_acc=0.9383, grad=18.2410]Training epoch 24:  24%|██▍       | 39/163 [00:46<02:00,  1.03it/s, loss=0.4892, batch_acc=0.8750, running_acc=0.9383, grad=18.2410]Training epoch 24:  24%|██▍       | 39/163 [00:46<02:00,  1.03it/s, loss=0.3918, batch_acc=0.9375, running_acc=0.9383, grad=15.7921]Training epoch 24:  25%|██▍       | 40/163 [00:48<02:17,  1.12s/it, loss=0.3918, batch_acc=0.9375, running_acc=0.9383, grad=15.7921]Training epoch 24:  25%|██▍       | 40/163 [00:48<02:17,  1.12s/it, loss=0.3478, batch_acc=0.9375, running_acc=0.9383, grad=14.9432]Training epoch 24:  25%|██▌       | 41/163 [00:49<02:09,  1.06s/it, loss=0.3478, batch_acc=0.9375, running_acc=0.9383, grad=14.9432]Training epoch 24:  25%|██▌       | 41/163 [00:49<02:09,  1.06s/it, loss=0.4426, batch_acc=0.9688, running_acc=0.9390, grad=20.5662]Training epoch 24:  26%|██▌       | 42/163 [00:49<02:01,  1.01s/it, loss=0.4426, batch_acc=0.9688, running_acc=0.9390, grad=20.5662]Training epoch 24:  26%|██▌       | 42/163 [00:49<02:01,  1.01s/it, loss=0.4202, batch_acc=0.9688, running_acc=0.9397, grad=14.1730]Training epoch 24:  26%|██▋       | 43/163 [00:50<01:56,  1.03it/s, loss=0.4202, batch_acc=0.9688, running_acc=0.9397, grad=14.1730]Training epoch 24:  26%|██▋       | 43/163 [00:50<01:56,  1.03it/s, loss=0.5548, batch_acc=0.8750, running_acc=0.9382, grad=29.1863]Training epoch 24:  27%|██▋       | 44/163 [00:52<02:25,  1.22s/it, loss=0.5548, batch_acc=0.8750, running_acc=0.9382, grad=29.1863]Training epoch 24:  27%|██▋       | 44/163 [00:52<02:25,  1.22s/it, loss=0.3600, batch_acc=0.9688, running_acc=0.9389, grad=17.7494]Training epoch 24:  28%|██▊       | 45/163 [00:53<02:11,  1.12s/it, loss=0.3600, batch_acc=0.9688, running_acc=0.9389, grad=17.7494]Training epoch 24:  28%|██▊       | 45/163 [00:53<02:11,  1.12s/it, loss=0.3487, batch_acc=0.9688, running_acc=0.9396, grad=22.5379]Training epoch 24:  28%|██▊       | 46/163 [00:54<02:02,  1.05s/it, loss=0.3487, batch_acc=0.9688, running_acc=0.9396, grad=22.5379]Training epoch 24:  28%|██▊       | 46/163 [00:54<02:02,  1.05s/it, loss=0.5154, batch_acc=0.9375, running_acc=0.9395, grad=26.9517]Training epoch 24:  29%|██▉       | 47/163 [00:55<01:55,  1.00it/s, loss=0.5154, batch_acc=0.9375, running_acc=0.9395, grad=26.9517]Training epoch 24:  29%|██▉       | 47/163 [00:55<01:55,  1.00it/s, loss=0.2713, batch_acc=1.0000, running_acc=0.9408, grad=11.7545]Training epoch 24:  29%|██▉       | 48/163 [00:57<02:25,  1.27s/it, loss=0.2713, batch_acc=1.0000, running_acc=0.9408, grad=11.7545]Training epoch 24:  29%|██▉       | 48/163 [00:57<02:25,  1.27s/it, loss=0.4715, batch_acc=0.9062, running_acc=0.9401, grad=21.8826]Training epoch 24:  30%|███       | 49/163 [00:58<02:11,  1.15s/it, loss=0.4715, batch_acc=0.9062, running_acc=0.9401, grad=21.8826]Training epoch 24:  30%|███       | 49/163 [00:58<02:11,  1.15s/it, loss=0.4743, batch_acc=0.9688, running_acc=0.9407, grad=28.5502]Training epoch 24:  31%|███       | 50/163 [00:58<02:00,  1.07s/it, loss=0.4743, batch_acc=0.9688, running_acc=0.9407, grad=28.5502]Training epoch 24:  31%|███       | 50/163 [00:58<02:00,  1.07s/it, loss=0.3679, batch_acc=0.9688, running_acc=0.9413, grad=18.9885]Training epoch 24:  31%|███▏      | 51/163 [00:59<01:53,  1.01s/it, loss=0.3679, batch_acc=0.9688, running_acc=0.9413, grad=18.9885]Training epoch 24:  31%|███▏      | 51/163 [00:59<01:53,  1.01s/it, loss=0.4417, batch_acc=0.9375, running_acc=0.9412, grad=22.1512]Training epoch 24:  32%|███▏      | 52/163 [01:01<02:17,  1.24s/it, loss=0.4417, batch_acc=0.9375, running_acc=0.9412, grad=22.1512]Training epoch 24:  32%|███▏      | 52/163 [01:01<02:17,  1.24s/it, loss=0.3820, batch_acc=0.9688, running_acc=0.9417, grad=17.5326]Training epoch 24:  33%|███▎      | 53/163 [01:02<02:05,  1.14s/it, loss=0.3820, batch_acc=0.9688, running_acc=0.9417, grad=17.5326]Training epoch 24:  33%|███▎      | 53/163 [01:02<02:05,  1.14s/it, loss=0.5466, batch_acc=0.9062, running_acc=0.9410, grad=21.8468]Training epoch 24:  33%|███▎      | 54/163 [01:03<01:56,  1.06s/it, loss=0.5466, batch_acc=0.9062, running_acc=0.9410, grad=21.8468]Training epoch 24:  33%|███▎      | 54/163 [01:03<01:56,  1.06s/it, loss=0.4222, batch_acc=0.9375, running_acc=0.9410, grad=22.9310]Training epoch 24:  34%|███▎      | 55/163 [01:04<01:49,  1.01s/it, loss=0.4222, batch_acc=0.9375, running_acc=0.9410, grad=22.9310]Training epoch 24:  34%|███▎      | 55/163 [01:04<01:49,  1.01s/it, loss=0.3411, batch_acc=0.9688, running_acc=0.9415, grad=17.7765]Training epoch 24:  34%|███▍      | 56/163 [01:05<01:48,  1.02s/it, loss=0.3411, batch_acc=0.9688, running_acc=0.9415, grad=17.7765]Training epoch 24:  34%|███▍      | 56/163 [01:05<01:48,  1.02s/it, loss=0.4311, batch_acc=0.9688, running_acc=0.9420, grad=26.7940]Training epoch 24:  35%|███▍      | 57/163 [01:06<01:49,  1.03s/it, loss=0.4311, batch_acc=0.9688, running_acc=0.9420, grad=26.7940]Training epoch 24:  35%|███▍      | 57/163 [01:06<01:49,  1.03s/it, loss=0.5208, batch_acc=0.9062, running_acc=0.9413, grad=26.5293]Training epoch 24:  36%|███▌      | 58/163 [01:07<01:43,  1.01it/s, loss=0.5208, batch_acc=0.9062, running_acc=0.9413, grad=26.5293]Training epoch 24:  36%|███▌      | 58/163 [01:07<01:43,  1.01it/s, loss=0.4638, batch_acc=0.8750, running_acc=0.9402, grad=31.6198]Training epoch 24:  36%|███▌      | 59/163 [01:08<01:39,  1.05it/s, loss=0.4638, batch_acc=0.8750, running_acc=0.9402, grad=31.6198]Training epoch 24:  36%|███▌      | 59/163 [01:08<01:39,  1.05it/s, loss=0.3286, batch_acc=0.9688, running_acc=0.9407, grad=17.7059]Training epoch 24:  37%|███▋      | 60/163 [01:09<01:46,  1.04s/it, loss=0.3286, batch_acc=0.9688, running_acc=0.9407, grad=17.7059]Training epoch 24:  37%|███▋      | 60/163 [01:09<01:46,  1.04s/it, loss=0.4113, batch_acc=0.9688, running_acc=0.9411, grad=20.5704]Training epoch 24:  37%|███▋      | 61/163 [01:10<02:01,  1.19s/it, loss=0.4113, batch_acc=0.9688, running_acc=0.9411, grad=20.5704]Training epoch 24:  37%|███▋      | 61/163 [01:10<02:01,  1.19s/it, loss=0.4495, batch_acc=0.9375, running_acc=0.9411, grad=22.2892]Training epoch 24:  38%|███▊      | 62/163 [01:11<01:50,  1.10s/it, loss=0.4495, batch_acc=0.9375, running_acc=0.9411, grad=22.2892]Training epoch 24:  38%|███▊      | 62/163 [01:11<01:50,  1.10s/it, loss=0.3895, batch_acc=1.0000, running_acc=0.9420, grad=18.8780]Training epoch 24:  39%|███▊      | 63/163 [01:12<01:43,  1.03s/it, loss=0.3895, batch_acc=1.0000, running_acc=0.9420, grad=18.8780]Training epoch 24:  39%|███▊      | 63/163 [01:12<01:43,  1.03s/it, loss=0.2853, batch_acc=0.9688, running_acc=0.9425, grad=16.7072]Training epoch 24:  39%|███▉      | 64/163 [01:13<01:38,  1.00it/s, loss=0.2853, batch_acc=0.9688, running_acc=0.9425, grad=16.7072]Training epoch 24:  39%|███▉      | 64/163 [01:13<01:38,  1.00it/s, loss=0.5051, batch_acc=0.9062, running_acc=0.9419, grad=25.7263]Training epoch 24:  40%|███▉      | 65/163 [01:15<01:51,  1.14s/it, loss=0.5051, batch_acc=0.9062, running_acc=0.9419, grad=25.7263]Training epoch 24:  40%|███▉      | 65/163 [01:15<01:51,  1.14s/it, loss=0.4143, batch_acc=0.9375, running_acc=0.9418, grad=25.0818]Training epoch 24:  40%|████      | 66/163 [01:15<01:42,  1.06s/it, loss=0.4143, batch_acc=0.9375, running_acc=0.9418, grad=25.0818]Training epoch 24:  40%|████      | 66/163 [01:15<01:42,  1.06s/it, loss=0.3059, batch_acc=0.9688, running_acc=0.9422, grad=16.5392]Training epoch 24:  41%|████      | 67/163 [01:16<01:36,  1.01s/it, loss=0.3059, batch_acc=0.9688, running_acc=0.9422, grad=16.5392]Training epoch 24:  41%|████      | 67/163 [01:16<01:36,  1.01s/it, loss=0.4270, batch_acc=0.9688, running_acc=0.9426, grad=19.6943]Training epoch 24:  42%|████▏     | 68/163 [01:17<01:38,  1.04s/it, loss=0.4270, batch_acc=0.9688, running_acc=0.9426, grad=19.6943]Training epoch 24:  42%|████▏     | 68/163 [01:17<01:38,  1.04s/it, loss=0.3970, batch_acc=1.0000, running_acc=0.9435, grad=24.4070]Training epoch 24:  42%|████▏     | 69/163 [01:19<01:55,  1.22s/it, loss=0.3970, batch_acc=1.0000, running_acc=0.9435, grad=24.4070]Training epoch 24:  42%|████▏     | 69/163 [01:19<01:55,  1.22s/it, loss=0.4546, batch_acc=0.9062, running_acc=0.9429, grad=26.7204]Training epoch 24:  43%|████▎     | 70/163 [01:20<01:44,  1.12s/it, loss=0.4546, batch_acc=0.9062, running_acc=0.9429, grad=26.7204]Training epoch 24:  43%|████▎     | 70/163 [01:20<01:44,  1.12s/it, loss=0.3098, batch_acc=0.9688, running_acc=0.9433, grad=14.0122]Training epoch 24:  44%|████▎     | 71/163 [01:21<01:36,  1.05s/it, loss=0.3098, batch_acc=0.9688, running_acc=0.9433, grad=14.0122]Training epoch 24:  44%|████▎     | 71/163 [01:21<01:36,  1.05s/it, loss=0.4621, batch_acc=0.8750, running_acc=0.9423, grad=21.0189]Training epoch 24:  44%|████▍     | 72/163 [01:22<01:42,  1.12s/it, loss=0.4621, batch_acc=0.8750, running_acc=0.9423, grad=21.0189]Training epoch 24:  44%|████▍     | 72/163 [01:22<01:42,  1.12s/it, loss=0.3279, batch_acc=0.9375, running_acc=0.9423, grad=16.1775]Training epoch 24:  45%|████▍     | 73/163 [01:24<02:12,  1.47s/it, loss=0.3279, batch_acc=0.9375, running_acc=0.9423, grad=16.1775]Training epoch 24:  45%|████▍     | 73/163 [01:24<02:12,  1.47s/it, loss=0.3212, batch_acc=0.9375, running_acc=0.9422, grad=20.2901]Training epoch 24:  45%|████▌     | 74/163 [01:25<01:55,  1.29s/it, loss=0.3212, batch_acc=0.9375, running_acc=0.9422, grad=20.2901]Training epoch 24:  45%|████▌     | 74/163 [01:25<01:55,  1.29s/it, loss=0.3089, batch_acc=0.9062, running_acc=0.9417, grad=15.1193]Training epoch 24:  46%|████▌     | 75/163 [01:26<01:42,  1.17s/it, loss=0.3089, batch_acc=0.9062, running_acc=0.9417, grad=15.1193]Training epoch 24:  46%|████▌     | 75/163 [01:26<01:42,  1.17s/it, loss=0.4743, batch_acc=0.9375, running_acc=0.9417, grad=23.2547]Training epoch 24:  47%|████▋     | 76/163 [01:27<01:34,  1.08s/it, loss=0.4743, batch_acc=0.9375, running_acc=0.9417, grad=23.2547]Training epoch 24:  47%|████▋     | 76/163 [01:27<01:34,  1.08s/it, loss=0.5116, batch_acc=0.9688, running_acc=0.9420, grad=26.4926]Training epoch 24:  47%|████▋     | 77/163 [01:29<01:54,  1.33s/it, loss=0.5116, batch_acc=0.9688, running_acc=0.9420, grad=26.4926]Training epoch 24:  47%|████▋     | 77/163 [01:29<01:54,  1.33s/it, loss=0.3319, batch_acc=0.9062, running_acc=0.9416, grad=14.0453]Training epoch 24:  48%|████▊     | 78/163 [01:30<01:41,  1.19s/it, loss=0.3319, batch_acc=0.9062, running_acc=0.9416, grad=14.0453]Training epoch 24:  48%|████▊     | 78/163 [01:30<01:41,  1.19s/it, loss=0.2846, batch_acc=0.9688, running_acc=0.9419, grad=13.7549]Training epoch 24:  48%|████▊     | 79/163 [01:31<01:32,  1.10s/it, loss=0.2846, batch_acc=0.9688, running_acc=0.9419, grad=13.7549]Training epoch 24:  48%|████▊     | 79/163 [01:31<01:32,  1.10s/it, loss=0.3762, batch_acc=0.9688, running_acc=0.9422, grad=23.8045]Training epoch 24:  49%|████▉     | 80/163 [01:32<01:25,  1.03s/it, loss=0.3762, batch_acc=0.9688, running_acc=0.9422, grad=23.8045]Training epoch 24:  49%|████▉     | 80/163 [01:32<01:25,  1.03s/it, loss=0.3366, batch_acc=0.9688, running_acc=0.9426, grad=19.5113]Training epoch 24:  50%|████▉     | 81/163 [01:33<01:40,  1.22s/it, loss=0.3366, batch_acc=0.9688, running_acc=0.9426, grad=19.5113]Training epoch 24:  50%|████▉     | 81/163 [01:33<01:40,  1.22s/it, loss=0.4621, batch_acc=1.0000, running_acc=0.9433, grad=18.5270]Training epoch 24:  50%|█████     | 82/163 [01:34<01:30,  1.12s/it, loss=0.4621, batch_acc=1.0000, running_acc=0.9433, grad=18.5270]Training epoch 24:  50%|█████     | 82/163 [01:34<01:30,  1.12s/it, loss=0.4007, batch_acc=0.9375, running_acc=0.9432, grad=18.7786]Training epoch 24:  51%|█████     | 83/163 [01:35<01:23,  1.05s/it, loss=0.4007, batch_acc=0.9375, running_acc=0.9432, grad=18.7786]Training epoch 24:  51%|█████     | 83/163 [01:35<01:23,  1.05s/it, loss=0.3748, batch_acc=0.9375, running_acc=0.9431, grad=20.6401]Training epoch 24:  52%|█████▏    | 84/163 [01:36<01:18,  1.00it/s, loss=0.3748, batch_acc=0.9375, running_acc=0.9431, grad=20.6401]Training epoch 24:  52%|█████▏    | 84/163 [01:36<01:18,  1.00it/s, loss=0.3204, batch_acc=0.9688, running_acc=0.9435, grad=16.0314]Training epoch 24:  52%|█████▏    | 85/163 [01:38<01:34,  1.21s/it, loss=0.3204, batch_acc=0.9688, running_acc=0.9435, grad=16.0314]Training epoch 24:  52%|█████▏    | 85/163 [01:38<01:34,  1.21s/it, loss=0.4002, batch_acc=0.9688, running_acc=0.9437, grad=22.6839]Training epoch 24:  53%|█████▎    | 86/163 [01:39<01:25,  1.11s/it, loss=0.4002, batch_acc=0.9688, running_acc=0.9437, grad=22.6839]Training epoch 24:  53%|█████▎    | 86/163 [01:39<01:25,  1.11s/it, loss=0.6582, batch_acc=0.8750, running_acc=0.9430, grad=27.2602]Training epoch 24:  53%|█████▎    | 87/163 [01:39<01:20,  1.06s/it, loss=0.6582, batch_acc=0.8750, running_acc=0.9430, grad=27.2602]Training epoch 24:  53%|█████▎    | 87/163 [01:39<01:20,  1.06s/it, loss=0.4293, batch_acc=0.9375, running_acc=0.9429, grad=21.3961]Training epoch 24:  54%|█████▍    | 88/163 [01:40<01:17,  1.04s/it, loss=0.4293, batch_acc=0.9375, running_acc=0.9429, grad=21.3961]Training epoch 24:  54%|█████▍    | 88/163 [01:40<01:17,  1.04s/it, loss=0.4386, batch_acc=0.9375, running_acc=0.9428, grad=28.6706]Training epoch 24:  55%|█████▍    | 89/163 [01:42<01:25,  1.16s/it, loss=0.4386, batch_acc=0.9375, running_acc=0.9428, grad=28.6706]Training epoch 24:  55%|█████▍    | 89/163 [01:42<01:25,  1.16s/it, loss=0.4502, batch_acc=0.9375, running_acc=0.9428, grad=18.4525]Training epoch 24:  55%|█████▌    | 90/163 [01:43<01:18,  1.08s/it, loss=0.4502, batch_acc=0.9375, running_acc=0.9428, grad=18.4525]Training epoch 24:  55%|█████▌    | 90/163 [01:43<01:18,  1.08s/it, loss=0.4844, batch_acc=0.9688, running_acc=0.9431, grad=26.2422]Training epoch 24:  56%|█████▌    | 91/163 [01:44<01:15,  1.05s/it, loss=0.4844, batch_acc=0.9688, running_acc=0.9431, grad=26.2422]Training epoch 24:  56%|█████▌    | 91/163 [01:44<01:15,  1.05s/it, loss=0.3165, batch_acc=0.9688, running_acc=0.9433, grad=14.7428]Training epoch 24:  56%|█████▋    | 92/163 [01:45<01:11,  1.00s/it, loss=0.3165, batch_acc=0.9688, running_acc=0.9433, grad=14.7428]Training epoch 24:  56%|█████▋    | 92/163 [01:45<01:11,  1.00s/it, loss=0.3614, batch_acc=0.9688, running_acc=0.9436, grad=17.5835]Training epoch 24:  57%|█████▋    | 93/163 [01:47<01:27,  1.26s/it, loss=0.3614, batch_acc=0.9688, running_acc=0.9436, grad=17.5835]Training epoch 24:  57%|█████▋    | 93/163 [01:47<01:27,  1.26s/it, loss=0.3155, batch_acc=1.0000, running_acc=0.9442, grad=20.3325]Training epoch 24:  58%|█████▊    | 94/163 [01:47<01:18,  1.14s/it, loss=0.3155, batch_acc=1.0000, running_acc=0.9442, grad=20.3325]Training epoch 24:  58%|█████▊    | 94/163 [01:47<01:18,  1.14s/it, loss=0.5147, batch_acc=0.9062, running_acc=0.9438, grad=25.0688]Training epoch 24:  58%|█████▊    | 95/163 [01:48<01:13,  1.08s/it, loss=0.5147, batch_acc=0.9062, running_acc=0.9438, grad=25.0688]Training epoch 24:  58%|█████▊    | 95/163 [01:48<01:13,  1.08s/it, loss=0.3557, batch_acc=0.9375, running_acc=0.9437, grad=15.9549]Training epoch 24:  59%|█████▉    | 96/163 [01:49<01:08,  1.02s/it, loss=0.3557, batch_acc=0.9375, running_acc=0.9437, grad=15.9549]Training epoch 24:  59%|█████▉    | 96/163 [01:49<01:08,  1.02s/it, loss=0.3879, batch_acc=1.0000, running_acc=0.9443, grad=20.6131]Training epoch 24:  60%|█████▉    | 97/163 [01:51<01:24,  1.28s/it, loss=0.3879, batch_acc=1.0000, running_acc=0.9443, grad=20.6131]Training epoch 24:  60%|█████▉    | 97/163 [01:51<01:24,  1.28s/it, loss=0.2926, batch_acc=1.0000, running_acc=0.9449, grad=15.9701]Training epoch 24:  60%|██████    | 98/163 [01:52<01:15,  1.16s/it, loss=0.2926, batch_acc=1.0000, running_acc=0.9449, grad=15.9701]Training epoch 24:  60%|██████    | 98/163 [01:52<01:15,  1.16s/it, loss=0.5210, batch_acc=0.8438, running_acc=0.9439, grad=27.2939]Training epoch 24:  61%|██████    | 99/163 [01:53<01:11,  1.11s/it, loss=0.5210, batch_acc=0.8438, running_acc=0.9439, grad=27.2939]Training epoch 24:  61%|██████    | 99/163 [01:53<01:11,  1.11s/it, loss=0.4241, batch_acc=0.9375, running_acc=0.9438, grad=20.7409]Training epoch 24:  61%|██████▏   | 100/163 [01:54<01:05,  1.04s/it, loss=0.4241, batch_acc=0.9375, running_acc=0.9438, grad=20.7409]Training epoch 24:  61%|██████▏   | 100/163 [01:54<01:05,  1.04s/it, loss=0.3385, batch_acc=1.0000, running_acc=0.9444, grad=15.0084]Training epoch 24:  62%|██████▏   | 101/163 [01:55<01:05,  1.06s/it, loss=0.3385, batch_acc=1.0000, running_acc=0.9444, grad=15.0084]Training epoch 24:  62%|██████▏   | 101/163 [01:55<01:05,  1.06s/it, loss=0.3581, batch_acc=0.9375, running_acc=0.9443, grad=21.6326]Training epoch 24:  63%|██████▎   | 102/163 [01:56<01:01,  1.01s/it, loss=0.3581, batch_acc=0.9375, running_acc=0.9443, grad=21.6326]Training epoch 24:  63%|██████▎   | 102/163 [01:56<01:01,  1.01s/it, loss=0.4663, batch_acc=0.9375, running_acc=0.9442, grad=27.5772]Training epoch 24:  63%|██████▎   | 103/163 [01:57<00:58,  1.03it/s, loss=0.4663, batch_acc=0.9375, running_acc=0.9442, grad=27.5772]Training epoch 24:  63%|██████▎   | 103/163 [01:57<00:58,  1.03it/s, loss=0.4753, batch_acc=0.9062, running_acc=0.9439, grad=25.6239]Training epoch 24:  64%|██████▍   | 104/163 [01:58<00:57,  1.03it/s, loss=0.4753, batch_acc=0.9062, running_acc=0.9439, grad=25.6239]Training epoch 24:  64%|██████▍   | 104/163 [01:58<00:57,  1.03it/s, loss=0.3940, batch_acc=0.9375, running_acc=0.9438, grad=17.6562]Training epoch 24:  64%|██████▍   | 105/163 [01:59<01:09,  1.20s/it, loss=0.3940, batch_acc=0.9375, running_acc=0.9438, grad=17.6562]Training epoch 24:  64%|██████▍   | 105/163 [01:59<01:09,  1.20s/it, loss=0.3588, batch_acc=0.9688, running_acc=0.9440, grad=16.7594]Training epoch 24:  65%|██████▌   | 106/163 [02:00<01:02,  1.10s/it, loss=0.3588, batch_acc=0.9688, running_acc=0.9440, grad=16.7594]Training epoch 24:  65%|██████▌   | 106/163 [02:00<01:02,  1.10s/it, loss=0.4100, batch_acc=0.9062, running_acc=0.9437, grad=22.1434]Training epoch 24:  66%|██████▌   | 107/163 [02:01<00:57,  1.04s/it, loss=0.4100, batch_acc=0.9062, running_acc=0.9437, grad=22.1434]Training epoch 24:  66%|██████▌   | 107/163 [02:01<00:57,  1.04s/it, loss=0.2890, batch_acc=0.9688, running_acc=0.9439, grad=18.0676]Training epoch 24:  66%|██████▋   | 108/163 [02:02<00:58,  1.06s/it, loss=0.2890, batch_acc=0.9688, running_acc=0.9439, grad=18.0676]Training epoch 24:  66%|██████▋   | 108/163 [02:02<00:58,  1.06s/it, loss=0.3834, batch_acc=0.9688, running_acc=0.9442, grad=17.2222]Training epoch 24:  67%|██████▋   | 109/163 [02:04<01:04,  1.20s/it, loss=0.3834, batch_acc=0.9688, running_acc=0.9442, grad=17.2222]Training epoch 24:  67%|██████▋   | 109/163 [02:04<01:04,  1.20s/it, loss=0.3839, batch_acc=0.9062, running_acc=0.9438, grad=21.2621]Training epoch 24:  67%|██████▋   | 110/163 [02:05<00:58,  1.10s/it, loss=0.3839, batch_acc=0.9062, running_acc=0.9438, grad=21.2621]Training epoch 24:  67%|██████▋   | 110/163 [02:05<00:58,  1.10s/it, loss=0.3165, batch_acc=1.0000, running_acc=0.9443, grad=16.8793]Training epoch 24:  68%|██████▊   | 111/163 [02:06<00:53,  1.04s/it, loss=0.3165, batch_acc=1.0000, running_acc=0.9443, grad=16.8793]Training epoch 24:  68%|██████▊   | 111/163 [02:06<00:53,  1.04s/it, loss=0.3185, batch_acc=0.9688, running_acc=0.9445, grad=19.5039]Training epoch 24:  69%|██████▊   | 112/163 [02:06<00:51,  1.00s/it, loss=0.3185, batch_acc=0.9688, running_acc=0.9445, grad=19.5039]Training epoch 24:  69%|██████▊   | 112/163 [02:06<00:51,  1.00s/it, loss=0.3482, batch_acc=0.9375, running_acc=0.9445, grad=17.4690]Training epoch 24:  69%|██████▉   | 113/163 [02:08<01:02,  1.25s/it, loss=0.3482, batch_acc=0.9375, running_acc=0.9445, grad=17.4690]Training epoch 24:  69%|██████▉   | 113/163 [02:08<01:02,  1.25s/it, loss=0.3381, batch_acc=0.9688, running_acc=0.9447, grad=20.6372]Training epoch 24:  70%|██████▉   | 114/163 [02:09<00:55,  1.14s/it, loss=0.3381, batch_acc=0.9688, running_acc=0.9447, grad=20.6372]Training epoch 24:  70%|██████▉   | 114/163 [02:09<00:55,  1.14s/it, loss=0.5953, batch_acc=0.9062, running_acc=0.9444, grad=26.2101]Training epoch 24:  71%|███████   | 115/163 [02:10<00:51,  1.06s/it, loss=0.5953, batch_acc=0.9062, running_acc=0.9444, grad=26.2101]Training epoch 24:  71%|███████   | 115/163 [02:10<00:51,  1.06s/it, loss=0.4473, batch_acc=0.9688, running_acc=0.9446, grad=27.2830]Training epoch 24:  71%|███████   | 116/163 [02:11<00:47,  1.01s/it, loss=0.4473, batch_acc=0.9688, running_acc=0.9446, grad=27.2830]Training epoch 24:  71%|███████   | 116/163 [02:11<00:47,  1.01s/it, loss=0.3541, batch_acc=0.9062, running_acc=0.9442, grad=18.5094]Training epoch 24:  72%|███████▏  | 117/163 [02:13<00:58,  1.27s/it, loss=0.3541, batch_acc=0.9062, running_acc=0.9442, grad=18.5094]Training epoch 24:  72%|███████▏  | 117/163 [02:13<00:58,  1.27s/it, loss=0.3462, batch_acc=0.9688, running_acc=0.9444, grad=18.0350]Training epoch 24:  72%|███████▏  | 118/163 [02:14<00:51,  1.15s/it, loss=0.3462, batch_acc=0.9688, running_acc=0.9444, grad=18.0350]Training epoch 24:  72%|███████▏  | 118/163 [02:14<00:51,  1.15s/it, loss=0.2995, batch_acc=1.0000, running_acc=0.9449, grad=14.4420]Training epoch 24:  73%|███████▎  | 119/163 [02:15<00:47,  1.07s/it, loss=0.2995, batch_acc=1.0000, running_acc=0.9449, grad=14.4420]Training epoch 24:  73%|███████▎  | 119/163 [02:15<00:47,  1.07s/it, loss=0.3346, batch_acc=0.9688, running_acc=0.9451, grad=17.4241]Training epoch 24:  74%|███████▎  | 120/163 [02:16<00:43,  1.02s/it, loss=0.3346, batch_acc=0.9688, running_acc=0.9451, grad=17.4241]Training epoch 24:  74%|███████▎  | 120/163 [02:16<00:43,  1.02s/it, loss=0.3848, batch_acc=0.9062, running_acc=0.9448, grad=19.8113]Training epoch 24:  74%|███████▍  | 121/163 [02:18<00:55,  1.32s/it, loss=0.3848, batch_acc=0.9062, running_acc=0.9448, grad=19.8113]Training epoch 24:  74%|███████▍  | 121/163 [02:18<00:55,  1.32s/it, loss=0.3343, batch_acc=0.9062, running_acc=0.9445, grad=18.4525]Training epoch 24:  75%|███████▍  | 122/163 [02:18<00:48,  1.19s/it, loss=0.3343, batch_acc=0.9062, running_acc=0.9445, grad=18.4525]Training epoch 24:  75%|███████▍  | 122/163 [02:18<00:48,  1.19s/it, loss=0.3866, batch_acc=0.9688, running_acc=0.9447, grad=30.3118]Training epoch 24:  75%|███████▌  | 123/163 [02:19<00:43,  1.10s/it, loss=0.3866, batch_acc=0.9688, running_acc=0.9447, grad=30.3118]Training epoch 24:  75%|███████▌  | 123/163 [02:19<00:43,  1.10s/it, loss=0.4633, batch_acc=0.9062, running_acc=0.9444, grad=19.3063]Training epoch 24:  76%|███████▌  | 124/163 [02:20<00:40,  1.03s/it, loss=0.4633, batch_acc=0.9062, running_acc=0.9444, grad=19.3063]Training epoch 24:  76%|███████▌  | 124/163 [02:20<00:40,  1.03s/it, loss=0.2527, batch_acc=1.0000, running_acc=0.9448, grad=13.3679]Training epoch 24:  77%|███████▋  | 125/163 [02:22<00:44,  1.17s/it, loss=0.2527, batch_acc=1.0000, running_acc=0.9448, grad=13.3679]Training epoch 24:  77%|███████▋  | 125/163 [02:22<00:44,  1.17s/it, loss=0.3821, batch_acc=0.9375, running_acc=0.9447, grad=14.5608]Training epoch 24:  77%|███████▋  | 126/163 [02:23<00:40,  1.08s/it, loss=0.3821, batch_acc=0.9375, running_acc=0.9447, grad=14.5608]Training epoch 24:  77%|███████▋  | 126/163 [02:23<00:40,  1.08s/it, loss=0.2614, batch_acc=0.9375, running_acc=0.9447, grad=14.3080]Training epoch 24:  78%|███████▊  | 127/163 [02:23<00:36,  1.02s/it, loss=0.2614, batch_acc=0.9375, running_acc=0.9447, grad=14.3080]Training epoch 24:  78%|███████▊  | 127/163 [02:23<00:36,  1.02s/it, loss=0.5206, batch_acc=0.9062, running_acc=0.9444, grad=24.0515]Training epoch 24:  79%|███████▊  | 128/163 [02:24<00:34,  1.02it/s, loss=0.5206, batch_acc=0.9062, running_acc=0.9444, grad=24.0515]Training epoch 24:  79%|███████▊  | 128/163 [02:24<00:34,  1.02it/s, loss=0.2064, batch_acc=1.0000, running_acc=0.9448, grad=12.6381]Training epoch 24:  79%|███████▉  | 129/163 [02:26<00:38,  1.12s/it, loss=0.2064, batch_acc=1.0000, running_acc=0.9448, grad=12.6381]Training epoch 24:  79%|███████▉  | 129/163 [02:26<00:38,  1.12s/it, loss=0.4024, batch_acc=0.9062, running_acc=0.9445, grad=16.9251]Training epoch 24:  80%|███████▉  | 130/163 [02:27<00:34,  1.05s/it, loss=0.4024, batch_acc=0.9062, running_acc=0.9445, grad=16.9251]Training epoch 24:  80%|███████▉  | 130/163 [02:27<00:34,  1.05s/it, loss=0.4296, batch_acc=0.9688, running_acc=0.9447, grad=30.0283]Training epoch 24:  80%|████████  | 131/163 [02:28<00:31,  1.00it/s, loss=0.4296, batch_acc=0.9688, running_acc=0.9447, grad=30.0283]Training epoch 24:  80%|████████  | 131/163 [02:28<00:31,  1.00it/s, loss=0.4419, batch_acc=0.9375, running_acc=0.9447, grad=23.0778]Training epoch 24:  81%|████████  | 132/163 [02:28<00:30,  1.02it/s, loss=0.4419, batch_acc=0.9375, running_acc=0.9447, grad=23.0778]Training epoch 24:  81%|████████  | 132/163 [02:28<00:30,  1.02it/s, loss=0.3024, batch_acc=0.9688, running_acc=0.9448, grad=22.8235]Training epoch 24:  82%|████████▏ | 133/163 [02:31<00:39,  1.31s/it, loss=0.3024, batch_acc=0.9688, running_acc=0.9448, grad=22.8235]Training epoch 24:  82%|████████▏ | 133/163 [02:31<00:39,  1.31s/it, loss=0.3374, batch_acc=0.9688, running_acc=0.9450, grad=23.3090]Training epoch 24:  82%|████████▏ | 134/163 [02:31<00:34,  1.18s/it, loss=0.3374, batch_acc=0.9688, running_acc=0.9450, grad=23.3090]Training epoch 24:  82%|████████▏ | 134/163 [02:31<00:34,  1.18s/it, loss=0.4497, batch_acc=0.9375, running_acc=0.9450, grad=29.7476]Training epoch 24:  83%|████████▎ | 135/163 [02:32<00:30,  1.09s/it, loss=0.4497, batch_acc=0.9375, running_acc=0.9450, grad=29.7476]Training epoch 24:  83%|████████▎ | 135/163 [02:32<00:30,  1.09s/it, loss=0.3591, batch_acc=0.9375, running_acc=0.9449, grad=18.5579]Training epoch 24:  83%|████████▎ | 136/163 [02:33<00:27,  1.03s/it, loss=0.3591, batch_acc=0.9375, running_acc=0.9449, grad=18.5579]Training epoch 24:  83%|████████▎ | 136/163 [02:33<00:27,  1.03s/it, loss=0.4687, batch_acc=0.9062, running_acc=0.9446, grad=31.0857]Training epoch 24:  84%|████████▍ | 137/163 [02:36<00:36,  1.42s/it, loss=0.4687, batch_acc=0.9062, running_acc=0.9446, grad=31.0857]Training epoch 24:  84%|████████▍ | 137/163 [02:36<00:36,  1.42s/it, loss=0.3925, batch_acc=0.9375, running_acc=0.9446, grad=24.0449]Training epoch 24:  85%|████████▍ | 138/163 [02:36<00:31,  1.26s/it, loss=0.3925, batch_acc=0.9375, running_acc=0.9446, grad=24.0449]Training epoch 24:  85%|████████▍ | 138/163 [02:36<00:31,  1.26s/it, loss=0.2826, batch_acc=0.9375, running_acc=0.9445, grad=11.6366]Training epoch 24:  85%|████████▌ | 139/163 [02:37<00:27,  1.14s/it, loss=0.2826, batch_acc=0.9375, running_acc=0.9445, grad=11.6366]Training epoch 24:  85%|████████▌ | 139/163 [02:37<00:27,  1.14s/it, loss=0.3092, batch_acc=0.9375, running_acc=0.9445, grad=17.1927]Training epoch 24:  86%|████████▌ | 140/163 [02:38<00:24,  1.06s/it, loss=0.3092, batch_acc=0.9375, running_acc=0.9445, grad=17.1927]Training epoch 24:  86%|████████▌ | 140/163 [02:38<00:24,  1.06s/it, loss=0.4598, batch_acc=0.9062, running_acc=0.9442, grad=30.4791]Training epoch 24:  87%|████████▋ | 141/163 [02:40<00:29,  1.33s/it, loss=0.4598, batch_acc=0.9062, running_acc=0.9442, grad=30.4791]Training epoch 24:  87%|████████▋ | 141/163 [02:40<00:29,  1.33s/it, loss=0.5970, batch_acc=0.8438, running_acc=0.9435, grad=31.8511]Training epoch 24:  87%|████████▋ | 142/163 [02:41<00:25,  1.19s/it, loss=0.5970, batch_acc=0.8438, running_acc=0.9435, grad=31.8511]Training epoch 24:  87%|████████▋ | 142/163 [02:41<00:25,  1.19s/it, loss=0.5347, batch_acc=0.8750, running_acc=0.9430, grad=24.8307]Training epoch 24:  88%|████████▊ | 143/163 [02:42<00:21,  1.10s/it, loss=0.5347, batch_acc=0.8750, running_acc=0.9430, grad=24.8307]Training epoch 24:  88%|████████▊ | 143/163 [02:42<00:21,  1.10s/it, loss=0.5230, batch_acc=0.9062, running_acc=0.9427, grad=22.6505]Training epoch 24:  88%|████████▊ | 144/163 [02:43<00:19,  1.03s/it, loss=0.5230, batch_acc=0.9062, running_acc=0.9427, grad=22.6505]Training epoch 24:  88%|████████▊ | 144/163 [02:43<00:19,  1.03s/it, loss=0.2586, batch_acc=1.0000, running_acc=0.9431, grad=16.3893]Training epoch 24:  89%|████████▉ | 145/163 [02:44<00:19,  1.07s/it, loss=0.2586, batch_acc=1.0000, running_acc=0.9431, grad=16.3893]Training epoch 24:  89%|████████▉ | 145/163 [02:44<00:19,  1.07s/it, loss=0.4775, batch_acc=0.9688, running_acc=0.9433, grad=23.9510]Training epoch 24:  90%|████████▉ | 146/163 [02:45<00:17,  1.02s/it, loss=0.4775, batch_acc=0.9688, running_acc=0.9433, grad=23.9510]Training epoch 24:  90%|████████▉ | 146/163 [02:45<00:17,  1.02s/it, loss=0.3200, batch_acc=0.9688, running_acc=0.9435, grad=16.1770]Training epoch 24:  90%|█████████ | 147/163 [02:46<00:15,  1.03it/s, loss=0.3200, batch_acc=0.9688, running_acc=0.9435, grad=16.1770]Training epoch 24:  90%|█████████ | 147/163 [02:46<00:15,  1.03it/s, loss=0.4371, batch_acc=0.9062, running_acc=0.9432, grad=21.1185]Training epoch 24:  91%|█████████ | 148/163 [02:47<00:14,  1.06it/s, loss=0.4371, batch_acc=0.9062, running_acc=0.9432, grad=21.1185]Training epoch 24:  91%|█████████ | 148/163 [02:47<00:14,  1.06it/s, loss=0.3435, batch_acc=0.9375, running_acc=0.9432, grad=15.7376]Training epoch 24:  91%|█████████▏| 149/163 [02:48<00:16,  1.20s/it, loss=0.3435, batch_acc=0.9375, running_acc=0.9432, grad=15.7376]Training epoch 24:  91%|█████████▏| 149/163 [02:48<00:16,  1.20s/it, loss=0.3841, batch_acc=0.9375, running_acc=0.9432, grad=19.9249]Training epoch 24:  92%|█████████▏| 150/163 [02:49<00:14,  1.11s/it, loss=0.3841, batch_acc=0.9375, running_acc=0.9432, grad=19.9249]Training epoch 24:  92%|█████████▏| 150/163 [02:49<00:14,  1.11s/it, loss=0.3085, batch_acc=0.9688, running_acc=0.9433, grad=21.9253]Training epoch 24:  93%|█████████▎| 151/163 [02:50<00:12,  1.06s/it, loss=0.3085, batch_acc=0.9688, running_acc=0.9433, grad=21.9253]Training epoch 24:  93%|█████████▎| 151/163 [02:50<00:12,  1.06s/it, loss=0.3474, batch_acc=0.9688, running_acc=0.9435, grad=20.8180]Training epoch 24:  93%|█████████▎| 152/163 [02:51<00:11,  1.01s/it, loss=0.3474, batch_acc=0.9688, running_acc=0.9435, grad=20.8180]Training epoch 24:  93%|█████████▎| 152/163 [02:51<00:11,  1.01s/it, loss=0.3913, batch_acc=0.9688, running_acc=0.9437, grad=24.6364]Training epoch 24:  94%|█████████▍| 153/163 [02:53<00:11,  1.18s/it, loss=0.3913, batch_acc=0.9688, running_acc=0.9437, grad=24.6364]Training epoch 24:  94%|█████████▍| 153/163 [02:53<00:11,  1.18s/it, loss=0.4114, batch_acc=0.9375, running_acc=0.9436, grad=19.8289]Training epoch 24:  94%|█████████▍| 154/163 [02:54<00:09,  1.09s/it, loss=0.4114, batch_acc=0.9375, running_acc=0.9436, grad=19.8289]Training epoch 24:  94%|█████████▍| 154/163 [02:54<00:09,  1.09s/it, loss=0.3890, batch_acc=1.0000, running_acc=0.9440, grad=27.1287]Training epoch 24:  95%|█████████▌| 155/163 [02:54<00:08,  1.03s/it, loss=0.3890, batch_acc=1.0000, running_acc=0.9440, grad=27.1287]Training epoch 24:  95%|█████████▌| 155/163 [02:54<00:08,  1.03s/it, loss=0.6400, batch_acc=0.9062, running_acc=0.9437, grad=34.8623]Training epoch 24:  96%|█████████▌| 156/163 [02:55<00:06,  1.02it/s, loss=0.6400, batch_acc=0.9062, running_acc=0.9437, grad=34.8623]Training epoch 24:  96%|█████████▌| 156/163 [02:55<00:06,  1.02it/s, loss=0.3372, batch_acc=0.9375, running_acc=0.9437, grad=18.7985]Training epoch 24:  96%|█████████▋| 157/163 [02:57<00:06,  1.13s/it, loss=0.3372, batch_acc=0.9375, running_acc=0.9437, grad=18.7985]Training epoch 24:  96%|█████████▋| 157/163 [02:57<00:06,  1.13s/it, loss=0.6012, batch_acc=0.8750, running_acc=0.9433, grad=19.8866]Training epoch 24:  97%|█████████▋| 158/163 [02:58<00:05,  1.06s/it, loss=0.6012, batch_acc=0.8750, running_acc=0.9433, grad=19.8866]Training epoch 24:  97%|█████████▋| 158/163 [02:58<00:05,  1.06s/it, loss=0.5475, batch_acc=0.9062, running_acc=0.9430, grad=26.4140]Training epoch 24:  98%|█████████▊| 159/163 [02:59<00:04,  1.00s/it, loss=0.5475, batch_acc=0.9062, running_acc=0.9430, grad=26.4140]Training epoch 24:  98%|█████████▊| 159/163 [02:59<00:04,  1.00s/it, loss=0.5694, batch_acc=0.8438, running_acc=0.9424, grad=28.3720]Training epoch 24:  98%|█████████▊| 160/163 [02:59<00:02,  1.03it/s, loss=0.5694, batch_acc=0.8438, running_acc=0.9424, grad=28.3720]Training epoch 24:  98%|█████████▊| 160/163 [02:59<00:02,  1.03it/s, loss=0.5657, batch_acc=0.9062, running_acc=0.9422, grad=29.5246]Training epoch 24:  99%|█████████▉| 161/163 [03:01<00:02,  1.17s/it, loss=0.5657, batch_acc=0.9062, running_acc=0.9422, grad=29.5246]Training epoch 24:  99%|█████████▉| 161/163 [03:01<00:02,  1.17s/it, loss=0.3248, batch_acc=0.9375, running_acc=0.9422, grad=17.5034]Training epoch 24:  99%|█████████▉| 162/163 [03:02<00:01,  1.08s/it, loss=0.3248, batch_acc=0.9375, running_acc=0.9422, grad=17.5034]Training epoch 24:  99%|█████████▉| 162/163 [03:02<00:01,  1.08s/it, loss=0.2423, batch_acc=0.9688, running_acc=0.9423, grad=11.2653]Training epoch 24: 100%|██████████| 163/163 [03:03<00:00,  1.06it/s, loss=0.2423, batch_acc=0.9688, running_acc=0.9423, grad=11.2653]Training epoch 24: 100%|██████████| 163/163 [03:03<00:00,  1.06it/s, loss=0.3576, batch_acc=0.8571, running_acc=0.9420, grad=27.7336]Training epoch 24: 100%|██████████| 163/163 [03:03<00:00,  1.12s/it, loss=0.3576, batch_acc=0.8571, running_acc=0.9420, grad=27.7336]
Evaluation epoch 24:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 24:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it]Evaluation epoch 24:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it, loss=0.7495, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 24:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.7495, batch_acc=0.8125, running_acc=0.8125]Evaluation epoch 24:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.3794, batch_acc=1.0000, running_acc=0.9062]Evaluation epoch 24:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3794, batch_acc=1.0000, running_acc=0.9062]Evaluation epoch 24:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.4848, batch_acc=0.9688, running_acc=0.9271]Evaluation epoch 24:  14%|█▍        | 4/28 [00:09<01:00,  2.51s/it, loss=0.4848, batch_acc=0.9688, running_acc=0.9271]Evaluation epoch 24:  14%|█▍        | 4/28 [00:09<01:00,  2.51s/it, loss=0.5768, batch_acc=0.9375, running_acc=0.9297]Evaluation epoch 24:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=0.5768, batch_acc=0.9375, running_acc=0.9297]Evaluation epoch 24:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=1.4380, batch_acc=0.5938, running_acc=0.8625]Evaluation epoch 24:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=1.4380, batch_acc=0.5938, running_acc=0.8625]Evaluation epoch 24:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=0.6456, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 24:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.6456, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 24:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=1.0320, batch_acc=0.8438, running_acc=0.8571]Evaluation epoch 24:  29%|██▊       | 8/28 [00:13<00:33,  1.69s/it, loss=1.0320, batch_acc=0.8438, running_acc=0.8571]Evaluation epoch 24:  29%|██▊       | 8/28 [00:13<00:33,  1.69s/it, loss=0.5788, batch_acc=0.8438, running_acc=0.8555]Evaluation epoch 24:  32%|███▏      | 9/28 [00:14<00:26,  1.41s/it, loss=0.5788, batch_acc=0.8438, running_acc=0.8555]Evaluation epoch 24:  32%|███▏      | 9/28 [00:14<00:26,  1.41s/it, loss=0.6915, batch_acc=0.9062, running_acc=0.8611]Evaluation epoch 24:  36%|███▌      | 10/28 [00:15<00:18,  1.05s/it, loss=0.6915, batch_acc=0.9062, running_acc=0.8611]Evaluation epoch 24:  36%|███▌      | 10/28 [00:15<00:18,  1.05s/it, loss=0.5945, batch_acc=0.9062, running_acc=0.8656]Evaluation epoch 24:  39%|███▉      | 11/28 [00:15<00:13,  1.23it/s, loss=0.5945, batch_acc=0.9062, running_acc=0.8656]Evaluation epoch 24:  39%|███▉      | 11/28 [00:15<00:13,  1.23it/s, loss=0.5683, batch_acc=0.8750, running_acc=0.8665]Evaluation epoch 24:  43%|████▎     | 12/28 [00:20<00:34,  2.14s/it, loss=0.5683, batch_acc=0.8750, running_acc=0.8665]Evaluation epoch 24:  43%|████▎     | 12/28 [00:20<00:34,  2.14s/it, loss=1.2739, batch_acc=0.6562, running_acc=0.8490]Evaluation epoch 24:  46%|████▋     | 13/28 [00:20<00:23,  1.57s/it, loss=1.2739, batch_acc=0.6562, running_acc=0.8490]Evaluation epoch 24:  46%|████▋     | 13/28 [00:20<00:23,  1.57s/it, loss=0.5075, batch_acc=0.9375, running_acc=0.8558]Evaluation epoch 24:  50%|█████     | 14/28 [00:21<00:16,  1.18s/it, loss=0.5075, batch_acc=0.9375, running_acc=0.8558]Evaluation epoch 24:  50%|█████     | 14/28 [00:21<00:16,  1.18s/it, loss=1.2386, batch_acc=0.7500, running_acc=0.8482]Evaluation epoch 24:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=1.2386, batch_acc=0.7500, running_acc=0.8482]Evaluation epoch 24:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=1.3188, batch_acc=0.6562, running_acc=0.8354]Evaluation epoch 24:  57%|█████▋    | 16/28 [00:23<00:17,  1.45s/it, loss=1.3188, batch_acc=0.6562, running_acc=0.8354]Evaluation epoch 24:  57%|█████▋    | 16/28 [00:23<00:17,  1.45s/it, loss=1.1226, batch_acc=0.7500, running_acc=0.8301]Evaluation epoch 24:  61%|██████    | 17/28 [00:24<00:11,  1.09s/it, loss=1.1226, batch_acc=0.7500, running_acc=0.8301]Evaluation epoch 24:  61%|██████    | 17/28 [00:24<00:11,  1.09s/it, loss=0.8677, batch_acc=0.7500, running_acc=0.8254]Evaluation epoch 24:  64%|██████▍   | 18/28 [00:24<00:08,  1.19it/s, loss=0.8677, batch_acc=0.7500, running_acc=0.8254]Evaluation epoch 24:  64%|██████▍   | 18/28 [00:24<00:08,  1.19it/s, loss=0.6675, batch_acc=0.8750, running_acc=0.8281]Evaluation epoch 24:  68%|██████▊   | 19/28 [00:24<00:06,  1.50it/s, loss=0.6675, batch_acc=0.8750, running_acc=0.8281]Evaluation epoch 24:  68%|██████▊   | 19/28 [00:24<00:06,  1.50it/s, loss=0.8020, batch_acc=0.6562, running_acc=0.8191]Evaluation epoch 24:  71%|███████▏  | 20/28 [00:27<00:10,  1.27s/it, loss=0.8020, batch_acc=0.6562, running_acc=0.8191]Evaluation epoch 24:  71%|███████▏  | 20/28 [00:27<00:10,  1.27s/it, loss=0.7709, batch_acc=0.7812, running_acc=0.8172]Evaluation epoch 24:  75%|███████▌  | 21/28 [00:27<00:06,  1.03it/s, loss=0.7709, batch_acc=0.7812, running_acc=0.8172]Evaluation epoch 24:  75%|███████▌  | 21/28 [00:27<00:06,  1.03it/s, loss=0.8750, batch_acc=0.7812, running_acc=0.8155]Evaluation epoch 24:  79%|███████▊  | 22/28 [00:27<00:04,  1.32it/s, loss=0.8750, batch_acc=0.7812, running_acc=0.8155]Evaluation epoch 24:  79%|███████▊  | 22/28 [00:27<00:04,  1.32it/s, loss=1.0998, batch_acc=0.6875, running_acc=0.8097]Evaluation epoch 24:  82%|████████▏ | 23/28 [00:28<00:03,  1.64it/s, loss=1.0998, batch_acc=0.6875, running_acc=0.8097]Evaluation epoch 24:  82%|████████▏ | 23/28 [00:28<00:03,  1.64it/s, loss=0.9914, batch_acc=0.7188, running_acc=0.8057]Evaluation epoch 24:  86%|████████▌ | 24/28 [00:33<00:07,  1.95s/it, loss=0.9914, batch_acc=0.7188, running_acc=0.8057]Evaluation epoch 24:  86%|████████▌ | 24/28 [00:33<00:07,  1.95s/it, loss=0.4512, batch_acc=0.9375, running_acc=0.8112]Evaluation epoch 24:  89%|████████▉ | 25/28 [00:33<00:04,  1.44s/it, loss=0.4512, batch_acc=0.9375, running_acc=0.8112]Evaluation epoch 24:  89%|████████▉ | 25/28 [00:33<00:04,  1.44s/it, loss=0.2593, batch_acc=1.0000, running_acc=0.8187]Evaluation epoch 24:  93%|█████████▎| 26/28 [00:33<00:02,  1.09s/it, loss=0.2593, batch_acc=1.0000, running_acc=0.8187]Evaluation epoch 24:  93%|█████████▎| 26/28 [00:33<00:02,  1.09s/it, loss=0.9526, batch_acc=0.7812, running_acc=0.8173]Evaluation epoch 24:  96%|█████████▋| 27/28 [00:34<00:00,  1.19it/s, loss=0.9526, batch_acc=0.7812, running_acc=0.8173]Evaluation epoch 24:  96%|█████████▋| 27/28 [00:34<00:00,  1.19it/s, loss=0.9846, batch_acc=0.6875, running_acc=0.8125]Evaluation epoch 24: 100%|██████████| 28/28 [00:34<00:00,  1.19it/s, loss=1.1295, batch_acc=0.6667, running_acc=0.8120]Evaluation epoch 24: 100%|██████████| 28/28 [00:34<00:00,  1.22s/it, loss=1.1295, batch_acc=0.6667, running_acc=0.8120]
Training epoch 25:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 25:   1%|          | 1/163 [00:05<15:13,  5.64s/it]Training epoch 25:   1%|          | 1/163 [00:05<15:13,  5.64s/it, loss=0.4110, batch_acc=0.9375, running_acc=0.9375, grad=28.3609]Training epoch 25:   1%|          | 2/163 [00:06<07:37,  2.84s/it, loss=0.4110, batch_acc=0.9375, running_acc=0.9375, grad=28.3609]Training epoch 25:   1%|          | 2/163 [00:06<07:37,  2.84s/it, loss=0.3541, batch_acc=0.9688, running_acc=0.9531, grad=20.1634]Training epoch 25:   2%|▏         | 3/163 [00:07<05:11,  1.95s/it, loss=0.3541, batch_acc=0.9688, running_acc=0.9531, grad=20.1634]Training epoch 25:   2%|▏         | 3/163 [00:07<05:11,  1.95s/it, loss=0.2462, batch_acc=0.9688, running_acc=0.9583, grad=15.5214]Training epoch 25:   2%|▏         | 4/163 [00:10<05:50,  2.21s/it, loss=0.2462, batch_acc=0.9688, running_acc=0.9583, grad=15.5214]Training epoch 25:   2%|▏         | 4/163 [00:10<05:50,  2.21s/it, loss=0.3282, batch_acc=0.9375, running_acc=0.9531, grad=14.9322]Training epoch 25:   3%|▎         | 5/163 [00:10<04:32,  1.73s/it, loss=0.3282, batch_acc=0.9375, running_acc=0.9531, grad=14.9322]Training epoch 25:   3%|▎         | 5/163 [00:10<04:32,  1.73s/it, loss=0.3705, batch_acc=1.0000, running_acc=0.9625, grad=20.6980]Training epoch 25:   4%|▎         | 6/163 [00:11<03:52,  1.48s/it, loss=0.3705, batch_acc=1.0000, running_acc=0.9625, grad=20.6980]Training epoch 25:   4%|▎         | 6/163 [00:11<03:52,  1.48s/it, loss=0.4889, batch_acc=0.9375, running_acc=0.9583, grad=24.5484]Training epoch 25:   4%|▍         | 7/163 [00:12<03:20,  1.28s/it, loss=0.4889, batch_acc=0.9375, running_acc=0.9583, grad=24.5484]Training epoch 25:   4%|▍         | 7/163 [00:12<03:20,  1.28s/it, loss=0.3241, batch_acc=0.9688, running_acc=0.9598, grad=18.2336]Training epoch 25:   5%|▍         | 8/163 [00:14<04:00,  1.55s/it, loss=0.3241, batch_acc=0.9688, running_acc=0.9598, grad=18.2336]Training epoch 25:   5%|▍         | 8/163 [00:14<04:00,  1.55s/it, loss=0.3300, batch_acc=0.9375, running_acc=0.9570, grad=17.0574]Training epoch 25:   6%|▌         | 9/163 [00:15<03:26,  1.34s/it, loss=0.3300, batch_acc=0.9375, running_acc=0.9570, grad=17.0574]Training epoch 25:   6%|▌         | 9/163 [00:15<03:26,  1.34s/it, loss=0.3295, batch_acc=1.0000, running_acc=0.9618, grad=20.2799]Training epoch 25:   6%|▌         | 10/163 [00:16<03:03,  1.20s/it, loss=0.3295, batch_acc=1.0000, running_acc=0.9618, grad=20.2799]Training epoch 25:   6%|▌         | 10/163 [00:16<03:03,  1.20s/it, loss=0.3097, batch_acc=1.0000, running_acc=0.9656, grad=23.7392]Training epoch 25:   7%|▋         | 11/163 [00:17<02:47,  1.10s/it, loss=0.3097, batch_acc=1.0000, running_acc=0.9656, grad=23.7392]Training epoch 25:   7%|▋         | 11/163 [00:17<02:47,  1.10s/it, loss=0.5478, batch_acc=0.9062, running_acc=0.9602, grad=29.7633]Training epoch 25:   7%|▋         | 12/163 [00:18<02:57,  1.17s/it, loss=0.5478, batch_acc=0.9062, running_acc=0.9602, grad=29.7633]Training epoch 25:   7%|▋         | 12/163 [00:18<02:57,  1.17s/it, loss=0.3302, batch_acc=1.0000, running_acc=0.9635, grad=20.5986]Training epoch 25:   8%|▊         | 13/163 [00:19<02:42,  1.08s/it, loss=0.3302, batch_acc=1.0000, running_acc=0.9635, grad=20.5986]Training epoch 25:   8%|▊         | 13/163 [00:19<02:42,  1.08s/it, loss=0.5045, batch_acc=0.9375, running_acc=0.9615, grad=25.3152]Training epoch 25:   9%|▊         | 14/163 [00:20<02:32,  1.02s/it, loss=0.5045, batch_acc=0.9375, running_acc=0.9615, grad=25.3152]Training epoch 25:   9%|▊         | 14/163 [00:20<02:32,  1.02s/it, loss=0.3475, batch_acc=0.9688, running_acc=0.9621, grad=24.0267]Training epoch 25:   9%|▉         | 15/163 [00:21<02:24,  1.02it/s, loss=0.3475, batch_acc=0.9688, running_acc=0.9621, grad=24.0267]Training epoch 25:   9%|▉         | 15/163 [00:21<02:24,  1.02it/s, loss=0.2657, batch_acc=0.9688, running_acc=0.9625, grad=15.4708]Training epoch 25:  10%|▉         | 16/163 [00:22<02:34,  1.05s/it, loss=0.2657, batch_acc=0.9688, running_acc=0.9625, grad=15.4708]Training epoch 25:  10%|▉         | 16/163 [00:22<02:34,  1.05s/it, loss=0.3634, batch_acc=0.9375, running_acc=0.9609, grad=17.4717]Training epoch 25:  10%|█         | 17/163 [00:23<02:25,  1.00it/s, loss=0.3634, batch_acc=0.9375, running_acc=0.9609, grad=17.4717]Training epoch 25:  10%|█         | 17/163 [00:23<02:25,  1.00it/s, loss=0.4860, batch_acc=0.9688, running_acc=0.9614, grad=23.8211]Training epoch 25:  11%|█         | 18/163 [00:24<02:19,  1.04it/s, loss=0.4860, batch_acc=0.9688, running_acc=0.9614, grad=23.8211]Training epoch 25:  11%|█         | 18/163 [00:24<02:19,  1.04it/s, loss=0.4176, batch_acc=0.9688, running_acc=0.9618, grad=18.2072]Training epoch 25:  12%|█▏        | 19/163 [00:25<02:15,  1.07it/s, loss=0.4176, batch_acc=0.9688, running_acc=0.9618, grad=18.2072]Training epoch 25:  12%|█▏        | 19/163 [00:25<02:15,  1.07it/s, loss=0.3144, batch_acc=0.9375, running_acc=0.9605, grad=18.5061]Training epoch 25:  12%|█▏        | 20/163 [00:27<02:47,  1.17s/it, loss=0.3144, batch_acc=0.9375, running_acc=0.9605, grad=18.5061]Training epoch 25:  12%|█▏        | 20/163 [00:27<02:47,  1.17s/it, loss=0.6413, batch_acc=0.9062, running_acc=0.9578, grad=26.4217]Training epoch 25:  13%|█▎        | 21/163 [00:27<02:33,  1.08s/it, loss=0.6413, batch_acc=0.9062, running_acc=0.9578, grad=26.4217]Training epoch 25:  13%|█▎        | 21/163 [00:27<02:33,  1.08s/it, loss=0.2592, batch_acc=1.0000, running_acc=0.9598, grad=14.2435]Training epoch 25:  13%|█▎        | 22/163 [00:28<02:23,  1.02s/it, loss=0.2592, batch_acc=1.0000, running_acc=0.9598, grad=14.2435]Training epoch 25:  13%|█▎        | 22/163 [00:28<02:23,  1.02s/it, loss=0.2601, batch_acc=1.0000, running_acc=0.9616, grad=14.2427]Training epoch 25:  14%|█▍        | 23/163 [00:29<02:16,  1.02it/s, loss=0.2601, batch_acc=1.0000, running_acc=0.9616, grad=14.2427]Training epoch 25:  14%|█▍        | 23/163 [00:29<02:16,  1.02it/s, loss=0.4096, batch_acc=0.9375, running_acc=0.9606, grad=20.4481]Training epoch 25:  15%|█▍        | 24/163 [00:31<02:40,  1.15s/it, loss=0.4096, batch_acc=0.9375, running_acc=0.9606, grad=20.4481]Training epoch 25:  15%|█▍        | 24/163 [00:31<02:40,  1.15s/it, loss=0.3024, batch_acc=0.9688, running_acc=0.9609, grad=24.1194]Training epoch 25:  15%|█▌        | 25/163 [00:32<02:27,  1.07s/it, loss=0.3024, batch_acc=0.9688, running_acc=0.9609, grad=24.1194]Training epoch 25:  15%|█▌        | 25/163 [00:32<02:27,  1.07s/it, loss=0.1991, batch_acc=1.0000, running_acc=0.9625, grad=12.0776]Training epoch 25:  16%|█▌        | 26/163 [00:33<02:18,  1.01s/it, loss=0.1991, batch_acc=1.0000, running_acc=0.9625, grad=12.0776]Training epoch 25:  16%|█▌        | 26/163 [00:33<02:18,  1.01s/it, loss=0.3868, batch_acc=0.9062, running_acc=0.9603, grad=19.7424]Training epoch 25:  17%|█▋        | 27/163 [00:33<02:12,  1.03it/s, loss=0.3868, batch_acc=0.9062, running_acc=0.9603, grad=19.7424]Training epoch 25:  17%|█▋        | 27/163 [00:33<02:12,  1.03it/s, loss=0.3300, batch_acc=0.9688, running_acc=0.9606, grad=20.5569]Training epoch 25:  17%|█▋        | 28/163 [00:35<02:16,  1.01s/it, loss=0.3300, batch_acc=0.9688, running_acc=0.9606, grad=20.5569]Training epoch 25:  17%|█▋        | 28/163 [00:35<02:16,  1.01s/it, loss=0.3957, batch_acc=0.9375, running_acc=0.9598, grad=22.2034]Training epoch 25:  18%|█▊        | 29/163 [00:35<02:10,  1.03it/s, loss=0.3957, batch_acc=0.9375, running_acc=0.9598, grad=22.2034]Training epoch 25:  18%|█▊        | 29/163 [00:35<02:10,  1.03it/s, loss=0.4961, batch_acc=0.9062, running_acc=0.9580, grad=17.4594]Training epoch 25:  18%|█▊        | 30/163 [00:36<02:05,  1.06it/s, loss=0.4961, batch_acc=0.9062, running_acc=0.9580, grad=17.4594]Training epoch 25:  18%|█▊        | 30/163 [00:36<02:05,  1.06it/s, loss=0.3529, batch_acc=0.9062, running_acc=0.9563, grad=18.6910]Training epoch 25:  19%|█▉        | 31/163 [00:37<02:02,  1.08it/s, loss=0.3529, batch_acc=0.9062, running_acc=0.9563, grad=18.6910]Training epoch 25:  19%|█▉        | 31/163 [00:37<02:02,  1.08it/s, loss=0.4469, batch_acc=0.9062, running_acc=0.9546, grad=23.7892]Training epoch 25:  20%|█▉        | 32/163 [00:39<02:42,  1.24s/it, loss=0.4469, batch_acc=0.9062, running_acc=0.9546, grad=23.7892]Training epoch 25:  20%|█▉        | 32/163 [00:39<02:42,  1.24s/it, loss=0.3960, batch_acc=0.9062, running_acc=0.9531, grad=13.8368]Training epoch 25:  20%|██        | 33/163 [00:40<02:27,  1.13s/it, loss=0.3960, batch_acc=0.9062, running_acc=0.9531, grad=13.8368]Training epoch 25:  20%|██        | 33/163 [00:40<02:27,  1.13s/it, loss=0.4527, batch_acc=0.9375, running_acc=0.9527, grad=22.9761]Training epoch 25:  21%|██        | 34/163 [00:41<02:16,  1.06s/it, loss=0.4527, batch_acc=0.9375, running_acc=0.9527, grad=22.9761]Training epoch 25:  21%|██        | 34/163 [00:41<02:16,  1.06s/it, loss=0.3746, batch_acc=0.9375, running_acc=0.9522, grad=17.5761]Training epoch 25:  21%|██▏       | 35/163 [00:42<02:08,  1.00s/it, loss=0.3746, batch_acc=0.9375, running_acc=0.9522, grad=17.5761]Training epoch 25:  21%|██▏       | 35/163 [00:42<02:08,  1.00s/it, loss=0.4462, batch_acc=0.8750, running_acc=0.9500, grad=27.1656]Training epoch 25:  22%|██▏       | 36/163 [00:45<03:50,  1.82s/it, loss=0.4462, batch_acc=0.8750, running_acc=0.9500, grad=27.1656]Training epoch 25:  22%|██▏       | 36/163 [00:45<03:50,  1.82s/it, loss=0.3095, batch_acc=1.0000, running_acc=0.9514, grad=20.8127]Training epoch 25:  23%|██▎       | 37/163 [00:46<03:13,  1.54s/it, loss=0.3095, batch_acc=1.0000, running_acc=0.9514, grad=20.8127]Training epoch 25:  23%|██▎       | 37/163 [00:46<03:13,  1.54s/it, loss=0.3203, batch_acc=1.0000, running_acc=0.9527, grad=20.0703]Training epoch 25:  23%|██▎       | 38/163 [00:47<02:47,  1.34s/it, loss=0.3203, batch_acc=1.0000, running_acc=0.9527, grad=20.0703]Training epoch 25:  23%|██▎       | 38/163 [00:47<02:47,  1.34s/it, loss=0.3678, batch_acc=0.9688, running_acc=0.9531, grad=19.6182]Training epoch 25:  24%|██▍       | 39/163 [00:48<02:29,  1.20s/it, loss=0.3678, batch_acc=0.9688, running_acc=0.9531, grad=19.6182]Training epoch 25:  24%|██▍       | 39/163 [00:48<02:29,  1.20s/it, loss=0.3974, batch_acc=0.9688, running_acc=0.9535, grad=19.1289]Training epoch 25:  25%|██▍       | 40/163 [00:51<03:31,  1.72s/it, loss=0.3974, batch_acc=0.9688, running_acc=0.9535, grad=19.1289]Training epoch 25:  25%|██▍       | 40/163 [00:51<03:31,  1.72s/it, loss=0.3867, batch_acc=0.8750, running_acc=0.9516, grad=15.0882]Training epoch 25:  25%|██▌       | 41/163 [00:52<02:58,  1.46s/it, loss=0.3867, batch_acc=0.8750, running_acc=0.9516, grad=15.0882]Training epoch 25:  25%|██▌       | 41/163 [00:52<02:58,  1.46s/it, loss=0.3877, batch_acc=0.9375, running_acc=0.9512, grad=19.8919]Training epoch 25:  26%|██▌       | 42/163 [00:53<02:35,  1.29s/it, loss=0.3877, batch_acc=0.9375, running_acc=0.9512, grad=19.8919]Training epoch 25:  26%|██▌       | 42/163 [00:53<02:35,  1.29s/it, loss=0.2083, batch_acc=1.0000, running_acc=0.9524, grad=10.1641]Training epoch 25:  26%|██▋       | 43/163 [00:54<02:19,  1.17s/it, loss=0.2083, batch_acc=1.0000, running_acc=0.9524, grad=10.1641]Training epoch 25:  26%|██▋       | 43/163 [00:54<02:19,  1.17s/it, loss=0.3274, batch_acc=0.9375, running_acc=0.9520, grad=16.7307]Training epoch 25:  27%|██▋       | 44/163 [00:55<02:18,  1.17s/it, loss=0.3274, batch_acc=0.9375, running_acc=0.9520, grad=16.7307]Training epoch 25:  27%|██▋       | 44/163 [00:55<02:18,  1.17s/it, loss=0.4246, batch_acc=1.0000, running_acc=0.9531, grad=24.8394]Training epoch 25:  28%|██▊       | 45/163 [00:56<02:07,  1.08s/it, loss=0.4246, batch_acc=1.0000, running_acc=0.9531, grad=24.8394]Training epoch 25:  28%|██▊       | 45/163 [00:56<02:07,  1.08s/it, loss=0.3060, batch_acc=0.9375, running_acc=0.9528, grad=16.2354]Training epoch 25:  28%|██▊       | 46/163 [00:57<01:59,  1.02s/it, loss=0.3060, batch_acc=0.9375, running_acc=0.9528, grad=16.2354]Training epoch 25:  28%|██▊       | 46/163 [00:57<01:59,  1.02s/it, loss=0.3618, batch_acc=0.9688, running_acc=0.9531, grad=17.7400]Training epoch 25:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.3618, batch_acc=0.9688, running_acc=0.9531, grad=17.7400]Training epoch 25:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.4239, batch_acc=0.8750, running_acc=0.9515, grad=21.2803]Training epoch 25:  29%|██▉       | 48/163 [00:59<02:19,  1.21s/it, loss=0.4239, batch_acc=0.8750, running_acc=0.9515, grad=21.2803]Training epoch 25:  29%|██▉       | 48/163 [00:59<02:19,  1.21s/it, loss=0.3257, batch_acc=1.0000, running_acc=0.9525, grad=20.2278]Training epoch 25:  30%|███       | 49/163 [01:00<02:06,  1.11s/it, loss=0.3257, batch_acc=1.0000, running_acc=0.9525, grad=20.2278]Training epoch 25:  30%|███       | 49/163 [01:00<02:06,  1.11s/it, loss=0.4201, batch_acc=0.9688, running_acc=0.9528, grad=21.8409]Training epoch 25:  31%|███       | 50/163 [01:01<01:57,  1.04s/it, loss=0.4201, batch_acc=0.9688, running_acc=0.9528, grad=21.8409]Training epoch 25:  31%|███       | 50/163 [01:01<01:57,  1.04s/it, loss=0.2695, batch_acc=1.0000, running_acc=0.9537, grad=11.2558]Training epoch 25:  31%|███▏      | 51/163 [01:02<01:51,  1.01it/s, loss=0.2695, batch_acc=1.0000, running_acc=0.9537, grad=11.2558]Training epoch 25:  31%|███▏      | 51/163 [01:02<01:51,  1.01it/s, loss=0.3430, batch_acc=0.9688, running_acc=0.9540, grad=22.4029]Training epoch 25:  32%|███▏      | 52/163 [01:04<02:35,  1.40s/it, loss=0.3430, batch_acc=0.9688, running_acc=0.9540, grad=22.4029]Training epoch 25:  32%|███▏      | 52/163 [01:04<02:35,  1.40s/it, loss=0.2976, batch_acc=1.0000, running_acc=0.9549, grad=21.6404]Training epoch 25:  33%|███▎      | 53/163 [01:05<02:16,  1.24s/it, loss=0.2976, batch_acc=1.0000, running_acc=0.9549, grad=21.6404]Training epoch 25:  33%|███▎      | 53/163 [01:05<02:16,  1.24s/it, loss=0.4194, batch_acc=0.9062, running_acc=0.9540, grad=29.0899]Training epoch 25:  33%|███▎      | 54/163 [01:06<02:03,  1.13s/it, loss=0.4194, batch_acc=0.9062, running_acc=0.9540, grad=29.0899]Training epoch 25:  33%|███▎      | 54/163 [01:06<02:03,  1.13s/it, loss=0.4955, batch_acc=0.9375, running_acc=0.9537, grad=25.2453]Training epoch 25:  34%|███▎      | 55/163 [01:07<01:54,  1.06s/it, loss=0.4955, batch_acc=0.9375, running_acc=0.9537, grad=25.2453]Training epoch 25:  34%|███▎      | 55/163 [01:07<01:54,  1.06s/it, loss=0.2844, batch_acc=0.9688, running_acc=0.9540, grad=18.6398]Training epoch 25:  34%|███▍      | 56/163 [01:08<02:02,  1.15s/it, loss=0.2844, batch_acc=0.9688, running_acc=0.9540, grad=18.6398]Training epoch 25:  34%|███▍      | 56/163 [01:08<02:02,  1.15s/it, loss=0.3211, batch_acc=0.9688, running_acc=0.9542, grad=17.3622]Training epoch 25:  35%|███▍      | 57/163 [01:09<01:52,  1.06s/it, loss=0.3211, batch_acc=0.9688, running_acc=0.9542, grad=17.3622]Training epoch 25:  35%|███▍      | 57/163 [01:09<01:52,  1.06s/it, loss=0.4081, batch_acc=0.9688, running_acc=0.9545, grad=17.2011]Training epoch 25:  36%|███▌      | 58/163 [01:10<01:45,  1.01s/it, loss=0.4081, batch_acc=0.9688, running_acc=0.9545, grad=17.2011]Training epoch 25:  36%|███▌      | 58/163 [01:10<01:45,  1.01s/it, loss=0.3718, batch_acc=0.9688, running_acc=0.9547, grad=15.8407]Training epoch 25:  36%|███▌      | 59/163 [01:11<01:40,  1.03it/s, loss=0.3718, batch_acc=0.9688, running_acc=0.9547, grad=15.8407]Training epoch 25:  36%|███▌      | 59/163 [01:11<01:40,  1.03it/s, loss=0.3589, batch_acc=0.9688, running_acc=0.9550, grad=20.4549]Training epoch 25:  37%|███▋      | 60/163 [01:13<02:10,  1.26s/it, loss=0.3589, batch_acc=0.9688, running_acc=0.9550, grad=20.4549]Training epoch 25:  37%|███▋      | 60/163 [01:13<02:10,  1.26s/it, loss=0.3669, batch_acc=0.9688, running_acc=0.9552, grad=22.8621]Training epoch 25:  37%|███▋      | 61/163 [01:14<01:57,  1.15s/it, loss=0.3669, batch_acc=0.9688, running_acc=0.9552, grad=22.8621]Training epoch 25:  37%|███▋      | 61/163 [01:14<01:57,  1.15s/it, loss=0.4154, batch_acc=0.9062, running_acc=0.9544, grad=19.3307]Training epoch 25:  38%|███▊      | 62/163 [01:15<01:47,  1.07s/it, loss=0.4154, batch_acc=0.9062, running_acc=0.9544, grad=19.3307]Training epoch 25:  38%|███▊      | 62/163 [01:15<01:47,  1.07s/it, loss=0.4176, batch_acc=0.8438, running_acc=0.9526, grad=22.1075]Training epoch 25:  39%|███▊      | 63/163 [01:15<01:41,  1.01s/it, loss=0.4176, batch_acc=0.8438, running_acc=0.9526, grad=22.1075]Training epoch 25:  39%|███▊      | 63/163 [01:15<01:41,  1.01s/it, loss=0.3673, batch_acc=0.9375, running_acc=0.9524, grad=18.8069]Training epoch 25:  39%|███▉      | 64/163 [01:17<01:45,  1.06s/it, loss=0.3673, batch_acc=0.9375, running_acc=0.9524, grad=18.8069]Training epoch 25:  39%|███▉      | 64/163 [01:17<01:45,  1.06s/it, loss=0.4411, batch_acc=0.9062, running_acc=0.9517, grad=24.9184]Training epoch 25:  40%|███▉      | 65/163 [01:17<01:38,  1.01s/it, loss=0.4411, batch_acc=0.9062, running_acc=0.9517, grad=24.9184]Training epoch 25:  40%|███▉      | 65/163 [01:17<01:38,  1.01s/it, loss=0.2764, batch_acc=0.9688, running_acc=0.9519, grad=10.6574]Training epoch 25:  40%|████      | 66/163 [01:18<01:33,  1.03it/s, loss=0.2764, batch_acc=0.9688, running_acc=0.9519, grad=10.6574]Training epoch 25:  40%|████      | 66/163 [01:18<01:33,  1.03it/s, loss=0.3530, batch_acc=0.9375, running_acc=0.9517, grad=23.0057]Training epoch 25:  41%|████      | 67/163 [01:19<01:30,  1.06it/s, loss=0.3530, batch_acc=0.9375, running_acc=0.9517, grad=23.0057]Training epoch 25:  41%|████      | 67/163 [01:19<01:30,  1.06it/s, loss=0.3747, batch_acc=0.9688, running_acc=0.9520, grad=21.5918]Training epoch 25:  42%|████▏     | 68/163 [01:21<01:48,  1.14s/it, loss=0.3747, batch_acc=0.9688, running_acc=0.9520, grad=21.5918]Training epoch 25:  42%|████▏     | 68/163 [01:21<01:48,  1.14s/it, loss=0.3045, batch_acc=1.0000, running_acc=0.9527, grad=18.4163]Training epoch 25:  42%|████▏     | 69/163 [01:22<01:39,  1.06s/it, loss=0.3045, batch_acc=1.0000, running_acc=0.9527, grad=18.4163]Training epoch 25:  42%|████▏     | 69/163 [01:22<01:39,  1.06s/it, loss=0.2899, batch_acc=1.0000, running_acc=0.9534, grad=14.8380]Training epoch 25:  43%|████▎     | 70/163 [01:23<01:33,  1.01s/it, loss=0.2899, batch_acc=1.0000, running_acc=0.9534, grad=14.8380]Training epoch 25:  43%|████▎     | 70/163 [01:23<01:33,  1.01s/it, loss=0.4023, batch_acc=0.9375, running_acc=0.9531, grad=22.9527]Training epoch 25:  44%|████▎     | 71/163 [01:23<01:29,  1.03it/s, loss=0.4023, batch_acc=0.9375, running_acc=0.9531, grad=22.9527]Training epoch 25:  44%|████▎     | 71/163 [01:23<01:29,  1.03it/s, loss=0.4055, batch_acc=0.9062, running_acc=0.9525, grad=22.5227]Training epoch 25:  44%|████▍     | 72/163 [01:25<01:43,  1.14s/it, loss=0.4055, batch_acc=0.9062, running_acc=0.9525, grad=22.5227]Training epoch 25:  44%|████▍     | 72/163 [01:25<01:43,  1.14s/it, loss=0.3564, batch_acc=0.9688, running_acc=0.9527, grad=23.5976]Training epoch 25:  45%|████▍     | 73/163 [01:26<01:35,  1.06s/it, loss=0.3564, batch_acc=0.9688, running_acc=0.9527, grad=23.5976]Training epoch 25:  45%|████▍     | 73/163 [01:26<01:35,  1.06s/it, loss=0.2461, batch_acc=1.0000, running_acc=0.9533, grad=14.8295]Training epoch 25:  45%|████▌     | 74/163 [01:27<01:29,  1.01s/it, loss=0.2461, batch_acc=1.0000, running_acc=0.9533, grad=14.8295]Training epoch 25:  45%|████▌     | 74/163 [01:27<01:29,  1.01s/it, loss=0.3763, batch_acc=0.9375, running_acc=0.9531, grad=22.6018]Training epoch 25:  46%|████▌     | 75/163 [01:28<01:25,  1.03it/s, loss=0.3763, batch_acc=0.9375, running_acc=0.9531, grad=22.6018]Training epoch 25:  46%|████▌     | 75/163 [01:28<01:25,  1.03it/s, loss=0.4560, batch_acc=0.9062, running_acc=0.9525, grad=22.7406]Training epoch 25:  47%|████▋     | 76/163 [01:29<01:34,  1.08s/it, loss=0.4560, batch_acc=0.9062, running_acc=0.9525, grad=22.7406]Training epoch 25:  47%|████▋     | 76/163 [01:29<01:34,  1.08s/it, loss=0.3022, batch_acc=1.0000, running_acc=0.9531, grad=16.9103]Training epoch 25:  47%|████▋     | 77/163 [01:30<01:27,  1.02s/it, loss=0.3022, batch_acc=1.0000, running_acc=0.9531, grad=16.9103]Training epoch 25:  47%|████▋     | 77/163 [01:30<01:27,  1.02s/it, loss=0.3257, batch_acc=0.9688, running_acc=0.9533, grad=21.3385]Training epoch 25:  48%|████▊     | 78/163 [01:31<01:23,  1.02it/s, loss=0.3257, batch_acc=0.9688, running_acc=0.9533, grad=21.3385]Training epoch 25:  48%|████▊     | 78/163 [01:31<01:23,  1.02it/s, loss=0.2772, batch_acc=0.9688, running_acc=0.9535, grad=21.2064]Training epoch 25:  48%|████▊     | 79/163 [01:32<01:19,  1.05it/s, loss=0.2772, batch_acc=0.9688, running_acc=0.9535, grad=21.2064]Training epoch 25:  48%|████▊     | 79/163 [01:32<01:19,  1.05it/s, loss=0.4471, batch_acc=0.9375, running_acc=0.9533, grad=28.7228]Training epoch 25:  49%|████▉     | 80/163 [01:33<01:32,  1.11s/it, loss=0.4471, batch_acc=0.9375, running_acc=0.9533, grad=28.7228]Training epoch 25:  49%|████▉     | 80/163 [01:33<01:32,  1.11s/it, loss=0.2196, batch_acc=0.9688, running_acc=0.9535, grad=11.0734]Training epoch 25:  50%|████▉     | 81/163 [01:34<01:25,  1.04s/it, loss=0.2196, batch_acc=0.9688, running_acc=0.9535, grad=11.0734]Training epoch 25:  50%|████▉     | 81/163 [01:34<01:25,  1.04s/it, loss=0.5011, batch_acc=0.8750, running_acc=0.9525, grad=24.9750]Training epoch 25:  50%|█████     | 82/163 [01:35<01:20,  1.01it/s, loss=0.5011, batch_acc=0.8750, running_acc=0.9525, grad=24.9750]Training epoch 25:  50%|█████     | 82/163 [01:35<01:20,  1.01it/s, loss=0.2910, batch_acc=0.9688, running_acc=0.9527, grad=23.0519]Training epoch 25:  51%|█████     | 83/163 [01:36<01:16,  1.04it/s, loss=0.2910, batch_acc=0.9688, running_acc=0.9527, grad=23.0519]Training epoch 25:  51%|█████     | 83/163 [01:36<01:16,  1.04it/s, loss=0.3281, batch_acc=1.0000, running_acc=0.9533, grad=17.2388]Training epoch 25:  52%|█████▏    | 84/163 [01:37<01:33,  1.19s/it, loss=0.3281, batch_acc=1.0000, running_acc=0.9533, grad=17.2388]Training epoch 25:  52%|█████▏    | 84/163 [01:37<01:33,  1.19s/it, loss=0.3456, batch_acc=0.9375, running_acc=0.9531, grad=17.4371]Training epoch 25:  52%|█████▏    | 85/163 [01:38<01:25,  1.10s/it, loss=0.3456, batch_acc=0.9375, running_acc=0.9531, grad=17.4371]Training epoch 25:  52%|█████▏    | 85/163 [01:38<01:25,  1.10s/it, loss=0.2369, batch_acc=1.0000, running_acc=0.9537, grad=13.8963]Training epoch 25:  53%|█████▎    | 86/163 [01:39<01:19,  1.03s/it, loss=0.2369, batch_acc=1.0000, running_acc=0.9537, grad=13.8963]Training epoch 25:  53%|█████▎    | 86/163 [01:39<01:19,  1.03s/it, loss=0.2826, batch_acc=0.9688, running_acc=0.9539, grad=13.6515]Training epoch 25:  53%|█████▎    | 87/163 [01:40<01:14,  1.02it/s, loss=0.2826, batch_acc=0.9688, running_acc=0.9539, grad=13.6515]Training epoch 25:  53%|█████▎    | 87/163 [01:40<01:14,  1.02it/s, loss=0.4145, batch_acc=0.9375, running_acc=0.9537, grad=26.6067]Training epoch 25:  54%|█████▍    | 88/163 [01:41<01:21,  1.09s/it, loss=0.4145, batch_acc=0.9375, running_acc=0.9537, grad=26.6067]Training epoch 25:  54%|█████▍    | 88/163 [01:41<01:21,  1.09s/it, loss=0.4352, batch_acc=0.9688, running_acc=0.9538, grad=35.1668]Training epoch 25:  55%|█████▍    | 89/163 [01:42<01:15,  1.02s/it, loss=0.4352, batch_acc=0.9688, running_acc=0.9538, grad=35.1668]Training epoch 25:  55%|█████▍    | 89/163 [01:42<01:15,  1.02s/it, loss=0.3827, batch_acc=0.9375, running_acc=0.9537, grad=16.7216]Training epoch 25:  55%|█████▌    | 90/163 [01:43<01:11,  1.02it/s, loss=0.3827, batch_acc=0.9375, running_acc=0.9537, grad=16.7216]Training epoch 25:  55%|█████▌    | 90/163 [01:43<01:11,  1.02it/s, loss=0.4633, batch_acc=0.9375, running_acc=0.9535, grad=30.6184]Training epoch 25:  56%|█████▌    | 91/163 [01:44<01:08,  1.05it/s, loss=0.4633, batch_acc=0.9375, running_acc=0.9535, grad=30.6184]Training epoch 25:  56%|█████▌    | 91/163 [01:44<01:08,  1.05it/s, loss=0.2852, batch_acc=0.9375, running_acc=0.9533, grad=14.8515]Training epoch 25:  56%|█████▋    | 92/163 [01:45<01:14,  1.05s/it, loss=0.2852, batch_acc=0.9375, running_acc=0.9533, grad=14.8515]Training epoch 25:  56%|█████▋    | 92/163 [01:45<01:14,  1.05s/it, loss=0.5239, batch_acc=0.9062, running_acc=0.9528, grad=28.9325]Training epoch 25:  57%|█████▋    | 93/163 [01:47<01:25,  1.22s/it, loss=0.5239, batch_acc=0.9062, running_acc=0.9528, grad=28.9325]Training epoch 25:  57%|█████▋    | 93/163 [01:47<01:25,  1.22s/it, loss=0.3534, batch_acc=0.9375, running_acc=0.9526, grad=19.7909]Training epoch 25:  58%|█████▊    | 94/163 [01:49<01:30,  1.32s/it, loss=0.3534, batch_acc=0.9375, running_acc=0.9526, grad=19.7909]Training epoch 25:  58%|█████▊    | 94/163 [01:49<01:30,  1.32s/it, loss=0.3360, batch_acc=0.9688, running_acc=0.9528, grad=25.7991]Training epoch 25:  58%|█████▊    | 95/163 [01:49<01:20,  1.18s/it, loss=0.3360, batch_acc=0.9688, running_acc=0.9528, grad=25.7991]Training epoch 25:  58%|█████▊    | 95/163 [01:49<01:20,  1.18s/it, loss=0.2449, batch_acc=1.0000, running_acc=0.9533, grad=14.0620]Training epoch 25:  59%|█████▉    | 96/163 [01:50<01:13,  1.09s/it, loss=0.2449, batch_acc=1.0000, running_acc=0.9533, grad=14.0620]Training epoch 25:  59%|█████▉    | 96/163 [01:50<01:13,  1.09s/it, loss=0.3952, batch_acc=0.9688, running_acc=0.9535, grad=18.9778]Training epoch 25:  60%|█████▉    | 97/163 [01:51<01:10,  1.07s/it, loss=0.3952, batch_acc=0.9688, running_acc=0.9535, grad=18.9778]Training epoch 25:  60%|█████▉    | 97/163 [01:51<01:10,  1.07s/it, loss=0.4370, batch_acc=0.9062, running_acc=0.9530, grad=18.8149]Training epoch 25:  60%|██████    | 98/163 [01:53<01:23,  1.28s/it, loss=0.4370, batch_acc=0.9062, running_acc=0.9530, grad=18.8149]Training epoch 25:  60%|██████    | 98/163 [01:53<01:23,  1.28s/it, loss=0.4281, batch_acc=0.9688, running_acc=0.9531, grad=22.4679]Training epoch 25:  61%|██████    | 99/163 [01:54<01:14,  1.16s/it, loss=0.4281, batch_acc=0.9688, running_acc=0.9531, grad=22.4679]Training epoch 25:  61%|██████    | 99/163 [01:54<01:14,  1.16s/it, loss=0.4300, batch_acc=0.9375, running_acc=0.9530, grad=24.0218]Training epoch 25:  61%|██████▏   | 100/163 [01:55<01:07,  1.08s/it, loss=0.4300, batch_acc=0.9375, running_acc=0.9530, grad=24.0218]Training epoch 25:  61%|██████▏   | 100/163 [01:55<01:07,  1.08s/it, loss=0.2903, batch_acc=0.9688, running_acc=0.9531, grad=12.9668]Training epoch 25:  62%|██████▏   | 101/163 [01:56<01:04,  1.04s/it, loss=0.2903, batch_acc=0.9688, running_acc=0.9531, grad=12.9668]Training epoch 25:  62%|██████▏   | 101/163 [01:56<01:04,  1.04s/it, loss=0.2677, batch_acc=0.9688, running_acc=0.9533, grad=16.5164]Training epoch 25:  63%|██████▎   | 102/163 [01:58<01:22,  1.35s/it, loss=0.2677, batch_acc=0.9688, running_acc=0.9533, grad=16.5164]Training epoch 25:  63%|██████▎   | 102/163 [01:58<01:22,  1.35s/it, loss=0.3833, batch_acc=0.9375, running_acc=0.9531, grad=19.2055]Training epoch 25:  63%|██████▎   | 103/163 [01:59<01:12,  1.21s/it, loss=0.3833, batch_acc=0.9375, running_acc=0.9531, grad=19.2055]Training epoch 25:  63%|██████▎   | 103/163 [01:59<01:12,  1.21s/it, loss=0.2988, batch_acc=1.0000, running_acc=0.9536, grad=16.1147]Training epoch 25:  64%|██████▍   | 104/163 [02:00<01:05,  1.11s/it, loss=0.2988, batch_acc=1.0000, running_acc=0.9536, grad=16.1147]Training epoch 25:  64%|██████▍   | 104/163 [02:00<01:05,  1.11s/it, loss=0.2738, batch_acc=0.9688, running_acc=0.9537, grad=15.6005]Training epoch 25:  64%|██████▍   | 105/163 [02:00<01:00,  1.04s/it, loss=0.2738, batch_acc=0.9688, running_acc=0.9537, grad=15.6005]Training epoch 25:  64%|██████▍   | 105/163 [02:00<01:00,  1.04s/it, loss=0.2365, batch_acc=1.0000, running_acc=0.9542, grad=17.3576]Training epoch 25:  65%|██████▌   | 106/163 [02:02<01:10,  1.24s/it, loss=0.2365, batch_acc=1.0000, running_acc=0.9542, grad=17.3576]Training epoch 25:  65%|██████▌   | 106/163 [02:02<01:10,  1.24s/it, loss=0.3583, batch_acc=0.9375, running_acc=0.9540, grad=24.7229]Training epoch 25:  66%|██████▌   | 107/163 [02:03<01:03,  1.13s/it, loss=0.3583, batch_acc=0.9375, running_acc=0.9540, grad=24.7229]Training epoch 25:  66%|██████▌   | 107/163 [02:03<01:03,  1.13s/it, loss=0.3116, batch_acc=0.9688, running_acc=0.9541, grad=15.6202]Training epoch 25:  66%|██████▋   | 108/163 [02:04<00:58,  1.06s/it, loss=0.3116, batch_acc=0.9688, running_acc=0.9541, grad=15.6202]Training epoch 25:  66%|██████▋   | 108/163 [02:04<00:58,  1.06s/it, loss=0.3653, batch_acc=0.9062, running_acc=0.9537, grad=20.0837]Training epoch 25:  67%|██████▋   | 109/163 [02:05<00:54,  1.00s/it, loss=0.3653, batch_acc=0.9062, running_acc=0.9537, grad=20.0837]Training epoch 25:  67%|██████▋   | 109/163 [02:05<00:54,  1.00s/it, loss=0.3836, batch_acc=0.9688, running_acc=0.9538, grad=15.8145]Training epoch 25:  67%|██████▋   | 110/163 [02:06<00:58,  1.11s/it, loss=0.3836, batch_acc=0.9688, running_acc=0.9538, grad=15.8145]Training epoch 25:  67%|██████▋   | 110/163 [02:06<00:58,  1.11s/it, loss=0.3968, batch_acc=0.9688, running_acc=0.9540, grad=18.9273]Training epoch 25:  68%|██████▊   | 111/163 [02:07<00:53,  1.04s/it, loss=0.3968, batch_acc=0.9688, running_acc=0.9540, grad=18.9273]Training epoch 25:  68%|██████▊   | 111/163 [02:07<00:53,  1.04s/it, loss=0.3639, batch_acc=0.9375, running_acc=0.9538, grad=15.9592]Training epoch 25:  69%|██████▊   | 112/163 [02:08<00:50,  1.01it/s, loss=0.3639, batch_acc=0.9375, running_acc=0.9538, grad=15.9592]Training epoch 25:  69%|██████▊   | 112/163 [02:08<00:50,  1.01it/s, loss=0.4840, batch_acc=0.9375, running_acc=0.9537, grad=24.8280]Training epoch 25:  69%|██████▉   | 113/163 [02:09<00:47,  1.05it/s, loss=0.4840, batch_acc=0.9375, running_acc=0.9537, grad=24.8280]Training epoch 25:  69%|██████▉   | 113/163 [02:09<00:47,  1.05it/s, loss=0.3025, batch_acc=0.9688, running_acc=0.9538, grad=16.5164]Training epoch 25:  70%|██████▉   | 114/163 [02:10<00:55,  1.12s/it, loss=0.3025, batch_acc=0.9688, running_acc=0.9538, grad=16.5164]Training epoch 25:  70%|██████▉   | 114/163 [02:10<00:55,  1.12s/it, loss=0.3483, batch_acc=0.9688, running_acc=0.9539, grad=24.8640]Training epoch 25:  71%|███████   | 115/163 [02:11<00:50,  1.05s/it, loss=0.3483, batch_acc=0.9688, running_acc=0.9539, grad=24.8640]Training epoch 25:  71%|███████   | 115/163 [02:11<00:50,  1.05s/it, loss=0.2696, batch_acc=1.0000, running_acc=0.9543, grad=17.1989]Training epoch 25:  71%|███████   | 116/163 [02:12<00:46,  1.00it/s, loss=0.2696, batch_acc=1.0000, running_acc=0.9543, grad=17.1989]Training epoch 25:  71%|███████   | 116/163 [02:12<00:46,  1.00it/s, loss=0.3668, batch_acc=0.9688, running_acc=0.9545, grad=19.8056]Training epoch 25:  72%|███████▏  | 117/163 [02:13<00:44,  1.04it/s, loss=0.3668, batch_acc=0.9688, running_acc=0.9545, grad=19.8056]Training epoch 25:  72%|███████▏  | 117/163 [02:13<00:44,  1.04it/s, loss=0.2707, batch_acc=1.0000, running_acc=0.9549, grad=14.3420]Training epoch 25:  72%|███████▏  | 118/163 [02:14<00:42,  1.06it/s, loss=0.2707, batch_acc=1.0000, running_acc=0.9549, grad=14.3420]Training epoch 25:  72%|███████▏  | 118/163 [02:14<00:42,  1.06it/s, loss=0.3893, batch_acc=0.9688, running_acc=0.9550, grad=26.5020]Training epoch 25:  73%|███████▎  | 119/163 [02:15<00:40,  1.08it/s, loss=0.3893, batch_acc=0.9688, running_acc=0.9550, grad=26.5020]Training epoch 25:  73%|███████▎  | 119/163 [02:15<00:40,  1.08it/s, loss=0.4898, batch_acc=0.9062, running_acc=0.9546, grad=26.5926]Training epoch 25:  74%|███████▎  | 120/163 [02:16<00:39,  1.10it/s, loss=0.4898, batch_acc=0.9062, running_acc=0.9546, grad=26.5926]Training epoch 25:  74%|███████▎  | 120/163 [02:16<00:39,  1.10it/s, loss=0.3684, batch_acc=0.9375, running_acc=0.9544, grad=20.9876]Training epoch 25:  74%|███████▍  | 121/163 [02:17<00:42,  1.02s/it, loss=0.3684, batch_acc=0.9375, running_acc=0.9544, grad=20.9876]Training epoch 25:  74%|███████▍  | 121/163 [02:17<00:42,  1.02s/it, loss=0.3017, batch_acc=0.9688, running_acc=0.9545, grad=17.8184]Training epoch 25:  75%|███████▍  | 122/163 [02:19<00:49,  1.20s/it, loss=0.3017, batch_acc=0.9688, running_acc=0.9545, grad=17.8184]Training epoch 25:  75%|███████▍  | 122/163 [02:19<00:49,  1.20s/it, loss=0.3029, batch_acc=1.0000, running_acc=0.9549, grad=12.9107]Training epoch 25:  75%|███████▌  | 123/163 [02:19<00:44,  1.11s/it, loss=0.3029, batch_acc=1.0000, running_acc=0.9549, grad=12.9107]Training epoch 25:  75%|███████▌  | 123/163 [02:19<00:44,  1.11s/it, loss=0.3913, batch_acc=0.9688, running_acc=0.9550, grad=21.2697]Training epoch 25:  76%|███████▌  | 124/163 [02:20<00:40,  1.04s/it, loss=0.3913, batch_acc=0.9688, running_acc=0.9550, grad=21.2697]Training epoch 25:  76%|███████▌  | 124/163 [02:20<00:40,  1.04s/it, loss=0.3558, batch_acc=0.9375, running_acc=0.9549, grad=21.1460]Training epoch 25:  77%|███████▋  | 125/163 [02:21<00:38,  1.02s/it, loss=0.3558, batch_acc=0.9375, running_acc=0.9549, grad=21.1460]Training epoch 25:  77%|███████▋  | 125/163 [02:21<00:38,  1.02s/it, loss=0.3972, batch_acc=0.9375, running_acc=0.9547, grad=21.4312]Training epoch 25:  77%|███████▋  | 126/163 [02:23<00:48,  1.31s/it, loss=0.3972, batch_acc=0.9375, running_acc=0.9547, grad=21.4312]Training epoch 25:  77%|███████▋  | 126/163 [02:23<00:48,  1.31s/it, loss=0.4125, batch_acc=0.9375, running_acc=0.9546, grad=27.4109]Training epoch 25:  78%|███████▊  | 127/163 [02:24<00:42,  1.18s/it, loss=0.4125, batch_acc=0.9375, running_acc=0.9546, grad=27.4109]Training epoch 25:  78%|███████▊  | 127/163 [02:24<00:42,  1.18s/it, loss=0.3340, batch_acc=0.9688, running_acc=0.9547, grad=17.8647]Training epoch 25:  79%|███████▊  | 128/163 [02:25<00:38,  1.09s/it, loss=0.3340, batch_acc=0.9688, running_acc=0.9547, grad=17.8647]Training epoch 25:  79%|███████▊  | 128/163 [02:25<00:38,  1.09s/it, loss=0.4325, batch_acc=0.9375, running_acc=0.9546, grad=18.0833]Training epoch 25:  79%|███████▉  | 129/163 [02:26<00:34,  1.03s/it, loss=0.4325, batch_acc=0.9375, running_acc=0.9546, grad=18.0833]Training epoch 25:  79%|███████▉  | 129/163 [02:26<00:34,  1.03s/it, loss=0.3656, batch_acc=0.9375, running_acc=0.9545, grad=16.3821]Training epoch 25:  80%|███████▉  | 130/163 [02:28<00:41,  1.25s/it, loss=0.3656, batch_acc=0.9375, running_acc=0.9545, grad=16.3821]Training epoch 25:  80%|███████▉  | 130/163 [02:28<00:41,  1.25s/it, loss=0.2672, batch_acc=1.0000, running_acc=0.9548, grad=17.5239]Training epoch 25:  80%|████████  | 131/163 [02:29<00:36,  1.14s/it, loss=0.2672, batch_acc=1.0000, running_acc=0.9548, grad=17.5239]Training epoch 25:  80%|████████  | 131/163 [02:29<00:36,  1.14s/it, loss=0.4155, batch_acc=0.9375, running_acc=0.9547, grad=17.8117]Training epoch 25:  81%|████████  | 132/163 [02:29<00:32,  1.06s/it, loss=0.4155, batch_acc=0.9375, running_acc=0.9547, grad=17.8117]Training epoch 25:  81%|████████  | 132/163 [02:29<00:32,  1.06s/it, loss=0.3434, batch_acc=0.9375, running_acc=0.9545, grad=22.7401]Training epoch 25:  82%|████████▏ | 133/163 [02:30<00:30,  1.01s/it, loss=0.3434, batch_acc=0.9375, running_acc=0.9545, grad=22.7401]Training epoch 25:  82%|████████▏ | 133/163 [02:30<00:30,  1.01s/it, loss=0.3221, batch_acc=0.9062, running_acc=0.9542, grad=16.5959]Training epoch 25:  82%|████████▏ | 134/163 [02:31<00:29,  1.02s/it, loss=0.3221, batch_acc=0.9062, running_acc=0.9542, grad=16.5959]Training epoch 25:  82%|████████▏ | 134/163 [02:31<00:29,  1.02s/it, loss=0.4386, batch_acc=0.9688, running_acc=0.9543, grad=21.3560]Training epoch 25:  83%|████████▎ | 135/163 [02:32<00:27,  1.02it/s, loss=0.4386, batch_acc=0.9688, running_acc=0.9543, grad=21.3560]Training epoch 25:  83%|████████▎ | 135/163 [02:32<00:27,  1.02it/s, loss=0.3863, batch_acc=0.9062, running_acc=0.9539, grad=23.2283]Training epoch 25:  83%|████████▎ | 136/163 [02:33<00:25,  1.05it/s, loss=0.3863, batch_acc=0.9062, running_acc=0.9539, grad=23.2283]Training epoch 25:  83%|████████▎ | 136/163 [02:33<00:25,  1.05it/s, loss=0.6095, batch_acc=0.8438, running_acc=0.9531, grad=26.4787]Training epoch 25:  84%|████████▍ | 137/163 [02:34<00:27,  1.07s/it, loss=0.6095, batch_acc=0.8438, running_acc=0.9531, grad=26.4787]Training epoch 25:  84%|████████▍ | 137/163 [02:34<00:27,  1.07s/it, loss=0.3168, batch_acc=0.9688, running_acc=0.9532, grad=13.6004]Training epoch 25:  85%|████████▍ | 138/163 [02:36<00:26,  1.08s/it, loss=0.3168, batch_acc=0.9688, running_acc=0.9532, grad=13.6004]Training epoch 25:  85%|████████▍ | 138/163 [02:36<00:26,  1.08s/it, loss=0.3692, batch_acc=0.9375, running_acc=0.9531, grad=27.2487]Training epoch 25:  85%|████████▌ | 139/163 [02:36<00:24,  1.02s/it, loss=0.3692, batch_acc=0.9375, running_acc=0.9531, grad=27.2487]Training epoch 25:  85%|████████▌ | 139/163 [02:36<00:24,  1.02s/it, loss=0.3181, batch_acc=0.9062, running_acc=0.9528, grad=21.9028]Training epoch 25:  86%|████████▌ | 140/163 [02:37<00:22,  1.02it/s, loss=0.3181, batch_acc=0.9062, running_acc=0.9528, grad=21.9028]Training epoch 25:  86%|████████▌ | 140/163 [02:37<00:22,  1.02it/s, loss=0.2798, batch_acc=0.9688, running_acc=0.9529, grad=16.1132]Training epoch 25:  87%|████████▋ | 141/163 [02:39<00:24,  1.12s/it, loss=0.2798, batch_acc=0.9688, running_acc=0.9529, grad=16.1132]Training epoch 25:  87%|████████▋ | 141/163 [02:39<00:24,  1.12s/it, loss=0.4193, batch_acc=1.0000, running_acc=0.9532, grad=27.7718]Training epoch 25:  87%|████████▋ | 142/163 [02:40<00:22,  1.09s/it, loss=0.4193, batch_acc=1.0000, running_acc=0.9532, grad=27.7718]Training epoch 25:  87%|████████▋ | 142/163 [02:40<00:22,  1.09s/it, loss=0.3366, batch_acc=0.9375, running_acc=0.9531, grad=16.0058]Training epoch 25:  88%|████████▊ | 143/163 [02:41<00:20,  1.03s/it, loss=0.3366, batch_acc=0.9375, running_acc=0.9531, grad=16.0058]Training epoch 25:  88%|████████▊ | 143/163 [02:41<00:20,  1.03s/it, loss=0.3858, batch_acc=0.9375, running_acc=0.9530, grad=17.8912]Training epoch 25:  88%|████████▊ | 144/163 [02:42<00:18,  1.02it/s, loss=0.3858, batch_acc=0.9375, running_acc=0.9530, grad=17.8912]Training epoch 25:  88%|████████▊ | 144/163 [02:42<00:18,  1.02it/s, loss=0.3221, batch_acc=1.0000, running_acc=0.9533, grad=18.0860]Training epoch 25:  89%|████████▉ | 145/163 [02:43<00:18,  1.03s/it, loss=0.3221, batch_acc=1.0000, running_acc=0.9533, grad=18.0860]Training epoch 25:  89%|████████▉ | 145/163 [02:43<00:18,  1.03s/it, loss=0.3881, batch_acc=0.9688, running_acc=0.9534, grad=27.1073]Training epoch 25:  90%|████████▉ | 146/163 [02:44<00:18,  1.09s/it, loss=0.3881, batch_acc=0.9688, running_acc=0.9534, grad=27.1073]Training epoch 25:  90%|████████▉ | 146/163 [02:44<00:18,  1.09s/it, loss=0.4237, batch_acc=0.9375, running_acc=0.9533, grad=21.2641]Training epoch 25:  90%|█████████ | 147/163 [02:45<00:16,  1.03s/it, loss=0.4237, batch_acc=0.9375, running_acc=0.9533, grad=21.2641]Training epoch 25:  90%|█████████ | 147/163 [02:45<00:16,  1.03s/it, loss=0.3981, batch_acc=0.9688, running_acc=0.9534, grad=26.4143]Training epoch 25:  91%|█████████ | 148/163 [02:46<00:14,  1.02it/s, loss=0.3981, batch_acc=0.9688, running_acc=0.9534, grad=26.4143]Training epoch 25:  91%|█████████ | 148/163 [02:46<00:14,  1.02it/s, loss=0.2593, batch_acc=1.0000, running_acc=0.9538, grad=13.6932]Training epoch 25:  91%|█████████▏| 149/163 [02:47<00:16,  1.19s/it, loss=0.2593, batch_acc=1.0000, running_acc=0.9538, grad=13.6932]Training epoch 25:  91%|█████████▏| 149/163 [02:47<00:16,  1.19s/it, loss=0.2987, batch_acc=0.9688, running_acc=0.9539, grad=19.1775]Training epoch 25:  92%|█████████▏| 150/163 [02:48<00:14,  1.10s/it, loss=0.2987, batch_acc=0.9688, running_acc=0.9539, grad=19.1775]Training epoch 25:  92%|█████████▏| 150/163 [02:48<00:14,  1.10s/it, loss=0.4008, batch_acc=0.9375, running_acc=0.9537, grad=17.2890]Training epoch 25:  93%|█████████▎| 151/163 [02:49<00:12,  1.03s/it, loss=0.4008, batch_acc=0.9375, running_acc=0.9537, grad=17.2890]Training epoch 25:  93%|█████████▎| 151/163 [02:49<00:12,  1.03s/it, loss=0.3364, batch_acc=0.9375, running_acc=0.9536, grad=14.3773]Training epoch 25:  93%|█████████▎| 152/163 [02:50<00:10,  1.01it/s, loss=0.3364, batch_acc=0.9375, running_acc=0.9536, grad=14.3773]Training epoch 25:  93%|█████████▎| 152/163 [02:50<00:10,  1.01it/s, loss=0.3546, batch_acc=0.9688, running_acc=0.9537, grad=15.5522]Training epoch 25:  94%|█████████▍| 153/163 [02:52<00:12,  1.24s/it, loss=0.3546, batch_acc=0.9688, running_acc=0.9537, grad=15.5522]Training epoch 25:  94%|█████████▍| 153/163 [02:52<00:12,  1.24s/it, loss=0.3867, batch_acc=0.9375, running_acc=0.9536, grad=15.7413]Training epoch 25:  94%|█████████▍| 154/163 [02:53<00:10,  1.13s/it, loss=0.3867, batch_acc=0.9375, running_acc=0.9536, grad=15.7413]Training epoch 25:  94%|█████████▍| 154/163 [02:53<00:10,  1.13s/it, loss=0.3925, batch_acc=0.9375, running_acc=0.9535, grad=19.5377]Training epoch 25:  95%|█████████▌| 155/163 [02:54<00:08,  1.06s/it, loss=0.3925, batch_acc=0.9375, running_acc=0.9535, grad=19.5377]Training epoch 25:  95%|█████████▌| 155/163 [02:54<00:08,  1.06s/it, loss=0.6249, batch_acc=0.8750, running_acc=0.9530, grad=30.4886]Training epoch 25:  96%|█████████▌| 156/163 [02:54<00:07,  1.00s/it, loss=0.6249, batch_acc=0.8750, running_acc=0.9530, grad=30.4886]Training epoch 25:  96%|█████████▌| 156/163 [02:54<00:07,  1.00s/it, loss=0.4606, batch_acc=0.9062, running_acc=0.9527, grad=25.1645]Training epoch 25:  96%|█████████▋| 157/163 [02:56<00:06,  1.11s/it, loss=0.4606, batch_acc=0.9062, running_acc=0.9527, grad=25.1645]Training epoch 25:  96%|█████████▋| 157/163 [02:56<00:06,  1.11s/it, loss=0.3694, batch_acc=0.9062, running_acc=0.9524, grad=22.2332]Training epoch 25:  97%|█████████▋| 158/163 [02:57<00:05,  1.04s/it, loss=0.3694, batch_acc=0.9062, running_acc=0.9524, grad=22.2332]Training epoch 25:  97%|█████████▋| 158/163 [02:57<00:05,  1.04s/it, loss=0.4998, batch_acc=0.8438, running_acc=0.9517, grad=23.4704]Training epoch 25:  98%|█████████▊| 159/163 [02:58<00:03,  1.01it/s, loss=0.4998, batch_acc=0.8438, running_acc=0.9517, grad=23.4704]Training epoch 25:  98%|█████████▊| 159/163 [02:58<00:03,  1.01it/s, loss=0.2420, batch_acc=1.0000, running_acc=0.9520, grad=15.2665]Training epoch 25:  98%|█████████▊| 160/163 [02:58<00:02,  1.04it/s, loss=0.2420, batch_acc=1.0000, running_acc=0.9520, grad=15.2665]Training epoch 25:  98%|█████████▊| 160/163 [02:58<00:02,  1.04it/s, loss=0.5401, batch_acc=0.8750, running_acc=0.9516, grad=22.5212]Training epoch 25:  99%|█████████▉| 161/163 [03:00<00:02,  1.20s/it, loss=0.5401, batch_acc=0.8750, running_acc=0.9516, grad=22.5212]Training epoch 25:  99%|█████████▉| 161/163 [03:00<00:02,  1.20s/it, loss=0.2668, batch_acc=0.9375, running_acc=0.9515, grad=13.8154]Training epoch 25:  99%|█████████▉| 162/163 [03:01<00:01,  1.10s/it, loss=0.2668, batch_acc=0.9375, running_acc=0.9515, grad=13.8154]Training epoch 25:  99%|█████████▉| 162/163 [03:01<00:01,  1.10s/it, loss=0.4030, batch_acc=0.9375, running_acc=0.9514, grad=22.0984]Training epoch 25: 100%|██████████| 163/163 [03:02<00:00,  1.04it/s, loss=0.4030, batch_acc=0.9375, running_acc=0.9514, grad=22.0984]Training epoch 25: 100%|██████████| 163/163 [03:02<00:00,  1.04it/s, loss=0.4834, batch_acc=0.9524, running_acc=0.9514, grad=26.6619]Training epoch 25: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.4834, batch_acc=0.9524, running_acc=0.9514, grad=26.6619]
Evaluation epoch 25:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 25:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it]Evaluation epoch 25:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it, loss=0.5837, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 25:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.5837, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 25:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.3956, batch_acc=0.9375, running_acc=0.9219]Evaluation epoch 25:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.3956, batch_acc=0.9375, running_acc=0.9219]Evaluation epoch 25:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.5256, batch_acc=0.9375, running_acc=0.9271]Evaluation epoch 25:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.5256, batch_acc=0.9375, running_acc=0.9271]Evaluation epoch 25:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.8858, batch_acc=0.8750, running_acc=0.9141]Evaluation epoch 25:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=0.8858, batch_acc=0.8750, running_acc=0.9141]Evaluation epoch 25:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=1.6998, batch_acc=0.5312, running_acc=0.8375]Evaluation epoch 25:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.6998, batch_acc=0.5312, running_acc=0.8375]Evaluation epoch 25:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.7202, batch_acc=0.8750, running_acc=0.8438]Evaluation epoch 25:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.7202, batch_acc=0.8750, running_acc=0.8438]Evaluation epoch 25:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.8900, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 25:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.8900, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 25:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.5112, batch_acc=0.8750, running_acc=0.8477]Evaluation epoch 25:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.5112, batch_acc=0.8750, running_acc=0.8477]Evaluation epoch 25:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.7731, batch_acc=0.9062, running_acc=0.8542]Evaluation epoch 25:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.7731, batch_acc=0.9062, running_acc=0.8542]Evaluation epoch 25:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.6120, batch_acc=0.9375, running_acc=0.8625]Evaluation epoch 25:  39%|███▉      | 11/28 [00:14<00:12,  1.33it/s, loss=0.6120, batch_acc=0.9375, running_acc=0.8625]Evaluation epoch 25:  39%|███▉      | 11/28 [00:14<00:12,  1.33it/s, loss=0.6168, batch_acc=0.8438, running_acc=0.8608]Evaluation epoch 25:  43%|████▎     | 12/28 [00:20<00:36,  2.28s/it, loss=0.6168, batch_acc=0.8438, running_acc=0.8608]Evaluation epoch 25:  43%|████▎     | 12/28 [00:20<00:36,  2.28s/it, loss=1.0157, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 25:  46%|████▋     | 13/28 [00:20<00:24,  1.67s/it, loss=1.0157, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 25:  46%|████▋     | 13/28 [00:20<00:24,  1.67s/it, loss=0.5032, batch_acc=0.9375, running_acc=0.8654]Evaluation epoch 25:  50%|█████     | 14/28 [00:21<00:17,  1.24s/it, loss=0.5032, batch_acc=0.9375, running_acc=0.8654]Evaluation epoch 25:  50%|█████     | 14/28 [00:21<00:17,  1.24s/it, loss=1.0269, batch_acc=0.8125, running_acc=0.8616]Evaluation epoch 25:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.0269, batch_acc=0.8125, running_acc=0.8616]Evaluation epoch 25:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.3671, batch_acc=0.6875, running_acc=0.8500]Evaluation epoch 25:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=1.3671, batch_acc=0.6875, running_acc=0.8500]Evaluation epoch 25:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=1.0384, batch_acc=0.7812, running_acc=0.8457]Evaluation epoch 25:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=1.0384, batch_acc=0.7812, running_acc=0.8457]Evaluation epoch 25:  61%|██████    | 17/28 [00:24<00:12,  1.16s/it, loss=0.8565, batch_acc=0.6875, running_acc=0.8364]Evaluation epoch 25:  64%|██████▍   | 18/28 [00:24<00:08,  1.12it/s, loss=0.8565, batch_acc=0.6875, running_acc=0.8364]Evaluation epoch 25:  64%|██████▍   | 18/28 [00:24<00:08,  1.12it/s, loss=0.6107, batch_acc=0.8750, running_acc=0.8385]Evaluation epoch 25:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=0.6107, batch_acc=0.8750, running_acc=0.8385]Evaluation epoch 25:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=0.8746, batch_acc=0.6562, running_acc=0.8289]Evaluation epoch 25:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=0.8746, batch_acc=0.6562, running_acc=0.8289]Evaluation epoch 25:  71%|███████▏  | 20/28 [00:28<00:11,  1.40s/it, loss=0.5865, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 25:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.5865, batch_acc=0.8125, running_acc=0.8281]Evaluation epoch 25:  75%|███████▌  | 21/28 [00:28<00:07,  1.06s/it, loss=0.7295, batch_acc=0.7812, running_acc=0.8259]Evaluation epoch 25:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=0.7295, batch_acc=0.7812, running_acc=0.8259]Evaluation epoch 25:  79%|███████▊  | 22/28 [00:28<00:04,  1.22it/s, loss=0.7636, batch_acc=0.7500, running_acc=0.8224]Evaluation epoch 25:  82%|████████▏ | 23/28 [00:28<00:03,  1.53it/s, loss=0.7636, batch_acc=0.7500, running_acc=0.8224]Evaluation epoch 25:  82%|████████▏ | 23/28 [00:28<00:03,  1.53it/s, loss=0.8683, batch_acc=0.7188, running_acc=0.8179]Evaluation epoch 25:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.8683, batch_acc=0.7188, running_acc=0.8179]Evaluation epoch 25:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.4473, batch_acc=0.9375, running_acc=0.8229]Evaluation epoch 25:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.4473, batch_acc=0.9375, running_acc=0.8229]Evaluation epoch 25:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.2362, batch_acc=0.9688, running_acc=0.8287]Evaluation epoch 25:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.2362, batch_acc=0.9688, running_acc=0.8287]Evaluation epoch 25:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.9137, batch_acc=0.7812, running_acc=0.8269]Evaluation epoch 25:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.9137, batch_acc=0.7812, running_acc=0.8269]Evaluation epoch 25:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.8902, batch_acc=0.7188, running_acc=0.8229]Evaluation epoch 25: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.5000, batch_acc=0.6667, running_acc=0.8224]Evaluation epoch 25: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.5000, batch_acc=0.6667, running_acc=0.8224]
Training epoch 26:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 26:   1%|          | 1/163 [00:05<15:36,  5.78s/it]Training epoch 26:   1%|          | 1/163 [00:05<15:36,  5.78s/it, loss=0.2523, batch_acc=1.0000, running_acc=1.0000, grad=16.5848]Training epoch 26:   1%|          | 2/163 [00:06<07:46,  2.90s/it, loss=0.2523, batch_acc=1.0000, running_acc=1.0000, grad=16.5848]Training epoch 26:   1%|          | 2/163 [00:06<07:46,  2.90s/it, loss=0.4512, batch_acc=0.9375, running_acc=0.9688, grad=32.7470]Training epoch 26:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.4512, batch_acc=0.9375, running_acc=0.9688, grad=32.7470]Training epoch 26:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.2835, batch_acc=0.9375, running_acc=0.9583, grad=18.8308]Training epoch 26:   2%|▏         | 4/163 [00:10<05:51,  2.21s/it, loss=0.2835, batch_acc=0.9375, running_acc=0.9583, grad=18.8308]Training epoch 26:   2%|▏         | 4/163 [00:10<05:51,  2.21s/it, loss=0.3079, batch_acc=0.9688, running_acc=0.9609, grad=16.4081]Training epoch 26:   3%|▎         | 5/163 [00:10<04:33,  1.73s/it, loss=0.3079, batch_acc=0.9688, running_acc=0.9609, grad=16.4081]Training epoch 26:   3%|▎         | 5/163 [00:10<04:33,  1.73s/it, loss=0.3762, batch_acc=0.9688, running_acc=0.9625, grad=30.3698]Training epoch 26:   4%|▎         | 6/163 [00:11<03:46,  1.44s/it, loss=0.3762, batch_acc=0.9688, running_acc=0.9625, grad=30.3698]Training epoch 26:   4%|▎         | 6/163 [00:11<03:46,  1.44s/it, loss=0.2069, batch_acc=1.0000, running_acc=0.9688, grad=13.9401]Training epoch 26:   4%|▍         | 7/163 [00:12<03:16,  1.26s/it, loss=0.2069, batch_acc=1.0000, running_acc=0.9688, grad=13.9401]Training epoch 26:   4%|▍         | 7/163 [00:12<03:16,  1.26s/it, loss=0.4710, batch_acc=0.8750, running_acc=0.9554, grad=20.1911]Training epoch 26:   5%|▍         | 8/163 [00:14<03:49,  1.48s/it, loss=0.4710, batch_acc=0.8750, running_acc=0.9554, grad=20.1911]Training epoch 26:   5%|▍         | 8/163 [00:14<03:49,  1.48s/it, loss=0.2323, batch_acc=1.0000, running_acc=0.9609, grad=16.4613]Training epoch 26:   6%|▌         | 9/163 [00:15<03:18,  1.29s/it, loss=0.2323, batch_acc=1.0000, running_acc=0.9609, grad=16.4613]Training epoch 26:   6%|▌         | 9/163 [00:15<03:18,  1.29s/it, loss=0.3660, batch_acc=0.9688, running_acc=0.9618, grad=21.9890]Training epoch 26:   6%|▌         | 10/163 [00:16<02:58,  1.16s/it, loss=0.3660, batch_acc=0.9688, running_acc=0.9618, grad=21.9890]Training epoch 26:   6%|▌         | 10/163 [00:16<02:58,  1.16s/it, loss=0.3214, batch_acc=0.9688, running_acc=0.9625, grad=26.0508]Training epoch 26:   7%|▋         | 11/163 [00:17<02:43,  1.08s/it, loss=0.3214, batch_acc=0.9688, running_acc=0.9625, grad=26.0508]Training epoch 26:   7%|▋         | 11/163 [00:17<02:43,  1.08s/it, loss=0.5042, batch_acc=0.9062, running_acc=0.9574, grad=31.9668]Training epoch 26:   7%|▋         | 12/163 [00:18<03:05,  1.23s/it, loss=0.5042, batch_acc=0.9062, running_acc=0.9574, grad=31.9668]Training epoch 26:   7%|▋         | 12/163 [00:18<03:05,  1.23s/it, loss=0.3249, batch_acc=0.9688, running_acc=0.9583, grad=20.4965]Training epoch 26:   8%|▊         | 13/163 [00:19<02:48,  1.12s/it, loss=0.3249, batch_acc=0.9688, running_acc=0.9583, grad=20.4965]Training epoch 26:   8%|▊         | 13/163 [00:19<02:48,  1.12s/it, loss=0.4364, batch_acc=0.8750, running_acc=0.9519, grad=21.5088]Training epoch 26:   9%|▊         | 14/163 [00:20<02:36,  1.05s/it, loss=0.4364, batch_acc=0.8750, running_acc=0.9519, grad=21.5088]Training epoch 26:   9%|▊         | 14/163 [00:20<02:36,  1.05s/it, loss=0.2497, batch_acc=1.0000, running_acc=0.9554, grad=17.4666]Training epoch 26:   9%|▉         | 15/163 [00:21<02:27,  1.00it/s, loss=0.2497, batch_acc=1.0000, running_acc=0.9554, grad=17.4666]Training epoch 26:   9%|▉         | 15/163 [00:21<02:27,  1.00it/s, loss=0.2719, batch_acc=1.0000, running_acc=0.9583, grad=20.7033]Training epoch 26:  10%|▉         | 16/163 [00:23<02:58,  1.21s/it, loss=0.2719, batch_acc=1.0000, running_acc=0.9583, grad=20.7033]Training epoch 26:  10%|▉         | 16/163 [00:23<02:58,  1.21s/it, loss=0.3233, batch_acc=0.9688, running_acc=0.9590, grad=15.7047]Training epoch 26:  10%|█         | 17/163 [00:24<02:44,  1.12s/it, loss=0.3233, batch_acc=0.9688, running_acc=0.9590, grad=15.7047]Training epoch 26:  10%|█         | 17/163 [00:24<02:44,  1.12s/it, loss=0.2314, batch_acc=1.0000, running_acc=0.9614, grad=12.6568]Training epoch 26:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.2314, batch_acc=1.0000, running_acc=0.9614, grad=12.6568]Training epoch 26:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.2552, batch_acc=1.0000, running_acc=0.9635, grad=12.4564]Training epoch 26:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.2552, batch_acc=1.0000, running_acc=0.9635, grad=12.4564]Training epoch 26:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.2139, batch_acc=1.0000, running_acc=0.9655, grad=12.3378]Training epoch 26:  12%|█▏        | 20/163 [00:27<03:00,  1.26s/it, loss=0.2139, batch_acc=1.0000, running_acc=0.9655, grad=12.3378]Training epoch 26:  12%|█▏        | 20/163 [00:27<03:00,  1.26s/it, loss=0.3145, batch_acc=1.0000, running_acc=0.9672, grad=19.9477]Training epoch 26:  13%|█▎        | 21/163 [00:28<02:42,  1.15s/it, loss=0.3145, batch_acc=1.0000, running_acc=0.9672, grad=19.9477]Training epoch 26:  13%|█▎        | 21/163 [00:28<02:42,  1.15s/it, loss=0.3252, batch_acc=0.9688, running_acc=0.9673, grad=18.1767]Training epoch 26:  13%|█▎        | 22/163 [00:29<02:30,  1.07s/it, loss=0.3252, batch_acc=0.9688, running_acc=0.9673, grad=18.1767]Training epoch 26:  13%|█▎        | 22/163 [00:29<02:30,  1.07s/it, loss=0.3419, batch_acc=1.0000, running_acc=0.9688, grad=19.5918]Training epoch 26:  14%|█▍        | 23/163 [00:30<02:21,  1.01s/it, loss=0.3419, batch_acc=1.0000, running_acc=0.9688, grad=19.5918]Training epoch 26:  14%|█▍        | 23/163 [00:30<02:21,  1.01s/it, loss=0.2792, batch_acc=0.9062, running_acc=0.9660, grad=19.1639]Training epoch 26:  15%|█▍        | 24/163 [00:31<02:38,  1.14s/it, loss=0.2792, batch_acc=0.9062, running_acc=0.9660, grad=19.1639]Training epoch 26:  15%|█▍        | 24/163 [00:31<02:38,  1.14s/it, loss=0.2938, batch_acc=1.0000, running_acc=0.9674, grad=15.0275]Training epoch 26:  15%|█▌        | 25/163 [00:32<02:27,  1.07s/it, loss=0.2938, batch_acc=1.0000, running_acc=0.9674, grad=15.0275]Training epoch 26:  15%|█▌        | 25/163 [00:32<02:27,  1.07s/it, loss=0.2404, batch_acc=1.0000, running_acc=0.9688, grad=18.2098]Training epoch 26:  16%|█▌        | 26/163 [00:33<02:18,  1.01s/it, loss=0.2404, batch_acc=1.0000, running_acc=0.9688, grad=18.2098]Training epoch 26:  16%|█▌        | 26/163 [00:33<02:18,  1.01s/it, loss=0.3553, batch_acc=0.9062, running_acc=0.9663, grad=20.4513]Training epoch 26:  17%|█▋        | 27/163 [00:34<02:12,  1.03it/s, loss=0.3553, batch_acc=0.9062, running_acc=0.9663, grad=20.4513]Training epoch 26:  17%|█▋        | 27/163 [00:34<02:12,  1.03it/s, loss=0.3628, batch_acc=0.9375, running_acc=0.9653, grad=21.5057]Training epoch 26:  17%|█▋        | 28/163 [00:35<02:15,  1.00s/it, loss=0.3628, batch_acc=0.9375, running_acc=0.9653, grad=21.5057]Training epoch 26:  17%|█▋        | 28/163 [00:35<02:15,  1.00s/it, loss=0.3274, batch_acc=0.9688, running_acc=0.9654, grad=19.1907]Training epoch 26:  18%|█▊        | 29/163 [00:36<02:17,  1.03s/it, loss=0.3274, batch_acc=0.9688, running_acc=0.9654, grad=19.1907]Training epoch 26:  18%|█▊        | 29/163 [00:36<02:17,  1.03s/it, loss=0.3876, batch_acc=0.9688, running_acc=0.9655, grad=16.3638]Training epoch 26:  18%|█▊        | 30/163 [00:37<02:10,  1.02it/s, loss=0.3876, batch_acc=0.9688, running_acc=0.9655, grad=16.3638]Training epoch 26:  18%|█▊        | 30/163 [00:37<02:10,  1.02it/s, loss=0.3420, batch_acc=0.9688, running_acc=0.9656, grad=24.4216]Training epoch 26:  19%|█▉        | 31/163 [00:38<02:05,  1.05it/s, loss=0.3420, batch_acc=0.9688, running_acc=0.9656, grad=24.4216]Training epoch 26:  19%|█▉        | 31/163 [00:38<02:05,  1.05it/s, loss=0.2602, batch_acc=0.9688, running_acc=0.9657, grad=15.0588]Training epoch 26:  20%|█▉        | 32/163 [00:39<02:21,  1.08s/it, loss=0.2602, batch_acc=0.9688, running_acc=0.9657, grad=15.0588]Training epoch 26:  20%|█▉        | 32/163 [00:39<02:21,  1.08s/it, loss=0.3460, batch_acc=0.9375, running_acc=0.9648, grad=19.2280]Training epoch 26:  20%|██        | 33/163 [00:41<02:41,  1.25s/it, loss=0.3460, batch_acc=0.9375, running_acc=0.9648, grad=19.2280]Training epoch 26:  20%|██        | 33/163 [00:41<02:41,  1.25s/it, loss=0.3015, batch_acc=0.9688, running_acc=0.9650, grad=16.8720]Training epoch 26:  21%|██        | 34/163 [00:42<02:26,  1.14s/it, loss=0.3015, batch_acc=0.9688, running_acc=0.9650, grad=16.8720]Training epoch 26:  21%|██        | 34/163 [00:42<02:26,  1.14s/it, loss=0.3370, batch_acc=0.9688, running_acc=0.9651, grad=27.0770]Training epoch 26:  21%|██▏       | 35/163 [00:43<02:15,  1.06s/it, loss=0.3370, batch_acc=0.9688, running_acc=0.9651, grad=27.0770]Training epoch 26:  21%|██▏       | 35/163 [00:43<02:15,  1.06s/it, loss=0.2997, batch_acc=0.9688, running_acc=0.9652, grad=13.3336]Training epoch 26:  22%|██▏       | 36/163 [00:44<02:08,  1.01s/it, loss=0.2997, batch_acc=0.9688, running_acc=0.9652, grad=13.3336]Training epoch 26:  22%|██▏       | 36/163 [00:44<02:08,  1.01s/it, loss=0.2632, batch_acc=1.0000, running_acc=0.9661, grad=16.5836]Training epoch 26:  23%|██▎       | 37/163 [00:45<02:39,  1.26s/it, loss=0.2632, batch_acc=1.0000, running_acc=0.9661, grad=16.5836]Training epoch 26:  23%|██▎       | 37/163 [00:45<02:39,  1.26s/it, loss=0.3344, batch_acc=0.9375, running_acc=0.9654, grad=25.7879]Training epoch 26:  23%|██▎       | 38/163 [00:46<02:23,  1.15s/it, loss=0.3344, batch_acc=0.9375, running_acc=0.9654, grad=25.7879]Training epoch 26:  23%|██▎       | 38/163 [00:46<02:23,  1.15s/it, loss=0.2688, batch_acc=0.9688, running_acc=0.9655, grad=21.0169]Training epoch 26:  24%|██▍       | 39/163 [00:47<02:12,  1.07s/it, loss=0.2688, batch_acc=0.9688, running_acc=0.9655, grad=21.0169]Training epoch 26:  24%|██▍       | 39/163 [00:47<02:12,  1.07s/it, loss=0.3196, batch_acc=0.9688, running_acc=0.9655, grad=18.5565]Training epoch 26:  25%|██▍       | 40/163 [00:48<02:04,  1.01s/it, loss=0.3196, batch_acc=0.9688, running_acc=0.9655, grad=18.5565]Training epoch 26:  25%|██▍       | 40/163 [00:48<02:04,  1.01s/it, loss=0.3796, batch_acc=0.9062, running_acc=0.9641, grad=18.7890]Training epoch 26:  25%|██▌       | 41/163 [00:50<02:45,  1.36s/it, loss=0.3796, batch_acc=0.9062, running_acc=0.9641, grad=18.7890]Training epoch 26:  25%|██▌       | 41/163 [00:50<02:45,  1.36s/it, loss=0.2811, batch_acc=0.9688, running_acc=0.9642, grad=15.4024]Training epoch 26:  26%|██▌       | 42/163 [00:51<02:27,  1.22s/it, loss=0.2811, batch_acc=0.9688, running_acc=0.9642, grad=15.4024]Training epoch 26:  26%|██▌       | 42/163 [00:51<02:27,  1.22s/it, loss=0.3258, batch_acc=0.9688, running_acc=0.9643, grad=21.3039]Training epoch 26:  26%|██▋       | 43/163 [00:52<02:13,  1.11s/it, loss=0.3258, batch_acc=0.9688, running_acc=0.9643, grad=21.3039]Training epoch 26:  26%|██▋       | 43/163 [00:52<02:13,  1.11s/it, loss=0.3379, batch_acc=0.9375, running_acc=0.9637, grad=18.5070]Training epoch 26:  27%|██▋       | 44/163 [00:53<02:07,  1.07s/it, loss=0.3379, batch_acc=0.9375, running_acc=0.9637, grad=18.5070]Training epoch 26:  27%|██▋       | 44/163 [00:53<02:07,  1.07s/it, loss=0.3292, batch_acc=0.9375, running_acc=0.9631, grad=25.0176]Training epoch 26:  28%|██▊       | 45/163 [00:55<02:54,  1.48s/it, loss=0.3292, batch_acc=0.9375, running_acc=0.9631, grad=25.0176]Training epoch 26:  28%|██▊       | 45/163 [00:55<02:54,  1.48s/it, loss=0.5558, batch_acc=0.9688, running_acc=0.9632, grad=21.2040]Training epoch 26:  28%|██▊       | 46/163 [00:56<02:32,  1.30s/it, loss=0.5558, batch_acc=0.9688, running_acc=0.9632, grad=21.2040]Training epoch 26:  28%|██▊       | 46/163 [00:56<02:32,  1.30s/it, loss=0.2345, batch_acc=1.0000, running_acc=0.9640, grad=15.8212]Training epoch 26:  29%|██▉       | 47/163 [00:57<02:16,  1.17s/it, loss=0.2345, batch_acc=1.0000, running_acc=0.9640, grad=15.8212]Training epoch 26:  29%|██▉       | 47/163 [00:57<02:16,  1.17s/it, loss=0.3445, batch_acc=0.9375, running_acc=0.9634, grad=18.5365]Training epoch 26:  29%|██▉       | 48/163 [00:58<02:04,  1.09s/it, loss=0.3445, batch_acc=0.9375, running_acc=0.9634, grad=18.5365]Training epoch 26:  29%|██▉       | 48/163 [00:58<02:04,  1.09s/it, loss=0.2749, batch_acc=0.9688, running_acc=0.9635, grad=14.0597]Training epoch 26:  30%|███       | 49/163 [00:59<02:14,  1.18s/it, loss=0.2749, batch_acc=0.9688, running_acc=0.9635, grad=14.0597]Training epoch 26:  30%|███       | 49/163 [00:59<02:14,  1.18s/it, loss=0.3255, batch_acc=0.9375, running_acc=0.9630, grad=18.2757]Training epoch 26:  31%|███       | 50/163 [01:00<02:03,  1.09s/it, loss=0.3255, batch_acc=0.9375, running_acc=0.9630, grad=18.2757]Training epoch 26:  31%|███       | 50/163 [01:00<02:03,  1.09s/it, loss=0.2821, batch_acc=0.9688, running_acc=0.9631, grad=20.3939]Training epoch 26:  31%|███▏      | 51/163 [01:01<01:55,  1.03s/it, loss=0.2821, batch_acc=0.9688, running_acc=0.9631, grad=20.3939]Training epoch 26:  31%|███▏      | 51/163 [01:01<01:55,  1.03s/it, loss=0.4245, batch_acc=0.9375, running_acc=0.9626, grad=22.4901]Training epoch 26:  32%|███▏      | 52/163 [01:02<01:49,  1.02it/s, loss=0.4245, batch_acc=0.9375, running_acc=0.9626, grad=22.4901]Training epoch 26:  32%|███▏      | 52/163 [01:02<01:49,  1.02it/s, loss=0.3590, batch_acc=0.9062, running_acc=0.9615, grad=20.4690]Training epoch 26:  33%|███▎      | 53/163 [01:04<02:14,  1.23s/it, loss=0.3590, batch_acc=0.9062, running_acc=0.9615, grad=20.4690]Training epoch 26:  33%|███▎      | 53/163 [01:04<02:14,  1.23s/it, loss=0.2641, batch_acc=0.9688, running_acc=0.9617, grad=12.0341]Training epoch 26:  33%|███▎      | 54/163 [01:05<02:02,  1.12s/it, loss=0.2641, batch_acc=0.9688, running_acc=0.9617, grad=12.0341]Training epoch 26:  33%|███▎      | 54/163 [01:05<02:02,  1.12s/it, loss=0.3401, batch_acc=0.9688, running_acc=0.9618, grad=22.5263]Training epoch 26:  34%|███▎      | 55/163 [01:06<01:53,  1.05s/it, loss=0.3401, batch_acc=0.9688, running_acc=0.9618, grad=22.5263]Training epoch 26:  34%|███▎      | 55/163 [01:06<01:53,  1.05s/it, loss=0.3811, batch_acc=0.9688, running_acc=0.9619, grad=26.2422]Training epoch 26:  34%|███▍      | 56/163 [01:07<01:46,  1.00it/s, loss=0.3811, batch_acc=0.9688, running_acc=0.9619, grad=26.2422]Training epoch 26:  34%|███▍      | 56/163 [01:07<01:46,  1.00it/s, loss=0.4862, batch_acc=0.8750, running_acc=0.9604, grad=20.4112]Training epoch 26:  35%|███▍      | 57/163 [01:09<02:16,  1.29s/it, loss=0.4862, batch_acc=0.8750, running_acc=0.9604, grad=20.4112]Training epoch 26:  35%|███▍      | 57/163 [01:09<02:16,  1.29s/it, loss=0.2891, batch_acc=1.0000, running_acc=0.9611, grad=15.4070]Training epoch 26:  36%|███▌      | 58/163 [01:09<02:02,  1.16s/it, loss=0.2891, batch_acc=1.0000, running_acc=0.9611, grad=15.4070]Training epoch 26:  36%|███▌      | 58/163 [01:09<02:02,  1.16s/it, loss=0.2031, batch_acc=1.0000, running_acc=0.9617, grad=15.0264]Training epoch 26:  36%|███▌      | 59/163 [01:10<01:52,  1.08s/it, loss=0.2031, batch_acc=1.0000, running_acc=0.9617, grad=15.0264]Training epoch 26:  36%|███▌      | 59/163 [01:10<01:52,  1.08s/it, loss=0.3705, batch_acc=0.9062, running_acc=0.9608, grad=29.4949]Training epoch 26:  37%|███▋      | 60/163 [01:11<01:44,  1.02s/it, loss=0.3705, batch_acc=0.9062, running_acc=0.9608, grad=29.4949]Training epoch 26:  37%|███▋      | 60/163 [01:11<01:44,  1.02s/it, loss=0.2805, batch_acc=0.9688, running_acc=0.9609, grad=21.0048]Training epoch 26:  37%|███▋      | 61/163 [01:13<02:11,  1.29s/it, loss=0.2805, batch_acc=0.9688, running_acc=0.9609, grad=21.0048]Training epoch 26:  37%|███▋      | 61/163 [01:13<02:11,  1.29s/it, loss=0.3098, batch_acc=1.0000, running_acc=0.9616, grad=18.9974]Training epoch 26:  38%|███▊      | 62/163 [01:14<01:57,  1.17s/it, loss=0.3098, batch_acc=1.0000, running_acc=0.9616, grad=18.9974]Training epoch 26:  38%|███▊      | 62/163 [01:14<01:57,  1.17s/it, loss=0.3810, batch_acc=0.9062, running_acc=0.9607, grad=15.4978]Training epoch 26:  39%|███▊      | 63/163 [01:15<01:48,  1.08s/it, loss=0.3810, batch_acc=0.9062, running_acc=0.9607, grad=15.4978]Training epoch 26:  39%|███▊      | 63/163 [01:15<01:48,  1.08s/it, loss=0.2545, batch_acc=1.0000, running_acc=0.9613, grad=15.9549]Training epoch 26:  39%|███▉      | 64/163 [01:16<01:41,  1.02s/it, loss=0.2545, batch_acc=1.0000, running_acc=0.9613, grad=15.9549]Training epoch 26:  39%|███▉      | 64/163 [01:16<01:41,  1.02s/it, loss=0.3971, batch_acc=0.9688, running_acc=0.9614, grad=25.8615]Training epoch 26:  40%|███▉      | 65/163 [01:18<02:07,  1.31s/it, loss=0.3971, batch_acc=0.9688, running_acc=0.9614, grad=25.8615]Training epoch 26:  40%|███▉      | 65/163 [01:18<02:07,  1.31s/it, loss=0.3732, batch_acc=0.9062, running_acc=0.9606, grad=17.5045]Training epoch 26:  40%|████      | 66/163 [01:19<01:54,  1.18s/it, loss=0.3732, batch_acc=0.9062, running_acc=0.9606, grad=17.5045]Training epoch 26:  40%|████      | 66/163 [01:19<01:54,  1.18s/it, loss=0.3432, batch_acc=0.9375, running_acc=0.9602, grad=18.7056]Training epoch 26:  41%|████      | 67/163 [01:19<01:44,  1.09s/it, loss=0.3432, batch_acc=0.9375, running_acc=0.9602, grad=18.7056]Training epoch 26:  41%|████      | 67/163 [01:19<01:44,  1.09s/it, loss=0.2539, batch_acc=1.0000, running_acc=0.9608, grad=13.8211]Training epoch 26:  42%|████▏     | 68/163 [01:20<01:37,  1.03s/it, loss=0.2539, batch_acc=1.0000, running_acc=0.9608, grad=13.8211]Training epoch 26:  42%|████▏     | 68/163 [01:20<01:37,  1.03s/it, loss=0.3001, batch_acc=0.9688, running_acc=0.9609, grad=21.1988]Training epoch 26:  42%|████▏     | 69/163 [01:22<01:57,  1.26s/it, loss=0.3001, batch_acc=0.9688, running_acc=0.9609, grad=21.1988]Training epoch 26:  42%|████▏     | 69/163 [01:22<01:57,  1.26s/it, loss=0.3225, batch_acc=0.9688, running_acc=0.9611, grad=21.6598]Training epoch 26:  43%|████▎     | 70/163 [01:23<01:46,  1.14s/it, loss=0.3225, batch_acc=0.9688, running_acc=0.9611, grad=21.6598]Training epoch 26:  43%|████▎     | 70/163 [01:23<01:46,  1.14s/it, loss=0.4569, batch_acc=0.9375, running_acc=0.9607, grad=31.5961]Training epoch 26:  44%|████▎     | 71/163 [01:24<01:37,  1.06s/it, loss=0.4569, batch_acc=0.9375, running_acc=0.9607, grad=31.5961]Training epoch 26:  44%|████▎     | 71/163 [01:24<01:37,  1.06s/it, loss=0.5102, batch_acc=0.8750, running_acc=0.9595, grad=25.3511]Training epoch 26:  44%|████▍     | 72/163 [01:25<01:31,  1.01s/it, loss=0.5102, batch_acc=0.8750, running_acc=0.9595, grad=25.3511]Training epoch 26:  44%|████▍     | 72/163 [01:25<01:31,  1.01s/it, loss=0.3598, batch_acc=0.9375, running_acc=0.9592, grad=17.7779]Training epoch 26:  45%|████▍     | 73/163 [01:27<01:52,  1.25s/it, loss=0.3598, batch_acc=0.9375, running_acc=0.9592, grad=17.7779]Training epoch 26:  45%|████▍     | 73/163 [01:27<01:52,  1.25s/it, loss=0.4311, batch_acc=0.9375, running_acc=0.9589, grad=21.1920]Training epoch 26:  45%|████▌     | 74/163 [01:27<01:41,  1.14s/it, loss=0.4311, batch_acc=0.9375, running_acc=0.9589, grad=21.1920]Training epoch 26:  45%|████▌     | 74/163 [01:27<01:41,  1.14s/it, loss=0.4052, batch_acc=0.9375, running_acc=0.9586, grad=20.6538]Training epoch 26:  46%|████▌     | 75/163 [01:28<01:33,  1.06s/it, loss=0.4052, batch_acc=0.9375, running_acc=0.9586, grad=20.6538]Training epoch 26:  46%|████▌     | 75/163 [01:28<01:33,  1.06s/it, loss=0.3015, batch_acc=1.0000, running_acc=0.9592, grad=18.5335]Training epoch 26:  47%|████▋     | 76/163 [01:29<01:27,  1.01s/it, loss=0.3015, batch_acc=1.0000, running_acc=0.9592, grad=18.5335]Training epoch 26:  47%|████▋     | 76/163 [01:29<01:27,  1.01s/it, loss=0.4036, batch_acc=0.9688, running_acc=0.9593, grad=31.6998]Training epoch 26:  47%|████▋     | 77/163 [01:31<01:58,  1.38s/it, loss=0.4036, batch_acc=0.9688, running_acc=0.9593, grad=31.6998]Training epoch 26:  47%|████▋     | 77/163 [01:31<01:58,  1.38s/it, loss=0.2512, batch_acc=1.0000, running_acc=0.9598, grad=16.4113]Training epoch 26:  48%|████▊     | 78/163 [01:32<01:44,  1.23s/it, loss=0.2512, batch_acc=1.0000, running_acc=0.9598, grad=16.4113]Training epoch 26:  48%|████▊     | 78/163 [01:32<01:44,  1.23s/it, loss=0.2651, batch_acc=0.9688, running_acc=0.9599, grad=14.1068]Training epoch 26:  48%|████▊     | 79/163 [01:33<01:34,  1.12s/it, loss=0.2651, batch_acc=0.9688, running_acc=0.9599, grad=14.1068]Training epoch 26:  48%|████▊     | 79/163 [01:33<01:34,  1.12s/it, loss=0.3643, batch_acc=0.9375, running_acc=0.9597, grad=16.6101]Training epoch 26:  49%|████▉     | 80/163 [01:34<01:27,  1.05s/it, loss=0.3643, batch_acc=0.9375, running_acc=0.9597, grad=16.6101]Training epoch 26:  49%|████▉     | 80/163 [01:34<01:27,  1.05s/it, loss=0.3562, batch_acc=0.9375, running_acc=0.9594, grad=22.9163]Training epoch 26:  50%|████▉     | 81/163 [01:36<01:41,  1.24s/it, loss=0.3562, batch_acc=0.9375, running_acc=0.9594, grad=22.9163]Training epoch 26:  50%|████▉     | 81/163 [01:36<01:41,  1.24s/it, loss=0.2822, batch_acc=0.9688, running_acc=0.9595, grad=14.5897]Training epoch 26:  50%|█████     | 82/163 [01:37<01:31,  1.13s/it, loss=0.2822, batch_acc=0.9688, running_acc=0.9595, grad=14.5897]Training epoch 26:  50%|█████     | 82/163 [01:37<01:31,  1.13s/it, loss=0.2230, batch_acc=1.0000, running_acc=0.9600, grad=13.9704]Training epoch 26:  51%|█████     | 83/163 [01:38<01:24,  1.06s/it, loss=0.2230, batch_acc=1.0000, running_acc=0.9600, grad=13.9704]Training epoch 26:  51%|█████     | 83/163 [01:38<01:24,  1.06s/it, loss=0.4951, batch_acc=0.8750, running_acc=0.9590, grad=27.1970]Training epoch 26:  52%|█████▏    | 84/163 [01:38<01:19,  1.00s/it, loss=0.4951, batch_acc=0.8750, running_acc=0.9590, grad=27.1970]Training epoch 26:  52%|█████▏    | 84/163 [01:38<01:19,  1.00s/it, loss=0.2990, batch_acc=1.0000, running_acc=0.9594, grad=18.9648]Training epoch 26:  52%|█████▏    | 85/163 [01:40<01:37,  1.24s/it, loss=0.2990, batch_acc=1.0000, running_acc=0.9594, grad=18.9648]Training epoch 26:  52%|█████▏    | 85/163 [01:40<01:37,  1.24s/it, loss=0.3543, batch_acc=0.9375, running_acc=0.9592, grad=22.1898]Training epoch 26:  53%|█████▎    | 86/163 [01:41<01:27,  1.14s/it, loss=0.3543, batch_acc=0.9375, running_acc=0.9592, grad=22.1898]Training epoch 26:  53%|█████▎    | 86/163 [01:41<01:27,  1.14s/it, loss=0.1956, batch_acc=1.0000, running_acc=0.9597, grad=12.9616]Training epoch 26:  53%|█████▎    | 87/163 [01:42<01:20,  1.06s/it, loss=0.1956, batch_acc=1.0000, running_acc=0.9597, grad=12.9616]Training epoch 26:  53%|█████▎    | 87/163 [01:42<01:20,  1.06s/it, loss=0.3054, batch_acc=0.9688, running_acc=0.9598, grad=15.8188]Training epoch 26:  54%|█████▍    | 88/163 [01:43<01:15,  1.01s/it, loss=0.3054, batch_acc=0.9688, running_acc=0.9598, grad=15.8188]Training epoch 26:  54%|█████▍    | 88/163 [01:43<01:15,  1.01s/it, loss=0.4019, batch_acc=0.9375, running_acc=0.9595, grad=27.1294]Training epoch 26:  55%|█████▍    | 89/163 [01:45<01:28,  1.20s/it, loss=0.4019, batch_acc=0.9375, running_acc=0.9595, grad=27.1294]Training epoch 26:  55%|█████▍    | 89/163 [01:45<01:28,  1.20s/it, loss=0.3057, batch_acc=0.9375, running_acc=0.9593, grad=15.5821]Training epoch 26:  55%|█████▌    | 90/163 [01:45<01:20,  1.10s/it, loss=0.3057, batch_acc=0.9375, running_acc=0.9593, grad=15.5821]Training epoch 26:  55%|█████▌    | 90/163 [01:45<01:20,  1.10s/it, loss=0.3219, batch_acc=0.9688, running_acc=0.9594, grad=21.1204]Training epoch 26:  56%|█████▌    | 91/163 [01:46<01:14,  1.04s/it, loss=0.3219, batch_acc=0.9688, running_acc=0.9594, grad=21.1204]Training epoch 26:  56%|█████▌    | 91/163 [01:46<01:14,  1.04s/it, loss=0.4084, batch_acc=0.9062, running_acc=0.9588, grad=21.0595]Training epoch 26:  56%|█████▋    | 92/163 [01:47<01:10,  1.01it/s, loss=0.4084, batch_acc=0.9062, running_acc=0.9588, grad=21.0595]Training epoch 26:  56%|█████▋    | 92/163 [01:47<01:10,  1.01it/s, loss=0.2788, batch_acc=0.9688, running_acc=0.9589, grad=15.4749]Training epoch 26:  57%|█████▋    | 93/163 [01:49<01:17,  1.11s/it, loss=0.2788, batch_acc=0.9688, running_acc=0.9589, grad=15.4749]Training epoch 26:  57%|█████▋    | 93/163 [01:49<01:17,  1.11s/it, loss=0.3694, batch_acc=0.9688, running_acc=0.9590, grad=18.4777]Training epoch 26:  58%|█████▊    | 94/163 [01:49<01:11,  1.04s/it, loss=0.3694, batch_acc=0.9688, running_acc=0.9590, grad=18.4777]Training epoch 26:  58%|█████▊    | 94/163 [01:49<01:11,  1.04s/it, loss=0.2529, batch_acc=1.0000, running_acc=0.9594, grad=12.8267]Training epoch 26:  58%|█████▊    | 95/163 [01:50<01:07,  1.01it/s, loss=0.2529, batch_acc=1.0000, running_acc=0.9594, grad=12.8267]Training epoch 26:  58%|█████▊    | 95/163 [01:50<01:07,  1.01it/s, loss=0.3538, batch_acc=0.9688, running_acc=0.9595, grad=16.7431]Training epoch 26:  59%|█████▉    | 96/163 [01:51<01:04,  1.05it/s, loss=0.3538, batch_acc=0.9688, running_acc=0.9595, grad=16.7431]Training epoch 26:  59%|█████▉    | 96/163 [01:51<01:04,  1.05it/s, loss=0.3358, batch_acc=0.9688, running_acc=0.9596, grad=16.2412]Training epoch 26:  60%|█████▉    | 97/163 [01:53<01:18,  1.19s/it, loss=0.3358, batch_acc=0.9688, running_acc=0.9596, grad=16.2412]Training epoch 26:  60%|█████▉    | 97/163 [01:53<01:18,  1.19s/it, loss=0.3318, batch_acc=0.8750, running_acc=0.9588, grad=22.8609]Training epoch 26:  60%|██████    | 98/163 [01:54<01:11,  1.10s/it, loss=0.3318, batch_acc=0.8750, running_acc=0.9588, grad=22.8609]Training epoch 26:  60%|██████    | 98/163 [01:54<01:11,  1.10s/it, loss=0.3354, batch_acc=0.9375, running_acc=0.9585, grad=16.0897]Training epoch 26:  61%|██████    | 99/163 [01:55<01:06,  1.03s/it, loss=0.3354, batch_acc=0.9375, running_acc=0.9585, grad=16.0897]Training epoch 26:  61%|██████    | 99/163 [01:55<01:06,  1.03s/it, loss=0.2837, batch_acc=1.0000, running_acc=0.9590, grad=15.0737]Training epoch 26:  61%|██████▏   | 100/163 [01:56<01:02,  1.01it/s, loss=0.2837, batch_acc=1.0000, running_acc=0.9590, grad=15.0737]Training epoch 26:  61%|██████▏   | 100/163 [01:56<01:02,  1.01it/s, loss=0.3421, batch_acc=0.9375, running_acc=0.9587, grad=21.8014]Training epoch 26:  62%|██████▏   | 101/163 [01:57<01:18,  1.26s/it, loss=0.3421, batch_acc=0.9375, running_acc=0.9587, grad=21.8014]Training epoch 26:  62%|██████▏   | 101/163 [01:57<01:18,  1.26s/it, loss=0.3757, batch_acc=0.9375, running_acc=0.9585, grad=17.5080]Training epoch 26:  63%|██████▎   | 102/163 [01:58<01:10,  1.15s/it, loss=0.3757, batch_acc=0.9375, running_acc=0.9585, grad=17.5080]Training epoch 26:  63%|██████▎   | 102/163 [01:58<01:10,  1.15s/it, loss=0.2729, batch_acc=1.0000, running_acc=0.9589, grad=14.7967]Training epoch 26:  63%|██████▎   | 103/163 [01:59<01:04,  1.07s/it, loss=0.2729, batch_acc=1.0000, running_acc=0.9589, grad=14.7967]Training epoch 26:  63%|██████▎   | 103/163 [01:59<01:04,  1.07s/it, loss=0.4190, batch_acc=0.9375, running_acc=0.9587, grad=17.7928]Training epoch 26:  64%|██████▍   | 104/163 [02:00<00:59,  1.01s/it, loss=0.4190, batch_acc=0.9375, running_acc=0.9587, grad=17.7928]Training epoch 26:  64%|██████▍   | 104/163 [02:00<00:59,  1.01s/it, loss=0.3005, batch_acc=0.9375, running_acc=0.9585, grad=14.5700]Training epoch 26:  64%|██████▍   | 105/163 [02:02<01:08,  1.18s/it, loss=0.3005, batch_acc=0.9375, running_acc=0.9585, grad=14.5700]Training epoch 26:  64%|██████▍   | 105/163 [02:02<01:08,  1.18s/it, loss=0.3676, batch_acc=0.9375, running_acc=0.9583, grad=20.4721]Training epoch 26:  65%|██████▌   | 106/163 [02:03<01:02,  1.09s/it, loss=0.3676, batch_acc=0.9375, running_acc=0.9583, grad=20.4721]Training epoch 26:  65%|██████▌   | 106/163 [02:03<01:02,  1.09s/it, loss=0.3745, batch_acc=0.9062, running_acc=0.9578, grad=23.0951]Training epoch 26:  66%|██████▌   | 107/163 [02:03<00:57,  1.03s/it, loss=0.3745, batch_acc=0.9062, running_acc=0.9578, grad=23.0951]Training epoch 26:  66%|██████▌   | 107/163 [02:03<00:57,  1.03s/it, loss=0.3874, batch_acc=0.9688, running_acc=0.9579, grad=24.5520]Training epoch 26:  66%|██████▋   | 108/163 [02:04<00:53,  1.02it/s, loss=0.3874, batch_acc=0.9688, running_acc=0.9579, grad=24.5520]Training epoch 26:  66%|██████▋   | 108/163 [02:04<00:53,  1.02it/s, loss=0.4827, batch_acc=0.9062, running_acc=0.9575, grad=26.6964]Training epoch 26:  67%|██████▋   | 109/163 [02:06<01:09,  1.28s/it, loss=0.4827, batch_acc=0.9062, running_acc=0.9575, grad=26.6964]Training epoch 26:  67%|██████▋   | 109/163 [02:06<01:09,  1.28s/it, loss=0.2283, batch_acc=1.0000, running_acc=0.9579, grad=17.1206]Training epoch 26:  67%|██████▋   | 110/163 [02:07<01:01,  1.16s/it, loss=0.2283, batch_acc=1.0000, running_acc=0.9579, grad=17.1206]Training epoch 26:  67%|██████▋   | 110/163 [02:07<01:01,  1.16s/it, loss=0.4635, batch_acc=0.9062, running_acc=0.9574, grad=26.8097]Training epoch 26:  68%|██████▊   | 111/163 [02:08<00:56,  1.08s/it, loss=0.4635, batch_acc=0.9062, running_acc=0.9574, grad=26.8097]Training epoch 26:  68%|██████▊   | 111/163 [02:08<00:56,  1.08s/it, loss=0.3553, batch_acc=0.9375, running_acc=0.9572, grad=24.8193]Training epoch 26:  69%|██████▊   | 112/163 [02:09<00:51,  1.02s/it, loss=0.3553, batch_acc=0.9375, running_acc=0.9572, grad=24.8193]Training epoch 26:  69%|██████▊   | 112/163 [02:09<00:51,  1.02s/it, loss=0.3209, batch_acc=0.9688, running_acc=0.9573, grad=22.8226]Training epoch 26:  69%|██████▉   | 113/163 [02:10<00:54,  1.10s/it, loss=0.3209, batch_acc=0.9688, running_acc=0.9573, grad=22.8226]Training epoch 26:  69%|██████▉   | 113/163 [02:10<00:54,  1.10s/it, loss=0.3455, batch_acc=0.9062, running_acc=0.9569, grad=19.7217]Training epoch 26:  70%|██████▉   | 114/163 [02:11<00:50,  1.03s/it, loss=0.3455, batch_acc=0.9062, running_acc=0.9569, grad=19.7217]Training epoch 26:  70%|██████▉   | 114/163 [02:11<00:50,  1.03s/it, loss=0.3082, batch_acc=1.0000, running_acc=0.9572, grad=17.5894]Training epoch 26:  71%|███████   | 115/163 [02:12<00:47,  1.01it/s, loss=0.3082, batch_acc=1.0000, running_acc=0.9572, grad=17.5894]Training epoch 26:  71%|███████   | 115/163 [02:12<00:47,  1.01it/s, loss=0.3057, batch_acc=0.9062, running_acc=0.9568, grad=16.5938]Training epoch 26:  71%|███████   | 116/163 [02:13<00:44,  1.05it/s, loss=0.3057, batch_acc=0.9062, running_acc=0.9568, grad=16.5938]Training epoch 26:  71%|███████   | 116/163 [02:13<00:44,  1.05it/s, loss=0.3547, batch_acc=1.0000, running_acc=0.9572, grad=28.7329]Training epoch 26:  72%|███████▏  | 117/163 [02:15<00:59,  1.29s/it, loss=0.3547, batch_acc=1.0000, running_acc=0.9572, grad=28.7329]Training epoch 26:  72%|███████▏  | 117/163 [02:15<00:59,  1.29s/it, loss=0.3051, batch_acc=0.9688, running_acc=0.9573, grad=18.9425]Training epoch 26:  72%|███████▏  | 118/163 [02:16<00:52,  1.17s/it, loss=0.3051, batch_acc=0.9688, running_acc=0.9573, grad=18.9425]Training epoch 26:  72%|███████▏  | 118/163 [02:16<00:52,  1.17s/it, loss=0.2845, batch_acc=0.9375, running_acc=0.9571, grad=16.1493]Training epoch 26:  73%|███████▎  | 119/163 [02:17<00:47,  1.08s/it, loss=0.2845, batch_acc=0.9375, running_acc=0.9571, grad=16.1493]Training epoch 26:  73%|███████▎  | 119/163 [02:17<00:47,  1.08s/it, loss=0.3109, batch_acc=0.9688, running_acc=0.9572, grad=17.6870]Training epoch 26:  74%|███████▎  | 120/163 [02:18<00:43,  1.02s/it, loss=0.3109, batch_acc=0.9688, running_acc=0.9572, grad=17.6870]Training epoch 26:  74%|███████▎  | 120/163 [02:18<00:43,  1.02s/it, loss=0.3929, batch_acc=0.9375, running_acc=0.9570, grad=21.6110]Training epoch 26:  74%|███████▍  | 121/163 [02:20<00:57,  1.37s/it, loss=0.3929, batch_acc=0.9375, running_acc=0.9570, grad=21.6110]Training epoch 26:  74%|███████▍  | 121/163 [02:20<00:57,  1.37s/it, loss=0.2731, batch_acc=0.9375, running_acc=0.9569, grad=18.3441]Training epoch 26:  75%|███████▍  | 122/163 [02:21<00:50,  1.22s/it, loss=0.2731, batch_acc=0.9375, running_acc=0.9569, grad=18.3441]Training epoch 26:  75%|███████▍  | 122/163 [02:21<00:50,  1.22s/it, loss=0.2654, batch_acc=1.0000, running_acc=0.9572, grad=22.7559]Training epoch 26:  75%|███████▌  | 123/163 [02:22<00:44,  1.12s/it, loss=0.2654, batch_acc=1.0000, running_acc=0.9572, grad=22.7559]Training epoch 26:  75%|███████▌  | 123/163 [02:22<00:44,  1.12s/it, loss=0.4475, batch_acc=0.8750, running_acc=0.9566, grad=28.3989]Training epoch 26:  76%|███████▌  | 124/163 [02:22<00:40,  1.05s/it, loss=0.4475, batch_acc=0.8750, running_acc=0.9566, grad=28.3989]Training epoch 26:  76%|███████▌  | 124/163 [02:22<00:40,  1.05s/it, loss=0.3223, batch_acc=1.0000, running_acc=0.9569, grad=15.4127]Training epoch 26:  77%|███████▋  | 125/163 [02:24<00:43,  1.16s/it, loss=0.3223, batch_acc=1.0000, running_acc=0.9569, grad=15.4127]Training epoch 26:  77%|███████▋  | 125/163 [02:24<00:43,  1.16s/it, loss=0.2635, batch_acc=1.0000, running_acc=0.9573, grad=18.4581]Training epoch 26:  77%|███████▋  | 126/163 [02:25<00:39,  1.07s/it, loss=0.2635, batch_acc=1.0000, running_acc=0.9573, grad=18.4581]Training epoch 26:  77%|███████▋  | 126/163 [02:25<00:39,  1.07s/it, loss=0.1965, batch_acc=0.9688, running_acc=0.9573, grad=11.0593]Training epoch 26:  78%|███████▊  | 127/163 [02:26<00:36,  1.01s/it, loss=0.1965, batch_acc=0.9688, running_acc=0.9573, grad=11.0593]Training epoch 26:  78%|███████▊  | 127/163 [02:26<00:36,  1.01s/it, loss=0.2112, batch_acc=1.0000, running_acc=0.9577, grad=14.1644]Training epoch 26:  79%|███████▊  | 128/163 [02:26<00:34,  1.03it/s, loss=0.2112, batch_acc=1.0000, running_acc=0.9577, grad=14.1644]Training epoch 26:  79%|███████▊  | 128/163 [02:26<00:34,  1.03it/s, loss=0.3143, batch_acc=0.9688, running_acc=0.9578, grad=19.0369]Training epoch 26:  79%|███████▉  | 129/163 [02:28<00:40,  1.20s/it, loss=0.3143, batch_acc=0.9688, running_acc=0.9578, grad=19.0369]Training epoch 26:  79%|███████▉  | 129/163 [02:28<00:40,  1.20s/it, loss=0.4822, batch_acc=0.9062, running_acc=0.9574, grad=23.2541]Training epoch 26:  80%|███████▉  | 130/163 [02:29<00:36,  1.11s/it, loss=0.4822, batch_acc=0.9062, running_acc=0.9574, grad=23.2541]Training epoch 26:  80%|███████▉  | 130/163 [02:29<00:36,  1.11s/it, loss=0.2826, batch_acc=0.9688, running_acc=0.9575, grad=18.3100]Training epoch 26:  80%|████████  | 131/163 [02:30<00:33,  1.04s/it, loss=0.2826, batch_acc=0.9688, running_acc=0.9575, grad=18.3100]Training epoch 26:  80%|████████  | 131/163 [02:30<00:33,  1.04s/it, loss=0.3947, batch_acc=0.9375, running_acc=0.9573, grad=23.7805]Training epoch 26:  81%|████████  | 132/163 [02:31<00:30,  1.01it/s, loss=0.3947, batch_acc=0.9375, running_acc=0.9573, grad=23.7805]Training epoch 26:  81%|████████  | 132/163 [02:31<00:30,  1.01it/s, loss=0.3471, batch_acc=0.9688, running_acc=0.9574, grad=22.6306]Training epoch 26:  82%|████████▏ | 133/163 [02:33<00:38,  1.28s/it, loss=0.3471, batch_acc=0.9688, running_acc=0.9574, grad=22.6306]Training epoch 26:  82%|████████▏ | 133/163 [02:33<00:38,  1.28s/it, loss=0.2939, batch_acc=1.0000, running_acc=0.9577, grad=17.0837]Training epoch 26:  82%|████████▏ | 134/163 [02:34<00:33,  1.16s/it, loss=0.2939, batch_acc=1.0000, running_acc=0.9577, grad=17.0837]Training epoch 26:  82%|████████▏ | 134/163 [02:34<00:33,  1.16s/it, loss=0.2678, batch_acc=0.9688, running_acc=0.9578, grad=16.1396]Training epoch 26:  83%|████████▎ | 135/163 [02:35<00:30,  1.07s/it, loss=0.2678, batch_acc=0.9688, running_acc=0.9578, grad=16.1396]Training epoch 26:  83%|████████▎ | 135/163 [02:35<00:30,  1.07s/it, loss=0.3691, batch_acc=0.9688, running_acc=0.9579, grad=22.8770]Training epoch 26:  83%|████████▎ | 136/163 [02:35<00:27,  1.02s/it, loss=0.3691, batch_acc=0.9688, running_acc=0.9579, grad=22.8770]Training epoch 26:  83%|████████▎ | 136/163 [02:35<00:27,  1.02s/it, loss=0.2478, batch_acc=0.9688, running_acc=0.9580, grad=14.4576]Training epoch 26:  84%|████████▍ | 137/163 [02:38<00:35,  1.38s/it, loss=0.2478, batch_acc=0.9688, running_acc=0.9580, grad=14.4576]Training epoch 26:  84%|████████▍ | 137/163 [02:38<00:35,  1.38s/it, loss=0.3389, batch_acc=0.9375, running_acc=0.9578, grad=18.9640]Training epoch 26:  85%|████████▍ | 138/163 [02:39<00:30,  1.23s/it, loss=0.3389, batch_acc=0.9375, running_acc=0.9578, grad=18.9640]Training epoch 26:  85%|████████▍ | 138/163 [02:39<00:30,  1.23s/it, loss=0.2381, batch_acc=0.9688, running_acc=0.9579, grad=15.1750]Training epoch 26:  85%|████████▌ | 139/163 [02:39<00:26,  1.12s/it, loss=0.2381, batch_acc=0.9688, running_acc=0.9579, grad=15.1750]Training epoch 26:  85%|████████▌ | 139/163 [02:39<00:26,  1.12s/it, loss=0.3049, batch_acc=0.9375, running_acc=0.9577, grad=21.4913]Training epoch 26:  86%|████████▌ | 140/163 [02:40<00:24,  1.05s/it, loss=0.3049, batch_acc=0.9375, running_acc=0.9577, grad=21.4913]Training epoch 26:  86%|████████▌ | 140/163 [02:40<00:24,  1.05s/it, loss=0.2926, batch_acc=0.9688, running_acc=0.9578, grad=15.2200]Training epoch 26:  87%|████████▋ | 141/163 [02:42<00:25,  1.18s/it, loss=0.2926, batch_acc=0.9688, running_acc=0.9578, grad=15.2200]Training epoch 26:  87%|████████▋ | 141/163 [02:42<00:25,  1.18s/it, loss=0.3288, batch_acc=0.9375, running_acc=0.9577, grad=16.7952]Training epoch 26:  87%|████████▋ | 142/163 [02:43<00:22,  1.09s/it, loss=0.3288, batch_acc=0.9375, running_acc=0.9577, grad=16.7952]Training epoch 26:  87%|████████▋ | 142/163 [02:43<00:22,  1.09s/it, loss=0.3992, batch_acc=0.9375, running_acc=0.9575, grad=22.2028]Training epoch 26:  88%|████████▊ | 143/163 [02:44<00:20,  1.02s/it, loss=0.3992, batch_acc=0.9375, running_acc=0.9575, grad=22.2028]Training epoch 26:  88%|████████▊ | 143/163 [02:44<00:20,  1.02s/it, loss=0.4982, batch_acc=0.8438, running_acc=0.9567, grad=24.0587]Training epoch 26:  88%|████████▊ | 144/163 [02:44<00:18,  1.02it/s, loss=0.4982, batch_acc=0.8438, running_acc=0.9567, grad=24.0587]Training epoch 26:  88%|████████▊ | 144/163 [02:44<00:18,  1.02it/s, loss=0.2213, batch_acc=0.9688, running_acc=0.9568, grad=13.6743]Training epoch 26:  89%|████████▉ | 145/163 [02:46<00:20,  1.16s/it, loss=0.2213, batch_acc=0.9688, running_acc=0.9568, grad=13.6743]Training epoch 26:  89%|████████▉ | 145/163 [02:46<00:20,  1.16s/it, loss=0.4256, batch_acc=0.9062, running_acc=0.9565, grad=23.6838]Training epoch 26:  90%|████████▉ | 146/163 [02:47<00:18,  1.08s/it, loss=0.4256, batch_acc=0.9062, running_acc=0.9565, grad=23.6838]Training epoch 26:  90%|████████▉ | 146/163 [02:47<00:18,  1.08s/it, loss=0.4462, batch_acc=0.8750, running_acc=0.9559, grad=24.6451]Training epoch 26:  90%|█████████ | 147/163 [02:48<00:16,  1.02s/it, loss=0.4462, batch_acc=0.8750, running_acc=0.9559, grad=24.6451]Training epoch 26:  90%|█████████ | 147/163 [02:48<00:16,  1.02s/it, loss=0.6382, batch_acc=0.8125, running_acc=0.9549, grad=25.8018]Training epoch 26:  91%|█████████ | 148/163 [02:49<00:14,  1.03it/s, loss=0.6382, batch_acc=0.8125, running_acc=0.9549, grad=25.8018]Training epoch 26:  91%|█████████ | 148/163 [02:49<00:14,  1.03it/s, loss=0.3643, batch_acc=0.9688, running_acc=0.9550, grad=21.1527]Training epoch 26:  91%|█████████▏| 149/163 [02:50<00:16,  1.16s/it, loss=0.3643, batch_acc=0.9688, running_acc=0.9550, grad=21.1527]Training epoch 26:  91%|█████████▏| 149/163 [02:50<00:16,  1.16s/it, loss=0.3218, batch_acc=0.9375, running_acc=0.9549, grad=16.7725]Training epoch 26:  92%|█████████▏| 150/163 [02:51<00:14,  1.08s/it, loss=0.3218, batch_acc=0.9375, running_acc=0.9549, grad=16.7725]Training epoch 26:  92%|█████████▏| 150/163 [02:51<00:14,  1.08s/it, loss=0.3071, batch_acc=1.0000, running_acc=0.9552, grad=18.9458]Training epoch 26:  93%|█████████▎| 151/163 [02:52<00:12,  1.02s/it, loss=0.3071, batch_acc=1.0000, running_acc=0.9552, grad=18.9458]Training epoch 26:  93%|█████████▎| 151/163 [02:52<00:12,  1.02s/it, loss=0.3988, batch_acc=0.9062, running_acc=0.9549, grad=16.2532]Training epoch 26:  93%|█████████▎| 152/163 [02:53<00:10,  1.02it/s, loss=0.3988, batch_acc=0.9062, running_acc=0.9549, grad=16.2532]Training epoch 26:  93%|█████████▎| 152/163 [02:53<00:10,  1.02it/s, loss=0.3698, batch_acc=1.0000, running_acc=0.9552, grad=24.7183]Training epoch 26:  94%|█████████▍| 153/163 [02:54<00:11,  1.11s/it, loss=0.3698, batch_acc=1.0000, running_acc=0.9552, grad=24.7183]Training epoch 26:  94%|█████████▍| 153/163 [02:54<00:11,  1.11s/it, loss=0.4561, batch_acc=0.9375, running_acc=0.9551, grad=25.6794]Training epoch 26:  94%|█████████▍| 154/163 [02:55<00:09,  1.04s/it, loss=0.4561, batch_acc=0.9375, running_acc=0.9551, grad=25.6794]Training epoch 26:  94%|█████████▍| 154/163 [02:55<00:09,  1.04s/it, loss=0.2270, batch_acc=1.0000, running_acc=0.9554, grad=18.6007]Training epoch 26:  95%|█████████▌| 155/163 [02:56<00:07,  1.01it/s, loss=0.2270, batch_acc=1.0000, running_acc=0.9554, grad=18.6007]Training epoch 26:  95%|█████████▌| 155/163 [02:56<00:07,  1.01it/s, loss=0.3180, batch_acc=0.9062, running_acc=0.9550, grad=16.1630]Training epoch 26:  96%|█████████▌| 156/163 [02:57<00:06,  1.04it/s, loss=0.3180, batch_acc=0.9062, running_acc=0.9550, grad=16.1630]Training epoch 26:  96%|█████████▌| 156/163 [02:57<00:06,  1.04it/s, loss=0.2657, batch_acc=0.9688, running_acc=0.9551, grad=16.3662]Training epoch 26:  96%|█████████▋| 157/163 [02:59<00:08,  1.36s/it, loss=0.2657, batch_acc=0.9688, running_acc=0.9551, grad=16.3662]Training epoch 26:  96%|█████████▋| 157/163 [02:59<00:08,  1.36s/it, loss=0.3190, batch_acc=0.9688, running_acc=0.9552, grad=26.0386]Training epoch 26:  97%|█████████▋| 158/163 [03:00<00:06,  1.22s/it, loss=0.3190, batch_acc=0.9688, running_acc=0.9552, grad=26.0386]Training epoch 26:  97%|█████████▋| 158/163 [03:00<00:06,  1.22s/it, loss=0.3787, batch_acc=1.0000, running_acc=0.9555, grad=25.1498]Training epoch 26:  98%|█████████▊| 159/163 [03:01<00:04,  1.11s/it, loss=0.3787, batch_acc=1.0000, running_acc=0.9555, grad=25.1498]Training epoch 26:  98%|█████████▊| 159/163 [03:01<00:04,  1.11s/it, loss=0.2884, batch_acc=0.9375, running_acc=0.9554, grad=17.3601]Training epoch 26:  98%|█████████▊| 160/163 [03:02<00:03,  1.04s/it, loss=0.2884, batch_acc=0.9375, running_acc=0.9554, grad=17.3601]Training epoch 26:  98%|█████████▊| 160/163 [03:02<00:03,  1.04s/it, loss=0.2937, batch_acc=0.9375, running_acc=0.9553, grad=22.4524]Training epoch 26:  99%|█████████▉| 161/163 [03:03<00:02,  1.21s/it, loss=0.2937, batch_acc=0.9375, running_acc=0.9553, grad=22.4524]Training epoch 26:  99%|█████████▉| 161/163 [03:03<00:02,  1.21s/it, loss=0.3498, batch_acc=0.9375, running_acc=0.9552, grad=20.8199]Training epoch 26:  99%|█████████▉| 162/163 [03:04<00:01,  1.11s/it, loss=0.3498, batch_acc=0.9375, running_acc=0.9552, grad=20.8199]Training epoch 26:  99%|█████████▉| 162/163 [03:04<00:01,  1.11s/it, loss=0.3990, batch_acc=0.9375, running_acc=0.9551, grad=15.5929]Training epoch 26: 100%|██████████| 163/163 [03:05<00:00,  1.03it/s, loss=0.3990, batch_acc=0.9375, running_acc=0.9551, grad=15.5929]Training epoch 26: 100%|██████████| 163/163 [03:05<00:00,  1.03it/s, loss=0.2988, batch_acc=0.9524, running_acc=0.9550, grad=19.0449]Training epoch 26: 100%|██████████| 163/163 [03:05<00:00,  1.14s/it, loss=0.2988, batch_acc=0.9524, running_acc=0.9550, grad=19.0449]
Evaluation epoch 26:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 26:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it]Evaluation epoch 26:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it, loss=0.5002, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 26:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.5002, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 26:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.4800, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 26:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.4800, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 26:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.6085, batch_acc=0.9375, running_acc=0.9167]Evaluation epoch 26:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.6085, batch_acc=0.9375, running_acc=0.9167]Evaluation epoch 26:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.6646, batch_acc=0.9062, running_acc=0.9141]Evaluation epoch 26:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=0.6646, batch_acc=0.9062, running_acc=0.9141]Evaluation epoch 26:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=1.6738, batch_acc=0.6250, running_acc=0.8562]Evaluation epoch 26:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.6738, batch_acc=0.6250, running_acc=0.8562]Evaluation epoch 26:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.7558, batch_acc=0.8438, running_acc=0.8542]Evaluation epoch 26:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.7558, batch_acc=0.8438, running_acc=0.8542]Evaluation epoch 26:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=1.0070, batch_acc=0.8125, running_acc=0.8482]Evaluation epoch 26:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=1.0070, batch_acc=0.8125, running_acc=0.8482]Evaluation epoch 26:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.5655, batch_acc=0.8438, running_acc=0.8477]Evaluation epoch 26:  32%|███▏      | 9/28 [00:14<00:27,  1.44s/it, loss=0.5655, batch_acc=0.8438, running_acc=0.8477]Evaluation epoch 26:  32%|███▏      | 9/28 [00:14<00:27,  1.44s/it, loss=0.7104, batch_acc=0.9062, running_acc=0.8542]Evaluation epoch 26:  36%|███▌      | 10/28 [00:15<00:19,  1.08s/it, loss=0.7104, batch_acc=0.9062, running_acc=0.8542]Evaluation epoch 26:  36%|███▌      | 10/28 [00:15<00:19,  1.08s/it, loss=0.6086, batch_acc=0.8750, running_acc=0.8562]Evaluation epoch 26:  39%|███▉      | 11/28 [00:15<00:14,  1.21it/s, loss=0.6086, batch_acc=0.8750, running_acc=0.8562]Evaluation epoch 26:  39%|███▉      | 11/28 [00:15<00:14,  1.21it/s, loss=0.5540, batch_acc=0.8750, running_acc=0.8580]Evaluation epoch 26:  43%|████▎     | 12/28 [00:20<00:33,  2.06s/it, loss=0.5540, batch_acc=0.8750, running_acc=0.8580]Evaluation epoch 26:  43%|████▎     | 12/28 [00:20<00:33,  2.06s/it, loss=1.1949, batch_acc=0.7500, running_acc=0.8490]Evaluation epoch 26:  46%|████▋     | 13/28 [00:20<00:22,  1.52s/it, loss=1.1949, batch_acc=0.7500, running_acc=0.8490]Evaluation epoch 26:  46%|████▋     | 13/28 [00:20<00:22,  1.52s/it, loss=0.4929, batch_acc=0.9375, running_acc=0.8558]Evaluation epoch 26:  50%|█████     | 14/28 [00:20<00:15,  1.14s/it, loss=0.4929, batch_acc=0.9375, running_acc=0.8558]Evaluation epoch 26:  50%|█████     | 14/28 [00:20<00:15,  1.14s/it, loss=1.1827, batch_acc=0.7500, running_acc=0.8482]Evaluation epoch 26:  54%|█████▎    | 15/28 [00:20<00:11,  1.15it/s, loss=1.1827, batch_acc=0.7500, running_acc=0.8482]Evaluation epoch 26:  54%|█████▎    | 15/28 [00:20<00:11,  1.15it/s, loss=1.2492, batch_acc=0.7188, running_acc=0.8396]Evaluation epoch 26:  57%|█████▋    | 16/28 [00:23<00:17,  1.50s/it, loss=1.2492, batch_acc=0.7188, running_acc=0.8396]Evaluation epoch 26:  57%|█████▋    | 16/28 [00:23<00:17,  1.50s/it, loss=0.8227, batch_acc=0.7812, running_acc=0.8359]Evaluation epoch 26:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=0.8227, batch_acc=0.7812, running_acc=0.8359]Evaluation epoch 26:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=0.6653, batch_acc=0.8125, running_acc=0.8346]Evaluation epoch 26:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.6653, batch_acc=0.8125, running_acc=0.8346]Evaluation epoch 26:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.5964, batch_acc=0.8438, running_acc=0.8351]Evaluation epoch 26:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.5964, batch_acc=0.8438, running_acc=0.8351]Evaluation epoch 26:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.7823, batch_acc=0.6562, running_acc=0.8257]Evaluation epoch 26:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.7823, batch_acc=0.6562, running_acc=0.8257]Evaluation epoch 26:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.6398, batch_acc=0.7188, running_acc=0.8203]Evaluation epoch 26:  75%|███████▌  | 21/28 [00:27<00:07,  1.03s/it, loss=0.6398, batch_acc=0.7188, running_acc=0.8203]Evaluation epoch 26:  75%|███████▌  | 21/28 [00:27<00:07,  1.03s/it, loss=0.7000, batch_acc=0.8125, running_acc=0.8199]Evaluation epoch 26:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=0.7000, batch_acc=0.8125, running_acc=0.8199]Evaluation epoch 26:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=0.8057, batch_acc=0.7812, running_acc=0.8182]Evaluation epoch 26:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=0.8057, batch_acc=0.7812, running_acc=0.8182]Evaluation epoch 26:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=0.9386, batch_acc=0.6875, running_acc=0.8125]Evaluation epoch 26:  86%|████████▌ | 24/28 [00:33<00:08,  2.05s/it, loss=0.9386, batch_acc=0.6875, running_acc=0.8125]Evaluation epoch 26:  86%|████████▌ | 24/28 [00:33<00:08,  2.05s/it, loss=0.4815, batch_acc=0.9062, running_acc=0.8164]Evaluation epoch 26:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.4815, batch_acc=0.9062, running_acc=0.8164]Evaluation epoch 26:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.2730, batch_acc=1.0000, running_acc=0.8237]Evaluation epoch 26:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.2730, batch_acc=1.0000, running_acc=0.8237]Evaluation epoch 26:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.7441, batch_acc=0.7812, running_acc=0.8221]Evaluation epoch 26:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.7441, batch_acc=0.7812, running_acc=0.8221]Evaluation epoch 26:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=1.1179, batch_acc=0.6875, running_acc=0.8171]Evaluation epoch 26: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=1.8617, batch_acc=0.3333, running_acc=0.8155]Evaluation epoch 26: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.8617, batch_acc=0.3333, running_acc=0.8155]
Training epoch 27:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 27:   1%|          | 1/163 [00:05<14:15,  5.28s/it]Training epoch 27:   1%|          | 1/163 [00:05<14:15,  5.28s/it, loss=0.3380, batch_acc=0.9688, running_acc=0.9688, grad=24.3572]Training epoch 27:   1%|          | 2/163 [00:06<07:13,  2.70s/it, loss=0.3380, batch_acc=0.9688, running_acc=0.9688, grad=24.3572]Training epoch 27:   1%|          | 2/163 [00:06<07:13,  2.70s/it, loss=0.2748, batch_acc=0.9688, running_acc=0.9688, grad=16.8568]Training epoch 27:   2%|▏         | 3/163 [00:07<04:58,  1.87s/it, loss=0.2748, batch_acc=0.9688, running_acc=0.9688, grad=16.8568]Training epoch 27:   2%|▏         | 3/163 [00:07<04:58,  1.87s/it, loss=0.2497, batch_acc=1.0000, running_acc=0.9792, grad=16.3567]Training epoch 27:   2%|▏         | 4/163 [00:09<05:34,  2.10s/it, loss=0.2497, batch_acc=1.0000, running_acc=0.9792, grad=16.3567]Training epoch 27:   2%|▏         | 4/163 [00:09<05:34,  2.10s/it, loss=0.1841, batch_acc=1.0000, running_acc=0.9844, grad=11.8717]Training epoch 27:   3%|▎         | 5/163 [00:10<04:22,  1.66s/it, loss=0.1841, batch_acc=1.0000, running_acc=0.9844, grad=11.8717]Training epoch 27:   3%|▎         | 5/163 [00:10<04:22,  1.66s/it, loss=0.3549, batch_acc=0.9688, running_acc=0.9812, grad=22.4491]Training epoch 27:   4%|▎         | 6/163 [00:11<03:39,  1.40s/it, loss=0.3549, batch_acc=0.9688, running_acc=0.9812, grad=22.4491]Training epoch 27:   4%|▎         | 6/163 [00:11<03:39,  1.40s/it, loss=0.2190, batch_acc=1.0000, running_acc=0.9844, grad=13.9602]Training epoch 27:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=0.2190, batch_acc=1.0000, running_acc=0.9844, grad=13.9602]Training epoch 27:   4%|▍         | 7/163 [00:12<03:11,  1.23s/it, loss=0.3221, batch_acc=0.9375, running_acc=0.9777, grad=19.2487]Training epoch 27:   5%|▍         | 8/163 [00:13<03:38,  1.41s/it, loss=0.3221, batch_acc=0.9375, running_acc=0.9777, grad=19.2487]Training epoch 27:   5%|▍         | 8/163 [00:13<03:38,  1.41s/it, loss=0.4289, batch_acc=0.9062, running_acc=0.9688, grad=29.7636]Training epoch 27:   6%|▌         | 9/163 [00:14<03:11,  1.24s/it, loss=0.4289, batch_acc=0.9062, running_acc=0.9688, grad=29.7636]Training epoch 27:   6%|▌         | 9/163 [00:14<03:11,  1.24s/it, loss=0.1669, batch_acc=1.0000, running_acc=0.9722, grad=13.1484]Training epoch 27:   6%|▌         | 10/163 [00:15<02:53,  1.13s/it, loss=0.1669, batch_acc=1.0000, running_acc=0.9722, grad=13.1484]Training epoch 27:   6%|▌         | 10/163 [00:15<02:53,  1.13s/it, loss=0.3099, batch_acc=0.9062, running_acc=0.9656, grad=19.4786]Training epoch 27:   7%|▋         | 11/163 [00:16<02:40,  1.06s/it, loss=0.3099, batch_acc=0.9062, running_acc=0.9656, grad=19.4786]Training epoch 27:   7%|▋         | 11/163 [00:16<02:40,  1.06s/it, loss=0.2480, batch_acc=1.0000, running_acc=0.9688, grad=16.4024]Training epoch 27:   7%|▋         | 12/163 [00:17<02:31,  1.00s/it, loss=0.2480, batch_acc=1.0000, running_acc=0.9688, grad=16.4024]Training epoch 27:   7%|▋         | 12/163 [00:17<02:31,  1.00s/it, loss=0.3379, batch_acc=0.9375, running_acc=0.9661, grad=15.9393]Training epoch 27:   8%|▊         | 13/163 [00:18<02:25,  1.03it/s, loss=0.3379, batch_acc=0.9375, running_acc=0.9661, grad=15.9393]Training epoch 27:   8%|▊         | 13/163 [00:18<02:25,  1.03it/s, loss=0.5685, batch_acc=0.8750, running_acc=0.9591, grad=23.3319]Training epoch 27:   9%|▊         | 14/163 [00:19<02:20,  1.06it/s, loss=0.5685, batch_acc=0.8750, running_acc=0.9591, grad=23.3319]Training epoch 27:   9%|▊         | 14/163 [00:19<02:20,  1.06it/s, loss=0.3516, batch_acc=1.0000, running_acc=0.9621, grad=19.2131]Training epoch 27:   9%|▉         | 15/163 [00:20<02:16,  1.08it/s, loss=0.3516, batch_acc=1.0000, running_acc=0.9621, grad=19.2131]Training epoch 27:   9%|▉         | 15/163 [00:20<02:16,  1.08it/s, loss=0.3899, batch_acc=0.9688, running_acc=0.9625, grad=19.7865]Training epoch 27:  10%|▉         | 16/163 [00:21<02:19,  1.06it/s, loss=0.3899, batch_acc=0.9688, running_acc=0.9625, grad=19.7865]Training epoch 27:  10%|▉         | 16/163 [00:21<02:19,  1.06it/s, loss=0.2096, batch_acc=1.0000, running_acc=0.9648, grad=16.5057]Training epoch 27:  10%|█         | 17/163 [00:22<02:19,  1.04it/s, loss=0.2096, batch_acc=1.0000, running_acc=0.9648, grad=16.5057]Training epoch 27:  10%|█         | 17/163 [00:22<02:19,  1.04it/s, loss=0.2358, batch_acc=1.0000, running_acc=0.9669, grad=13.2610]Training epoch 27:  11%|█         | 18/163 [00:22<02:15,  1.07it/s, loss=0.2358, batch_acc=1.0000, running_acc=0.9669, grad=13.2610]Training epoch 27:  11%|█         | 18/163 [00:22<02:15,  1.07it/s, loss=0.2851, batch_acc=0.9375, running_acc=0.9653, grad=14.4831]Training epoch 27:  12%|█▏        | 19/163 [00:24<02:41,  1.12s/it, loss=0.2851, batch_acc=0.9375, running_acc=0.9653, grad=14.4831]Training epoch 27:  12%|█▏        | 19/163 [00:24<02:41,  1.12s/it, loss=0.2505, batch_acc=0.9375, running_acc=0.9638, grad=18.0542]Training epoch 27:  12%|█▏        | 20/163 [00:25<02:46,  1.16s/it, loss=0.2505, batch_acc=0.9375, running_acc=0.9638, grad=18.0542]Training epoch 27:  12%|█▏        | 20/163 [00:25<02:46,  1.16s/it, loss=0.2795, batch_acc=0.9688, running_acc=0.9641, grad=12.1214]Training epoch 27:  13%|█▎        | 21/163 [00:26<02:33,  1.08s/it, loss=0.2795, batch_acc=0.9688, running_acc=0.9641, grad=12.1214]Training epoch 27:  13%|█▎        | 21/163 [00:26<02:33,  1.08s/it, loss=0.2442, batch_acc=0.9688, running_acc=0.9643, grad=16.7610]Training epoch 27:  13%|█▎        | 22/163 [00:27<02:23,  1.02s/it, loss=0.2442, batch_acc=0.9688, running_acc=0.9643, grad=16.7610]Training epoch 27:  13%|█▎        | 22/163 [00:27<02:23,  1.02s/it, loss=0.1917, batch_acc=1.0000, running_acc=0.9659, grad=11.4234]Training epoch 27:  14%|█▍        | 23/163 [00:28<02:16,  1.02it/s, loss=0.1917, batch_acc=1.0000, running_acc=0.9659, grad=11.4234]Training epoch 27:  14%|█▍        | 23/163 [00:28<02:16,  1.02it/s, loss=0.4787, batch_acc=0.9062, running_acc=0.9633, grad=22.6527]Training epoch 27:  15%|█▍        | 24/163 [00:30<02:54,  1.26s/it, loss=0.4787, batch_acc=0.9062, running_acc=0.9633, grad=22.6527]Training epoch 27:  15%|█▍        | 24/163 [00:30<02:54,  1.26s/it, loss=0.2559, batch_acc=1.0000, running_acc=0.9648, grad=14.1825]Training epoch 27:  15%|█▌        | 25/163 [00:31<02:37,  1.14s/it, loss=0.2559, batch_acc=1.0000, running_acc=0.9648, grad=14.1825]Training epoch 27:  15%|█▌        | 25/163 [00:31<02:37,  1.14s/it, loss=0.2347, batch_acc=1.0000, running_acc=0.9663, grad=15.5244]Training epoch 27:  16%|█▌        | 26/163 [00:32<02:25,  1.06s/it, loss=0.2347, batch_acc=1.0000, running_acc=0.9663, grad=15.5244]Training epoch 27:  16%|█▌        | 26/163 [00:32<02:25,  1.06s/it, loss=0.2459, batch_acc=1.0000, running_acc=0.9675, grad=15.4347]Training epoch 27:  17%|█▋        | 27/163 [00:33<02:17,  1.01s/it, loss=0.2459, batch_acc=1.0000, running_acc=0.9675, grad=15.4347]Training epoch 27:  17%|█▋        | 27/163 [00:33<02:17,  1.01s/it, loss=0.3493, batch_acc=1.0000, running_acc=0.9688, grad=22.5336]Training epoch 27:  17%|█▋        | 28/163 [00:35<03:09,  1.40s/it, loss=0.3493, batch_acc=1.0000, running_acc=0.9688, grad=22.5336]Training epoch 27:  17%|█▋        | 28/163 [00:35<03:09,  1.40s/it, loss=0.2209, batch_acc=1.0000, running_acc=0.9699, grad=17.3396]Training epoch 27:  18%|█▊        | 29/163 [00:36<02:46,  1.24s/it, loss=0.2209, batch_acc=1.0000, running_acc=0.9699, grad=17.3396]Training epoch 27:  18%|█▊        | 29/163 [00:36<02:46,  1.24s/it, loss=0.1807, batch_acc=1.0000, running_acc=0.9709, grad=12.7141]Training epoch 27:  18%|█▊        | 30/163 [00:37<02:31,  1.14s/it, loss=0.1807, batch_acc=1.0000, running_acc=0.9709, grad=12.7141]Training epoch 27:  18%|█▊        | 30/163 [00:37<02:31,  1.14s/it, loss=0.3337, batch_acc=0.9688, running_acc=0.9708, grad=17.4255]Training epoch 27:  19%|█▉        | 31/163 [00:37<02:19,  1.06s/it, loss=0.3337, batch_acc=0.9688, running_acc=0.9708, grad=17.4255]Training epoch 27:  19%|█▉        | 31/163 [00:37<02:19,  1.06s/it, loss=0.3516, batch_acc=0.8750, running_acc=0.9677, grad=25.3041]Training epoch 27:  20%|█▉        | 32/163 [00:39<02:39,  1.22s/it, loss=0.3516, batch_acc=0.8750, running_acc=0.9677, grad=25.3041]Training epoch 27:  20%|█▉        | 32/163 [00:39<02:39,  1.22s/it, loss=0.1809, batch_acc=1.0000, running_acc=0.9688, grad=11.0789]Training epoch 27:  20%|██        | 33/163 [00:40<02:24,  1.12s/it, loss=0.1809, batch_acc=1.0000, running_acc=0.9688, grad=11.0789]Training epoch 27:  20%|██        | 33/163 [00:40<02:24,  1.12s/it, loss=0.2978, batch_acc=0.9688, running_acc=0.9688, grad=15.8703]Training epoch 27:  21%|██        | 34/163 [00:41<02:14,  1.04s/it, loss=0.2978, batch_acc=0.9688, running_acc=0.9688, grad=15.8703]Training epoch 27:  21%|██        | 34/163 [00:41<02:14,  1.04s/it, loss=0.1958, batch_acc=1.0000, running_acc=0.9697, grad=10.3016]Training epoch 27:  21%|██▏       | 35/163 [00:42<02:07,  1.00it/s, loss=0.1958, batch_acc=1.0000, running_acc=0.9697, grad=10.3016]Training epoch 27:  21%|██▏       | 35/163 [00:42<02:07,  1.00it/s, loss=0.3946, batch_acc=1.0000, running_acc=0.9705, grad=30.6736]Training epoch 27:  22%|██▏       | 36/163 [00:43<02:21,  1.12s/it, loss=0.3946, batch_acc=1.0000, running_acc=0.9705, grad=30.6736]Training epoch 27:  22%|██▏       | 36/163 [00:43<02:21,  1.12s/it, loss=0.4044, batch_acc=0.9062, running_acc=0.9688, grad=21.9071]Training epoch 27:  23%|██▎       | 37/163 [00:44<02:11,  1.05s/it, loss=0.4044, batch_acc=0.9062, running_acc=0.9688, grad=21.9071]Training epoch 27:  23%|██▎       | 37/163 [00:44<02:11,  1.05s/it, loss=0.2418, batch_acc=0.9688, running_acc=0.9688, grad=16.4103]Training epoch 27:  23%|██▎       | 38/163 [00:45<02:04,  1.00it/s, loss=0.2418, batch_acc=0.9688, running_acc=0.9688, grad=16.4103]Training epoch 27:  23%|██▎       | 38/163 [00:45<02:04,  1.00it/s, loss=0.3690, batch_acc=0.8750, running_acc=0.9663, grad=20.8333]Training epoch 27:  24%|██▍       | 39/163 [00:46<01:59,  1.04it/s, loss=0.3690, batch_acc=0.8750, running_acc=0.9663, grad=20.8333]Training epoch 27:  24%|██▍       | 39/163 [00:46<01:59,  1.04it/s, loss=0.3255, batch_acc=0.9062, running_acc=0.9647, grad=20.7198]Training epoch 27:  25%|██▍       | 40/163 [00:48<02:38,  1.29s/it, loss=0.3255, batch_acc=0.9062, running_acc=0.9647, grad=20.7198]Training epoch 27:  25%|██▍       | 40/163 [00:48<02:38,  1.29s/it, loss=0.2545, batch_acc=1.0000, running_acc=0.9656, grad=18.0750]Training epoch 27:  25%|██▌       | 41/163 [00:49<02:22,  1.16s/it, loss=0.2545, batch_acc=1.0000, running_acc=0.9656, grad=18.0750]Training epoch 27:  25%|██▌       | 41/163 [00:49<02:22,  1.16s/it, loss=0.2240, batch_acc=0.9688, running_acc=0.9657, grad=16.4427]Training epoch 27:  26%|██▌       | 42/163 [00:50<02:10,  1.08s/it, loss=0.2240, batch_acc=0.9688, running_acc=0.9657, grad=16.4427]Training epoch 27:  26%|██▌       | 42/163 [00:50<02:10,  1.08s/it, loss=0.3789, batch_acc=0.9688, running_acc=0.9658, grad=19.2129]Training epoch 27:  26%|██▋       | 43/163 [00:50<02:02,  1.02s/it, loss=0.3789, batch_acc=0.9688, running_acc=0.9658, grad=19.2129]Training epoch 27:  26%|██▋       | 43/163 [00:50<02:02,  1.02s/it, loss=0.2911, batch_acc=1.0000, running_acc=0.9666, grad=14.5355]Training epoch 27:  27%|██▋       | 44/163 [00:52<02:30,  1.26s/it, loss=0.2911, batch_acc=1.0000, running_acc=0.9666, grad=14.5355]Training epoch 27:  27%|██▋       | 44/163 [00:52<02:30,  1.26s/it, loss=0.1871, batch_acc=0.9688, running_acc=0.9666, grad=12.2200]Training epoch 27:  28%|██▊       | 45/163 [00:53<02:15,  1.15s/it, loss=0.1871, batch_acc=0.9688, running_acc=0.9666, grad=12.2200]Training epoch 27:  28%|██▊       | 45/163 [00:53<02:15,  1.15s/it, loss=0.2470, batch_acc=1.0000, running_acc=0.9674, grad=19.5183]Training epoch 27:  28%|██▊       | 46/163 [00:54<02:05,  1.07s/it, loss=0.2470, batch_acc=1.0000, running_acc=0.9674, grad=19.5183]Training epoch 27:  28%|██▊       | 46/163 [00:54<02:05,  1.07s/it, loss=0.2588, batch_acc=0.9375, running_acc=0.9667, grad=10.1272]Training epoch 27:  29%|██▉       | 47/163 [00:55<01:59,  1.03s/it, loss=0.2588, batch_acc=0.9375, running_acc=0.9667, grad=10.1272]Training epoch 27:  29%|██▉       | 47/163 [00:55<01:59,  1.03s/it, loss=0.2613, batch_acc=0.9688, running_acc=0.9668, grad=18.0382]Training epoch 27:  29%|██▉       | 48/163 [00:57<02:18,  1.21s/it, loss=0.2613, batch_acc=0.9688, running_acc=0.9668, grad=18.0382]Training epoch 27:  29%|██▉       | 48/163 [00:57<02:18,  1.21s/it, loss=0.3540, batch_acc=0.9688, running_acc=0.9668, grad=21.7997]Training epoch 27:  30%|███       | 49/163 [00:57<02:06,  1.11s/it, loss=0.3540, batch_acc=0.9688, running_acc=0.9668, grad=21.7997]Training epoch 27:  30%|███       | 49/163 [00:57<02:06,  1.11s/it, loss=0.3390, batch_acc=0.9375, running_acc=0.9662, grad=16.9620]Training epoch 27:  31%|███       | 50/163 [00:58<01:57,  1.04s/it, loss=0.3390, batch_acc=0.9375, running_acc=0.9662, grad=16.9620]Training epoch 27:  31%|███       | 50/163 [00:58<01:57,  1.04s/it, loss=0.3094, batch_acc=0.9688, running_acc=0.9663, grad=14.9496]Training epoch 27:  31%|███▏      | 51/163 [00:59<01:51,  1.01it/s, loss=0.3094, batch_acc=0.9688, running_acc=0.9663, grad=14.9496]Training epoch 27:  31%|███▏      | 51/163 [00:59<01:51,  1.01it/s, loss=0.2970, batch_acc=1.0000, running_acc=0.9669, grad=17.3164]Training epoch 27:  32%|███▏      | 52/163 [01:01<02:04,  1.13s/it, loss=0.2970, batch_acc=1.0000, running_acc=0.9669, grad=17.3164]Training epoch 27:  32%|███▏      | 52/163 [01:01<02:04,  1.13s/it, loss=0.2791, batch_acc=0.9688, running_acc=0.9669, grad=18.4321]Training epoch 27:  33%|███▎      | 53/163 [01:02<01:55,  1.05s/it, loss=0.2791, batch_acc=0.9688, running_acc=0.9669, grad=18.4321]Training epoch 27:  33%|███▎      | 53/163 [01:02<01:55,  1.05s/it, loss=0.3347, batch_acc=0.9062, running_acc=0.9658, grad=21.2450]Training epoch 27:  33%|███▎      | 54/163 [01:02<01:49,  1.00s/it, loss=0.3347, batch_acc=0.9062, running_acc=0.9658, grad=21.2450]Training epoch 27:  33%|███▎      | 54/163 [01:02<01:49,  1.00s/it, loss=0.3700, batch_acc=0.9375, running_acc=0.9653, grad=20.9593]Training epoch 27:  34%|███▎      | 55/163 [01:03<01:44,  1.04it/s, loss=0.3700, batch_acc=0.9375, running_acc=0.9653, grad=20.9593]Training epoch 27:  34%|███▎      | 55/163 [01:03<01:44,  1.04it/s, loss=0.3371, batch_acc=0.9062, running_acc=0.9642, grad=16.6428]Training epoch 27:  34%|███▍      | 56/163 [01:05<01:56,  1.09s/it, loss=0.3371, batch_acc=0.9062, running_acc=0.9642, grad=16.6428]Training epoch 27:  34%|███▍      | 56/163 [01:05<01:56,  1.09s/it, loss=0.2836, batch_acc=0.9375, running_acc=0.9637, grad=21.9870]Training epoch 27:  35%|███▍      | 57/163 [01:06<01:48,  1.02s/it, loss=0.2836, batch_acc=0.9375, running_acc=0.9637, grad=21.9870]Training epoch 27:  35%|███▍      | 57/163 [01:06<01:48,  1.02s/it, loss=0.3938, batch_acc=0.9375, running_acc=0.9633, grad=16.6027]Training epoch 27:  36%|███▌      | 58/163 [01:06<01:43,  1.02it/s, loss=0.3938, batch_acc=0.9375, running_acc=0.9633, grad=16.6027]Training epoch 27:  36%|███▌      | 58/163 [01:06<01:43,  1.02it/s, loss=0.2377, batch_acc=1.0000, running_acc=0.9639, grad=16.0207]Training epoch 27:  36%|███▌      | 59/163 [01:07<01:38,  1.05it/s, loss=0.2377, batch_acc=1.0000, running_acc=0.9639, grad=16.0207]Training epoch 27:  36%|███▌      | 59/163 [01:07<01:38,  1.05it/s, loss=0.3018, batch_acc=1.0000, running_acc=0.9645, grad=18.0431]Training epoch 27:  37%|███▋      | 60/163 [01:09<02:04,  1.21s/it, loss=0.3018, batch_acc=1.0000, running_acc=0.9645, grad=18.0431]Training epoch 27:  37%|███▋      | 60/163 [01:09<02:04,  1.21s/it, loss=0.2392, batch_acc=1.0000, running_acc=0.9651, grad=16.2792]Training epoch 27:  37%|███▋      | 61/163 [01:10<01:53,  1.11s/it, loss=0.2392, batch_acc=1.0000, running_acc=0.9651, grad=16.2792]Training epoch 27:  37%|███▋      | 61/163 [01:10<01:53,  1.11s/it, loss=0.2847, batch_acc=0.9375, running_acc=0.9647, grad=11.5365]Training epoch 27:  38%|███▊      | 62/163 [01:11<01:45,  1.04s/it, loss=0.2847, batch_acc=0.9375, running_acc=0.9647, grad=11.5365]Training epoch 27:  38%|███▊      | 62/163 [01:11<01:45,  1.04s/it, loss=0.2859, batch_acc=0.9375, running_acc=0.9642, grad=16.8920]Training epoch 27:  39%|███▊      | 63/163 [01:12<01:39,  1.01it/s, loss=0.2859, batch_acc=0.9375, running_acc=0.9642, grad=16.8920]Training epoch 27:  39%|███▊      | 63/163 [01:12<01:39,  1.01it/s, loss=0.2823, batch_acc=0.9688, running_acc=0.9643, grad=16.3975]Training epoch 27:  39%|███▉      | 64/163 [01:13<01:43,  1.04s/it, loss=0.2823, batch_acc=0.9688, running_acc=0.9643, grad=16.3975]Training epoch 27:  39%|███▉      | 64/163 [01:13<01:43,  1.04s/it, loss=0.3031, batch_acc=1.0000, running_acc=0.9648, grad=24.5837]Training epoch 27:  40%|███▉      | 65/163 [01:14<01:37,  1.01it/s, loss=0.3031, batch_acc=1.0000, running_acc=0.9648, grad=24.5837]Training epoch 27:  40%|███▉      | 65/163 [01:14<01:37,  1.01it/s, loss=0.3689, batch_acc=0.9375, running_acc=0.9644, grad=19.9352]Training epoch 27:  40%|████      | 66/163 [01:15<01:33,  1.04it/s, loss=0.3689, batch_acc=0.9375, running_acc=0.9644, grad=19.9352]Training epoch 27:  40%|████      | 66/163 [01:15<01:33,  1.04it/s, loss=0.2518, batch_acc=1.0000, running_acc=0.9650, grad=14.8296]Training epoch 27:  41%|████      | 67/163 [01:16<01:29,  1.07it/s, loss=0.2518, batch_acc=1.0000, running_acc=0.9650, grad=14.8296]Training epoch 27:  41%|████      | 67/163 [01:16<01:29,  1.07it/s, loss=0.1894, batch_acc=1.0000, running_acc=0.9655, grad=11.3864]Training epoch 27:  42%|████▏     | 68/163 [01:17<01:46,  1.12s/it, loss=0.1894, batch_acc=1.0000, running_acc=0.9655, grad=11.3864]Training epoch 27:  42%|████▏     | 68/163 [01:17<01:46,  1.12s/it, loss=0.2232, batch_acc=1.0000, running_acc=0.9660, grad=15.3278]Training epoch 27:  42%|████▏     | 69/163 [01:18<01:38,  1.05s/it, loss=0.2232, batch_acc=1.0000, running_acc=0.9660, grad=15.3278]Training epoch 27:  42%|████▏     | 69/163 [01:18<01:38,  1.05s/it, loss=0.2250, batch_acc=1.0000, running_acc=0.9665, grad=15.5898]Training epoch 27:  43%|████▎     | 70/163 [01:19<01:32,  1.00it/s, loss=0.2250, batch_acc=1.0000, running_acc=0.9665, grad=15.5898]Training epoch 27:  43%|████▎     | 70/163 [01:19<01:32,  1.00it/s, loss=0.3799, batch_acc=0.9375, running_acc=0.9661, grad=18.0034]Training epoch 27:  44%|████▎     | 71/163 [01:20<01:28,  1.04it/s, loss=0.3799, batch_acc=0.9375, running_acc=0.9661, grad=18.0034]Training epoch 27:  44%|████▎     | 71/163 [01:20<01:28,  1.04it/s, loss=0.3118, batch_acc=0.9688, running_acc=0.9661, grad=16.3774]Training epoch 27:  44%|████▍     | 72/163 [01:21<01:33,  1.03s/it, loss=0.3118, batch_acc=0.9688, running_acc=0.9661, grad=16.3774]Training epoch 27:  44%|████▍     | 72/163 [01:21<01:33,  1.03s/it, loss=0.3496, batch_acc=0.9375, running_acc=0.9657, grad=20.7440]Training epoch 27:  45%|████▍     | 73/163 [01:22<01:28,  1.02it/s, loss=0.3496, batch_acc=0.9375, running_acc=0.9657, grad=20.7440]Training epoch 27:  45%|████▍     | 73/163 [01:22<01:28,  1.02it/s, loss=0.3425, batch_acc=1.0000, running_acc=0.9662, grad=25.7682]Training epoch 27:  45%|████▌     | 74/163 [01:23<01:24,  1.05it/s, loss=0.3425, batch_acc=1.0000, running_acc=0.9662, grad=25.7682]Training epoch 27:  45%|████▌     | 74/163 [01:23<01:24,  1.05it/s, loss=0.3311, batch_acc=1.0000, running_acc=0.9666, grad=20.4087]Training epoch 27:  46%|████▌     | 75/163 [01:24<01:21,  1.07it/s, loss=0.3311, batch_acc=1.0000, running_acc=0.9666, grad=20.4087]Training epoch 27:  46%|████▌     | 75/163 [01:24<01:21,  1.07it/s, loss=0.2096, batch_acc=0.9688, running_acc=0.9667, grad=12.9154]Training epoch 27:  47%|████▋     | 76/163 [01:25<01:36,  1.10s/it, loss=0.2096, batch_acc=0.9688, running_acc=0.9667, grad=12.9154]Training epoch 27:  47%|████▋     | 76/163 [01:25<01:36,  1.10s/it, loss=0.2780, batch_acc=0.9688, running_acc=0.9667, grad=17.7836]Training epoch 27:  47%|████▋     | 77/163 [01:26<01:29,  1.04s/it, loss=0.2780, batch_acc=0.9688, running_acc=0.9667, grad=17.7836]Training epoch 27:  47%|████▋     | 77/163 [01:26<01:29,  1.04s/it, loss=0.3680, batch_acc=0.9062, running_acc=0.9659, grad=19.5807]Training epoch 27:  48%|████▊     | 78/163 [01:27<01:24,  1.01it/s, loss=0.3680, batch_acc=0.9062, running_acc=0.9659, grad=19.5807]Training epoch 27:  48%|████▊     | 78/163 [01:27<01:24,  1.01it/s, loss=0.2136, batch_acc=1.0000, running_acc=0.9663, grad=14.0613]Training epoch 27:  48%|████▊     | 79/163 [01:28<01:20,  1.04it/s, loss=0.2136, batch_acc=1.0000, running_acc=0.9663, grad=14.0613]Training epoch 27:  48%|████▊     | 79/163 [01:28<01:20,  1.04it/s, loss=0.2513, batch_acc=1.0000, running_acc=0.9668, grad=15.2511]Training epoch 27:  49%|████▉     | 80/163 [01:30<01:43,  1.24s/it, loss=0.2513, batch_acc=1.0000, running_acc=0.9668, grad=15.2511]Training epoch 27:  49%|████▉     | 80/163 [01:30<01:43,  1.24s/it, loss=0.3871, batch_acc=0.9375, running_acc=0.9664, grad=18.5772]Training epoch 27:  50%|████▉     | 81/163 [01:31<01:33,  1.14s/it, loss=0.3871, batch_acc=0.9375, running_acc=0.9664, grad=18.5772]Training epoch 27:  50%|████▉     | 81/163 [01:31<01:33,  1.14s/it, loss=0.2460, batch_acc=0.9688, running_acc=0.9664, grad=15.9532]Training epoch 27:  50%|█████     | 82/163 [01:31<01:25,  1.06s/it, loss=0.2460, batch_acc=0.9688, running_acc=0.9664, grad=15.9532]Training epoch 27:  50%|█████     | 82/163 [01:31<01:25,  1.06s/it, loss=0.2711, batch_acc=1.0000, running_acc=0.9668, grad=15.2428]Training epoch 27:  51%|█████     | 83/163 [01:32<01:20,  1.01s/it, loss=0.2711, batch_acc=1.0000, running_acc=0.9668, grad=15.2428]Training epoch 27:  51%|█████     | 83/163 [01:32<01:20,  1.01s/it, loss=0.2751, batch_acc=1.0000, running_acc=0.9672, grad=17.6754]Training epoch 27:  52%|█████▏    | 84/163 [01:34<01:39,  1.26s/it, loss=0.2751, batch_acc=1.0000, running_acc=0.9672, grad=17.6754]Training epoch 27:  52%|█████▏    | 84/163 [01:34<01:39,  1.26s/it, loss=0.3540, batch_acc=0.9375, running_acc=0.9669, grad=23.4796]Training epoch 27:  52%|█████▏    | 85/163 [01:35<01:29,  1.15s/it, loss=0.3540, batch_acc=0.9375, running_acc=0.9669, grad=23.4796]Training epoch 27:  52%|█████▏    | 85/163 [01:35<01:29,  1.15s/it, loss=0.2162, batch_acc=0.9688, running_acc=0.9669, grad=15.1077]Training epoch 27:  53%|█████▎    | 86/163 [01:36<01:22,  1.07s/it, loss=0.2162, batch_acc=0.9688, running_acc=0.9669, grad=15.1077]Training epoch 27:  53%|█████▎    | 86/163 [01:36<01:22,  1.07s/it, loss=0.2880, batch_acc=0.9062, running_acc=0.9662, grad=15.6177]Training epoch 27:  53%|█████▎    | 87/163 [01:37<01:16,  1.01s/it, loss=0.2880, batch_acc=0.9062, running_acc=0.9662, grad=15.6177]Training epoch 27:  53%|█████▎    | 87/163 [01:37<01:16,  1.01s/it, loss=0.4930, batch_acc=0.9062, running_acc=0.9655, grad=32.0751]Training epoch 27:  54%|█████▍    | 88/163 [01:38<01:28,  1.18s/it, loss=0.4930, batch_acc=0.9062, running_acc=0.9655, grad=32.0751]Training epoch 27:  54%|█████▍    | 88/163 [01:38<01:28,  1.18s/it, loss=0.3874, batch_acc=0.9062, running_acc=0.9648, grad=25.0009]Training epoch 27:  55%|█████▍    | 89/163 [01:39<01:20,  1.09s/it, loss=0.3874, batch_acc=0.9062, running_acc=0.9648, grad=25.0009]Training epoch 27:  55%|█████▍    | 89/163 [01:39<01:20,  1.09s/it, loss=0.3009, batch_acc=0.9688, running_acc=0.9649, grad=19.2587]Training epoch 27:  55%|█████▌    | 90/163 [01:40<01:15,  1.03s/it, loss=0.3009, batch_acc=0.9688, running_acc=0.9649, grad=19.2587]Training epoch 27:  55%|█████▌    | 90/163 [01:40<01:15,  1.03s/it, loss=0.3384, batch_acc=0.9688, running_acc=0.9649, grad=22.1212]Training epoch 27:  56%|█████▌    | 91/163 [01:41<01:10,  1.02it/s, loss=0.3384, batch_acc=0.9688, running_acc=0.9649, grad=22.1212]Training epoch 27:  56%|█████▌    | 91/163 [01:41<01:10,  1.02it/s, loss=0.4709, batch_acc=0.9375, running_acc=0.9646, grad=21.1433]Training epoch 27:  56%|█████▋    | 92/163 [01:42<01:20,  1.13s/it, loss=0.4709, batch_acc=0.9375, running_acc=0.9646, grad=21.1433]Training epoch 27:  56%|█████▋    | 92/163 [01:42<01:20,  1.13s/it, loss=0.2304, batch_acc=1.0000, running_acc=0.9650, grad=14.8418]Training epoch 27:  57%|█████▋    | 93/163 [01:43<01:13,  1.05s/it, loss=0.2304, batch_acc=1.0000, running_acc=0.9650, grad=14.8418]Training epoch 27:  57%|█████▋    | 93/163 [01:43<01:13,  1.05s/it, loss=0.1851, batch_acc=1.0000, running_acc=0.9654, grad=12.5639]Training epoch 27:  58%|█████▊    | 94/163 [01:44<01:09,  1.00s/it, loss=0.1851, batch_acc=1.0000, running_acc=0.9654, grad=12.5639]Training epoch 27:  58%|█████▊    | 94/163 [01:44<01:09,  1.00s/it, loss=0.2354, batch_acc=1.0000, running_acc=0.9658, grad=16.8074]Training epoch 27:  58%|█████▊    | 95/163 [01:45<01:05,  1.04it/s, loss=0.2354, batch_acc=1.0000, running_acc=0.9658, grad=16.8074]Training epoch 27:  58%|█████▊    | 95/163 [01:45<01:05,  1.04it/s, loss=0.2591, batch_acc=0.9688, running_acc=0.9658, grad=21.8427]Training epoch 27:  59%|█████▉    | 96/163 [01:47<01:19,  1.18s/it, loss=0.2591, batch_acc=0.9688, running_acc=0.9658, grad=21.8427]Training epoch 27:  59%|█████▉    | 96/163 [01:47<01:19,  1.18s/it, loss=0.3472, batch_acc=0.9062, running_acc=0.9652, grad=28.0682]Training epoch 27:  60%|█████▉    | 97/163 [01:48<01:12,  1.09s/it, loss=0.3472, batch_acc=0.9062, running_acc=0.9652, grad=28.0682]Training epoch 27:  60%|█████▉    | 97/163 [01:48<01:12,  1.09s/it, loss=0.3583, batch_acc=0.9375, running_acc=0.9649, grad=27.5724]Training epoch 27:  60%|██████    | 98/163 [01:49<01:06,  1.03s/it, loss=0.3583, batch_acc=0.9375, running_acc=0.9649, grad=27.5724]Training epoch 27:  60%|██████    | 98/163 [01:49<01:06,  1.03s/it, loss=0.2634, batch_acc=0.9688, running_acc=0.9649, grad=22.1382]Training epoch 27:  61%|██████    | 99/163 [01:49<01:02,  1.02it/s, loss=0.2634, batch_acc=0.9688, running_acc=0.9649, grad=22.1382]Training epoch 27:  61%|██████    | 99/163 [01:49<01:02,  1.02it/s, loss=0.3753, batch_acc=0.9062, running_acc=0.9643, grad=22.9300]Training epoch 27:  61%|██████▏   | 100/163 [01:51<01:13,  1.16s/it, loss=0.3753, batch_acc=0.9062, running_acc=0.9643, grad=22.9300]Training epoch 27:  61%|██████▏   | 100/163 [01:51<01:13,  1.16s/it, loss=0.2072, batch_acc=1.0000, running_acc=0.9647, grad=15.7369]Training epoch 27:  62%|██████▏   | 101/163 [01:52<01:06,  1.08s/it, loss=0.2072, batch_acc=1.0000, running_acc=0.9647, grad=15.7369]Training epoch 27:  62%|██████▏   | 101/163 [01:52<01:06,  1.08s/it, loss=0.3581, batch_acc=0.9688, running_acc=0.9647, grad=24.5667]Training epoch 27:  63%|██████▎   | 102/163 [01:53<01:02,  1.02s/it, loss=0.3581, batch_acc=0.9688, running_acc=0.9647, grad=24.5667]Training epoch 27:  63%|██████▎   | 102/163 [01:53<01:02,  1.02s/it, loss=0.3268, batch_acc=1.0000, running_acc=0.9651, grad=17.0096]Training epoch 27:  63%|██████▎   | 103/163 [01:54<00:58,  1.02it/s, loss=0.3268, batch_acc=1.0000, running_acc=0.9651, grad=17.0096]Training epoch 27:  63%|██████▎   | 103/163 [01:54<00:58,  1.02it/s, loss=0.3018, batch_acc=0.9688, running_acc=0.9651, grad=17.7992]Training epoch 27:  64%|██████▍   | 104/163 [01:55<01:04,  1.09s/it, loss=0.3018, batch_acc=0.9688, running_acc=0.9651, grad=17.7992]Training epoch 27:  64%|██████▍   | 104/163 [01:55<01:04,  1.09s/it, loss=0.1625, batch_acc=1.0000, running_acc=0.9654, grad=11.0398]Training epoch 27:  64%|██████▍   | 105/163 [01:56<00:59,  1.03s/it, loss=0.1625, batch_acc=1.0000, running_acc=0.9654, grad=11.0398]Training epoch 27:  64%|██████▍   | 105/163 [01:56<00:59,  1.03s/it, loss=0.3564, batch_acc=0.9688, running_acc=0.9655, grad=23.4330]Training epoch 27:  65%|██████▌   | 106/163 [01:57<00:56,  1.02it/s, loss=0.3564, batch_acc=0.9688, running_acc=0.9655, grad=23.4330]Training epoch 27:  65%|██████▌   | 106/163 [01:57<00:56,  1.02it/s, loss=0.4373, batch_acc=0.9062, running_acc=0.9649, grad=24.0146]Training epoch 27:  66%|██████▌   | 107/163 [01:58<00:53,  1.05it/s, loss=0.4373, batch_acc=0.9062, running_acc=0.9649, grad=24.0146]Training epoch 27:  66%|██████▌   | 107/163 [01:58<00:53,  1.05it/s, loss=0.4916, batch_acc=0.8750, running_acc=0.9641, grad=21.4399]Training epoch 27:  66%|██████▋   | 108/163 [01:59<01:01,  1.12s/it, loss=0.4916, batch_acc=0.8750, running_acc=0.9641, grad=21.4399]Training epoch 27:  66%|██████▋   | 108/163 [01:59<01:01,  1.12s/it, loss=0.1887, batch_acc=1.0000, running_acc=0.9644, grad=12.2296]Training epoch 27:  67%|██████▋   | 109/163 [02:00<00:56,  1.05s/it, loss=0.1887, batch_acc=1.0000, running_acc=0.9644, grad=12.2296]Training epoch 27:  67%|██████▋   | 109/163 [02:00<00:56,  1.05s/it, loss=0.2542, batch_acc=1.0000, running_acc=0.9647, grad=16.0828]Training epoch 27:  67%|██████▋   | 110/163 [02:01<00:52,  1.00it/s, loss=0.2542, batch_acc=1.0000, running_acc=0.9647, grad=16.0828]Training epoch 27:  67%|██████▋   | 110/163 [02:01<00:52,  1.00it/s, loss=0.1701, batch_acc=1.0000, running_acc=0.9651, grad=14.4324]Training epoch 27:  68%|██████▊   | 111/163 [02:02<00:50,  1.04it/s, loss=0.1701, batch_acc=1.0000, running_acc=0.9651, grad=14.4324]Training epoch 27:  68%|██████▊   | 111/163 [02:02<00:50,  1.04it/s, loss=0.2541, batch_acc=0.9062, running_acc=0.9645, grad=22.6341]Training epoch 27:  69%|██████▊   | 112/163 [02:03<00:50,  1.00it/s, loss=0.2541, batch_acc=0.9062, running_acc=0.9645, grad=22.6341]Training epoch 27:  69%|██████▊   | 112/163 [02:03<00:50,  1.00it/s, loss=0.2754, batch_acc=1.0000, running_acc=0.9648, grad=14.9590]Training epoch 27:  69%|██████▉   | 113/163 [02:04<00:48,  1.04it/s, loss=0.2754, batch_acc=1.0000, running_acc=0.9648, grad=14.9590]Training epoch 27:  69%|██████▉   | 113/163 [02:04<00:48,  1.04it/s, loss=0.2705, batch_acc=0.9688, running_acc=0.9649, grad=14.8859]Training epoch 27:  70%|██████▉   | 114/163 [02:05<00:46,  1.07it/s, loss=0.2705, batch_acc=0.9688, running_acc=0.9649, grad=14.8859]Training epoch 27:  70%|██████▉   | 114/163 [02:05<00:46,  1.07it/s, loss=0.3338, batch_acc=0.9688, running_acc=0.9649, grad=20.0834]Training epoch 27:  71%|███████   | 115/163 [02:06<00:44,  1.08it/s, loss=0.3338, batch_acc=0.9688, running_acc=0.9649, grad=20.0834]Training epoch 27:  71%|███████   | 115/163 [02:06<00:44,  1.08it/s, loss=0.5184, batch_acc=0.8750, running_acc=0.9641, grad=27.9983]Training epoch 27:  71%|███████   | 116/163 [02:08<01:03,  1.36s/it, loss=0.5184, batch_acc=0.8750, running_acc=0.9641, grad=27.9983]Training epoch 27:  71%|███████   | 116/163 [02:08<01:03,  1.36s/it, loss=0.2864, batch_acc=1.0000, running_acc=0.9644, grad=15.2495]Training epoch 27:  72%|███████▏  | 117/163 [02:09<00:55,  1.22s/it, loss=0.2864, batch_acc=1.0000, running_acc=0.9644, grad=15.2495]Training epoch 27:  72%|███████▏  | 117/163 [02:09<00:55,  1.22s/it, loss=0.2408, batch_acc=1.0000, running_acc=0.9647, grad=13.9196]Training epoch 27:  72%|███████▏  | 118/163 [02:10<00:50,  1.11s/it, loss=0.2408, batch_acc=1.0000, running_acc=0.9647, grad=13.9196]Training epoch 27:  72%|███████▏  | 118/163 [02:10<00:50,  1.11s/it, loss=0.2817, batch_acc=1.0000, running_acc=0.9650, grad=24.8648]Training epoch 27:  73%|███████▎  | 119/163 [02:11<00:45,  1.04s/it, loss=0.2817, batch_acc=1.0000, running_acc=0.9650, grad=24.8648]Training epoch 27:  73%|███████▎  | 119/163 [02:11<00:45,  1.04s/it, loss=0.3225, batch_acc=0.9688, running_acc=0.9651, grad=22.5978]Training epoch 27:  74%|███████▎  | 120/163 [02:13<00:57,  1.35s/it, loss=0.3225, batch_acc=0.9688, running_acc=0.9651, grad=22.5978]Training epoch 27:  74%|███████▎  | 120/163 [02:13<00:57,  1.35s/it, loss=0.2810, batch_acc=1.0000, running_acc=0.9654, grad=23.3169]Training epoch 27:  74%|███████▍  | 121/163 [02:13<00:50,  1.21s/it, loss=0.2810, batch_acc=1.0000, running_acc=0.9654, grad=23.3169]Training epoch 27:  74%|███████▍  | 121/163 [02:13<00:50,  1.21s/it, loss=0.3548, batch_acc=0.9375, running_acc=0.9651, grad=27.1922]Training epoch 27:  75%|███████▍  | 122/163 [02:14<00:45,  1.11s/it, loss=0.3548, batch_acc=0.9375, running_acc=0.9651, grad=27.1922]Training epoch 27:  75%|███████▍  | 122/163 [02:14<00:45,  1.11s/it, loss=0.4064, batch_acc=0.9375, running_acc=0.9649, grad=23.5488]Training epoch 27:  75%|███████▌  | 123/163 [02:15<00:41,  1.04s/it, loss=0.4064, batch_acc=0.9375, running_acc=0.9649, grad=23.5488]Training epoch 27:  75%|███████▌  | 123/163 [02:15<00:41,  1.04s/it, loss=0.2538, batch_acc=1.0000, running_acc=0.9652, grad=14.8535]Training epoch 27:  76%|███████▌  | 124/163 [02:17<00:48,  1.24s/it, loss=0.2538, batch_acc=1.0000, running_acc=0.9652, grad=14.8535]Training epoch 27:  76%|███████▌  | 124/163 [02:17<00:48,  1.24s/it, loss=0.3895, batch_acc=0.9375, running_acc=0.9650, grad=28.4005]Training epoch 27:  77%|███████▋  | 125/163 [02:18<00:42,  1.13s/it, loss=0.3895, batch_acc=0.9375, running_acc=0.9650, grad=28.4005]Training epoch 27:  77%|███████▋  | 125/163 [02:18<00:42,  1.13s/it, loss=0.3085, batch_acc=0.9375, running_acc=0.9647, grad=20.8287]Training epoch 27:  77%|███████▋  | 126/163 [02:19<00:39,  1.06s/it, loss=0.3085, batch_acc=0.9375, running_acc=0.9647, grad=20.8287]Training epoch 27:  77%|███████▋  | 126/163 [02:19<00:39,  1.06s/it, loss=0.2376, batch_acc=0.9688, running_acc=0.9648, grad=18.6871]Training epoch 27:  78%|███████▊  | 127/163 [02:20<00:36,  1.00s/it, loss=0.2376, batch_acc=0.9688, running_acc=0.9648, grad=18.6871]Training epoch 27:  78%|███████▊  | 127/163 [02:20<00:36,  1.00s/it, loss=0.3619, batch_acc=0.9375, running_acc=0.9646, grad=23.8610]Training epoch 27:  79%|███████▊  | 128/163 [02:21<00:34,  1.01it/s, loss=0.3619, batch_acc=0.9375, running_acc=0.9646, grad=23.8610]Training epoch 27:  79%|███████▊  | 128/163 [02:21<00:34,  1.01it/s, loss=0.2642, batch_acc=0.9688, running_acc=0.9646, grad=20.1136]Training epoch 27:  79%|███████▉  | 129/163 [02:21<00:32,  1.05it/s, loss=0.2642, batch_acc=0.9688, running_acc=0.9646, grad=20.1136]Training epoch 27:  79%|███████▉  | 129/163 [02:21<00:32,  1.05it/s, loss=0.2185, batch_acc=1.0000, running_acc=0.9649, grad=15.4504]Training epoch 27:  80%|███████▉  | 130/163 [02:22<00:30,  1.07it/s, loss=0.2185, batch_acc=1.0000, running_acc=0.9649, grad=15.4504]Training epoch 27:  80%|███████▉  | 130/163 [02:22<00:30,  1.07it/s, loss=0.3635, batch_acc=0.9375, running_acc=0.9647, grad=28.2925]Training epoch 27:  80%|████████  | 131/163 [02:23<00:29,  1.09it/s, loss=0.3635, batch_acc=0.9375, running_acc=0.9647, grad=28.2925]Training epoch 27:  80%|████████  | 131/163 [02:23<00:29,  1.09it/s, loss=0.3421, batch_acc=0.9375, running_acc=0.9645, grad=27.2250]Training epoch 27:  81%|████████  | 132/163 [02:25<00:36,  1.17s/it, loss=0.3421, batch_acc=0.9375, running_acc=0.9645, grad=27.2250]Training epoch 27:  81%|████████  | 132/163 [02:25<00:36,  1.17s/it, loss=0.3072, batch_acc=1.0000, running_acc=0.9647, grad=18.7869]Training epoch 27:  82%|████████▏ | 133/163 [02:26<00:32,  1.08s/it, loss=0.3072, batch_acc=1.0000, running_acc=0.9647, grad=18.7869]Training epoch 27:  82%|████████▏ | 133/163 [02:26<00:32,  1.08s/it, loss=0.2906, batch_acc=0.9688, running_acc=0.9648, grad=13.1988]Training epoch 27:  82%|████████▏ | 134/163 [02:27<00:29,  1.02s/it, loss=0.2906, batch_acc=0.9688, running_acc=0.9648, grad=13.1988]Training epoch 27:  82%|████████▏ | 134/163 [02:27<00:29,  1.02s/it, loss=0.4520, batch_acc=0.9062, running_acc=0.9643, grad=22.2908]Training epoch 27:  83%|████████▎ | 135/163 [02:28<00:27,  1.02it/s, loss=0.4520, batch_acc=0.9062, running_acc=0.9643, grad=22.2908]Training epoch 27:  83%|████████▎ | 135/163 [02:28<00:27,  1.02it/s, loss=0.2253, batch_acc=1.0000, running_acc=0.9646, grad=14.4339]Training epoch 27:  83%|████████▎ | 136/163 [02:30<00:34,  1.29s/it, loss=0.2253, batch_acc=1.0000, running_acc=0.9646, grad=14.4339]Training epoch 27:  83%|████████▎ | 136/163 [02:30<00:34,  1.29s/it, loss=0.3511, batch_acc=0.9062, running_acc=0.9642, grad=19.3333]Training epoch 27:  84%|████████▍ | 137/163 [02:30<00:30,  1.17s/it, loss=0.3511, batch_acc=0.9062, running_acc=0.9642, grad=19.3333]Training epoch 27:  84%|████████▍ | 137/163 [02:30<00:30,  1.17s/it, loss=0.2957, batch_acc=0.9688, running_acc=0.9642, grad=17.7150]Training epoch 27:  85%|████████▍ | 138/163 [02:31<00:27,  1.08s/it, loss=0.2957, batch_acc=0.9688, running_acc=0.9642, grad=17.7150]Training epoch 27:  85%|████████▍ | 138/163 [02:31<00:27,  1.08s/it, loss=0.3299, batch_acc=0.9375, running_acc=0.9640, grad=17.9614]Training epoch 27:  85%|████████▌ | 139/163 [02:32<00:24,  1.02s/it, loss=0.3299, batch_acc=0.9375, running_acc=0.9640, grad=17.9614]Training epoch 27:  85%|████████▌ | 139/163 [02:32<00:24,  1.02s/it, loss=0.4389, batch_acc=0.9062, running_acc=0.9636, grad=23.9743]Training epoch 27:  86%|████████▌ | 140/163 [02:34<00:25,  1.12s/it, loss=0.4389, batch_acc=0.9062, running_acc=0.9636, grad=23.9743]Training epoch 27:  86%|████████▌ | 140/163 [02:34<00:25,  1.12s/it, loss=0.1811, batch_acc=1.0000, running_acc=0.9638, grad=12.6566]Training epoch 27:  87%|████████▋ | 141/163 [02:34<00:23,  1.05s/it, loss=0.1811, batch_acc=1.0000, running_acc=0.9638, grad=12.6566]Training epoch 27:  87%|████████▋ | 141/163 [02:34<00:23,  1.05s/it, loss=0.3061, batch_acc=0.9062, running_acc=0.9634, grad=14.9243]Training epoch 27:  87%|████████▋ | 142/163 [02:35<00:20,  1.00it/s, loss=0.3061, batch_acc=0.9062, running_acc=0.9634, grad=14.9243]Training epoch 27:  87%|████████▋ | 142/163 [02:35<00:20,  1.00it/s, loss=0.4338, batch_acc=0.9062, running_acc=0.9630, grad=19.4368]Training epoch 27:  88%|████████▊ | 143/163 [02:36<00:19,  1.04it/s, loss=0.4338, batch_acc=0.9062, running_acc=0.9630, grad=19.4368]Training epoch 27:  88%|████████▊ | 143/163 [02:36<00:19,  1.04it/s, loss=0.2248, batch_acc=0.9688, running_acc=0.9631, grad=9.1263] Training epoch 27:  88%|████████▊ | 144/163 [02:38<00:21,  1.14s/it, loss=0.2248, batch_acc=0.9688, running_acc=0.9631, grad=9.1263]Training epoch 27:  88%|████████▊ | 144/163 [02:38<00:21,  1.14s/it, loss=0.2753, batch_acc=1.0000, running_acc=0.9633, grad=16.4153]Training epoch 27:  89%|████████▉ | 145/163 [02:39<00:19,  1.07s/it, loss=0.2753, batch_acc=1.0000, running_acc=0.9633, grad=16.4153]Training epoch 27:  89%|████████▉ | 145/163 [02:39<00:19,  1.07s/it, loss=0.3459, batch_acc=0.9375, running_acc=0.9631, grad=15.4092]Training epoch 27:  90%|████████▉ | 146/163 [02:40<00:17,  1.01s/it, loss=0.3459, batch_acc=0.9375, running_acc=0.9631, grad=15.4092]Training epoch 27:  90%|████████▉ | 146/163 [02:40<00:17,  1.01s/it, loss=0.2408, batch_acc=0.9375, running_acc=0.9630, grad=12.9996]Training epoch 27:  90%|█████████ | 147/163 [02:40<00:15,  1.03it/s, loss=0.2408, batch_acc=0.9375, running_acc=0.9630, grad=12.9996]Training epoch 27:  90%|█████████ | 147/163 [02:40<00:15,  1.03it/s, loss=0.2322, batch_acc=1.0000, running_acc=0.9632, grad=14.1083]Training epoch 27:  91%|█████████ | 148/163 [02:42<00:16,  1.11s/it, loss=0.2322, batch_acc=1.0000, running_acc=0.9632, grad=14.1083]Training epoch 27:  91%|█████████ | 148/163 [02:42<00:16,  1.11s/it, loss=0.2018, batch_acc=1.0000, running_acc=0.9635, grad=13.6425]Training epoch 27:  91%|█████████▏| 149/163 [02:43<00:14,  1.04s/it, loss=0.2018, batch_acc=1.0000, running_acc=0.9635, grad=13.6425]Training epoch 27:  91%|█████████▏| 149/163 [02:43<00:14,  1.04s/it, loss=0.3262, batch_acc=0.9688, running_acc=0.9635, grad=20.4195]Training epoch 27:  92%|█████████▏| 150/163 [02:44<00:12,  1.01it/s, loss=0.3262, batch_acc=0.9688, running_acc=0.9635, grad=20.4195]Training epoch 27:  92%|█████████▏| 150/163 [02:44<00:12,  1.01it/s, loss=0.3122, batch_acc=0.9375, running_acc=0.9633, grad=20.0478]Training epoch 27:  93%|█████████▎| 151/163 [02:44<00:11,  1.04it/s, loss=0.3122, batch_acc=0.9375, running_acc=0.9633, grad=20.0478]Training epoch 27:  93%|█████████▎| 151/163 [02:44<00:11,  1.04it/s, loss=0.3582, batch_acc=0.9375, running_acc=0.9632, grad=21.5480]Training epoch 27:  93%|█████████▎| 152/163 [02:46<00:12,  1.12s/it, loss=0.3582, batch_acc=0.9375, running_acc=0.9632, grad=21.5480]Training epoch 27:  93%|█████████▎| 152/163 [02:46<00:12,  1.12s/it, loss=0.4176, batch_acc=0.9062, running_acc=0.9628, grad=31.4127]Training epoch 27:  94%|█████████▍| 153/163 [02:47<00:10,  1.05s/it, loss=0.4176, batch_acc=0.9062, running_acc=0.9628, grad=31.4127]Training epoch 27:  94%|█████████▍| 153/163 [02:47<00:10,  1.05s/it, loss=0.3428, batch_acc=0.9062, running_acc=0.9624, grad=15.6716]Training epoch 27:  94%|█████████▍| 154/163 [02:48<00:08,  1.00it/s, loss=0.3428, batch_acc=0.9062, running_acc=0.9624, grad=15.6716]Training epoch 27:  94%|█████████▍| 154/163 [02:48<00:08,  1.00it/s, loss=0.4307, batch_acc=0.9375, running_acc=0.9623, grad=23.0569]Training epoch 27:  95%|█████████▌| 155/163 [02:49<00:07,  1.04it/s, loss=0.4307, batch_acc=0.9375, running_acc=0.9623, grad=23.0569]Training epoch 27:  95%|█████████▌| 155/163 [02:49<00:07,  1.04it/s, loss=0.2203, batch_acc=1.0000, running_acc=0.9625, grad=16.4981]Training epoch 27:  96%|█████████▌| 156/163 [02:50<00:07,  1.10s/it, loss=0.2203, batch_acc=1.0000, running_acc=0.9625, grad=16.4981]Training epoch 27:  96%|█████████▌| 156/163 [02:50<00:07,  1.10s/it, loss=0.4578, batch_acc=0.8750, running_acc=0.9619, grad=27.0567]Training epoch 27:  96%|█████████▋| 157/163 [02:51<00:06,  1.04s/it, loss=0.4578, batch_acc=0.8750, running_acc=0.9619, grad=27.0567]Training epoch 27:  96%|█████████▋| 157/163 [02:51<00:06,  1.04s/it, loss=0.4148, batch_acc=0.9688, running_acc=0.9620, grad=23.6437]Training epoch 27:  97%|█████████▋| 158/163 [02:52<00:04,  1.01it/s, loss=0.4148, batch_acc=0.9688, running_acc=0.9620, grad=23.6437]Training epoch 27:  97%|█████████▋| 158/163 [02:52<00:04,  1.01it/s, loss=0.2525, batch_acc=0.9688, running_acc=0.9620, grad=17.6099]Training epoch 27:  98%|█████████▊| 159/163 [02:53<00:03,  1.04it/s, loss=0.2525, batch_acc=0.9688, running_acc=0.9620, grad=17.6099]Training epoch 27:  98%|█████████▊| 159/163 [02:53<00:03,  1.04it/s, loss=0.2668, batch_acc=0.9375, running_acc=0.9619, grad=19.3455]Training epoch 27:  98%|█████████▊| 160/163 [02:55<00:03,  1.30s/it, loss=0.2668, batch_acc=0.9375, running_acc=0.9619, grad=19.3455]Training epoch 27:  98%|█████████▊| 160/163 [02:55<00:03,  1.30s/it, loss=0.3476, batch_acc=0.9375, running_acc=0.9617, grad=22.2130]Training epoch 27:  99%|█████████▉| 161/163 [02:56<00:02,  1.17s/it, loss=0.3476, batch_acc=0.9375, running_acc=0.9617, grad=22.2130]Training epoch 27:  99%|█████████▉| 161/163 [02:56<00:02,  1.17s/it, loss=0.3307, batch_acc=0.9375, running_acc=0.9616, grad=18.5709]Training epoch 27:  99%|█████████▉| 162/163 [02:57<00:01,  1.08s/it, loss=0.3307, batch_acc=0.9375, running_acc=0.9616, grad=18.5709]Training epoch 27:  99%|█████████▉| 162/163 [02:57<00:01,  1.08s/it, loss=0.2686, batch_acc=0.9688, running_acc=0.9616, grad=23.2310]Training epoch 27: 100%|██████████| 163/163 [02:57<00:00,  1.05it/s, loss=0.2686, batch_acc=0.9688, running_acc=0.9616, grad=23.2310]Training epoch 27: 100%|██████████| 163/163 [02:57<00:00,  1.05it/s, loss=0.2826, batch_acc=0.9524, running_acc=0.9616, grad=17.2875]Training epoch 27: 100%|██████████| 163/163 [02:57<00:00,  1.09s/it, loss=0.2826, batch_acc=0.9524, running_acc=0.9616, grad=17.2875]
Evaluation epoch 27:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 27:   4%|▎         | 1/28 [00:04<02:08,  4.75s/it]Evaluation epoch 27:   4%|▎         | 1/28 [00:04<02:08,  4.75s/it, loss=0.4637, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 27:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=0.4637, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 27:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=0.3885, batch_acc=1.0000, running_acc=0.9688]Evaluation epoch 27:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.3885, batch_acc=1.0000, running_acc=0.9688]Evaluation epoch 27:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.4797, batch_acc=0.9375, running_acc=0.9583]Evaluation epoch 27:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.4797, batch_acc=0.9375, running_acc=0.9583]Evaluation epoch 27:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.7566, batch_acc=0.8750, running_acc=0.9375]Evaluation epoch 27:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=0.7566, batch_acc=0.8750, running_acc=0.9375]Evaluation epoch 27:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=1.5890, batch_acc=0.5625, running_acc=0.8625]Evaluation epoch 27:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.5890, batch_acc=0.5625, running_acc=0.8625]Evaluation epoch 27:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.6926, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 27:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.6926, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 27:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.7952, batch_acc=0.8750, running_acc=0.8616]Evaluation epoch 27:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.7952, batch_acc=0.8750, running_acc=0.8616]Evaluation epoch 27:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.5906, batch_acc=0.8750, running_acc=0.8633]Evaluation epoch 27:  32%|███▏      | 9/28 [00:14<00:24,  1.30s/it, loss=0.5906, batch_acc=0.8750, running_acc=0.8633]Evaluation epoch 27:  32%|███▏      | 9/28 [00:14<00:24,  1.30s/it, loss=0.5854, batch_acc=0.9062, running_acc=0.8681]Evaluation epoch 27:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.5854, batch_acc=0.9062, running_acc=0.8681]Evaluation epoch 27:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.5078, batch_acc=0.9062, running_acc=0.8719]Evaluation epoch 27:  39%|███▉      | 11/28 [00:14<00:12,  1.32it/s, loss=0.5078, batch_acc=0.9062, running_acc=0.8719]Evaluation epoch 27:  39%|███▉      | 11/28 [00:14<00:12,  1.32it/s, loss=0.4812, batch_acc=0.8438, running_acc=0.8693]Evaluation epoch 27:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=0.4812, batch_acc=0.8438, running_acc=0.8693]Evaluation epoch 27:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=1.0569, batch_acc=0.8125, running_acc=0.8646]Evaluation epoch 27:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=1.0569, batch_acc=0.8125, running_acc=0.8646]Evaluation epoch 27:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=0.4434, batch_acc=0.9375, running_acc=0.8702]Evaluation epoch 27:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=0.4434, batch_acc=0.9375, running_acc=0.8702]Evaluation epoch 27:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=0.9888, batch_acc=0.7812, running_acc=0.8638]Evaluation epoch 27:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=0.9888, batch_acc=0.7812, running_acc=0.8638]Evaluation epoch 27:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.1200, batch_acc=0.7188, running_acc=0.8542]Evaluation epoch 27:  57%|█████▋    | 16/28 [00:23<00:18,  1.50s/it, loss=1.1200, batch_acc=0.7188, running_acc=0.8542]Evaluation epoch 27:  57%|█████▋    | 16/28 [00:23<00:18,  1.50s/it, loss=1.0629, batch_acc=0.7500, running_acc=0.8477]Evaluation epoch 27:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=1.0629, batch_acc=0.7500, running_acc=0.8477]Evaluation epoch 27:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.8620, batch_acc=0.6562, running_acc=0.8364]Evaluation epoch 27:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.8620, batch_acc=0.6562, running_acc=0.8364]Evaluation epoch 27:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.7047, batch_acc=0.8125, running_acc=0.8351]Evaluation epoch 27:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.7047, batch_acc=0.8125, running_acc=0.8351]Evaluation epoch 27:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.9688, batch_acc=0.6250, running_acc=0.8240]Evaluation epoch 27:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.9688, batch_acc=0.6250, running_acc=0.8240]Evaluation epoch 27:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.6164, batch_acc=0.7188, running_acc=0.8187]Evaluation epoch 27:  75%|███████▌  | 21/28 [00:27<00:07,  1.03s/it, loss=0.6164, batch_acc=0.7188, running_acc=0.8187]Evaluation epoch 27:  75%|███████▌  | 21/28 [00:27<00:07,  1.03s/it, loss=0.6779, batch_acc=0.8750, running_acc=0.8214]Evaluation epoch 27:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.6779, batch_acc=0.8750, running_acc=0.8214]Evaluation epoch 27:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.7417, batch_acc=0.7812, running_acc=0.8196]Evaluation epoch 27:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=0.7417, batch_acc=0.7812, running_acc=0.8196]Evaluation epoch 27:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=0.9449, batch_acc=0.6875, running_acc=0.8139]Evaluation epoch 27:  86%|████████▌ | 24/28 [00:33<00:08,  2.05s/it, loss=0.9449, batch_acc=0.6875, running_acc=0.8139]Evaluation epoch 27:  86%|████████▌ | 24/28 [00:33<00:08,  2.05s/it, loss=0.4023, batch_acc=0.9375, running_acc=0.8190]Evaluation epoch 27:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.4023, batch_acc=0.9375, running_acc=0.8190]Evaluation epoch 27:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.2359, batch_acc=1.0000, running_acc=0.8263]Evaluation epoch 27:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.2359, batch_acc=1.0000, running_acc=0.8263]Evaluation epoch 27:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.8828, batch_acc=0.7500, running_acc=0.8233]Evaluation epoch 27:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.8828, batch_acc=0.7500, running_acc=0.8233]Evaluation epoch 27:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.7314, batch_acc=0.8125, running_acc=0.8229]Evaluation epoch 27: 100%|██████████| 28/28 [00:34<00:00,  1.14it/s, loss=1.4159, batch_acc=0.6667, running_acc=0.8224]Evaluation epoch 27: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.4159, batch_acc=0.6667, running_acc=0.8224]
Training epoch 28:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 28:   1%|          | 1/163 [00:05<15:38,  5.79s/it]Training epoch 28:   1%|          | 1/163 [00:05<15:38,  5.79s/it, loss=0.2521, batch_acc=0.9688, running_acc=0.9688, grad=23.0707]Training epoch 28:   1%|          | 2/163 [00:06<07:47,  2.90s/it, loss=0.2521, batch_acc=0.9688, running_acc=0.9688, grad=23.0707]Training epoch 28:   1%|          | 2/163 [00:06<07:47,  2.90s/it, loss=0.2510, batch_acc=1.0000, running_acc=0.9844, grad=15.8847]Training epoch 28:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.2510, batch_acc=1.0000, running_acc=0.9844, grad=15.8847]Training epoch 28:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.2447, batch_acc=1.0000, running_acc=0.9896, grad=15.5817]Training epoch 28:   2%|▏         | 4/163 [00:10<05:53,  2.22s/it, loss=0.2447, batch_acc=1.0000, running_acc=0.9896, grad=15.5817]Training epoch 28:   2%|▏         | 4/163 [00:10<05:53,  2.22s/it, loss=0.2658, batch_acc=0.9688, running_acc=0.9844, grad=24.2331]Training epoch 28:   3%|▎         | 5/163 [00:11<04:34,  1.74s/it, loss=0.2658, batch_acc=0.9688, running_acc=0.9844, grad=24.2331]Training epoch 28:   3%|▎         | 5/163 [00:11<04:34,  1.74s/it, loss=0.2654, batch_acc=0.9688, running_acc=0.9812, grad=17.3342]Training epoch 28:   4%|▎         | 6/163 [00:11<03:46,  1.44s/it, loss=0.2654, batch_acc=0.9688, running_acc=0.9812, grad=17.3342]Training epoch 28:   4%|▎         | 6/163 [00:11<03:46,  1.44s/it, loss=0.3579, batch_acc=0.8750, running_acc=0.9635, grad=16.6340]Training epoch 28:   4%|▍         | 7/163 [00:12<03:16,  1.26s/it, loss=0.3579, batch_acc=0.8750, running_acc=0.9635, grad=16.6340]Training epoch 28:   4%|▍         | 7/163 [00:12<03:16,  1.26s/it, loss=0.2580, batch_acc=0.9688, running_acc=0.9643, grad=17.0494]Training epoch 28:   5%|▍         | 8/163 [00:14<03:49,  1.48s/it, loss=0.2580, batch_acc=0.9688, running_acc=0.9643, grad=17.0494]Training epoch 28:   5%|▍         | 8/163 [00:14<03:49,  1.48s/it, loss=0.2875, batch_acc=1.0000, running_acc=0.9688, grad=18.7634]Training epoch 28:   6%|▌         | 9/163 [00:15<03:19,  1.29s/it, loss=0.2875, batch_acc=1.0000, running_acc=0.9688, grad=18.7634]Training epoch 28:   6%|▌         | 9/163 [00:15<03:19,  1.29s/it, loss=0.2802, batch_acc=0.9688, running_acc=0.9688, grad=16.7473]Training epoch 28:   6%|▌         | 10/163 [00:16<02:58,  1.17s/it, loss=0.2802, batch_acc=0.9688, running_acc=0.9688, grad=16.7473]Training epoch 28:   6%|▌         | 10/163 [00:16<02:58,  1.17s/it, loss=0.2354, batch_acc=0.9688, running_acc=0.9688, grad=10.3967]Training epoch 28:   7%|▋         | 11/163 [00:17<02:43,  1.08s/it, loss=0.2354, batch_acc=0.9688, running_acc=0.9688, grad=10.3967]Training epoch 28:   7%|▋         | 11/163 [00:17<02:43,  1.08s/it, loss=0.2780, batch_acc=0.9062, running_acc=0.9631, grad=17.8410]Training epoch 28:   7%|▋         | 12/163 [00:19<03:20,  1.33s/it, loss=0.2780, batch_acc=0.9062, running_acc=0.9631, grad=17.8410]Training epoch 28:   7%|▋         | 12/163 [00:19<03:20,  1.33s/it, loss=0.1711, batch_acc=1.0000, running_acc=0.9661, grad=11.0227]Training epoch 28:   8%|▊         | 13/163 [00:20<02:58,  1.19s/it, loss=0.1711, batch_acc=1.0000, running_acc=0.9661, grad=11.0227]Training epoch 28:   8%|▊         | 13/163 [00:20<02:58,  1.19s/it, loss=0.2511, batch_acc=1.0000, running_acc=0.9688, grad=15.3899]Training epoch 28:   9%|▊         | 14/163 [00:21<02:43,  1.10s/it, loss=0.2511, batch_acc=1.0000, running_acc=0.9688, grad=15.3899]Training epoch 28:   9%|▊         | 14/163 [00:21<02:43,  1.10s/it, loss=0.2142, batch_acc=0.9688, running_acc=0.9688, grad=12.3652]Training epoch 28:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=0.2142, batch_acc=0.9688, running_acc=0.9688, grad=12.3652]Training epoch 28:   9%|▉         | 15/163 [00:21<02:32,  1.03s/it, loss=0.1852, batch_acc=1.0000, running_acc=0.9708, grad=10.2530]Training epoch 28:  10%|▉         | 16/163 [00:23<03:10,  1.29s/it, loss=0.1852, batch_acc=1.0000, running_acc=0.9708, grad=10.2530]Training epoch 28:  10%|▉         | 16/163 [00:23<03:10,  1.29s/it, loss=0.3101, batch_acc=1.0000, running_acc=0.9727, grad=28.9566]Training epoch 28:  10%|█         | 17/163 [00:24<02:50,  1.17s/it, loss=0.3101, batch_acc=1.0000, running_acc=0.9727, grad=28.9566]Training epoch 28:  10%|█         | 17/163 [00:24<02:50,  1.17s/it, loss=0.2883, batch_acc=0.9375, running_acc=0.9706, grad=24.5051]Training epoch 28:  11%|█         | 18/163 [00:25<02:36,  1.08s/it, loss=0.2883, batch_acc=0.9375, running_acc=0.9706, grad=24.5051]Training epoch 28:  11%|█         | 18/163 [00:25<02:36,  1.08s/it, loss=0.2310, batch_acc=1.0000, running_acc=0.9722, grad=15.2879]Training epoch 28:  12%|█▏        | 19/163 [00:26<02:26,  1.02s/it, loss=0.2310, batch_acc=1.0000, running_acc=0.9722, grad=15.2879]Training epoch 28:  12%|█▏        | 19/163 [00:26<02:26,  1.02s/it, loss=0.2702, batch_acc=1.0000, running_acc=0.9737, grad=19.1096]Training epoch 28:  12%|█▏        | 20/163 [00:28<02:55,  1.23s/it, loss=0.2702, batch_acc=1.0000, running_acc=0.9737, grad=19.1096]Training epoch 28:  12%|█▏        | 20/163 [00:28<02:55,  1.23s/it, loss=0.1684, batch_acc=1.0000, running_acc=0.9750, grad=10.4289]Training epoch 28:  13%|█▎        | 21/163 [00:29<02:49,  1.19s/it, loss=0.1684, batch_acc=1.0000, running_acc=0.9750, grad=10.4289]Training epoch 28:  13%|█▎        | 21/163 [00:29<02:49,  1.19s/it, loss=0.1871, batch_acc=1.0000, running_acc=0.9762, grad=13.5870]Training epoch 28:  13%|█▎        | 22/163 [00:30<02:34,  1.10s/it, loss=0.1871, batch_acc=1.0000, running_acc=0.9762, grad=13.5870]Training epoch 28:  13%|█▎        | 22/163 [00:30<02:34,  1.10s/it, loss=0.2659, batch_acc=0.9375, running_acc=0.9744, grad=15.3386]Training epoch 28:  14%|█▍        | 23/163 [00:31<02:24,  1.03s/it, loss=0.2659, batch_acc=0.9375, running_acc=0.9744, grad=15.3386]Training epoch 28:  14%|█▍        | 23/163 [00:31<02:24,  1.03s/it, loss=0.2887, batch_acc=0.9688, running_acc=0.9742, grad=17.2600]Training epoch 28:  15%|█▍        | 24/163 [00:32<02:44,  1.18s/it, loss=0.2887, batch_acc=0.9688, running_acc=0.9742, grad=17.2600]Training epoch 28:  15%|█▍        | 24/163 [00:32<02:44,  1.18s/it, loss=0.2536, batch_acc=0.9688, running_acc=0.9740, grad=17.5590]Training epoch 28:  15%|█▌        | 25/163 [00:33<02:42,  1.18s/it, loss=0.2536, batch_acc=0.9688, running_acc=0.9740, grad=17.5590]Training epoch 28:  15%|█▌        | 25/163 [00:33<02:42,  1.18s/it, loss=0.2734, batch_acc=0.9688, running_acc=0.9738, grad=16.2265]Training epoch 28:  16%|█▌        | 26/163 [00:34<02:28,  1.09s/it, loss=0.2734, batch_acc=0.9688, running_acc=0.9738, grad=16.2265]Training epoch 28:  16%|█▌        | 26/163 [00:34<02:28,  1.09s/it, loss=0.2265, batch_acc=1.0000, running_acc=0.9748, grad=14.1910]Training epoch 28:  17%|█▋        | 27/163 [00:35<02:19,  1.03s/it, loss=0.2265, batch_acc=1.0000, running_acc=0.9748, grad=14.1910]Training epoch 28:  17%|█▋        | 27/163 [00:35<02:19,  1.03s/it, loss=0.1455, batch_acc=1.0000, running_acc=0.9757, grad=9.5422] Training epoch 28:  17%|█▋        | 28/163 [00:36<02:38,  1.17s/it, loss=0.1455, batch_acc=1.0000, running_acc=0.9757, grad=9.5422]Training epoch 28:  17%|█▋        | 28/163 [00:36<02:38,  1.17s/it, loss=0.1972, batch_acc=1.0000, running_acc=0.9766, grad=11.6540]Training epoch 28:  18%|█▊        | 29/163 [00:37<02:25,  1.08s/it, loss=0.1972, batch_acc=1.0000, running_acc=0.9766, grad=11.6540]Training epoch 28:  18%|█▊        | 29/163 [00:37<02:25,  1.08s/it, loss=0.3718, batch_acc=0.9688, running_acc=0.9763, grad=32.7597]Training epoch 28:  18%|█▊        | 30/163 [00:38<02:16,  1.02s/it, loss=0.3718, batch_acc=0.9688, running_acc=0.9763, grad=32.7597]Training epoch 28:  18%|█▊        | 30/163 [00:38<02:16,  1.02s/it, loss=0.4423, batch_acc=0.9062, running_acc=0.9740, grad=26.7182]Training epoch 28:  19%|█▉        | 31/163 [00:39<02:09,  1.02it/s, loss=0.4423, batch_acc=0.9062, running_acc=0.9740, grad=26.7182]Training epoch 28:  19%|█▉        | 31/163 [00:39<02:09,  1.02it/s, loss=0.3378, batch_acc=0.9375, running_acc=0.9728, grad=19.6869]Training epoch 28:  20%|█▉        | 32/163 [00:41<02:49,  1.30s/it, loss=0.3378, batch_acc=0.9375, running_acc=0.9728, grad=19.6869]Training epoch 28:  20%|█▉        | 32/163 [00:41<02:49,  1.30s/it, loss=0.3517, batch_acc=0.9062, running_acc=0.9707, grad=19.4588]Training epoch 28:  20%|██        | 33/163 [00:42<02:32,  1.17s/it, loss=0.3517, batch_acc=0.9062, running_acc=0.9707, grad=19.4588]Training epoch 28:  20%|██        | 33/163 [00:42<02:32,  1.17s/it, loss=0.1889, batch_acc=1.0000, running_acc=0.9716, grad=12.3354]Training epoch 28:  21%|██        | 34/163 [00:43<02:19,  1.08s/it, loss=0.1889, batch_acc=1.0000, running_acc=0.9716, grad=12.3354]Training epoch 28:  21%|██        | 34/163 [00:43<02:19,  1.08s/it, loss=0.3313, batch_acc=0.9375, running_acc=0.9706, grad=17.0329]Training epoch 28:  21%|██▏       | 35/163 [00:44<02:10,  1.02s/it, loss=0.3313, batch_acc=0.9375, running_acc=0.9706, grad=17.0329]Training epoch 28:  21%|██▏       | 35/163 [00:44<02:10,  1.02s/it, loss=0.2258, batch_acc=0.9688, running_acc=0.9705, grad=13.8885]Training epoch 28:  22%|██▏       | 36/163 [00:46<02:48,  1.33s/it, loss=0.2258, batch_acc=0.9688, running_acc=0.9705, grad=13.8885]Training epoch 28:  22%|██▏       | 36/163 [00:46<02:48,  1.33s/it, loss=0.2751, batch_acc=0.9688, running_acc=0.9705, grad=16.5366]Training epoch 28:  23%|██▎       | 37/163 [00:47<02:30,  1.19s/it, loss=0.2751, batch_acc=0.9688, running_acc=0.9705, grad=16.5366]Training epoch 28:  23%|██▎       | 37/163 [00:47<02:30,  1.19s/it, loss=0.3727, batch_acc=0.9688, running_acc=0.9704, grad=20.4309]Training epoch 28:  23%|██▎       | 38/163 [00:48<02:17,  1.10s/it, loss=0.3727, batch_acc=0.9688, running_acc=0.9704, grad=20.4309]Training epoch 28:  23%|██▎       | 38/163 [00:48<02:17,  1.10s/it, loss=0.2356, batch_acc=0.9688, running_acc=0.9704, grad=13.5812]Training epoch 28:  24%|██▍       | 39/163 [00:48<02:07,  1.03s/it, loss=0.2356, batch_acc=0.9688, running_acc=0.9704, grad=13.5812]Training epoch 28:  24%|██▍       | 39/163 [00:48<02:07,  1.03s/it, loss=0.1746, batch_acc=1.0000, running_acc=0.9712, grad=13.5398]Training epoch 28:  25%|██▍       | 40/163 [00:51<02:44,  1.34s/it, loss=0.1746, batch_acc=1.0000, running_acc=0.9712, grad=13.5398]Training epoch 28:  25%|██▍       | 40/163 [00:51<02:44,  1.34s/it, loss=0.2312, batch_acc=1.0000, running_acc=0.9719, grad=14.4024]Training epoch 28:  25%|██▌       | 41/163 [00:51<02:26,  1.20s/it, loss=0.2312, batch_acc=1.0000, running_acc=0.9719, grad=14.4024]Training epoch 28:  25%|██▌       | 41/163 [00:51<02:26,  1.20s/it, loss=0.2384, batch_acc=1.0000, running_acc=0.9726, grad=18.2182]Training epoch 28:  26%|██▌       | 42/163 [00:52<02:13,  1.10s/it, loss=0.2384, batch_acc=1.0000, running_acc=0.9726, grad=18.2182]Training epoch 28:  26%|██▌       | 42/163 [00:52<02:13,  1.10s/it, loss=0.3207, batch_acc=0.9375, running_acc=0.9717, grad=21.8482]Training epoch 28:  26%|██▋       | 43/163 [00:53<02:04,  1.03s/it, loss=0.3207, batch_acc=0.9375, running_acc=0.9717, grad=21.8482]Training epoch 28:  26%|██▋       | 43/163 [00:53<02:04,  1.03s/it, loss=0.3627, batch_acc=0.9062, running_acc=0.9702, grad=18.1803]Training epoch 28:  27%|██▋       | 44/163 [00:55<02:32,  1.28s/it, loss=0.3627, batch_acc=0.9062, running_acc=0.9702, grad=18.1803]Training epoch 28:  27%|██▋       | 44/163 [00:55<02:32,  1.28s/it, loss=0.3367, batch_acc=0.9688, running_acc=0.9702, grad=23.0612]Training epoch 28:  28%|██▊       | 45/163 [00:56<02:16,  1.16s/it, loss=0.3367, batch_acc=0.9688, running_acc=0.9702, grad=23.0612]Training epoch 28:  28%|██▊       | 45/163 [00:56<02:16,  1.16s/it, loss=0.3724, batch_acc=0.9375, running_acc=0.9694, grad=21.3155]Training epoch 28:  28%|██▊       | 46/163 [00:57<02:05,  1.07s/it, loss=0.3724, batch_acc=0.9375, running_acc=0.9694, grad=21.3155]Training epoch 28:  28%|██▊       | 46/163 [00:57<02:05,  1.07s/it, loss=0.2709, batch_acc=0.9375, running_acc=0.9688, grad=12.6595]Training epoch 28:  29%|██▉       | 47/163 [00:58<01:57,  1.01s/it, loss=0.2709, batch_acc=0.9375, running_acc=0.9688, grad=12.6595]Training epoch 28:  29%|██▉       | 47/163 [00:58<01:57,  1.01s/it, loss=0.2904, batch_acc=0.9688, running_acc=0.9688, grad=14.5341]Training epoch 28:  29%|██▉       | 48/163 [00:59<02:24,  1.25s/it, loss=0.2904, batch_acc=0.9688, running_acc=0.9688, grad=14.5341]Training epoch 28:  29%|██▉       | 48/163 [00:59<02:24,  1.25s/it, loss=0.2933, batch_acc=0.9688, running_acc=0.9688, grad=15.4032]Training epoch 28:  30%|███       | 49/163 [01:00<02:09,  1.14s/it, loss=0.2933, batch_acc=0.9688, running_acc=0.9688, grad=15.4032]Training epoch 28:  30%|███       | 49/163 [01:00<02:09,  1.14s/it, loss=0.3367, batch_acc=0.9375, running_acc=0.9681, grad=21.8040]Training epoch 28:  31%|███       | 50/163 [01:01<02:00,  1.06s/it, loss=0.3367, batch_acc=0.9375, running_acc=0.9681, grad=21.8040]Training epoch 28:  31%|███       | 50/163 [01:01<02:00,  1.06s/it, loss=0.3222, batch_acc=0.9688, running_acc=0.9681, grad=32.3309]Training epoch 28:  31%|███▏      | 51/163 [01:02<01:52,  1.01s/it, loss=0.3222, batch_acc=0.9688, running_acc=0.9681, grad=32.3309]Training epoch 28:  31%|███▏      | 51/163 [01:02<01:52,  1.01s/it, loss=0.2388, batch_acc=1.0000, running_acc=0.9688, grad=13.7326]Training epoch 28:  32%|███▏      | 52/163 [01:04<02:07,  1.15s/it, loss=0.2388, batch_acc=1.0000, running_acc=0.9688, grad=13.7326]Training epoch 28:  32%|███▏      | 52/163 [01:04<02:07,  1.15s/it, loss=0.2924, batch_acc=0.9688, running_acc=0.9688, grad=31.0358]Training epoch 28:  33%|███▎      | 53/163 [01:04<01:57,  1.07s/it, loss=0.2924, batch_acc=0.9688, running_acc=0.9688, grad=31.0358]Training epoch 28:  33%|███▎      | 53/163 [01:04<01:57,  1.07s/it, loss=0.2165, batch_acc=0.9688, running_acc=0.9688, grad=12.9244]Training epoch 28:  33%|███▎      | 54/163 [01:05<01:50,  1.01s/it, loss=0.2165, batch_acc=0.9688, running_acc=0.9688, grad=12.9244]Training epoch 28:  33%|███▎      | 54/163 [01:05<01:50,  1.01s/it, loss=0.3399, batch_acc=0.9688, running_acc=0.9688, grad=20.7278]Training epoch 28:  34%|███▎      | 55/163 [01:06<01:44,  1.03it/s, loss=0.3399, batch_acc=0.9688, running_acc=0.9688, grad=20.7278]Training epoch 28:  34%|███▎      | 55/163 [01:06<01:44,  1.03it/s, loss=0.3497, batch_acc=0.9062, running_acc=0.9676, grad=20.5428]Training epoch 28:  34%|███▍      | 56/163 [01:08<01:58,  1.11s/it, loss=0.3497, batch_acc=0.9062, running_acc=0.9676, grad=20.5428]Training epoch 28:  34%|███▍      | 56/163 [01:08<01:58,  1.11s/it, loss=0.2374, batch_acc=0.9688, running_acc=0.9676, grad=18.1404]Training epoch 28:  35%|███▍      | 57/163 [01:08<01:49,  1.04s/it, loss=0.2374, batch_acc=0.9688, running_acc=0.9676, grad=18.1404]Training epoch 28:  35%|███▍      | 57/163 [01:08<01:49,  1.04s/it, loss=0.2312, batch_acc=1.0000, running_acc=0.9682, grad=15.3568]Training epoch 28:  36%|███▌      | 58/163 [01:09<01:43,  1.01it/s, loss=0.2312, batch_acc=1.0000, running_acc=0.9682, grad=15.3568]Training epoch 28:  36%|███▌      | 58/163 [01:09<01:43,  1.01it/s, loss=0.4017, batch_acc=0.9688, running_acc=0.9682, grad=25.5382]Training epoch 28:  36%|███▌      | 59/163 [01:10<01:39,  1.05it/s, loss=0.4017, batch_acc=0.9688, running_acc=0.9682, grad=25.5382]Training epoch 28:  36%|███▌      | 59/163 [01:10<01:39,  1.05it/s, loss=0.3120, batch_acc=0.9688, running_acc=0.9682, grad=20.2144]Training epoch 28:  37%|███▋      | 60/163 [01:12<01:50,  1.07s/it, loss=0.3120, batch_acc=0.9688, running_acc=0.9682, grad=20.2144]Training epoch 28:  37%|███▋      | 60/163 [01:12<01:50,  1.07s/it, loss=0.2701, batch_acc=0.9062, running_acc=0.9672, grad=19.3604]Training epoch 28:  37%|███▋      | 61/163 [01:12<01:43,  1.01s/it, loss=0.2701, batch_acc=0.9062, running_acc=0.9672, grad=19.3604]Training epoch 28:  37%|███▋      | 61/163 [01:12<01:43,  1.01s/it, loss=0.2764, batch_acc=0.9688, running_acc=0.9672, grad=24.4893]Training epoch 28:  38%|███▊      | 62/163 [01:13<01:38,  1.03it/s, loss=0.2764, batch_acc=0.9688, running_acc=0.9672, grad=24.4893]Training epoch 28:  38%|███▊      | 62/163 [01:13<01:38,  1.03it/s, loss=0.3114, batch_acc=0.9375, running_acc=0.9667, grad=19.0885]Training epoch 28:  39%|███▊      | 63/163 [01:14<01:34,  1.06it/s, loss=0.3114, batch_acc=0.9375, running_acc=0.9667, grad=19.0885]Training epoch 28:  39%|███▊      | 63/163 [01:14<01:34,  1.06it/s, loss=0.3505, batch_acc=0.9062, running_acc=0.9658, grad=20.5057]Training epoch 28:  39%|███▉      | 64/163 [01:15<01:31,  1.08it/s, loss=0.3505, batch_acc=0.9062, running_acc=0.9658, grad=20.5057]Training epoch 28:  39%|███▉      | 64/163 [01:15<01:31,  1.08it/s, loss=0.2513, batch_acc=0.9688, running_acc=0.9658, grad=16.9576]Training epoch 28:  40%|███▉      | 65/163 [01:16<01:29,  1.10it/s, loss=0.2513, batch_acc=0.9688, running_acc=0.9658, grad=16.9576]Training epoch 28:  40%|███▉      | 65/163 [01:16<01:29,  1.10it/s, loss=0.2874, batch_acc=1.0000, running_acc=0.9663, grad=18.2150]Training epoch 28:  40%|████      | 66/163 [01:17<01:27,  1.11it/s, loss=0.2874, batch_acc=1.0000, running_acc=0.9663, grad=18.2150]Training epoch 28:  40%|████      | 66/163 [01:17<01:27,  1.11it/s, loss=0.3225, batch_acc=0.9375, running_acc=0.9659, grad=29.9892]Training epoch 28:  41%|████      | 67/163 [01:18<01:25,  1.12it/s, loss=0.3225, batch_acc=0.9375, running_acc=0.9659, grad=29.9892]Training epoch 28:  41%|████      | 67/163 [01:18<01:25,  1.12it/s, loss=0.2826, batch_acc=0.9688, running_acc=0.9660, grad=18.7394]Training epoch 28:  42%|████▏     | 68/163 [01:20<02:03,  1.30s/it, loss=0.2826, batch_acc=0.9688, running_acc=0.9660, grad=18.7394]Training epoch 28:  42%|████▏     | 68/163 [01:20<02:03,  1.30s/it, loss=0.1912, batch_acc=0.9688, running_acc=0.9660, grad=14.5290]Training epoch 28:  42%|████▏     | 69/163 [01:21<01:50,  1.18s/it, loss=0.1912, batch_acc=0.9688, running_acc=0.9660, grad=14.5290]Training epoch 28:  42%|████▏     | 69/163 [01:21<01:50,  1.18s/it, loss=0.2904, batch_acc=0.9375, running_acc=0.9656, grad=15.7618]Training epoch 28:  43%|████▎     | 70/163 [01:22<01:41,  1.09s/it, loss=0.2904, batch_acc=0.9375, running_acc=0.9656, grad=15.7618]Training epoch 28:  43%|████▎     | 70/163 [01:22<01:41,  1.09s/it, loss=0.2949, batch_acc=0.9688, running_acc=0.9656, grad=19.1552]Training epoch 28:  44%|████▎     | 71/163 [01:23<01:34,  1.02s/it, loss=0.2949, batch_acc=0.9688, running_acc=0.9656, grad=19.1552]Training epoch 28:  44%|████▎     | 71/163 [01:23<01:34,  1.02s/it, loss=0.2994, batch_acc=0.9375, running_acc=0.9652, grad=20.6410]Training epoch 28:  44%|████▍     | 72/163 [01:24<01:36,  1.06s/it, loss=0.2994, batch_acc=0.9375, running_acc=0.9652, grad=20.6410]Training epoch 28:  44%|████▍     | 72/163 [01:24<01:36,  1.06s/it, loss=0.2003, batch_acc=1.0000, running_acc=0.9657, grad=15.4968]Training epoch 28:  45%|████▍     | 73/163 [01:25<01:30,  1.01s/it, loss=0.2003, batch_acc=1.0000, running_acc=0.9657, grad=15.4968]Training epoch 28:  45%|████▍     | 73/163 [01:25<01:30,  1.01s/it, loss=0.4038, batch_acc=0.8750, running_acc=0.9645, grad=26.8845]Training epoch 28:  45%|████▌     | 74/163 [01:26<01:26,  1.03it/s, loss=0.4038, batch_acc=0.8750, running_acc=0.9645, grad=26.8845]Training epoch 28:  45%|████▌     | 74/163 [01:26<01:26,  1.03it/s, loss=0.2123, batch_acc=1.0000, running_acc=0.9649, grad=15.0324]Training epoch 28:  46%|████▌     | 75/163 [01:26<01:22,  1.06it/s, loss=0.2123, batch_acc=1.0000, running_acc=0.9649, grad=15.0324]Training epoch 28:  46%|████▌     | 75/163 [01:26<01:22,  1.06it/s, loss=0.2559, batch_acc=0.9688, running_acc=0.9650, grad=16.1655]Training epoch 28:  47%|████▋     | 76/163 [01:28<01:43,  1.19s/it, loss=0.2559, batch_acc=0.9688, running_acc=0.9650, grad=16.1655]Training epoch 28:  47%|████▋     | 76/163 [01:28<01:43,  1.19s/it, loss=0.2071, batch_acc=1.0000, running_acc=0.9655, grad=14.0401]Training epoch 28:  47%|████▋     | 77/163 [01:29<01:34,  1.09s/it, loss=0.2071, batch_acc=1.0000, running_acc=0.9655, grad=14.0401]Training epoch 28:  47%|████▋     | 77/163 [01:29<01:34,  1.09s/it, loss=0.2352, batch_acc=0.9688, running_acc=0.9655, grad=15.9461]Training epoch 28:  48%|████▊     | 78/163 [01:30<01:27,  1.03s/it, loss=0.2352, batch_acc=0.9688, running_acc=0.9655, grad=15.9461]Training epoch 28:  48%|████▊     | 78/163 [01:30<01:27,  1.03s/it, loss=0.3146, batch_acc=0.9688, running_acc=0.9655, grad=18.9504]Training epoch 28:  48%|████▊     | 79/163 [01:31<01:22,  1.02it/s, loss=0.3146, batch_acc=0.9688, running_acc=0.9655, grad=18.9504]Training epoch 28:  48%|████▊     | 79/163 [01:31<01:22,  1.02it/s, loss=0.2930, batch_acc=0.9688, running_acc=0.9656, grad=15.7299]Training epoch 28:  49%|████▉     | 80/163 [01:32<01:31,  1.11s/it, loss=0.2930, batch_acc=0.9688, running_acc=0.9656, grad=15.7299]Training epoch 28:  49%|████▉     | 80/163 [01:32<01:31,  1.11s/it, loss=0.2040, batch_acc=1.0000, running_acc=0.9660, grad=18.9696]Training epoch 28:  50%|████▉     | 81/163 [01:33<01:25,  1.04s/it, loss=0.2040, batch_acc=1.0000, running_acc=0.9660, grad=18.9696]Training epoch 28:  50%|████▉     | 81/163 [01:33<01:25,  1.04s/it, loss=0.2877, batch_acc=0.9688, running_acc=0.9660, grad=16.2416]Training epoch 28:  50%|█████     | 82/163 [01:34<01:20,  1.01it/s, loss=0.2877, batch_acc=0.9688, running_acc=0.9660, grad=16.2416]Training epoch 28:  50%|█████     | 82/163 [01:34<01:20,  1.01it/s, loss=0.2722, batch_acc=0.9688, running_acc=0.9661, grad=13.7475]Training epoch 28:  51%|█████     | 83/163 [01:35<01:16,  1.05it/s, loss=0.2722, batch_acc=0.9688, running_acc=0.9661, grad=13.7475]Training epoch 28:  51%|█████     | 83/163 [01:35<01:16,  1.05it/s, loss=0.3084, batch_acc=1.0000, running_acc=0.9665, grad=23.8707]Training epoch 28:  52%|█████▏    | 84/163 [01:37<01:41,  1.29s/it, loss=0.3084, batch_acc=1.0000, running_acc=0.9665, grad=23.8707]Training epoch 28:  52%|█████▏    | 84/163 [01:37<01:41,  1.29s/it, loss=0.1953, batch_acc=1.0000, running_acc=0.9669, grad=12.2645]Training epoch 28:  52%|█████▏    | 85/163 [01:38<01:31,  1.17s/it, loss=0.1953, batch_acc=1.0000, running_acc=0.9669, grad=12.2645]Training epoch 28:  52%|█████▏    | 85/163 [01:38<01:31,  1.17s/it, loss=0.2421, batch_acc=1.0000, running_acc=0.9673, grad=12.3934]Training epoch 28:  53%|█████▎    | 86/163 [01:39<01:23,  1.08s/it, loss=0.2421, batch_acc=1.0000, running_acc=0.9673, grad=12.3934]Training epoch 28:  53%|█████▎    | 86/163 [01:39<01:23,  1.08s/it, loss=0.1781, batch_acc=1.0000, running_acc=0.9677, grad=11.2387]Training epoch 28:  53%|█████▎    | 87/163 [01:40<01:17,  1.02s/it, loss=0.1781, batch_acc=1.0000, running_acc=0.9677, grad=11.2387]Training epoch 28:  53%|█████▎    | 87/163 [01:40<01:17,  1.02s/it, loss=0.2908, batch_acc=0.9688, running_acc=0.9677, grad=17.7947]Training epoch 28:  54%|█████▍    | 88/163 [01:40<01:14,  1.01it/s, loss=0.2908, batch_acc=0.9688, running_acc=0.9677, grad=17.7947]Training epoch 28:  54%|█████▍    | 88/163 [01:40<01:14,  1.01it/s, loss=0.2698, batch_acc=0.9688, running_acc=0.9677, grad=18.8144]Training epoch 28:  55%|█████▍    | 89/163 [01:41<01:10,  1.05it/s, loss=0.2698, batch_acc=0.9688, running_acc=0.9677, grad=18.8144]Training epoch 28:  55%|█████▍    | 89/163 [01:41<01:10,  1.05it/s, loss=0.2423, batch_acc=0.9688, running_acc=0.9677, grad=13.8332]Training epoch 28:  55%|█████▌    | 90/163 [01:42<01:08,  1.07it/s, loss=0.2423, batch_acc=0.9688, running_acc=0.9677, grad=13.8332]Training epoch 28:  55%|█████▌    | 90/163 [01:42<01:08,  1.07it/s, loss=0.2503, batch_acc=1.0000, running_acc=0.9681, grad=15.5482]Training epoch 28:  56%|█████▌    | 91/163 [01:43<01:06,  1.09it/s, loss=0.2503, batch_acc=1.0000, running_acc=0.9681, grad=15.5482]Training epoch 28:  56%|█████▌    | 91/163 [01:43<01:06,  1.09it/s, loss=0.2211, batch_acc=1.0000, running_acc=0.9684, grad=14.5380]Training epoch 28:  56%|█████▋    | 92/163 [01:45<01:24,  1.20s/it, loss=0.2211, batch_acc=1.0000, running_acc=0.9684, grad=14.5380]Training epoch 28:  56%|█████▋    | 92/163 [01:45<01:24,  1.20s/it, loss=0.2017, batch_acc=1.0000, running_acc=0.9688, grad=14.4131]Training epoch 28:  57%|█████▋    | 93/163 [01:46<01:17,  1.10s/it, loss=0.2017, batch_acc=1.0000, running_acc=0.9688, grad=14.4131]Training epoch 28:  57%|█████▋    | 93/163 [01:46<01:17,  1.10s/it, loss=0.2177, batch_acc=1.0000, running_acc=0.9691, grad=16.5665]Training epoch 28:  58%|█████▊    | 94/163 [01:47<01:11,  1.04s/it, loss=0.2177, batch_acc=1.0000, running_acc=0.9691, grad=16.5665]Training epoch 28:  58%|█████▊    | 94/163 [01:47<01:11,  1.04s/it, loss=0.3081, batch_acc=0.9375, running_acc=0.9688, grad=21.1194]Training epoch 28:  58%|█████▊    | 95/163 [01:48<01:07,  1.01it/s, loss=0.3081, batch_acc=0.9375, running_acc=0.9688, grad=21.1194]Training epoch 28:  58%|█████▊    | 95/163 [01:48<01:07,  1.01it/s, loss=0.2902, batch_acc=0.9062, running_acc=0.9681, grad=19.4542]Training epoch 28:  59%|█████▉    | 96/163 [01:49<01:24,  1.27s/it, loss=0.2902, batch_acc=0.9062, running_acc=0.9681, grad=19.4542]Training epoch 28:  59%|█████▉    | 96/163 [01:49<01:24,  1.27s/it, loss=0.2561, batch_acc=0.9688, running_acc=0.9681, grad=15.1158]Training epoch 28:  60%|█████▉    | 97/163 [01:50<01:15,  1.15s/it, loss=0.2561, batch_acc=0.9688, running_acc=0.9681, grad=15.1158]Training epoch 28:  60%|█████▉    | 97/163 [01:50<01:15,  1.15s/it, loss=0.2316, batch_acc=0.9688, running_acc=0.9681, grad=15.0312]Training epoch 28:  60%|██████    | 98/163 [01:51<01:09,  1.07s/it, loss=0.2316, batch_acc=0.9688, running_acc=0.9681, grad=15.0312]Training epoch 28:  60%|██████    | 98/163 [01:51<01:09,  1.07s/it, loss=0.2442, batch_acc=0.9375, running_acc=0.9678, grad=13.7609]Training epoch 28:  61%|██████    | 99/163 [01:52<01:04,  1.01s/it, loss=0.2442, batch_acc=0.9375, running_acc=0.9678, grad=13.7609]Training epoch 28:  61%|██████    | 99/163 [01:52<01:04,  1.01s/it, loss=0.2733, batch_acc=0.9375, running_acc=0.9675, grad=16.6387]Training epoch 28:  61%|██████▏   | 100/163 [01:53<01:05,  1.04s/it, loss=0.2733, batch_acc=0.9375, running_acc=0.9675, grad=16.6387]Training epoch 28:  61%|██████▏   | 100/163 [01:53<01:05,  1.04s/it, loss=0.3122, batch_acc=0.9375, running_acc=0.9672, grad=17.3325]Training epoch 28:  62%|██████▏   | 101/163 [01:54<01:01,  1.01it/s, loss=0.3122, batch_acc=0.9375, running_acc=0.9672, grad=17.3325]Training epoch 28:  62%|██████▏   | 101/163 [01:54<01:01,  1.01it/s, loss=0.3813, batch_acc=0.9375, running_acc=0.9669, grad=21.8115]Training epoch 28:  63%|██████▎   | 102/163 [01:55<00:58,  1.05it/s, loss=0.3813, batch_acc=0.9375, running_acc=0.9669, grad=21.8115]Training epoch 28:  63%|██████▎   | 102/163 [01:55<00:58,  1.05it/s, loss=0.4105, batch_acc=0.9062, running_acc=0.9663, grad=27.3052]Training epoch 28:  63%|██████▎   | 103/163 [01:56<00:55,  1.07it/s, loss=0.4105, batch_acc=0.9062, running_acc=0.9663, grad=27.3052]Training epoch 28:  63%|██████▎   | 103/163 [01:56<00:55,  1.07it/s, loss=0.3622, batch_acc=0.9688, running_acc=0.9663, grad=21.4143]Training epoch 28:  64%|██████▍   | 104/163 [01:57<01:07,  1.14s/it, loss=0.3622, batch_acc=0.9688, running_acc=0.9663, grad=21.4143]Training epoch 28:  64%|██████▍   | 104/163 [01:57<01:07,  1.14s/it, loss=0.2794, batch_acc=0.9375, running_acc=0.9660, grad=18.8342]Training epoch 28:  64%|██████▍   | 105/163 [01:58<01:01,  1.06s/it, loss=0.2794, batch_acc=0.9375, running_acc=0.9660, grad=18.8342]Training epoch 28:  64%|██████▍   | 105/163 [01:58<01:01,  1.06s/it, loss=0.2938, batch_acc=0.9688, running_acc=0.9661, grad=22.1879]Training epoch 28:  65%|██████▌   | 106/163 [01:59<00:57,  1.01s/it, loss=0.2938, batch_acc=0.9688, running_acc=0.9661, grad=22.1879]Training epoch 28:  65%|██████▌   | 106/163 [01:59<00:57,  1.01s/it, loss=0.2905, batch_acc=0.9688, running_acc=0.9661, grad=28.6371]Training epoch 28:  66%|██████▌   | 107/163 [02:00<00:54,  1.03it/s, loss=0.2905, batch_acc=0.9688, running_acc=0.9661, grad=28.6371]Training epoch 28:  66%|██████▌   | 107/163 [02:00<00:54,  1.03it/s, loss=0.2868, batch_acc=1.0000, running_acc=0.9664, grad=16.1564]Training epoch 28:  66%|██████▋   | 108/163 [02:01<00:59,  1.09s/it, loss=0.2868, batch_acc=1.0000, running_acc=0.9664, grad=16.1564]Training epoch 28:  66%|██████▋   | 108/163 [02:01<00:59,  1.09s/it, loss=0.3284, batch_acc=0.9688, running_acc=0.9664, grad=21.4780]Training epoch 28:  67%|██████▋   | 109/163 [02:02<00:55,  1.03s/it, loss=0.3284, batch_acc=0.9688, running_acc=0.9664, grad=21.4780]Training epoch 28:  67%|██████▋   | 109/163 [02:02<00:55,  1.03s/it, loss=0.3907, batch_acc=0.9375, running_acc=0.9662, grad=22.2492]Training epoch 28:  67%|██████▋   | 110/163 [02:03<00:52,  1.02it/s, loss=0.3907, batch_acc=0.9375, running_acc=0.9662, grad=22.2492]Training epoch 28:  67%|██████▋   | 110/163 [02:03<00:52,  1.02it/s, loss=0.2852, batch_acc=0.9688, running_acc=0.9662, grad=22.8878]Training epoch 28:  68%|██████▊   | 111/163 [02:04<00:49,  1.05it/s, loss=0.2852, batch_acc=0.9688, running_acc=0.9662, grad=22.8878]Training epoch 28:  68%|██████▊   | 111/163 [02:04<00:49,  1.05it/s, loss=0.2572, batch_acc=0.9688, running_acc=0.9662, grad=14.9020]Training epoch 28:  69%|██████▊   | 112/163 [02:06<00:57,  1.12s/it, loss=0.2572, batch_acc=0.9688, running_acc=0.9662, grad=14.9020]Training epoch 28:  69%|██████▊   | 112/163 [02:06<00:57,  1.12s/it, loss=0.2639, batch_acc=0.9688, running_acc=0.9662, grad=19.9836]Training epoch 28:  69%|██████▉   | 113/163 [02:07<00:53,  1.07s/it, loss=0.2639, batch_acc=0.9688, running_acc=0.9662, grad=19.9836]Training epoch 28:  69%|██████▉   | 113/163 [02:07<00:53,  1.07s/it, loss=0.2220, batch_acc=0.9688, running_acc=0.9663, grad=12.9399]Training epoch 28:  70%|██████▉   | 114/163 [02:07<00:49,  1.02s/it, loss=0.2220, batch_acc=0.9688, running_acc=0.9663, grad=12.9399]Training epoch 28:  70%|██████▉   | 114/163 [02:07<00:49,  1.02s/it, loss=0.3290, batch_acc=0.9375, running_acc=0.9660, grad=21.5488]Training epoch 28:  71%|███████   | 115/163 [02:08<00:46,  1.02it/s, loss=0.3290, batch_acc=0.9375, running_acc=0.9660, grad=21.5488]Training epoch 28:  71%|███████   | 115/163 [02:08<00:46,  1.02it/s, loss=0.2852, batch_acc=0.9375, running_acc=0.9658, grad=18.4049]Training epoch 28:  71%|███████   | 116/163 [02:10<00:53,  1.14s/it, loss=0.2852, batch_acc=0.9375, running_acc=0.9658, grad=18.4049]Training epoch 28:  71%|███████   | 116/163 [02:10<00:53,  1.14s/it, loss=0.1920, batch_acc=1.0000, running_acc=0.9661, grad=14.7658]Training epoch 28:  72%|███████▏  | 117/163 [02:11<00:55,  1.20s/it, loss=0.1920, batch_acc=1.0000, running_acc=0.9661, grad=14.7658]Training epoch 28:  72%|███████▏  | 117/163 [02:11<00:55,  1.20s/it, loss=0.2130, batch_acc=1.0000, running_acc=0.9663, grad=11.6317]Training epoch 28:  72%|███████▏  | 118/163 [02:12<00:49,  1.11s/it, loss=0.2130, batch_acc=1.0000, running_acc=0.9663, grad=11.6317]Training epoch 28:  72%|███████▏  | 118/163 [02:12<00:49,  1.11s/it, loss=0.1916, batch_acc=0.9688, running_acc=0.9664, grad=13.6641]Training epoch 28:  73%|███████▎  | 119/163 [02:13<00:45,  1.04s/it, loss=0.1916, batch_acc=0.9688, running_acc=0.9664, grad=13.6641]Training epoch 28:  73%|███████▎  | 119/163 [02:13<00:45,  1.04s/it, loss=0.2750, batch_acc=0.9688, running_acc=0.9664, grad=21.2818]Training epoch 28:  74%|███████▎  | 120/163 [02:14<00:50,  1.17s/it, loss=0.2750, batch_acc=0.9688, running_acc=0.9664, grad=21.2818]Training epoch 28:  74%|███████▎  | 120/163 [02:14<00:50,  1.17s/it, loss=0.2614, batch_acc=0.9375, running_acc=0.9661, grad=13.1954]Training epoch 28:  74%|███████▍  | 121/163 [02:16<00:47,  1.14s/it, loss=0.2614, batch_acc=0.9375, running_acc=0.9661, grad=13.1954]Training epoch 28:  74%|███████▍  | 121/163 [02:16<00:47,  1.14s/it, loss=0.2425, batch_acc=0.9688, running_acc=0.9662, grad=14.9473]Training epoch 28:  75%|███████▍  | 122/163 [02:16<00:43,  1.06s/it, loss=0.2425, batch_acc=0.9688, running_acc=0.9662, grad=14.9473]Training epoch 28:  75%|███████▍  | 122/163 [02:16<00:43,  1.06s/it, loss=0.3430, batch_acc=0.9375, running_acc=0.9659, grad=25.2510]Training epoch 28:  75%|███████▌  | 123/163 [02:17<00:40,  1.01s/it, loss=0.3430, batch_acc=0.9375, running_acc=0.9659, grad=25.2510]Training epoch 28:  75%|███████▌  | 123/163 [02:17<00:40,  1.01s/it, loss=0.2750, batch_acc=0.9375, running_acc=0.9657, grad=22.0091]Training epoch 28:  76%|███████▌  | 124/163 [02:19<00:44,  1.13s/it, loss=0.2750, batch_acc=0.9375, running_acc=0.9657, grad=22.0091]Training epoch 28:  76%|███████▌  | 124/163 [02:19<00:44,  1.13s/it, loss=0.2074, batch_acc=1.0000, running_acc=0.9660, grad=14.5914]Training epoch 28:  77%|███████▋  | 125/163 [02:20<00:44,  1.17s/it, loss=0.2074, batch_acc=1.0000, running_acc=0.9660, grad=14.5914]Training epoch 28:  77%|███████▋  | 125/163 [02:20<00:44,  1.17s/it, loss=0.2063, batch_acc=1.0000, running_acc=0.9663, grad=17.6502]Training epoch 28:  77%|███████▋  | 126/163 [02:21<00:40,  1.08s/it, loss=0.2063, batch_acc=1.0000, running_acc=0.9663, grad=17.6502]Training epoch 28:  77%|███████▋  | 126/163 [02:21<00:40,  1.08s/it, loss=0.2386, batch_acc=0.9688, running_acc=0.9663, grad=15.3319]Training epoch 28:  78%|███████▊  | 127/163 [02:22<00:36,  1.02s/it, loss=0.2386, batch_acc=0.9688, running_acc=0.9663, grad=15.3319]Training epoch 28:  78%|███████▊  | 127/163 [02:22<00:36,  1.02s/it, loss=0.3429, batch_acc=0.9688, running_acc=0.9663, grad=22.3955]Training epoch 28:  79%|███████▊  | 128/163 [02:23<00:38,  1.11s/it, loss=0.3429, batch_acc=0.9688, running_acc=0.9663, grad=22.3955]Training epoch 28:  79%|███████▊  | 128/163 [02:23<00:38,  1.11s/it, loss=0.3375, batch_acc=1.0000, running_acc=0.9666, grad=21.9896]Training epoch 28:  79%|███████▉  | 129/163 [02:25<00:45,  1.34s/it, loss=0.3375, batch_acc=1.0000, running_acc=0.9666, grad=21.9896]Training epoch 28:  79%|███████▉  | 129/163 [02:25<00:45,  1.34s/it, loss=0.2698, batch_acc=1.0000, running_acc=0.9668, grad=18.8298]Training epoch 28:  80%|███████▉  | 130/163 [02:26<00:39,  1.20s/it, loss=0.2698, batch_acc=1.0000, running_acc=0.9668, grad=18.8298]Training epoch 28:  80%|███████▉  | 130/163 [02:26<00:39,  1.20s/it, loss=0.2719, batch_acc=1.0000, running_acc=0.9671, grad=15.4921]Training epoch 28:  80%|████████  | 131/163 [02:27<00:35,  1.10s/it, loss=0.2719, batch_acc=1.0000, running_acc=0.9671, grad=15.4921]Training epoch 28:  80%|████████  | 131/163 [02:27<00:35,  1.10s/it, loss=0.5314, batch_acc=0.9062, running_acc=0.9666, grad=23.5855]Training epoch 28:  81%|████████  | 132/163 [02:28<00:33,  1.08s/it, loss=0.5314, batch_acc=0.9062, running_acc=0.9666, grad=23.5855]Training epoch 28:  81%|████████  | 132/163 [02:28<00:33,  1.08s/it, loss=0.2283, batch_acc=0.9688, running_acc=0.9666, grad=11.4468]Training epoch 28:  82%|████████▏ | 133/163 [02:30<00:42,  1.42s/it, loss=0.2283, batch_acc=0.9688, running_acc=0.9666, grad=11.4468]Training epoch 28:  82%|████████▏ | 133/163 [02:30<00:42,  1.42s/it, loss=0.4414, batch_acc=0.9375, running_acc=0.9664, grad=18.6741]Training epoch 28:  82%|████████▏ | 134/163 [02:31<00:36,  1.26s/it, loss=0.4414, batch_acc=0.9375, running_acc=0.9664, grad=18.6741]Training epoch 28:  82%|████████▏ | 134/163 [02:31<00:36,  1.26s/it, loss=0.3066, batch_acc=0.9375, running_acc=0.9662, grad=16.7564]Training epoch 28:  83%|████████▎ | 135/163 [02:32<00:32,  1.15s/it, loss=0.3066, batch_acc=0.9375, running_acc=0.9662, grad=16.7564]Training epoch 28:  83%|████████▎ | 135/163 [02:32<00:32,  1.15s/it, loss=0.3687, batch_acc=0.9688, running_acc=0.9662, grad=28.7604]Training epoch 28:  83%|████████▎ | 136/163 [02:33<00:28,  1.07s/it, loss=0.3687, batch_acc=0.9688, running_acc=0.9662, grad=28.7604]Training epoch 28:  83%|████████▎ | 136/163 [02:33<00:28,  1.07s/it, loss=0.2576, batch_acc=0.9688, running_acc=0.9662, grad=14.4451]Training epoch 28:  84%|████████▍ | 137/163 [02:33<00:26,  1.01s/it, loss=0.2576, batch_acc=0.9688, running_acc=0.9662, grad=14.4451]Training epoch 28:  84%|████████▍ | 137/163 [02:33<00:26,  1.01s/it, loss=0.2487, batch_acc=1.0000, running_acc=0.9665, grad=16.3776]Training epoch 28:  85%|████████▍ | 138/163 [02:34<00:24,  1.03it/s, loss=0.2487, batch_acc=1.0000, running_acc=0.9665, grad=16.3776]Training epoch 28:  85%|████████▍ | 138/163 [02:34<00:24,  1.03it/s, loss=0.2325, batch_acc=1.0000, running_acc=0.9667, grad=17.6584]Training epoch 28:  85%|████████▌ | 139/163 [02:35<00:22,  1.06it/s, loss=0.2325, batch_acc=1.0000, running_acc=0.9667, grad=17.6584]Training epoch 28:  85%|████████▌ | 139/163 [02:35<00:22,  1.06it/s, loss=0.2227, batch_acc=1.0000, running_acc=0.9670, grad=12.3411]Training epoch 28:  86%|████████▌ | 140/163 [02:36<00:21,  1.08it/s, loss=0.2227, batch_acc=1.0000, running_acc=0.9670, grad=12.3411]Training epoch 28:  86%|████████▌ | 140/163 [02:36<00:21,  1.08it/s, loss=0.2862, batch_acc=0.9375, running_acc=0.9667, grad=21.9358]Training epoch 28:  87%|████████▋ | 141/163 [02:38<00:23,  1.08s/it, loss=0.2862, batch_acc=0.9375, running_acc=0.9667, grad=21.9358]Training epoch 28:  87%|████████▋ | 141/163 [02:38<00:23,  1.08s/it, loss=0.2598, batch_acc=1.0000, running_acc=0.9670, grad=15.5720]Training epoch 28:  87%|████████▋ | 142/163 [02:38<00:21,  1.02s/it, loss=0.2598, batch_acc=1.0000, running_acc=0.9670, grad=15.5720]Training epoch 28:  87%|████████▋ | 142/163 [02:38<00:21,  1.02s/it, loss=0.2313, batch_acc=0.9688, running_acc=0.9670, grad=16.3856]Training epoch 28:  88%|████████▊ | 143/163 [02:39<00:19,  1.02it/s, loss=0.2313, batch_acc=0.9688, running_acc=0.9670, grad=16.3856]Training epoch 28:  88%|████████▊ | 143/163 [02:39<00:19,  1.02it/s, loss=0.3597, batch_acc=1.0000, running_acc=0.9672, grad=26.3687]Training epoch 28:  88%|████████▊ | 144/163 [02:40<00:18,  1.05it/s, loss=0.3597, batch_acc=1.0000, running_acc=0.9672, grad=26.3687]Training epoch 28:  88%|████████▊ | 144/163 [02:40<00:18,  1.05it/s, loss=0.2134, batch_acc=1.0000, running_acc=0.9674, grad=11.5465]Training epoch 28:  89%|████████▉ | 145/163 [02:42<00:21,  1.17s/it, loss=0.2134, batch_acc=1.0000, running_acc=0.9674, grad=11.5465]Training epoch 28:  89%|████████▉ | 145/163 [02:42<00:21,  1.17s/it, loss=0.2300, batch_acc=1.0000, running_acc=0.9677, grad=14.5040]Training epoch 28:  90%|████████▉ | 146/163 [02:43<00:18,  1.08s/it, loss=0.2300, batch_acc=1.0000, running_acc=0.9677, grad=14.5040]Training epoch 28:  90%|████████▉ | 146/163 [02:43<00:18,  1.08s/it, loss=0.2233, batch_acc=0.9688, running_acc=0.9677, grad=18.8742]Training epoch 28:  90%|█████████ | 147/163 [02:44<00:16,  1.02s/it, loss=0.2233, batch_acc=0.9688, running_acc=0.9677, grad=18.8742]Training epoch 28:  90%|█████████ | 147/163 [02:44<00:16,  1.02s/it, loss=0.2587, batch_acc=0.9688, running_acc=0.9677, grad=15.7004]Training epoch 28:  91%|█████████ | 148/163 [02:45<00:14,  1.02it/s, loss=0.2587, batch_acc=0.9688, running_acc=0.9677, grad=15.7004]Training epoch 28:  91%|█████████ | 148/163 [02:45<00:14,  1.02it/s, loss=0.2244, batch_acc=1.0000, running_acc=0.9679, grad=16.3968]Training epoch 28:  91%|█████████▏| 149/163 [02:46<00:17,  1.24s/it, loss=0.2244, batch_acc=1.0000, running_acc=0.9679, grad=16.3968]Training epoch 28:  91%|█████████▏| 149/163 [02:46<00:17,  1.24s/it, loss=0.2582, batch_acc=0.9688, running_acc=0.9679, grad=23.2744]Training epoch 28:  92%|█████████▏| 150/163 [02:47<00:14,  1.13s/it, loss=0.2582, batch_acc=0.9688, running_acc=0.9679, grad=23.2744]Training epoch 28:  92%|█████████▏| 150/163 [02:47<00:14,  1.13s/it, loss=0.3189, batch_acc=0.9688, running_acc=0.9679, grad=19.0609]Training epoch 28:  93%|█████████▎| 151/163 [02:48<00:12,  1.06s/it, loss=0.3189, batch_acc=0.9688, running_acc=0.9679, grad=19.0609]Training epoch 28:  93%|█████████▎| 151/163 [02:48<00:12,  1.06s/it, loss=0.2154, batch_acc=1.0000, running_acc=0.9681, grad=12.8989]Training epoch 28:  93%|█████████▎| 152/163 [02:49<00:11,  1.02s/it, loss=0.2154, batch_acc=1.0000, running_acc=0.9681, grad=12.8989]Training epoch 28:  93%|█████████▎| 152/163 [02:49<00:11,  1.02s/it, loss=0.3394, batch_acc=0.9688, running_acc=0.9681, grad=23.4688]Training epoch 28:  94%|█████████▍| 153/163 [02:51<00:12,  1.25s/it, loss=0.3394, batch_acc=0.9688, running_acc=0.9681, grad=23.4688]Training epoch 28:  94%|█████████▍| 153/163 [02:51<00:12,  1.25s/it, loss=0.2863, batch_acc=0.9375, running_acc=0.9679, grad=35.7149]Training epoch 28:  94%|█████████▍| 154/163 [02:52<00:10,  1.14s/it, loss=0.2863, batch_acc=0.9375, running_acc=0.9679, grad=35.7149]Training epoch 28:  94%|█████████▍| 154/163 [02:52<00:10,  1.14s/it, loss=0.2548, batch_acc=0.9688, running_acc=0.9679, grad=12.4261]Training epoch 28:  95%|█████████▌| 155/163 [02:53<00:08,  1.06s/it, loss=0.2548, batch_acc=0.9688, running_acc=0.9679, grad=12.4261]Training epoch 28:  95%|█████████▌| 155/163 [02:53<00:08,  1.06s/it, loss=0.2223, batch_acc=0.9375, running_acc=0.9677, grad=14.9276]Training epoch 28:  96%|█████████▌| 156/163 [02:53<00:07,  1.01s/it, loss=0.2223, batch_acc=0.9375, running_acc=0.9677, grad=14.9276]Training epoch 28:  96%|█████████▌| 156/163 [02:53<00:07,  1.01s/it, loss=0.3329, batch_acc=0.9375, running_acc=0.9675, grad=20.0133]Training epoch 28:  96%|█████████▋| 157/163 [02:55<00:07,  1.17s/it, loss=0.3329, batch_acc=0.9375, running_acc=0.9675, grad=20.0133]Training epoch 28:  96%|█████████▋| 157/163 [02:55<00:07,  1.17s/it, loss=0.3153, batch_acc=0.9688, running_acc=0.9676, grad=19.9945]Training epoch 28:  97%|█████████▋| 158/163 [02:56<00:05,  1.08s/it, loss=0.3153, batch_acc=0.9688, running_acc=0.9676, grad=19.9945]Training epoch 28:  97%|█████████▋| 158/163 [02:56<00:05,  1.08s/it, loss=0.2355, batch_acc=0.9688, running_acc=0.9676, grad=12.0441]Training epoch 28:  98%|█████████▊| 159/163 [02:57<00:04,  1.02s/it, loss=0.2355, batch_acc=0.9688, running_acc=0.9676, grad=12.0441]Training epoch 28:  98%|█████████▊| 159/163 [02:57<00:04,  1.02s/it, loss=0.4110, batch_acc=0.9688, running_acc=0.9676, grad=22.5449]Training epoch 28:  98%|█████████▊| 160/163 [02:58<00:02,  1.02it/s, loss=0.4110, batch_acc=0.9688, running_acc=0.9676, grad=22.5449]Training epoch 28:  98%|█████████▊| 160/163 [02:58<00:02,  1.02it/s, loss=0.3132, batch_acc=0.9688, running_acc=0.9676, grad=21.2831]Training epoch 28:  99%|█████████▉| 161/163 [02:59<00:02,  1.21s/it, loss=0.3132, batch_acc=0.9688, running_acc=0.9676, grad=21.2831]Training epoch 28:  99%|█████████▉| 161/163 [02:59<00:02,  1.21s/it, loss=0.3184, batch_acc=0.9688, running_acc=0.9676, grad=16.5618]Training epoch 28:  99%|█████████▉| 162/163 [03:00<00:01,  1.11s/it, loss=0.3184, batch_acc=0.9688, running_acc=0.9676, grad=16.5618]Training epoch 28:  99%|█████████▉| 162/163 [03:00<00:01,  1.11s/it, loss=0.2274, batch_acc=0.9688, running_acc=0.9676, grad=17.4493]Training epoch 28: 100%|██████████| 163/163 [03:01<00:00,  1.03it/s, loss=0.2274, batch_acc=0.9688, running_acc=0.9676, grad=17.4493]Training epoch 28: 100%|██████████| 163/163 [03:01<00:00,  1.03it/s, loss=0.3212, batch_acc=0.9048, running_acc=0.9673, grad=23.1901]Training epoch 28: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=0.3212, batch_acc=0.9048, running_acc=0.9673, grad=23.1901]
Evaluation epoch 28:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 28:   4%|▎         | 1/28 [00:04<02:14,  4.99s/it]Evaluation epoch 28:   4%|▎         | 1/28 [00:04<02:14,  4.99s/it, loss=0.4390, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 28:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=0.4390, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 28:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=0.3621, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 28:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=0.3621, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 28:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=0.5204, batch_acc=0.9375, running_acc=0.9479]Evaluation epoch 28:  14%|█▍        | 4/28 [00:09<00:59,  2.50s/it, loss=0.5204, batch_acc=0.9375, running_acc=0.9479]Evaluation epoch 28:  14%|█▍        | 4/28 [00:09<00:59,  2.50s/it, loss=0.6687, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 28:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=0.6687, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 28:  18%|█▊        | 5/28 [00:10<00:38,  1.69s/it, loss=1.2996, batch_acc=0.6562, running_acc=0.8812]Evaluation epoch 28:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=1.2996, batch_acc=0.6562, running_acc=0.8812]Evaluation epoch 28:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=0.6598, batch_acc=0.8750, running_acc=0.8802]Evaluation epoch 28:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.6598, batch_acc=0.8750, running_acc=0.8802]Evaluation epoch 28:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.7729, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 28:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.7729, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 28:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.5334, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 28:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=0.5334, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 28:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=0.5730, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 28:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.5730, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 28:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.5353, batch_acc=0.9375, running_acc=0.8844]Evaluation epoch 28:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.5353, batch_acc=0.9375, running_acc=0.8844]Evaluation epoch 28:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.5710, batch_acc=0.8438, running_acc=0.8807]Evaluation epoch 28:  43%|████▎     | 12/28 [00:20<00:34,  2.15s/it, loss=0.5710, batch_acc=0.8438, running_acc=0.8807]Evaluation epoch 28:  43%|████▎     | 12/28 [00:20<00:34,  2.15s/it, loss=1.1101, batch_acc=0.7812, running_acc=0.8724]Evaluation epoch 28:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=1.1101, batch_acc=0.7812, running_acc=0.8724]Evaluation epoch 28:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.3925, batch_acc=0.9375, running_acc=0.8774]Evaluation epoch 28:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.3925, batch_acc=0.9375, running_acc=0.8774]Evaluation epoch 28:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=1.1010, batch_acc=0.7812, running_acc=0.8705]Evaluation epoch 28:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=1.1010, batch_acc=0.7812, running_acc=0.8705]Evaluation epoch 28:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=1.1924, batch_acc=0.6562, running_acc=0.8562]Evaluation epoch 28:  57%|█████▋    | 16/28 [00:24<00:17,  1.49s/it, loss=1.1924, batch_acc=0.6562, running_acc=0.8562]Evaluation epoch 28:  57%|█████▋    | 16/28 [00:24<00:17,  1.49s/it, loss=0.7951, batch_acc=0.7500, running_acc=0.8496]Evaluation epoch 28:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=0.7951, batch_acc=0.7500, running_acc=0.8496]Evaluation epoch 28:  61%|██████    | 17/28 [00:24<00:12,  1.12s/it, loss=0.6335, batch_acc=0.7188, running_acc=0.8419]Evaluation epoch 28:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.6335, batch_acc=0.7188, running_acc=0.8419]Evaluation epoch 28:  64%|██████▍   | 18/28 [00:24<00:08,  1.16it/s, loss=0.6898, batch_acc=0.8125, running_acc=0.8403]Evaluation epoch 28:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.6898, batch_acc=0.8125, running_acc=0.8403]Evaluation epoch 28:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.8738, batch_acc=0.6250, running_acc=0.8289]Evaluation epoch 28:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.8738, batch_acc=0.6250, running_acc=0.8289]Evaluation epoch 28:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.5691, batch_acc=0.7500, running_acc=0.8250]Evaluation epoch 28:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=0.5691, batch_acc=0.7500, running_acc=0.8250]Evaluation epoch 28:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=0.6511, batch_acc=0.8438, running_acc=0.8259]Evaluation epoch 28:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.6511, batch_acc=0.8438, running_acc=0.8259]Evaluation epoch 28:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.6930, batch_acc=0.8438, running_acc=0.8267]Evaluation epoch 28:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=0.6930, batch_acc=0.8438, running_acc=0.8267]Evaluation epoch 28:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=0.9289, batch_acc=0.7500, running_acc=0.8234]Evaluation epoch 28:  86%|████████▌ | 24/28 [00:33<00:08,  2.01s/it, loss=0.9289, batch_acc=0.7500, running_acc=0.8234]Evaluation epoch 28:  86%|████████▌ | 24/28 [00:33<00:08,  2.01s/it, loss=0.3296, batch_acc=0.9375, running_acc=0.8281]Evaluation epoch 28:  89%|████████▉ | 25/28 [00:33<00:04,  1.49s/it, loss=0.3296, batch_acc=0.9375, running_acc=0.8281]Evaluation epoch 28:  89%|████████▉ | 25/28 [00:33<00:04,  1.49s/it, loss=0.1764, batch_acc=1.0000, running_acc=0.8350]Evaluation epoch 28:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.1764, batch_acc=1.0000, running_acc=0.8350]Evaluation epoch 28:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.8400, batch_acc=0.7500, running_acc=0.8317]Evaluation epoch 28:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.8400, batch_acc=0.7500, running_acc=0.8317]Evaluation epoch 28:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=1.0762, batch_acc=0.6562, running_acc=0.8252]Evaluation epoch 28: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=1.5376, batch_acc=0.6667, running_acc=0.8247]Evaluation epoch 28: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=1.5376, batch_acc=0.6667, running_acc=0.8247]
Training epoch 29:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 29:   1%|          | 1/163 [00:06<16:28,  6.10s/it]Training epoch 29:   1%|          | 1/163 [00:06<16:28,  6.10s/it, loss=0.2514, batch_acc=0.9688, running_acc=0.9688, grad=17.5539]Training epoch 29:   1%|          | 2/163 [00:06<08:07,  3.03s/it, loss=0.2514, batch_acc=0.9688, running_acc=0.9688, grad=17.5539]Training epoch 29:   1%|          | 2/163 [00:06<08:07,  3.03s/it, loss=0.2772, batch_acc=1.0000, running_acc=0.9844, grad=21.8126]Training epoch 29:   2%|▏         | 3/163 [00:07<05:27,  2.05s/it, loss=0.2772, batch_acc=1.0000, running_acc=0.9844, grad=21.8126]Training epoch 29:   2%|▏         | 3/163 [00:07<05:27,  2.05s/it, loss=0.2914, batch_acc=0.9688, running_acc=0.9792, grad=22.7690]Training epoch 29:   2%|▏         | 4/163 [00:10<06:18,  2.38s/it, loss=0.2914, batch_acc=0.9688, running_acc=0.9792, grad=22.7690]Training epoch 29:   2%|▏         | 4/163 [00:10<06:18,  2.38s/it, loss=0.2519, batch_acc=0.9688, running_acc=0.9766, grad=19.0748]Training epoch 29:   3%|▎         | 5/163 [00:11<04:50,  1.84s/it, loss=0.2519, batch_acc=0.9688, running_acc=0.9766, grad=19.0748]Training epoch 29:   3%|▎         | 5/163 [00:11<04:50,  1.84s/it, loss=0.3205, batch_acc=0.9375, running_acc=0.9688, grad=18.1084]Training epoch 29:   4%|▎         | 6/163 [00:12<03:57,  1.51s/it, loss=0.3205, batch_acc=0.9375, running_acc=0.9688, grad=18.1084]Training epoch 29:   4%|▎         | 6/163 [00:12<03:57,  1.51s/it, loss=0.1586, batch_acc=1.0000, running_acc=0.9740, grad=11.6812]Training epoch 29:   4%|▍         | 7/163 [00:13<03:23,  1.31s/it, loss=0.1586, batch_acc=1.0000, running_acc=0.9740, grad=11.6812]Training epoch 29:   4%|▍         | 7/163 [00:13<03:23,  1.31s/it, loss=0.2308, batch_acc=0.9688, running_acc=0.9732, grad=13.7319]Training epoch 29:   5%|▍         | 8/163 [00:14<03:19,  1.29s/it, loss=0.2308, batch_acc=0.9688, running_acc=0.9732, grad=13.7319]Training epoch 29:   5%|▍         | 8/163 [00:14<03:19,  1.29s/it, loss=0.3058, batch_acc=0.9375, running_acc=0.9688, grad=13.3170]Training epoch 29:   6%|▌         | 9/163 [00:15<02:58,  1.16s/it, loss=0.3058, batch_acc=0.9375, running_acc=0.9688, grad=13.3170]Training epoch 29:   6%|▌         | 9/163 [00:15<02:58,  1.16s/it, loss=0.1965, batch_acc=1.0000, running_acc=0.9722, grad=14.3528]Training epoch 29:   6%|▌         | 10/163 [00:16<02:44,  1.07s/it, loss=0.1965, batch_acc=1.0000, running_acc=0.9722, grad=14.3528]Training epoch 29:   6%|▌         | 10/163 [00:16<02:44,  1.07s/it, loss=0.2214, batch_acc=0.9375, running_acc=0.9688, grad=11.6196]Training epoch 29:   7%|▋         | 11/163 [00:17<02:34,  1.02s/it, loss=0.2214, batch_acc=0.9375, running_acc=0.9688, grad=11.6196]Training epoch 29:   7%|▋         | 11/163 [00:17<02:34,  1.02s/it, loss=0.3392, batch_acc=0.9688, running_acc=0.9688, grad=18.6562]Training epoch 29:   7%|▋         | 12/163 [00:18<03:00,  1.20s/it, loss=0.3392, batch_acc=0.9688, running_acc=0.9688, grad=18.6562]Training epoch 29:   7%|▋         | 12/163 [00:18<03:00,  1.20s/it, loss=0.2005, batch_acc=0.9688, running_acc=0.9688, grad=14.8183]Training epoch 29:   8%|▊         | 13/163 [00:19<02:45,  1.10s/it, loss=0.2005, batch_acc=0.9688, running_acc=0.9688, grad=14.8183]Training epoch 29:   8%|▊         | 13/163 [00:19<02:45,  1.10s/it, loss=0.3188, batch_acc=0.9375, running_acc=0.9663, grad=18.4236]Training epoch 29:   9%|▊         | 14/163 [00:20<02:34,  1.04s/it, loss=0.3188, batch_acc=0.9375, running_acc=0.9663, grad=18.4236]Training epoch 29:   9%|▊         | 14/163 [00:20<02:34,  1.04s/it, loss=0.1957, batch_acc=1.0000, running_acc=0.9688, grad=14.8015]Training epoch 29:   9%|▉         | 15/163 [00:21<02:26,  1.01it/s, loss=0.1957, batch_acc=1.0000, running_acc=0.9688, grad=14.8015]Training epoch 29:   9%|▉         | 15/163 [00:21<02:26,  1.01it/s, loss=0.1362, batch_acc=1.0000, running_acc=0.9708, grad=9.3178] Training epoch 29:  10%|▉         | 16/163 [00:23<03:19,  1.36s/it, loss=0.1362, batch_acc=1.0000, running_acc=0.9708, grad=9.3178]Training epoch 29:  10%|▉         | 16/163 [00:23<03:19,  1.36s/it, loss=0.1789, batch_acc=0.9688, running_acc=0.9707, grad=11.5683]Training epoch 29:  10%|█         | 17/163 [00:24<02:57,  1.22s/it, loss=0.1789, batch_acc=0.9688, running_acc=0.9707, grad=11.5683]Training epoch 29:  10%|█         | 17/163 [00:24<02:57,  1.22s/it, loss=0.2050, batch_acc=0.9688, running_acc=0.9706, grad=11.1508]Training epoch 29:  11%|█         | 18/163 [00:25<02:41,  1.12s/it, loss=0.2050, batch_acc=0.9688, running_acc=0.9706, grad=11.1508]Training epoch 29:  11%|█         | 18/163 [00:25<02:41,  1.12s/it, loss=0.1988, batch_acc=0.9688, running_acc=0.9705, grad=14.0152]Training epoch 29:  12%|█▏        | 19/163 [00:26<02:30,  1.04s/it, loss=0.1988, batch_acc=0.9688, running_acc=0.9705, grad=14.0152]Training epoch 29:  12%|█▏        | 19/163 [00:26<02:30,  1.04s/it, loss=0.2428, batch_acc=0.9375, running_acc=0.9688, grad=16.2722]Training epoch 29:  12%|█▏        | 20/163 [00:28<02:54,  1.22s/it, loss=0.2428, batch_acc=0.9375, running_acc=0.9688, grad=16.2722]Training epoch 29:  12%|█▏        | 20/163 [00:28<02:54,  1.22s/it, loss=0.2069, batch_acc=1.0000, running_acc=0.9703, grad=15.2214]Training epoch 29:  13%|█▎        | 21/163 [00:28<02:38,  1.12s/it, loss=0.2069, batch_acc=1.0000, running_acc=0.9703, grad=15.2214]Training epoch 29:  13%|█▎        | 21/163 [00:28<02:38,  1.12s/it, loss=0.2184, batch_acc=0.9688, running_acc=0.9702, grad=14.4098]Training epoch 29:  13%|█▎        | 22/163 [00:29<02:27,  1.05s/it, loss=0.2184, batch_acc=0.9688, running_acc=0.9702, grad=14.4098]Training epoch 29:  13%|█▎        | 22/163 [00:29<02:27,  1.05s/it, loss=0.2015, batch_acc=0.9688, running_acc=0.9702, grad=13.8184]Training epoch 29:  14%|█▍        | 23/163 [00:30<02:19,  1.00it/s, loss=0.2015, batch_acc=0.9688, running_acc=0.9702, grad=13.8184]Training epoch 29:  14%|█▍        | 23/163 [00:30<02:19,  1.00it/s, loss=0.2424, batch_acc=0.9062, running_acc=0.9674, grad=10.9552]Training epoch 29:  15%|█▍        | 24/163 [00:32<02:51,  1.24s/it, loss=0.2424, batch_acc=0.9062, running_acc=0.9674, grad=10.9552]Training epoch 29:  15%|█▍        | 24/163 [00:32<02:51,  1.24s/it, loss=0.2075, batch_acc=0.9688, running_acc=0.9674, grad=12.1400]Training epoch 29:  15%|█▌        | 25/163 [00:33<02:35,  1.13s/it, loss=0.2075, batch_acc=0.9688, running_acc=0.9674, grad=12.1400]Training epoch 29:  15%|█▌        | 25/163 [00:33<02:35,  1.13s/it, loss=0.2211, batch_acc=1.0000, running_acc=0.9688, grad=13.8050]Training epoch 29:  16%|█▌        | 26/163 [00:34<02:24,  1.05s/it, loss=0.2211, batch_acc=1.0000, running_acc=0.9688, grad=13.8050]Training epoch 29:  16%|█▌        | 26/163 [00:34<02:24,  1.05s/it, loss=0.3139, batch_acc=0.9375, running_acc=0.9675, grad=19.2759]Training epoch 29:  17%|█▋        | 27/163 [00:35<02:16,  1.00s/it, loss=0.3139, batch_acc=0.9375, running_acc=0.9675, grad=19.2759]Training epoch 29:  17%|█▋        | 27/163 [00:35<02:16,  1.00s/it, loss=0.1862, batch_acc=0.9688, running_acc=0.9676, grad=18.5203]Training epoch 29:  17%|█▋        | 28/163 [00:36<02:47,  1.24s/it, loss=0.1862, batch_acc=0.9688, running_acc=0.9676, grad=18.5203]Training epoch 29:  17%|█▋        | 28/163 [00:36<02:47,  1.24s/it, loss=0.2181, batch_acc=0.9688, running_acc=0.9676, grad=9.8047] Training epoch 29:  18%|█▊        | 29/163 [00:37<02:31,  1.13s/it, loss=0.2181, batch_acc=0.9688, running_acc=0.9676, grad=9.8047]Training epoch 29:  18%|█▊        | 29/163 [00:37<02:31,  1.13s/it, loss=0.2431, batch_acc=0.9688, running_acc=0.9677, grad=15.0237]Training epoch 29:  18%|█▊        | 30/163 [00:38<02:22,  1.07s/it, loss=0.2431, batch_acc=0.9688, running_acc=0.9677, grad=15.0237]Training epoch 29:  18%|█▊        | 30/163 [00:38<02:22,  1.07s/it, loss=0.2526, batch_acc=1.0000, running_acc=0.9688, grad=14.3138]Training epoch 29:  19%|█▉        | 31/163 [00:39<02:13,  1.01s/it, loss=0.2526, batch_acc=1.0000, running_acc=0.9688, grad=14.3138]Training epoch 29:  19%|█▉        | 31/163 [00:39<02:13,  1.01s/it, loss=0.3228, batch_acc=0.8750, running_acc=0.9657, grad=18.0885]Training epoch 29:  20%|█▉        | 32/163 [00:41<02:33,  1.17s/it, loss=0.3228, batch_acc=0.8750, running_acc=0.9657, grad=18.0885]Training epoch 29:  20%|█▉        | 32/163 [00:41<02:33,  1.17s/it, loss=0.1621, batch_acc=1.0000, running_acc=0.9668, grad=14.2407]Training epoch 29:  20%|██        | 33/163 [00:42<02:20,  1.08s/it, loss=0.1621, batch_acc=1.0000, running_acc=0.9668, grad=14.2407]Training epoch 29:  20%|██        | 33/163 [00:42<02:20,  1.08s/it, loss=0.2782, batch_acc=0.9375, running_acc=0.9659, grad=27.5344]Training epoch 29:  21%|██        | 34/163 [00:42<02:11,  1.02s/it, loss=0.2782, batch_acc=0.9375, running_acc=0.9659, grad=27.5344]Training epoch 29:  21%|██        | 34/163 [00:42<02:11,  1.02s/it, loss=0.2709, batch_acc=1.0000, running_acc=0.9669, grad=17.4589]Training epoch 29:  21%|██▏       | 35/163 [00:43<02:05,  1.02it/s, loss=0.2709, batch_acc=1.0000, running_acc=0.9669, grad=17.4589]Training epoch 29:  21%|██▏       | 35/163 [00:43<02:05,  1.02it/s, loss=0.2702, batch_acc=0.9375, running_acc=0.9661, grad=14.6558]Training epoch 29:  22%|██▏       | 36/163 [00:45<02:17,  1.08s/it, loss=0.2702, batch_acc=0.9375, running_acc=0.9661, grad=14.6558]Training epoch 29:  22%|██▏       | 36/163 [00:45<02:17,  1.08s/it, loss=0.2803, batch_acc=0.9688, running_acc=0.9661, grad=16.9562]Training epoch 29:  23%|██▎       | 37/163 [00:45<02:08,  1.02s/it, loss=0.2803, batch_acc=0.9688, running_acc=0.9661, grad=16.9562]Training epoch 29:  23%|██▎       | 37/163 [00:45<02:08,  1.02s/it, loss=0.2341, batch_acc=0.9688, running_acc=0.9662, grad=16.0113]Training epoch 29:  23%|██▎       | 38/163 [00:46<02:02,  1.02it/s, loss=0.2341, batch_acc=0.9688, running_acc=0.9662, grad=16.0113]Training epoch 29:  23%|██▎       | 38/163 [00:46<02:02,  1.02it/s, loss=0.1836, batch_acc=1.0000, running_acc=0.9671, grad=13.3719]Training epoch 29:  24%|██▍       | 39/163 [00:47<01:57,  1.05it/s, loss=0.1836, batch_acc=1.0000, running_acc=0.9671, grad=13.3719]Training epoch 29:  24%|██▍       | 39/163 [00:47<01:57,  1.05it/s, loss=0.2759, batch_acc=0.9688, running_acc=0.9671, grad=15.9426]Training epoch 29:  25%|██▍       | 40/163 [00:48<02:00,  1.02it/s, loss=0.2759, batch_acc=0.9688, running_acc=0.9671, grad=15.9426]Training epoch 29:  25%|██▍       | 40/163 [00:48<02:00,  1.02it/s, loss=0.2462, batch_acc=1.0000, running_acc=0.9680, grad=15.7800]Training epoch 29:  25%|██▌       | 41/163 [00:49<01:55,  1.05it/s, loss=0.2462, batch_acc=1.0000, running_acc=0.9680, grad=15.7800]Training epoch 29:  25%|██▌       | 41/163 [00:49<01:55,  1.05it/s, loss=0.2181, batch_acc=1.0000, running_acc=0.9688, grad=16.2162]Training epoch 29:  26%|██▌       | 42/163 [00:50<01:56,  1.04it/s, loss=0.2181, batch_acc=1.0000, running_acc=0.9688, grad=16.2162]Training epoch 29:  26%|██▌       | 42/163 [00:50<01:56,  1.04it/s, loss=0.1982, batch_acc=0.9688, running_acc=0.9688, grad=12.0717]Training epoch 29:  26%|██▋       | 43/163 [00:51<01:52,  1.07it/s, loss=0.1982, batch_acc=0.9688, running_acc=0.9688, grad=12.0717]Training epoch 29:  26%|██▋       | 43/163 [00:51<01:52,  1.07it/s, loss=0.1597, batch_acc=1.0000, running_acc=0.9695, grad=10.0764]Training epoch 29:  27%|██▋       | 44/163 [00:53<02:24,  1.21s/it, loss=0.1597, batch_acc=1.0000, running_acc=0.9695, grad=10.0764]Training epoch 29:  27%|██▋       | 44/163 [00:53<02:24,  1.21s/it, loss=0.2743, batch_acc=0.9688, running_acc=0.9695, grad=20.3336]Training epoch 29:  28%|██▊       | 45/163 [00:54<02:11,  1.11s/it, loss=0.2743, batch_acc=0.9688, running_acc=0.9695, grad=20.3336]Training epoch 29:  28%|██▊       | 45/163 [00:54<02:11,  1.11s/it, loss=0.2854, batch_acc=1.0000, running_acc=0.9701, grad=21.4917]Training epoch 29:  28%|██▊       | 46/163 [00:55<02:01,  1.04s/it, loss=0.2854, batch_acc=1.0000, running_acc=0.9701, grad=21.4917]Training epoch 29:  28%|██▊       | 46/163 [00:55<02:01,  1.04s/it, loss=0.1725, batch_acc=1.0000, running_acc=0.9708, grad=11.6083]Training epoch 29:  29%|██▉       | 47/163 [00:56<01:55,  1.01it/s, loss=0.1725, batch_acc=1.0000, running_acc=0.9708, grad=11.6083]Training epoch 29:  29%|██▉       | 47/163 [00:56<01:55,  1.01it/s, loss=0.1977, batch_acc=1.0000, running_acc=0.9714, grad=17.1350]Training epoch 29:  29%|██▉       | 48/163 [00:57<02:03,  1.08s/it, loss=0.1977, batch_acc=1.0000, running_acc=0.9714, grad=17.1350]Training epoch 29:  29%|██▉       | 48/163 [00:57<02:03,  1.08s/it, loss=0.2923, batch_acc=0.9375, running_acc=0.9707, grad=15.5456]Training epoch 29:  30%|███       | 49/163 [00:58<01:55,  1.02s/it, loss=0.2923, batch_acc=0.9375, running_acc=0.9707, grad=15.5456]Training epoch 29:  30%|███       | 49/163 [00:58<01:55,  1.02s/it, loss=0.1614, batch_acc=1.0000, running_acc=0.9713, grad=9.0436] Training epoch 29:  31%|███       | 50/163 [00:59<01:56,  1.03s/it, loss=0.1614, batch_acc=1.0000, running_acc=0.9713, grad=9.0436]Training epoch 29:  31%|███       | 50/163 [00:59<01:56,  1.03s/it, loss=0.2529, batch_acc=1.0000, running_acc=0.9719, grad=17.6685]Training epoch 29:  31%|███▏      | 51/163 [01:00<01:50,  1.01it/s, loss=0.2529, batch_acc=1.0000, running_acc=0.9719, grad=17.6685]Training epoch 29:  31%|███▏      | 51/163 [01:00<01:50,  1.01it/s, loss=0.3593, batch_acc=0.9375, running_acc=0.9712, grad=22.8104]Training epoch 29:  32%|███▏      | 52/163 [01:01<02:02,  1.10s/it, loss=0.3593, batch_acc=0.9375, running_acc=0.9712, grad=22.8104]Training epoch 29:  32%|███▏      | 52/163 [01:01<02:02,  1.10s/it, loss=0.2779, batch_acc=1.0000, running_acc=0.9718, grad=19.0442]Training epoch 29:  33%|███▎      | 53/163 [01:02<01:56,  1.06s/it, loss=0.2779, batch_acc=1.0000, running_acc=0.9718, grad=19.0442]Training epoch 29:  33%|███▎      | 53/163 [01:02<01:56,  1.06s/it, loss=0.2317, batch_acc=1.0000, running_acc=0.9723, grad=18.1981]Training epoch 29:  33%|███▎      | 54/163 [01:04<02:13,  1.22s/it, loss=0.2317, batch_acc=1.0000, running_acc=0.9723, grad=18.1981]Training epoch 29:  33%|███▎      | 54/163 [01:04<02:13,  1.22s/it, loss=0.1870, batch_acc=1.0000, running_acc=0.9728, grad=10.2376]Training epoch 29:  34%|███▎      | 55/163 [01:04<02:00,  1.12s/it, loss=0.1870, batch_acc=1.0000, running_acc=0.9728, grad=10.2376]Training epoch 29:  34%|███▎      | 55/163 [01:04<02:00,  1.12s/it, loss=0.2271, batch_acc=1.0000, running_acc=0.9733, grad=16.3216]Training epoch 29:  34%|███▍      | 56/163 [01:05<01:55,  1.08s/it, loss=0.2271, batch_acc=1.0000, running_acc=0.9733, grad=16.3216]Training epoch 29:  34%|███▍      | 56/163 [01:05<01:55,  1.08s/it, loss=0.2656, batch_acc=0.9688, running_acc=0.9732, grad=15.8876]Training epoch 29:  35%|███▍      | 57/163 [01:06<01:48,  1.02s/it, loss=0.2656, batch_acc=0.9688, running_acc=0.9732, grad=15.8876]Training epoch 29:  35%|███▍      | 57/163 [01:06<01:48,  1.02s/it, loss=0.3205, batch_acc=0.9688, running_acc=0.9731, grad=18.4062]Training epoch 29:  36%|███▌      | 58/163 [01:08<02:08,  1.22s/it, loss=0.3205, batch_acc=0.9688, running_acc=0.9731, grad=18.4062]Training epoch 29:  36%|███▌      | 58/163 [01:08<02:08,  1.22s/it, loss=0.2631, batch_acc=0.9688, running_acc=0.9731, grad=13.0714]Training epoch 29:  36%|███▌      | 59/163 [01:09<01:56,  1.12s/it, loss=0.2631, batch_acc=0.9688, running_acc=0.9731, grad=13.0714]Training epoch 29:  36%|███▌      | 59/163 [01:09<01:56,  1.12s/it, loss=0.2447, batch_acc=0.9375, running_acc=0.9725, grad=13.4772]Training epoch 29:  37%|███▋      | 60/163 [01:10<01:50,  1.07s/it, loss=0.2447, batch_acc=0.9375, running_acc=0.9725, grad=13.4772]Training epoch 29:  37%|███▋      | 60/163 [01:10<01:50,  1.07s/it, loss=0.2730, batch_acc=1.0000, running_acc=0.9729, grad=21.0877]Training epoch 29:  37%|███▋      | 61/163 [01:11<01:44,  1.02s/it, loss=0.2730, batch_acc=1.0000, running_acc=0.9729, grad=21.0877]Training epoch 29:  37%|███▋      | 61/163 [01:11<01:44,  1.02s/it, loss=0.3083, batch_acc=0.9688, running_acc=0.9728, grad=20.4320]Training epoch 29:  38%|███▊      | 62/163 [01:12<02:05,  1.25s/it, loss=0.3083, batch_acc=0.9688, running_acc=0.9728, grad=20.4320]Training epoch 29:  38%|███▊      | 62/163 [01:12<02:05,  1.25s/it, loss=0.2516, batch_acc=1.0000, running_acc=0.9733, grad=19.6306]Training epoch 29:  39%|███▊      | 63/163 [01:13<01:53,  1.14s/it, loss=0.2516, batch_acc=1.0000, running_acc=0.9733, grad=19.6306]Training epoch 29:  39%|███▊      | 63/163 [01:13<01:53,  1.14s/it, loss=0.2525, batch_acc=1.0000, running_acc=0.9737, grad=16.6525]Training epoch 29:  39%|███▉      | 64/163 [01:15<01:52,  1.14s/it, loss=0.2525, batch_acc=1.0000, running_acc=0.9737, grad=16.6525]Training epoch 29:  39%|███▉      | 64/163 [01:15<01:52,  1.14s/it, loss=0.2591, batch_acc=0.9688, running_acc=0.9736, grad=15.9859]Training epoch 29:  40%|███▉      | 65/163 [01:15<01:44,  1.06s/it, loss=0.2591, batch_acc=0.9688, running_acc=0.9736, grad=15.9859]Training epoch 29:  40%|███▉      | 65/163 [01:15<01:44,  1.06s/it, loss=0.2461, batch_acc=0.9688, running_acc=0.9736, grad=17.4664]Training epoch 29:  40%|████      | 66/163 [01:17<01:58,  1.22s/it, loss=0.2461, batch_acc=0.9688, running_acc=0.9736, grad=17.4664]Training epoch 29:  40%|████      | 66/163 [01:17<01:58,  1.22s/it, loss=0.2083, batch_acc=1.0000, running_acc=0.9740, grad=16.1295]Training epoch 29:  41%|████      | 67/163 [01:18<01:47,  1.12s/it, loss=0.2083, batch_acc=1.0000, running_acc=0.9740, grad=16.1295]Training epoch 29:  41%|████      | 67/163 [01:18<01:47,  1.12s/it, loss=0.2343, batch_acc=1.0000, running_acc=0.9743, grad=14.7938]Training epoch 29:  42%|████▏     | 68/163 [01:19<01:39,  1.05s/it, loss=0.2343, batch_acc=1.0000, running_acc=0.9743, grad=14.7938]Training epoch 29:  42%|████▏     | 68/163 [01:19<01:39,  1.05s/it, loss=0.2481, batch_acc=0.9688, running_acc=0.9743, grad=18.0335]Training epoch 29:  42%|████▏     | 69/163 [01:20<01:33,  1.00it/s, loss=0.2481, batch_acc=0.9688, running_acc=0.9743, grad=18.0335]Training epoch 29:  42%|████▏     | 69/163 [01:20<01:33,  1.00it/s, loss=0.2763, batch_acc=0.9688, running_acc=0.9742, grad=14.5921]Training epoch 29:  43%|████▎     | 70/163 [01:21<01:42,  1.10s/it, loss=0.2763, batch_acc=0.9688, running_acc=0.9742, grad=14.5921]Training epoch 29:  43%|████▎     | 70/163 [01:21<01:42,  1.10s/it, loss=0.2178, batch_acc=0.9688, running_acc=0.9741, grad=13.2770]Training epoch 29:  44%|████▎     | 71/163 [01:22<01:35,  1.03s/it, loss=0.2178, batch_acc=0.9688, running_acc=0.9741, grad=13.2770]Training epoch 29:  44%|████▎     | 71/163 [01:22<01:35,  1.03s/it, loss=0.2852, batch_acc=0.9688, running_acc=0.9740, grad=18.6749]Training epoch 29:  44%|████▍     | 72/163 [01:23<01:36,  1.07s/it, loss=0.2852, batch_acc=0.9688, running_acc=0.9740, grad=18.6749]Training epoch 29:  44%|████▍     | 72/163 [01:23<01:36,  1.07s/it, loss=0.1926, batch_acc=0.9688, running_acc=0.9740, grad=10.6876]Training epoch 29:  45%|████▍     | 73/163 [01:24<01:30,  1.01s/it, loss=0.1926, batch_acc=0.9688, running_acc=0.9740, grad=10.6876]Training epoch 29:  45%|████▍     | 73/163 [01:24<01:30,  1.01s/it, loss=0.2189, batch_acc=1.0000, running_acc=0.9743, grad=16.4702]Training epoch 29:  45%|████▌     | 74/163 [01:25<01:44,  1.17s/it, loss=0.2189, batch_acc=1.0000, running_acc=0.9743, grad=16.4702]Training epoch 29:  45%|████▌     | 74/163 [01:25<01:44,  1.17s/it, loss=0.2948, batch_acc=1.0000, running_acc=0.9747, grad=22.4830]Training epoch 29:  46%|████▌     | 75/163 [01:26<01:35,  1.08s/it, loss=0.2948, batch_acc=1.0000, running_acc=0.9747, grad=22.4830]Training epoch 29:  46%|████▌     | 75/163 [01:26<01:35,  1.08s/it, loss=0.2914, batch_acc=0.9375, running_acc=0.9742, grad=25.7049]Training epoch 29:  47%|████▋     | 76/163 [01:28<01:41,  1.16s/it, loss=0.2914, batch_acc=0.9375, running_acc=0.9742, grad=25.7049]Training epoch 29:  47%|████▋     | 76/163 [01:28<01:41,  1.16s/it, loss=0.2819, batch_acc=0.9688, running_acc=0.9741, grad=18.0090]Training epoch 29:  47%|████▋     | 77/163 [01:29<01:32,  1.08s/it, loss=0.2819, batch_acc=0.9688, running_acc=0.9741, grad=18.0090]Training epoch 29:  47%|████▋     | 77/163 [01:29<01:32,  1.08s/it, loss=0.3439, batch_acc=0.9375, running_acc=0.9736, grad=20.9975]Training epoch 29:  48%|████▊     | 78/163 [01:30<01:34,  1.11s/it, loss=0.3439, batch_acc=0.9375, running_acc=0.9736, grad=20.9975]Training epoch 29:  48%|████▊     | 78/163 [01:30<01:34,  1.11s/it, loss=0.2351, batch_acc=0.9688, running_acc=0.9736, grad=17.0562]Training epoch 29:  48%|████▊     | 79/163 [01:31<01:27,  1.04s/it, loss=0.2351, batch_acc=0.9688, running_acc=0.9736, grad=17.0562]Training epoch 29:  48%|████▊     | 79/163 [01:31<01:27,  1.04s/it, loss=0.3269, batch_acc=0.9375, running_acc=0.9731, grad=15.8073]Training epoch 29:  49%|████▉     | 80/163 [01:32<01:31,  1.10s/it, loss=0.3269, batch_acc=0.9375, running_acc=0.9731, grad=15.8073]Training epoch 29:  49%|████▉     | 80/163 [01:32<01:31,  1.10s/it, loss=0.2074, batch_acc=1.0000, running_acc=0.9734, grad=13.1269]Training epoch 29:  50%|████▉     | 81/163 [01:33<01:24,  1.03s/it, loss=0.2074, batch_acc=1.0000, running_acc=0.9734, grad=13.1269]Training epoch 29:  50%|████▉     | 81/163 [01:33<01:24,  1.03s/it, loss=0.2980, batch_acc=0.9688, running_acc=0.9734, grad=22.0875]Training epoch 29:  50%|█████     | 82/163 [01:34<01:31,  1.13s/it, loss=0.2980, batch_acc=0.9688, running_acc=0.9734, grad=22.0875]Training epoch 29:  50%|█████     | 82/163 [01:34<01:31,  1.13s/it, loss=0.1643, batch_acc=0.9688, running_acc=0.9733, grad=11.0424]Training epoch 29:  51%|█████     | 83/163 [01:35<01:24,  1.05s/it, loss=0.1643, batch_acc=0.9688, running_acc=0.9733, grad=11.0424]Training epoch 29:  51%|█████     | 83/163 [01:35<01:24,  1.05s/it, loss=0.2565, batch_acc=0.9688, running_acc=0.9733, grad=18.1917]Training epoch 29:  52%|█████▏    | 84/163 [01:37<01:41,  1.28s/it, loss=0.2565, batch_acc=0.9688, running_acc=0.9733, grad=18.1917]Training epoch 29:  52%|█████▏    | 84/163 [01:37<01:41,  1.28s/it, loss=0.2158, batch_acc=1.0000, running_acc=0.9736, grad=14.5883]Training epoch 29:  52%|█████▏    | 85/163 [01:38<01:30,  1.16s/it, loss=0.2158, batch_acc=1.0000, running_acc=0.9736, grad=14.5883]Training epoch 29:  52%|█████▏    | 85/163 [01:38<01:30,  1.16s/it, loss=0.2686, batch_acc=0.9688, running_acc=0.9735, grad=22.4041]Training epoch 29:  53%|█████▎    | 86/163 [01:39<01:22,  1.08s/it, loss=0.2686, batch_acc=0.9688, running_acc=0.9735, grad=22.4041]Training epoch 29:  53%|█████▎    | 86/163 [01:39<01:22,  1.08s/it, loss=0.2763, batch_acc=0.9688, running_acc=0.9735, grad=16.9450]Training epoch 29:  53%|█████▎    | 87/163 [01:39<01:17,  1.02s/it, loss=0.2763, batch_acc=0.9688, running_acc=0.9735, grad=16.9450]Training epoch 29:  53%|█████▎    | 87/163 [01:39<01:17,  1.02s/it, loss=0.1500, batch_acc=0.9688, running_acc=0.9734, grad=9.3992] Training epoch 29:  54%|█████▍    | 88/163 [01:41<01:29,  1.19s/it, loss=0.1500, batch_acc=0.9688, running_acc=0.9734, grad=9.3992]Training epoch 29:  54%|█████▍    | 88/163 [01:41<01:29,  1.19s/it, loss=0.1964, batch_acc=1.0000, running_acc=0.9737, grad=14.9653]Training epoch 29:  55%|█████▍    | 89/163 [01:42<01:21,  1.10s/it, loss=0.1964, batch_acc=1.0000, running_acc=0.9737, grad=14.9653]Training epoch 29:  55%|█████▍    | 89/163 [01:42<01:21,  1.10s/it, loss=0.2846, batch_acc=0.9375, running_acc=0.9733, grad=18.9005]Training epoch 29:  55%|█████▌    | 90/163 [01:43<01:15,  1.03s/it, loss=0.2846, batch_acc=0.9375, running_acc=0.9733, grad=18.9005]Training epoch 29:  55%|█████▌    | 90/163 [01:43<01:15,  1.03s/it, loss=0.2951, batch_acc=0.9375, running_acc=0.9729, grad=17.7608]Training epoch 29:  56%|█████▌    | 91/163 [01:44<01:11,  1.01it/s, loss=0.2951, batch_acc=0.9375, running_acc=0.9729, grad=17.7608]Training epoch 29:  56%|█████▌    | 91/163 [01:44<01:11,  1.01it/s, loss=0.2225, batch_acc=0.9688, running_acc=0.9729, grad=22.4563]Training epoch 29:  56%|█████▋    | 92/163 [01:46<01:30,  1.28s/it, loss=0.2225, batch_acc=0.9688, running_acc=0.9729, grad=22.4563]Training epoch 29:  56%|█████▋    | 92/163 [01:46<01:30,  1.28s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9732, grad=7.1332] Training epoch 29:  57%|█████▋    | 93/163 [01:46<01:21,  1.16s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9732, grad=7.1332]Training epoch 29:  57%|█████▋    | 93/163 [01:46<01:21,  1.16s/it, loss=0.2088, batch_acc=0.9688, running_acc=0.9731, grad=16.1611]Training epoch 29:  58%|█████▊    | 94/163 [01:47<01:16,  1.11s/it, loss=0.2088, batch_acc=0.9688, running_acc=0.9731, grad=16.1611]Training epoch 29:  58%|█████▊    | 94/163 [01:47<01:16,  1.11s/it, loss=0.2658, batch_acc=0.9688, running_acc=0.9731, grad=23.3262]Training epoch 29:  58%|█████▊    | 95/163 [01:48<01:10,  1.04s/it, loss=0.2658, batch_acc=0.9688, running_acc=0.9731, grad=23.3262]Training epoch 29:  58%|█████▊    | 95/163 [01:48<01:10,  1.04s/it, loss=0.2680, batch_acc=0.9375, running_acc=0.9727, grad=16.7584]Training epoch 29:  59%|█████▉    | 96/163 [01:50<01:12,  1.08s/it, loss=0.2680, batch_acc=0.9375, running_acc=0.9727, grad=16.7584]Training epoch 29:  59%|█████▉    | 96/163 [01:50<01:12,  1.08s/it, loss=0.2531, batch_acc=0.9688, running_acc=0.9727, grad=24.4111]Training epoch 29:  60%|█████▉    | 97/163 [01:50<01:07,  1.02s/it, loss=0.2531, batch_acc=0.9688, running_acc=0.9727, grad=24.4111]Training epoch 29:  60%|█████▉    | 97/163 [01:50<01:07,  1.02s/it, loss=0.2415, batch_acc=0.9375, running_acc=0.9723, grad=15.1708]Training epoch 29:  60%|██████    | 98/163 [01:51<01:03,  1.02it/s, loss=0.2415, batch_acc=0.9375, running_acc=0.9723, grad=15.1708]Training epoch 29:  60%|██████    | 98/163 [01:51<01:03,  1.02it/s, loss=0.2867, batch_acc=0.9688, running_acc=0.9723, grad=18.4789]Training epoch 29:  61%|██████    | 99/163 [01:52<01:00,  1.05it/s, loss=0.2867, batch_acc=0.9688, running_acc=0.9723, grad=18.4789]Training epoch 29:  61%|██████    | 99/163 [01:52<01:00,  1.05it/s, loss=0.2419, batch_acc=0.9688, running_acc=0.9722, grad=19.8400]Training epoch 29:  61%|██████▏   | 100/163 [01:54<01:19,  1.27s/it, loss=0.2419, batch_acc=0.9688, running_acc=0.9722, grad=19.8400]Training epoch 29:  61%|██████▏   | 100/163 [01:54<01:19,  1.27s/it, loss=0.1516, batch_acc=1.0000, running_acc=0.9725, grad=10.1312]Training epoch 29:  62%|██████▏   | 101/163 [01:55<01:11,  1.15s/it, loss=0.1516, batch_acc=1.0000, running_acc=0.9725, grad=10.1312]Training epoch 29:  62%|██████▏   | 101/163 [01:55<01:11,  1.15s/it, loss=0.2220, batch_acc=0.9688, running_acc=0.9725, grad=18.1974]Training epoch 29:  63%|██████▎   | 102/163 [01:56<01:05,  1.07s/it, loss=0.2220, batch_acc=0.9688, running_acc=0.9725, grad=18.1974]Training epoch 29:  63%|██████▎   | 102/163 [01:56<01:05,  1.07s/it, loss=0.2690, batch_acc=0.9688, running_acc=0.9724, grad=15.1244]Training epoch 29:  63%|██████▎   | 103/163 [01:57<01:00,  1.02s/it, loss=0.2690, batch_acc=0.9688, running_acc=0.9724, grad=15.1244]Training epoch 29:  63%|██████▎   | 103/163 [01:57<01:00,  1.02s/it, loss=0.2682, batch_acc=0.9688, running_acc=0.9724, grad=15.1093]Training epoch 29:  64%|██████▍   | 104/163 [01:58<01:07,  1.14s/it, loss=0.2682, batch_acc=0.9688, running_acc=0.9724, grad=15.1093]Training epoch 29:  64%|██████▍   | 104/163 [01:58<01:07,  1.14s/it, loss=0.2653, batch_acc=0.9688, running_acc=0.9724, grad=18.7285]Training epoch 29:  64%|██████▍   | 105/163 [01:59<01:01,  1.06s/it, loss=0.2653, batch_acc=0.9688, running_acc=0.9724, grad=18.7285]Training epoch 29:  64%|██████▍   | 105/163 [01:59<01:01,  1.06s/it, loss=0.1852, batch_acc=0.9688, running_acc=0.9723, grad=14.2781]Training epoch 29:  65%|██████▌   | 106/163 [02:00<00:59,  1.05s/it, loss=0.1852, batch_acc=0.9688, running_acc=0.9723, grad=14.2781]Training epoch 29:  65%|██████▌   | 106/163 [02:00<00:59,  1.05s/it, loss=0.2571, batch_acc=1.0000, running_acc=0.9726, grad=19.2584]Training epoch 29:  66%|██████▌   | 107/163 [02:01<00:55,  1.00it/s, loss=0.2571, batch_acc=1.0000, running_acc=0.9726, grad=19.2584]Training epoch 29:  66%|██████▌   | 107/163 [02:01<00:55,  1.00it/s, loss=0.1930, batch_acc=1.0000, running_acc=0.9728, grad=12.4871]Training epoch 29:  66%|██████▋   | 108/163 [02:02<01:01,  1.11s/it, loss=0.1930, batch_acc=1.0000, running_acc=0.9728, grad=12.4871]Training epoch 29:  66%|██████▋   | 108/163 [02:02<01:01,  1.11s/it, loss=0.3351, batch_acc=0.9375, running_acc=0.9725, grad=21.4641]Training epoch 29:  67%|██████▋   | 109/163 [02:03<00:56,  1.04s/it, loss=0.3351, batch_acc=0.9375, running_acc=0.9725, grad=21.4641]Training epoch 29:  67%|██████▋   | 109/163 [02:03<00:56,  1.04s/it, loss=0.2370, batch_acc=0.9688, running_acc=0.9725, grad=15.8342]Training epoch 29:  67%|██████▋   | 110/163 [02:04<00:53,  1.02s/it, loss=0.2370, batch_acc=0.9688, running_acc=0.9725, grad=15.8342]Training epoch 29:  67%|██████▋   | 110/163 [02:04<00:53,  1.02s/it, loss=0.3089, batch_acc=0.9688, running_acc=0.9724, grad=19.9637]Training epoch 29:  68%|██████▊   | 111/163 [02:05<00:50,  1.03it/s, loss=0.3089, batch_acc=0.9688, running_acc=0.9724, grad=19.9637]Training epoch 29:  68%|██████▊   | 111/163 [02:05<00:50,  1.03it/s, loss=0.4335, batch_acc=0.9375, running_acc=0.9721, grad=26.1230]Training epoch 29:  69%|██████▊   | 112/163 [02:07<00:57,  1.13s/it, loss=0.4335, batch_acc=0.9375, running_acc=0.9721, grad=26.1230]Training epoch 29:  69%|██████▊   | 112/163 [02:07<00:57,  1.13s/it, loss=0.2272, batch_acc=1.0000, running_acc=0.9724, grad=19.8762]Training epoch 29:  69%|██████▉   | 113/163 [02:08<00:52,  1.05s/it, loss=0.2272, batch_acc=1.0000, running_acc=0.9724, grad=19.8762]Training epoch 29:  69%|██████▉   | 113/163 [02:08<00:52,  1.05s/it, loss=0.3200, batch_acc=0.9688, running_acc=0.9723, grad=20.6201]Training epoch 29:  70%|██████▉   | 114/163 [02:08<00:49,  1.02s/it, loss=0.3200, batch_acc=0.9688, running_acc=0.9723, grad=20.6201]Training epoch 29:  70%|██████▉   | 114/163 [02:08<00:49,  1.02s/it, loss=0.3770, batch_acc=0.9375, running_acc=0.9720, grad=19.6839]Training epoch 29:  71%|███████   | 115/163 [02:09<00:46,  1.03it/s, loss=0.3770, batch_acc=0.9375, running_acc=0.9720, grad=19.6839]Training epoch 29:  71%|███████   | 115/163 [02:09<00:46,  1.03it/s, loss=0.2071, batch_acc=0.9688, running_acc=0.9720, grad=13.0274]Training epoch 29:  71%|███████   | 116/163 [02:11<00:55,  1.18s/it, loss=0.2071, batch_acc=0.9688, running_acc=0.9720, grad=13.0274]Training epoch 29:  71%|███████   | 116/163 [02:11<00:55,  1.18s/it, loss=0.2652, batch_acc=1.0000, running_acc=0.9723, grad=20.0646]Training epoch 29:  72%|███████▏  | 117/163 [02:12<00:50,  1.09s/it, loss=0.2652, batch_acc=1.0000, running_acc=0.9723, grad=20.0646]Training epoch 29:  72%|███████▏  | 117/163 [02:12<00:50,  1.09s/it, loss=0.1718, batch_acc=1.0000, running_acc=0.9725, grad=11.8858]Training epoch 29:  72%|███████▏  | 118/163 [02:13<00:46,  1.03s/it, loss=0.1718, batch_acc=1.0000, running_acc=0.9725, grad=11.8858]Training epoch 29:  72%|███████▏  | 118/163 [02:13<00:46,  1.03s/it, loss=0.2933, batch_acc=0.9688, running_acc=0.9725, grad=21.3663]Training epoch 29:  73%|███████▎  | 119/163 [02:14<00:43,  1.01it/s, loss=0.2933, batch_acc=0.9688, running_acc=0.9725, grad=21.3663]Training epoch 29:  73%|███████▎  | 119/163 [02:14<00:43,  1.01it/s, loss=0.2558, batch_acc=1.0000, running_acc=0.9727, grad=19.9991]Training epoch 29:  74%|███████▎  | 120/163 [02:16<00:54,  1.26s/it, loss=0.2558, batch_acc=1.0000, running_acc=0.9727, grad=19.9991]Training epoch 29:  74%|███████▎  | 120/163 [02:16<00:54,  1.26s/it, loss=0.1976, batch_acc=1.0000, running_acc=0.9729, grad=13.2645]Training epoch 29:  74%|███████▍  | 121/163 [02:16<00:48,  1.15s/it, loss=0.1976, batch_acc=1.0000, running_acc=0.9729, grad=13.2645]Training epoch 29:  74%|███████▍  | 121/163 [02:16<00:48,  1.15s/it, loss=0.2159, batch_acc=1.0000, running_acc=0.9731, grad=13.4303]Training epoch 29:  75%|███████▍  | 122/163 [02:17<00:43,  1.07s/it, loss=0.2159, batch_acc=1.0000, running_acc=0.9731, grad=13.4303]Training epoch 29:  75%|███████▍  | 122/163 [02:17<00:43,  1.07s/it, loss=0.2185, batch_acc=0.9688, running_acc=0.9731, grad=14.6626]Training epoch 29:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.2185, batch_acc=0.9688, running_acc=0.9731, grad=14.6626]Training epoch 29:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.3782, batch_acc=0.9688, running_acc=0.9731, grad=20.9032]Training epoch 29:  76%|███████▌  | 124/163 [02:20<00:43,  1.11s/it, loss=0.3782, batch_acc=0.9688, running_acc=0.9731, grad=20.9032]Training epoch 29:  76%|███████▌  | 124/163 [02:20<00:43,  1.11s/it, loss=0.1912, batch_acc=1.0000, running_acc=0.9733, grad=14.1339]Training epoch 29:  77%|███████▋  | 125/163 [02:20<00:39,  1.04s/it, loss=0.1912, batch_acc=1.0000, running_acc=0.9733, grad=14.1339]Training epoch 29:  77%|███████▋  | 125/163 [02:20<00:39,  1.04s/it, loss=0.2772, batch_acc=0.9688, running_acc=0.9732, grad=18.1052]Training epoch 29:  77%|███████▋  | 126/163 [02:22<00:40,  1.10s/it, loss=0.2772, batch_acc=0.9688, running_acc=0.9732, grad=18.1052]Training epoch 29:  77%|███████▋  | 126/163 [02:22<00:40,  1.10s/it, loss=0.2532, batch_acc=0.9688, running_acc=0.9732, grad=16.4130]Training epoch 29:  78%|███████▊  | 127/163 [02:23<00:37,  1.04s/it, loss=0.2532, batch_acc=0.9688, running_acc=0.9732, grad=16.4130]Training epoch 29:  78%|███████▊  | 127/163 [02:23<00:37,  1.04s/it, loss=0.1530, batch_acc=0.9688, running_acc=0.9732, grad=12.1745]Training epoch 29:  79%|███████▊  | 128/163 [02:24<00:40,  1.17s/it, loss=0.1530, batch_acc=0.9688, running_acc=0.9732, grad=12.1745]Training epoch 29:  79%|███████▊  | 128/163 [02:24<00:40,  1.17s/it, loss=0.3216, batch_acc=0.9375, running_acc=0.9729, grad=18.3512]Training epoch 29:  79%|███████▉  | 129/163 [02:25<00:36,  1.08s/it, loss=0.3216, batch_acc=0.9375, running_acc=0.9729, grad=18.3512]Training epoch 29:  79%|███████▉  | 129/163 [02:25<00:36,  1.08s/it, loss=0.3633, batch_acc=0.9375, running_acc=0.9726, grad=27.5338]Training epoch 29:  80%|███████▉  | 130/163 [02:26<00:33,  1.02s/it, loss=0.3633, batch_acc=0.9375, running_acc=0.9726, grad=27.5338]Training epoch 29:  80%|███████▉  | 130/163 [02:26<00:33,  1.02s/it, loss=0.3328, batch_acc=0.9375, running_acc=0.9724, grad=23.3368]Training epoch 29:  80%|████████  | 131/163 [02:27<00:31,  1.02it/s, loss=0.3328, batch_acc=0.9375, running_acc=0.9724, grad=23.3368]Training epoch 29:  80%|████████  | 131/163 [02:27<00:31,  1.02it/s, loss=0.4283, batch_acc=0.8438, running_acc=0.9714, grad=17.6324]Training epoch 29:  81%|████████  | 132/163 [02:28<00:33,  1.09s/it, loss=0.4283, batch_acc=0.8438, running_acc=0.9714, grad=17.6324]Training epoch 29:  81%|████████  | 132/163 [02:28<00:33,  1.09s/it, loss=0.2823, batch_acc=0.9375, running_acc=0.9711, grad=19.4241]Training epoch 29:  82%|████████▏ | 133/163 [02:29<00:30,  1.03s/it, loss=0.2823, batch_acc=0.9375, running_acc=0.9711, grad=19.4241]Training epoch 29:  82%|████████▏ | 133/163 [02:29<00:30,  1.03s/it, loss=0.3329, batch_acc=0.9688, running_acc=0.9711, grad=16.6837]Training epoch 29:  82%|████████▏ | 134/163 [02:31<00:37,  1.29s/it, loss=0.3329, batch_acc=0.9688, running_acc=0.9711, grad=16.6837]Training epoch 29:  82%|████████▏ | 134/163 [02:31<00:37,  1.29s/it, loss=0.3782, batch_acc=0.9375, running_acc=0.9708, grad=24.1985]Training epoch 29:  83%|████████▎ | 135/163 [02:32<00:32,  1.17s/it, loss=0.3782, batch_acc=0.9375, running_acc=0.9708, grad=24.1985]Training epoch 29:  83%|████████▎ | 135/163 [02:32<00:32,  1.17s/it, loss=0.2278, batch_acc=1.0000, running_acc=0.9711, grad=14.8014]Training epoch 29:  83%|████████▎ | 136/163 [02:33<00:29,  1.08s/it, loss=0.2278, batch_acc=1.0000, running_acc=0.9711, grad=14.8014]Training epoch 29:  83%|████████▎ | 136/163 [02:33<00:29,  1.08s/it, loss=0.2938, batch_acc=0.9688, running_acc=0.9710, grad=17.6554]Training epoch 29:  84%|████████▍ | 137/163 [02:33<00:26,  1.02s/it, loss=0.2938, batch_acc=0.9688, running_acc=0.9710, grad=17.6554]Training epoch 29:  84%|████████▍ | 137/163 [02:33<00:26,  1.02s/it, loss=0.2505, batch_acc=0.9062, running_acc=0.9706, grad=14.3716]Training epoch 29:  85%|████████▍ | 138/163 [02:35<00:28,  1.15s/it, loss=0.2505, batch_acc=0.9062, running_acc=0.9706, grad=14.3716]Training epoch 29:  85%|████████▍ | 138/163 [02:35<00:28,  1.15s/it, loss=0.2195, batch_acc=1.0000, running_acc=0.9708, grad=11.6860]Training epoch 29:  85%|████████▌ | 139/163 [02:36<00:25,  1.07s/it, loss=0.2195, batch_acc=1.0000, running_acc=0.9708, grad=11.6860]Training epoch 29:  85%|████████▌ | 139/163 [02:36<00:25,  1.07s/it, loss=0.2119, batch_acc=1.0000, running_acc=0.9710, grad=13.0461]Training epoch 29:  86%|████████▌ | 140/163 [02:37<00:25,  1.10s/it, loss=0.2119, batch_acc=1.0000, running_acc=0.9710, grad=13.0461]Training epoch 29:  86%|████████▌ | 140/163 [02:37<00:25,  1.10s/it, loss=0.2237, batch_acc=0.9375, running_acc=0.9708, grad=16.8596]Training epoch 29:  87%|████████▋ | 141/163 [02:38<00:22,  1.04s/it, loss=0.2237, batch_acc=0.9375, running_acc=0.9708, grad=16.8596]Training epoch 29:  87%|████████▋ | 141/163 [02:38<00:22,  1.04s/it, loss=0.3928, batch_acc=0.9375, running_acc=0.9705, grad=19.0025]Training epoch 29:  87%|████████▋ | 142/163 [02:40<00:25,  1.23s/it, loss=0.3928, batch_acc=0.9375, running_acc=0.9705, grad=19.0025]Training epoch 29:  87%|████████▋ | 142/163 [02:40<00:25,  1.23s/it, loss=0.2216, batch_acc=1.0000, running_acc=0.9707, grad=17.4088]Training epoch 29:  88%|████████▊ | 143/163 [02:40<00:22,  1.13s/it, loss=0.2216, batch_acc=1.0000, running_acc=0.9707, grad=17.4088]Training epoch 29:  88%|████████▊ | 143/163 [02:40<00:22,  1.13s/it, loss=0.2827, batch_acc=0.9688, running_acc=0.9707, grad=20.6682]Training epoch 29:  88%|████████▊ | 144/163 [02:41<00:21,  1.11s/it, loss=0.2827, batch_acc=0.9688, running_acc=0.9707, grad=20.6682]Training epoch 29:  88%|████████▊ | 144/163 [02:41<00:21,  1.11s/it, loss=0.2223, batch_acc=0.9688, running_acc=0.9707, grad=14.2657]Training epoch 29:  89%|████████▉ | 145/163 [02:42<00:18,  1.04s/it, loss=0.2223, batch_acc=0.9688, running_acc=0.9707, grad=14.2657]Training epoch 29:  89%|████████▉ | 145/163 [02:42<00:18,  1.04s/it, loss=0.2759, batch_acc=0.9375, running_acc=0.9705, grad=21.8490]Training epoch 29:  90%|████████▉ | 146/163 [02:44<00:19,  1.13s/it, loss=0.2759, batch_acc=0.9375, running_acc=0.9705, grad=21.8490]Training epoch 29:  90%|████████▉ | 146/163 [02:44<00:19,  1.13s/it, loss=0.3152, batch_acc=0.8750, running_acc=0.9698, grad=18.2440]Training epoch 29:  90%|█████████ | 147/163 [02:45<00:16,  1.05s/it, loss=0.3152, batch_acc=0.8750, running_acc=0.9698, grad=18.2440]Training epoch 29:  90%|█████████ | 147/163 [02:45<00:16,  1.05s/it, loss=0.3719, batch_acc=0.9375, running_acc=0.9696, grad=23.1451]Training epoch 29:  91%|█████████ | 148/163 [02:46<00:16,  1.08s/it, loss=0.3719, batch_acc=0.9375, running_acc=0.9696, grad=23.1451]Training epoch 29:  91%|█████████ | 148/163 [02:46<00:16,  1.08s/it, loss=0.2577, batch_acc=0.9375, running_acc=0.9694, grad=17.6985]Training epoch 29:  91%|█████████▏| 149/163 [02:47<00:14,  1.02s/it, loss=0.2577, batch_acc=0.9375, running_acc=0.9694, grad=17.6985]Training epoch 29:  91%|█████████▏| 149/163 [02:47<00:14,  1.02s/it, loss=0.2064, batch_acc=1.0000, running_acc=0.9696, grad=12.4135]Training epoch 29:  92%|█████████▏| 150/163 [02:48<00:14,  1.08s/it, loss=0.2064, batch_acc=1.0000, running_acc=0.9696, grad=12.4135]Training epoch 29:  92%|█████████▏| 150/163 [02:48<00:14,  1.08s/it, loss=0.2503, batch_acc=1.0000, running_acc=0.9698, grad=15.7027]Training epoch 29:  93%|█████████▎| 151/163 [02:49<00:12,  1.02s/it, loss=0.2503, batch_acc=1.0000, running_acc=0.9698, grad=15.7027]Training epoch 29:  93%|█████████▎| 151/163 [02:49<00:12,  1.02s/it, loss=0.2973, batch_acc=0.9375, running_acc=0.9696, grad=19.5044]Training epoch 29:  93%|█████████▎| 152/163 [02:50<00:11,  1.07s/it, loss=0.2973, batch_acc=0.9375, running_acc=0.9696, grad=19.5044]Training epoch 29:  93%|█████████▎| 152/163 [02:50<00:11,  1.07s/it, loss=0.2356, batch_acc=0.9375, running_acc=0.9694, grad=15.5124]Training epoch 29:  94%|█████████▍| 153/163 [02:51<00:10,  1.01s/it, loss=0.2356, batch_acc=0.9375, running_acc=0.9694, grad=15.5124]Training epoch 29:  94%|█████████▍| 153/163 [02:51<00:10,  1.01s/it, loss=0.2689, batch_acc=0.9688, running_acc=0.9694, grad=17.5836]Training epoch 29:  94%|█████████▍| 154/163 [02:52<00:09,  1.09s/it, loss=0.2689, batch_acc=0.9688, running_acc=0.9694, grad=17.5836]Training epoch 29:  94%|█████████▍| 154/163 [02:52<00:09,  1.09s/it, loss=0.3309, batch_acc=0.9375, running_acc=0.9692, grad=24.1434]Training epoch 29:  95%|█████████▌| 155/163 [02:53<00:08,  1.02s/it, loss=0.3309, batch_acc=0.9375, running_acc=0.9692, grad=24.1434]Training epoch 29:  95%|█████████▌| 155/163 [02:53<00:08,  1.02s/it, loss=0.2390, batch_acc=1.0000, running_acc=0.9694, grad=25.9165]Training epoch 29:  96%|█████████▌| 156/163 [02:54<00:07,  1.00s/it, loss=0.2390, batch_acc=1.0000, running_acc=0.9694, grad=25.9165]Training epoch 29:  96%|█████████▌| 156/163 [02:54<00:07,  1.00s/it, loss=0.1916, batch_acc=1.0000, running_acc=0.9696, grad=11.8897]Training epoch 29:  96%|█████████▋| 157/163 [02:55<00:05,  1.04it/s, loss=0.1916, batch_acc=1.0000, running_acc=0.9696, grad=11.8897]Training epoch 29:  96%|█████████▋| 157/163 [02:55<00:05,  1.04it/s, loss=0.2888, batch_acc=0.9375, running_acc=0.9693, grad=16.5862]Training epoch 29:  97%|█████████▋| 158/163 [02:57<00:06,  1.22s/it, loss=0.2888, batch_acc=0.9375, running_acc=0.9693, grad=16.5862]Training epoch 29:  97%|█████████▋| 158/163 [02:57<00:06,  1.22s/it, loss=0.3175, batch_acc=0.9062, running_acc=0.9689, grad=22.8086]Training epoch 29:  98%|█████████▊| 159/163 [02:57<00:04,  1.12s/it, loss=0.3175, batch_acc=0.9062, running_acc=0.9689, grad=22.8086]Training epoch 29:  98%|█████████▊| 159/163 [02:57<00:04,  1.12s/it, loss=0.2124, batch_acc=1.0000, running_acc=0.9691, grad=16.1547]Training epoch 29:  98%|█████████▊| 160/163 [02:58<00:03,  1.04s/it, loss=0.2124, batch_acc=1.0000, running_acc=0.9691, grad=16.1547]Training epoch 29:  98%|█████████▊| 160/163 [02:58<00:03,  1.04s/it, loss=0.4193, batch_acc=0.9375, running_acc=0.9689, grad=24.3093]Training epoch 29:  99%|█████████▉| 161/163 [02:59<00:01,  1.01it/s, loss=0.4193, batch_acc=0.9375, running_acc=0.9689, grad=24.3093]Training epoch 29:  99%|█████████▉| 161/163 [02:59<00:01,  1.01it/s, loss=0.3698, batch_acc=0.9688, running_acc=0.9689, grad=25.1425]Training epoch 29:  99%|█████████▉| 162/163 [03:00<00:00,  1.04it/s, loss=0.3698, batch_acc=0.9688, running_acc=0.9689, grad=25.1425]Training epoch 29:  99%|█████████▉| 162/163 [03:00<00:00,  1.04it/s, loss=0.3086, batch_acc=0.9688, running_acc=0.9689, grad=20.0594]Training epoch 29: 100%|██████████| 163/163 [03:01<00:00,  1.15it/s, loss=0.3086, batch_acc=0.9688, running_acc=0.9689, grad=20.0594]Training epoch 29: 100%|██████████| 163/163 [03:01<00:00,  1.15it/s, loss=0.2062, batch_acc=1.0000, running_acc=0.9691, grad=17.1414]Training epoch 29: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=0.2062, batch_acc=1.0000, running_acc=0.9691, grad=17.1414]
Evaluation epoch 29:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 29:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it]Evaluation epoch 29:   4%|▎         | 1/28 [00:04<02:13,  4.93s/it, loss=0.5192, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 29:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.5192, batch_acc=0.8438, running_acc=0.8438]Evaluation epoch 29:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.2989, batch_acc=1.0000, running_acc=0.9219]Evaluation epoch 29:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.2989, batch_acc=1.0000, running_acc=0.9219]Evaluation epoch 29:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3761, batch_acc=1.0000, running_acc=0.9479]Evaluation epoch 29:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.3761, batch_acc=1.0000, running_acc=0.9479]Evaluation epoch 29:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.6087, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 29:  18%|█▊        | 5/28 [00:09<00:38,  1.68s/it, loss=0.6087, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 29:  18%|█▊        | 5/28 [00:09<00:38,  1.68s/it, loss=1.5655, batch_acc=0.6562, running_acc=0.8875]Evaluation epoch 29:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.5655, batch_acc=0.6562, running_acc=0.8875]Evaluation epoch 29:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.7001, batch_acc=0.8438, running_acc=0.8802]Evaluation epoch 29:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.7001, batch_acc=0.8438, running_acc=0.8802]Evaluation epoch 29:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.8106, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 29:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=0.8106, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 29:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=0.4920, batch_acc=0.8438, running_acc=0.8711]Evaluation epoch 29:  32%|███▏      | 9/28 [00:14<00:24,  1.30s/it, loss=0.4920, batch_acc=0.8438, running_acc=0.8711]Evaluation epoch 29:  32%|███▏      | 9/28 [00:14<00:24,  1.30s/it, loss=0.5974, batch_acc=0.9062, running_acc=0.8750]Evaluation epoch 29:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.5974, batch_acc=0.9062, running_acc=0.8750]Evaluation epoch 29:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.5646, batch_acc=0.9062, running_acc=0.8781]Evaluation epoch 29:  39%|███▉      | 11/28 [00:14<00:12,  1.31it/s, loss=0.5646, batch_acc=0.9062, running_acc=0.8781]Evaluation epoch 29:  39%|███▉      | 11/28 [00:14<00:12,  1.31it/s, loss=0.4750, batch_acc=0.8750, running_acc=0.8778]Evaluation epoch 29:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=0.4750, batch_acc=0.8750, running_acc=0.8778]Evaluation epoch 29:  43%|████▎     | 12/28 [00:20<00:34,  2.17s/it, loss=0.9952, batch_acc=0.8125, running_acc=0.8724]Evaluation epoch 29:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=0.9952, batch_acc=0.8125, running_acc=0.8724]Evaluation epoch 29:  46%|████▋     | 13/28 [00:20<00:23,  1.59s/it, loss=0.4079, batch_acc=0.9375, running_acc=0.8774]Evaluation epoch 29:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=0.4079, batch_acc=0.9375, running_acc=0.8774]Evaluation epoch 29:  50%|█████     | 14/28 [00:20<00:16,  1.19s/it, loss=1.1294, batch_acc=0.7500, running_acc=0.8683]Evaluation epoch 29:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.1294, batch_acc=0.7500, running_acc=0.8683]Evaluation epoch 29:  54%|█████▎    | 15/28 [00:21<00:11,  1.10it/s, loss=1.0158, batch_acc=0.7500, running_acc=0.8604]Evaluation epoch 29:  57%|█████▋    | 16/28 [00:23<00:17,  1.50s/it, loss=1.0158, batch_acc=0.7500, running_acc=0.8604]Evaluation epoch 29:  57%|█████▋    | 16/28 [00:23<00:17,  1.50s/it, loss=0.7631, batch_acc=0.8125, running_acc=0.8574]Evaluation epoch 29:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.7631, batch_acc=0.8125, running_acc=0.8574]Evaluation epoch 29:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.6333, batch_acc=0.8125, running_acc=0.8548]Evaluation epoch 29:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.6333, batch_acc=0.8125, running_acc=0.8548]Evaluation epoch 29:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5018, batch_acc=0.8438, running_acc=0.8542]Evaluation epoch 29:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.5018, batch_acc=0.8438, running_acc=0.8542]Evaluation epoch 29:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.9457, batch_acc=0.6250, running_acc=0.8421]Evaluation epoch 29:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=0.9457, batch_acc=0.6250, running_acc=0.8421]Evaluation epoch 29:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=0.7315, batch_acc=0.6562, running_acc=0.8328]Evaluation epoch 29:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=0.7315, batch_acc=0.6562, running_acc=0.8328]Evaluation epoch 29:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=0.7179, batch_acc=0.8125, running_acc=0.8318]Evaluation epoch 29:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.7179, batch_acc=0.8125, running_acc=0.8318]Evaluation epoch 29:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.6621, batch_acc=0.8438, running_acc=0.8324]Evaluation epoch 29:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=0.6621, batch_acc=0.8438, running_acc=0.8324]Evaluation epoch 29:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=0.9752, batch_acc=0.7188, running_acc=0.8274]Evaluation epoch 29:  86%|████████▌ | 24/28 [00:33<00:08,  2.02s/it, loss=0.9752, batch_acc=0.7188, running_acc=0.8274]Evaluation epoch 29:  86%|████████▌ | 24/28 [00:33<00:08,  2.02s/it, loss=0.3479, batch_acc=0.9375, running_acc=0.8320]Evaluation epoch 29:  89%|████████▉ | 25/28 [00:33<00:04,  1.49s/it, loss=0.3479, batch_acc=0.9375, running_acc=0.8320]Evaluation epoch 29:  89%|████████▉ | 25/28 [00:33<00:04,  1.49s/it, loss=0.2154, batch_acc=1.0000, running_acc=0.8387]Evaluation epoch 29:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.2154, batch_acc=1.0000, running_acc=0.8387]Evaluation epoch 29:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.7880, batch_acc=0.7500, running_acc=0.8353]Evaluation epoch 29:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.7880, batch_acc=0.7500, running_acc=0.8353]Evaluation epoch 29:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=1.0168, batch_acc=0.7188, running_acc=0.8310]Evaluation epoch 29: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=1.6513, batch_acc=0.3333, running_acc=0.8293]Evaluation epoch 29: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=1.6513, batch_acc=0.3333, running_acc=0.8293]
Training epoch 30:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 30:   1%|          | 1/163 [00:05<15:36,  5.78s/it]Training epoch 30:   1%|          | 1/163 [00:05<15:36,  5.78s/it, loss=0.1908, batch_acc=0.9688, running_acc=0.9688, grad=15.6652]Training epoch 30:   1%|          | 2/163 [00:06<07:46,  2.90s/it, loss=0.1908, batch_acc=0.9688, running_acc=0.9688, grad=15.6652]Training epoch 30:   1%|          | 2/163 [00:06<07:46,  2.90s/it, loss=0.2174, batch_acc=0.9688, running_acc=0.9688, grad=10.2794]Training epoch 30:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.2174, batch_acc=0.9688, running_acc=0.9688, grad=10.2794]Training epoch 30:   2%|▏         | 3/163 [00:07<05:16,  1.98s/it, loss=0.2828, batch_acc=0.9062, running_acc=0.9479, grad=16.1873]Training epoch 30:   2%|▏         | 4/163 [00:09<05:42,  2.15s/it, loss=0.2828, batch_acc=0.9062, running_acc=0.9479, grad=16.1873]Training epoch 30:   2%|▏         | 4/163 [00:09<05:42,  2.15s/it, loss=0.1429, batch_acc=1.0000, running_acc=0.9609, grad=9.1226] Training epoch 30:   3%|▎         | 5/163 [00:10<04:27,  1.69s/it, loss=0.1429, batch_acc=1.0000, running_acc=0.9609, grad=9.1226]Training epoch 30:   3%|▎         | 5/163 [00:10<04:27,  1.69s/it, loss=0.2252, batch_acc=0.9375, running_acc=0.9563, grad=15.3210]Training epoch 30:   4%|▎         | 6/163 [00:11<03:42,  1.42s/it, loss=0.2252, batch_acc=0.9375, running_acc=0.9563, grad=15.3210]Training epoch 30:   4%|▎         | 6/163 [00:11<03:42,  1.42s/it, loss=0.2733, batch_acc=0.9062, running_acc=0.9479, grad=19.8826]Training epoch 30:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=0.2733, batch_acc=0.9062, running_acc=0.9479, grad=19.8826]Training epoch 30:   4%|▍         | 7/163 [00:12<03:13,  1.24s/it, loss=0.2130, batch_acc=1.0000, running_acc=0.9554, grad=17.6191]Training epoch 30:   5%|▍         | 8/163 [00:14<03:37,  1.40s/it, loss=0.2130, batch_acc=1.0000, running_acc=0.9554, grad=17.6191]Training epoch 30:   5%|▍         | 8/163 [00:14<03:37,  1.40s/it, loss=0.1654, batch_acc=1.0000, running_acc=0.9609, grad=11.3561]Training epoch 30:   6%|▌         | 9/163 [00:15<03:10,  1.24s/it, loss=0.1654, batch_acc=1.0000, running_acc=0.9609, grad=11.3561]Training epoch 30:   6%|▌         | 9/163 [00:15<03:10,  1.24s/it, loss=0.2529, batch_acc=1.0000, running_acc=0.9653, grad=18.5518]Training epoch 30:   6%|▌         | 10/163 [00:16<02:52,  1.13s/it, loss=0.2529, batch_acc=1.0000, running_acc=0.9653, grad=18.5518]Training epoch 30:   6%|▌         | 10/163 [00:16<02:52,  1.13s/it, loss=0.2244, batch_acc=0.9688, running_acc=0.9656, grad=15.8000]Training epoch 30:   7%|▋         | 11/163 [00:16<02:39,  1.05s/it, loss=0.2244, batch_acc=0.9688, running_acc=0.9656, grad=15.8000]Training epoch 30:   7%|▋         | 11/163 [00:16<02:39,  1.05s/it, loss=0.1708, batch_acc=1.0000, running_acc=0.9688, grad=13.2496]Training epoch 30:   7%|▋         | 12/163 [00:19<03:28,  1.38s/it, loss=0.1708, batch_acc=1.0000, running_acc=0.9688, grad=13.2496]Training epoch 30:   7%|▋         | 12/163 [00:19<03:28,  1.38s/it, loss=0.2155, batch_acc=1.0000, running_acc=0.9714, grad=12.5070]Training epoch 30:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.2155, batch_acc=1.0000, running_acc=0.9714, grad=12.5070]Training epoch 30:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.1783, batch_acc=1.0000, running_acc=0.9736, grad=13.9893]Training epoch 30:   9%|▊         | 14/163 [00:20<02:47,  1.13s/it, loss=0.1783, batch_acc=1.0000, running_acc=0.9736, grad=13.9893]Training epoch 30:   9%|▊         | 14/163 [00:20<02:47,  1.13s/it, loss=0.2029, batch_acc=1.0000, running_acc=0.9754, grad=12.7737]Training epoch 30:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.2029, batch_acc=1.0000, running_acc=0.9754, grad=12.7737]Training epoch 30:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.1588, batch_acc=1.0000, running_acc=0.9771, grad=10.8667]Training epoch 30:  10%|▉         | 16/163 [00:23<03:19,  1.36s/it, loss=0.1588, batch_acc=1.0000, running_acc=0.9771, grad=10.8667]Training epoch 30:  10%|▉         | 16/163 [00:23<03:19,  1.36s/it, loss=0.2145, batch_acc=0.9688, running_acc=0.9766, grad=19.5431]Training epoch 30:  10%|█         | 17/163 [00:24<02:57,  1.21s/it, loss=0.2145, batch_acc=0.9688, running_acc=0.9766, grad=19.5431]Training epoch 30:  10%|█         | 17/163 [00:24<02:57,  1.21s/it, loss=0.3126, batch_acc=0.9375, running_acc=0.9743, grad=19.7126]Training epoch 30:  11%|█         | 18/163 [00:25<02:41,  1.11s/it, loss=0.3126, batch_acc=0.9375, running_acc=0.9743, grad=19.7126]Training epoch 30:  11%|█         | 18/163 [00:25<02:41,  1.11s/it, loss=0.1326, batch_acc=1.0000, running_acc=0.9757, grad=9.1676] Training epoch 30:  12%|█▏        | 19/163 [00:26<02:30,  1.04s/it, loss=0.1326, batch_acc=1.0000, running_acc=0.9757, grad=9.1676]Training epoch 30:  12%|█▏        | 19/163 [00:26<02:30,  1.04s/it, loss=0.1730, batch_acc=1.0000, running_acc=0.9770, grad=14.6438]Training epoch 30:  12%|█▏        | 20/163 [00:28<03:07,  1.31s/it, loss=0.1730, batch_acc=1.0000, running_acc=0.9770, grad=14.6438]Training epoch 30:  12%|█▏        | 20/163 [00:28<03:07,  1.31s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9766, grad=7.6872] Training epoch 30:  13%|█▎        | 21/163 [00:29<02:48,  1.18s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9766, grad=7.6872]Training epoch 30:  13%|█▎        | 21/163 [00:29<02:48,  1.18s/it, loss=0.2152, batch_acc=0.9688, running_acc=0.9762, grad=15.7033]Training epoch 30:  13%|█▎        | 22/163 [00:30<02:33,  1.09s/it, loss=0.2152, batch_acc=0.9688, running_acc=0.9762, grad=15.7033]Training epoch 30:  13%|█▎        | 22/163 [00:30<02:33,  1.09s/it, loss=0.1284, batch_acc=1.0000, running_acc=0.9773, grad=7.7411] Training epoch 30:  14%|█▍        | 23/163 [00:31<02:24,  1.03s/it, loss=0.1284, batch_acc=1.0000, running_acc=0.9773, grad=7.7411]Training epoch 30:  14%|█▍        | 23/163 [00:31<02:24,  1.03s/it, loss=0.1787, batch_acc=1.0000, running_acc=0.9783, grad=17.3380]Training epoch 30:  15%|█▍        | 24/163 [00:32<02:40,  1.16s/it, loss=0.1787, batch_acc=1.0000, running_acc=0.9783, grad=17.3380]Training epoch 30:  15%|█▍        | 24/163 [00:32<02:40,  1.16s/it, loss=0.1800, batch_acc=1.0000, running_acc=0.9792, grad=10.2689]Training epoch 30:  15%|█▌        | 25/163 [00:33<02:28,  1.07s/it, loss=0.1800, batch_acc=1.0000, running_acc=0.9792, grad=10.2689]Training epoch 30:  15%|█▌        | 25/163 [00:33<02:28,  1.07s/it, loss=0.3233, batch_acc=0.9688, running_acc=0.9788, grad=26.7245]Training epoch 30:  16%|█▌        | 26/163 [00:34<02:20,  1.03s/it, loss=0.3233, batch_acc=0.9688, running_acc=0.9788, grad=26.7245]Training epoch 30:  16%|█▌        | 26/163 [00:34<02:20,  1.03s/it, loss=0.1932, batch_acc=1.0000, running_acc=0.9796, grad=16.7228]Training epoch 30:  17%|█▋        | 27/163 [00:35<02:13,  1.02it/s, loss=0.1932, batch_acc=1.0000, running_acc=0.9796, grad=16.7228]Training epoch 30:  17%|█▋        | 27/163 [00:35<02:13,  1.02it/s, loss=0.1881, batch_acc=1.0000, running_acc=0.9803, grad=12.9888]Training epoch 30:  17%|█▋        | 28/163 [00:37<02:51,  1.27s/it, loss=0.1881, batch_acc=1.0000, running_acc=0.9803, grad=12.9888]Training epoch 30:  17%|█▋        | 28/163 [00:37<02:51,  1.27s/it, loss=0.2574, batch_acc=0.9688, running_acc=0.9799, grad=28.4711]Training epoch 30:  18%|█▊        | 29/163 [00:38<02:34,  1.15s/it, loss=0.2574, batch_acc=0.9688, running_acc=0.9799, grad=28.4711]Training epoch 30:  18%|█▊        | 29/163 [00:38<02:34,  1.15s/it, loss=0.1815, batch_acc=1.0000, running_acc=0.9806, grad=21.8371]Training epoch 30:  18%|█▊        | 30/163 [00:38<02:22,  1.07s/it, loss=0.1815, batch_acc=1.0000, running_acc=0.9806, grad=21.8371]Training epoch 30:  18%|█▊        | 30/163 [00:38<02:22,  1.07s/it, loss=0.3325, batch_acc=0.9375, running_acc=0.9792, grad=23.6880]Training epoch 30:  19%|█▉        | 31/163 [00:39<02:13,  1.01s/it, loss=0.3325, batch_acc=0.9375, running_acc=0.9792, grad=23.6880]Training epoch 30:  19%|█▉        | 31/163 [00:39<02:13,  1.01s/it, loss=0.2700, batch_acc=0.9688, running_acc=0.9788, grad=17.6627]Training epoch 30:  20%|█▉        | 32/163 [00:41<02:29,  1.14s/it, loss=0.2700, batch_acc=0.9688, running_acc=0.9788, grad=17.6627]Training epoch 30:  20%|█▉        | 32/163 [00:41<02:29,  1.14s/it, loss=0.2056, batch_acc=1.0000, running_acc=0.9795, grad=15.6864]Training epoch 30:  20%|██        | 33/163 [00:42<02:18,  1.06s/it, loss=0.2056, batch_acc=1.0000, running_acc=0.9795, grad=15.6864]Training epoch 30:  20%|██        | 33/163 [00:42<02:18,  1.06s/it, loss=0.2601, batch_acc=1.0000, running_acc=0.9801, grad=20.9185]Training epoch 30:  21%|██        | 34/163 [00:42<02:09,  1.01s/it, loss=0.2601, batch_acc=1.0000, running_acc=0.9801, grad=20.9185]Training epoch 30:  21%|██        | 34/163 [00:42<02:09,  1.01s/it, loss=0.2212, batch_acc=0.9375, running_acc=0.9789, grad=16.2728]Training epoch 30:  21%|██▏       | 35/163 [00:43<02:04,  1.03it/s, loss=0.2212, batch_acc=0.9375, running_acc=0.9789, grad=16.2728]Training epoch 30:  21%|██▏       | 35/163 [00:43<02:04,  1.03it/s, loss=0.2910, batch_acc=0.9062, running_acc=0.9768, grad=24.2823]Training epoch 30:  22%|██▏       | 36/163 [00:45<02:30,  1.19s/it, loss=0.2910, batch_acc=0.9062, running_acc=0.9768, grad=24.2823]Training epoch 30:  22%|██▏       | 36/163 [00:45<02:30,  1.19s/it, loss=0.2139, batch_acc=1.0000, running_acc=0.9774, grad=12.7579]Training epoch 30:  23%|██▎       | 37/163 [00:46<02:17,  1.09s/it, loss=0.2139, batch_acc=1.0000, running_acc=0.9774, grad=12.7579]Training epoch 30:  23%|██▎       | 37/163 [00:46<02:17,  1.09s/it, loss=0.2342, batch_acc=0.9688, running_acc=0.9772, grad=13.0495]Training epoch 30:  23%|██▎       | 38/163 [00:47<02:08,  1.03s/it, loss=0.2342, batch_acc=0.9688, running_acc=0.9772, grad=13.0495]Training epoch 30:  23%|██▎       | 38/163 [00:47<02:08,  1.03s/it, loss=0.3078, batch_acc=0.9688, running_acc=0.9770, grad=20.3455]Training epoch 30:  24%|██▍       | 39/163 [00:48<02:02,  1.01it/s, loss=0.3078, batch_acc=0.9688, running_acc=0.9770, grad=20.3455]Training epoch 30:  24%|██▍       | 39/163 [00:48<02:02,  1.01it/s, loss=0.1909, batch_acc=1.0000, running_acc=0.9776, grad=13.6783]Training epoch 30:  25%|██▍       | 40/163 [00:49<02:08,  1.04s/it, loss=0.1909, batch_acc=1.0000, running_acc=0.9776, grad=13.6783]Training epoch 30:  25%|██▍       | 40/163 [00:49<02:08,  1.04s/it, loss=0.1843, batch_acc=0.9688, running_acc=0.9773, grad=14.5126]Training epoch 30:  25%|██▌       | 41/163 [00:50<02:01,  1.01it/s, loss=0.1843, batch_acc=0.9688, running_acc=0.9773, grad=14.5126]Training epoch 30:  25%|██▌       | 41/163 [00:50<02:01,  1.01it/s, loss=0.2635, batch_acc=0.9062, running_acc=0.9756, grad=7.8171] Training epoch 30:  26%|██▌       | 42/163 [00:51<01:55,  1.04it/s, loss=0.2635, batch_acc=0.9062, running_acc=0.9756, grad=7.8171]Training epoch 30:  26%|██▌       | 42/163 [00:51<01:55,  1.04it/s, loss=0.2321, batch_acc=1.0000, running_acc=0.9762, grad=16.9168]Training epoch 30:  26%|██▋       | 43/163 [00:52<01:52,  1.07it/s, loss=0.2321, batch_acc=1.0000, running_acc=0.9762, grad=16.9168]Training epoch 30:  26%|██▋       | 43/163 [00:52<01:52,  1.07it/s, loss=0.2490, batch_acc=0.9688, running_acc=0.9760, grad=12.5060]Training epoch 30:  27%|██▋       | 44/163 [00:53<02:25,  1.22s/it, loss=0.2490, batch_acc=0.9688, running_acc=0.9760, grad=12.5060]Training epoch 30:  27%|██▋       | 44/163 [00:53<02:25,  1.22s/it, loss=0.3007, batch_acc=0.9375, running_acc=0.9751, grad=28.3485]Training epoch 30:  28%|██▊       | 45/163 [00:54<02:12,  1.12s/it, loss=0.3007, batch_acc=0.9375, running_acc=0.9751, grad=28.3485]Training epoch 30:  28%|██▊       | 45/163 [00:54<02:12,  1.12s/it, loss=0.1786, batch_acc=1.0000, running_acc=0.9757, grad=10.7023]Training epoch 30:  28%|██▊       | 46/163 [00:55<02:02,  1.05s/it, loss=0.1786, batch_acc=1.0000, running_acc=0.9757, grad=10.7023]Training epoch 30:  28%|██▊       | 46/163 [00:55<02:02,  1.05s/it, loss=0.2806, batch_acc=0.9688, running_acc=0.9755, grad=18.5036]Training epoch 30:  29%|██▉       | 47/163 [00:56<01:55,  1.00it/s, loss=0.2806, batch_acc=0.9688, running_acc=0.9755, grad=18.5036]Training epoch 30:  29%|██▉       | 47/163 [00:56<01:55,  1.00it/s, loss=0.2525, batch_acc=0.9375, running_acc=0.9747, grad=11.6793]Training epoch 30:  29%|██▉       | 48/163 [00:58<02:38,  1.38s/it, loss=0.2525, batch_acc=0.9375, running_acc=0.9747, grad=11.6793]Training epoch 30:  29%|██▉       | 48/163 [00:58<02:38,  1.38s/it, loss=0.2365, batch_acc=0.9688, running_acc=0.9746, grad=11.9717]Training epoch 30:  30%|███       | 49/163 [00:59<02:29,  1.31s/it, loss=0.2365, batch_acc=0.9688, running_acc=0.9746, grad=11.9717]Training epoch 30:  30%|███       | 49/163 [00:59<02:29,  1.31s/it, loss=0.3341, batch_acc=0.8750, running_acc=0.9726, grad=20.1793]Training epoch 30:  31%|███       | 50/163 [01:00<02:13,  1.18s/it, loss=0.3341, batch_acc=0.8750, running_acc=0.9726, grad=20.1793]Training epoch 30:  31%|███       | 50/163 [01:00<02:13,  1.18s/it, loss=0.1858, batch_acc=1.0000, running_acc=0.9731, grad=15.8847]Training epoch 30:  31%|███▏      | 51/163 [01:01<02:01,  1.09s/it, loss=0.1858, batch_acc=1.0000, running_acc=0.9731, grad=15.8847]Training epoch 30:  31%|███▏      | 51/163 [01:01<02:01,  1.09s/it, loss=0.2842, batch_acc=0.9688, running_acc=0.9730, grad=20.3114]Training epoch 30:  32%|███▏      | 52/163 [01:03<02:13,  1.20s/it, loss=0.2842, batch_acc=0.9688, running_acc=0.9730, grad=20.3114]Training epoch 30:  32%|███▏      | 52/163 [01:03<02:13,  1.20s/it, loss=0.2386, batch_acc=0.9688, running_acc=0.9730, grad=15.5586]Training epoch 30:  33%|███▎      | 53/163 [01:04<02:12,  1.20s/it, loss=0.2386, batch_acc=0.9688, running_acc=0.9730, grad=15.5586]Training epoch 30:  33%|███▎      | 53/163 [01:04<02:12,  1.20s/it, loss=0.2053, batch_acc=0.9688, running_acc=0.9729, grad=14.1928]Training epoch 30:  33%|███▎      | 54/163 [01:05<02:00,  1.11s/it, loss=0.2053, batch_acc=0.9688, running_acc=0.9729, grad=14.1928]Training epoch 30:  33%|███▎      | 54/163 [01:05<02:00,  1.11s/it, loss=0.1798, batch_acc=1.0000, running_acc=0.9734, grad=13.5242]Training epoch 30:  34%|███▎      | 55/163 [01:06<01:52,  1.04s/it, loss=0.1798, batch_acc=1.0000, running_acc=0.9734, grad=13.5242]Training epoch 30:  34%|███▎      | 55/163 [01:06<01:52,  1.04s/it, loss=0.3244, batch_acc=0.9062, running_acc=0.9722, grad=22.8207]Training epoch 30:  34%|███▍      | 56/163 [01:07<01:54,  1.07s/it, loss=0.3244, batch_acc=0.9062, running_acc=0.9722, grad=22.8207]Training epoch 30:  34%|███▍      | 56/163 [01:07<01:54,  1.07s/it, loss=0.1919, batch_acc=1.0000, running_acc=0.9727, grad=18.1607]Training epoch 30:  35%|███▍      | 57/163 [01:08<02:03,  1.17s/it, loss=0.1919, batch_acc=1.0000, running_acc=0.9727, grad=18.1607]Training epoch 30:  35%|███▍      | 57/163 [01:08<02:03,  1.17s/it, loss=0.2821, batch_acc=0.9375, running_acc=0.9720, grad=23.7665]Training epoch 30:  36%|███▌      | 58/163 [01:09<01:53,  1.08s/it, loss=0.2821, batch_acc=0.9375, running_acc=0.9720, grad=23.7665]Training epoch 30:  36%|███▌      | 58/163 [01:09<01:53,  1.08s/it, loss=0.1723, batch_acc=0.9688, running_acc=0.9720, grad=10.2283]Training epoch 30:  36%|███▌      | 59/163 [01:10<01:46,  1.02s/it, loss=0.1723, batch_acc=0.9688, running_acc=0.9720, grad=10.2283]Training epoch 30:  36%|███▌      | 59/163 [01:10<01:46,  1.02s/it, loss=0.3652, batch_acc=0.9688, running_acc=0.9719, grad=20.7624]Training epoch 30:  37%|███▋      | 60/163 [01:11<01:51,  1.08s/it, loss=0.3652, batch_acc=0.9688, running_acc=0.9719, grad=20.7624]Training epoch 30:  37%|███▋      | 60/163 [01:11<01:51,  1.08s/it, loss=0.2366, batch_acc=0.9688, running_acc=0.9719, grad=16.3232]Training epoch 30:  37%|███▋      | 61/163 [01:12<01:45,  1.04s/it, loss=0.2366, batch_acc=0.9688, running_acc=0.9719, grad=16.3232]Training epoch 30:  37%|███▋      | 61/163 [01:12<01:45,  1.04s/it, loss=0.2007, batch_acc=1.0000, running_acc=0.9723, grad=15.0582]Training epoch 30:  38%|███▊      | 62/163 [01:13<01:39,  1.01it/s, loss=0.2007, batch_acc=1.0000, running_acc=0.9723, grad=15.0582]Training epoch 30:  38%|███▊      | 62/163 [01:13<01:39,  1.01it/s, loss=0.1868, batch_acc=0.9688, running_acc=0.9723, grad=12.0588]Training epoch 30:  39%|███▊      | 63/163 [01:14<01:35,  1.05it/s, loss=0.1868, batch_acc=0.9688, running_acc=0.9723, grad=12.0588]Training epoch 30:  39%|███▊      | 63/163 [01:14<01:35,  1.05it/s, loss=0.2908, batch_acc=0.9688, running_acc=0.9722, grad=25.0236]Training epoch 30:  39%|███▉      | 64/163 [01:16<02:13,  1.35s/it, loss=0.2908, batch_acc=0.9688, running_acc=0.9722, grad=25.0236]Training epoch 30:  39%|███▉      | 64/163 [01:16<02:13,  1.35s/it, loss=0.2114, batch_acc=0.9688, running_acc=0.9722, grad=13.7028]Training epoch 30:  40%|███▉      | 65/163 [01:17<01:58,  1.21s/it, loss=0.2114, batch_acc=0.9688, running_acc=0.9722, grad=13.7028]Training epoch 30:  40%|███▉      | 65/163 [01:17<01:58,  1.21s/it, loss=0.1797, batch_acc=1.0000, running_acc=0.9726, grad=12.3156]Training epoch 30:  40%|████      | 66/163 [01:18<01:47,  1.11s/it, loss=0.1797, batch_acc=1.0000, running_acc=0.9726, grad=12.3156]Training epoch 30:  40%|████      | 66/163 [01:18<01:47,  1.11s/it, loss=0.3177, batch_acc=0.9375, running_acc=0.9721, grad=17.4827]Training epoch 30:  41%|████      | 67/163 [01:19<01:40,  1.04s/it, loss=0.3177, batch_acc=0.9375, running_acc=0.9721, grad=17.4827]Training epoch 30:  41%|████      | 67/163 [01:19<01:40,  1.04s/it, loss=0.2742, batch_acc=0.9062, running_acc=0.9711, grad=13.3623]Training epoch 30:  42%|████▏     | 68/163 [01:20<01:58,  1.25s/it, loss=0.2742, batch_acc=0.9062, running_acc=0.9711, grad=13.3623]Training epoch 30:  42%|████▏     | 68/163 [01:20<01:58,  1.25s/it, loss=0.2298, batch_acc=1.0000, running_acc=0.9715, grad=14.7113]Training epoch 30:  42%|████▏     | 69/163 [01:21<01:46,  1.14s/it, loss=0.2298, batch_acc=1.0000, running_acc=0.9715, grad=14.7113]Training epoch 30:  42%|████▏     | 69/163 [01:21<01:46,  1.14s/it, loss=0.2543, batch_acc=1.0000, running_acc=0.9719, grad=17.7073]Training epoch 30:  43%|████▎     | 70/163 [01:22<01:38,  1.06s/it, loss=0.2543, batch_acc=1.0000, running_acc=0.9719, grad=17.7073]Training epoch 30:  43%|████▎     | 70/163 [01:22<01:38,  1.06s/it, loss=0.2594, batch_acc=0.9375, running_acc=0.9714, grad=19.5938]Training epoch 30:  44%|████▎     | 71/163 [01:23<01:32,  1.01s/it, loss=0.2594, batch_acc=0.9375, running_acc=0.9714, grad=19.5938]Training epoch 30:  44%|████▎     | 71/163 [01:23<01:32,  1.01s/it, loss=0.3327, batch_acc=0.9375, running_acc=0.9710, grad=24.9793]Training epoch 30:  44%|████▍     | 72/163 [01:25<01:54,  1.26s/it, loss=0.3327, batch_acc=0.9375, running_acc=0.9710, grad=24.9793]Training epoch 30:  44%|████▍     | 72/163 [01:25<01:54,  1.26s/it, loss=0.1749, batch_acc=0.9688, running_acc=0.9709, grad=11.9382]Training epoch 30:  45%|████▍     | 73/163 [01:26<01:42,  1.14s/it, loss=0.1749, batch_acc=0.9688, running_acc=0.9709, grad=11.9382]Training epoch 30:  45%|████▍     | 73/163 [01:26<01:42,  1.14s/it, loss=0.2171, batch_acc=1.0000, running_acc=0.9713, grad=15.0065]Training epoch 30:  45%|████▌     | 74/163 [01:27<01:34,  1.06s/it, loss=0.2171, batch_acc=1.0000, running_acc=0.9713, grad=15.0065]Training epoch 30:  45%|████▌     | 74/163 [01:27<01:34,  1.06s/it, loss=0.1618, batch_acc=0.9688, running_acc=0.9713, grad=12.9552]Training epoch 30:  46%|████▌     | 75/163 [01:28<01:28,  1.01s/it, loss=0.1618, batch_acc=0.9688, running_acc=0.9713, grad=12.9552]Training epoch 30:  46%|████▌     | 75/163 [01:28<01:28,  1.01s/it, loss=0.1735, batch_acc=1.0000, running_acc=0.9717, grad=15.8190]Training epoch 30:  47%|████▋     | 76/163 [01:30<01:55,  1.33s/it, loss=0.1735, batch_acc=1.0000, running_acc=0.9717, grad=15.8190]Training epoch 30:  47%|████▋     | 76/163 [01:30<01:55,  1.33s/it, loss=0.3459, batch_acc=0.9375, running_acc=0.9712, grad=16.8271]Training epoch 30:  47%|████▋     | 77/163 [01:31<01:42,  1.20s/it, loss=0.3459, batch_acc=0.9375, running_acc=0.9712, grad=16.8271]Training epoch 30:  47%|████▋     | 77/163 [01:31<01:42,  1.20s/it, loss=0.3176, batch_acc=0.9688, running_acc=0.9712, grad=18.6795]Training epoch 30:  48%|████▊     | 78/163 [01:31<01:33,  1.10s/it, loss=0.3176, batch_acc=0.9688, running_acc=0.9712, grad=18.6795]Training epoch 30:  48%|████▊     | 78/163 [01:31<01:33,  1.10s/it, loss=0.1670, batch_acc=0.9688, running_acc=0.9712, grad=10.6605]Training epoch 30:  48%|████▊     | 79/163 [01:32<01:26,  1.04s/it, loss=0.1670, batch_acc=0.9688, running_acc=0.9712, grad=10.6605]Training epoch 30:  48%|████▊     | 79/163 [01:32<01:26,  1.04s/it, loss=0.1900, batch_acc=1.0000, running_acc=0.9715, grad=15.0254]Training epoch 30:  49%|████▉     | 80/163 [01:34<01:52,  1.35s/it, loss=0.1900, batch_acc=1.0000, running_acc=0.9715, grad=15.0254]Training epoch 30:  49%|████▉     | 80/163 [01:34<01:52,  1.35s/it, loss=0.2354, batch_acc=0.9688, running_acc=0.9715, grad=13.0395]Training epoch 30:  50%|████▉     | 81/163 [01:35<01:39,  1.21s/it, loss=0.2354, batch_acc=0.9688, running_acc=0.9715, grad=13.0395]Training epoch 30:  50%|████▉     | 81/163 [01:35<01:39,  1.21s/it, loss=0.1576, batch_acc=1.0000, running_acc=0.9718, grad=11.1448]Training epoch 30:  50%|█████     | 82/163 [01:36<01:30,  1.11s/it, loss=0.1576, batch_acc=1.0000, running_acc=0.9718, grad=11.1448]Training epoch 30:  50%|█████     | 82/163 [01:36<01:30,  1.11s/it, loss=0.2067, batch_acc=0.9688, running_acc=0.9718, grad=14.7864]Training epoch 30:  51%|█████     | 83/163 [01:37<01:23,  1.04s/it, loss=0.2067, batch_acc=0.9688, running_acc=0.9718, grad=14.7864]Training epoch 30:  51%|█████     | 83/163 [01:37<01:23,  1.04s/it, loss=0.3304, batch_acc=0.9375, running_acc=0.9714, grad=18.8859]Training epoch 30:  52%|█████▏    | 84/163 [01:39<01:46,  1.35s/it, loss=0.3304, batch_acc=0.9375, running_acc=0.9714, grad=18.8859]Training epoch 30:  52%|█████▏    | 84/163 [01:39<01:46,  1.35s/it, loss=0.2354, batch_acc=1.0000, running_acc=0.9717, grad=16.7551]Training epoch 30:  52%|█████▏    | 85/163 [01:40<01:34,  1.21s/it, loss=0.2354, batch_acc=1.0000, running_acc=0.9717, grad=16.7551]Training epoch 30:  52%|█████▏    | 85/163 [01:40<01:34,  1.21s/it, loss=0.2670, batch_acc=0.9375, running_acc=0.9713, grad=24.6471]Training epoch 30:  53%|█████▎    | 86/163 [01:41<01:25,  1.11s/it, loss=0.2670, batch_acc=0.9375, running_acc=0.9713, grad=24.6471]Training epoch 30:  53%|█████▎    | 86/163 [01:41<01:25,  1.11s/it, loss=0.2214, batch_acc=1.0000, running_acc=0.9717, grad=11.8548]Training epoch 30:  53%|█████▎    | 87/163 [01:42<01:19,  1.04s/it, loss=0.2214, batch_acc=1.0000, running_acc=0.9717, grad=11.8548]Training epoch 30:  53%|█████▎    | 87/163 [01:42<01:19,  1.04s/it, loss=0.2580, batch_acc=0.9375, running_acc=0.9713, grad=14.5680]Training epoch 30:  54%|█████▍    | 88/163 [01:43<01:21,  1.08s/it, loss=0.2580, batch_acc=0.9375, running_acc=0.9713, grad=14.5680]Training epoch 30:  54%|█████▍    | 88/163 [01:43<01:21,  1.08s/it, loss=0.3322, batch_acc=0.9688, running_acc=0.9712, grad=19.5456]Training epoch 30:  55%|█████▍    | 89/163 [01:44<01:15,  1.02s/it, loss=0.3322, batch_acc=0.9688, running_acc=0.9712, grad=19.5456]Training epoch 30:  55%|█████▍    | 89/163 [01:44<01:15,  1.02s/it, loss=0.2312, batch_acc=0.9688, running_acc=0.9712, grad=19.9635]Training epoch 30:  55%|█████▌    | 90/163 [01:45<01:11,  1.02it/s, loss=0.2312, batch_acc=0.9688, running_acc=0.9712, grad=19.9635]Training epoch 30:  55%|█████▌    | 90/163 [01:45<01:11,  1.02it/s, loss=0.2856, batch_acc=0.9375, running_acc=0.9708, grad=25.0079]Training epoch 30:  56%|█████▌    | 91/163 [01:46<01:08,  1.05it/s, loss=0.2856, batch_acc=0.9375, running_acc=0.9708, grad=25.0079]Training epoch 30:  56%|█████▌    | 91/163 [01:46<01:08,  1.05it/s, loss=0.2128, batch_acc=0.9688, running_acc=0.9708, grad=14.3966]Training epoch 30:  56%|█████▋    | 92/163 [01:47<01:13,  1.04s/it, loss=0.2128, batch_acc=0.9688, running_acc=0.9708, grad=14.3966]Training epoch 30:  56%|█████▋    | 92/163 [01:47<01:13,  1.04s/it, loss=0.1826, batch_acc=1.0000, running_acc=0.9711, grad=13.5059]Training epoch 30:  57%|█████▋    | 93/163 [01:48<01:09,  1.01it/s, loss=0.1826, batch_acc=1.0000, running_acc=0.9711, grad=13.5059]Training epoch 30:  57%|█████▋    | 93/163 [01:48<01:09,  1.01it/s, loss=0.2849, batch_acc=0.9062, running_acc=0.9704, grad=17.9517]Training epoch 30:  58%|█████▊    | 94/163 [01:49<01:06,  1.04it/s, loss=0.2849, batch_acc=0.9062, running_acc=0.9704, grad=17.9517]Training epoch 30:  58%|█████▊    | 94/163 [01:49<01:06,  1.04it/s, loss=0.2932, batch_acc=0.9062, running_acc=0.9697, grad=19.6097]Training epoch 30:  58%|█████▊    | 95/163 [01:49<01:03,  1.07it/s, loss=0.2932, batch_acc=0.9062, running_acc=0.9697, grad=19.6097]Training epoch 30:  58%|█████▊    | 95/163 [01:49<01:03,  1.07it/s, loss=0.1600, batch_acc=0.9688, running_acc=0.9697, grad=9.1681] Training epoch 30:  59%|█████▉    | 96/163 [01:51<01:10,  1.06s/it, loss=0.1600, batch_acc=0.9688, running_acc=0.9697, grad=9.1681]Training epoch 30:  59%|█████▉    | 96/163 [01:51<01:10,  1.06s/it, loss=0.2460, batch_acc=0.9688, running_acc=0.9697, grad=20.3603]Training epoch 30:  60%|█████▉    | 97/163 [01:52<01:06,  1.00s/it, loss=0.2460, batch_acc=0.9688, running_acc=0.9697, grad=20.3603]Training epoch 30:  60%|█████▉    | 97/163 [01:52<01:06,  1.00s/it, loss=0.2415, batch_acc=1.0000, running_acc=0.9700, grad=19.5608]Training epoch 30:  60%|██████    | 98/163 [01:53<01:02,  1.04it/s, loss=0.2415, batch_acc=1.0000, running_acc=0.9700, grad=19.5608]Training epoch 30:  60%|██████    | 98/163 [01:53<01:02,  1.04it/s, loss=0.1724, batch_acc=0.9688, running_acc=0.9700, grad=10.2117]Training epoch 30:  61%|██████    | 99/163 [01:53<01:00,  1.06it/s, loss=0.1724, batch_acc=0.9688, running_acc=0.9700, grad=10.2117]Training epoch 30:  61%|██████    | 99/163 [01:53<01:00,  1.06it/s, loss=0.2733, batch_acc=0.9688, running_acc=0.9700, grad=21.6053]Training epoch 30:  61%|██████▏   | 100/163 [01:55<01:09,  1.11s/it, loss=0.2733, batch_acc=0.9688, running_acc=0.9700, grad=21.6053]Training epoch 30:  61%|██████▏   | 100/163 [01:55<01:09,  1.11s/it, loss=0.3444, batch_acc=0.9062, running_acc=0.9694, grad=23.5826]Training epoch 30:  62%|██████▏   | 101/163 [01:56<01:04,  1.04s/it, loss=0.3444, batch_acc=0.9062, running_acc=0.9694, grad=23.5826]Training epoch 30:  62%|██████▏   | 101/163 [01:56<01:04,  1.04s/it, loss=0.2206, batch_acc=1.0000, running_acc=0.9697, grad=18.3735]Training epoch 30:  63%|██████▎   | 102/163 [01:57<01:00,  1.01it/s, loss=0.2206, batch_acc=1.0000, running_acc=0.9697, grad=18.3735]Training epoch 30:  63%|██████▎   | 102/163 [01:57<01:00,  1.01it/s, loss=0.2036, batch_acc=1.0000, running_acc=0.9700, grad=15.0648]Training epoch 30:  63%|██████▎   | 103/163 [01:58<00:57,  1.04it/s, loss=0.2036, batch_acc=1.0000, running_acc=0.9700, grad=15.0648]Training epoch 30:  63%|██████▎   | 103/163 [01:58<00:57,  1.04it/s, loss=0.2348, batch_acc=1.0000, running_acc=0.9703, grad=22.5260]Training epoch 30:  64%|██████▍   | 104/163 [02:00<01:16,  1.30s/it, loss=0.2348, batch_acc=1.0000, running_acc=0.9703, grad=22.5260]Training epoch 30:  64%|██████▍   | 104/163 [02:00<01:16,  1.30s/it, loss=0.2558, batch_acc=1.0000, running_acc=0.9706, grad=16.1328]Training epoch 30:  64%|██████▍   | 105/163 [02:01<01:08,  1.18s/it, loss=0.2558, batch_acc=1.0000, running_acc=0.9706, grad=16.1328]Training epoch 30:  64%|██████▍   | 105/163 [02:01<01:08,  1.18s/it, loss=0.1756, batch_acc=0.9688, running_acc=0.9705, grad=17.6287]Training epoch 30:  65%|██████▌   | 106/163 [02:01<01:01,  1.09s/it, loss=0.1756, batch_acc=0.9688, running_acc=0.9705, grad=17.6287]Training epoch 30:  65%|██████▌   | 106/163 [02:01<01:01,  1.09s/it, loss=0.2251, batch_acc=0.9688, running_acc=0.9705, grad=15.3726]Training epoch 30:  66%|██████▌   | 107/163 [02:02<00:57,  1.03s/it, loss=0.2251, batch_acc=0.9688, running_acc=0.9705, grad=15.3726]Training epoch 30:  66%|██████▌   | 107/163 [02:02<00:57,  1.03s/it, loss=0.2755, batch_acc=0.9688, running_acc=0.9705, grad=19.6437]Training epoch 30:  66%|██████▋   | 108/163 [02:04<01:06,  1.21s/it, loss=0.2755, batch_acc=0.9688, running_acc=0.9705, grad=19.6437]Training epoch 30:  66%|██████▋   | 108/163 [02:04<01:06,  1.21s/it, loss=0.3707, batch_acc=0.9375, running_acc=0.9702, grad=19.7077]Training epoch 30:  67%|██████▋   | 109/163 [02:05<00:59,  1.11s/it, loss=0.3707, batch_acc=0.9375, running_acc=0.9702, grad=19.7077]Training epoch 30:  67%|██████▋   | 109/163 [02:05<00:59,  1.11s/it, loss=0.2007, batch_acc=1.0000, running_acc=0.9705, grad=13.2330]Training epoch 30:  67%|██████▋   | 110/163 [02:06<00:55,  1.04s/it, loss=0.2007, batch_acc=1.0000, running_acc=0.9705, grad=13.2330]Training epoch 30:  67%|██████▋   | 110/163 [02:06<00:55,  1.04s/it, loss=0.2070, batch_acc=1.0000, running_acc=0.9707, grad=17.0875]Training epoch 30:  68%|██████▊   | 111/163 [02:07<00:51,  1.01it/s, loss=0.2070, batch_acc=1.0000, running_acc=0.9707, grad=17.0875]Training epoch 30:  68%|██████▊   | 111/163 [02:07<00:51,  1.01it/s, loss=0.2196, batch_acc=0.9688, running_acc=0.9707, grad=17.0923]Training epoch 30:  69%|██████▊   | 112/163 [02:08<00:55,  1.10s/it, loss=0.2196, batch_acc=0.9688, running_acc=0.9707, grad=17.0923]Training epoch 30:  69%|██████▊   | 112/163 [02:08<00:55,  1.10s/it, loss=0.2013, batch_acc=1.0000, running_acc=0.9710, grad=13.1480]Training epoch 30:  69%|██████▉   | 113/163 [02:09<00:51,  1.03s/it, loss=0.2013, batch_acc=1.0000, running_acc=0.9710, grad=13.1480]Training epoch 30:  69%|██████▉   | 113/163 [02:09<00:51,  1.03s/it, loss=0.1662, batch_acc=1.0000, running_acc=0.9712, grad=12.0649]Training epoch 30:  70%|██████▉   | 114/163 [02:10<00:48,  1.02it/s, loss=0.1662, batch_acc=1.0000, running_acc=0.9712, grad=12.0649]Training epoch 30:  70%|██████▉   | 114/163 [02:10<00:48,  1.02it/s, loss=0.1495, batch_acc=1.0000, running_acc=0.9715, grad=19.6879]Training epoch 30:  71%|███████   | 115/163 [02:11<00:45,  1.05it/s, loss=0.1495, batch_acc=1.0000, running_acc=0.9715, grad=19.6879]Training epoch 30:  71%|███████   | 115/163 [02:11<00:45,  1.05it/s, loss=0.2788, batch_acc=1.0000, running_acc=0.9717, grad=18.7341]Training epoch 30:  71%|███████   | 116/163 [02:12<00:54,  1.17s/it, loss=0.2788, batch_acc=1.0000, running_acc=0.9717, grad=18.7341]Training epoch 30:  71%|███████   | 116/163 [02:12<00:54,  1.17s/it, loss=0.1863, batch_acc=0.9688, running_acc=0.9717, grad=10.6525]Training epoch 30:  72%|███████▏  | 117/163 [02:13<00:49,  1.08s/it, loss=0.1863, batch_acc=0.9688, running_acc=0.9717, grad=10.6525]Training epoch 30:  72%|███████▏  | 117/163 [02:13<00:49,  1.08s/it, loss=0.1931, batch_acc=0.9688, running_acc=0.9717, grad=12.1976]Training epoch 30:  72%|███████▏  | 118/163 [02:14<00:45,  1.02s/it, loss=0.1931, batch_acc=0.9688, running_acc=0.9717, grad=12.1976]Training epoch 30:  72%|███████▏  | 118/163 [02:14<00:45,  1.02s/it, loss=0.2611, batch_acc=0.9688, running_acc=0.9717, grad=18.9739]Training epoch 30:  73%|███████▎  | 119/163 [02:15<00:43,  1.02it/s, loss=0.2611, batch_acc=0.9688, running_acc=0.9717, grad=18.9739]Training epoch 30:  73%|███████▎  | 119/163 [02:15<00:43,  1.02it/s, loss=0.1828, batch_acc=0.9688, running_acc=0.9716, grad=11.2433]Training epoch 30:  74%|███████▎  | 120/163 [02:16<00:43,  1.02s/it, loss=0.1828, batch_acc=0.9688, running_acc=0.9716, grad=11.2433]Training epoch 30:  74%|███████▎  | 120/163 [02:16<00:43,  1.02s/it, loss=0.2849, batch_acc=0.9375, running_acc=0.9714, grad=21.8220]Training epoch 30:  74%|███████▍  | 121/163 [02:17<00:41,  1.02it/s, loss=0.2849, batch_acc=0.9375, running_acc=0.9714, grad=21.8220]Training epoch 30:  74%|███████▍  | 121/163 [02:17<00:41,  1.02it/s, loss=0.1711, batch_acc=1.0000, running_acc=0.9716, grad=11.7737]Training epoch 30:  75%|███████▍  | 122/163 [02:18<00:38,  1.05it/s, loss=0.1711, batch_acc=1.0000, running_acc=0.9716, grad=11.7737]Training epoch 30:  75%|███████▍  | 122/163 [02:18<00:38,  1.05it/s, loss=0.2068, batch_acc=0.9688, running_acc=0.9716, grad=17.0454]Training epoch 30:  75%|███████▌  | 123/163 [02:19<00:37,  1.08it/s, loss=0.2068, batch_acc=0.9688, running_acc=0.9716, grad=17.0454]Training epoch 30:  75%|███████▌  | 123/163 [02:19<00:37,  1.08it/s, loss=0.2319, batch_acc=0.9688, running_acc=0.9715, grad=20.2765]Training epoch 30:  76%|███████▌  | 124/163 [02:20<00:44,  1.14s/it, loss=0.2319, batch_acc=0.9688, running_acc=0.9715, grad=20.2765]Training epoch 30:  76%|███████▌  | 124/163 [02:20<00:44,  1.14s/it, loss=0.2364, batch_acc=0.9375, running_acc=0.9713, grad=15.1076]Training epoch 30:  77%|███████▋  | 125/163 [02:21<00:40,  1.06s/it, loss=0.2364, batch_acc=0.9375, running_acc=0.9713, grad=15.1076]Training epoch 30:  77%|███████▋  | 125/163 [02:21<00:40,  1.06s/it, loss=0.1874, batch_acc=0.9688, running_acc=0.9712, grad=12.9864]Training epoch 30:  77%|███████▋  | 126/163 [02:22<00:37,  1.01s/it, loss=0.1874, batch_acc=0.9688, running_acc=0.9712, grad=12.9864]Training epoch 30:  77%|███████▋  | 126/163 [02:22<00:37,  1.01s/it, loss=0.1484, batch_acc=1.0000, running_acc=0.9715, grad=12.9416]Training epoch 30:  78%|███████▊  | 127/163 [02:23<00:35,  1.02it/s, loss=0.1484, batch_acc=1.0000, running_acc=0.9715, grad=12.9416]Training epoch 30:  78%|███████▊  | 127/163 [02:23<00:35,  1.02it/s, loss=0.2513, batch_acc=0.9688, running_acc=0.9715, grad=17.6390]Training epoch 30:  79%|███████▊  | 128/163 [02:25<00:41,  1.19s/it, loss=0.2513, batch_acc=0.9688, running_acc=0.9715, grad=17.6390]Training epoch 30:  79%|███████▊  | 128/163 [02:25<00:41,  1.19s/it, loss=0.2387, batch_acc=0.9375, running_acc=0.9712, grad=20.2673]Training epoch 30:  79%|███████▉  | 129/163 [02:26<00:37,  1.10s/it, loss=0.2387, batch_acc=0.9375, running_acc=0.9712, grad=20.2673]Training epoch 30:  79%|███████▉  | 129/163 [02:26<00:37,  1.10s/it, loss=0.2321, batch_acc=0.9688, running_acc=0.9712, grad=18.8531]Training epoch 30:  80%|███████▉  | 130/163 [02:26<00:34,  1.03s/it, loss=0.2321, batch_acc=0.9688, running_acc=0.9712, grad=18.8531]Training epoch 30:  80%|███████▉  | 130/163 [02:26<00:34,  1.03s/it, loss=0.3059, batch_acc=0.9062, running_acc=0.9707, grad=20.2425]Training epoch 30:  80%|████████  | 131/163 [02:27<00:31,  1.01it/s, loss=0.3059, batch_acc=0.9062, running_acc=0.9707, grad=20.2425]Training epoch 30:  80%|████████  | 131/163 [02:27<00:31,  1.01it/s, loss=0.1640, batch_acc=1.0000, running_acc=0.9709, grad=15.1428]Training epoch 30:  81%|████████  | 132/163 [02:29<00:35,  1.14s/it, loss=0.1640, batch_acc=1.0000, running_acc=0.9709, grad=15.1428]Training epoch 30:  81%|████████  | 132/163 [02:29<00:35,  1.14s/it, loss=0.1803, batch_acc=1.0000, running_acc=0.9711, grad=12.3108]Training epoch 30:  82%|████████▏ | 133/163 [02:30<00:31,  1.06s/it, loss=0.1803, batch_acc=1.0000, running_acc=0.9711, grad=12.3108]Training epoch 30:  82%|████████▏ | 133/163 [02:30<00:31,  1.06s/it, loss=0.2935, batch_acc=0.9062, running_acc=0.9706, grad=17.4804]Training epoch 30:  82%|████████▏ | 134/163 [02:31<00:29,  1.01s/it, loss=0.2935, batch_acc=0.9062, running_acc=0.9706, grad=17.4804]Training epoch 30:  82%|████████▏ | 134/163 [02:31<00:29,  1.01s/it, loss=0.2666, batch_acc=0.9375, running_acc=0.9704, grad=17.6554]Training epoch 30:  83%|████████▎ | 135/163 [02:32<00:28,  1.00s/it, loss=0.2666, batch_acc=0.9375, running_acc=0.9704, grad=17.6554]Training epoch 30:  83%|████████▎ | 135/163 [02:32<00:28,  1.00s/it, loss=0.1794, batch_acc=1.0000, running_acc=0.9706, grad=13.9273]Training epoch 30:  83%|████████▎ | 136/163 [02:34<00:35,  1.31s/it, loss=0.1794, batch_acc=1.0000, running_acc=0.9706, grad=13.9273]Training epoch 30:  83%|████████▎ | 136/163 [02:34<00:35,  1.31s/it, loss=0.2983, batch_acc=0.9375, running_acc=0.9704, grad=21.6221]Training epoch 30:  84%|████████▍ | 137/163 [02:34<00:30,  1.18s/it, loss=0.2983, batch_acc=0.9375, running_acc=0.9704, grad=21.6221]Training epoch 30:  84%|████████▍ | 137/163 [02:34<00:30,  1.18s/it, loss=0.2468, batch_acc=0.9688, running_acc=0.9703, grad=16.5046]Training epoch 30:  85%|████████▍ | 138/163 [02:35<00:27,  1.09s/it, loss=0.2468, batch_acc=0.9688, running_acc=0.9703, grad=16.5046]Training epoch 30:  85%|████████▍ | 138/163 [02:35<00:27,  1.09s/it, loss=0.2745, batch_acc=0.9375, running_acc=0.9701, grad=20.5578]Training epoch 30:  85%|████████▌ | 139/163 [02:36<00:24,  1.03s/it, loss=0.2745, batch_acc=0.9375, running_acc=0.9701, grad=20.5578]Training epoch 30:  85%|████████▌ | 139/163 [02:36<00:24,  1.03s/it, loss=0.3332, batch_acc=0.9062, running_acc=0.9696, grad=22.9720]Training epoch 30:  86%|████████▌ | 140/163 [02:38<00:31,  1.39s/it, loss=0.3332, batch_acc=0.9062, running_acc=0.9696, grad=22.9720]Training epoch 30:  86%|████████▌ | 140/163 [02:38<00:31,  1.39s/it, loss=0.2557, batch_acc=0.9688, running_acc=0.9696, grad=18.4666]Training epoch 30:  87%|████████▋ | 141/163 [02:39<00:27,  1.24s/it, loss=0.2557, batch_acc=0.9688, running_acc=0.9696, grad=18.4666]Training epoch 30:  87%|████████▋ | 141/163 [02:39<00:27,  1.24s/it, loss=0.2452, batch_acc=0.9375, running_acc=0.9694, grad=16.3378]Training epoch 30:  87%|████████▋ | 142/163 [02:40<00:23,  1.13s/it, loss=0.2452, batch_acc=0.9375, running_acc=0.9694, grad=16.3378]Training epoch 30:  87%|████████▋ | 142/163 [02:40<00:23,  1.13s/it, loss=0.2126, batch_acc=1.0000, running_acc=0.9696, grad=14.3564]Training epoch 30:  88%|████████▊ | 143/163 [02:41<00:21,  1.06s/it, loss=0.2126, batch_acc=1.0000, running_acc=0.9696, grad=14.3564]Training epoch 30:  88%|████████▊ | 143/163 [02:41<00:21,  1.06s/it, loss=0.2226, batch_acc=1.0000, running_acc=0.9698, grad=15.6840]Training epoch 30:  88%|████████▊ | 144/163 [02:43<00:25,  1.32s/it, loss=0.2226, batch_acc=1.0000, running_acc=0.9698, grad=15.6840]Training epoch 30:  88%|████████▊ | 144/163 [02:43<00:25,  1.32s/it, loss=0.3237, batch_acc=0.9688, running_acc=0.9698, grad=23.0302]Training epoch 30:  89%|████████▉ | 145/163 [02:44<00:21,  1.19s/it, loss=0.3237, batch_acc=0.9688, running_acc=0.9698, grad=23.0302]Training epoch 30:  89%|████████▉ | 145/163 [02:44<00:21,  1.19s/it, loss=0.2545, batch_acc=0.9375, running_acc=0.9696, grad=15.8328]Training epoch 30:  90%|████████▉ | 146/163 [02:45<00:18,  1.09s/it, loss=0.2545, batch_acc=0.9375, running_acc=0.9696, grad=15.8328]Training epoch 30:  90%|████████▉ | 146/163 [02:45<00:18,  1.09s/it, loss=0.3483, batch_acc=0.9375, running_acc=0.9694, grad=19.6498]Training epoch 30:  90%|█████████ | 147/163 [02:46<00:16,  1.03s/it, loss=0.3483, batch_acc=0.9375, running_acc=0.9694, grad=19.6498]Training epoch 30:  90%|█████████ | 147/163 [02:46<00:16,  1.03s/it, loss=0.2109, batch_acc=1.0000, running_acc=0.9696, grad=17.2192]Training epoch 30:  91%|█████████ | 148/163 [02:47<00:18,  1.21s/it, loss=0.2109, batch_acc=1.0000, running_acc=0.9696, grad=17.2192]Training epoch 30:  91%|█████████ | 148/163 [02:47<00:18,  1.21s/it, loss=0.1706, batch_acc=0.9688, running_acc=0.9696, grad=13.7739]Training epoch 30:  91%|█████████▏| 149/163 [02:48<00:15,  1.11s/it, loss=0.1706, batch_acc=0.9688, running_acc=0.9696, grad=13.7739]Training epoch 30:  91%|█████████▏| 149/163 [02:48<00:15,  1.11s/it, loss=0.3578, batch_acc=0.9375, running_acc=0.9694, grad=22.9340]Training epoch 30:  92%|█████████▏| 150/163 [02:49<00:13,  1.04s/it, loss=0.3578, batch_acc=0.9375, running_acc=0.9694, grad=22.9340]Training epoch 30:  92%|█████████▏| 150/163 [02:49<00:13,  1.04s/it, loss=0.3120, batch_acc=0.9375, running_acc=0.9692, grad=20.3833]Training epoch 30:  93%|█████████▎| 151/163 [02:50<00:11,  1.01it/s, loss=0.3120, batch_acc=0.9375, running_acc=0.9692, grad=20.3833]Training epoch 30:  93%|█████████▎| 151/163 [02:50<00:11,  1.01it/s, loss=0.1989, batch_acc=1.0000, running_acc=0.9694, grad=17.8621]Training epoch 30:  93%|█████████▎| 152/163 [02:51<00:12,  1.16s/it, loss=0.1989, batch_acc=1.0000, running_acc=0.9694, grad=17.8621]Training epoch 30:  93%|█████████▎| 152/163 [02:51<00:12,  1.16s/it, loss=0.2251, batch_acc=1.0000, running_acc=0.9696, grad=16.7358]Training epoch 30:  94%|█████████▍| 153/163 [02:52<00:10,  1.07s/it, loss=0.2251, batch_acc=1.0000, running_acc=0.9696, grad=16.7358]Training epoch 30:  94%|█████████▍| 153/163 [02:52<00:10,  1.07s/it, loss=0.2915, batch_acc=0.9688, running_acc=0.9696, grad=19.6125]Training epoch 30:  94%|█████████▍| 154/163 [02:53<00:09,  1.02s/it, loss=0.2915, batch_acc=0.9688, running_acc=0.9696, grad=19.6125]Training epoch 30:  94%|█████████▍| 154/163 [02:53<00:09,  1.02s/it, loss=0.2356, batch_acc=0.9688, running_acc=0.9696, grad=22.6509]Training epoch 30:  95%|█████████▌| 155/163 [02:54<00:07,  1.02it/s, loss=0.2356, batch_acc=0.9688, running_acc=0.9696, grad=22.6509]Training epoch 30:  95%|█████████▌| 155/163 [02:54<00:07,  1.02it/s, loss=0.2471, batch_acc=1.0000, running_acc=0.9698, grad=17.1691]Training epoch 30:  96%|█████████▌| 156/163 [02:56<00:08,  1.15s/it, loss=0.2471, batch_acc=1.0000, running_acc=0.9698, grad=17.1691]Training epoch 30:  96%|█████████▌| 156/163 [02:56<00:08,  1.15s/it, loss=0.2318, batch_acc=1.0000, running_acc=0.9700, grad=16.8250]Training epoch 30:  96%|█████████▋| 157/163 [02:57<00:06,  1.07s/it, loss=0.2318, batch_acc=1.0000, running_acc=0.9700, grad=16.8250]Training epoch 30:  96%|█████████▋| 157/163 [02:57<00:06,  1.07s/it, loss=0.1542, batch_acc=1.0000, running_acc=0.9701, grad=9.1296] Training epoch 30:  97%|█████████▋| 158/163 [02:57<00:05,  1.01s/it, loss=0.1542, batch_acc=1.0000, running_acc=0.9701, grad=9.1296]Training epoch 30:  97%|█████████▋| 158/163 [02:57<00:05,  1.01s/it, loss=0.1833, batch_acc=1.0000, running_acc=0.9703, grad=15.2385]Training epoch 30:  98%|█████████▊| 159/163 [02:58<00:03,  1.03it/s, loss=0.1833, batch_acc=1.0000, running_acc=0.9703, grad=15.2385]Training epoch 30:  98%|█████████▊| 159/163 [02:58<00:03,  1.03it/s, loss=0.2227, batch_acc=1.0000, running_acc=0.9705, grad=12.6788]Training epoch 30:  98%|█████████▊| 160/163 [02:59<00:02,  1.06it/s, loss=0.2227, batch_acc=1.0000, running_acc=0.9705, grad=12.6788]Training epoch 30:  98%|█████████▊| 160/163 [02:59<00:02,  1.06it/s, loss=0.2946, batch_acc=0.9688, running_acc=0.9705, grad=16.9205]Training epoch 30:  99%|█████████▉| 161/163 [03:00<00:01,  1.08it/s, loss=0.2946, batch_acc=0.9688, running_acc=0.9705, grad=16.9205]Training epoch 30:  99%|█████████▉| 161/163 [03:00<00:01,  1.08it/s, loss=0.2657, batch_acc=0.9375, running_acc=0.9703, grad=15.1114]Training epoch 30:  99%|█████████▉| 162/163 [03:01<00:00,  1.10it/s, loss=0.2657, batch_acc=0.9375, running_acc=0.9703, grad=15.1114]Training epoch 30:  99%|█████████▉| 162/163 [03:01<00:00,  1.10it/s, loss=0.1834, batch_acc=1.0000, running_acc=0.9705, grad=12.2847]Training epoch 30: 100%|██████████| 163/163 [03:02<00:00,  1.20it/s, loss=0.1834, batch_acc=1.0000, running_acc=0.9705, grad=12.2847]Training epoch 30: 100%|██████████| 163/163 [03:02<00:00,  1.20it/s, loss=0.2829, batch_acc=0.9524, running_acc=0.9704, grad=25.8626]Training epoch 30: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.2829, batch_acc=0.9524, running_acc=0.9704, grad=25.8626]
Evaluation epoch 30:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 30:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it]Evaluation epoch 30:   4%|▎         | 1/28 [00:04<02:13,  4.94s/it, loss=0.3886, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 30:   7%|▋         | 2/28 [00:05<00:58,  2.25s/it, loss=0.3886, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 30:   7%|▋         | 2/28 [00:05<00:58,  2.25s/it, loss=0.4000, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 30:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.4000, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 30:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.4157, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 30:  14%|█▍        | 4/28 [00:09<00:58,  2.44s/it, loss=0.4157, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 30:  14%|█▍        | 4/28 [00:09<00:58,  2.44s/it, loss=0.5147, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 30:  18%|█▊        | 5/28 [00:09<00:38,  1.65s/it, loss=0.5147, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 30:  18%|█▊        | 5/28 [00:09<00:38,  1.65s/it, loss=1.3228, batch_acc=0.7188, running_acc=0.8938]Evaluation epoch 30:  21%|██▏       | 6/28 [00:10<00:25,  1.18s/it, loss=1.3228, batch_acc=0.7188, running_acc=0.8938]Evaluation epoch 30:  21%|██▏       | 6/28 [00:10<00:25,  1.18s/it, loss=0.5528, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 30:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=0.5528, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 30:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=0.6637, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 30:  29%|██▊       | 8/28 [00:13<00:32,  1.63s/it, loss=0.6637, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 30:  29%|██▊       | 8/28 [00:13<00:32,  1.63s/it, loss=0.4718, batch_acc=0.8750, running_acc=0.8906]Evaluation epoch 30:  32%|███▏      | 9/28 [00:14<00:28,  1.49s/it, loss=0.4718, batch_acc=0.8750, running_acc=0.8906]Evaluation epoch 30:  32%|███▏      | 9/28 [00:14<00:28,  1.49s/it, loss=0.5908, batch_acc=0.9062, running_acc=0.8924]Evaluation epoch 30:  36%|███▌      | 10/28 [00:15<00:19,  1.11s/it, loss=0.5908, batch_acc=0.9062, running_acc=0.8924]Evaluation epoch 30:  36%|███▌      | 10/28 [00:15<00:19,  1.11s/it, loss=0.5869, batch_acc=0.8750, running_acc=0.8906]Evaluation epoch 30:  39%|███▉      | 11/28 [00:15<00:14,  1.18it/s, loss=0.5869, batch_acc=0.8750, running_acc=0.8906]Evaluation epoch 30:  39%|███▉      | 11/28 [00:15<00:14,  1.18it/s, loss=0.4830, batch_acc=0.8750, running_acc=0.8892]Evaluation epoch 30:  43%|████▎     | 12/28 [00:19<00:31,  1.98s/it, loss=0.4830, batch_acc=0.8750, running_acc=0.8892]Evaluation epoch 30:  43%|████▎     | 12/28 [00:19<00:31,  1.98s/it, loss=1.1673, batch_acc=0.7812, running_acc=0.8802]Evaluation epoch 30:  46%|████▋     | 13/28 [00:20<00:21,  1.46s/it, loss=1.1673, batch_acc=0.7812, running_acc=0.8802]Evaluation epoch 30:  46%|████▋     | 13/28 [00:20<00:21,  1.46s/it, loss=0.3894, batch_acc=0.9375, running_acc=0.8846]Evaluation epoch 30:  50%|█████     | 14/28 [00:20<00:15,  1.09s/it, loss=0.3894, batch_acc=0.9375, running_acc=0.8846]Evaluation epoch 30:  50%|█████     | 14/28 [00:20<00:15,  1.09s/it, loss=1.0024, batch_acc=0.7500, running_acc=0.8750]Evaluation epoch 30:  54%|█████▎    | 15/28 [00:20<00:10,  1.18it/s, loss=1.0024, batch_acc=0.7500, running_acc=0.8750]Evaluation epoch 30:  54%|█████▎    | 15/28 [00:20<00:10,  1.18it/s, loss=1.0756, batch_acc=0.7188, running_acc=0.8646]Evaluation epoch 30:  57%|█████▋    | 16/28 [00:23<00:16,  1.40s/it, loss=1.0756, batch_acc=0.7188, running_acc=0.8646]Evaluation epoch 30:  57%|█████▋    | 16/28 [00:23<00:16,  1.40s/it, loss=0.7363, batch_acc=0.8125, running_acc=0.8613]Evaluation epoch 30:  61%|██████    | 17/28 [00:23<00:11,  1.05s/it, loss=0.7363, batch_acc=0.8125, running_acc=0.8613]Evaluation epoch 30:  61%|██████    | 17/28 [00:23<00:11,  1.05s/it, loss=0.5529, batch_acc=0.8438, running_acc=0.8603]Evaluation epoch 30:  64%|██████▍   | 18/28 [00:23<00:08,  1.22it/s, loss=0.5529, batch_acc=0.8438, running_acc=0.8603]Evaluation epoch 30:  64%|██████▍   | 18/28 [00:23<00:08,  1.22it/s, loss=0.6345, batch_acc=0.8125, running_acc=0.8576]Evaluation epoch 30:  68%|██████▊   | 19/28 [00:24<00:05,  1.54it/s, loss=0.6345, batch_acc=0.8125, running_acc=0.8576]Evaluation epoch 30:  68%|██████▊   | 19/28 [00:24<00:05,  1.54it/s, loss=0.9597, batch_acc=0.6562, running_acc=0.8470]Evaluation epoch 30:  71%|███████▏  | 20/28 [00:26<00:09,  1.24s/it, loss=0.9597, batch_acc=0.6562, running_acc=0.8470]Evaluation epoch 30:  71%|███████▏  | 20/28 [00:26<00:09,  1.24s/it, loss=0.7253, batch_acc=0.6875, running_acc=0.8391]Evaluation epoch 30:  75%|███████▌  | 21/28 [00:27<00:06,  1.06it/s, loss=0.7253, batch_acc=0.6875, running_acc=0.8391]Evaluation epoch 30:  75%|███████▌  | 21/28 [00:27<00:06,  1.06it/s, loss=0.6627, batch_acc=0.8438, running_acc=0.8393]Evaluation epoch 30:  79%|███████▊  | 22/28 [00:27<00:04,  1.35it/s, loss=0.6627, batch_acc=0.8438, running_acc=0.8393]Evaluation epoch 30:  79%|███████▊  | 22/28 [00:27<00:04,  1.35it/s, loss=0.6969, batch_acc=0.8438, running_acc=0.8395]Evaluation epoch 30:  82%|████████▏ | 23/28 [00:27<00:02,  1.68it/s, loss=0.6969, batch_acc=0.8438, running_acc=0.8395]Evaluation epoch 30:  82%|████████▏ | 23/28 [00:27<00:02,  1.68it/s, loss=1.0143, batch_acc=0.6875, running_acc=0.8329]Evaluation epoch 30:  86%|████████▌ | 24/28 [00:32<00:07,  1.93s/it, loss=1.0143, batch_acc=0.6875, running_acc=0.8329]Evaluation epoch 30:  86%|████████▌ | 24/28 [00:32<00:07,  1.93s/it, loss=0.3596, batch_acc=0.9375, running_acc=0.8372]Evaluation epoch 30:  89%|████████▉ | 25/28 [00:32<00:04,  1.43s/it, loss=0.3596, batch_acc=0.9375, running_acc=0.8372]Evaluation epoch 30:  89%|████████▉ | 25/28 [00:32<00:04,  1.43s/it, loss=0.1921, batch_acc=1.0000, running_acc=0.8438]Evaluation epoch 30:  93%|█████████▎| 26/28 [00:33<00:02,  1.08s/it, loss=0.1921, batch_acc=1.0000, running_acc=0.8438]Evaluation epoch 30:  93%|█████████▎| 26/28 [00:33<00:02,  1.08s/it, loss=0.6701, batch_acc=0.7812, running_acc=0.8413]Evaluation epoch 30:  96%|█████████▋| 27/28 [00:33<00:00,  1.20it/s, loss=0.6701, batch_acc=0.7812, running_acc=0.8413]Evaluation epoch 30:  96%|█████████▋| 27/28 [00:33<00:00,  1.20it/s, loss=0.9218, batch_acc=0.7500, running_acc=0.8380]Evaluation epoch 30: 100%|██████████| 28/28 [00:33<00:00,  1.20it/s, loss=1.4601, batch_acc=0.6667, running_acc=0.8374]Evaluation epoch 30: 100%|██████████| 28/28 [00:33<00:00,  1.20s/it, loss=1.4601, batch_acc=0.6667, running_acc=0.8374]
Training epoch 31:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 31:   1%|          | 1/163 [00:05<15:02,  5.57s/it]Training epoch 31:   1%|          | 1/163 [00:05<15:02,  5.57s/it, loss=0.1495, batch_acc=1.0000, running_acc=1.0000, grad=12.7351]Training epoch 31:   1%|          | 2/163 [00:06<07:32,  2.81s/it, loss=0.1495, batch_acc=1.0000, running_acc=1.0000, grad=12.7351]Training epoch 31:   1%|          | 2/163 [00:06<07:32,  2.81s/it, loss=0.1559, batch_acc=1.0000, running_acc=1.0000, grad=11.6312]Training epoch 31:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=0.1559, batch_acc=1.0000, running_acc=1.0000, grad=11.6312]Training epoch 31:   2%|▏         | 3/163 [00:07<05:18,  1.99s/it, loss=0.2358, batch_acc=0.9688, running_acc=0.9896, grad=10.8191]Training epoch 31:   2%|▏         | 4/163 [00:09<05:22,  2.03s/it, loss=0.2358, batch_acc=0.9688, running_acc=0.9896, grad=10.8191]Training epoch 31:   2%|▏         | 4/163 [00:09<05:22,  2.03s/it, loss=0.2285, batch_acc=0.9688, running_acc=0.9844, grad=13.3823]Training epoch 31:   3%|▎         | 5/163 [00:10<04:19,  1.64s/it, loss=0.2285, batch_acc=0.9688, running_acc=0.9844, grad=13.3823]Training epoch 31:   3%|▎         | 5/163 [00:10<04:19,  1.64s/it, loss=0.1417, batch_acc=1.0000, running_acc=0.9875, grad=11.1986]Training epoch 31:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=0.1417, batch_acc=1.0000, running_acc=0.9875, grad=11.1986]Training epoch 31:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=0.1927, batch_acc=0.9688, running_acc=0.9844, grad=12.2887]Training epoch 31:   4%|▍         | 7/163 [00:12<03:09,  1.22s/it, loss=0.1927, batch_acc=0.9688, running_acc=0.9844, grad=12.2887]Training epoch 31:   4%|▍         | 7/163 [00:12<03:09,  1.22s/it, loss=0.2052, batch_acc=0.9375, running_acc=0.9777, grad=13.8662]Training epoch 31:   5%|▍         | 8/163 [00:14<03:38,  1.41s/it, loss=0.2052, batch_acc=0.9375, running_acc=0.9777, grad=13.8662]Training epoch 31:   5%|▍         | 8/163 [00:14<03:38,  1.41s/it, loss=0.2261, batch_acc=0.9688, running_acc=0.9766, grad=20.2528]Training epoch 31:   6%|▌         | 9/163 [00:14<03:11,  1.25s/it, loss=0.2261, batch_acc=0.9688, running_acc=0.9766, grad=20.2528]Training epoch 31:   6%|▌         | 9/163 [00:14<03:11,  1.25s/it, loss=0.1682, batch_acc=1.0000, running_acc=0.9792, grad=11.9342]Training epoch 31:   6%|▌         | 10/163 [00:15<02:53,  1.13s/it, loss=0.1682, batch_acc=1.0000, running_acc=0.9792, grad=11.9342]Training epoch 31:   6%|▌         | 10/163 [00:15<02:53,  1.13s/it, loss=0.1547, batch_acc=1.0000, running_acc=0.9812, grad=10.6556]Training epoch 31:   7%|▋         | 11/163 [00:16<02:42,  1.07s/it, loss=0.1547, batch_acc=1.0000, running_acc=0.9812, grad=10.6556]Training epoch 31:   7%|▋         | 11/163 [00:16<02:42,  1.07s/it, loss=0.2793, batch_acc=0.9688, running_acc=0.9801, grad=20.3332]Training epoch 31:   7%|▋         | 12/163 [00:18<03:25,  1.36s/it, loss=0.2793, batch_acc=0.9688, running_acc=0.9801, grad=20.3332]Training epoch 31:   7%|▋         | 12/163 [00:18<03:25,  1.36s/it, loss=0.1462, batch_acc=1.0000, running_acc=0.9818, grad=10.1196]Training epoch 31:   8%|▊         | 13/163 [00:19<03:01,  1.21s/it, loss=0.1462, batch_acc=1.0000, running_acc=0.9818, grad=10.1196]Training epoch 31:   8%|▊         | 13/163 [00:19<03:01,  1.21s/it, loss=0.2723, batch_acc=0.9375, running_acc=0.9784, grad=16.6014]Training epoch 31:   9%|▊         | 14/163 [00:20<02:45,  1.11s/it, loss=0.2723, batch_acc=0.9375, running_acc=0.9784, grad=16.6014]Training epoch 31:   9%|▊         | 14/163 [00:20<02:45,  1.11s/it, loss=0.2164, batch_acc=1.0000, running_acc=0.9799, grad=18.5531]Training epoch 31:   9%|▉         | 15/163 [00:21<02:34,  1.04s/it, loss=0.2164, batch_acc=1.0000, running_acc=0.9799, grad=18.5531]Training epoch 31:   9%|▉         | 15/163 [00:21<02:34,  1.04s/it, loss=0.2703, batch_acc=0.9062, running_acc=0.9750, grad=12.5788]Training epoch 31:  10%|▉         | 16/163 [00:23<02:57,  1.21s/it, loss=0.2703, batch_acc=0.9062, running_acc=0.9750, grad=12.5788]Training epoch 31:  10%|▉         | 16/163 [00:23<02:57,  1.21s/it, loss=0.1807, batch_acc=0.9688, running_acc=0.9746, grad=9.9558] Training epoch 31:  10%|█         | 17/163 [00:23<02:42,  1.11s/it, loss=0.1807, batch_acc=0.9688, running_acc=0.9746, grad=9.9558]Training epoch 31:  10%|█         | 17/163 [00:23<02:42,  1.11s/it, loss=0.2489, batch_acc=0.9375, running_acc=0.9724, grad=13.8346]Training epoch 31:  11%|█         | 18/163 [00:24<02:31,  1.04s/it, loss=0.2489, batch_acc=0.9375, running_acc=0.9724, grad=13.8346]Training epoch 31:  11%|█         | 18/163 [00:24<02:31,  1.04s/it, loss=0.1938, batch_acc=0.9688, running_acc=0.9722, grad=15.1550]Training epoch 31:  12%|█▏        | 19/163 [00:25<02:23,  1.01it/s, loss=0.1938, batch_acc=0.9688, running_acc=0.9722, grad=15.1550]Training epoch 31:  12%|█▏        | 19/163 [00:25<02:23,  1.01it/s, loss=0.2141, batch_acc=1.0000, running_acc=0.9737, grad=18.6503]Training epoch 31:  12%|█▏        | 20/163 [00:27<02:37,  1.10s/it, loss=0.2141, batch_acc=1.0000, running_acc=0.9737, grad=18.6503]Training epoch 31:  12%|█▏        | 20/163 [00:27<02:37,  1.10s/it, loss=0.2247, batch_acc=0.9688, running_acc=0.9734, grad=14.6710]Training epoch 31:  13%|█▎        | 21/163 [00:27<02:27,  1.04s/it, loss=0.2247, batch_acc=0.9688, running_acc=0.9734, grad=14.6710]Training epoch 31:  13%|█▎        | 21/163 [00:27<02:27,  1.04s/it, loss=0.2728, batch_acc=0.9375, running_acc=0.9717, grad=19.8923]Training epoch 31:  13%|█▎        | 22/163 [00:28<02:22,  1.01s/it, loss=0.2728, batch_acc=0.9375, running_acc=0.9717, grad=19.8923]Training epoch 31:  13%|█▎        | 22/163 [00:28<02:22,  1.01s/it, loss=0.2216, batch_acc=0.9688, running_acc=0.9716, grad=12.5816]Training epoch 31:  14%|█▍        | 23/163 [00:29<02:15,  1.03it/s, loss=0.2216, batch_acc=0.9688, running_acc=0.9716, grad=12.5816]Training epoch 31:  14%|█▍        | 23/163 [00:29<02:15,  1.03it/s, loss=0.1594, batch_acc=1.0000, running_acc=0.9728, grad=10.1767]Training epoch 31:  15%|█▍        | 24/163 [00:30<02:19,  1.00s/it, loss=0.1594, batch_acc=1.0000, running_acc=0.9728, grad=10.1767]Training epoch 31:  15%|█▍        | 24/163 [00:30<02:19,  1.00s/it, loss=0.2600, batch_acc=0.9375, running_acc=0.9714, grad=14.1145]Training epoch 31:  15%|█▌        | 25/163 [00:31<02:13,  1.03it/s, loss=0.2600, batch_acc=0.9375, running_acc=0.9714, grad=14.1145]Training epoch 31:  15%|█▌        | 25/163 [00:31<02:13,  1.03it/s, loss=0.2748, batch_acc=0.9375, running_acc=0.9700, grad=19.1343]Training epoch 31:  16%|█▌        | 26/163 [00:33<02:42,  1.19s/it, loss=0.2748, batch_acc=0.9375, running_acc=0.9700, grad=19.1343]Training epoch 31:  16%|█▌        | 26/163 [00:33<02:42,  1.19s/it, loss=0.1888, batch_acc=0.9375, running_acc=0.9688, grad=12.1903]Training epoch 31:  17%|█▋        | 27/163 [00:34<02:28,  1.10s/it, loss=0.1888, batch_acc=0.9375, running_acc=0.9688, grad=12.1903]Training epoch 31:  17%|█▋        | 27/163 [00:34<02:28,  1.10s/it, loss=0.2034, batch_acc=1.0000, running_acc=0.9699, grad=14.3464]Training epoch 31:  17%|█▋        | 28/163 [00:35<02:19,  1.03s/it, loss=0.2034, batch_acc=1.0000, running_acc=0.9699, grad=14.3464]Training epoch 31:  17%|█▋        | 28/163 [00:35<02:19,  1.03s/it, loss=0.1611, batch_acc=1.0000, running_acc=0.9710, grad=10.4426]Training epoch 31:  18%|█▊        | 29/163 [00:36<02:12,  1.01it/s, loss=0.1611, batch_acc=1.0000, running_acc=0.9710, grad=10.4426]Training epoch 31:  18%|█▊        | 29/163 [00:36<02:12,  1.01it/s, loss=0.2751, batch_acc=0.9688, running_acc=0.9709, grad=17.0331]Training epoch 31:  18%|█▊        | 30/163 [00:38<03:05,  1.39s/it, loss=0.2751, batch_acc=0.9688, running_acc=0.9709, grad=17.0331]Training epoch 31:  18%|█▊        | 30/163 [00:38<03:05,  1.39s/it, loss=0.2103, batch_acc=1.0000, running_acc=0.9719, grad=15.1395]Training epoch 31:  19%|█▉        | 31/163 [00:39<02:43,  1.24s/it, loss=0.2103, batch_acc=1.0000, running_acc=0.9719, grad=15.1395]Training epoch 31:  19%|█▉        | 31/163 [00:39<02:43,  1.24s/it, loss=0.3255, batch_acc=0.9375, running_acc=0.9708, grad=18.6618]Training epoch 31:  20%|█▉        | 32/163 [00:40<02:28,  1.13s/it, loss=0.3255, batch_acc=0.9375, running_acc=0.9708, grad=18.6618]Training epoch 31:  20%|█▉        | 32/163 [00:40<02:28,  1.13s/it, loss=0.2494, batch_acc=0.9375, running_acc=0.9697, grad=21.9018]Training epoch 31:  20%|██        | 33/163 [00:41<02:17,  1.06s/it, loss=0.2494, batch_acc=0.9375, running_acc=0.9697, grad=21.9018]Training epoch 31:  20%|██        | 33/163 [00:41<02:17,  1.06s/it, loss=0.1979, batch_acc=0.9688, running_acc=0.9697, grad=10.5917]Training epoch 31:  21%|██        | 34/163 [00:42<02:30,  1.17s/it, loss=0.1979, batch_acc=0.9688, running_acc=0.9697, grad=10.5917]Training epoch 31:  21%|██        | 34/163 [00:42<02:30,  1.17s/it, loss=0.1873, batch_acc=0.9688, running_acc=0.9697, grad=10.5470]Training epoch 31:  21%|██▏       | 35/163 [00:43<02:18,  1.08s/it, loss=0.1873, batch_acc=0.9688, running_acc=0.9697, grad=10.5470]Training epoch 31:  21%|██▏       | 35/163 [00:43<02:18,  1.08s/it, loss=0.1699, batch_acc=1.0000, running_acc=0.9705, grad=18.2779]Training epoch 31:  22%|██▏       | 36/163 [00:44<02:09,  1.02s/it, loss=0.1699, batch_acc=1.0000, running_acc=0.9705, grad=18.2779]Training epoch 31:  22%|██▏       | 36/163 [00:44<02:09,  1.02s/it, loss=0.2287, batch_acc=1.0000, running_acc=0.9714, grad=16.1818]Training epoch 31:  23%|██▎       | 37/163 [00:45<02:03,  1.02it/s, loss=0.2287, batch_acc=1.0000, running_acc=0.9714, grad=16.1818]Training epoch 31:  23%|██▎       | 37/163 [00:45<02:03,  1.02it/s, loss=0.1703, batch_acc=1.0000, running_acc=0.9721, grad=13.1173]Training epoch 31:  23%|██▎       | 38/163 [00:46<02:33,  1.22s/it, loss=0.1703, batch_acc=1.0000, running_acc=0.9721, grad=13.1173]Training epoch 31:  23%|██▎       | 38/163 [00:46<02:33,  1.22s/it, loss=0.2947, batch_acc=0.9688, running_acc=0.9720, grad=18.4084]Training epoch 31:  24%|██▍       | 39/163 [00:47<02:19,  1.12s/it, loss=0.2947, batch_acc=0.9688, running_acc=0.9720, grad=18.4084]Training epoch 31:  24%|██▍       | 39/163 [00:47<02:19,  1.12s/it, loss=0.2965, batch_acc=0.9688, running_acc=0.9720, grad=21.1009]Training epoch 31:  25%|██▍       | 40/163 [00:48<02:09,  1.05s/it, loss=0.2965, batch_acc=0.9688, running_acc=0.9720, grad=21.1009]Training epoch 31:  25%|██▍       | 40/163 [00:48<02:09,  1.05s/it, loss=0.1538, batch_acc=1.0000, running_acc=0.9727, grad=16.6028]Training epoch 31:  25%|██▌       | 41/163 [00:49<02:03,  1.01s/it, loss=0.1538, batch_acc=1.0000, running_acc=0.9727, grad=16.6028]Training epoch 31:  25%|██▌       | 41/163 [00:49<02:03,  1.01s/it, loss=0.2168, batch_acc=1.0000, running_acc=0.9733, grad=18.2676]Training epoch 31:  26%|██▌       | 42/163 [00:51<02:31,  1.25s/it, loss=0.2168, batch_acc=1.0000, running_acc=0.9733, grad=18.2676]Training epoch 31:  26%|██▌       | 42/163 [00:51<02:31,  1.25s/it, loss=0.2663, batch_acc=0.9375, running_acc=0.9725, grad=17.3925]Training epoch 31:  26%|██▋       | 43/163 [00:52<02:16,  1.14s/it, loss=0.2663, batch_acc=0.9375, running_acc=0.9725, grad=17.3925]Training epoch 31:  26%|██▋       | 43/163 [00:52<02:16,  1.14s/it, loss=0.1860, batch_acc=1.0000, running_acc=0.9731, grad=13.6171]Training epoch 31:  27%|██▋       | 44/163 [00:53<02:06,  1.06s/it, loss=0.1860, batch_acc=1.0000, running_acc=0.9731, grad=13.6171]Training epoch 31:  27%|██▋       | 44/163 [00:53<02:06,  1.06s/it, loss=0.3202, batch_acc=1.0000, running_acc=0.9737, grad=17.3594]Training epoch 31:  28%|██▊       | 45/163 [00:54<01:58,  1.01s/it, loss=0.3202, batch_acc=1.0000, running_acc=0.9737, grad=17.3594]Training epoch 31:  28%|██▊       | 45/163 [00:54<01:58,  1.01s/it, loss=0.2089, batch_acc=0.9688, running_acc=0.9736, grad=19.0189]Training epoch 31:  28%|██▊       | 46/163 [00:55<02:15,  1.16s/it, loss=0.2089, batch_acc=0.9688, running_acc=0.9736, grad=19.0189]Training epoch 31:  28%|██▊       | 46/163 [00:55<02:15,  1.16s/it, loss=0.2490, batch_acc=1.0000, running_acc=0.9742, grad=11.5380]Training epoch 31:  29%|██▉       | 47/163 [00:56<02:04,  1.08s/it, loss=0.2490, batch_acc=1.0000, running_acc=0.9742, grad=11.5380]Training epoch 31:  29%|██▉       | 47/163 [00:56<02:04,  1.08s/it, loss=0.1614, batch_acc=1.0000, running_acc=0.9747, grad=12.5918]Training epoch 31:  29%|██▉       | 48/163 [00:57<01:56,  1.02s/it, loss=0.1614, batch_acc=1.0000, running_acc=0.9747, grad=12.5918]Training epoch 31:  29%|██▉       | 48/163 [00:57<01:56,  1.02s/it, loss=0.2289, batch_acc=0.9688, running_acc=0.9746, grad=21.9855]Training epoch 31:  30%|███       | 49/163 [00:58<01:51,  1.02it/s, loss=0.2289, batch_acc=0.9688, running_acc=0.9746, grad=21.9855]Training epoch 31:  30%|███       | 49/163 [00:58<01:51,  1.02it/s, loss=0.2600, batch_acc=0.9688, running_acc=0.9745, grad=34.8801]Training epoch 31:  31%|███       | 50/163 [01:00<02:28,  1.31s/it, loss=0.2600, batch_acc=0.9688, running_acc=0.9745, grad=34.8801]Training epoch 31:  31%|███       | 50/163 [01:00<02:28,  1.31s/it, loss=0.1639, batch_acc=1.0000, running_acc=0.9750, grad=13.9239]Training epoch 31:  31%|███▏      | 51/163 [01:01<02:12,  1.18s/it, loss=0.1639, batch_acc=1.0000, running_acc=0.9750, grad=13.9239]Training epoch 31:  31%|███▏      | 51/163 [01:01<02:12,  1.18s/it, loss=0.1774, batch_acc=0.9688, running_acc=0.9749, grad=10.3736]Training epoch 31:  32%|███▏      | 52/163 [01:02<02:01,  1.09s/it, loss=0.1774, batch_acc=0.9688, running_acc=0.9749, grad=10.3736]Training epoch 31:  32%|███▏      | 52/163 [01:02<02:01,  1.09s/it, loss=0.1814, batch_acc=0.9688, running_acc=0.9748, grad=11.3056]Training epoch 31:  33%|███▎      | 53/163 [01:03<01:56,  1.06s/it, loss=0.1814, batch_acc=0.9688, running_acc=0.9748, grad=11.3056]Training epoch 31:  33%|███▎      | 53/163 [01:03<01:56,  1.06s/it, loss=0.1871, batch_acc=1.0000, running_acc=0.9752, grad=13.4140]Training epoch 31:  33%|███▎      | 54/163 [01:04<02:21,  1.30s/it, loss=0.1871, batch_acc=1.0000, running_acc=0.9752, grad=13.4140]Training epoch 31:  33%|███▎      | 54/163 [01:04<02:21,  1.30s/it, loss=0.1723, batch_acc=1.0000, running_acc=0.9757, grad=18.0724]Training epoch 31:  34%|███▎      | 55/163 [01:05<02:06,  1.17s/it, loss=0.1723, batch_acc=1.0000, running_acc=0.9757, grad=18.0724]Training epoch 31:  34%|███▎      | 55/163 [01:05<02:06,  1.17s/it, loss=0.2043, batch_acc=1.0000, running_acc=0.9761, grad=18.4323]Training epoch 31:  34%|███▍      | 56/163 [01:06<01:56,  1.09s/it, loss=0.2043, batch_acc=1.0000, running_acc=0.9761, grad=18.4323]Training epoch 31:  34%|███▍      | 56/163 [01:06<01:56,  1.09s/it, loss=0.2071, batch_acc=0.9688, running_acc=0.9760, grad=12.9005]Training epoch 31:  35%|███▍      | 57/163 [01:07<01:48,  1.02s/it, loss=0.2071, batch_acc=0.9688, running_acc=0.9760, grad=12.9005]Training epoch 31:  35%|███▍      | 57/163 [01:07<01:48,  1.02s/it, loss=0.2122, batch_acc=0.9688, running_acc=0.9759, grad=16.0385]Training epoch 31:  36%|███▌      | 58/163 [01:08<01:51,  1.06s/it, loss=0.2122, batch_acc=0.9688, running_acc=0.9759, grad=16.0385]Training epoch 31:  36%|███▌      | 58/163 [01:08<01:51,  1.06s/it, loss=0.1886, batch_acc=0.9688, running_acc=0.9758, grad=14.5661]Training epoch 31:  36%|███▌      | 59/163 [01:09<01:44,  1.01s/it, loss=0.1886, batch_acc=0.9688, running_acc=0.9758, grad=14.5661]Training epoch 31:  36%|███▌      | 59/163 [01:09<01:44,  1.01s/it, loss=0.2980, batch_acc=0.8750, running_acc=0.9740, grad=20.8735]Training epoch 31:  37%|███▋      | 60/163 [01:10<01:39,  1.03it/s, loss=0.2980, batch_acc=0.8750, running_acc=0.9740, grad=20.8735]Training epoch 31:  37%|███▋      | 60/163 [01:10<01:39,  1.03it/s, loss=0.3248, batch_acc=0.9688, running_acc=0.9740, grad=23.1535]Training epoch 31:  37%|███▋      | 61/163 [01:11<01:38,  1.04it/s, loss=0.3248, batch_acc=0.9688, running_acc=0.9740, grad=23.1535]Training epoch 31:  37%|███▋      | 61/163 [01:11<01:38,  1.04it/s, loss=0.2280, batch_acc=0.9688, running_acc=0.9739, grad=15.3988]Training epoch 31:  38%|███▊      | 62/163 [01:12<01:47,  1.07s/it, loss=0.2280, batch_acc=0.9688, running_acc=0.9739, grad=15.3988]Training epoch 31:  38%|███▊      | 62/163 [01:12<01:47,  1.07s/it, loss=0.2835, batch_acc=0.8750, running_acc=0.9723, grad=15.8321]Training epoch 31:  39%|███▊      | 63/163 [01:13<01:41,  1.01s/it, loss=0.2835, batch_acc=0.8750, running_acc=0.9723, grad=15.8321]Training epoch 31:  39%|███▊      | 63/163 [01:13<01:41,  1.01s/it, loss=0.1595, batch_acc=0.9688, running_acc=0.9722, grad=9.1760] Training epoch 31:  39%|███▉      | 64/163 [01:14<01:36,  1.03it/s, loss=0.1595, batch_acc=0.9688, running_acc=0.9722, grad=9.1760]Training epoch 31:  39%|███▉      | 64/163 [01:14<01:36,  1.03it/s, loss=0.2041, batch_acc=0.9688, running_acc=0.9722, grad=9.5354]Training epoch 31:  40%|███▉      | 65/163 [01:15<01:32,  1.06it/s, loss=0.2041, batch_acc=0.9688, running_acc=0.9722, grad=9.5354]Training epoch 31:  40%|███▉      | 65/163 [01:15<01:32,  1.06it/s, loss=0.2510, batch_acc=0.9375, running_acc=0.9716, grad=15.1767]Training epoch 31:  40%|████      | 66/163 [01:17<01:54,  1.18s/it, loss=0.2510, batch_acc=0.9375, running_acc=0.9716, grad=15.1767]Training epoch 31:  40%|████      | 66/163 [01:17<01:54,  1.18s/it, loss=0.2265, batch_acc=0.9688, running_acc=0.9716, grad=12.4454]Training epoch 31:  41%|████      | 67/163 [01:17<01:44,  1.09s/it, loss=0.2265, batch_acc=0.9688, running_acc=0.9716, grad=12.4454]Training epoch 31:  41%|████      | 67/163 [01:17<01:44,  1.09s/it, loss=0.1996, batch_acc=0.9688, running_acc=0.9715, grad=17.0674]Training epoch 31:  42%|████▏     | 68/163 [01:18<01:37,  1.03s/it, loss=0.1996, batch_acc=0.9688, running_acc=0.9715, grad=17.0674]Training epoch 31:  42%|████▏     | 68/163 [01:18<01:37,  1.03s/it, loss=0.2306, batch_acc=0.9375, running_acc=0.9710, grad=14.4438]Training epoch 31:  42%|████▏     | 69/163 [01:19<01:32,  1.02it/s, loss=0.2306, batch_acc=0.9375, running_acc=0.9710, grad=14.4438]Training epoch 31:  42%|████▏     | 69/163 [01:19<01:32,  1.02it/s, loss=0.1853, batch_acc=1.0000, running_acc=0.9715, grad=16.4096]Training epoch 31:  43%|████▎     | 70/163 [01:21<01:55,  1.24s/it, loss=0.1853, batch_acc=1.0000, running_acc=0.9715, grad=16.4096]Training epoch 31:  43%|████▎     | 70/163 [01:21<01:55,  1.24s/it, loss=0.2135, batch_acc=0.9688, running_acc=0.9714, grad=13.7772]Training epoch 31:  44%|████▎     | 71/163 [01:22<01:44,  1.13s/it, loss=0.2135, batch_acc=0.9688, running_acc=0.9714, grad=13.7772]Training epoch 31:  44%|████▎     | 71/163 [01:22<01:44,  1.13s/it, loss=0.1768, batch_acc=0.9688, running_acc=0.9714, grad=14.4169]Training epoch 31:  44%|████▍     | 72/163 [01:23<01:36,  1.06s/it, loss=0.1768, batch_acc=0.9688, running_acc=0.9714, grad=14.4169]Training epoch 31:  44%|████▍     | 72/163 [01:23<01:36,  1.06s/it, loss=0.2252, batch_acc=0.9688, running_acc=0.9714, grad=12.9914]Training epoch 31:  45%|████▍     | 73/163 [01:24<01:30,  1.00s/it, loss=0.2252, batch_acc=0.9688, running_acc=0.9714, grad=12.9914]Training epoch 31:  45%|████▍     | 73/163 [01:24<01:30,  1.00s/it, loss=0.2387, batch_acc=0.9688, running_acc=0.9713, grad=15.0002]Training epoch 31:  45%|████▌     | 74/163 [01:25<01:50,  1.24s/it, loss=0.2387, batch_acc=0.9688, running_acc=0.9713, grad=15.0002]Training epoch 31:  45%|████▌     | 74/163 [01:25<01:50,  1.24s/it, loss=0.2948, batch_acc=0.9062, running_acc=0.9704, grad=15.3537]Training epoch 31:  46%|████▌     | 75/163 [01:26<01:39,  1.13s/it, loss=0.2948, batch_acc=0.9062, running_acc=0.9704, grad=15.3537]Training epoch 31:  46%|████▌     | 75/163 [01:26<01:39,  1.13s/it, loss=0.3016, batch_acc=0.9688, running_acc=0.9704, grad=19.4116]Training epoch 31:  47%|████▋     | 76/163 [01:27<01:31,  1.06s/it, loss=0.3016, batch_acc=0.9688, running_acc=0.9704, grad=19.4116]Training epoch 31:  47%|████▋     | 76/163 [01:27<01:31,  1.06s/it, loss=0.1875, batch_acc=0.9688, running_acc=0.9704, grad=13.0876]Training epoch 31:  47%|████▋     | 77/163 [01:28<01:27,  1.01s/it, loss=0.1875, batch_acc=0.9688, running_acc=0.9704, grad=13.0876]Training epoch 31:  47%|████▋     | 77/163 [01:28<01:27,  1.01s/it, loss=0.2576, batch_acc=0.9688, running_acc=0.9704, grad=18.4540]Training epoch 31:  48%|████▊     | 78/163 [01:30<01:48,  1.28s/it, loss=0.2576, batch_acc=0.9688, running_acc=0.9704, grad=18.4540]Training epoch 31:  48%|████▊     | 78/163 [01:30<01:48,  1.28s/it, loss=0.1803, batch_acc=1.0000, running_acc=0.9708, grad=15.1925]Training epoch 31:  48%|████▊     | 79/163 [01:31<01:37,  1.16s/it, loss=0.1803, batch_acc=1.0000, running_acc=0.9708, grad=15.1925]Training epoch 31:  48%|████▊     | 79/163 [01:31<01:37,  1.16s/it, loss=0.2488, batch_acc=0.9688, running_acc=0.9707, grad=15.7838]Training epoch 31:  49%|████▉     | 80/163 [01:32<01:29,  1.07s/it, loss=0.2488, batch_acc=0.9688, running_acc=0.9707, grad=15.7838]Training epoch 31:  49%|████▉     | 80/163 [01:32<01:29,  1.07s/it, loss=0.2458, batch_acc=0.9688, running_acc=0.9707, grad=21.0438]Training epoch 31:  50%|████▉     | 81/163 [01:33<01:23,  1.02s/it, loss=0.2458, batch_acc=0.9688, running_acc=0.9707, grad=21.0438]Training epoch 31:  50%|████▉     | 81/163 [01:33<01:23,  1.02s/it, loss=0.1887, batch_acc=0.9688, running_acc=0.9707, grad=10.5040]Training epoch 31:  50%|█████     | 82/163 [01:35<01:43,  1.28s/it, loss=0.1887, batch_acc=0.9688, running_acc=0.9707, grad=10.5040]Training epoch 31:  50%|█████     | 82/163 [01:35<01:43,  1.28s/it, loss=0.1625, batch_acc=0.9688, running_acc=0.9707, grad=9.5290] Training epoch 31:  51%|█████     | 83/163 [01:35<01:32,  1.16s/it, loss=0.1625, batch_acc=0.9688, running_acc=0.9707, grad=9.5290]Training epoch 31:  51%|█████     | 83/163 [01:35<01:32,  1.16s/it, loss=0.1752, batch_acc=1.0000, running_acc=0.9710, grad=9.9178]Training epoch 31:  52%|█████▏    | 84/163 [01:36<01:24,  1.07s/it, loss=0.1752, batch_acc=1.0000, running_acc=0.9710, grad=9.9178]Training epoch 31:  52%|█████▏    | 84/163 [01:36<01:24,  1.07s/it, loss=0.2357, batch_acc=0.9375, running_acc=0.9706, grad=18.0272]Training epoch 31:  52%|█████▏    | 85/163 [01:37<01:20,  1.04s/it, loss=0.2357, batch_acc=0.9375, running_acc=0.9706, grad=18.0272]Training epoch 31:  52%|█████▏    | 85/163 [01:37<01:20,  1.04s/it, loss=0.1560, batch_acc=0.9688, running_acc=0.9706, grad=9.7658] Training epoch 31:  53%|█████▎    | 86/163 [01:40<02:02,  1.60s/it, loss=0.1560, batch_acc=0.9688, running_acc=0.9706, grad=9.7658]Training epoch 31:  53%|█████▎    | 86/163 [01:40<02:02,  1.60s/it, loss=0.1729, batch_acc=1.0000, running_acc=0.9709, grad=11.9399]Training epoch 31:  53%|█████▎    | 87/163 [01:41<01:44,  1.38s/it, loss=0.1729, batch_acc=1.0000, running_acc=0.9709, grad=11.9399]Training epoch 31:  53%|█████▎    | 87/163 [01:41<01:44,  1.38s/it, loss=0.1512, batch_acc=1.0000, running_acc=0.9713, grad=9.8242] Training epoch 31:  54%|█████▍    | 88/163 [01:42<01:32,  1.23s/it, loss=0.1512, batch_acc=1.0000, running_acc=0.9713, grad=9.8242]Training epoch 31:  54%|█████▍    | 88/163 [01:42<01:32,  1.23s/it, loss=0.2689, batch_acc=1.0000, running_acc=0.9716, grad=17.4685]Training epoch 31:  55%|█████▍    | 89/163 [01:43<01:23,  1.12s/it, loss=0.2689, batch_acc=1.0000, running_acc=0.9716, grad=17.4685]Training epoch 31:  55%|█████▍    | 89/163 [01:43<01:23,  1.12s/it, loss=0.2094, batch_acc=1.0000, running_acc=0.9719, grad=15.9455]Training epoch 31:  55%|█████▌    | 90/163 [01:44<01:27,  1.19s/it, loss=0.2094, batch_acc=1.0000, running_acc=0.9719, grad=15.9455]Training epoch 31:  55%|█████▌    | 90/163 [01:44<01:27,  1.19s/it, loss=0.2355, batch_acc=0.9375, running_acc=0.9715, grad=16.9571]Training epoch 31:  56%|█████▌    | 91/163 [01:45<01:19,  1.10s/it, loss=0.2355, batch_acc=0.9375, running_acc=0.9715, grad=16.9571]Training epoch 31:  56%|█████▌    | 91/163 [01:45<01:19,  1.10s/it, loss=0.1975, batch_acc=1.0000, running_acc=0.9718, grad=18.2814]Training epoch 31:  56%|█████▋    | 92/163 [01:46<01:13,  1.03s/it, loss=0.1975, batch_acc=1.0000, running_acc=0.9718, grad=18.2814]Training epoch 31:  56%|█████▋    | 92/163 [01:46<01:13,  1.03s/it, loss=0.2849, batch_acc=0.9688, running_acc=0.9718, grad=18.0577]Training epoch 31:  57%|█████▋    | 93/163 [01:47<01:09,  1.01it/s, loss=0.2849, batch_acc=0.9688, running_acc=0.9718, grad=18.0577]Training epoch 31:  57%|█████▋    | 93/163 [01:47<01:09,  1.01it/s, loss=0.2038, batch_acc=0.9375, running_acc=0.9714, grad=19.8942]Training epoch 31:  58%|█████▊    | 94/163 [01:48<01:14,  1.08s/it, loss=0.2038, batch_acc=0.9375, running_acc=0.9714, grad=19.8942]Training epoch 31:  58%|█████▊    | 94/163 [01:48<01:14,  1.08s/it, loss=0.2700, batch_acc=0.9688, running_acc=0.9714, grad=25.5256]Training epoch 31:  58%|█████▊    | 95/163 [01:49<01:09,  1.02s/it, loss=0.2700, batch_acc=0.9688, running_acc=0.9714, grad=25.5256]Training epoch 31:  58%|█████▊    | 95/163 [01:49<01:09,  1.02s/it, loss=0.2269, batch_acc=0.9688, running_acc=0.9714, grad=16.8808]Training epoch 31:  59%|█████▉    | 96/163 [01:50<01:05,  1.02it/s, loss=0.2269, batch_acc=0.9688, running_acc=0.9714, grad=16.8808]Training epoch 31:  59%|█████▉    | 96/163 [01:50<01:05,  1.02it/s, loss=0.1717, batch_acc=1.0000, running_acc=0.9717, grad=14.6991]Training epoch 31:  60%|█████▉    | 97/163 [01:51<01:02,  1.05it/s, loss=0.1717, batch_acc=1.0000, running_acc=0.9717, grad=14.6991]Training epoch 31:  60%|█████▉    | 97/163 [01:51<01:02,  1.05it/s, loss=0.3019, batch_acc=0.9688, running_acc=0.9716, grad=18.0476]Training epoch 31:  60%|██████    | 98/163 [01:53<01:22,  1.27s/it, loss=0.3019, batch_acc=0.9688, running_acc=0.9716, grad=18.0476]Training epoch 31:  60%|██████    | 98/163 [01:53<01:22,  1.27s/it, loss=0.2884, batch_acc=0.9688, running_acc=0.9716, grad=25.3802]Training epoch 31:  61%|██████    | 99/163 [01:54<01:13,  1.15s/it, loss=0.2884, batch_acc=0.9688, running_acc=0.9716, grad=25.3802]Training epoch 31:  61%|██████    | 99/163 [01:54<01:13,  1.15s/it, loss=0.1097, batch_acc=1.0000, running_acc=0.9719, grad=9.1377] Training epoch 31:  61%|██████▏   | 100/163 [01:55<01:07,  1.07s/it, loss=0.1097, batch_acc=1.0000, running_acc=0.9719, grad=9.1377]Training epoch 31:  61%|██████▏   | 100/163 [01:55<01:07,  1.07s/it, loss=0.1821, batch_acc=1.0000, running_acc=0.9722, grad=14.7455]Training epoch 31:  62%|██████▏   | 101/163 [01:55<01:02,  1.01s/it, loss=0.1821, batch_acc=1.0000, running_acc=0.9722, grad=14.7455]Training epoch 31:  62%|██████▏   | 101/163 [01:55<01:02,  1.01s/it, loss=0.2338, batch_acc=0.9375, running_acc=0.9718, grad=13.9905]Training epoch 31:  63%|██████▎   | 102/163 [01:57<01:14,  1.22s/it, loss=0.2338, batch_acc=0.9375, running_acc=0.9718, grad=13.9905]Training epoch 31:  63%|██████▎   | 102/163 [01:57<01:14,  1.22s/it, loss=0.1303, batch_acc=1.0000, running_acc=0.9721, grad=7.7859] Training epoch 31:  63%|██████▎   | 103/163 [01:58<01:06,  1.11s/it, loss=0.1303, batch_acc=1.0000, running_acc=0.9721, grad=7.7859]Training epoch 31:  63%|██████▎   | 103/163 [01:58<01:06,  1.11s/it, loss=0.2015, batch_acc=1.0000, running_acc=0.9724, grad=16.9970]Training epoch 31:  64%|██████▍   | 104/163 [01:59<01:01,  1.04s/it, loss=0.2015, batch_acc=1.0000, running_acc=0.9724, grad=16.9970]Training epoch 31:  64%|██████▍   | 104/163 [01:59<01:01,  1.04s/it, loss=0.2786, batch_acc=0.9062, running_acc=0.9718, grad=18.1688]Training epoch 31:  64%|██████▍   | 105/163 [02:00<00:57,  1.00it/s, loss=0.2786, batch_acc=0.9062, running_acc=0.9718, grad=18.1688]Training epoch 31:  64%|██████▍   | 105/163 [02:00<00:57,  1.00it/s, loss=0.2309, batch_acc=0.9688, running_acc=0.9717, grad=15.0726]Training epoch 31:  65%|██████▌   | 106/163 [02:01<01:06,  1.17s/it, loss=0.2309, batch_acc=0.9688, running_acc=0.9717, grad=15.0726]Training epoch 31:  65%|██████▌   | 106/163 [02:01<01:06,  1.17s/it, loss=0.1551, batch_acc=1.0000, running_acc=0.9720, grad=9.1568] Training epoch 31:  66%|██████▌   | 107/163 [02:02<01:00,  1.08s/it, loss=0.1551, batch_acc=1.0000, running_acc=0.9720, grad=9.1568]Training epoch 31:  66%|██████▌   | 107/163 [02:02<01:00,  1.08s/it, loss=0.2098, batch_acc=0.9375, running_acc=0.9717, grad=14.1543]Training epoch 31:  66%|██████▋   | 108/163 [02:03<00:56,  1.02s/it, loss=0.2098, batch_acc=0.9375, running_acc=0.9717, grad=14.1543]Training epoch 31:  66%|██████▋   | 108/163 [02:03<00:56,  1.02s/it, loss=0.2081, batch_acc=1.0000, running_acc=0.9719, grad=14.9504]Training epoch 31:  67%|██████▋   | 109/163 [02:04<00:52,  1.02it/s, loss=0.2081, batch_acc=1.0000, running_acc=0.9719, grad=14.9504]Training epoch 31:  67%|██████▋   | 109/163 [02:04<00:52,  1.02it/s, loss=0.2182, batch_acc=0.9688, running_acc=0.9719, grad=16.3475]Training epoch 31:  67%|██████▋   | 110/163 [02:05<00:55,  1.04s/it, loss=0.2182, batch_acc=0.9688, running_acc=0.9719, grad=16.3475]Training epoch 31:  67%|██████▋   | 110/163 [02:05<00:55,  1.04s/it, loss=0.2205, batch_acc=0.9688, running_acc=0.9719, grad=12.7016]Training epoch 31:  68%|██████▊   | 111/163 [02:06<00:51,  1.01it/s, loss=0.2205, batch_acc=0.9688, running_acc=0.9719, grad=12.7016]Training epoch 31:  68%|██████▊   | 111/163 [02:06<00:51,  1.01it/s, loss=0.2650, batch_acc=0.9688, running_acc=0.9718, grad=14.3336]Training epoch 31:  69%|██████▊   | 112/163 [02:07<00:48,  1.04it/s, loss=0.2650, batch_acc=0.9688, running_acc=0.9718, grad=14.3336]Training epoch 31:  69%|██████▊   | 112/163 [02:07<00:48,  1.04it/s, loss=0.2323, batch_acc=0.9688, running_acc=0.9718, grad=16.7929]Training epoch 31:  69%|██████▉   | 113/163 [02:08<00:46,  1.07it/s, loss=0.2323, batch_acc=0.9688, running_acc=0.9718, grad=16.7929]Training epoch 31:  69%|██████▉   | 113/163 [02:08<00:46,  1.07it/s, loss=0.2104, batch_acc=0.9688, running_acc=0.9718, grad=13.2939]Training epoch 31:  70%|██████▉   | 114/163 [02:10<01:02,  1.28s/it, loss=0.2104, batch_acc=0.9688, running_acc=0.9718, grad=13.2939]Training epoch 31:  70%|██████▉   | 114/163 [02:10<01:02,  1.28s/it, loss=0.2066, batch_acc=0.9688, running_acc=0.9718, grad=19.2711]Training epoch 31:  71%|███████   | 115/163 [02:11<00:55,  1.16s/it, loss=0.2066, batch_acc=0.9688, running_acc=0.9718, grad=19.2711]Training epoch 31:  71%|███████   | 115/163 [02:11<00:55,  1.16s/it, loss=0.2540, batch_acc=0.9688, running_acc=0.9717, grad=16.0193]Training epoch 31:  71%|███████   | 116/163 [02:12<00:50,  1.08s/it, loss=0.2540, batch_acc=0.9688, running_acc=0.9717, grad=16.0193]Training epoch 31:  71%|███████   | 116/163 [02:12<00:50,  1.08s/it, loss=0.3170, batch_acc=0.9062, running_acc=0.9712, grad=18.6652]Training epoch 31:  72%|███████▏  | 117/163 [02:13<00:47,  1.03s/it, loss=0.3170, batch_acc=0.9062, running_acc=0.9712, grad=18.6652]Training epoch 31:  72%|███████▏  | 117/163 [02:13<00:47,  1.03s/it, loss=0.1809, batch_acc=0.9688, running_acc=0.9712, grad=9.6204] Training epoch 31:  72%|███████▏  | 118/163 [02:14<00:56,  1.26s/it, loss=0.1809, batch_acc=0.9688, running_acc=0.9712, grad=9.6204]Training epoch 31:  72%|███████▏  | 118/163 [02:14<00:56,  1.26s/it, loss=0.2155, batch_acc=1.0000, running_acc=0.9714, grad=15.8804]Training epoch 31:  73%|███████▎  | 119/163 [02:15<00:50,  1.15s/it, loss=0.2155, batch_acc=1.0000, running_acc=0.9714, grad=15.8804]Training epoch 31:  73%|███████▎  | 119/163 [02:15<00:50,  1.15s/it, loss=0.2028, batch_acc=1.0000, running_acc=0.9716, grad=14.7938]Training epoch 31:  74%|███████▎  | 120/163 [02:16<00:45,  1.07s/it, loss=0.2028, batch_acc=1.0000, running_acc=0.9716, grad=14.7938]Training epoch 31:  74%|███████▎  | 120/163 [02:16<00:45,  1.07s/it, loss=0.2287, batch_acc=1.0000, running_acc=0.9719, grad=15.4578]Training epoch 31:  74%|███████▍  | 121/163 [02:17<00:42,  1.01s/it, loss=0.2287, batch_acc=1.0000, running_acc=0.9719, grad=15.4578]Training epoch 31:  74%|███████▍  | 121/163 [02:17<00:42,  1.01s/it, loss=0.2060, batch_acc=1.0000, running_acc=0.9721, grad=15.0614]Training epoch 31:  75%|███████▍  | 122/163 [02:19<00:48,  1.18s/it, loss=0.2060, batch_acc=1.0000, running_acc=0.9721, grad=15.0614]Training epoch 31:  75%|███████▍  | 122/163 [02:19<00:48,  1.18s/it, loss=0.1427, batch_acc=0.9688, running_acc=0.9721, grad=11.2947]Training epoch 31:  75%|███████▌  | 123/163 [02:19<00:43,  1.09s/it, loss=0.1427, batch_acc=0.9688, running_acc=0.9721, grad=11.2947]Training epoch 31:  75%|███████▌  | 123/163 [02:19<00:43,  1.09s/it, loss=0.1196, batch_acc=1.0000, running_acc=0.9723, grad=8.8508] Training epoch 31:  76%|███████▌  | 124/163 [02:20<00:40,  1.03s/it, loss=0.1196, batch_acc=1.0000, running_acc=0.9723, grad=8.8508]Training epoch 31:  76%|███████▌  | 124/163 [02:20<00:40,  1.03s/it, loss=0.2115, batch_acc=1.0000, running_acc=0.9725, grad=14.5823]Training epoch 31:  77%|███████▋  | 125/163 [02:21<00:37,  1.02it/s, loss=0.2115, batch_acc=1.0000, running_acc=0.9725, grad=14.5823]Training epoch 31:  77%|███████▋  | 125/163 [02:21<00:37,  1.02it/s, loss=0.1933, batch_acc=1.0000, running_acc=0.9728, grad=14.2634]Training epoch 31:  77%|███████▋  | 126/163 [02:23<00:43,  1.19s/it, loss=0.1933, batch_acc=1.0000, running_acc=0.9728, grad=14.2634]Training epoch 31:  77%|███████▋  | 126/163 [02:23<00:43,  1.19s/it, loss=0.2027, batch_acc=1.0000, running_acc=0.9730, grad=18.3279]Training epoch 31:  78%|███████▊  | 127/163 [02:24<00:39,  1.09s/it, loss=0.2027, batch_acc=1.0000, running_acc=0.9730, grad=18.3279]Training epoch 31:  78%|███████▊  | 127/163 [02:24<00:39,  1.09s/it, loss=0.2265, batch_acc=0.9688, running_acc=0.9729, grad=19.8235]Training epoch 31:  79%|███████▊  | 128/163 [02:25<00:36,  1.03s/it, loss=0.2265, batch_acc=0.9688, running_acc=0.9729, grad=19.8235]Training epoch 31:  79%|███████▊  | 128/163 [02:25<00:36,  1.03s/it, loss=0.1555, batch_acc=1.0000, running_acc=0.9731, grad=13.2602]Training epoch 31:  79%|███████▉  | 129/163 [02:26<00:33,  1.01it/s, loss=0.1555, batch_acc=1.0000, running_acc=0.9731, grad=13.2602]Training epoch 31:  79%|███████▉  | 129/163 [02:26<00:33,  1.01it/s, loss=0.2202, batch_acc=1.0000, running_acc=0.9734, grad=22.3670]Training epoch 31:  80%|███████▉  | 130/163 [02:27<00:39,  1.21s/it, loss=0.2202, batch_acc=1.0000, running_acc=0.9734, grad=22.3670]Training epoch 31:  80%|███████▉  | 130/163 [02:27<00:39,  1.21s/it, loss=0.2021, batch_acc=1.0000, running_acc=0.9736, grad=16.6310]Training epoch 31:  80%|████████  | 131/163 [02:28<00:35,  1.11s/it, loss=0.2021, batch_acc=1.0000, running_acc=0.9736, grad=16.6310]Training epoch 31:  80%|████████  | 131/163 [02:28<00:35,  1.11s/it, loss=0.3980, batch_acc=0.8750, running_acc=0.9728, grad=25.5193]Training epoch 31:  81%|████████  | 132/163 [02:29<00:32,  1.04s/it, loss=0.3980, batch_acc=0.8750, running_acc=0.9728, grad=25.5193]Training epoch 31:  81%|████████  | 132/163 [02:29<00:32,  1.04s/it, loss=0.2063, batch_acc=0.9688, running_acc=0.9728, grad=16.6085]Training epoch 31:  82%|████████▏ | 133/163 [02:30<00:29,  1.01it/s, loss=0.2063, batch_acc=0.9688, running_acc=0.9728, grad=16.6085]Training epoch 31:  82%|████████▏ | 133/163 [02:30<00:29,  1.01it/s, loss=0.1592, batch_acc=1.0000, running_acc=0.9730, grad=16.7095]Training epoch 31:  82%|████████▏ | 134/163 [02:31<00:32,  1.11s/it, loss=0.1592, batch_acc=1.0000, running_acc=0.9730, grad=16.7095]Training epoch 31:  82%|████████▏ | 134/163 [02:31<00:32,  1.11s/it, loss=0.1566, batch_acc=1.0000, running_acc=0.9732, grad=11.0994]Training epoch 31:  83%|████████▎ | 135/163 [02:32<00:29,  1.04s/it, loss=0.1566, batch_acc=1.0000, running_acc=0.9732, grad=11.0994]Training epoch 31:  83%|████████▎ | 135/163 [02:32<00:29,  1.04s/it, loss=0.1462, batch_acc=1.0000, running_acc=0.9734, grad=13.4484]Training epoch 31:  83%|████████▎ | 136/163 [02:33<00:26,  1.01it/s, loss=0.1462, batch_acc=1.0000, running_acc=0.9734, grad=13.4484]Training epoch 31:  83%|████████▎ | 136/163 [02:33<00:26,  1.01it/s, loss=0.2637, batch_acc=0.9375, running_acc=0.9731, grad=18.9371]Training epoch 31:  84%|████████▍ | 137/163 [02:34<00:24,  1.04it/s, loss=0.2637, batch_acc=0.9375, running_acc=0.9731, grad=18.9371]Training epoch 31:  84%|████████▍ | 137/163 [02:34<00:24,  1.04it/s, loss=0.3385, batch_acc=0.8750, running_acc=0.9724, grad=20.6882]Training epoch 31:  85%|████████▍ | 138/163 [02:36<00:30,  1.21s/it, loss=0.3385, batch_acc=0.8750, running_acc=0.9724, grad=20.6882]Training epoch 31:  85%|████████▍ | 138/163 [02:36<00:30,  1.21s/it, loss=0.1949, batch_acc=0.9688, running_acc=0.9724, grad=13.8079]Training epoch 31:  85%|████████▌ | 139/163 [02:37<00:26,  1.11s/it, loss=0.1949, batch_acc=0.9688, running_acc=0.9724, grad=13.8079]Training epoch 31:  85%|████████▌ | 139/163 [02:37<00:26,  1.11s/it, loss=0.2387, batch_acc=0.9688, running_acc=0.9723, grad=21.0147]Training epoch 31:  86%|████████▌ | 140/163 [02:37<00:23,  1.04s/it, loss=0.2387, batch_acc=0.9688, running_acc=0.9723, grad=21.0147]Training epoch 31:  86%|████████▌ | 140/163 [02:37<00:23,  1.04s/it, loss=0.1473, batch_acc=1.0000, running_acc=0.9725, grad=8.9629] Training epoch 31:  87%|████████▋ | 141/163 [02:38<00:21,  1.01it/s, loss=0.1473, batch_acc=1.0000, running_acc=0.9725, grad=8.9629]Training epoch 31:  87%|████████▋ | 141/163 [02:38<00:21,  1.01it/s, loss=0.1693, batch_acc=1.0000, running_acc=0.9727, grad=13.2209]Training epoch 31:  87%|████████▋ | 142/163 [02:40<00:26,  1.28s/it, loss=0.1693, batch_acc=1.0000, running_acc=0.9727, grad=13.2209]Training epoch 31:  87%|████████▋ | 142/163 [02:40<00:26,  1.28s/it, loss=0.1941, batch_acc=0.9688, running_acc=0.9727, grad=11.6348]Training epoch 31:  88%|████████▊ | 143/163 [02:41<00:23,  1.16s/it, loss=0.1941, batch_acc=0.9688, running_acc=0.9727, grad=11.6348]Training epoch 31:  88%|████████▊ | 143/163 [02:41<00:23,  1.16s/it, loss=0.1618, batch_acc=1.0000, running_acc=0.9729, grad=13.2012]Training epoch 31:  88%|████████▊ | 144/163 [02:42<00:20,  1.07s/it, loss=0.1618, batch_acc=1.0000, running_acc=0.9729, grad=13.2012]Training epoch 31:  88%|████████▊ | 144/163 [02:42<00:20,  1.07s/it, loss=0.2118, batch_acc=0.9688, running_acc=0.9729, grad=11.8826]Training epoch 31:  89%|████████▉ | 145/163 [02:43<00:18,  1.02s/it, loss=0.2118, batch_acc=0.9688, running_acc=0.9729, grad=11.8826]Training epoch 31:  89%|████████▉ | 145/163 [02:43<00:18,  1.02s/it, loss=0.2108, batch_acc=1.0000, running_acc=0.9731, grad=18.4942]Training epoch 31:  90%|████████▉ | 146/163 [02:45<00:21,  1.26s/it, loss=0.2108, batch_acc=1.0000, running_acc=0.9731, grad=18.4942]Training epoch 31:  90%|████████▉ | 146/163 [02:45<00:21,  1.26s/it, loss=0.2258, batch_acc=0.9688, running_acc=0.9730, grad=16.5084]Training epoch 31:  90%|█████████ | 147/163 [02:46<00:18,  1.15s/it, loss=0.2258, batch_acc=0.9688, running_acc=0.9730, grad=16.5084]Training epoch 31:  90%|█████████ | 147/163 [02:46<00:18,  1.15s/it, loss=0.1951, batch_acc=0.9688, running_acc=0.9730, grad=11.9186]Training epoch 31:  91%|█████████ | 148/163 [02:46<00:16,  1.07s/it, loss=0.1951, batch_acc=0.9688, running_acc=0.9730, grad=11.9186]Training epoch 31:  91%|█████████ | 148/163 [02:46<00:16,  1.07s/it, loss=0.1971, batch_acc=0.9688, running_acc=0.9730, grad=11.8200]Training epoch 31:  91%|█████████▏| 149/163 [02:47<00:14,  1.01s/it, loss=0.1971, batch_acc=0.9688, running_acc=0.9730, grad=11.8200]Training epoch 31:  91%|█████████▏| 149/163 [02:47<00:14,  1.01s/it, loss=0.1624, batch_acc=1.0000, running_acc=0.9732, grad=11.3631]Training epoch 31:  92%|█████████▏| 150/163 [02:49<00:16,  1.29s/it, loss=0.1624, batch_acc=1.0000, running_acc=0.9732, grad=11.3631]Training epoch 31:  92%|█████████▏| 150/163 [02:49<00:16,  1.29s/it, loss=0.2490, batch_acc=0.9688, running_acc=0.9731, grad=19.0761]Training epoch 31:  93%|█████████▎| 151/163 [02:50<00:14,  1.17s/it, loss=0.2490, batch_acc=0.9688, running_acc=0.9731, grad=19.0761]Training epoch 31:  93%|█████████▎| 151/163 [02:50<00:14,  1.17s/it, loss=0.1469, batch_acc=1.0000, running_acc=0.9733, grad=11.5256]Training epoch 31:  93%|█████████▎| 152/163 [02:51<00:11,  1.08s/it, loss=0.1469, batch_acc=1.0000, running_acc=0.9733, grad=11.5256]Training epoch 31:  93%|█████████▎| 152/163 [02:51<00:11,  1.08s/it, loss=0.2070, batch_acc=1.0000, running_acc=0.9735, grad=21.3439]Training epoch 31:  94%|█████████▍| 153/163 [02:52<00:10,  1.02s/it, loss=0.2070, batch_acc=1.0000, running_acc=0.9735, grad=21.3439]Training epoch 31:  94%|█████████▍| 153/163 [02:52<00:10,  1.02s/it, loss=0.1578, batch_acc=1.0000, running_acc=0.9737, grad=12.0149]Training epoch 31:  94%|█████████▍| 154/163 [02:54<00:11,  1.29s/it, loss=0.1578, batch_acc=1.0000, running_acc=0.9737, grad=12.0149]Training epoch 31:  94%|█████████▍| 154/163 [02:54<00:11,  1.29s/it, loss=0.1574, batch_acc=1.0000, running_acc=0.9738, grad=12.8257]Training epoch 31:  95%|█████████▌| 155/163 [02:55<00:09,  1.16s/it, loss=0.1574, batch_acc=1.0000, running_acc=0.9738, grad=12.8257]Training epoch 31:  95%|█████████▌| 155/163 [02:55<00:09,  1.16s/it, loss=0.2324, batch_acc=0.9688, running_acc=0.9738, grad=17.0941]Training epoch 31:  96%|█████████▌| 156/163 [02:56<00:07,  1.08s/it, loss=0.2324, batch_acc=0.9688, running_acc=0.9738, grad=17.0941]Training epoch 31:  96%|█████████▌| 156/163 [02:56<00:07,  1.08s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9740, grad=11.1671]Training epoch 31:  96%|█████████▋| 157/163 [02:56<00:06,  1.02s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9740, grad=11.1671]Training epoch 31:  96%|█████████▋| 157/163 [02:56<00:06,  1.02s/it, loss=0.2949, batch_acc=0.9375, running_acc=0.9737, grad=27.6593]Training epoch 31:  97%|█████████▋| 158/163 [02:58<00:06,  1.21s/it, loss=0.2949, batch_acc=0.9375, running_acc=0.9737, grad=27.6593]Training epoch 31:  97%|█████████▋| 158/163 [02:58<00:06,  1.21s/it, loss=0.2251, batch_acc=0.9688, running_acc=0.9737, grad=15.8481]Training epoch 31:  98%|█████████▊| 159/163 [02:59<00:04,  1.11s/it, loss=0.2251, batch_acc=0.9688, running_acc=0.9737, grad=15.8481]Training epoch 31:  98%|█████████▊| 159/163 [02:59<00:04,  1.11s/it, loss=0.1989, batch_acc=1.0000, running_acc=0.9739, grad=21.8663]Training epoch 31:  98%|█████████▊| 160/163 [03:00<00:03,  1.04s/it, loss=0.1989, batch_acc=1.0000, running_acc=0.9739, grad=21.8663]Training epoch 31:  98%|█████████▊| 160/163 [03:00<00:03,  1.04s/it, loss=0.1788, batch_acc=0.9688, running_acc=0.9738, grad=12.9026]Training epoch 31:  99%|█████████▉| 161/163 [03:01<00:01,  1.01it/s, loss=0.1788, batch_acc=0.9688, running_acc=0.9738, grad=12.9026]Training epoch 31:  99%|█████████▉| 161/163 [03:01<00:01,  1.01it/s, loss=0.1612, batch_acc=0.9688, running_acc=0.9738, grad=10.5511]Training epoch 31:  99%|█████████▉| 162/163 [03:02<00:00,  1.04it/s, loss=0.1612, batch_acc=0.9688, running_acc=0.9738, grad=10.5511]Training epoch 31:  99%|█████████▉| 162/163 [03:02<00:00,  1.04it/s, loss=0.2640, batch_acc=0.9375, running_acc=0.9736, grad=17.0969]Training epoch 31: 100%|██████████| 163/163 [03:02<00:00,  1.16it/s, loss=0.2640, batch_acc=0.9375, running_acc=0.9736, grad=17.0969]Training epoch 31: 100%|██████████| 163/163 [03:02<00:00,  1.16it/s, loss=0.1847, batch_acc=1.0000, running_acc=0.9737, grad=23.8550]Training epoch 31: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.1847, batch_acc=1.0000, running_acc=0.9737, grad=23.8550]
Evaluation epoch 31:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 31:   4%|▎         | 1/28 [00:04<02:11,  4.86s/it]Evaluation epoch 31:   4%|▎         | 1/28 [00:04<02:11,  4.86s/it, loss=0.4352, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 31:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=0.4352, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 31:   7%|▋         | 2/28 [00:05<00:58,  2.26s/it, loss=0.3529, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 31:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.3529, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 31:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.4881, batch_acc=0.9375, running_acc=0.9167]Evaluation epoch 31:  14%|█▍        | 4/28 [00:09<01:01,  2.56s/it, loss=0.4881, batch_acc=0.9375, running_acc=0.9167]Evaluation epoch 31:  14%|█▍        | 4/28 [00:09<01:01,  2.56s/it, loss=0.4271, batch_acc=0.9688, running_acc=0.9297]Evaluation epoch 31:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=0.4271, batch_acc=0.9688, running_acc=0.9297]Evaluation epoch 31:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.2126, batch_acc=0.7812, running_acc=0.9000]Evaluation epoch 31:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.2126, batch_acc=0.7812, running_acc=0.9000]Evaluation epoch 31:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=0.6939, batch_acc=0.8125, running_acc=0.8854]Evaluation epoch 31:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.6939, batch_acc=0.8125, running_acc=0.8854]Evaluation epoch 31:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.7854, batch_acc=0.8125, running_acc=0.8750]Evaluation epoch 31:  29%|██▊       | 8/28 [00:15<00:42,  2.13s/it, loss=0.7854, batch_acc=0.8125, running_acc=0.8750]Evaluation epoch 31:  29%|██▊       | 8/28 [00:15<00:42,  2.13s/it, loss=0.4677, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 31:  32%|███▏      | 9/28 [00:15<00:29,  1.55s/it, loss=0.4677, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 31:  32%|███▏      | 9/28 [00:15<00:29,  1.55s/it, loss=0.5829, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 31:  36%|███▌      | 10/28 [00:16<00:20,  1.15s/it, loss=0.5829, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 31:  36%|███▌      | 10/28 [00:16<00:20,  1.15s/it, loss=0.5344, batch_acc=0.9375, running_acc=0.8844]Evaluation epoch 31:  39%|███▉      | 11/28 [00:16<00:14,  1.14it/s, loss=0.5344, batch_acc=0.9375, running_acc=0.8844]Evaluation epoch 31:  39%|███▉      | 11/28 [00:16<00:14,  1.14it/s, loss=0.4008, batch_acc=0.9375, running_acc=0.8892]Evaluation epoch 31:  43%|████▎     | 12/28 [00:22<00:38,  2.43s/it, loss=0.4008, batch_acc=0.9375, running_acc=0.8892]Evaluation epoch 31:  43%|████▎     | 12/28 [00:22<00:38,  2.43s/it, loss=0.8513, batch_acc=0.8125, running_acc=0.8828]Evaluation epoch 31:  46%|████▋     | 13/28 [00:22<00:26,  1.77s/it, loss=0.8513, batch_acc=0.8125, running_acc=0.8828]Evaluation epoch 31:  46%|████▋     | 13/28 [00:22<00:26,  1.77s/it, loss=0.4128, batch_acc=0.9375, running_acc=0.8870]Evaluation epoch 31:  50%|█████     | 14/28 [00:22<00:18,  1.31s/it, loss=0.4128, batch_acc=0.9375, running_acc=0.8870]Evaluation epoch 31:  50%|█████     | 14/28 [00:22<00:18,  1.31s/it, loss=1.0427, batch_acc=0.7500, running_acc=0.8772]Evaluation epoch 31:  54%|█████▎    | 15/28 [00:23<00:12,  1.00it/s, loss=1.0427, batch_acc=0.7500, running_acc=0.8772]Evaluation epoch 31:  54%|█████▎    | 15/28 [00:23<00:12,  1.00it/s, loss=1.0693, batch_acc=0.6875, running_acc=0.8646]Evaluation epoch 31:  57%|█████▋    | 16/28 [00:26<00:21,  1.79s/it, loss=1.0693, batch_acc=0.6875, running_acc=0.8646]Evaluation epoch 31:  57%|█████▋    | 16/28 [00:26<00:21,  1.79s/it, loss=0.7646, batch_acc=0.7500, running_acc=0.8574]Evaluation epoch 31:  61%|██████    | 17/28 [00:26<00:14,  1.33s/it, loss=0.7646, batch_acc=0.7500, running_acc=0.8574]Evaluation epoch 31:  61%|██████    | 17/28 [00:26<00:14,  1.33s/it, loss=0.6338, batch_acc=0.6875, running_acc=0.8474]Evaluation epoch 31:  64%|██████▍   | 18/28 [00:27<00:10,  1.01s/it, loss=0.6338, batch_acc=0.6875, running_acc=0.8474]Evaluation epoch 31:  64%|██████▍   | 18/28 [00:27<00:10,  1.01s/it, loss=0.5961, batch_acc=0.8438, running_acc=0.8472]Evaluation epoch 31:  68%|██████▊   | 19/28 [00:27<00:07,  1.28it/s, loss=0.5961, batch_acc=0.8438, running_acc=0.8472]Evaluation epoch 31:  68%|██████▊   | 19/28 [00:27<00:07,  1.28it/s, loss=0.8736, batch_acc=0.6562, running_acc=0.8372]Evaluation epoch 31:  71%|███████▏  | 20/28 [00:30<00:12,  1.51s/it, loss=0.8736, batch_acc=0.6562, running_acc=0.8372]Evaluation epoch 31:  71%|███████▏  | 20/28 [00:30<00:12,  1.51s/it, loss=0.6170, batch_acc=0.7188, running_acc=0.8313]Evaluation epoch 31:  75%|███████▌  | 21/28 [00:30<00:07,  1.13s/it, loss=0.6170, batch_acc=0.7188, running_acc=0.8313]Evaluation epoch 31:  75%|███████▌  | 21/28 [00:30<00:07,  1.13s/it, loss=0.5668, batch_acc=0.8750, running_acc=0.8333]Evaluation epoch 31:  79%|███████▊  | 22/28 [00:31<00:05,  1.15it/s, loss=0.5668, batch_acc=0.8750, running_acc=0.8333]Evaluation epoch 31:  79%|███████▊  | 22/28 [00:31<00:05,  1.15it/s, loss=0.6996, batch_acc=0.8125, running_acc=0.8324]Evaluation epoch 31:  82%|████████▏ | 23/28 [00:31<00:03,  1.45it/s, loss=0.6996, batch_acc=0.8125, running_acc=0.8324]Evaluation epoch 31:  82%|████████▏ | 23/28 [00:31<00:03,  1.45it/s, loss=0.9244, batch_acc=0.7188, running_acc=0.8274]Evaluation epoch 31:  86%|████████▌ | 24/28 [00:37<00:09,  2.32s/it, loss=0.9244, batch_acc=0.7188, running_acc=0.8274]Evaluation epoch 31:  86%|████████▌ | 24/28 [00:37<00:09,  2.32s/it, loss=0.4460, batch_acc=0.9062, running_acc=0.8307]Evaluation epoch 31:  89%|████████▉ | 25/28 [00:37<00:05,  1.70s/it, loss=0.4460, batch_acc=0.9062, running_acc=0.8307]Evaluation epoch 31:  89%|████████▉ | 25/28 [00:37<00:05,  1.70s/it, loss=0.1905, batch_acc=1.0000, running_acc=0.8375]Evaluation epoch 31:  93%|█████████▎| 26/28 [00:38<00:02,  1.27s/it, loss=0.1905, batch_acc=1.0000, running_acc=0.8375]Evaluation epoch 31:  93%|█████████▎| 26/28 [00:38<00:02,  1.27s/it, loss=0.7253, batch_acc=0.8125, running_acc=0.8365]Evaluation epoch 31:  96%|█████████▋| 27/28 [00:38<00:00,  1.03it/s, loss=0.7253, batch_acc=0.8125, running_acc=0.8365]Evaluation epoch 31:  96%|█████████▋| 27/28 [00:38<00:00,  1.03it/s, loss=1.0065, batch_acc=0.6875, running_acc=0.8310]Evaluation epoch 31: 100%|██████████| 28/28 [00:38<00:00,  1.03it/s, loss=1.2845, batch_acc=0.6667, running_acc=0.8304]Evaluation epoch 31: 100%|██████████| 28/28 [00:38<00:00,  1.37s/it, loss=1.2845, batch_acc=0.6667, running_acc=0.8304]
Training epoch 32:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 32:   1%|          | 1/163 [00:05<15:27,  5.73s/it]Training epoch 32:   1%|          | 1/163 [00:05<15:27,  5.73s/it, loss=0.2146, batch_acc=0.9688, running_acc=0.9688, grad=12.8144]Training epoch 32:   1%|          | 2/163 [00:06<07:42,  2.87s/it, loss=0.2146, batch_acc=0.9688, running_acc=0.9688, grad=12.8144]Training epoch 32:   1%|          | 2/163 [00:06<07:42,  2.87s/it, loss=0.2409, batch_acc=0.9688, running_acc=0.9688, grad=16.2298]Training epoch 32:   2%|▏         | 3/163 [00:07<05:13,  1.96s/it, loss=0.2409, batch_acc=0.9688, running_acc=0.9688, grad=16.2298]Training epoch 32:   2%|▏         | 3/163 [00:07<05:13,  1.96s/it, loss=0.1506, batch_acc=1.0000, running_acc=0.9792, grad=9.9432] Training epoch 32:   2%|▏         | 4/163 [00:10<06:11,  2.34s/it, loss=0.1506, batch_acc=1.0000, running_acc=0.9792, grad=9.9432]Training epoch 32:   2%|▏         | 4/163 [00:10<06:11,  2.34s/it, loss=0.2070, batch_acc=0.9688, running_acc=0.9766, grad=16.0629]Training epoch 32:   3%|▎         | 5/163 [00:11<04:46,  1.81s/it, loss=0.2070, batch_acc=0.9688, running_acc=0.9766, grad=16.0629]Training epoch 32:   3%|▎         | 5/163 [00:11<04:46,  1.81s/it, loss=0.1784, batch_acc=0.9688, running_acc=0.9750, grad=14.8342]Training epoch 32:   4%|▎         | 6/163 [00:12<03:54,  1.50s/it, loss=0.1784, batch_acc=0.9688, running_acc=0.9750, grad=14.8342]Training epoch 32:   4%|▎         | 6/163 [00:12<03:54,  1.50s/it, loss=0.2175, batch_acc=0.9688, running_acc=0.9740, grad=24.7426]Training epoch 32:   4%|▍         | 7/163 [00:13<03:21,  1.29s/it, loss=0.2175, batch_acc=0.9688, running_acc=0.9740, grad=24.7426]Training epoch 32:   4%|▍         | 7/163 [00:13<03:21,  1.29s/it, loss=0.1334, batch_acc=1.0000, running_acc=0.9777, grad=7.8745] Training epoch 32:   5%|▍         | 8/163 [00:15<03:56,  1.53s/it, loss=0.1334, batch_acc=1.0000, running_acc=0.9777, grad=7.8745]Training epoch 32:   5%|▍         | 8/163 [00:15<03:56,  1.53s/it, loss=0.2260, batch_acc=1.0000, running_acc=0.9805, grad=22.7179]Training epoch 32:   6%|▌         | 9/163 [00:15<03:23,  1.32s/it, loss=0.2260, batch_acc=1.0000, running_acc=0.9805, grad=22.7179]Training epoch 32:   6%|▌         | 9/163 [00:15<03:23,  1.32s/it, loss=0.2523, batch_acc=0.9688, running_acc=0.9792, grad=17.6761]Training epoch 32:   6%|▌         | 10/163 [00:16<03:01,  1.19s/it, loss=0.2523, batch_acc=0.9688, running_acc=0.9792, grad=17.6761]Training epoch 32:   6%|▌         | 10/163 [00:16<03:01,  1.19s/it, loss=0.1788, batch_acc=1.0000, running_acc=0.9812, grad=13.5719]Training epoch 32:   7%|▋         | 11/163 [00:17<02:46,  1.09s/it, loss=0.1788, batch_acc=1.0000, running_acc=0.9812, grad=13.5719]Training epoch 32:   7%|▋         | 11/163 [00:17<02:46,  1.09s/it, loss=0.2232, batch_acc=0.9688, running_acc=0.9801, grad=16.9805]Training epoch 32:   7%|▋         | 12/163 [00:19<03:27,  1.37s/it, loss=0.2232, batch_acc=0.9688, running_acc=0.9801, grad=16.9805]Training epoch 32:   7%|▋         | 12/163 [00:19<03:27,  1.37s/it, loss=0.1941, batch_acc=1.0000, running_acc=0.9818, grad=15.0272]Training epoch 32:   8%|▊         | 13/163 [00:20<03:03,  1.22s/it, loss=0.1941, batch_acc=1.0000, running_acc=0.9818, grad=15.0272]Training epoch 32:   8%|▊         | 13/163 [00:20<03:03,  1.22s/it, loss=0.1901, batch_acc=0.9688, running_acc=0.9808, grad=15.6517]Training epoch 32:   9%|▊         | 14/163 [00:21<02:47,  1.12s/it, loss=0.1901, batch_acc=0.9688, running_acc=0.9808, grad=15.6517]Training epoch 32:   9%|▊         | 14/163 [00:21<02:47,  1.12s/it, loss=0.1818, batch_acc=0.9375, running_acc=0.9777, grad=10.0198]Training epoch 32:   9%|▉         | 15/163 [00:22<02:35,  1.05s/it, loss=0.1818, batch_acc=0.9375, running_acc=0.9777, grad=10.0198]Training epoch 32:   9%|▉         | 15/163 [00:22<02:35,  1.05s/it, loss=0.2293, batch_acc=0.9688, running_acc=0.9771, grad=19.3815]Training epoch 32:  10%|▉         | 16/163 [00:23<02:50,  1.16s/it, loss=0.2293, batch_acc=0.9688, running_acc=0.9771, grad=19.3815]Training epoch 32:  10%|▉         | 16/163 [00:23<02:50,  1.16s/it, loss=0.2273, batch_acc=0.9375, running_acc=0.9746, grad=16.3119]Training epoch 32:  10%|█         | 17/163 [00:24<02:36,  1.07s/it, loss=0.2273, batch_acc=0.9375, running_acc=0.9746, grad=16.3119]Training epoch 32:  10%|█         | 17/163 [00:24<02:36,  1.07s/it, loss=0.1141, batch_acc=1.0000, running_acc=0.9761, grad=10.2136]Training epoch 32:  11%|█         | 18/163 [00:25<02:27,  1.02s/it, loss=0.1141, batch_acc=1.0000, running_acc=0.9761, grad=10.2136]Training epoch 32:  11%|█         | 18/163 [00:25<02:27,  1.02s/it, loss=0.1372, batch_acc=1.0000, running_acc=0.9774, grad=12.3562]Training epoch 32:  12%|█▏        | 19/163 [00:26<02:20,  1.02it/s, loss=0.1372, batch_acc=1.0000, running_acc=0.9774, grad=12.3562]Training epoch 32:  12%|█▏        | 19/163 [00:26<02:20,  1.02it/s, loss=0.2104, batch_acc=0.9688, running_acc=0.9770, grad=13.4487]Training epoch 32:  12%|█▏        | 20/163 [00:27<02:34,  1.08s/it, loss=0.2104, batch_acc=0.9688, running_acc=0.9770, grad=13.4487]Training epoch 32:  12%|█▏        | 20/163 [00:27<02:34,  1.08s/it, loss=0.1713, batch_acc=1.0000, running_acc=0.9781, grad=12.7711]Training epoch 32:  13%|█▎        | 21/163 [00:28<02:24,  1.02s/it, loss=0.1713, batch_acc=1.0000, running_acc=0.9781, grad=12.7711]Training epoch 32:  13%|█▎        | 21/163 [00:28<02:24,  1.02s/it, loss=0.1960, batch_acc=0.9375, running_acc=0.9762, grad=14.3762]Training epoch 32:  13%|█▎        | 22/163 [00:29<02:18,  1.02it/s, loss=0.1960, batch_acc=0.9375, running_acc=0.9762, grad=14.3762]Training epoch 32:  13%|█▎        | 22/163 [00:29<02:18,  1.02it/s, loss=0.1922, batch_acc=0.9688, running_acc=0.9759, grad=9.9169] Training epoch 32:  14%|█▍        | 23/163 [00:30<02:12,  1.05it/s, loss=0.1922, batch_acc=0.9688, running_acc=0.9759, grad=9.9169]Training epoch 32:  14%|█▍        | 23/163 [00:30<02:12,  1.05it/s, loss=0.1766, batch_acc=0.9375, running_acc=0.9742, grad=12.9212]Training epoch 32:  15%|█▍        | 24/163 [00:32<02:47,  1.21s/it, loss=0.1766, batch_acc=0.9375, running_acc=0.9742, grad=12.9212]Training epoch 32:  15%|█▍        | 24/163 [00:32<02:47,  1.21s/it, loss=0.2251, batch_acc=1.0000, running_acc=0.9753, grad=14.9618]Training epoch 32:  15%|█▌        | 25/163 [00:33<02:33,  1.11s/it, loss=0.2251, batch_acc=1.0000, running_acc=0.9753, grad=14.9618]Training epoch 32:  15%|█▌        | 25/163 [00:33<02:33,  1.11s/it, loss=0.1483, batch_acc=1.0000, running_acc=0.9762, grad=9.3733] Training epoch 32:  16%|█▌        | 26/163 [00:33<02:22,  1.04s/it, loss=0.1483, batch_acc=1.0000, running_acc=0.9762, grad=9.3733]Training epoch 32:  16%|█▌        | 26/163 [00:33<02:22,  1.04s/it, loss=0.2259, batch_acc=0.9688, running_acc=0.9760, grad=16.0806]Training epoch 32:  17%|█▋        | 27/163 [00:34<02:15,  1.01it/s, loss=0.2259, batch_acc=0.9688, running_acc=0.9760, grad=16.0806]Training epoch 32:  17%|█▋        | 27/163 [00:34<02:15,  1.01it/s, loss=0.1727, batch_acc=1.0000, running_acc=0.9769, grad=14.8023]Training epoch 32:  17%|█▋        | 28/163 [00:36<02:29,  1.11s/it, loss=0.1727, batch_acc=1.0000, running_acc=0.9769, grad=14.8023]Training epoch 32:  17%|█▋        | 28/163 [00:36<02:29,  1.11s/it, loss=0.2843, batch_acc=0.9688, running_acc=0.9766, grad=31.3840]Training epoch 32:  18%|█▊        | 29/163 [00:37<02:19,  1.04s/it, loss=0.2843, batch_acc=0.9688, running_acc=0.9766, grad=31.3840]Training epoch 32:  18%|█▊        | 29/163 [00:37<02:19,  1.04s/it, loss=0.2394, batch_acc=0.9688, running_acc=0.9763, grad=17.0708]Training epoch 32:  18%|█▊        | 30/163 [00:37<02:12,  1.01it/s, loss=0.2394, batch_acc=0.9688, running_acc=0.9763, grad=17.0708]Training epoch 32:  18%|█▊        | 30/163 [00:37<02:12,  1.01it/s, loss=0.1954, batch_acc=0.9688, running_acc=0.9760, grad=10.7998]Training epoch 32:  19%|█▉        | 31/163 [00:38<02:06,  1.04it/s, loss=0.1954, batch_acc=0.9688, running_acc=0.9760, grad=10.7998]Training epoch 32:  19%|█▉        | 31/163 [00:38<02:06,  1.04it/s, loss=0.2168, batch_acc=0.9375, running_acc=0.9748, grad=10.3062]Training epoch 32:  20%|█▉        | 32/163 [00:40<02:20,  1.07s/it, loss=0.2168, batch_acc=0.9375, running_acc=0.9748, grad=10.3062]Training epoch 32:  20%|█▉        | 32/163 [00:40<02:20,  1.07s/it, loss=0.1618, batch_acc=1.0000, running_acc=0.9756, grad=14.6364]Training epoch 32:  20%|██        | 33/163 [00:41<02:11,  1.01s/it, loss=0.1618, batch_acc=1.0000, running_acc=0.9756, grad=14.6364]Training epoch 32:  20%|██        | 33/163 [00:41<02:11,  1.01s/it, loss=0.2122, batch_acc=0.9688, running_acc=0.9754, grad=13.2846]Training epoch 32:  21%|██        | 34/163 [00:41<02:05,  1.03it/s, loss=0.2122, batch_acc=0.9688, running_acc=0.9754, grad=13.2846]Training epoch 32:  21%|██        | 34/163 [00:41<02:05,  1.03it/s, loss=0.2549, batch_acc=0.9062, running_acc=0.9733, grad=10.8255]Training epoch 32:  21%|██▏       | 35/163 [00:42<02:01,  1.06it/s, loss=0.2549, batch_acc=0.9062, running_acc=0.9733, grad=10.8255]Training epoch 32:  21%|██▏       | 35/163 [00:42<02:01,  1.06it/s, loss=0.2140, batch_acc=1.0000, running_acc=0.9741, grad=21.5013]Training epoch 32:  22%|██▏       | 36/163 [00:44<02:36,  1.23s/it, loss=0.2140, batch_acc=1.0000, running_acc=0.9741, grad=21.5013]Training epoch 32:  22%|██▏       | 36/163 [00:44<02:36,  1.23s/it, loss=0.2374, batch_acc=0.9688, running_acc=0.9740, grad=16.3023]Training epoch 32:  23%|██▎       | 37/163 [00:45<02:21,  1.13s/it, loss=0.2374, batch_acc=0.9688, running_acc=0.9740, grad=16.3023]Training epoch 32:  23%|██▎       | 37/163 [00:45<02:21,  1.13s/it, loss=0.1477, batch_acc=1.0000, running_acc=0.9747, grad=13.0625]Training epoch 32:  23%|██▎       | 38/163 [00:46<02:11,  1.05s/it, loss=0.1477, batch_acc=1.0000, running_acc=0.9747, grad=13.0625]Training epoch 32:  23%|██▎       | 38/163 [00:46<02:11,  1.05s/it, loss=0.2565, batch_acc=0.9688, running_acc=0.9745, grad=14.5413]Training epoch 32:  24%|██▍       | 39/163 [00:47<02:04,  1.00s/it, loss=0.2565, batch_acc=0.9688, running_acc=0.9745, grad=14.5413]Training epoch 32:  24%|██▍       | 39/163 [00:47<02:04,  1.00s/it, loss=0.1399, batch_acc=1.0000, running_acc=0.9752, grad=9.5786] Training epoch 32:  25%|██▍       | 40/163 [00:49<02:45,  1.35s/it, loss=0.1399, batch_acc=1.0000, running_acc=0.9752, grad=9.5786]Training epoch 32:  25%|██▍       | 40/163 [00:49<02:45,  1.35s/it, loss=0.2230, batch_acc=0.9688, running_acc=0.9750, grad=17.3538]Training epoch 32:  25%|██▌       | 41/163 [00:50<02:27,  1.21s/it, loss=0.2230, batch_acc=0.9688, running_acc=0.9750, grad=17.3538]Training epoch 32:  25%|██▌       | 41/163 [00:50<02:27,  1.21s/it, loss=0.2186, batch_acc=0.9688, running_acc=0.9748, grad=15.4759]Training epoch 32:  26%|██▌       | 42/163 [00:51<02:14,  1.11s/it, loss=0.2186, batch_acc=0.9688, running_acc=0.9748, grad=15.4759]Training epoch 32:  26%|██▌       | 42/163 [00:51<02:14,  1.11s/it, loss=0.1751, batch_acc=0.9688, running_acc=0.9747, grad=10.3478]Training epoch 32:  26%|██▋       | 43/163 [00:52<02:04,  1.04s/it, loss=0.1751, batch_acc=0.9688, running_acc=0.9747, grad=10.3478]Training epoch 32:  26%|██▋       | 43/163 [00:52<02:04,  1.04s/it, loss=0.2815, batch_acc=0.9375, running_acc=0.9738, grad=20.9003]Training epoch 32:  27%|██▋       | 44/163 [00:53<01:58,  1.01it/s, loss=0.2815, batch_acc=0.9375, running_acc=0.9738, grad=20.9003]Training epoch 32:  27%|██▋       | 44/163 [00:53<01:58,  1.01it/s, loss=0.1823, batch_acc=0.9688, running_acc=0.9737, grad=11.2992]Training epoch 32:  28%|██▊       | 45/163 [00:53<01:53,  1.04it/s, loss=0.1823, batch_acc=0.9688, running_acc=0.9737, grad=11.2992]Training epoch 32:  28%|██▊       | 45/163 [00:53<01:53,  1.04it/s, loss=0.2422, batch_acc=0.9062, running_acc=0.9722, grad=15.0328]Training epoch 32:  28%|██▊       | 46/163 [00:54<01:53,  1.03it/s, loss=0.2422, batch_acc=0.9062, running_acc=0.9722, grad=15.0328]Training epoch 32:  28%|██▊       | 46/163 [00:54<01:53,  1.03it/s, loss=0.1971, batch_acc=0.9688, running_acc=0.9721, grad=17.2498]Training epoch 32:  29%|██▉       | 47/163 [00:55<01:49,  1.06it/s, loss=0.1971, batch_acc=0.9688, running_acc=0.9721, grad=17.2498]Training epoch 32:  29%|██▉       | 47/163 [00:55<01:49,  1.06it/s, loss=0.2039, batch_acc=1.0000, running_acc=0.9727, grad=16.6329]Training epoch 32:  29%|██▉       | 48/163 [00:57<02:15,  1.18s/it, loss=0.2039, batch_acc=1.0000, running_acc=0.9727, grad=16.6329]Training epoch 32:  29%|██▉       | 48/163 [00:57<02:15,  1.18s/it, loss=0.1628, batch_acc=1.0000, running_acc=0.9733, grad=13.0993]Training epoch 32:  30%|███       | 49/163 [00:58<02:04,  1.09s/it, loss=0.1628, batch_acc=1.0000, running_acc=0.9733, grad=13.0993]Training epoch 32:  30%|███       | 49/163 [00:58<02:04,  1.09s/it, loss=0.2086, batch_acc=0.9688, running_acc=0.9732, grad=16.1935]Training epoch 32:  31%|███       | 50/163 [00:59<01:56,  1.03s/it, loss=0.2086, batch_acc=0.9688, running_acc=0.9732, grad=16.1935]Training epoch 32:  31%|███       | 50/163 [00:59<01:56,  1.03s/it, loss=0.1612, batch_acc=0.9688, running_acc=0.9731, grad=9.7402] Training epoch 32:  31%|███▏      | 51/163 [01:00<01:50,  1.02it/s, loss=0.1612, batch_acc=0.9688, running_acc=0.9731, grad=9.7402]Training epoch 32:  31%|███▏      | 51/163 [01:00<01:50,  1.02it/s, loss=0.1753, batch_acc=1.0000, running_acc=0.9737, grad=11.6234]Training epoch 32:  32%|███▏      | 52/163 [01:01<01:55,  1.04s/it, loss=0.1753, batch_acc=1.0000, running_acc=0.9737, grad=11.6234]Training epoch 32:  32%|███▏      | 52/163 [01:01<01:55,  1.04s/it, loss=0.1406, batch_acc=1.0000, running_acc=0.9742, grad=13.4384]Training epoch 32:  33%|███▎      | 53/163 [01:02<01:48,  1.01it/s, loss=0.1406, batch_acc=1.0000, running_acc=0.9742, grad=13.4384]Training epoch 32:  33%|███▎      | 53/163 [01:02<01:48,  1.01it/s, loss=0.1924, batch_acc=0.9688, running_acc=0.9741, grad=15.4728]Training epoch 32:  33%|███▎      | 54/163 [01:03<01:44,  1.04it/s, loss=0.1924, batch_acc=0.9688, running_acc=0.9741, grad=15.4728]Training epoch 32:  33%|███▎      | 54/163 [01:03<01:44,  1.04it/s, loss=0.1627, batch_acc=0.9688, running_acc=0.9740, grad=10.5841]Training epoch 32:  34%|███▎      | 55/163 [01:03<01:40,  1.07it/s, loss=0.1627, batch_acc=0.9688, running_acc=0.9740, grad=10.5841]Training epoch 32:  34%|███▎      | 55/163 [01:03<01:40,  1.07it/s, loss=0.2448, batch_acc=0.9688, running_acc=0.9739, grad=18.1992]Training epoch 32:  34%|███▍      | 56/163 [01:05<02:09,  1.21s/it, loss=0.2448, batch_acc=0.9688, running_acc=0.9739, grad=18.1992]Training epoch 32:  34%|███▍      | 56/163 [01:05<02:09,  1.21s/it, loss=0.2162, batch_acc=1.0000, running_acc=0.9743, grad=22.4805]Training epoch 32:  35%|███▍      | 57/163 [01:06<01:57,  1.11s/it, loss=0.2162, batch_acc=1.0000, running_acc=0.9743, grad=22.4805]Training epoch 32:  35%|███▍      | 57/163 [01:06<01:57,  1.11s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9742, grad=18.7713]Training epoch 32:  36%|███▌      | 58/163 [01:07<01:49,  1.04s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9742, grad=18.7713]Training epoch 32:  36%|███▌      | 58/163 [01:07<01:49,  1.04s/it, loss=0.1826, batch_acc=0.9688, running_acc=0.9741, grad=11.5176]Training epoch 32:  36%|███▌      | 59/163 [01:08<01:43,  1.01it/s, loss=0.1826, batch_acc=0.9688, running_acc=0.9741, grad=11.5176]Training epoch 32:  36%|███▌      | 59/163 [01:08<01:43,  1.01it/s, loss=0.2805, batch_acc=0.9688, running_acc=0.9740, grad=27.6986]Training epoch 32:  37%|███▋      | 60/163 [01:10<02:01,  1.18s/it, loss=0.2805, batch_acc=0.9688, running_acc=0.9740, grad=27.6986]Training epoch 32:  37%|███▋      | 60/163 [01:10<02:01,  1.18s/it, loss=0.2923, batch_acc=0.9062, running_acc=0.9729, grad=20.5520]Training epoch 32:  37%|███▋      | 61/163 [01:10<01:50,  1.09s/it, loss=0.2923, batch_acc=0.9062, running_acc=0.9729, grad=20.5520]Training epoch 32:  37%|███▋      | 61/163 [01:10<01:50,  1.09s/it, loss=0.2152, batch_acc=1.0000, running_acc=0.9734, grad=14.5218]Training epoch 32:  38%|███▊      | 62/163 [01:11<01:43,  1.03s/it, loss=0.2152, batch_acc=1.0000, running_acc=0.9734, grad=14.5218]Training epoch 32:  38%|███▊      | 62/163 [01:11<01:43,  1.03s/it, loss=0.1934, batch_acc=1.0000, running_acc=0.9738, grad=13.8096]Training epoch 32:  39%|███▊      | 63/163 [01:12<01:38,  1.02it/s, loss=0.1934, batch_acc=1.0000, running_acc=0.9738, grad=13.8096]Training epoch 32:  39%|███▊      | 63/163 [01:12<01:38,  1.02it/s, loss=0.1260, batch_acc=1.0000, running_acc=0.9742, grad=11.0678]Training epoch 32:  39%|███▉      | 64/163 [01:14<01:52,  1.14s/it, loss=0.1260, batch_acc=1.0000, running_acc=0.9742, grad=11.0678]Training epoch 32:  39%|███▉      | 64/163 [01:14<01:52,  1.14s/it, loss=0.2003, batch_acc=1.0000, running_acc=0.9746, grad=15.9968]Training epoch 32:  40%|███▉      | 65/163 [01:15<01:44,  1.06s/it, loss=0.2003, batch_acc=1.0000, running_acc=0.9746, grad=15.9968]Training epoch 32:  40%|███▉      | 65/163 [01:15<01:44,  1.06s/it, loss=0.2025, batch_acc=0.9688, running_acc=0.9745, grad=15.2228]Training epoch 32:  40%|████      | 66/163 [01:15<01:37,  1.01s/it, loss=0.2025, batch_acc=0.9688, running_acc=0.9745, grad=15.2228]Training epoch 32:  40%|████      | 66/163 [01:15<01:37,  1.01s/it, loss=0.1366, batch_acc=1.0000, running_acc=0.9749, grad=15.7017]Training epoch 32:  41%|████      | 67/163 [01:16<01:33,  1.03it/s, loss=0.1366, batch_acc=1.0000, running_acc=0.9749, grad=15.7017]Training epoch 32:  41%|████      | 67/163 [01:16<01:33,  1.03it/s, loss=0.3254, batch_acc=0.9062, running_acc=0.9739, grad=20.6167]Training epoch 32:  42%|████▏     | 68/163 [01:18<01:58,  1.25s/it, loss=0.3254, batch_acc=0.9062, running_acc=0.9739, grad=20.6167]Training epoch 32:  42%|████▏     | 68/163 [01:18<01:58,  1.25s/it, loss=0.1210, batch_acc=1.0000, running_acc=0.9743, grad=10.7894]Training epoch 32:  42%|████▏     | 69/163 [01:19<01:46,  1.14s/it, loss=0.1210, batch_acc=1.0000, running_acc=0.9743, grad=10.7894]Training epoch 32:  42%|████▏     | 69/163 [01:19<01:46,  1.14s/it, loss=0.2297, batch_acc=0.9688, running_acc=0.9742, grad=14.4242]Training epoch 32:  43%|████▎     | 70/163 [01:20<01:38,  1.06s/it, loss=0.2297, batch_acc=0.9688, running_acc=0.9742, grad=14.4242]Training epoch 32:  43%|████▎     | 70/163 [01:20<01:38,  1.06s/it, loss=0.1737, batch_acc=1.0000, running_acc=0.9746, grad=12.8154]Training epoch 32:  44%|████▎     | 71/163 [01:21<01:32,  1.01s/it, loss=0.1737, batch_acc=1.0000, running_acc=0.9746, grad=12.8154]Training epoch 32:  44%|████▎     | 71/163 [01:21<01:32,  1.01s/it, loss=0.2332, batch_acc=0.9688, running_acc=0.9745, grad=24.7436]Training epoch 32:  44%|████▍     | 72/163 [01:22<01:35,  1.05s/it, loss=0.2332, batch_acc=0.9688, running_acc=0.9745, grad=24.7436]Training epoch 32:  44%|████▍     | 72/163 [01:22<01:35,  1.05s/it, loss=0.1428, batch_acc=1.0000, running_acc=0.9748, grad=10.8942]Training epoch 32:  45%|████▍     | 73/163 [01:23<01:29,  1.00it/s, loss=0.1428, batch_acc=1.0000, running_acc=0.9748, grad=10.8942]Training epoch 32:  45%|████▍     | 73/163 [01:23<01:29,  1.00it/s, loss=0.2099, batch_acc=0.9688, running_acc=0.9747, grad=13.9740]Training epoch 32:  45%|████▌     | 74/163 [01:24<01:38,  1.11s/it, loss=0.2099, batch_acc=0.9688, running_acc=0.9747, grad=13.9740]Training epoch 32:  45%|████▌     | 74/163 [01:24<01:38,  1.11s/it, loss=0.2428, batch_acc=1.0000, running_acc=0.9751, grad=19.7842]Training epoch 32:  46%|████▌     | 75/163 [01:25<01:31,  1.04s/it, loss=0.2428, batch_acc=1.0000, running_acc=0.9751, grad=19.7842]Training epoch 32:  46%|████▌     | 75/163 [01:25<01:31,  1.04s/it, loss=0.1583, batch_acc=1.0000, running_acc=0.9754, grad=16.0997]Training epoch 32:  47%|████▋     | 76/163 [01:26<01:28,  1.01s/it, loss=0.1583, batch_acc=1.0000, running_acc=0.9754, grad=16.0997]Training epoch 32:  47%|████▋     | 76/163 [01:26<01:28,  1.01s/it, loss=0.1812, batch_acc=0.9688, running_acc=0.9753, grad=14.8115]Training epoch 32:  47%|████▋     | 77/163 [01:27<01:23,  1.03it/s, loss=0.1812, batch_acc=0.9688, running_acc=0.9753, grad=14.8115]Training epoch 32:  47%|████▋     | 77/163 [01:27<01:23,  1.03it/s, loss=0.2184, batch_acc=1.0000, running_acc=0.9756, grad=16.1980]Training epoch 32:  48%|████▊     | 78/163 [01:29<01:41,  1.19s/it, loss=0.2184, batch_acc=1.0000, running_acc=0.9756, grad=16.1980]Training epoch 32:  48%|████▊     | 78/163 [01:29<01:41,  1.19s/it, loss=0.1849, batch_acc=1.0000, running_acc=0.9760, grad=17.5819]Training epoch 32:  48%|████▊     | 79/163 [01:30<01:32,  1.10s/it, loss=0.1849, batch_acc=1.0000, running_acc=0.9760, grad=17.5819]Training epoch 32:  48%|████▊     | 79/163 [01:30<01:32,  1.10s/it, loss=0.1575, batch_acc=1.0000, running_acc=0.9763, grad=12.4334]Training epoch 32:  49%|████▉     | 80/163 [01:30<01:25,  1.03s/it, loss=0.1575, batch_acc=1.0000, running_acc=0.9763, grad=12.4334]Training epoch 32:  49%|████▉     | 80/163 [01:30<01:25,  1.03s/it, loss=0.1268, batch_acc=1.0000, running_acc=0.9766, grad=9.5790] Training epoch 32:  50%|████▉     | 81/163 [01:31<01:20,  1.01it/s, loss=0.1268, batch_acc=1.0000, running_acc=0.9766, grad=9.5790]Training epoch 32:  50%|████▉     | 81/163 [01:31<01:20,  1.01it/s, loss=0.2499, batch_acc=0.9688, running_acc=0.9765, grad=17.7187]Training epoch 32:  50%|█████     | 82/163 [01:33<01:39,  1.22s/it, loss=0.2499, batch_acc=0.9688, running_acc=0.9765, grad=17.7187]Training epoch 32:  50%|█████     | 82/163 [01:33<01:39,  1.22s/it, loss=0.3075, batch_acc=0.8750, running_acc=0.9752, grad=24.2057]Training epoch 32:  51%|█████     | 83/163 [01:34<01:29,  1.12s/it, loss=0.3075, batch_acc=0.8750, running_acc=0.9752, grad=24.2057]Training epoch 32:  51%|█████     | 83/163 [01:34<01:29,  1.12s/it, loss=0.1426, batch_acc=1.0000, running_acc=0.9755, grad=12.6243]Training epoch 32:  52%|█████▏    | 84/163 [01:35<01:22,  1.05s/it, loss=0.1426, batch_acc=1.0000, running_acc=0.9755, grad=12.6243]Training epoch 32:  52%|█████▏    | 84/163 [01:35<01:22,  1.05s/it, loss=0.1681, batch_acc=0.9688, running_acc=0.9754, grad=10.0186]Training epoch 32:  52%|█████▏    | 85/163 [01:36<01:17,  1.00it/s, loss=0.1681, batch_acc=0.9688, running_acc=0.9754, grad=10.0186]Training epoch 32:  52%|█████▏    | 85/163 [01:36<01:17,  1.00it/s, loss=0.1814, batch_acc=0.9688, running_acc=0.9754, grad=13.8547]Training epoch 32:  53%|█████▎    | 86/163 [01:37<01:22,  1.07s/it, loss=0.1814, batch_acc=0.9688, running_acc=0.9754, grad=13.8547]Training epoch 32:  53%|█████▎    | 86/163 [01:37<01:22,  1.07s/it, loss=0.1745, batch_acc=1.0000, running_acc=0.9757, grad=12.1364]Training epoch 32:  53%|█████▎    | 87/163 [01:38<01:16,  1.01s/it, loss=0.1745, batch_acc=1.0000, running_acc=0.9757, grad=12.1364]Training epoch 32:  53%|█████▎    | 87/163 [01:38<01:16,  1.01s/it, loss=0.2184, batch_acc=0.9688, running_acc=0.9756, grad=15.7771]Training epoch 32:  54%|█████▍    | 88/163 [01:39<01:12,  1.03it/s, loss=0.2184, batch_acc=0.9688, running_acc=0.9756, grad=15.7771]Training epoch 32:  54%|█████▍    | 88/163 [01:39<01:12,  1.03it/s, loss=0.1794, batch_acc=0.9688, running_acc=0.9755, grad=18.8439]Training epoch 32:  55%|█████▍    | 89/163 [01:40<01:09,  1.06it/s, loss=0.1794, batch_acc=0.9688, running_acc=0.9755, grad=18.8439]Training epoch 32:  55%|█████▍    | 89/163 [01:40<01:09,  1.06it/s, loss=0.2913, batch_acc=0.9688, running_acc=0.9754, grad=19.4298]Training epoch 32:  55%|█████▌    | 90/163 [01:41<01:23,  1.15s/it, loss=0.2913, batch_acc=0.9688, running_acc=0.9754, grad=19.4298]Training epoch 32:  55%|█████▌    | 90/163 [01:41<01:23,  1.15s/it, loss=0.2012, batch_acc=1.0000, running_acc=0.9757, grad=18.9997]Training epoch 32:  56%|█████▌    | 91/163 [01:42<01:16,  1.07s/it, loss=0.2012, batch_acc=1.0000, running_acc=0.9757, grad=18.9997]Training epoch 32:  56%|█████▌    | 91/163 [01:42<01:16,  1.07s/it, loss=0.1955, batch_acc=1.0000, running_acc=0.9760, grad=13.6893]Training epoch 32:  56%|█████▋    | 92/163 [01:43<01:11,  1.01s/it, loss=0.1955, batch_acc=1.0000, running_acc=0.9760, grad=13.6893]Training epoch 32:  56%|█████▋    | 92/163 [01:43<01:11,  1.01s/it, loss=0.2284, batch_acc=0.9688, running_acc=0.9759, grad=20.8653]Training epoch 32:  57%|█████▋    | 93/163 [01:44<01:08,  1.03it/s, loss=0.2284, batch_acc=0.9688, running_acc=0.9759, grad=20.8653]Training epoch 32:  57%|█████▋    | 93/163 [01:44<01:08,  1.03it/s, loss=0.2026, batch_acc=0.9688, running_acc=0.9758, grad=16.5691]Training epoch 32:  58%|█████▊    | 94/163 [01:46<01:20,  1.17s/it, loss=0.2026, batch_acc=0.9688, running_acc=0.9758, grad=16.5691]Training epoch 32:  58%|█████▊    | 94/163 [01:46<01:20,  1.17s/it, loss=0.1729, batch_acc=0.9688, running_acc=0.9757, grad=15.4820]Training epoch 32:  58%|█████▊    | 95/163 [01:47<01:15,  1.11s/it, loss=0.1729, batch_acc=0.9688, running_acc=0.9757, grad=15.4820]Training epoch 32:  58%|█████▊    | 95/163 [01:47<01:15,  1.11s/it, loss=0.1528, batch_acc=1.0000, running_acc=0.9760, grad=12.1471]Training epoch 32:  59%|█████▉    | 96/163 [01:47<01:09,  1.04s/it, loss=0.1528, batch_acc=1.0000, running_acc=0.9760, grad=12.1471]Training epoch 32:  59%|█████▉    | 96/163 [01:47<01:09,  1.04s/it, loss=0.2960, batch_acc=0.9375, running_acc=0.9756, grad=22.8072]Training epoch 32:  60%|█████▉    | 97/163 [01:48<01:05,  1.01it/s, loss=0.2960, batch_acc=0.9375, running_acc=0.9756, grad=22.8072]Training epoch 32:  60%|█████▉    | 97/163 [01:48<01:05,  1.01it/s, loss=0.2765, batch_acc=0.9688, running_acc=0.9755, grad=22.5704]Training epoch 32:  60%|██████    | 98/163 [01:50<01:13,  1.13s/it, loss=0.2765, batch_acc=0.9688, running_acc=0.9755, grad=22.5704]Training epoch 32:  60%|██████    | 98/163 [01:50<01:13,  1.13s/it, loss=0.1392, batch_acc=1.0000, running_acc=0.9758, grad=11.3445]Training epoch 32:  61%|██████    | 99/163 [01:51<01:07,  1.06s/it, loss=0.1392, batch_acc=1.0000, running_acc=0.9758, grad=11.3445]Training epoch 32:  61%|██████    | 99/163 [01:51<01:07,  1.06s/it, loss=0.1746, batch_acc=0.9688, running_acc=0.9757, grad=18.1329]Training epoch 32:  61%|██████▏   | 100/163 [01:52<01:13,  1.16s/it, loss=0.1746, batch_acc=0.9688, running_acc=0.9757, grad=18.1329]Training epoch 32:  61%|██████▏   | 100/163 [01:52<01:13,  1.16s/it, loss=0.1639, batch_acc=1.0000, running_acc=0.9759, grad=16.6812]Training epoch 32:  62%|██████▏   | 101/163 [01:53<01:06,  1.08s/it, loss=0.1639, batch_acc=1.0000, running_acc=0.9759, grad=16.6812]Training epoch 32:  62%|██████▏   | 101/163 [01:53<01:06,  1.08s/it, loss=0.1949, batch_acc=0.9688, running_acc=0.9759, grad=12.0758]Training epoch 32:  63%|██████▎   | 102/163 [01:54<01:02,  1.02s/it, loss=0.1949, batch_acc=0.9688, running_acc=0.9759, grad=12.0758]Training epoch 32:  63%|██████▎   | 102/163 [01:54<01:02,  1.02s/it, loss=0.1391, batch_acc=1.0000, running_acc=0.9761, grad=12.2500]Training epoch 32:  63%|██████▎   | 103/163 [01:55<01:00,  1.00s/it, loss=0.1391, batch_acc=1.0000, running_acc=0.9761, grad=12.2500]Training epoch 32:  63%|██████▎   | 103/163 [01:55<01:00,  1.00s/it, loss=0.3171, batch_acc=0.9375, running_acc=0.9757, grad=20.8243]Training epoch 32:  64%|██████▍   | 104/163 [01:56<01:11,  1.22s/it, loss=0.3171, batch_acc=0.9375, running_acc=0.9757, grad=20.8243]Training epoch 32:  64%|██████▍   | 104/163 [01:56<01:11,  1.22s/it, loss=0.2287, batch_acc=0.9688, running_acc=0.9757, grad=14.8660]Training epoch 32:  64%|██████▍   | 105/163 [01:57<01:04,  1.12s/it, loss=0.2287, batch_acc=0.9688, running_acc=0.9757, grad=14.8660]Training epoch 32:  64%|██████▍   | 105/163 [01:57<01:04,  1.12s/it, loss=0.1706, batch_acc=0.9688, running_acc=0.9756, grad=14.8749]Training epoch 32:  65%|██████▌   | 106/163 [01:58<00:59,  1.05s/it, loss=0.1706, batch_acc=0.9688, running_acc=0.9756, grad=14.8749]Training epoch 32:  65%|██████▌   | 106/163 [01:58<00:59,  1.05s/it, loss=0.2582, batch_acc=0.9375, running_acc=0.9752, grad=14.4297]Training epoch 32:  66%|██████▌   | 107/163 [01:59<00:55,  1.00it/s, loss=0.2582, batch_acc=0.9375, running_acc=0.9752, grad=14.4297]Training epoch 32:  66%|██████▌   | 107/163 [01:59<00:55,  1.00it/s, loss=0.1285, batch_acc=1.0000, running_acc=0.9755, grad=8.5244] Training epoch 32:  66%|██████▋   | 108/163 [02:01<01:17,  1.41s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9755, grad=8.5244]Training epoch 32:  66%|██████▋   | 108/163 [02:01<01:17,  1.41s/it, loss=0.2473, batch_acc=0.9062, running_acc=0.9748, grad=15.3407]Training epoch 32:  67%|██████▋   | 109/163 [02:02<01:07,  1.25s/it, loss=0.2473, batch_acc=0.9062, running_acc=0.9748, grad=15.3407]Training epoch 32:  67%|██████▋   | 109/163 [02:02<01:07,  1.25s/it, loss=0.1392, batch_acc=1.0000, running_acc=0.9751, grad=9.8962] Training epoch 32:  67%|██████▋   | 110/163 [02:03<01:00,  1.14s/it, loss=0.1392, batch_acc=1.0000, running_acc=0.9751, grad=9.8962]Training epoch 32:  67%|██████▋   | 110/163 [02:03<01:00,  1.14s/it, loss=0.2486, batch_acc=0.9688, running_acc=0.9750, grad=19.8827]Training epoch 32:  68%|██████▊   | 111/163 [02:04<00:55,  1.06s/it, loss=0.2486, batch_acc=0.9688, running_acc=0.9750, grad=19.8827]Training epoch 32:  68%|██████▊   | 111/163 [02:04<00:55,  1.06s/it, loss=0.1214, batch_acc=1.0000, running_acc=0.9752, grad=8.1655] Training epoch 32:  69%|██████▊   | 112/163 [02:06<01:02,  1.23s/it, loss=0.1214, batch_acc=1.0000, running_acc=0.9752, grad=8.1655]Training epoch 32:  69%|██████▊   | 112/163 [02:06<01:02,  1.23s/it, loss=0.2793, batch_acc=0.9375, running_acc=0.9749, grad=16.9849]Training epoch 32:  69%|██████▉   | 113/163 [02:07<00:56,  1.13s/it, loss=0.2793, batch_acc=0.9375, running_acc=0.9749, grad=16.9849]Training epoch 32:  69%|██████▉   | 113/163 [02:07<00:56,  1.13s/it, loss=0.2115, batch_acc=1.0000, running_acc=0.9751, grad=12.9196]Training epoch 32:  70%|██████▉   | 114/163 [02:08<00:52,  1.08s/it, loss=0.2115, batch_acc=1.0000, running_acc=0.9751, grad=12.9196]Training epoch 32:  70%|██████▉   | 114/163 [02:08<00:52,  1.08s/it, loss=0.1713, batch_acc=0.9688, running_acc=0.9751, grad=16.1280]Training epoch 32:  71%|███████   | 115/163 [02:08<00:49,  1.02s/it, loss=0.1713, batch_acc=0.9688, running_acc=0.9751, grad=16.1280]Training epoch 32:  71%|███████   | 115/163 [02:08<00:49,  1.02s/it, loss=0.2579, batch_acc=0.9688, running_acc=0.9750, grad=14.8062]Training epoch 32:  71%|███████   | 116/163 [02:11<01:03,  1.34s/it, loss=0.2579, batch_acc=0.9688, running_acc=0.9750, grad=14.8062]Training epoch 32:  71%|███████   | 116/163 [02:11<01:03,  1.34s/it, loss=0.1374, batch_acc=1.0000, running_acc=0.9752, grad=9.3606] Training epoch 32:  72%|███████▏  | 117/163 [02:11<00:55,  1.20s/it, loss=0.1374, batch_acc=1.0000, running_acc=0.9752, grad=9.3606]Training epoch 32:  72%|███████▏  | 117/163 [02:11<00:55,  1.20s/it, loss=0.2885, batch_acc=0.9688, running_acc=0.9752, grad=25.1701]Training epoch 32:  72%|███████▏  | 118/163 [02:12<00:49,  1.11s/it, loss=0.2885, batch_acc=0.9688, running_acc=0.9752, grad=25.1701]Training epoch 32:  72%|███████▏  | 118/163 [02:12<00:49,  1.11s/it, loss=0.2009, batch_acc=1.0000, running_acc=0.9754, grad=16.0901]Training epoch 32:  73%|███████▎  | 119/163 [02:13<00:45,  1.04s/it, loss=0.2009, batch_acc=1.0000, running_acc=0.9754, grad=16.0901]Training epoch 32:  73%|███████▎  | 119/163 [02:13<00:45,  1.04s/it, loss=0.3021, batch_acc=0.8750, running_acc=0.9745, grad=19.4553]Training epoch 32:  74%|███████▎  | 120/163 [02:15<00:58,  1.36s/it, loss=0.3021, batch_acc=0.8750, running_acc=0.9745, grad=19.4553]Training epoch 32:  74%|███████▎  | 120/163 [02:15<00:58,  1.36s/it, loss=0.2036, batch_acc=0.9375, running_acc=0.9742, grad=21.0370]Training epoch 32:  74%|███████▍  | 121/163 [02:16<00:51,  1.22s/it, loss=0.2036, batch_acc=0.9375, running_acc=0.9742, grad=21.0370]Training epoch 32:  74%|███████▍  | 121/163 [02:16<00:51,  1.22s/it, loss=0.1258, batch_acc=1.0000, running_acc=0.9744, grad=9.5129] Training epoch 32:  75%|███████▍  | 122/163 [02:17<00:45,  1.12s/it, loss=0.1258, batch_acc=1.0000, running_acc=0.9744, grad=9.5129]Training epoch 32:  75%|███████▍  | 122/163 [02:17<00:45,  1.12s/it, loss=0.1675, batch_acc=0.9688, running_acc=0.9744, grad=8.6423]Training epoch 32:  75%|███████▌  | 123/163 [02:18<00:41,  1.05s/it, loss=0.1675, batch_acc=0.9688, running_acc=0.9744, grad=8.6423]Training epoch 32:  75%|███████▌  | 123/163 [02:18<00:41,  1.05s/it, loss=0.1993, batch_acc=1.0000, running_acc=0.9746, grad=16.6874]Training epoch 32:  76%|███████▌  | 124/163 [02:20<00:48,  1.24s/it, loss=0.1993, batch_acc=1.0000, running_acc=0.9746, grad=16.6874]Training epoch 32:  76%|███████▌  | 124/163 [02:20<00:48,  1.24s/it, loss=0.2121, batch_acc=0.9688, running_acc=0.9745, grad=26.0330]Training epoch 32:  77%|███████▋  | 125/163 [02:21<00:42,  1.13s/it, loss=0.2121, batch_acc=0.9688, running_acc=0.9745, grad=26.0330]Training epoch 32:  77%|███████▋  | 125/163 [02:21<00:42,  1.13s/it, loss=0.2099, batch_acc=0.9688, running_acc=0.9745, grad=13.5526]Training epoch 32:  77%|███████▋  | 126/163 [02:21<00:39,  1.05s/it, loss=0.2099, batch_acc=0.9688, running_acc=0.9745, grad=13.5526]Training epoch 32:  77%|███████▋  | 126/163 [02:21<00:39,  1.05s/it, loss=0.1291, batch_acc=1.0000, running_acc=0.9747, grad=10.4899]Training epoch 32:  78%|███████▊  | 127/163 [02:22<00:36,  1.00s/it, loss=0.1291, batch_acc=1.0000, running_acc=0.9747, grad=10.4899]Training epoch 32:  78%|███████▊  | 127/163 [02:22<00:36,  1.00s/it, loss=0.2136, batch_acc=0.9375, running_acc=0.9744, grad=12.6339]Training epoch 32:  79%|███████▊  | 128/163 [02:24<00:43,  1.25s/it, loss=0.2136, batch_acc=0.9375, running_acc=0.9744, grad=12.6339]Training epoch 32:  79%|███████▊  | 128/163 [02:24<00:43,  1.25s/it, loss=0.1379, batch_acc=1.0000, running_acc=0.9746, grad=10.1765]Training epoch 32:  79%|███████▉  | 129/163 [02:25<00:38,  1.14s/it, loss=0.1379, batch_acc=1.0000, running_acc=0.9746, grad=10.1765]Training epoch 32:  79%|███████▉  | 129/163 [02:25<00:38,  1.14s/it, loss=0.1768, batch_acc=0.9688, running_acc=0.9746, grad=11.1724]Training epoch 32:  80%|███████▉  | 130/163 [02:26<00:35,  1.06s/it, loss=0.1768, batch_acc=0.9688, running_acc=0.9746, grad=11.1724]Training epoch 32:  80%|███████▉  | 130/163 [02:26<00:35,  1.06s/it, loss=0.2900, batch_acc=0.9375, running_acc=0.9743, grad=20.0899]Training epoch 32:  80%|████████  | 131/163 [02:27<00:32,  1.01s/it, loss=0.2900, batch_acc=0.9375, running_acc=0.9743, grad=20.0899]Training epoch 32:  80%|████████  | 131/163 [02:27<00:32,  1.01s/it, loss=0.2114, batch_acc=1.0000, running_acc=0.9745, grad=17.9962]Training epoch 32:  81%|████████  | 132/163 [02:28<00:34,  1.10s/it, loss=0.2114, batch_acc=1.0000, running_acc=0.9745, grad=17.9962]Training epoch 32:  81%|████████  | 132/163 [02:28<00:34,  1.10s/it, loss=0.2820, batch_acc=0.9688, running_acc=0.9744, grad=18.8739]Training epoch 32:  82%|████████▏ | 133/163 [02:29<00:31,  1.03s/it, loss=0.2820, batch_acc=0.9688, running_acc=0.9744, grad=18.8739]Training epoch 32:  82%|████████▏ | 133/163 [02:29<00:31,  1.03s/it, loss=0.2209, batch_acc=0.9688, running_acc=0.9744, grad=18.1495]Training epoch 32:  82%|████████▏ | 134/163 [02:30<00:28,  1.01it/s, loss=0.2209, batch_acc=0.9688, running_acc=0.9744, grad=18.1495]Training epoch 32:  82%|████████▏ | 134/163 [02:30<00:28,  1.01it/s, loss=0.1633, batch_acc=1.0000, running_acc=0.9746, grad=13.4859]Training epoch 32:  83%|████████▎ | 135/163 [02:31<00:26,  1.05it/s, loss=0.1633, batch_acc=1.0000, running_acc=0.9746, grad=13.4859]Training epoch 32:  83%|████████▎ | 135/163 [02:31<00:26,  1.05it/s, loss=0.2216, batch_acc=0.9688, running_acc=0.9745, grad=14.6197]Training epoch 32:  83%|████████▎ | 136/163 [02:33<00:35,  1.32s/it, loss=0.2216, batch_acc=0.9688, running_acc=0.9745, grad=14.6197]Training epoch 32:  83%|████████▎ | 136/163 [02:33<00:35,  1.32s/it, loss=0.1296, batch_acc=1.0000, running_acc=0.9747, grad=8.8967] Training epoch 32:  84%|████████▍ | 137/163 [02:34<00:30,  1.19s/it, loss=0.1296, batch_acc=1.0000, running_acc=0.9747, grad=8.8967]Training epoch 32:  84%|████████▍ | 137/163 [02:34<00:30,  1.19s/it, loss=0.2247, batch_acc=1.0000, running_acc=0.9749, grad=15.5092]Training epoch 32:  85%|████████▍ | 138/163 [02:35<00:27,  1.10s/it, loss=0.2247, batch_acc=1.0000, running_acc=0.9749, grad=15.5092]Training epoch 32:  85%|████████▍ | 138/163 [02:35<00:27,  1.10s/it, loss=0.1986, batch_acc=0.9688, running_acc=0.9749, grad=17.8513]Training epoch 32:  85%|████████▌ | 139/163 [02:36<00:24,  1.03s/it, loss=0.1986, batch_acc=0.9688, running_acc=0.9749, grad=17.8513]Training epoch 32:  85%|████████▌ | 139/163 [02:36<00:24,  1.03s/it, loss=0.1739, batch_acc=1.0000, running_acc=0.9750, grad=15.2946]Training epoch 32:  86%|████████▌ | 140/163 [02:37<00:28,  1.22s/it, loss=0.1739, batch_acc=1.0000, running_acc=0.9750, grad=15.2946]Training epoch 32:  86%|████████▌ | 140/163 [02:37<00:28,  1.22s/it, loss=0.2469, batch_acc=0.9688, running_acc=0.9750, grad=15.1622]Training epoch 32:  87%|████████▋ | 141/163 [02:38<00:24,  1.12s/it, loss=0.2469, batch_acc=0.9688, running_acc=0.9750, grad=15.1622]Training epoch 32:  87%|████████▋ | 141/163 [02:38<00:24,  1.12s/it, loss=0.3115, batch_acc=0.9375, running_acc=0.9747, grad=16.4185]Training epoch 32:  87%|████████▋ | 142/163 [02:39<00:22,  1.05s/it, loss=0.3115, batch_acc=0.9375, running_acc=0.9747, grad=16.4185]Training epoch 32:  87%|████████▋ | 142/163 [02:39<00:22,  1.05s/it, loss=0.1410, batch_acc=1.0000, running_acc=0.9749, grad=11.8496]Training epoch 32:  88%|████████▊ | 143/163 [02:40<00:19,  1.00it/s, loss=0.1410, batch_acc=1.0000, running_acc=0.9749, grad=11.8496]Training epoch 32:  88%|████████▊ | 143/163 [02:40<00:19,  1.00it/s, loss=0.1910, batch_acc=0.9688, running_acc=0.9749, grad=12.2294]Training epoch 32:  88%|████████▊ | 144/163 [02:41<00:21,  1.15s/it, loss=0.1910, batch_acc=0.9688, running_acc=0.9749, grad=12.2294]Training epoch 32:  88%|████████▊ | 144/163 [02:41<00:21,  1.15s/it, loss=0.1889, batch_acc=1.0000, running_acc=0.9750, grad=14.1732]Training epoch 32:  89%|████████▉ | 145/163 [02:42<00:19,  1.07s/it, loss=0.1889, batch_acc=1.0000, running_acc=0.9750, grad=14.1732]Training epoch 32:  89%|████████▉ | 145/163 [02:42<00:19,  1.07s/it, loss=0.2335, batch_acc=1.0000, running_acc=0.9752, grad=16.1223]Training epoch 32:  90%|████████▉ | 146/163 [02:43<00:17,  1.01s/it, loss=0.2335, batch_acc=1.0000, running_acc=0.9752, grad=16.1223]Training epoch 32:  90%|████████▉ | 146/163 [02:43<00:17,  1.01s/it, loss=0.1865, batch_acc=0.9688, running_acc=0.9752, grad=13.4613]Training epoch 32:  90%|█████████ | 147/163 [02:44<00:15,  1.03it/s, loss=0.1865, batch_acc=0.9688, running_acc=0.9752, grad=13.4613]Training epoch 32:  90%|█████████ | 147/163 [02:44<00:15,  1.03it/s, loss=0.1975, batch_acc=1.0000, running_acc=0.9753, grad=20.7035]Training epoch 32:  91%|█████████ | 148/163 [02:45<00:16,  1.09s/it, loss=0.1975, batch_acc=1.0000, running_acc=0.9753, grad=20.7035]Training epoch 32:  91%|█████████ | 148/163 [02:45<00:16,  1.09s/it, loss=0.2199, batch_acc=0.9688, running_acc=0.9753, grad=12.0866]Training epoch 32:  91%|█████████▏| 149/163 [02:46<00:14,  1.03s/it, loss=0.2199, batch_acc=0.9688, running_acc=0.9753, grad=12.0866]Training epoch 32:  91%|█████████▏| 149/163 [02:46<00:14,  1.03s/it, loss=0.2110, batch_acc=1.0000, running_acc=0.9755, grad=20.3820]Training epoch 32:  92%|█████████▏| 150/163 [02:47<00:12,  1.01it/s, loss=0.2110, batch_acc=1.0000, running_acc=0.9755, grad=20.3820]Training epoch 32:  92%|█████████▏| 150/163 [02:47<00:12,  1.01it/s, loss=0.1671, batch_acc=1.0000, running_acc=0.9756, grad=14.7602]Training epoch 32:  93%|█████████▎| 151/163 [02:48<00:11,  1.05it/s, loss=0.1671, batch_acc=1.0000, running_acc=0.9756, grad=14.7602]Training epoch 32:  93%|█████████▎| 151/163 [02:48<00:11,  1.05it/s, loss=0.1898, batch_acc=0.9375, running_acc=0.9754, grad=12.0838]Training epoch 32:  93%|█████████▎| 152/163 [02:50<00:12,  1.16s/it, loss=0.1898, batch_acc=0.9375, running_acc=0.9754, grad=12.0838]Training epoch 32:  93%|█████████▎| 152/163 [02:50<00:12,  1.16s/it, loss=0.1560, batch_acc=0.9688, running_acc=0.9753, grad=13.8312]Training epoch 32:  94%|█████████▍| 153/163 [02:51<00:10,  1.07s/it, loss=0.1560, batch_acc=0.9688, running_acc=0.9753, grad=13.8312]Training epoch 32:  94%|█████████▍| 153/163 [02:51<00:10,  1.07s/it, loss=0.1945, batch_acc=0.9688, running_acc=0.9753, grad=13.2134]Training epoch 32:  94%|█████████▍| 154/163 [02:51<00:09,  1.02s/it, loss=0.1945, batch_acc=0.9688, running_acc=0.9753, grad=13.2134]Training epoch 32:  94%|█████████▍| 154/163 [02:51<00:09,  1.02s/it, loss=0.2679, batch_acc=0.9688, running_acc=0.9752, grad=18.1410]Training epoch 32:  95%|█████████▌| 155/163 [02:52<00:07,  1.03it/s, loss=0.2679, batch_acc=0.9688, running_acc=0.9752, grad=18.1410]Training epoch 32:  95%|█████████▌| 155/163 [02:52<00:07,  1.03it/s, loss=0.1737, batch_acc=1.0000, running_acc=0.9754, grad=13.8566]Training epoch 32:  96%|█████████▌| 156/163 [02:54<00:08,  1.20s/it, loss=0.1737, batch_acc=1.0000, running_acc=0.9754, grad=13.8566]Training epoch 32:  96%|█████████▌| 156/163 [02:54<00:08,  1.20s/it, loss=0.2520, batch_acc=0.9375, running_acc=0.9752, grad=16.7613]Training epoch 32:  96%|█████████▋| 157/163 [02:55<00:06,  1.11s/it, loss=0.2520, batch_acc=0.9375, running_acc=0.9752, grad=16.7613]Training epoch 32:  96%|█████████▋| 157/163 [02:55<00:06,  1.11s/it, loss=0.1181, batch_acc=1.0000, running_acc=0.9753, grad=9.9279] Training epoch 32:  97%|█████████▋| 158/163 [02:56<00:05,  1.04s/it, loss=0.1181, batch_acc=1.0000, running_acc=0.9753, grad=9.9279]Training epoch 32:  97%|█████████▋| 158/163 [02:56<00:05,  1.04s/it, loss=0.2948, batch_acc=0.8750, running_acc=0.9747, grad=18.6589]Training epoch 32:  98%|█████████▊| 159/163 [02:57<00:03,  1.01it/s, loss=0.2948, batch_acc=0.8750, running_acc=0.9747, grad=18.6589]Training epoch 32:  98%|█████████▊| 159/163 [02:57<00:03,  1.01it/s, loss=0.1979, batch_acc=0.9688, running_acc=0.9746, grad=11.8549]Training epoch 32:  98%|█████████▊| 160/163 [02:58<00:03,  1.17s/it, loss=0.1979, batch_acc=0.9688, running_acc=0.9746, grad=11.8549]Training epoch 32:  98%|█████████▊| 160/163 [02:58<00:03,  1.17s/it, loss=0.2476, batch_acc=0.9062, running_acc=0.9742, grad=16.1987]Training epoch 32:  99%|█████████▉| 161/163 [02:59<00:02,  1.08s/it, loss=0.2476, batch_acc=0.9062, running_acc=0.9742, grad=16.1987]Training epoch 32:  99%|█████████▉| 161/163 [02:59<00:02,  1.08s/it, loss=0.1917, batch_acc=0.9688, running_acc=0.9742, grad=15.3181]Training epoch 32:  99%|█████████▉| 162/163 [03:00<00:01,  1.02s/it, loss=0.1917, batch_acc=0.9688, running_acc=0.9742, grad=15.3181]Training epoch 32:  99%|█████████▉| 162/163 [03:00<00:01,  1.02s/it, loss=0.1672, batch_acc=0.9688, running_acc=0.9742, grad=10.0821]Training epoch 32: 100%|██████████| 163/163 [03:01<00:00,  1.10it/s, loss=0.1672, batch_acc=0.9688, running_acc=0.9742, grad=10.0821]Training epoch 32: 100%|██████████| 163/163 [03:01<00:00,  1.10it/s, loss=0.0979, batch_acc=1.0000, running_acc=0.9743, grad=8.4636] Training epoch 32: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=0.0979, batch_acc=1.0000, running_acc=0.9743, grad=8.4636]
Evaluation epoch 32:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 32:   4%|▎         | 1/28 [00:05<02:19,  5.16s/it]Evaluation epoch 32:   4%|▎         | 1/28 [00:05<02:19,  5.16s/it, loss=0.4916, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 32:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=0.4916, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 32:   7%|▋         | 2/28 [00:05<00:59,  2.28s/it, loss=0.3235, batch_acc=0.9688, running_acc=0.9219]Evaluation epoch 32:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=0.3235, batch_acc=0.9688, running_acc=0.9219]Evaluation epoch 32:  11%|█         | 3/28 [00:05<00:33,  1.36s/it, loss=0.3956, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 32:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=0.3956, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 32:  14%|█▍        | 4/28 [00:10<01:01,  2.56s/it, loss=0.4818, batch_acc=0.9062, running_acc=0.9297]Evaluation epoch 32:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=0.4818, batch_acc=0.9062, running_acc=0.9297]Evaluation epoch 32:  18%|█▊        | 5/28 [00:10<00:39,  1.73s/it, loss=1.5223, batch_acc=0.5938, running_acc=0.8625]Evaluation epoch 32:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=1.5223, batch_acc=0.5938, running_acc=0.8625]Evaluation epoch 32:  21%|██▏       | 6/28 [00:10<00:27,  1.23s/it, loss=0.6064, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 32:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.6064, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 32:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.6622, batch_acc=0.8438, running_acc=0.8571]Evaluation epoch 32:  29%|██▊       | 8/28 [00:14<00:33,  1.69s/it, loss=0.6622, batch_acc=0.8438, running_acc=0.8571]Evaluation epoch 32:  29%|██▊       | 8/28 [00:14<00:33,  1.69s/it, loss=0.3959, batch_acc=0.8750, running_acc=0.8594]Evaluation epoch 32:  32%|███▏      | 9/28 [00:14<00:24,  1.31s/it, loss=0.3959, batch_acc=0.8750, running_acc=0.8594]Evaluation epoch 32:  32%|███▏      | 9/28 [00:14<00:24,  1.31s/it, loss=0.4775, batch_acc=0.9062, running_acc=0.8646]Evaluation epoch 32:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.4775, batch_acc=0.9062, running_acc=0.8646]Evaluation epoch 32:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.4879, batch_acc=0.9375, running_acc=0.8719]Evaluation epoch 32:  39%|███▉      | 11/28 [00:15<00:12,  1.31it/s, loss=0.4879, batch_acc=0.9375, running_acc=0.8719]Evaluation epoch 32:  39%|███▉      | 11/28 [00:15<00:12,  1.31it/s, loss=0.4028, batch_acc=0.9375, running_acc=0.8778]Evaluation epoch 32:  43%|████▎     | 12/28 [00:20<00:36,  2.25s/it, loss=0.4028, batch_acc=0.9375, running_acc=0.8778]Evaluation epoch 32:  43%|████▎     | 12/28 [00:20<00:36,  2.25s/it, loss=0.8902, batch_acc=0.8125, running_acc=0.8724]Evaluation epoch 32:  46%|████▋     | 13/28 [00:21<00:24,  1.65s/it, loss=0.8902, batch_acc=0.8125, running_acc=0.8724]Evaluation epoch 32:  46%|████▋     | 13/28 [00:21<00:24,  1.65s/it, loss=0.3477, batch_acc=0.9375, running_acc=0.8774]Evaluation epoch 32:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=0.3477, batch_acc=0.9375, running_acc=0.8774]Evaluation epoch 32:  50%|█████     | 14/28 [00:21<00:17,  1.23s/it, loss=0.8812, batch_acc=0.7812, running_acc=0.8705]Evaluation epoch 32:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=0.8812, batch_acc=0.7812, running_acc=0.8705]Evaluation epoch 32:  54%|█████▎    | 15/28 [00:21<00:12,  1.06it/s, loss=1.0669, batch_acc=0.6875, running_acc=0.8583]Evaluation epoch 32:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=1.0669, batch_acc=0.6875, running_acc=0.8583]Evaluation epoch 32:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=0.8779, batch_acc=0.7812, running_acc=0.8535]Evaluation epoch 32:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=0.8779, batch_acc=0.7812, running_acc=0.8535]Evaluation epoch 32:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=0.6885, batch_acc=0.7188, running_acc=0.8456]Evaluation epoch 32:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=0.6885, batch_acc=0.7188, running_acc=0.8456]Evaluation epoch 32:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=0.6185, batch_acc=0.8438, running_acc=0.8455]Evaluation epoch 32:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=0.6185, batch_acc=0.8438, running_acc=0.8455]Evaluation epoch 32:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=0.8324, batch_acc=0.6562, running_acc=0.8355]Evaluation epoch 32:  71%|███████▏  | 20/28 [00:28<00:10,  1.36s/it, loss=0.8324, batch_acc=0.6562, running_acc=0.8355]Evaluation epoch 32:  71%|███████▏  | 20/28 [00:28<00:10,  1.36s/it, loss=0.5703, batch_acc=0.6875, running_acc=0.8281]Evaluation epoch 32:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5703, batch_acc=0.6875, running_acc=0.8281]Evaluation epoch 32:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5813, batch_acc=0.8125, running_acc=0.8274]Evaluation epoch 32:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5813, batch_acc=0.8125, running_acc=0.8274]Evaluation epoch 32:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5214, batch_acc=0.9375, running_acc=0.8324]Evaluation epoch 32:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.5214, batch_acc=0.9375, running_acc=0.8324]Evaluation epoch 32:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.9264, batch_acc=0.7188, running_acc=0.8274]Evaluation epoch 32:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.9264, batch_acc=0.7188, running_acc=0.8274]Evaluation epoch 32:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.4664, batch_acc=0.9062, running_acc=0.8307]Evaluation epoch 32:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.4664, batch_acc=0.9062, running_acc=0.8307]Evaluation epoch 32:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.1593, batch_acc=1.0000, running_acc=0.8375]Evaluation epoch 32:  93%|█████████▎| 26/28 [00:35<00:02,  1.14s/it, loss=0.1593, batch_acc=1.0000, running_acc=0.8375]Evaluation epoch 32:  93%|█████████▎| 26/28 [00:35<00:02,  1.14s/it, loss=0.6749, batch_acc=0.8125, running_acc=0.8365]Evaluation epoch 32:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.6749, batch_acc=0.8125, running_acc=0.8365]Evaluation epoch 32:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.8735, batch_acc=0.7188, running_acc=0.8322]Evaluation epoch 32: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.2692, batch_acc=0.6667, running_acc=0.8316]Evaluation epoch 32: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.2692, batch_acc=0.6667, running_acc=0.8316]
Training epoch 33:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 33:   1%|          | 1/163 [00:05<15:33,  5.76s/it]Training epoch 33:   1%|          | 1/163 [00:05<15:33,  5.76s/it, loss=0.1458, batch_acc=1.0000, running_acc=1.0000, grad=12.6439]Training epoch 33:   1%|          | 2/163 [00:06<07:45,  2.89s/it, loss=0.1458, batch_acc=1.0000, running_acc=1.0000, grad=12.6439]Training epoch 33:   1%|          | 2/163 [00:06<07:45,  2.89s/it, loss=0.1551, batch_acc=0.9688, running_acc=0.9844, grad=11.0154]Training epoch 33:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=0.1551, batch_acc=0.9688, running_acc=0.9844, grad=11.0154]Training epoch 33:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=0.2165, batch_acc=0.9688, running_acc=0.9792, grad=21.1317]Training epoch 33:   2%|▏         | 4/163 [00:10<05:50,  2.20s/it, loss=0.2165, batch_acc=0.9688, running_acc=0.9792, grad=21.1317]Training epoch 33:   2%|▏         | 4/163 [00:10<05:50,  2.20s/it, loss=0.1291, batch_acc=1.0000, running_acc=0.9844, grad=7.9351] Training epoch 33:   3%|▎         | 5/163 [00:10<04:32,  1.73s/it, loss=0.1291, batch_acc=1.0000, running_acc=0.9844, grad=7.9351]Training epoch 33:   3%|▎         | 5/163 [00:10<04:32,  1.73s/it, loss=0.1826, batch_acc=0.9688, running_acc=0.9812, grad=12.7590]Training epoch 33:   4%|▎         | 6/163 [00:11<03:45,  1.44s/it, loss=0.1826, batch_acc=0.9688, running_acc=0.9812, grad=12.7590]Training epoch 33:   4%|▎         | 6/163 [00:11<03:45,  1.44s/it, loss=0.1610, batch_acc=0.9688, running_acc=0.9792, grad=12.7011]Training epoch 33:   4%|▍         | 7/163 [00:12<03:15,  1.25s/it, loss=0.1610, batch_acc=0.9688, running_acc=0.9792, grad=12.7011]Training epoch 33:   4%|▍         | 7/163 [00:12<03:15,  1.25s/it, loss=0.2274, batch_acc=1.0000, running_acc=0.9821, grad=14.0706]Training epoch 33:   5%|▍         | 8/163 [00:14<03:50,  1.48s/it, loss=0.2274, batch_acc=1.0000, running_acc=0.9821, grad=14.0706]Training epoch 33:   5%|▍         | 8/163 [00:14<03:50,  1.48s/it, loss=0.2001, batch_acc=1.0000, running_acc=0.9844, grad=16.8749]Training epoch 33:   6%|▌         | 9/163 [00:15<03:19,  1.29s/it, loss=0.2001, batch_acc=1.0000, running_acc=0.9844, grad=16.8749]Training epoch 33:   6%|▌         | 9/163 [00:15<03:19,  1.29s/it, loss=0.2477, batch_acc=0.9062, running_acc=0.9757, grad=14.6290]Training epoch 33:   6%|▌         | 10/163 [00:16<02:58,  1.17s/it, loss=0.2477, batch_acc=0.9062, running_acc=0.9757, grad=14.6290]Training epoch 33:   6%|▌         | 10/163 [00:16<02:58,  1.17s/it, loss=0.1400, batch_acc=1.0000, running_acc=0.9781, grad=12.6565]Training epoch 33:   7%|▋         | 11/163 [00:17<02:43,  1.08s/it, loss=0.1400, batch_acc=1.0000, running_acc=0.9781, grad=12.6565]Training epoch 33:   7%|▋         | 11/163 [00:17<02:43,  1.08s/it, loss=0.2180, batch_acc=0.9375, running_acc=0.9744, grad=14.3532]Training epoch 33:   7%|▋         | 12/163 [00:19<03:28,  1.38s/it, loss=0.2180, batch_acc=0.9375, running_acc=0.9744, grad=14.3532]Training epoch 33:   7%|▋         | 12/163 [00:19<03:28,  1.38s/it, loss=0.2253, batch_acc=0.9688, running_acc=0.9740, grad=19.6520]Training epoch 33:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.2253, batch_acc=0.9688, running_acc=0.9740, grad=19.6520]Training epoch 33:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.2451, batch_acc=0.9688, running_acc=0.9736, grad=17.2587]Training epoch 33:   9%|▊         | 14/163 [00:21<02:47,  1.12s/it, loss=0.2451, batch_acc=0.9688, running_acc=0.9736, grad=17.2587]Training epoch 33:   9%|▊         | 14/163 [00:21<02:47,  1.12s/it, loss=0.1849, batch_acc=0.9688, running_acc=0.9732, grad=11.6791]Training epoch 33:   9%|▉         | 15/163 [00:22<02:35,  1.05s/it, loss=0.1849, batch_acc=0.9688, running_acc=0.9732, grad=11.6791]Training epoch 33:   9%|▉         | 15/163 [00:22<02:35,  1.05s/it, loss=0.1746, batch_acc=1.0000, running_acc=0.9750, grad=14.4355]Training epoch 33:  10%|▉         | 16/163 [00:24<03:17,  1.35s/it, loss=0.1746, batch_acc=1.0000, running_acc=0.9750, grad=14.4355]Training epoch 33:  10%|▉         | 16/163 [00:24<03:17,  1.35s/it, loss=0.1311, batch_acc=1.0000, running_acc=0.9766, grad=9.9304] Training epoch 33:  10%|█         | 17/163 [00:24<02:55,  1.20s/it, loss=0.1311, batch_acc=1.0000, running_acc=0.9766, grad=9.9304]Training epoch 33:  10%|█         | 17/163 [00:24<02:55,  1.20s/it, loss=0.1296, batch_acc=0.9688, running_acc=0.9761, grad=9.7490]Training epoch 33:  11%|█         | 18/163 [00:25<02:40,  1.11s/it, loss=0.1296, batch_acc=0.9688, running_acc=0.9761, grad=9.7490]Training epoch 33:  11%|█         | 18/163 [00:25<02:40,  1.11s/it, loss=0.1055, batch_acc=1.0000, running_acc=0.9774, grad=6.6930]Training epoch 33:  12%|█▏        | 19/163 [00:26<02:29,  1.04s/it, loss=0.1055, batch_acc=1.0000, running_acc=0.9774, grad=6.6930]Training epoch 33:  12%|█▏        | 19/163 [00:26<02:29,  1.04s/it, loss=0.1631, batch_acc=1.0000, running_acc=0.9786, grad=13.9069]Training epoch 33:  12%|█▏        | 20/163 [00:27<02:32,  1.07s/it, loss=0.1631, batch_acc=1.0000, running_acc=0.9786, grad=13.9069]Training epoch 33:  12%|█▏        | 20/163 [00:27<02:32,  1.07s/it, loss=0.1421, batch_acc=0.9688, running_acc=0.9781, grad=12.6099]Training epoch 33:  13%|█▎        | 21/163 [00:28<02:23,  1.01s/it, loss=0.1421, batch_acc=0.9688, running_acc=0.9781, grad=12.6099]Training epoch 33:  13%|█▎        | 21/163 [00:28<02:23,  1.01s/it, loss=0.2097, batch_acc=0.9375, running_acc=0.9762, grad=16.9045]Training epoch 33:  13%|█▎        | 22/163 [00:29<02:16,  1.03it/s, loss=0.2097, batch_acc=0.9375, running_acc=0.9762, grad=16.9045]Training epoch 33:  13%|█▎        | 22/163 [00:29<02:16,  1.03it/s, loss=0.1606, batch_acc=1.0000, running_acc=0.9773, grad=10.9468]Training epoch 33:  14%|█▍        | 23/163 [00:30<02:12,  1.06it/s, loss=0.1606, batch_acc=1.0000, running_acc=0.9773, grad=10.9468]Training epoch 33:  14%|█▍        | 23/163 [00:30<02:12,  1.06it/s, loss=0.1959, batch_acc=0.9375, running_acc=0.9755, grad=14.0142]Training epoch 33:  15%|█▍        | 24/163 [00:31<02:25,  1.05s/it, loss=0.1959, batch_acc=0.9375, running_acc=0.9755, grad=14.0142]Training epoch 33:  15%|█▍        | 24/163 [00:31<02:25,  1.05s/it, loss=0.2117, batch_acc=0.9688, running_acc=0.9753, grad=15.2207]Training epoch 33:  15%|█▌        | 25/163 [00:32<02:17,  1.00it/s, loss=0.2117, batch_acc=0.9688, running_acc=0.9753, grad=15.2207]Training epoch 33:  15%|█▌        | 25/163 [00:32<02:17,  1.00it/s, loss=0.1190, batch_acc=1.0000, running_acc=0.9762, grad=9.5368] Training epoch 33:  16%|█▌        | 26/163 [00:33<02:11,  1.04it/s, loss=0.1190, batch_acc=1.0000, running_acc=0.9762, grad=9.5368]Training epoch 33:  16%|█▌        | 26/163 [00:33<02:11,  1.04it/s, loss=0.1459, batch_acc=1.0000, running_acc=0.9772, grad=12.3113]Training epoch 33:  17%|█▋        | 27/163 [00:34<02:07,  1.07it/s, loss=0.1459, batch_acc=1.0000, running_acc=0.9772, grad=12.3113]Training epoch 33:  17%|█▋        | 27/163 [00:34<02:07,  1.07it/s, loss=0.1896, batch_acc=1.0000, running_acc=0.9780, grad=15.3812]Training epoch 33:  17%|█▋        | 28/163 [00:35<02:25,  1.08s/it, loss=0.1896, batch_acc=1.0000, running_acc=0.9780, grad=15.3812]Training epoch 33:  17%|█▋        | 28/163 [00:35<02:25,  1.08s/it, loss=0.2095, batch_acc=1.0000, running_acc=0.9788, grad=22.0882]Training epoch 33:  18%|█▊        | 29/163 [00:36<02:16,  1.02s/it, loss=0.2095, batch_acc=1.0000, running_acc=0.9788, grad=22.0882]Training epoch 33:  18%|█▊        | 29/163 [00:36<02:16,  1.02s/it, loss=0.2223, batch_acc=1.0000, running_acc=0.9795, grad=15.8150]Training epoch 33:  18%|█▊        | 30/163 [00:37<02:09,  1.03it/s, loss=0.2223, batch_acc=1.0000, running_acc=0.9795, grad=15.8150]Training epoch 33:  18%|█▊        | 30/163 [00:37<02:09,  1.03it/s, loss=0.2508, batch_acc=0.9375, running_acc=0.9781, grad=12.1823]Training epoch 33:  19%|█▉        | 31/163 [00:38<02:05,  1.05it/s, loss=0.2508, batch_acc=0.9375, running_acc=0.9781, grad=12.1823]Training epoch 33:  19%|█▉        | 31/163 [00:38<02:05,  1.05it/s, loss=0.1677, batch_acc=1.0000, running_acc=0.9788, grad=10.4619]Training epoch 33:  20%|█▉        | 32/163 [00:39<02:22,  1.09s/it, loss=0.1677, batch_acc=1.0000, running_acc=0.9788, grad=10.4619]Training epoch 33:  20%|█▉        | 32/163 [00:39<02:22,  1.09s/it, loss=0.1273, batch_acc=1.0000, running_acc=0.9795, grad=12.1218]Training epoch 33:  20%|██        | 33/163 [00:40<02:12,  1.02s/it, loss=0.1273, batch_acc=1.0000, running_acc=0.9795, grad=12.1218]Training epoch 33:  20%|██        | 33/163 [00:40<02:12,  1.02s/it, loss=0.1286, batch_acc=1.0000, running_acc=0.9801, grad=12.3405]Training epoch 33:  21%|██        | 34/163 [00:41<02:06,  1.02it/s, loss=0.1286, batch_acc=1.0000, running_acc=0.9801, grad=12.3405]Training epoch 33:  21%|██        | 34/163 [00:41<02:06,  1.02it/s, loss=0.3777, batch_acc=0.9062, running_acc=0.9779, grad=25.4431]Training epoch 33:  21%|██▏       | 35/163 [00:42<02:01,  1.05it/s, loss=0.3777, batch_acc=0.9062, running_acc=0.9779, grad=25.4431]Training epoch 33:  21%|██▏       | 35/163 [00:42<02:01,  1.05it/s, loss=0.2084, batch_acc=1.0000, running_acc=0.9786, grad=24.6390]Training epoch 33:  22%|██▏       | 36/163 [00:43<02:08,  1.01s/it, loss=0.2084, batch_acc=1.0000, running_acc=0.9786, grad=24.6390]Training epoch 33:  22%|██▏       | 36/163 [00:43<02:08,  1.01s/it, loss=0.2110, batch_acc=0.9375, running_acc=0.9774, grad=19.6001]Training epoch 33:  23%|██▎       | 37/163 [00:44<02:02,  1.03it/s, loss=0.2110, batch_acc=0.9375, running_acc=0.9774, grad=19.6001]Training epoch 33:  23%|██▎       | 37/163 [00:44<02:02,  1.03it/s, loss=0.1680, batch_acc=1.0000, running_acc=0.9780, grad=11.7558]Training epoch 33:  23%|██▎       | 38/163 [00:45<01:57,  1.06it/s, loss=0.1680, batch_acc=1.0000, running_acc=0.9780, grad=11.7558]Training epoch 33:  23%|██▎       | 38/163 [00:45<01:57,  1.06it/s, loss=0.1923, batch_acc=0.9688, running_acc=0.9778, grad=13.8247]Training epoch 33:  24%|██▍       | 39/163 [00:46<01:54,  1.08it/s, loss=0.1923, batch_acc=0.9688, running_acc=0.9778, grad=13.8247]Training epoch 33:  24%|██▍       | 39/163 [00:46<01:54,  1.08it/s, loss=0.2247, batch_acc=0.9688, running_acc=0.9776, grad=14.3205]Training epoch 33:  25%|██▍       | 40/163 [00:47<02:11,  1.07s/it, loss=0.2247, batch_acc=0.9688, running_acc=0.9776, grad=14.3205]Training epoch 33:  25%|██▍       | 40/163 [00:47<02:11,  1.07s/it, loss=0.1974, batch_acc=0.9375, running_acc=0.9766, grad=12.4399]Training epoch 33:  25%|██▌       | 41/163 [00:48<02:03,  1.01s/it, loss=0.1974, batch_acc=0.9375, running_acc=0.9766, grad=12.4399]Training epoch 33:  25%|██▌       | 41/163 [00:48<02:03,  1.01s/it, loss=0.1914, batch_acc=1.0000, running_acc=0.9771, grad=19.7715]Training epoch 33:  26%|██▌       | 42/163 [00:49<01:57,  1.03it/s, loss=0.1914, batch_acc=1.0000, running_acc=0.9771, grad=19.7715]Training epoch 33:  26%|██▌       | 42/163 [00:49<01:57,  1.03it/s, loss=0.1980, batch_acc=0.9688, running_acc=0.9769, grad=15.9754]Training epoch 33:  26%|██▋       | 43/163 [00:50<01:53,  1.06it/s, loss=0.1980, batch_acc=0.9688, running_acc=0.9769, grad=15.9754]Training epoch 33:  26%|██▋       | 43/163 [00:50<01:53,  1.06it/s, loss=0.2054, batch_acc=0.9688, running_acc=0.9767, grad=15.3092]Training epoch 33:  27%|██▋       | 44/163 [00:51<01:53,  1.05it/s, loss=0.2054, batch_acc=0.9688, running_acc=0.9767, grad=15.3092]Training epoch 33:  27%|██▋       | 44/163 [00:51<01:53,  1.05it/s, loss=0.2445, batch_acc=0.9375, running_acc=0.9759, grad=15.0742]Training epoch 33:  28%|██▊       | 45/163 [00:52<01:50,  1.07it/s, loss=0.2445, batch_acc=0.9375, running_acc=0.9759, grad=15.0742]Training epoch 33:  28%|██▊       | 45/163 [00:52<01:50,  1.07it/s, loss=0.1835, batch_acc=0.9688, running_acc=0.9757, grad=10.6327]Training epoch 33:  28%|██▊       | 46/163 [00:53<01:47,  1.09it/s, loss=0.1835, batch_acc=0.9688, running_acc=0.9757, grad=10.6327]Training epoch 33:  28%|██▊       | 46/163 [00:53<01:47,  1.09it/s, loss=0.1530, batch_acc=0.9688, running_acc=0.9755, grad=10.5830]Training epoch 33:  29%|██▉       | 47/163 [00:53<01:44,  1.10it/s, loss=0.1530, batch_acc=0.9688, running_acc=0.9755, grad=10.5830]Training epoch 33:  29%|██▉       | 47/163 [00:53<01:44,  1.10it/s, loss=0.1785, batch_acc=0.9688, running_acc=0.9754, grad=11.6384]Training epoch 33:  29%|██▉       | 48/163 [00:54<01:43,  1.11it/s, loss=0.1785, batch_acc=0.9688, running_acc=0.9754, grad=11.6384]Training epoch 33:  29%|██▉       | 48/163 [00:54<01:43,  1.11it/s, loss=0.2454, batch_acc=0.9375, running_acc=0.9746, grad=15.2493]Training epoch 33:  30%|███       | 49/163 [00:55<01:41,  1.12it/s, loss=0.2454, batch_acc=0.9375, running_acc=0.9746, grad=15.2493]Training epoch 33:  30%|███       | 49/163 [00:55<01:41,  1.12it/s, loss=0.1706, batch_acc=1.0000, running_acc=0.9751, grad=11.5379]Training epoch 33:  31%|███       | 50/163 [00:56<01:40,  1.13it/s, loss=0.1706, batch_acc=1.0000, running_acc=0.9751, grad=11.5379]Training epoch 33:  31%|███       | 50/163 [00:56<01:40,  1.13it/s, loss=0.1650, batch_acc=1.0000, running_acc=0.9756, grad=16.9043]Training epoch 33:  31%|███▏      | 51/163 [00:57<01:40,  1.12it/s, loss=0.1650, batch_acc=1.0000, running_acc=0.9756, grad=16.9043]Training epoch 33:  31%|███▏      | 51/163 [00:57<01:40,  1.12it/s, loss=0.2532, batch_acc=0.9375, running_acc=0.9749, grad=15.8609]Training epoch 33:  32%|███▏      | 52/163 [00:58<01:53,  1.03s/it, loss=0.2532, batch_acc=0.9375, running_acc=0.9749, grad=15.8609]Training epoch 33:  32%|███▏      | 52/163 [00:58<01:53,  1.03s/it, loss=0.1965, batch_acc=1.0000, running_acc=0.9754, grad=15.5418]Training epoch 33:  33%|███▎      | 53/163 [00:59<01:50,  1.00s/it, loss=0.1965, batch_acc=1.0000, running_acc=0.9754, grad=15.5418]Training epoch 33:  33%|███▎      | 53/163 [00:59<01:50,  1.00s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9758, grad=8.5807] Training epoch 33:  33%|███▎      | 54/163 [01:00<01:45,  1.04it/s, loss=0.1356, batch_acc=1.0000, running_acc=0.9758, grad=8.5807]Training epoch 33:  33%|███▎      | 54/163 [01:00<01:45,  1.04it/s, loss=0.2382, batch_acc=0.9062, running_acc=0.9745, grad=19.0520]Training epoch 33:  34%|███▎      | 55/163 [01:01<01:49,  1.02s/it, loss=0.2382, batch_acc=0.9062, running_acc=0.9745, grad=19.0520]Training epoch 33:  34%|███▎      | 55/163 [01:01<01:49,  1.02s/it, loss=0.1035, batch_acc=1.0000, running_acc=0.9750, grad=7.2723] Training epoch 33:  34%|███▍      | 56/163 [01:02<01:47,  1.01s/it, loss=0.1035, batch_acc=1.0000, running_acc=0.9750, grad=7.2723]Training epoch 33:  34%|███▍      | 56/163 [01:02<01:47,  1.01s/it, loss=0.1747, batch_acc=1.0000, running_acc=0.9754, grad=12.4760]Training epoch 33:  35%|███▍      | 57/163 [01:03<01:42,  1.03it/s, loss=0.1747, batch_acc=1.0000, running_acc=0.9754, grad=12.4760]Training epoch 33:  35%|███▍      | 57/163 [01:03<01:42,  1.03it/s, loss=0.1992, batch_acc=0.9688, running_acc=0.9753, grad=17.3452]Training epoch 33:  36%|███▌      | 58/163 [01:04<01:39,  1.06it/s, loss=0.1992, batch_acc=0.9688, running_acc=0.9753, grad=17.3452]Training epoch 33:  36%|███▌      | 58/163 [01:04<01:39,  1.06it/s, loss=0.0953, batch_acc=1.0000, running_acc=0.9758, grad=6.8282] Training epoch 33:  36%|███▌      | 59/163 [01:06<02:05,  1.21s/it, loss=0.0953, batch_acc=1.0000, running_acc=0.9758, grad=6.8282]Training epoch 33:  36%|███▌      | 59/163 [01:06<02:05,  1.21s/it, loss=0.1770, batch_acc=1.0000, running_acc=0.9762, grad=11.9671]Training epoch 33:  37%|███▋      | 60/163 [01:07<01:57,  1.14s/it, loss=0.1770, batch_acc=1.0000, running_acc=0.9762, grad=11.9671]Training epoch 33:  37%|███▋      | 60/163 [01:07<01:57,  1.14s/it, loss=0.1597, batch_acc=1.0000, running_acc=0.9766, grad=12.5066]Training epoch 33:  37%|███▋      | 61/163 [01:08<01:48,  1.06s/it, loss=0.1597, batch_acc=1.0000, running_acc=0.9766, grad=12.5066]Training epoch 33:  37%|███▋      | 61/163 [01:08<01:48,  1.06s/it, loss=0.1143, batch_acc=1.0000, running_acc=0.9769, grad=8.7392] Training epoch 33:  38%|███▊      | 62/163 [01:09<01:41,  1.01s/it, loss=0.1143, batch_acc=1.0000, running_acc=0.9769, grad=8.7392]Training epoch 33:  38%|███▊      | 62/163 [01:09<01:41,  1.01s/it, loss=0.2474, batch_acc=0.9688, running_acc=0.9768, grad=16.4650]Training epoch 33:  39%|███▊      | 63/163 [01:09<01:36,  1.03it/s, loss=0.2474, batch_acc=0.9688, running_acc=0.9768, grad=16.4650]Training epoch 33:  39%|███▊      | 63/163 [01:09<01:36,  1.03it/s, loss=0.1485, batch_acc=1.0000, running_acc=0.9772, grad=10.6190]Training epoch 33:  39%|███▉      | 64/163 [01:11<01:46,  1.07s/it, loss=0.1485, batch_acc=1.0000, running_acc=0.9772, grad=10.6190]Training epoch 33:  39%|███▉      | 64/163 [01:11<01:46,  1.07s/it, loss=0.1690, batch_acc=1.0000, running_acc=0.9775, grad=19.4705]Training epoch 33:  40%|███▉      | 65/163 [01:12<01:39,  1.01s/it, loss=0.1690, batch_acc=1.0000, running_acc=0.9775, grad=19.4705]Training epoch 33:  40%|███▉      | 65/163 [01:12<01:39,  1.01s/it, loss=0.1766, batch_acc=1.0000, running_acc=0.9779, grad=16.3423]Training epoch 33:  40%|████      | 66/163 [01:13<01:34,  1.03it/s, loss=0.1766, batch_acc=1.0000, running_acc=0.9779, grad=16.3423]Training epoch 33:  40%|████      | 66/163 [01:13<01:34,  1.03it/s, loss=0.1086, batch_acc=1.0000, running_acc=0.9782, grad=8.1613] Training epoch 33:  41%|████      | 67/163 [01:14<01:43,  1.08s/it, loss=0.1086, batch_acc=1.0000, running_acc=0.9782, grad=8.1613]Training epoch 33:  41%|████      | 67/163 [01:14<01:43,  1.08s/it, loss=0.1200, batch_acc=1.0000, running_acc=0.9785, grad=8.7372]Training epoch 33:  42%|████▏     | 68/163 [01:15<01:52,  1.19s/it, loss=0.1200, batch_acc=1.0000, running_acc=0.9785, grad=8.7372]Training epoch 33:  42%|████▏     | 68/163 [01:15<01:52,  1.19s/it, loss=0.2091, batch_acc=0.9375, running_acc=0.9779, grad=16.5726]Training epoch 33:  42%|████▏     | 69/163 [01:16<01:42,  1.10s/it, loss=0.2091, batch_acc=0.9375, running_acc=0.9779, grad=16.5726]Training epoch 33:  42%|████▏     | 69/163 [01:16<01:42,  1.10s/it, loss=0.2109, batch_acc=0.9688, running_acc=0.9778, grad=14.1931]Training epoch 33:  43%|████▎     | 70/163 [01:17<01:35,  1.03s/it, loss=0.2109, batch_acc=0.9688, running_acc=0.9778, grad=14.1931]Training epoch 33:  43%|████▎     | 70/163 [01:17<01:35,  1.03s/it, loss=0.1597, batch_acc=0.9688, running_acc=0.9777, grad=8.3721] Training epoch 33:  44%|████▎     | 71/163 [01:19<01:48,  1.18s/it, loss=0.1597, batch_acc=0.9688, running_acc=0.9777, grad=8.3721]Training epoch 33:  44%|████▎     | 71/163 [01:19<01:48,  1.18s/it, loss=0.2403, batch_acc=0.9688, running_acc=0.9776, grad=14.2440]Training epoch 33:  44%|████▍     | 72/163 [01:20<01:40,  1.10s/it, loss=0.2403, batch_acc=0.9688, running_acc=0.9776, grad=14.2440]Training epoch 33:  44%|████▍     | 72/163 [01:20<01:40,  1.10s/it, loss=0.2348, batch_acc=1.0000, running_acc=0.9779, grad=18.0196]Training epoch 33:  45%|████▍     | 73/163 [01:20<01:33,  1.04s/it, loss=0.2348, batch_acc=1.0000, running_acc=0.9779, grad=18.0196]Training epoch 33:  45%|████▍     | 73/163 [01:20<01:33,  1.04s/it, loss=0.1493, batch_acc=1.0000, running_acc=0.9782, grad=9.8242] Training epoch 33:  45%|████▌     | 74/163 [01:21<01:27,  1.01it/s, loss=0.1493, batch_acc=1.0000, running_acc=0.9782, grad=9.8242]Training epoch 33:  45%|████▌     | 74/163 [01:21<01:27,  1.01it/s, loss=0.2452, batch_acc=0.9375, running_acc=0.9776, grad=26.6170]Training epoch 33:  46%|████▌     | 75/163 [01:22<01:32,  1.05s/it, loss=0.2452, batch_acc=0.9375, running_acc=0.9776, grad=26.6170]Training epoch 33:  46%|████▌     | 75/163 [01:22<01:32,  1.05s/it, loss=0.1494, batch_acc=1.0000, running_acc=0.9779, grad=11.3228]Training epoch 33:  47%|████▋     | 76/163 [01:23<01:27,  1.00s/it, loss=0.1494, batch_acc=1.0000, running_acc=0.9779, grad=11.3228]Training epoch 33:  47%|████▋     | 76/163 [01:23<01:27,  1.00s/it, loss=0.1944, batch_acc=1.0000, running_acc=0.9782, grad=17.4849]Training epoch 33:  47%|████▋     | 77/163 [01:25<01:29,  1.04s/it, loss=0.1944, batch_acc=1.0000, running_acc=0.9782, grad=17.4849]Training epoch 33:  47%|████▋     | 77/163 [01:25<01:29,  1.04s/it, loss=0.1614, batch_acc=0.9688, running_acc=0.9781, grad=10.6667]Training epoch 33:  48%|████▊     | 78/163 [01:25<01:24,  1.01it/s, loss=0.1614, batch_acc=0.9688, running_acc=0.9781, grad=10.6667]Training epoch 33:  48%|████▊     | 78/163 [01:25<01:24,  1.01it/s, loss=0.1738, batch_acc=0.9688, running_acc=0.9780, grad=12.2051]Training epoch 33:  48%|████▊     | 79/163 [01:27<01:36,  1.15s/it, loss=0.1738, batch_acc=0.9688, running_acc=0.9780, grad=12.2051]Training epoch 33:  48%|████▊     | 79/163 [01:27<01:36,  1.15s/it, loss=0.1851, batch_acc=0.9688, running_acc=0.9778, grad=13.1553]Training epoch 33:  49%|████▉     | 80/163 [01:28<01:28,  1.07s/it, loss=0.1851, batch_acc=0.9688, running_acc=0.9778, grad=13.1553]Training epoch 33:  49%|████▉     | 80/163 [01:28<01:28,  1.07s/it, loss=0.3790, batch_acc=0.8438, running_acc=0.9762, grad=22.3246]Training epoch 33:  50%|████▉     | 81/163 [01:29<01:34,  1.15s/it, loss=0.3790, batch_acc=0.8438, running_acc=0.9762, grad=22.3246]Training epoch 33:  50%|████▉     | 81/163 [01:29<01:34,  1.15s/it, loss=0.1420, batch_acc=1.0000, running_acc=0.9765, grad=9.6963] Training epoch 33:  50%|█████     | 82/163 [01:30<01:26,  1.07s/it, loss=0.1420, batch_acc=1.0000, running_acc=0.9765, grad=9.6963]Training epoch 33:  50%|█████     | 82/163 [01:30<01:26,  1.07s/it, loss=0.1757, batch_acc=1.0000, running_acc=0.9768, grad=13.3664]Training epoch 33:  51%|█████     | 83/163 [01:31<01:21,  1.01s/it, loss=0.1757, batch_acc=1.0000, running_acc=0.9768, grad=13.3664]Training epoch 33:  51%|█████     | 83/163 [01:31<01:21,  1.01s/it, loss=0.1341, batch_acc=0.9688, running_acc=0.9767, grad=9.5095] Training epoch 33:  52%|█████▏    | 84/163 [01:32<01:16,  1.03it/s, loss=0.1341, batch_acc=0.9688, running_acc=0.9767, grad=9.5095]Training epoch 33:  52%|█████▏    | 84/163 [01:32<01:16,  1.03it/s, loss=0.1799, batch_acc=1.0000, running_acc=0.9769, grad=12.0092]Training epoch 33:  52%|█████▏    | 85/163 [01:33<01:32,  1.19s/it, loss=0.1799, batch_acc=1.0000, running_acc=0.9769, grad=12.0092]Training epoch 33:  52%|█████▏    | 85/163 [01:33<01:32,  1.19s/it, loss=0.1864, batch_acc=1.0000, running_acc=0.9772, grad=13.5028]Training epoch 33:  53%|█████▎    | 86/163 [01:34<01:24,  1.09s/it, loss=0.1864, batch_acc=1.0000, running_acc=0.9772, grad=13.5028]Training epoch 33:  53%|█████▎    | 86/163 [01:34<01:24,  1.09s/it, loss=0.1634, batch_acc=0.9688, running_acc=0.9771, grad=23.4635]Training epoch 33:  53%|█████▎    | 87/163 [01:35<01:18,  1.03s/it, loss=0.1634, batch_acc=0.9688, running_acc=0.9771, grad=23.4635]Training epoch 33:  53%|█████▎    | 87/163 [01:35<01:18,  1.03s/it, loss=0.2820, batch_acc=0.9375, running_acc=0.9767, grad=22.1036]Training epoch 33:  54%|█████▍    | 88/163 [01:36<01:14,  1.01it/s, loss=0.2820, batch_acc=0.9375, running_acc=0.9767, grad=22.1036]Training epoch 33:  54%|█████▍    | 88/163 [01:36<01:14,  1.01it/s, loss=0.1808, batch_acc=0.9688, running_acc=0.9766, grad=19.3386]Training epoch 33:  55%|█████▍    | 89/163 [01:38<01:26,  1.17s/it, loss=0.1808, batch_acc=0.9688, running_acc=0.9766, grad=19.3386]Training epoch 33:  55%|█████▍    | 89/163 [01:38<01:26,  1.17s/it, loss=0.1427, batch_acc=1.0000, running_acc=0.9768, grad=12.9278]Training epoch 33:  55%|█████▌    | 90/163 [01:39<01:19,  1.08s/it, loss=0.1427, batch_acc=1.0000, running_acc=0.9768, grad=12.9278]Training epoch 33:  55%|█████▌    | 90/163 [01:39<01:19,  1.08s/it, loss=0.2062, batch_acc=0.9688, running_acc=0.9767, grad=13.9789]Training epoch 33:  56%|█████▌    | 91/163 [01:39<01:13,  1.02s/it, loss=0.2062, batch_acc=0.9688, running_acc=0.9767, grad=13.9789]Training epoch 33:  56%|█████▌    | 91/163 [01:39<01:13,  1.02s/it, loss=0.1812, batch_acc=0.9375, running_acc=0.9763, grad=12.8081]Training epoch 33:  56%|█████▋    | 92/163 [01:40<01:09,  1.02it/s, loss=0.1812, batch_acc=0.9375, running_acc=0.9763, grad=12.8081]Training epoch 33:  56%|█████▋    | 92/163 [01:40<01:09,  1.02it/s, loss=0.1974, batch_acc=0.9688, running_acc=0.9762, grad=14.5740]Training epoch 33:  57%|█████▋    | 93/163 [01:42<01:19,  1.14s/it, loss=0.1974, batch_acc=0.9688, running_acc=0.9762, grad=14.5740]Training epoch 33:  57%|█████▋    | 93/163 [01:42<01:19,  1.14s/it, loss=0.1384, batch_acc=0.9688, running_acc=0.9761, grad=12.1415]Training epoch 33:  58%|█████▊    | 94/163 [01:43<01:13,  1.06s/it, loss=0.1384, batch_acc=0.9688, running_acc=0.9761, grad=12.1415]Training epoch 33:  58%|█████▊    | 94/163 [01:43<01:13,  1.06s/it, loss=0.1488, batch_acc=1.0000, running_acc=0.9764, grad=10.7331]Training epoch 33:  58%|█████▊    | 95/163 [01:44<01:09,  1.02s/it, loss=0.1488, batch_acc=1.0000, running_acc=0.9764, grad=10.7331]Training epoch 33:  58%|█████▊    | 95/163 [01:44<01:09,  1.02s/it, loss=0.1766, batch_acc=0.9688, running_acc=0.9763, grad=12.6216]Training epoch 33:  59%|█████▉    | 96/163 [01:45<01:05,  1.02it/s, loss=0.1766, batch_acc=0.9688, running_acc=0.9763, grad=12.6216]Training epoch 33:  59%|█████▉    | 96/163 [01:45<01:05,  1.02it/s, loss=0.1600, batch_acc=0.9688, running_acc=0.9762, grad=10.9948]Training epoch 33:  60%|█████▉    | 97/163 [01:46<01:09,  1.05s/it, loss=0.1600, batch_acc=0.9688, running_acc=0.9762, grad=10.9948]Training epoch 33:  60%|█████▉    | 97/163 [01:46<01:09,  1.05s/it, loss=0.1659, batch_acc=0.9688, running_acc=0.9762, grad=12.0343]Training epoch 33:  60%|██████    | 98/163 [01:47<01:04,  1.00it/s, loss=0.1659, batch_acc=0.9688, running_acc=0.9762, grad=12.0343]Training epoch 33:  60%|██████    | 98/163 [01:47<01:04,  1.00it/s, loss=0.1361, batch_acc=0.9688, running_acc=0.9761, grad=8.4962] Training epoch 33:  61%|██████    | 99/163 [01:48<01:01,  1.04it/s, loss=0.1361, batch_acc=0.9688, running_acc=0.9761, grad=8.4962]Training epoch 33:  61%|██████    | 99/163 [01:48<01:01,  1.04it/s, loss=0.2146, batch_acc=0.9375, running_acc=0.9757, grad=18.4160]Training epoch 33:  61%|██████▏   | 100/163 [01:48<00:59,  1.07it/s, loss=0.2146, batch_acc=0.9375, running_acc=0.9757, grad=18.4160]Training epoch 33:  61%|██████▏   | 100/163 [01:48<00:59,  1.07it/s, loss=0.2686, batch_acc=0.9688, running_acc=0.9756, grad=18.5067]Training epoch 33:  62%|██████▏   | 101/163 [01:50<01:13,  1.19s/it, loss=0.2686, batch_acc=0.9688, running_acc=0.9756, grad=18.5067]Training epoch 33:  62%|██████▏   | 101/163 [01:50<01:13,  1.19s/it, loss=0.1182, batch_acc=1.0000, running_acc=0.9759, grad=10.0504]Training epoch 33:  63%|██████▎   | 102/163 [01:51<01:06,  1.10s/it, loss=0.1182, batch_acc=1.0000, running_acc=0.9759, grad=10.0504]Training epoch 33:  63%|██████▎   | 102/163 [01:51<01:06,  1.10s/it, loss=0.1828, batch_acc=0.9688, running_acc=0.9758, grad=15.3126]Training epoch 33:  63%|██████▎   | 103/163 [01:52<01:01,  1.03s/it, loss=0.1828, batch_acc=0.9688, running_acc=0.9758, grad=15.3126]Training epoch 33:  63%|██████▎   | 103/163 [01:52<01:01,  1.03s/it, loss=0.2122, batch_acc=0.9375, running_acc=0.9754, grad=12.2789]Training epoch 33:  64%|██████▍   | 104/163 [01:53<00:58,  1.01it/s, loss=0.2122, batch_acc=0.9375, running_acc=0.9754, grad=12.2789]Training epoch 33:  64%|██████▍   | 104/163 [01:53<00:58,  1.01it/s, loss=0.1854, batch_acc=1.0000, running_acc=0.9757, grad=13.7451]Training epoch 33:  64%|██████▍   | 105/163 [01:55<01:13,  1.26s/it, loss=0.1854, batch_acc=1.0000, running_acc=0.9757, grad=13.7451]Training epoch 33:  64%|██████▍   | 105/163 [01:55<01:13,  1.26s/it, loss=0.1776, batch_acc=1.0000, running_acc=0.9759, grad=15.0737]Training epoch 33:  65%|██████▌   | 106/163 [01:56<01:05,  1.15s/it, loss=0.1776, batch_acc=1.0000, running_acc=0.9759, grad=15.0737]Training epoch 33:  65%|██████▌   | 106/163 [01:56<01:05,  1.15s/it, loss=0.1828, batch_acc=1.0000, running_acc=0.9761, grad=14.7563]Training epoch 33:  66%|██████▌   | 107/163 [01:57<01:00,  1.07s/it, loss=0.1828, batch_acc=1.0000, running_acc=0.9761, grad=14.7563]Training epoch 33:  66%|██████▌   | 107/163 [01:57<01:00,  1.07s/it, loss=0.2208, batch_acc=1.0000, running_acc=0.9763, grad=19.5764]Training epoch 33:  66%|██████▋   | 108/163 [01:57<00:55,  1.01s/it, loss=0.2208, batch_acc=1.0000, running_acc=0.9763, grad=19.5764]Training epoch 33:  66%|██████▋   | 108/163 [01:57<00:55,  1.01s/it, loss=0.1391, batch_acc=1.0000, running_acc=0.9766, grad=11.7485]Training epoch 33:  67%|██████▋   | 109/163 [01:59<01:02,  1.15s/it, loss=0.1391, batch_acc=1.0000, running_acc=0.9766, grad=11.7485]Training epoch 33:  67%|██████▋   | 109/163 [01:59<01:02,  1.15s/it, loss=0.1967, batch_acc=0.9688, running_acc=0.9765, grad=14.3664]Training epoch 33:  67%|██████▋   | 110/163 [02:00<00:56,  1.07s/it, loss=0.1967, batch_acc=0.9688, running_acc=0.9765, grad=14.3664]Training epoch 33:  67%|██████▋   | 110/163 [02:00<00:56,  1.07s/it, loss=0.1555, batch_acc=1.0000, running_acc=0.9767, grad=12.3011]Training epoch 33:  68%|██████▊   | 111/163 [02:01<00:52,  1.01s/it, loss=0.1555, batch_acc=1.0000, running_acc=0.9767, grad=12.3011]Training epoch 33:  68%|██████▊   | 111/163 [02:01<00:52,  1.01s/it, loss=0.1423, batch_acc=1.0000, running_acc=0.9769, grad=10.2819]Training epoch 33:  69%|██████▊   | 112/163 [02:01<00:49,  1.03it/s, loss=0.1423, batch_acc=1.0000, running_acc=0.9769, grad=10.2819]Training epoch 33:  69%|██████▊   | 112/163 [02:01<00:49,  1.03it/s, loss=0.2377, batch_acc=0.9688, running_acc=0.9768, grad=15.2230]Training epoch 33:  69%|██████▉   | 113/163 [02:03<01:00,  1.22s/it, loss=0.2377, batch_acc=0.9688, running_acc=0.9768, grad=15.2230]Training epoch 33:  69%|██████▉   | 113/163 [02:03<01:00,  1.22s/it, loss=0.1446, batch_acc=1.0000, running_acc=0.9770, grad=11.0562]Training epoch 33:  70%|██████▉   | 114/163 [02:04<00:54,  1.12s/it, loss=0.1446, batch_acc=1.0000, running_acc=0.9770, grad=11.0562]Training epoch 33:  70%|██████▉   | 114/163 [02:04<00:54,  1.12s/it, loss=0.1331, batch_acc=1.0000, running_acc=0.9772, grad=11.0001]Training epoch 33:  71%|███████   | 115/163 [02:05<00:50,  1.04s/it, loss=0.1331, batch_acc=1.0000, running_acc=0.9772, grad=11.0001]Training epoch 33:  71%|███████   | 115/163 [02:05<00:50,  1.04s/it, loss=0.1619, batch_acc=1.0000, running_acc=0.9774, grad=25.2090]Training epoch 33:  71%|███████   | 116/163 [02:06<00:46,  1.01it/s, loss=0.1619, batch_acc=1.0000, running_acc=0.9774, grad=25.2090]Training epoch 33:  71%|███████   | 116/163 [02:06<00:46,  1.01it/s, loss=0.2141, batch_acc=0.9688, running_acc=0.9774, grad=25.7894]Training epoch 33:  72%|███████▏  | 117/163 [02:08<01:01,  1.34s/it, loss=0.2141, batch_acc=0.9688, running_acc=0.9774, grad=25.7894]Training epoch 33:  72%|███████▏  | 117/163 [02:08<01:01,  1.34s/it, loss=0.1283, batch_acc=1.0000, running_acc=0.9776, grad=14.2973]Training epoch 33:  72%|███████▏  | 118/163 [02:09<00:54,  1.20s/it, loss=0.1283, batch_acc=1.0000, running_acc=0.9776, grad=14.2973]Training epoch 33:  72%|███████▏  | 118/163 [02:09<00:54,  1.20s/it, loss=0.1104, batch_acc=1.0000, running_acc=0.9778, grad=11.5552]Training epoch 33:  73%|███████▎  | 119/163 [02:10<00:48,  1.11s/it, loss=0.1104, batch_acc=1.0000, running_acc=0.9778, grad=11.5552]Training epoch 33:  73%|███████▎  | 119/163 [02:10<00:48,  1.11s/it, loss=0.2064, batch_acc=0.9688, running_acc=0.9777, grad=16.2480]Training epoch 33:  74%|███████▎  | 120/163 [02:11<00:44,  1.04s/it, loss=0.2064, batch_acc=0.9688, running_acc=0.9777, grad=16.2480]Training epoch 33:  74%|███████▎  | 120/163 [02:11<00:44,  1.04s/it, loss=0.2638, batch_acc=0.9375, running_acc=0.9773, grad=18.3554]Training epoch 33:  74%|███████▍  | 121/163 [02:12<00:51,  1.24s/it, loss=0.2638, batch_acc=0.9375, running_acc=0.9773, grad=18.3554]Training epoch 33:  74%|███████▍  | 121/163 [02:12<00:51,  1.24s/it, loss=0.1646, batch_acc=1.0000, running_acc=0.9775, grad=12.7843]Training epoch 33:  75%|███████▍  | 122/163 [02:14<00:50,  1.23s/it, loss=0.1646, batch_acc=1.0000, running_acc=0.9775, grad=12.7843]Training epoch 33:  75%|███████▍  | 122/163 [02:14<00:50,  1.23s/it, loss=0.1596, batch_acc=1.0000, running_acc=0.9777, grad=13.1549]Training epoch 33:  75%|███████▌  | 123/163 [02:15<00:45,  1.13s/it, loss=0.1596, batch_acc=1.0000, running_acc=0.9777, grad=13.1549]Training epoch 33:  75%|███████▌  | 123/163 [02:15<00:45,  1.13s/it, loss=0.1486, batch_acc=1.0000, running_acc=0.9779, grad=15.1184]Training epoch 33:  76%|███████▌  | 124/163 [02:15<00:41,  1.05s/it, loss=0.1486, batch_acc=1.0000, running_acc=0.9779, grad=15.1184]Training epoch 33:  76%|███████▌  | 124/163 [02:15<00:41,  1.05s/it, loss=0.2403, batch_acc=0.9375, running_acc=0.9776, grad=17.8124]Training epoch 33:  77%|███████▋  | 125/163 [02:17<00:42,  1.12s/it, loss=0.2403, batch_acc=0.9375, running_acc=0.9776, grad=17.8124]Training epoch 33:  77%|███████▋  | 125/163 [02:17<00:42,  1.12s/it, loss=0.1886, batch_acc=1.0000, running_acc=0.9778, grad=17.8934]Training epoch 33:  77%|███████▋  | 126/163 [02:18<00:39,  1.08s/it, loss=0.1886, batch_acc=1.0000, running_acc=0.9778, grad=17.8934]Training epoch 33:  77%|███████▋  | 126/163 [02:18<00:39,  1.08s/it, loss=0.1407, batch_acc=1.0000, running_acc=0.9779, grad=9.4410] Training epoch 33:  78%|███████▊  | 127/163 [02:19<00:36,  1.02s/it, loss=0.1407, batch_acc=1.0000, running_acc=0.9779, grad=9.4410]Training epoch 33:  78%|███████▊  | 127/163 [02:19<00:36,  1.02s/it, loss=0.2316, batch_acc=0.9375, running_acc=0.9776, grad=14.3576]Training epoch 33:  79%|███████▊  | 128/163 [02:19<00:34,  1.02it/s, loss=0.2316, batch_acc=0.9375, running_acc=0.9776, grad=14.3576]Training epoch 33:  79%|███████▊  | 128/163 [02:19<00:34,  1.02it/s, loss=0.2372, batch_acc=0.9375, running_acc=0.9773, grad=18.1352]Training epoch 33:  79%|███████▉  | 129/163 [02:21<00:36,  1.07s/it, loss=0.2372, batch_acc=0.9375, running_acc=0.9773, grad=18.1352]Training epoch 33:  79%|███████▉  | 129/163 [02:21<00:36,  1.07s/it, loss=0.1568, batch_acc=0.9688, running_acc=0.9772, grad=11.2274]Training epoch 33:  80%|███████▉  | 130/163 [02:22<00:33,  1.03s/it, loss=0.1568, batch_acc=0.9688, running_acc=0.9772, grad=11.2274]Training epoch 33:  80%|███████▉  | 130/163 [02:22<00:33,  1.03s/it, loss=0.1248, batch_acc=1.0000, running_acc=0.9774, grad=8.9315] Training epoch 33:  80%|████████  | 131/163 [02:23<00:31,  1.02it/s, loss=0.1248, batch_acc=1.0000, running_acc=0.9774, grad=8.9315]Training epoch 33:  80%|████████  | 131/163 [02:23<00:31,  1.02it/s, loss=0.1804, batch_acc=1.0000, running_acc=0.9776, grad=13.7590]Training epoch 33:  81%|████████  | 132/163 [02:23<00:29,  1.05it/s, loss=0.1804, batch_acc=1.0000, running_acc=0.9776, grad=13.7590]Training epoch 33:  81%|████████  | 132/163 [02:23<00:29,  1.05it/s, loss=0.1679, batch_acc=1.0000, running_acc=0.9777, grad=11.8358]Training epoch 33:  82%|████████▏ | 133/163 [02:25<00:32,  1.08s/it, loss=0.1679, batch_acc=1.0000, running_acc=0.9777, grad=11.8358]Training epoch 33:  82%|████████▏ | 133/163 [02:25<00:32,  1.08s/it, loss=0.1964, batch_acc=1.0000, running_acc=0.9779, grad=15.7387]Training epoch 33:  82%|████████▏ | 134/163 [02:26<00:29,  1.03s/it, loss=0.1964, batch_acc=1.0000, running_acc=0.9779, grad=15.7387]Training epoch 33:  82%|████████▏ | 134/163 [02:26<00:29,  1.03s/it, loss=0.1499, batch_acc=1.0000, running_acc=0.9781, grad=11.2798]Training epoch 33:  83%|████████▎ | 135/163 [02:27<00:27,  1.02it/s, loss=0.1499, batch_acc=1.0000, running_acc=0.9781, grad=11.2798]Training epoch 33:  83%|████████▎ | 135/163 [02:27<00:27,  1.02it/s, loss=0.2698, batch_acc=0.9375, running_acc=0.9778, grad=19.8910]Training epoch 33:  83%|████████▎ | 136/163 [02:27<00:25,  1.05it/s, loss=0.2698, batch_acc=0.9375, running_acc=0.9778, grad=19.8910]Training epoch 33:  83%|████████▎ | 136/163 [02:27<00:25,  1.05it/s, loss=0.1926, batch_acc=0.9375, running_acc=0.9775, grad=12.9425]Training epoch 33:  84%|████████▍ | 137/163 [02:29<00:26,  1.02s/it, loss=0.1926, batch_acc=0.9375, running_acc=0.9775, grad=12.9425]Training epoch 33:  84%|████████▍ | 137/163 [02:29<00:26,  1.02s/it, loss=0.2241, batch_acc=0.9688, running_acc=0.9774, grad=14.1375]Training epoch 33:  85%|████████▍ | 138/163 [02:30<00:26,  1.04s/it, loss=0.2241, batch_acc=0.9688, running_acc=0.9774, grad=14.1375]Training epoch 33:  85%|████████▍ | 138/163 [02:30<00:26,  1.04s/it, loss=0.3066, batch_acc=0.9375, running_acc=0.9771, grad=18.0052]Training epoch 33:  85%|████████▌ | 139/163 [02:31<00:23,  1.01it/s, loss=0.3066, batch_acc=0.9375, running_acc=0.9771, grad=18.0052]Training epoch 33:  85%|████████▌ | 139/163 [02:31<00:23,  1.01it/s, loss=0.1837, batch_acc=0.9375, running_acc=0.9768, grad=11.1586]Training epoch 33:  86%|████████▌ | 140/163 [02:31<00:22,  1.04it/s, loss=0.1837, batch_acc=0.9375, running_acc=0.9768, grad=11.1586]Training epoch 33:  86%|████████▌ | 140/163 [02:31<00:22,  1.04it/s, loss=0.1248, batch_acc=1.0000, running_acc=0.9770, grad=11.2462]Training epoch 33:  87%|████████▋ | 141/163 [02:32<00:20,  1.07it/s, loss=0.1248, batch_acc=1.0000, running_acc=0.9770, grad=11.2462]Training epoch 33:  87%|████████▋ | 141/163 [02:32<00:20,  1.07it/s, loss=0.1833, batch_acc=0.9688, running_acc=0.9770, grad=17.7778]Training epoch 33:  87%|████████▋ | 142/163 [02:34<00:24,  1.15s/it, loss=0.1833, batch_acc=0.9688, running_acc=0.9770, grad=17.7778]Training epoch 33:  87%|████████▋ | 142/163 [02:34<00:24,  1.15s/it, loss=0.1845, batch_acc=1.0000, running_acc=0.9771, grad=13.7508]Training epoch 33:  88%|████████▊ | 143/163 [02:35<00:21,  1.07s/it, loss=0.1845, batch_acc=1.0000, running_acc=0.9771, grad=13.7508]Training epoch 33:  88%|████████▊ | 143/163 [02:35<00:21,  1.07s/it, loss=0.2000, batch_acc=1.0000, running_acc=0.9773, grad=15.7856]Training epoch 33:  88%|████████▊ | 144/163 [02:36<00:19,  1.01s/it, loss=0.2000, batch_acc=1.0000, running_acc=0.9773, grad=15.7856]Training epoch 33:  88%|████████▊ | 144/163 [02:36<00:19,  1.01s/it, loss=0.2215, batch_acc=0.9688, running_acc=0.9772, grad=14.0936]Training epoch 33:  89%|████████▉ | 145/163 [02:37<00:17,  1.03it/s, loss=0.2215, batch_acc=0.9688, running_acc=0.9772, grad=14.0936]Training epoch 33:  89%|████████▉ | 145/163 [02:37<00:17,  1.03it/s, loss=0.2557, batch_acc=0.9688, running_acc=0.9772, grad=18.0377]Training epoch 33:  90%|████████▉ | 146/163 [02:38<00:20,  1.22s/it, loss=0.2557, batch_acc=0.9688, running_acc=0.9772, grad=18.0377]Training epoch 33:  90%|████████▉ | 146/163 [02:38<00:20,  1.22s/it, loss=0.1483, batch_acc=1.0000, running_acc=0.9773, grad=10.2245]Training epoch 33:  90%|█████████ | 147/163 [02:39<00:17,  1.11s/it, loss=0.1483, batch_acc=1.0000, running_acc=0.9773, grad=10.2245]Training epoch 33:  90%|█████████ | 147/163 [02:39<00:17,  1.11s/it, loss=0.1484, batch_acc=1.0000, running_acc=0.9775, grad=14.3064]Training epoch 33:  91%|█████████ | 148/163 [02:40<00:15,  1.04s/it, loss=0.1484, batch_acc=1.0000, running_acc=0.9775, grad=14.3064]Training epoch 33:  91%|█████████ | 148/163 [02:40<00:15,  1.04s/it, loss=0.1594, batch_acc=0.9688, running_acc=0.9774, grad=11.0216]Training epoch 33:  91%|█████████▏| 149/163 [02:41<00:13,  1.01it/s, loss=0.1594, batch_acc=0.9688, running_acc=0.9774, grad=11.0216]Training epoch 33:  91%|█████████▏| 149/163 [02:41<00:13,  1.01it/s, loss=0.1091, batch_acc=1.0000, running_acc=0.9776, grad=8.7760] Training epoch 33:  92%|█████████▏| 150/163 [02:42<00:14,  1.10s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9776, grad=8.7760]Training epoch 33:  92%|█████████▏| 150/163 [02:42<00:14,  1.10s/it, loss=0.1851, batch_acc=0.9688, running_acc=0.9775, grad=14.0422]Training epoch 33:  93%|█████████▎| 151/163 [02:43<00:12,  1.03s/it, loss=0.1851, batch_acc=0.9688, running_acc=0.9775, grad=14.0422]Training epoch 33:  93%|█████████▎| 151/163 [02:43<00:12,  1.03s/it, loss=0.2331, batch_acc=0.9688, running_acc=0.9774, grad=16.2944]Training epoch 33:  93%|█████████▎| 152/163 [02:44<00:10,  1.01it/s, loss=0.2331, batch_acc=0.9688, running_acc=0.9774, grad=16.2944]Training epoch 33:  93%|█████████▎| 152/163 [02:44<00:10,  1.01it/s, loss=0.1778, batch_acc=0.9688, running_acc=0.9774, grad=11.2066]Training epoch 33:  94%|█████████▍| 153/163 [02:45<00:09,  1.05it/s, loss=0.1778, batch_acc=0.9688, running_acc=0.9774, grad=11.2066]Training epoch 33:  94%|█████████▍| 153/163 [02:45<00:09,  1.05it/s, loss=0.1929, batch_acc=0.9688, running_acc=0.9773, grad=14.4238]Training epoch 33:  94%|█████████▍| 154/163 [02:47<00:10,  1.14s/it, loss=0.1929, batch_acc=0.9688, running_acc=0.9773, grad=14.4238]Training epoch 33:  94%|█████████▍| 154/163 [02:47<00:10,  1.14s/it, loss=0.2271, batch_acc=1.0000, running_acc=0.9775, grad=12.7516]Training epoch 33:  95%|█████████▌| 155/163 [02:47<00:08,  1.06s/it, loss=0.2271, batch_acc=1.0000, running_acc=0.9775, grad=12.7516]Training epoch 33:  95%|█████████▌| 155/163 [02:47<00:08,  1.06s/it, loss=0.1515, batch_acc=0.9688, running_acc=0.9774, grad=8.6478] Training epoch 33:  96%|█████████▌| 156/163 [02:48<00:07,  1.01s/it, loss=0.1515, batch_acc=0.9688, running_acc=0.9774, grad=8.6478]Training epoch 33:  96%|█████████▌| 156/163 [02:48<00:07,  1.01s/it, loss=0.1550, batch_acc=1.0000, running_acc=0.9776, grad=10.8487]Training epoch 33:  96%|█████████▋| 157/163 [02:49<00:05,  1.03it/s, loss=0.1550, batch_acc=1.0000, running_acc=0.9776, grad=10.8487]Training epoch 33:  96%|█████████▋| 157/163 [02:49<00:05,  1.03it/s, loss=0.1728, batch_acc=1.0000, running_acc=0.9777, grad=11.1024]Training epoch 33:  97%|█████████▋| 158/163 [02:51<00:05,  1.08s/it, loss=0.1728, batch_acc=1.0000, running_acc=0.9777, grad=11.1024]Training epoch 33:  97%|█████████▋| 158/163 [02:51<00:05,  1.08s/it, loss=0.1723, batch_acc=0.9688, running_acc=0.9777, grad=10.6580]Training epoch 33:  98%|█████████▊| 159/163 [02:51<00:04,  1.02s/it, loss=0.1723, batch_acc=0.9688, running_acc=0.9777, grad=10.6580]Training epoch 33:  98%|█████████▊| 159/163 [02:51<00:04,  1.02s/it, loss=0.1470, batch_acc=1.0000, running_acc=0.9778, grad=9.7274] Training epoch 33:  98%|█████████▊| 160/163 [02:52<00:02,  1.03it/s, loss=0.1470, batch_acc=1.0000, running_acc=0.9778, grad=9.7274]Training epoch 33:  98%|█████████▊| 160/163 [02:52<00:02,  1.03it/s, loss=0.1586, batch_acc=1.0000, running_acc=0.9779, grad=17.8375]Training epoch 33:  99%|█████████▉| 161/163 [02:53<00:01,  1.06it/s, loss=0.1586, batch_acc=1.0000, running_acc=0.9779, grad=17.8375]Training epoch 33:  99%|█████████▉| 161/163 [02:53<00:01,  1.06it/s, loss=0.1834, batch_acc=0.9375, running_acc=0.9777, grad=16.4773]Training epoch 33:  99%|█████████▉| 162/163 [02:54<00:00,  1.08it/s, loss=0.1834, batch_acc=0.9375, running_acc=0.9777, grad=16.4773]Training epoch 33:  99%|█████████▉| 162/163 [02:54<00:00,  1.08it/s, loss=0.2181, batch_acc=0.9375, running_acc=0.9774, grad=12.3850]Training epoch 33: 100%|██████████| 163/163 [02:55<00:00,  1.19it/s, loss=0.2181, batch_acc=0.9375, running_acc=0.9774, grad=12.3850]Training epoch 33: 100%|██████████| 163/163 [02:55<00:00,  1.19it/s, loss=0.1464, batch_acc=1.0000, running_acc=0.9775, grad=20.8866]Training epoch 33: 100%|██████████| 163/163 [02:55<00:00,  1.08s/it, loss=0.1464, batch_acc=1.0000, running_acc=0.9775, grad=20.8866]
Evaluation epoch 33:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 33:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it]Evaluation epoch 33:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it, loss=0.4670, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:   7%|▋         | 2/28 [00:05<00:57,  2.20s/it, loss=0.4670, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:   7%|▋         | 2/28 [00:05<00:57,  2.20s/it, loss=0.3448, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 33:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3448, batch_acc=0.9375, running_acc=0.9062]Evaluation epoch 33:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.4415, batch_acc=0.9688, running_acc=0.9271]Evaluation epoch 33:  14%|█▍        | 4/28 [00:09<00:58,  2.43s/it, loss=0.4415, batch_acc=0.9688, running_acc=0.9271]Evaluation epoch 33:  14%|█▍        | 4/28 [00:09<00:58,  2.43s/it, loss=0.5508, batch_acc=0.9062, running_acc=0.9219]Evaluation epoch 33:  18%|█▊        | 5/28 [00:09<00:37,  1.65s/it, loss=0.5508, batch_acc=0.9062, running_acc=0.9219]Evaluation epoch 33:  18%|█▊        | 5/28 [00:09<00:37,  1.65s/it, loss=1.4287, batch_acc=0.6875, running_acc=0.8750]Evaluation epoch 33:  21%|██▏       | 6/28 [00:10<00:25,  1.18s/it, loss=1.4287, batch_acc=0.6875, running_acc=0.8750]Evaluation epoch 33:  21%|██▏       | 6/28 [00:10<00:25,  1.18s/it, loss=0.5864, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=0.5864, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=0.6688, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:  29%|██▊       | 8/28 [00:13<00:32,  1.63s/it, loss=0.6688, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:  29%|██▊       | 8/28 [00:13<00:32,  1.63s/it, loss=0.4350, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:  32%|███▏      | 9/28 [00:14<00:27,  1.43s/it, loss=0.4350, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 33:  32%|███▏      | 9/28 [00:14<00:27,  1.43s/it, loss=0.5096, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 33:  36%|███▌      | 10/28 [00:14<00:19,  1.07s/it, loss=0.5096, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 33:  36%|███▌      | 10/28 [00:14<00:19,  1.07s/it, loss=0.5090, batch_acc=0.9062, running_acc=0.8812]Evaluation epoch 33:  39%|███▉      | 11/28 [00:15<00:13,  1.22it/s, loss=0.5090, batch_acc=0.9062, running_acc=0.8812]Evaluation epoch 33:  39%|███▉      | 11/28 [00:15<00:13,  1.22it/s, loss=0.4045, batch_acc=0.9062, running_acc=0.8835]Evaluation epoch 33:  43%|████▎     | 12/28 [00:19<00:32,  2.04s/it, loss=0.4045, batch_acc=0.9062, running_acc=0.8835]Evaluation epoch 33:  43%|████▎     | 12/28 [00:19<00:32,  2.04s/it, loss=0.9096, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 33:  46%|████▋     | 13/28 [00:20<00:22,  1.50s/it, loss=0.9096, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 33:  46%|████▋     | 13/28 [00:20<00:22,  1.50s/it, loss=0.3475, batch_acc=0.9375, running_acc=0.8798]Evaluation epoch 33:  50%|█████     | 14/28 [00:20<00:15,  1.13s/it, loss=0.3475, batch_acc=0.9375, running_acc=0.8798]Evaluation epoch 33:  50%|█████     | 14/28 [00:20<00:15,  1.13s/it, loss=0.9635, batch_acc=0.7812, running_acc=0.8728]Evaluation epoch 33:  54%|█████▎    | 15/28 [00:20<00:11,  1.16it/s, loss=0.9635, batch_acc=0.7812, running_acc=0.8728]Evaluation epoch 33:  54%|█████▎    | 15/28 [00:20<00:11,  1.16it/s, loss=1.0840, batch_acc=0.7188, running_acc=0.8625]Evaluation epoch 33:  57%|█████▋    | 16/28 [00:23<00:17,  1.45s/it, loss=1.0840, batch_acc=0.7188, running_acc=0.8625]Evaluation epoch 33:  57%|█████▋    | 16/28 [00:23<00:17,  1.45s/it, loss=0.6988, batch_acc=0.7812, running_acc=0.8574]Evaluation epoch 33:  61%|██████    | 17/28 [00:23<00:12,  1.09s/it, loss=0.6988, batch_acc=0.7812, running_acc=0.8574]Evaluation epoch 33:  61%|██████    | 17/28 [00:23<00:12,  1.09s/it, loss=0.4935, batch_acc=0.8438, running_acc=0.8566]Evaluation epoch 33:  64%|██████▍   | 18/28 [00:24<00:08,  1.19it/s, loss=0.4935, batch_acc=0.8438, running_acc=0.8566]Evaluation epoch 33:  64%|██████▍   | 18/28 [00:24<00:08,  1.19it/s, loss=0.5219, batch_acc=0.8438, running_acc=0.8559]Evaluation epoch 33:  68%|██████▊   | 19/28 [00:24<00:06,  1.50it/s, loss=0.5219, batch_acc=0.8438, running_acc=0.8559]Evaluation epoch 33:  68%|██████▊   | 19/28 [00:24<00:06,  1.50it/s, loss=0.9391, batch_acc=0.6250, running_acc=0.8438]Evaluation epoch 33:  71%|███████▏  | 20/28 [00:27<00:10,  1.29s/it, loss=0.9391, batch_acc=0.6250, running_acc=0.8438]Evaluation epoch 33:  71%|███████▏  | 20/28 [00:27<00:10,  1.29s/it, loss=0.6256, batch_acc=0.6875, running_acc=0.8359]Evaluation epoch 33:  75%|███████▌  | 21/28 [00:27<00:06,  1.02it/s, loss=0.6256, batch_acc=0.6875, running_acc=0.8359]Evaluation epoch 33:  75%|███████▌  | 21/28 [00:27<00:06,  1.02it/s, loss=0.5591, batch_acc=0.8438, running_acc=0.8363]Evaluation epoch 33:  79%|███████▊  | 22/28 [00:27<00:04,  1.31it/s, loss=0.5591, batch_acc=0.8438, running_acc=0.8363]Evaluation epoch 33:  79%|███████▊  | 22/28 [00:27<00:04,  1.31it/s, loss=0.5797, batch_acc=0.9062, running_acc=0.8395]Evaluation epoch 33:  82%|████████▏ | 23/28 [00:27<00:03,  1.63it/s, loss=0.5797, batch_acc=0.9062, running_acc=0.8395]Evaluation epoch 33:  82%|████████▏ | 23/28 [00:27<00:03,  1.63it/s, loss=0.8567, batch_acc=0.7812, running_acc=0.8370]Evaluation epoch 33:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=0.8567, batch_acc=0.7812, running_acc=0.8370]Evaluation epoch 33:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=0.3223, batch_acc=0.9375, running_acc=0.8411]Evaluation epoch 33:  89%|████████▉ | 25/28 [00:33<00:04,  1.48s/it, loss=0.3223, batch_acc=0.9375, running_acc=0.8411]Evaluation epoch 33:  89%|████████▉ | 25/28 [00:33<00:04,  1.48s/it, loss=0.1773, batch_acc=0.9688, running_acc=0.8462]Evaluation epoch 33:  93%|█████████▎| 26/28 [00:33<00:02,  1.11s/it, loss=0.1773, batch_acc=0.9688, running_acc=0.8462]Evaluation epoch 33:  93%|█████████▎| 26/28 [00:33<00:02,  1.11s/it, loss=0.6503, batch_acc=0.8438, running_acc=0.8462]Evaluation epoch 33:  96%|█████████▋| 27/28 [00:33<00:00,  1.17it/s, loss=0.6503, batch_acc=0.8438, running_acc=0.8462]Evaluation epoch 33:  96%|█████████▋| 27/28 [00:33<00:00,  1.17it/s, loss=0.8763, batch_acc=0.7500, running_acc=0.8426]Evaluation epoch 33: 100%|██████████| 28/28 [00:33<00:00,  1.17it/s, loss=1.5429, batch_acc=0.6667, running_acc=0.8420]Evaluation epoch 33: 100%|██████████| 28/28 [00:33<00:00,  1.21s/it, loss=1.5429, batch_acc=0.6667, running_acc=0.8420]
Training epoch 34:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 34:   1%|          | 1/163 [00:06<16:53,  6.26s/it]Training epoch 34:   1%|          | 1/163 [00:06<16:53,  6.26s/it, loss=0.1624, batch_acc=1.0000, running_acc=1.0000, grad=14.7340]Training epoch 34:   1%|          | 2/163 [00:07<08:18,  3.09s/it, loss=0.1624, batch_acc=1.0000, running_acc=1.0000, grad=14.7340]Training epoch 34:   1%|          | 2/163 [00:07<08:18,  3.09s/it, loss=0.1610, batch_acc=0.9688, running_acc=0.9844, grad=9.8069] Training epoch 34:   2%|▏         | 3/163 [00:08<05:33,  2.08s/it, loss=0.1610, batch_acc=0.9688, running_acc=0.9844, grad=9.8069]Training epoch 34:   2%|▏         | 3/163 [00:08<05:33,  2.08s/it, loss=0.1477, batch_acc=1.0000, running_acc=0.9896, grad=11.0064]Training epoch 34:   2%|▏         | 4/163 [00:10<06:08,  2.32s/it, loss=0.1477, batch_acc=1.0000, running_acc=0.9896, grad=11.0064]Training epoch 34:   2%|▏         | 4/163 [00:10<06:08,  2.32s/it, loss=0.1316, batch_acc=1.0000, running_acc=0.9922, grad=9.4632] Training epoch 34:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=0.1316, batch_acc=1.0000, running_acc=0.9922, grad=9.4632]Training epoch 34:   3%|▎         | 5/163 [00:11<04:44,  1.80s/it, loss=0.1532, batch_acc=1.0000, running_acc=0.9938, grad=10.1591]Training epoch 34:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=0.1532, batch_acc=1.0000, running_acc=0.9938, grad=10.1591]Training epoch 34:   4%|▎         | 6/163 [00:12<03:53,  1.49s/it, loss=0.2356, batch_acc=0.9688, running_acc=0.9896, grad=15.6372]Training epoch 34:   4%|▍         | 7/163 [00:13<03:21,  1.29s/it, loss=0.2356, batch_acc=0.9688, running_acc=0.9896, grad=15.6372]Training epoch 34:   4%|▍         | 7/163 [00:13<03:21,  1.29s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.9911, grad=8.3749] Training epoch 34:   5%|▍         | 8/163 [00:15<03:44,  1.45s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.9911, grad=8.3749]Training epoch 34:   5%|▍         | 8/163 [00:15<03:44,  1.45s/it, loss=0.1319, batch_acc=1.0000, running_acc=0.9922, grad=8.4581]Training epoch 34:   6%|▌         | 9/163 [00:15<03:15,  1.27s/it, loss=0.1319, batch_acc=1.0000, running_acc=0.9922, grad=8.4581]Training epoch 34:   6%|▌         | 9/163 [00:15<03:15,  1.27s/it, loss=0.1644, batch_acc=0.9375, running_acc=0.9861, grad=13.2861]Training epoch 34:   6%|▌         | 10/163 [00:16<02:55,  1.15s/it, loss=0.1644, batch_acc=0.9375, running_acc=0.9861, grad=13.2861]Training epoch 34:   6%|▌         | 10/163 [00:16<02:55,  1.15s/it, loss=0.1908, batch_acc=0.9688, running_acc=0.9844, grad=12.8672]Training epoch 34:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=0.1908, batch_acc=0.9688, running_acc=0.9844, grad=12.8672]Training epoch 34:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=0.1598, batch_acc=0.9688, running_acc=0.9830, grad=14.5960]Training epoch 34:   7%|▋         | 12/163 [00:19<03:06,  1.23s/it, loss=0.1598, batch_acc=0.9688, running_acc=0.9830, grad=14.5960]Training epoch 34:   7%|▋         | 12/163 [00:19<03:06,  1.23s/it, loss=0.1391, batch_acc=0.9688, running_acc=0.9818, grad=9.2177] Training epoch 34:   8%|▊         | 13/163 [00:20<02:48,  1.13s/it, loss=0.1391, batch_acc=0.9688, running_acc=0.9818, grad=9.2177]Training epoch 34:   8%|▊         | 13/163 [00:20<02:48,  1.13s/it, loss=0.2153, batch_acc=0.9688, running_acc=0.9808, grad=16.4039]Training epoch 34:   9%|▊         | 14/163 [00:21<02:36,  1.05s/it, loss=0.2153, batch_acc=0.9688, running_acc=0.9808, grad=16.4039]Training epoch 34:   9%|▊         | 14/163 [00:21<02:36,  1.05s/it, loss=0.1146, batch_acc=0.9688, running_acc=0.9799, grad=9.8052] Training epoch 34:   9%|▉         | 15/163 [00:22<02:28,  1.00s/it, loss=0.1146, batch_acc=0.9688, running_acc=0.9799, grad=9.8052]Training epoch 34:   9%|▉         | 15/163 [00:22<02:28,  1.00s/it, loss=0.2193, batch_acc=0.9375, running_acc=0.9771, grad=15.2250]Training epoch 34:  10%|▉         | 16/163 [00:23<03:01,  1.24s/it, loss=0.2193, batch_acc=0.9375, running_acc=0.9771, grad=15.2250]Training epoch 34:  10%|▉         | 16/163 [00:23<03:01,  1.24s/it, loss=0.1745, batch_acc=0.9375, running_acc=0.9746, grad=8.7559] Training epoch 34:  10%|█         | 17/163 [00:24<02:44,  1.13s/it, loss=0.1745, batch_acc=0.9375, running_acc=0.9746, grad=8.7559]Training epoch 34:  10%|█         | 17/163 [00:24<02:44,  1.13s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9761, grad=8.8406]Training epoch 34:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9761, grad=8.8406]Training epoch 34:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.1521, batch_acc=1.0000, running_acc=0.9774, grad=19.9097]Training epoch 34:  12%|█▏        | 19/163 [00:26<02:24,  1.00s/it, loss=0.1521, batch_acc=1.0000, running_acc=0.9774, grad=19.9097]Training epoch 34:  12%|█▏        | 19/163 [00:26<02:24,  1.00s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9786, grad=9.2312] Training epoch 34:  12%|█▏        | 20/163 [00:28<02:50,  1.19s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9786, grad=9.2312]Training epoch 34:  12%|█▏        | 20/163 [00:28<02:50,  1.19s/it, loss=0.1158, batch_acc=1.0000, running_acc=0.9797, grad=8.9898]Training epoch 34:  13%|█▎        | 21/163 [00:28<02:35,  1.10s/it, loss=0.1158, batch_acc=1.0000, running_acc=0.9797, grad=8.9898]Training epoch 34:  13%|█▎        | 21/163 [00:28<02:35,  1.10s/it, loss=0.1569, batch_acc=1.0000, running_acc=0.9807, grad=12.9621]Training epoch 34:  13%|█▎        | 22/163 [00:29<02:25,  1.03s/it, loss=0.1569, batch_acc=1.0000, running_acc=0.9807, grad=12.9621]Training epoch 34:  13%|█▎        | 22/163 [00:29<02:25,  1.03s/it, loss=0.1682, batch_acc=1.0000, running_acc=0.9815, grad=11.9187]Training epoch 34:  14%|█▍        | 23/163 [00:30<02:17,  1.02it/s, loss=0.1682, batch_acc=1.0000, running_acc=0.9815, grad=11.9187]Training epoch 34:  14%|█▍        | 23/163 [00:30<02:17,  1.02it/s, loss=0.1686, batch_acc=1.0000, running_acc=0.9823, grad=14.3508]Training epoch 34:  15%|█▍        | 24/163 [00:32<02:29,  1.08s/it, loss=0.1686, batch_acc=1.0000, running_acc=0.9823, grad=14.3508]Training epoch 34:  15%|█▍        | 24/163 [00:32<02:29,  1.08s/it, loss=0.1824, batch_acc=0.9688, running_acc=0.9818, grad=14.4842]Training epoch 34:  15%|█▌        | 25/163 [00:32<02:20,  1.02s/it, loss=0.1824, batch_acc=0.9688, running_acc=0.9818, grad=14.4842]Training epoch 34:  15%|█▌        | 25/163 [00:32<02:20,  1.02s/it, loss=0.1847, batch_acc=1.0000, running_acc=0.9825, grad=8.7198] Training epoch 34:  16%|█▌        | 26/163 [00:33<02:13,  1.02it/s, loss=0.1847, batch_acc=1.0000, running_acc=0.9825, grad=8.7198]Training epoch 34:  16%|█▌        | 26/163 [00:33<02:13,  1.02it/s, loss=0.1302, batch_acc=1.0000, running_acc=0.9832, grad=9.1846]Training epoch 34:  17%|█▋        | 27/163 [00:34<02:09,  1.05it/s, loss=0.1302, batch_acc=1.0000, running_acc=0.9832, grad=9.1846]Training epoch 34:  17%|█▋        | 27/163 [00:34<02:09,  1.05it/s, loss=0.1695, batch_acc=0.9688, running_acc=0.9826, grad=7.8589]Training epoch 34:  17%|█▋        | 28/163 [00:35<02:21,  1.05s/it, loss=0.1695, batch_acc=0.9688, running_acc=0.9826, grad=7.8589]Training epoch 34:  17%|█▋        | 28/163 [00:35<02:21,  1.05s/it, loss=0.1673, batch_acc=0.9375, running_acc=0.9810, grad=10.8015]Training epoch 34:  18%|█▊        | 29/163 [00:36<02:13,  1.00it/s, loss=0.1673, batch_acc=0.9375, running_acc=0.9810, grad=10.8015]Training epoch 34:  18%|█▊        | 29/163 [00:36<02:13,  1.00it/s, loss=0.1888, batch_acc=0.9375, running_acc=0.9795, grad=14.6030]Training epoch 34:  18%|█▊        | 30/163 [00:37<02:08,  1.04it/s, loss=0.1888, batch_acc=0.9375, running_acc=0.9795, grad=14.6030]Training epoch 34:  18%|█▊        | 30/163 [00:37<02:08,  1.04it/s, loss=0.1419, batch_acc=1.0000, running_acc=0.9802, grad=9.4497] Training epoch 34:  19%|█▉        | 31/163 [00:38<02:03,  1.06it/s, loss=0.1419, batch_acc=1.0000, running_acc=0.9802, grad=9.4497]Training epoch 34:  19%|█▉        | 31/163 [00:38<02:03,  1.06it/s, loss=0.1805, batch_acc=1.0000, running_acc=0.9808, grad=15.8497]Training epoch 34:  20%|█▉        | 32/163 [00:40<02:50,  1.30s/it, loss=0.1805, batch_acc=1.0000, running_acc=0.9808, grad=15.8497]Training epoch 34:  20%|█▉        | 32/163 [00:40<02:50,  1.30s/it, loss=0.1259, batch_acc=1.0000, running_acc=0.9814, grad=14.3450]Training epoch 34:  20%|██        | 33/163 [00:41<02:36,  1.20s/it, loss=0.1259, batch_acc=1.0000, running_acc=0.9814, grad=14.3450]Training epoch 34:  20%|██        | 33/163 [00:41<02:36,  1.20s/it, loss=0.1447, batch_acc=1.0000, running_acc=0.9820, grad=12.3391]Training epoch 34:  21%|██        | 34/163 [00:42<02:22,  1.11s/it, loss=0.1447, batch_acc=1.0000, running_acc=0.9820, grad=12.3391]Training epoch 34:  21%|██        | 34/163 [00:42<02:22,  1.11s/it, loss=0.1662, batch_acc=1.0000, running_acc=0.9825, grad=15.9568]Training epoch 34:  21%|██▏       | 35/163 [00:43<02:13,  1.04s/it, loss=0.1662, batch_acc=1.0000, running_acc=0.9825, grad=15.9568]Training epoch 34:  21%|██▏       | 35/163 [00:43<02:13,  1.04s/it, loss=0.2048, batch_acc=0.9375, running_acc=0.9812, grad=19.6164]Training epoch 34:  22%|██▏       | 36/163 [00:45<02:33,  1.21s/it, loss=0.2048, batch_acc=0.9375, running_acc=0.9812, grad=19.6164]Training epoch 34:  22%|██▏       | 36/163 [00:45<02:33,  1.21s/it, loss=0.2150, batch_acc=1.0000, running_acc=0.9818, grad=15.6853]Training epoch 34:  23%|██▎       | 37/163 [00:45<02:19,  1.11s/it, loss=0.2150, batch_acc=1.0000, running_acc=0.9818, grad=15.6853]Training epoch 34:  23%|██▎       | 37/163 [00:45<02:19,  1.11s/it, loss=0.1601, batch_acc=0.9375, running_acc=0.9806, grad=9.2486] Training epoch 34:  23%|██▎       | 38/163 [00:46<02:09,  1.04s/it, loss=0.1601, batch_acc=0.9375, running_acc=0.9806, grad=9.2486]Training epoch 34:  23%|██▎       | 38/163 [00:46<02:09,  1.04s/it, loss=0.1452, batch_acc=1.0000, running_acc=0.9811, grad=12.2879]Training epoch 34:  24%|██▍       | 39/163 [00:47<02:02,  1.01it/s, loss=0.1452, batch_acc=1.0000, running_acc=0.9811, grad=12.2879]Training epoch 34:  24%|██▍       | 39/163 [00:47<02:02,  1.01it/s, loss=0.1296, batch_acc=1.0000, running_acc=0.9816, grad=9.0098] Training epoch 34:  25%|██▍       | 40/163 [00:49<02:48,  1.37s/it, loss=0.1296, batch_acc=1.0000, running_acc=0.9816, grad=9.0098]Training epoch 34:  25%|██▍       | 40/163 [00:49<02:48,  1.37s/it, loss=0.2232, batch_acc=0.9688, running_acc=0.9812, grad=14.0123]Training epoch 34:  25%|██▌       | 41/163 [00:50<02:28,  1.22s/it, loss=0.2232, batch_acc=0.9688, running_acc=0.9812, grad=14.0123]Training epoch 34:  25%|██▌       | 41/163 [00:50<02:28,  1.22s/it, loss=0.1951, batch_acc=1.0000, running_acc=0.9817, grad=20.1925]Training epoch 34:  26%|██▌       | 42/163 [00:51<02:15,  1.12s/it, loss=0.1951, batch_acc=1.0000, running_acc=0.9817, grad=20.1925]Training epoch 34:  26%|██▌       | 42/163 [00:51<02:15,  1.12s/it, loss=0.1928, batch_acc=0.9688, running_acc=0.9814, grad=12.5303]Training epoch 34:  26%|██▋       | 43/163 [00:52<02:05,  1.05s/it, loss=0.1928, batch_acc=0.9688, running_acc=0.9814, grad=12.5303]Training epoch 34:  26%|██▋       | 43/163 [00:52<02:05,  1.05s/it, loss=0.1524, batch_acc=1.0000, running_acc=0.9818, grad=13.2896]Training epoch 34:  27%|██▋       | 44/163 [00:54<02:27,  1.24s/it, loss=0.1524, batch_acc=1.0000, running_acc=0.9818, grad=13.2896]Training epoch 34:  27%|██▋       | 44/163 [00:54<02:27,  1.24s/it, loss=0.2104, batch_acc=1.0000, running_acc=0.9822, grad=19.0663]Training epoch 34:  28%|██▊       | 45/163 [00:55<02:13,  1.13s/it, loss=0.2104, batch_acc=1.0000, running_acc=0.9822, grad=19.0663]Training epoch 34:  28%|██▊       | 45/163 [00:55<02:13,  1.13s/it, loss=0.1153, batch_acc=1.0000, running_acc=0.9826, grad=9.0746] Training epoch 34:  28%|██▊       | 46/163 [00:56<02:03,  1.06s/it, loss=0.1153, batch_acc=1.0000, running_acc=0.9826, grad=9.0746]Training epoch 34:  28%|██▊       | 46/163 [00:56<02:03,  1.06s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9817, grad=12.1230]Training epoch 34:  29%|██▉       | 47/163 [00:56<01:56,  1.00s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9817, grad=12.1230]Training epoch 34:  29%|██▉       | 47/163 [00:56<01:56,  1.00s/it, loss=0.1492, batch_acc=1.0000, running_acc=0.9820, grad=9.7381] Training epoch 34:  29%|██▉       | 48/163 [00:58<02:19,  1.21s/it, loss=0.1492, batch_acc=1.0000, running_acc=0.9820, grad=9.7381]Training epoch 34:  29%|██▉       | 48/163 [00:58<02:19,  1.21s/it, loss=0.1864, batch_acc=0.9688, running_acc=0.9818, grad=14.9503]Training epoch 34:  30%|███       | 49/163 [00:59<02:06,  1.11s/it, loss=0.1864, batch_acc=0.9688, running_acc=0.9818, grad=14.9503]Training epoch 34:  30%|███       | 49/163 [00:59<02:06,  1.11s/it, loss=0.1377, batch_acc=0.9688, running_acc=0.9815, grad=8.8885] Training epoch 34:  31%|███       | 50/163 [01:00<01:57,  1.04s/it, loss=0.1377, batch_acc=0.9688, running_acc=0.9815, grad=8.8885]Training epoch 34:  31%|███       | 50/163 [01:00<01:57,  1.04s/it, loss=0.1476, batch_acc=0.9688, running_acc=0.9812, grad=9.5820]Training epoch 34:  31%|███▏      | 51/163 [01:01<01:51,  1.01it/s, loss=0.1476, batch_acc=0.9688, running_acc=0.9812, grad=9.5820]Training epoch 34:  31%|███▏      | 51/163 [01:01<01:51,  1.01it/s, loss=0.1801, batch_acc=1.0000, running_acc=0.9816, grad=15.5494]Training epoch 34:  32%|███▏      | 52/163 [01:02<02:06,  1.14s/it, loss=0.1801, batch_acc=1.0000, running_acc=0.9816, grad=15.5494]Training epoch 34:  32%|███▏      | 52/163 [01:02<02:06,  1.14s/it, loss=0.1772, batch_acc=1.0000, running_acc=0.9820, grad=16.0588]Training epoch 34:  33%|███▎      | 53/163 [01:03<01:56,  1.06s/it, loss=0.1772, batch_acc=1.0000, running_acc=0.9820, grad=16.0588]Training epoch 34:  33%|███▎      | 53/163 [01:03<01:56,  1.06s/it, loss=0.1399, batch_acc=1.0000, running_acc=0.9823, grad=12.2445]Training epoch 34:  33%|███▎      | 54/163 [01:04<01:49,  1.01s/it, loss=0.1399, batch_acc=1.0000, running_acc=0.9823, grad=12.2445]Training epoch 34:  33%|███▎      | 54/163 [01:04<01:49,  1.01s/it, loss=0.1702, batch_acc=1.0000, running_acc=0.9826, grad=19.6966]Training epoch 34:  34%|███▎      | 55/163 [01:05<01:44,  1.03it/s, loss=0.1702, batch_acc=1.0000, running_acc=0.9826, grad=19.6966]Training epoch 34:  34%|███▎      | 55/163 [01:05<01:44,  1.03it/s, loss=0.1010, batch_acc=1.0000, running_acc=0.9830, grad=6.1001] Training epoch 34:  34%|███▍      | 56/163 [01:06<01:55,  1.08s/it, loss=0.1010, batch_acc=1.0000, running_acc=0.9830, grad=6.1001]Training epoch 34:  34%|███▍      | 56/163 [01:06<01:55,  1.08s/it, loss=0.1780, batch_acc=1.0000, running_acc=0.9833, grad=14.8825]Training epoch 34:  35%|███▍      | 57/163 [01:07<01:47,  1.02s/it, loss=0.1780, batch_acc=1.0000, running_acc=0.9833, grad=14.8825]Training epoch 34:  35%|███▍      | 57/163 [01:07<01:47,  1.02s/it, loss=0.1329, batch_acc=1.0000, running_acc=0.9836, grad=10.9909]Training epoch 34:  36%|███▌      | 58/163 [01:08<01:42,  1.02it/s, loss=0.1329, batch_acc=1.0000, running_acc=0.9836, grad=10.9909]Training epoch 34:  36%|███▌      | 58/163 [01:08<01:42,  1.02it/s, loss=0.1444, batch_acc=0.9688, running_acc=0.9833, grad=9.5732] Training epoch 34:  36%|███▌      | 59/163 [01:09<01:38,  1.05it/s, loss=0.1444, batch_acc=0.9688, running_acc=0.9833, grad=9.5732]Training epoch 34:  36%|███▌      | 59/163 [01:09<01:38,  1.05it/s, loss=0.2388, batch_acc=0.9062, running_acc=0.9820, grad=12.6905]Training epoch 34:  37%|███▋      | 60/163 [01:11<02:02,  1.19s/it, loss=0.2388, batch_acc=0.9062, running_acc=0.9820, grad=12.6905]Training epoch 34:  37%|███▋      | 60/163 [01:11<02:02,  1.19s/it, loss=0.2295, batch_acc=0.9688, running_acc=0.9818, grad=29.7766]Training epoch 34:  37%|███▋      | 61/163 [01:11<01:51,  1.09s/it, loss=0.2295, batch_acc=0.9688, running_acc=0.9818, grad=29.7766]Training epoch 34:  37%|███▋      | 61/163 [01:11<01:51,  1.09s/it, loss=0.2069, batch_acc=0.9375, running_acc=0.9810, grad=16.5758]Training epoch 34:  38%|███▊      | 62/163 [01:12<01:44,  1.03s/it, loss=0.2069, batch_acc=0.9375, running_acc=0.9810, grad=16.5758]Training epoch 34:  38%|███▊      | 62/163 [01:12<01:44,  1.03s/it, loss=0.1281, batch_acc=1.0000, running_acc=0.9814, grad=9.8177] Training epoch 34:  39%|███▊      | 63/163 [01:13<01:38,  1.01it/s, loss=0.1281, batch_acc=1.0000, running_acc=0.9814, grad=9.8177]Training epoch 34:  39%|███▊      | 63/163 [01:13<01:38,  1.01it/s, loss=0.1927, batch_acc=0.9688, running_acc=0.9812, grad=11.2932]Training epoch 34:  39%|███▉      | 64/163 [01:15<01:50,  1.12s/it, loss=0.1927, batch_acc=0.9688, running_acc=0.9812, grad=11.2932]Training epoch 34:  39%|███▉      | 64/163 [01:15<01:50,  1.12s/it, loss=0.1786, batch_acc=0.9375, running_acc=0.9805, grad=12.7755]Training epoch 34:  40%|███▉      | 65/163 [01:16<01:42,  1.05s/it, loss=0.1786, batch_acc=0.9375, running_acc=0.9805, grad=12.7755]Training epoch 34:  40%|███▉      | 65/163 [01:16<01:42,  1.05s/it, loss=0.1760, batch_acc=0.9375, running_acc=0.9798, grad=18.9091]Training epoch 34:  40%|████      | 66/163 [01:16<01:36,  1.00it/s, loss=0.1760, batch_acc=0.9375, running_acc=0.9798, grad=18.9091]Training epoch 34:  40%|████      | 66/163 [01:16<01:36,  1.00it/s, loss=0.1338, batch_acc=1.0000, running_acc=0.9801, grad=10.7785]Training epoch 34:  41%|████      | 67/163 [01:17<01:32,  1.04it/s, loss=0.1338, batch_acc=1.0000, running_acc=0.9801, grad=10.7785]Training epoch 34:  41%|████      | 67/163 [01:17<01:32,  1.04it/s, loss=0.1406, batch_acc=1.0000, running_acc=0.9804, grad=9.7545] Training epoch 34:  42%|████▏     | 68/163 [01:19<01:59,  1.26s/it, loss=0.1406, batch_acc=1.0000, running_acc=0.9804, grad=9.7545]Training epoch 34:  42%|████▏     | 68/163 [01:19<01:59,  1.26s/it, loss=0.1331, batch_acc=1.0000, running_acc=0.9807, grad=9.8334]Training epoch 34:  42%|████▏     | 69/163 [01:20<01:47,  1.14s/it, loss=0.1331, batch_acc=1.0000, running_acc=0.9807, grad=9.8334]Training epoch 34:  42%|████▏     | 69/163 [01:20<01:47,  1.14s/it, loss=0.1586, batch_acc=1.0000, running_acc=0.9810, grad=11.5480]Training epoch 34:  43%|████▎     | 70/163 [01:21<01:39,  1.06s/it, loss=0.1586, batch_acc=1.0000, running_acc=0.9810, grad=11.5480]Training epoch 34:  43%|████▎     | 70/163 [01:21<01:39,  1.06s/it, loss=0.2398, batch_acc=0.9688, running_acc=0.9808, grad=23.0684]Training epoch 34:  44%|████▎     | 71/163 [01:22<01:32,  1.01s/it, loss=0.2398, batch_acc=0.9688, running_acc=0.9808, grad=23.0684]Training epoch 34:  44%|████▎     | 71/163 [01:22<01:32,  1.01s/it, loss=0.2127, batch_acc=0.9688, running_acc=0.9806, grad=19.2213]Training epoch 34:  44%|████▍     | 72/163 [01:24<01:53,  1.24s/it, loss=0.2127, batch_acc=0.9688, running_acc=0.9806, grad=19.2213]Training epoch 34:  44%|████▍     | 72/163 [01:24<01:53,  1.24s/it, loss=0.2386, batch_acc=0.9375, running_acc=0.9800, grad=13.9448]Training epoch 34:  45%|████▍     | 73/163 [01:25<01:42,  1.14s/it, loss=0.2386, batch_acc=0.9375, running_acc=0.9800, grad=13.9448]Training epoch 34:  45%|████▍     | 73/163 [01:25<01:42,  1.14s/it, loss=0.1805, batch_acc=1.0000, running_acc=0.9803, grad=10.8093]Training epoch 34:  45%|████▌     | 74/163 [01:25<01:34,  1.06s/it, loss=0.1805, batch_acc=1.0000, running_acc=0.9803, grad=10.8093]Training epoch 34:  45%|████▌     | 74/163 [01:25<01:34,  1.06s/it, loss=0.1639, batch_acc=0.9688, running_acc=0.9802, grad=16.2826]Training epoch 34:  46%|████▌     | 75/163 [01:26<01:28,  1.01s/it, loss=0.1639, batch_acc=0.9688, running_acc=0.9802, grad=16.2826]Training epoch 34:  46%|████▌     | 75/163 [01:26<01:28,  1.01s/it, loss=0.1429, batch_acc=1.0000, running_acc=0.9804, grad=11.9485]Training epoch 34:  47%|████▋     | 76/163 [01:28<01:47,  1.24s/it, loss=0.1429, batch_acc=1.0000, running_acc=0.9804, grad=11.9485]Training epoch 34:  47%|████▋     | 76/163 [01:28<01:47,  1.24s/it, loss=0.1519, batch_acc=1.0000, running_acc=0.9807, grad=10.5277]Training epoch 34:  47%|████▋     | 77/163 [01:29<01:37,  1.13s/it, loss=0.1519, batch_acc=1.0000, running_acc=0.9807, grad=10.5277]Training epoch 34:  47%|████▋     | 77/163 [01:29<01:37,  1.13s/it, loss=0.1562, batch_acc=1.0000, running_acc=0.9809, grad=13.1971]Training epoch 34:  48%|████▊     | 78/163 [01:30<01:29,  1.05s/it, loss=0.1562, batch_acc=1.0000, running_acc=0.9809, grad=13.1971]Training epoch 34:  48%|████▊     | 78/163 [01:30<01:29,  1.05s/it, loss=0.1632, batch_acc=0.9688, running_acc=0.9808, grad=13.3429]Training epoch 34:  48%|████▊     | 79/163 [01:31<01:24,  1.00s/it, loss=0.1632, batch_acc=0.9688, running_acc=0.9808, grad=13.3429]Training epoch 34:  48%|████▊     | 79/163 [01:31<01:24,  1.00s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9810, grad=10.2704]Training epoch 34:  49%|████▉     | 80/163 [01:33<01:45,  1.28s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9810, grad=10.2704]Training epoch 34:  49%|████▉     | 80/163 [01:33<01:45,  1.28s/it, loss=0.1757, batch_acc=1.0000, running_acc=0.9812, grad=15.0166]Training epoch 34:  50%|████▉     | 81/163 [01:34<01:34,  1.16s/it, loss=0.1757, batch_acc=1.0000, running_acc=0.9812, grad=15.0166]Training epoch 34:  50%|████▉     | 81/163 [01:34<01:34,  1.16s/it, loss=0.2242, batch_acc=0.9375, running_acc=0.9807, grad=15.1401]Training epoch 34:  50%|█████     | 82/163 [01:34<01:27,  1.08s/it, loss=0.2242, batch_acc=0.9375, running_acc=0.9807, grad=15.1401]Training epoch 34:  50%|█████     | 82/163 [01:34<01:27,  1.08s/it, loss=0.2097, batch_acc=1.0000, running_acc=0.9809, grad=19.7532]Training epoch 34:  51%|█████     | 83/163 [01:35<01:23,  1.05s/it, loss=0.2097, batch_acc=1.0000, running_acc=0.9809, grad=19.7532]Training epoch 34:  51%|█████     | 83/163 [01:35<01:23,  1.05s/it, loss=0.1811, batch_acc=1.0000, running_acc=0.9812, grad=21.3793]Training epoch 34:  52%|█████▏    | 84/163 [01:37<01:34,  1.20s/it, loss=0.1811, batch_acc=1.0000, running_acc=0.9812, grad=21.3793]Training epoch 34:  52%|█████▏    | 84/163 [01:37<01:34,  1.20s/it, loss=0.1418, batch_acc=1.0000, running_acc=0.9814, grad=9.1385] Training epoch 34:  52%|█████▏    | 85/163 [01:38<01:25,  1.10s/it, loss=0.1418, batch_acc=1.0000, running_acc=0.9814, grad=9.1385]Training epoch 34:  52%|█████▏    | 85/163 [01:38<01:25,  1.10s/it, loss=0.1976, batch_acc=0.9688, running_acc=0.9812, grad=14.3792]Training epoch 34:  53%|█████▎    | 86/163 [01:39<01:19,  1.04s/it, loss=0.1976, batch_acc=0.9688, running_acc=0.9812, grad=14.3792]Training epoch 34:  53%|█████▎    | 86/163 [01:39<01:19,  1.04s/it, loss=0.2493, batch_acc=0.9688, running_acc=0.9811, grad=11.5394]Training epoch 34:  53%|█████▎    | 87/163 [01:40<01:15,  1.01it/s, loss=0.2493, batch_acc=0.9688, running_acc=0.9811, grad=11.5394]Training epoch 34:  53%|█████▎    | 87/163 [01:40<01:15,  1.01it/s, loss=0.1490, batch_acc=1.0000, running_acc=0.9813, grad=11.4236]Training epoch 34:  54%|█████▍    | 88/163 [01:41<01:19,  1.07s/it, loss=0.1490, batch_acc=1.0000, running_acc=0.9813, grad=11.4236]Training epoch 34:  54%|█████▍    | 88/163 [01:41<01:19,  1.07s/it, loss=0.1624, batch_acc=1.0000, running_acc=0.9815, grad=12.6552]Training epoch 34:  55%|█████▍    | 89/163 [01:42<01:14,  1.01s/it, loss=0.1624, batch_acc=1.0000, running_acc=0.9815, grad=12.6552]Training epoch 34:  55%|█████▍    | 89/163 [01:42<01:14,  1.01s/it, loss=0.1782, batch_acc=0.9688, running_acc=0.9814, grad=16.4453]Training epoch 34:  55%|█████▌    | 90/163 [01:43<01:10,  1.03it/s, loss=0.1782, batch_acc=0.9688, running_acc=0.9814, grad=16.4453]Training epoch 34:  55%|█████▌    | 90/163 [01:43<01:10,  1.03it/s, loss=0.2006, batch_acc=0.9375, running_acc=0.9809, grad=13.0314]Training epoch 34:  56%|█████▌    | 91/163 [01:43<01:07,  1.06it/s, loss=0.2006, batch_acc=0.9375, running_acc=0.9809, grad=13.0314]Training epoch 34:  56%|█████▌    | 91/163 [01:43<01:07,  1.06it/s, loss=0.2423, batch_acc=1.0000, running_acc=0.9811, grad=17.3007]Training epoch 34:  56%|█████▋    | 92/163 [01:45<01:23,  1.18s/it, loss=0.2423, batch_acc=1.0000, running_acc=0.9811, grad=17.3007]Training epoch 34:  56%|█████▋    | 92/163 [01:45<01:23,  1.18s/it, loss=0.1397, batch_acc=1.0000, running_acc=0.9813, grad=11.1730]Training epoch 34:  57%|█████▋    | 93/163 [01:46<01:16,  1.09s/it, loss=0.1397, batch_acc=1.0000, running_acc=0.9813, grad=11.1730]Training epoch 34:  57%|█████▋    | 93/163 [01:46<01:16,  1.09s/it, loss=0.1560, batch_acc=1.0000, running_acc=0.9815, grad=11.3045]Training epoch 34:  58%|█████▊    | 94/163 [01:47<01:10,  1.03s/it, loss=0.1560, batch_acc=1.0000, running_acc=0.9815, grad=11.3045]Training epoch 34:  58%|█████▊    | 94/163 [01:47<01:10,  1.03s/it, loss=0.1954, batch_acc=1.0000, running_acc=0.9817, grad=16.9245]Training epoch 34:  58%|█████▊    | 95/163 [01:48<01:06,  1.02it/s, loss=0.1954, batch_acc=1.0000, running_acc=0.9817, grad=16.9245]Training epoch 34:  58%|█████▊    | 95/163 [01:48<01:06,  1.02it/s, loss=0.2078, batch_acc=0.9062, running_acc=0.9809, grad=13.4996]Training epoch 34:  59%|█████▉    | 96/163 [01:49<01:18,  1.17s/it, loss=0.2078, batch_acc=0.9062, running_acc=0.9809, grad=13.4996]Training epoch 34:  59%|█████▉    | 96/163 [01:49<01:18,  1.17s/it, loss=0.1480, batch_acc=0.9688, running_acc=0.9808, grad=9.0587] Training epoch 34:  60%|█████▉    | 97/163 [01:50<01:11,  1.08s/it, loss=0.1480, batch_acc=0.9688, running_acc=0.9808, grad=9.0587]Training epoch 34:  60%|█████▉    | 97/163 [01:50<01:11,  1.08s/it, loss=0.1457, batch_acc=1.0000, running_acc=0.9810, grad=14.4630]Training epoch 34:  60%|██████    | 98/163 [01:51<01:06,  1.02s/it, loss=0.1457, batch_acc=1.0000, running_acc=0.9810, grad=14.4630]Training epoch 34:  60%|██████    | 98/163 [01:51<01:06,  1.02s/it, loss=0.1832, batch_acc=0.9375, running_acc=0.9805, grad=7.9846] Training epoch 34:  61%|██████    | 99/163 [01:52<01:02,  1.02it/s, loss=0.1832, batch_acc=0.9375, running_acc=0.9805, grad=7.9846]Training epoch 34:  61%|██████    | 99/163 [01:52<01:02,  1.02it/s, loss=0.2169, batch_acc=0.9688, running_acc=0.9804, grad=14.7536]Training epoch 34:  61%|██████▏   | 100/163 [01:54<01:22,  1.31s/it, loss=0.2169, batch_acc=0.9688, running_acc=0.9804, grad=14.7536]Training epoch 34:  61%|██████▏   | 100/163 [01:54<01:22,  1.31s/it, loss=0.2126, batch_acc=0.9375, running_acc=0.9800, grad=17.2213]Training epoch 34:  62%|██████▏   | 101/163 [01:55<01:13,  1.18s/it, loss=0.2126, batch_acc=0.9375, running_acc=0.9800, grad=17.2213]Training epoch 34:  62%|██████▏   | 101/163 [01:55<01:13,  1.18s/it, loss=0.2283, batch_acc=0.9062, running_acc=0.9793, grad=18.5365]Training epoch 34:  63%|██████▎   | 102/163 [01:56<01:06,  1.09s/it, loss=0.2283, batch_acc=0.9062, running_acc=0.9793, grad=18.5365]Training epoch 34:  63%|██████▎   | 102/163 [01:56<01:06,  1.09s/it, loss=0.2807, batch_acc=0.9062, running_acc=0.9786, grad=17.6869]Training epoch 34:  63%|██████▎   | 103/163 [01:57<01:02,  1.04s/it, loss=0.2807, batch_acc=0.9062, running_acc=0.9786, grad=17.6869]Training epoch 34:  63%|██████▎   | 103/163 [01:57<01:02,  1.04s/it, loss=0.1036, batch_acc=1.0000, running_acc=0.9788, grad=11.2997]Training epoch 34:  64%|██████▍   | 104/163 [01:59<01:15,  1.28s/it, loss=0.1036, batch_acc=1.0000, running_acc=0.9788, grad=11.2997]Training epoch 34:  64%|██████▍   | 104/163 [01:59<01:15,  1.28s/it, loss=0.1797, batch_acc=0.9688, running_acc=0.9787, grad=11.4524]Training epoch 34:  64%|██████▍   | 105/163 [02:00<01:07,  1.16s/it, loss=0.1797, batch_acc=0.9688, running_acc=0.9787, grad=11.4524]Training epoch 34:  64%|██████▍   | 105/163 [02:00<01:07,  1.16s/it, loss=0.1983, batch_acc=0.9688, running_acc=0.9786, grad=19.0182]Training epoch 34:  65%|██████▌   | 106/163 [02:00<01:01,  1.08s/it, loss=0.1983, batch_acc=0.9688, running_acc=0.9786, grad=19.0182]Training epoch 34:  65%|██████▌   | 106/163 [02:00<01:01,  1.08s/it, loss=0.1396, batch_acc=1.0000, running_acc=0.9788, grad=11.5461]Training epoch 34:  66%|██████▌   | 107/163 [02:01<00:59,  1.06s/it, loss=0.1396, batch_acc=1.0000, running_acc=0.9788, grad=11.5461]Training epoch 34:  66%|██████▌   | 107/163 [02:01<00:59,  1.06s/it, loss=0.1592, batch_acc=1.0000, running_acc=0.9790, grad=14.6337]Training epoch 34:  66%|██████▋   | 108/163 [02:03<01:07,  1.23s/it, loss=0.1592, batch_acc=1.0000, running_acc=0.9790, grad=14.6337]Training epoch 34:  66%|██████▋   | 108/163 [02:03<01:07,  1.23s/it, loss=0.1602, batch_acc=1.0000, running_acc=0.9792, grad=13.7204]Training epoch 34:  67%|██████▋   | 109/163 [02:04<01:00,  1.12s/it, loss=0.1602, batch_acc=1.0000, running_acc=0.9792, grad=13.7204]Training epoch 34:  67%|██████▋   | 109/163 [02:04<01:00,  1.12s/it, loss=0.3071, batch_acc=0.9375, running_acc=0.9788, grad=19.8905]Training epoch 34:  67%|██████▋   | 110/163 [02:05<00:55,  1.05s/it, loss=0.3071, batch_acc=0.9375, running_acc=0.9788, grad=19.8905]Training epoch 34:  67%|██████▋   | 110/163 [02:05<00:55,  1.05s/it, loss=0.1848, batch_acc=1.0000, running_acc=0.9790, grad=21.6921]Training epoch 34:  68%|██████▊   | 111/163 [02:06<00:51,  1.00it/s, loss=0.1848, batch_acc=1.0000, running_acc=0.9790, grad=21.6921]Training epoch 34:  68%|██████▊   | 111/163 [02:06<00:51,  1.00it/s, loss=0.1427, batch_acc=1.0000, running_acc=0.9792, grad=10.3873]Training epoch 34:  69%|██████▊   | 112/163 [02:07<00:56,  1.11s/it, loss=0.1427, batch_acc=1.0000, running_acc=0.9792, grad=10.3873]Training epoch 34:  69%|██████▊   | 112/163 [02:07<00:56,  1.11s/it, loss=0.1689, batch_acc=0.9688, running_acc=0.9791, grad=18.0095]Training epoch 34:  69%|██████▉   | 113/163 [02:08<00:52,  1.04s/it, loss=0.1689, batch_acc=0.9688, running_acc=0.9791, grad=18.0095]Training epoch 34:  69%|██████▉   | 113/163 [02:08<00:52,  1.04s/it, loss=0.3053, batch_acc=0.9062, running_acc=0.9784, grad=21.2400]Training epoch 34:  70%|██████▉   | 114/163 [02:09<00:48,  1.01it/s, loss=0.3053, batch_acc=0.9062, running_acc=0.9784, grad=21.2400]Training epoch 34:  70%|██████▉   | 114/163 [02:09<00:48,  1.01it/s, loss=0.1261, batch_acc=0.9688, running_acc=0.9783, grad=9.0127] Training epoch 34:  71%|███████   | 115/163 [02:10<00:46,  1.04it/s, loss=0.1261, batch_acc=0.9688, running_acc=0.9783, grad=9.0127]Training epoch 34:  71%|███████   | 115/163 [02:10<00:46,  1.04it/s, loss=0.0954, batch_acc=1.0000, running_acc=0.9785, grad=8.7860]Training epoch 34:  71%|███████   | 116/163 [02:11<00:54,  1.17s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9785, grad=8.7860]Training epoch 34:  71%|███████   | 116/163 [02:11<00:54,  1.17s/it, loss=0.1876, batch_acc=1.0000, running_acc=0.9787, grad=14.3968]Training epoch 34:  72%|███████▏  | 117/163 [02:12<00:49,  1.08s/it, loss=0.1876, batch_acc=1.0000, running_acc=0.9787, grad=14.3968]Training epoch 34:  72%|███████▏  | 117/163 [02:12<00:49,  1.08s/it, loss=0.1983, batch_acc=0.9062, running_acc=0.9781, grad=12.7916]Training epoch 34:  72%|███████▏  | 118/163 [02:13<00:45,  1.02s/it, loss=0.1983, batch_acc=0.9062, running_acc=0.9781, grad=12.7916]Training epoch 34:  72%|███████▏  | 118/163 [02:13<00:45,  1.02s/it, loss=0.1413, batch_acc=0.9688, running_acc=0.9780, grad=6.7177] Training epoch 34:  73%|███████▎  | 119/163 [02:14<00:43,  1.02it/s, loss=0.1413, batch_acc=0.9688, running_acc=0.9780, grad=6.7177]Training epoch 34:  73%|███████▎  | 119/163 [02:14<00:43,  1.02it/s, loss=0.1482, batch_acc=1.0000, running_acc=0.9782, grad=10.6238]Training epoch 34:  74%|███████▎  | 120/163 [02:16<00:49,  1.14s/it, loss=0.1482, batch_acc=1.0000, running_acc=0.9782, grad=10.6238]Training epoch 34:  74%|███████▎  | 120/163 [02:16<00:49,  1.14s/it, loss=0.2755, batch_acc=0.9062, running_acc=0.9776, grad=16.1931]Training epoch 34:  74%|███████▍  | 121/163 [02:16<00:44,  1.06s/it, loss=0.2755, batch_acc=0.9062, running_acc=0.9776, grad=16.1931]Training epoch 34:  74%|███████▍  | 121/163 [02:16<00:44,  1.06s/it, loss=0.1251, batch_acc=1.0000, running_acc=0.9778, grad=11.9814]Training epoch 34:  75%|███████▍  | 122/163 [02:17<00:41,  1.01s/it, loss=0.1251, batch_acc=1.0000, running_acc=0.9778, grad=11.9814]Training epoch 34:  75%|███████▍  | 122/163 [02:17<00:41,  1.01s/it, loss=0.2021, batch_acc=0.9688, running_acc=0.9777, grad=14.2163]Training epoch 34:  75%|███████▌  | 123/163 [02:18<00:39,  1.00it/s, loss=0.2021, batch_acc=0.9688, running_acc=0.9777, grad=14.2163]Training epoch 34:  75%|███████▌  | 123/163 [02:18<00:39,  1.00it/s, loss=0.2272, batch_acc=1.0000, running_acc=0.9779, grad=13.3761]Training epoch 34:  76%|███████▌  | 124/163 [02:20<00:49,  1.26s/it, loss=0.2272, batch_acc=1.0000, running_acc=0.9779, grad=13.3761]Training epoch 34:  76%|███████▌  | 124/163 [02:20<00:49,  1.26s/it, loss=0.1129, batch_acc=1.0000, running_acc=0.9781, grad=12.4947]Training epoch 34:  77%|███████▋  | 125/163 [02:21<00:43,  1.15s/it, loss=0.1129, batch_acc=1.0000, running_acc=0.9781, grad=12.4947]Training epoch 34:  77%|███████▋  | 125/163 [02:21<00:43,  1.15s/it, loss=0.2544, batch_acc=0.9375, running_acc=0.9778, grad=14.2604]Training epoch 34:  77%|███████▋  | 126/163 [02:22<00:39,  1.07s/it, loss=0.2544, batch_acc=0.9375, running_acc=0.9778, grad=14.2604]Training epoch 34:  77%|███████▋  | 126/163 [02:22<00:39,  1.07s/it, loss=0.1264, batch_acc=1.0000, running_acc=0.9779, grad=12.4686]Training epoch 34:  78%|███████▊  | 127/163 [02:23<00:36,  1.01s/it, loss=0.1264, batch_acc=1.0000, running_acc=0.9779, grad=12.4686]Training epoch 34:  78%|███████▊  | 127/163 [02:23<00:36,  1.01s/it, loss=0.1652, batch_acc=0.9688, running_acc=0.9779, grad=11.6828]Training epoch 34:  79%|███████▊  | 128/163 [02:24<00:40,  1.16s/it, loss=0.1652, batch_acc=0.9688, running_acc=0.9779, grad=11.6828]Training epoch 34:  79%|███████▊  | 128/163 [02:24<00:40,  1.16s/it, loss=0.1431, batch_acc=1.0000, running_acc=0.9780, grad=12.2211]Training epoch 34:  79%|███████▉  | 129/163 [02:25<00:36,  1.08s/it, loss=0.1431, batch_acc=1.0000, running_acc=0.9780, grad=12.2211]Training epoch 34:  79%|███████▉  | 129/163 [02:25<00:36,  1.08s/it, loss=0.1754, batch_acc=0.9688, running_acc=0.9780, grad=13.5881]Training epoch 34:  80%|███████▉  | 130/163 [02:26<00:33,  1.02s/it, loss=0.1754, batch_acc=0.9688, running_acc=0.9780, grad=13.5881]Training epoch 34:  80%|███████▉  | 130/163 [02:26<00:33,  1.02s/it, loss=0.1719, batch_acc=0.9688, running_acc=0.9779, grad=10.6479]Training epoch 34:  80%|████████  | 131/163 [02:27<00:31,  1.02it/s, loss=0.1719, batch_acc=0.9688, running_acc=0.9779, grad=10.6479]Training epoch 34:  80%|████████  | 131/163 [02:27<00:31,  1.02it/s, loss=0.1355, batch_acc=1.0000, running_acc=0.9781, grad=10.7154]Training epoch 34:  81%|████████  | 132/163 [02:28<00:33,  1.09s/it, loss=0.1355, batch_acc=1.0000, running_acc=0.9781, grad=10.7154]Training epoch 34:  81%|████████  | 132/163 [02:28<00:33,  1.09s/it, loss=0.1703, batch_acc=1.0000, running_acc=0.9782, grad=12.4838]Training epoch 34:  82%|████████▏ | 133/163 [02:29<00:30,  1.02s/it, loss=0.1703, batch_acc=1.0000, running_acc=0.9782, grad=12.4838]Training epoch 34:  82%|████████▏ | 133/163 [02:29<00:30,  1.02s/it, loss=0.2396, batch_acc=0.9375, running_acc=0.9779, grad=16.6096]Training epoch 34:  82%|████████▏ | 134/163 [02:30<00:28,  1.02it/s, loss=0.2396, batch_acc=0.9375, running_acc=0.9779, grad=16.6096]Training epoch 34:  82%|████████▏ | 134/163 [02:30<00:28,  1.02it/s, loss=0.1498, batch_acc=1.0000, running_acc=0.9781, grad=17.8359]Training epoch 34:  83%|████████▎ | 135/163 [02:31<00:26,  1.05it/s, loss=0.1498, batch_acc=1.0000, running_acc=0.9781, grad=17.8359]Training epoch 34:  83%|████████▎ | 135/163 [02:31<00:26,  1.05it/s, loss=0.1304, batch_acc=1.0000, running_acc=0.9782, grad=10.6405]Training epoch 34:  83%|████████▎ | 136/163 [02:32<00:29,  1.10s/it, loss=0.1304, batch_acc=1.0000, running_acc=0.9782, grad=10.6405]Training epoch 34:  83%|████████▎ | 136/163 [02:32<00:29,  1.10s/it, loss=0.2121, batch_acc=0.9688, running_acc=0.9782, grad=19.6606]Training epoch 34:  84%|████████▍ | 137/163 [02:33<00:26,  1.03s/it, loss=0.2121, batch_acc=0.9688, running_acc=0.9782, grad=19.6606]Training epoch 34:  84%|████████▍ | 137/163 [02:33<00:26,  1.03s/it, loss=0.1857, batch_acc=1.0000, running_acc=0.9783, grad=13.0056]Training epoch 34:  85%|████████▍ | 138/163 [02:34<00:24,  1.01it/s, loss=0.1857, batch_acc=1.0000, running_acc=0.9783, grad=13.0056]Training epoch 34:  85%|████████▍ | 138/163 [02:34<00:24,  1.01it/s, loss=0.1125, batch_acc=1.0000, running_acc=0.9785, grad=10.2328]Training epoch 34:  85%|████████▌ | 139/163 [02:35<00:25,  1.05s/it, loss=0.1125, batch_acc=1.0000, running_acc=0.9785, grad=10.2328]Training epoch 34:  85%|████████▌ | 139/163 [02:35<00:25,  1.05s/it, loss=0.2130, batch_acc=0.9375, running_acc=0.9782, grad=11.8525]Training epoch 34:  86%|████████▌ | 140/163 [02:37<00:28,  1.23s/it, loss=0.2130, batch_acc=0.9375, running_acc=0.9782, grad=11.8525]Training epoch 34:  86%|████████▌ | 140/163 [02:37<00:28,  1.23s/it, loss=0.0892, batch_acc=1.0000, running_acc=0.9783, grad=8.7135] Training epoch 34:  87%|████████▋ | 141/163 [02:38<00:24,  1.13s/it, loss=0.0892, batch_acc=1.0000, running_acc=0.9783, grad=8.7135]Training epoch 34:  87%|████████▋ | 141/163 [02:38<00:24,  1.13s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9783, grad=9.9949]Training epoch 34:  87%|████████▋ | 142/163 [02:39<00:22,  1.05s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9783, grad=9.9949]Training epoch 34:  87%|████████▋ | 142/163 [02:39<00:22,  1.05s/it, loss=0.1818, batch_acc=0.9688, running_acc=0.9782, grad=11.4623]Training epoch 34:  88%|████████▊ | 143/163 [02:40<00:21,  1.07s/it, loss=0.1818, batch_acc=0.9688, running_acc=0.9782, grad=11.4623]Training epoch 34:  88%|████████▊ | 143/163 [02:40<00:21,  1.07s/it, loss=0.3173, batch_acc=0.9688, running_acc=0.9781, grad=21.8140]Training epoch 34:  88%|████████▊ | 144/163 [02:41<00:23,  1.23s/it, loss=0.3173, batch_acc=0.9688, running_acc=0.9781, grad=21.8140]Training epoch 34:  88%|████████▊ | 144/163 [02:41<00:23,  1.23s/it, loss=0.1459, batch_acc=1.0000, running_acc=0.9783, grad=14.8467]Training epoch 34:  89%|████████▉ | 145/163 [02:42<00:20,  1.13s/it, loss=0.1459, batch_acc=1.0000, running_acc=0.9783, grad=14.8467]Training epoch 34:  89%|████████▉ | 145/163 [02:42<00:20,  1.13s/it, loss=0.1423, batch_acc=1.0000, running_acc=0.9784, grad=12.0921]Training epoch 34:  90%|████████▉ | 146/163 [02:43<00:17,  1.05s/it, loss=0.1423, batch_acc=1.0000, running_acc=0.9784, grad=12.0921]Training epoch 34:  90%|████████▉ | 146/163 [02:43<00:17,  1.05s/it, loss=0.1702, batch_acc=1.0000, running_acc=0.9786, grad=15.0986]Training epoch 34:  90%|█████████ | 147/163 [02:44<00:17,  1.12s/it, loss=0.1702, batch_acc=1.0000, running_acc=0.9786, grad=15.0986]Training epoch 34:  90%|█████████ | 147/163 [02:44<00:17,  1.12s/it, loss=0.2300, batch_acc=0.9688, running_acc=0.9785, grad=15.9266]Training epoch 34:  91%|█████████ | 148/163 [02:45<00:15,  1.05s/it, loss=0.2300, batch_acc=0.9688, running_acc=0.9785, grad=15.9266]Training epoch 34:  91%|█████████ | 148/163 [02:45<00:15,  1.05s/it, loss=0.1378, batch_acc=1.0000, running_acc=0.9787, grad=9.3601] Training epoch 34:  91%|█████████▏| 149/163 [02:46<00:13,  1.00it/s, loss=0.1378, batch_acc=1.0000, running_acc=0.9787, grad=9.3601]Training epoch 34:  91%|█████████▏| 149/163 [02:46<00:13,  1.00it/s, loss=0.1430, batch_acc=1.0000, running_acc=0.9788, grad=10.3231]Training epoch 34:  92%|█████████▏| 150/163 [02:47<00:12,  1.04it/s, loss=0.1430, batch_acc=1.0000, running_acc=0.9788, grad=10.3231]Training epoch 34:  92%|█████████▏| 150/163 [02:47<00:12,  1.04it/s, loss=0.1724, batch_acc=0.9688, running_acc=0.9788, grad=11.0857]Training epoch 34:  93%|█████████▎| 151/163 [02:49<00:15,  1.31s/it, loss=0.1724, batch_acc=0.9688, running_acc=0.9788, grad=11.0857]Training epoch 34:  93%|█████████▎| 151/163 [02:49<00:15,  1.31s/it, loss=0.1894, batch_acc=0.9062, running_acc=0.9783, grad=10.0677]Training epoch 34:  93%|█████████▎| 152/163 [02:50<00:13,  1.20s/it, loss=0.1894, batch_acc=0.9062, running_acc=0.9783, grad=10.0677]Training epoch 34:  93%|█████████▎| 152/163 [02:50<00:13,  1.20s/it, loss=0.1823, batch_acc=1.0000, running_acc=0.9784, grad=16.1255]Training epoch 34:  94%|█████████▍| 153/163 [02:51<00:11,  1.11s/it, loss=0.1823, batch_acc=1.0000, running_acc=0.9784, grad=16.1255]Training epoch 34:  94%|█████████▍| 153/163 [02:51<00:11,  1.11s/it, loss=0.1425, batch_acc=1.0000, running_acc=0.9786, grad=12.2084]Training epoch 34:  94%|█████████▍| 154/163 [02:52<00:09,  1.04s/it, loss=0.1425, batch_acc=1.0000, running_acc=0.9786, grad=12.2084]Training epoch 34:  94%|█████████▍| 154/163 [02:52<00:09,  1.04s/it, loss=0.0909, batch_acc=1.0000, running_acc=0.9787, grad=13.9990]Training epoch 34:  95%|█████████▌| 155/163 [02:54<00:10,  1.37s/it, loss=0.0909, batch_acc=1.0000, running_acc=0.9787, grad=13.9990]Training epoch 34:  95%|█████████▌| 155/163 [02:54<00:10,  1.37s/it, loss=0.1255, batch_acc=1.0000, running_acc=0.9788, grad=10.4647]Training epoch 34:  96%|█████████▌| 156/163 [02:55<00:08,  1.22s/it, loss=0.1255, batch_acc=1.0000, running_acc=0.9788, grad=10.4647]Training epoch 34:  96%|█████████▌| 156/163 [02:55<00:08,  1.22s/it, loss=0.1623, batch_acc=0.9688, running_acc=0.9788, grad=10.6352]Training epoch 34:  96%|█████████▋| 157/163 [02:56<00:06,  1.12s/it, loss=0.1623, batch_acc=0.9688, running_acc=0.9788, grad=10.6352]Training epoch 34:  96%|█████████▋| 157/163 [02:56<00:06,  1.12s/it, loss=0.1474, batch_acc=1.0000, running_acc=0.9789, grad=12.2006]Training epoch 34:  97%|█████████▋| 158/163 [02:57<00:05,  1.05s/it, loss=0.1474, batch_acc=1.0000, running_acc=0.9789, grad=12.2006]Training epoch 34:  97%|█████████▋| 158/163 [02:57<00:05,  1.05s/it, loss=0.1948, batch_acc=0.9688, running_acc=0.9788, grad=17.8651]Training epoch 34:  98%|█████████▊| 159/163 [02:59<00:05,  1.43s/it, loss=0.1948, batch_acc=0.9688, running_acc=0.9788, grad=17.8651]Training epoch 34:  98%|█████████▊| 159/163 [02:59<00:05,  1.43s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9788, grad=8.2903] Training epoch 34:  98%|█████████▊| 160/163 [03:00<00:03,  1.27s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9788, grad=8.2903]Training epoch 34:  98%|█████████▊| 160/163 [03:00<00:03,  1.27s/it, loss=0.1581, batch_acc=1.0000, running_acc=0.9789, grad=11.2397]Training epoch 34:  99%|█████████▉| 161/163 [03:01<00:02,  1.15s/it, loss=0.1581, batch_acc=1.0000, running_acc=0.9789, grad=11.2397]Training epoch 34:  99%|█████████▉| 161/163 [03:01<00:02,  1.15s/it, loss=0.1546, batch_acc=0.9688, running_acc=0.9788, grad=13.2792]Training epoch 34:  99%|█████████▉| 162/163 [03:02<00:01,  1.07s/it, loss=0.1546, batch_acc=0.9688, running_acc=0.9788, grad=13.2792]Training epoch 34:  99%|█████████▉| 162/163 [03:02<00:01,  1.07s/it, loss=0.0950, batch_acc=1.0000, running_acc=0.9790, grad=7.0673] Training epoch 34: 100%|██████████| 163/163 [03:02<00:00,  1.07it/s, loss=0.0950, batch_acc=1.0000, running_acc=0.9790, grad=7.0673]Training epoch 34: 100%|██████████| 163/163 [03:02<00:00,  1.07it/s, loss=0.2219, batch_acc=1.0000, running_acc=0.9791, grad=16.1349]Training epoch 34: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.2219, batch_acc=1.0000, running_acc=0.9791, grad=16.1349]
Evaluation epoch 34:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 34:   4%|▎         | 1/28 [00:05<02:24,  5.33s/it]Evaluation epoch 34:   4%|▎         | 1/28 [00:05<02:24,  5.33s/it, loss=0.3967, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 34:   7%|▋         | 2/28 [00:05<01:01,  2.35s/it, loss=0.3967, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 34:   7%|▋         | 2/28 [00:05<01:01,  2.35s/it, loss=0.3621, batch_acc=0.9375, running_acc=0.9219]Evaluation epoch 34:  11%|█         | 3/28 [00:05<00:34,  1.40s/it, loss=0.3621, batch_acc=0.9375, running_acc=0.9219]Evaluation epoch 34:  11%|█         | 3/28 [00:05<00:34,  1.40s/it, loss=0.4300, batch_acc=0.9062, running_acc=0.9167]Evaluation epoch 34:  14%|█▍        | 4/28 [00:10<01:05,  2.73s/it, loss=0.4300, batch_acc=0.9062, running_acc=0.9167]Evaluation epoch 34:  14%|█▍        | 4/28 [00:10<01:05,  2.73s/it, loss=0.4100, batch_acc=0.9375, running_acc=0.9219]Evaluation epoch 34:  18%|█▊        | 5/28 [00:10<00:42,  1.84s/it, loss=0.4100, batch_acc=0.9375, running_acc=0.9219]Evaluation epoch 34:  18%|█▊        | 5/28 [00:10<00:42,  1.84s/it, loss=1.3933, batch_acc=0.6875, running_acc=0.8750]Evaluation epoch 34:  21%|██▏       | 6/28 [00:11<00:28,  1.30s/it, loss=1.3933, batch_acc=0.6875, running_acc=0.8750]Evaluation epoch 34:  21%|██▏       | 6/28 [00:11<00:28,  1.30s/it, loss=0.7254, batch_acc=0.8125, running_acc=0.8646]Evaluation epoch 34:  25%|██▌       | 7/28 [00:11<00:20,  1.04it/s, loss=0.7254, batch_acc=0.8125, running_acc=0.8646]Evaluation epoch 34:  25%|██▌       | 7/28 [00:11<00:20,  1.04it/s, loss=0.6772, batch_acc=0.8750, running_acc=0.8661]Evaluation epoch 34:  29%|██▊       | 8/28 [00:14<00:34,  1.74s/it, loss=0.6772, batch_acc=0.8750, running_acc=0.8661]Evaluation epoch 34:  29%|██▊       | 8/28 [00:14<00:34,  1.74s/it, loss=0.4112, batch_acc=0.8750, running_acc=0.8672]Evaluation epoch 34:  32%|███▏      | 9/28 [00:15<00:24,  1.28s/it, loss=0.4112, batch_acc=0.8750, running_acc=0.8672]Evaluation epoch 34:  32%|███▏      | 9/28 [00:15<00:24,  1.28s/it, loss=0.4672, batch_acc=0.9062, running_acc=0.8715]Evaluation epoch 34:  36%|███▌      | 10/28 [00:15<00:17,  1.04it/s, loss=0.4672, batch_acc=0.9062, running_acc=0.8715]Evaluation epoch 34:  36%|███▌      | 10/28 [00:15<00:17,  1.04it/s, loss=0.4999, batch_acc=0.9062, running_acc=0.8750]Evaluation epoch 34:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=0.4999, batch_acc=0.9062, running_acc=0.8750]Evaluation epoch 34:  39%|███▉      | 11/28 [00:15<00:12,  1.33it/s, loss=0.3990, batch_acc=0.9062, running_acc=0.8778]Evaluation epoch 34:  43%|████▎     | 12/28 [00:21<00:35,  2.23s/it, loss=0.3990, batch_acc=0.9062, running_acc=0.8778]Evaluation epoch 34:  43%|████▎     | 12/28 [00:21<00:35,  2.23s/it, loss=0.9788, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 34:  46%|████▋     | 13/28 [00:21<00:24,  1.63s/it, loss=0.9788, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 34:  46%|████▋     | 13/28 [00:21<00:24,  1.63s/it, loss=0.3190, batch_acc=0.9375, running_acc=0.8798]Evaluation epoch 34:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=0.3190, batch_acc=0.9375, running_acc=0.8798]Evaluation epoch 34:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=0.9540, batch_acc=0.7500, running_acc=0.8705]Evaluation epoch 34:  54%|█████▎    | 15/28 [00:22<00:12,  1.07it/s, loss=0.9540, batch_acc=0.7500, running_acc=0.8705]Evaluation epoch 34:  54%|█████▎    | 15/28 [00:22<00:12,  1.07it/s, loss=1.0374, batch_acc=0.7812, running_acc=0.8646]Evaluation epoch 34:  57%|█████▋    | 16/28 [00:24<00:18,  1.50s/it, loss=1.0374, batch_acc=0.7812, running_acc=0.8646]Evaluation epoch 34:  57%|█████▋    | 16/28 [00:24<00:18,  1.50s/it, loss=0.8072, batch_acc=0.7500, running_acc=0.8574]Evaluation epoch 34:  61%|██████    | 17/28 [00:25<00:12,  1.13s/it, loss=0.8072, batch_acc=0.7500, running_acc=0.8574]Evaluation epoch 34:  61%|██████    | 17/28 [00:25<00:12,  1.13s/it, loss=0.6170, batch_acc=0.7812, running_acc=0.8529]Evaluation epoch 34:  64%|██████▍   | 18/28 [00:25<00:08,  1.15it/s, loss=0.6170, batch_acc=0.7812, running_acc=0.8529]Evaluation epoch 34:  64%|██████▍   | 18/28 [00:25<00:08,  1.15it/s, loss=0.5725, batch_acc=0.8438, running_acc=0.8524]Evaluation epoch 34:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=0.5725, batch_acc=0.8438, running_acc=0.8524]Evaluation epoch 34:  68%|██████▊   | 19/28 [00:25<00:06,  1.45it/s, loss=0.9247, batch_acc=0.6250, running_acc=0.8405]Evaluation epoch 34:  71%|███████▏  | 20/28 [00:28<00:10,  1.33s/it, loss=0.9247, batch_acc=0.6250, running_acc=0.8405]Evaluation epoch 34:  71%|███████▏  | 20/28 [00:28<00:10,  1.33s/it, loss=0.5740, batch_acc=0.7500, running_acc=0.8359]Evaluation epoch 34:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=0.5740, batch_acc=0.7500, running_acc=0.8359]Evaluation epoch 34:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=0.5669, batch_acc=0.8438, running_acc=0.8363]Evaluation epoch 34:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.5669, batch_acc=0.8438, running_acc=0.8363]Evaluation epoch 34:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.4731, batch_acc=0.9375, running_acc=0.8409]Evaluation epoch 34:  82%|████████▏ | 23/28 [00:29<00:03,  1.59it/s, loss=0.4731, batch_acc=0.9375, running_acc=0.8409]Evaluation epoch 34:  82%|████████▏ | 23/28 [00:29<00:03,  1.59it/s, loss=0.8299, batch_acc=0.7500, running_acc=0.8370]Evaluation epoch 34:  86%|████████▌ | 24/28 [00:34<00:08,  2.01s/it, loss=0.8299, batch_acc=0.7500, running_acc=0.8370]Evaluation epoch 34:  86%|████████▌ | 24/28 [00:34<00:08,  2.01s/it, loss=0.4281, batch_acc=0.9062, running_acc=0.8398]Evaluation epoch 34:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.4281, batch_acc=0.9062, running_acc=0.8398]Evaluation epoch 34:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.1897, batch_acc=0.9688, running_acc=0.8450]Evaluation epoch 34:  93%|█████████▎| 26/28 [00:35<00:02,  1.12s/it, loss=0.1897, batch_acc=0.9688, running_acc=0.8450]Evaluation epoch 34:  93%|█████████▎| 26/28 [00:35<00:02,  1.12s/it, loss=0.6887, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 34:  96%|█████████▋| 27/28 [00:35<00:00,  1.16it/s, loss=0.6887, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 34:  96%|█████████▋| 27/28 [00:35<00:00,  1.16it/s, loss=0.8051, batch_acc=0.7500, running_acc=0.8403]Evaluation epoch 34: 100%|██████████| 28/28 [00:35<00:00,  1.16it/s, loss=1.1866, batch_acc=0.6667, running_acc=0.8397]Evaluation epoch 34: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.1866, batch_acc=0.6667, running_acc=0.8397]
Training epoch 35:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 35:   1%|          | 1/163 [00:05<15:05,  5.59s/it]Training epoch 35:   1%|          | 1/163 [00:05<15:05,  5.59s/it, loss=0.2638, batch_acc=0.9688, running_acc=0.9688, grad=18.0569]Training epoch 35:   1%|          | 2/163 [00:06<07:33,  2.82s/it, loss=0.2638, batch_acc=0.9688, running_acc=0.9688, grad=18.0569]Training epoch 35:   1%|          | 2/163 [00:06<07:33,  2.82s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9844, grad=8.1284] Training epoch 35:   2%|▏         | 3/163 [00:07<05:09,  1.93s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9844, grad=8.1284]Training epoch 35:   2%|▏         | 3/163 [00:07<05:09,  1.93s/it, loss=0.2506, batch_acc=1.0000, running_acc=0.9896, grad=18.9335]Training epoch 35:   2%|▏         | 4/163 [00:10<05:55,  2.24s/it, loss=0.2506, batch_acc=1.0000, running_acc=0.9896, grad=18.9335]Training epoch 35:   2%|▏         | 4/163 [00:10<05:55,  2.24s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9922, grad=9.7907] Training epoch 35:   3%|▎         | 5/163 [00:10<04:36,  1.75s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9922, grad=9.7907]Training epoch 35:   3%|▎         | 5/163 [00:10<04:36,  1.75s/it, loss=0.1729, batch_acc=1.0000, running_acc=0.9938, grad=11.6303]Training epoch 35:   4%|▎         | 6/163 [00:11<03:48,  1.45s/it, loss=0.1729, batch_acc=1.0000, running_acc=0.9938, grad=11.6303]Training epoch 35:   4%|▎         | 6/163 [00:11<03:48,  1.45s/it, loss=0.1419, batch_acc=0.9688, running_acc=0.9896, grad=10.8205]Training epoch 35:   4%|▍         | 7/163 [00:12<03:19,  1.28s/it, loss=0.1419, batch_acc=0.9688, running_acc=0.9896, grad=10.8205]Training epoch 35:   4%|▍         | 7/163 [00:12<03:19,  1.28s/it, loss=0.1735, batch_acc=1.0000, running_acc=0.9911, grad=16.7389]Training epoch 35:   5%|▍         | 8/163 [00:14<03:42,  1.44s/it, loss=0.1735, batch_acc=1.0000, running_acc=0.9911, grad=16.7389]Training epoch 35:   5%|▍         | 8/163 [00:14<03:42,  1.44s/it, loss=0.1662, batch_acc=1.0000, running_acc=0.9922, grad=18.0511]Training epoch 35:   6%|▌         | 9/163 [00:15<03:14,  1.26s/it, loss=0.1662, batch_acc=1.0000, running_acc=0.9922, grad=18.0511]Training epoch 35:   6%|▌         | 9/163 [00:15<03:14,  1.26s/it, loss=0.1601, batch_acc=0.9688, running_acc=0.9896, grad=13.6670]Training epoch 35:   6%|▌         | 10/163 [00:16<02:54,  1.14s/it, loss=0.1601, batch_acc=0.9688, running_acc=0.9896, grad=13.6670]Training epoch 35:   6%|▌         | 10/163 [00:16<02:54,  1.14s/it, loss=0.1347, batch_acc=0.9688, running_acc=0.9875, grad=10.4927]Training epoch 35:   7%|▋         | 11/163 [00:17<02:41,  1.06s/it, loss=0.1347, batch_acc=0.9688, running_acc=0.9875, grad=10.4927]Training epoch 35:   7%|▋         | 11/163 [00:17<02:41,  1.06s/it, loss=0.1237, batch_acc=1.0000, running_acc=0.9886, grad=8.7144] Training epoch 35:   7%|▋         | 12/163 [00:19<03:36,  1.43s/it, loss=0.1237, batch_acc=1.0000, running_acc=0.9886, grad=8.7144]Training epoch 35:   7%|▋         | 12/163 [00:19<03:36,  1.43s/it, loss=0.0866, batch_acc=1.0000, running_acc=0.9896, grad=9.0392]Training epoch 35:   8%|▊         | 13/163 [00:20<03:09,  1.26s/it, loss=0.0866, batch_acc=1.0000, running_acc=0.9896, grad=9.0392]Training epoch 35:   8%|▊         | 13/163 [00:20<03:09,  1.26s/it, loss=0.2432, batch_acc=0.9688, running_acc=0.9880, grad=21.5651]Training epoch 35:   9%|▊         | 14/163 [00:21<02:51,  1.15s/it, loss=0.2432, batch_acc=0.9688, running_acc=0.9880, grad=21.5651]Training epoch 35:   9%|▊         | 14/163 [00:21<02:51,  1.15s/it, loss=0.2180, batch_acc=0.9375, running_acc=0.9844, grad=15.1276]Training epoch 35:   9%|▉         | 15/163 [00:22<02:38,  1.07s/it, loss=0.2180, batch_acc=0.9375, running_acc=0.9844, grad=15.1276]Training epoch 35:   9%|▉         | 15/163 [00:22<02:38,  1.07s/it, loss=0.1369, batch_acc=1.0000, running_acc=0.9854, grad=14.0186]Training epoch 35:  10%|▉         | 16/163 [00:24<03:32,  1.45s/it, loss=0.1369, batch_acc=1.0000, running_acc=0.9854, grad=14.0186]Training epoch 35:  10%|▉         | 16/163 [00:24<03:32,  1.45s/it, loss=0.1185, batch_acc=1.0000, running_acc=0.9863, grad=5.6271] Training epoch 35:  10%|█         | 17/163 [00:25<03:06,  1.28s/it, loss=0.1185, batch_acc=1.0000, running_acc=0.9863, grad=5.6271]Training epoch 35:  10%|█         | 17/163 [00:25<03:06,  1.28s/it, loss=0.1772, batch_acc=0.9688, running_acc=0.9853, grad=13.5438]Training epoch 35:  11%|█         | 18/163 [00:26<02:47,  1.16s/it, loss=0.1772, batch_acc=0.9688, running_acc=0.9853, grad=13.5438]Training epoch 35:  11%|█         | 18/163 [00:26<02:47,  1.16s/it, loss=0.2078, batch_acc=0.9688, running_acc=0.9844, grad=15.6349]Training epoch 35:  12%|█▏        | 19/163 [00:27<02:34,  1.07s/it, loss=0.2078, batch_acc=0.9688, running_acc=0.9844, grad=15.6349]Training epoch 35:  12%|█▏        | 19/163 [00:27<02:34,  1.07s/it, loss=0.1102, batch_acc=1.0000, running_acc=0.9852, grad=10.2027]Training epoch 35:  12%|█▏        | 20/163 [00:29<03:24,  1.43s/it, loss=0.1102, batch_acc=1.0000, running_acc=0.9852, grad=10.2027]Training epoch 35:  12%|█▏        | 20/163 [00:29<03:24,  1.43s/it, loss=0.2501, batch_acc=0.9688, running_acc=0.9844, grad=13.3902]Training epoch 35:  13%|█▎        | 21/163 [00:30<02:59,  1.27s/it, loss=0.2501, batch_acc=0.9688, running_acc=0.9844, grad=13.3902]Training epoch 35:  13%|█▎        | 21/163 [00:30<02:59,  1.27s/it, loss=0.1814, batch_acc=1.0000, running_acc=0.9851, grad=18.1102]Training epoch 35:  13%|█▎        | 22/163 [00:31<02:42,  1.15s/it, loss=0.1814, batch_acc=1.0000, running_acc=0.9851, grad=18.1102]Training epoch 35:  13%|█▎        | 22/163 [00:31<02:42,  1.15s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9858, grad=14.0555]Training epoch 35:  14%|█▍        | 23/163 [00:31<02:29,  1.07s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9858, grad=14.0555]Training epoch 35:  14%|█▍        | 23/163 [00:31<02:29,  1.07s/it, loss=0.1775, batch_acc=1.0000, running_acc=0.9864, grad=14.3099]Training epoch 35:  15%|█▍        | 24/163 [00:34<03:13,  1.39s/it, loss=0.1775, batch_acc=1.0000, running_acc=0.9864, grad=14.3099]Training epoch 35:  15%|█▍        | 24/163 [00:34<03:13,  1.39s/it, loss=0.1568, batch_acc=0.9688, running_acc=0.9857, grad=10.8182]Training epoch 35:  15%|█▌        | 25/163 [00:34<02:51,  1.24s/it, loss=0.1568, batch_acc=0.9688, running_acc=0.9857, grad=10.8182]Training epoch 35:  15%|█▌        | 25/163 [00:34<02:51,  1.24s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9850, grad=9.1667] Training epoch 35:  16%|█▌        | 26/163 [00:35<02:35,  1.13s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9850, grad=9.1667]Training epoch 35:  16%|█▌        | 26/163 [00:35<02:35,  1.13s/it, loss=0.1757, batch_acc=0.9688, running_acc=0.9844, grad=14.1062]Training epoch 35:  17%|█▋        | 27/163 [00:36<02:23,  1.06s/it, loss=0.1757, batch_acc=0.9688, running_acc=0.9844, grad=14.1062]Training epoch 35:  17%|█▋        | 27/163 [00:36<02:23,  1.06s/it, loss=0.1275, batch_acc=1.0000, running_acc=0.9850, grad=12.6177]Training epoch 35:  17%|█▋        | 28/163 [00:38<02:55,  1.30s/it, loss=0.1275, batch_acc=1.0000, running_acc=0.9850, grad=12.6177]Training epoch 35:  17%|█▋        | 28/163 [00:38<02:55,  1.30s/it, loss=0.1873, batch_acc=1.0000, running_acc=0.9855, grad=27.7408]Training epoch 35:  18%|█▊        | 29/163 [00:39<02:37,  1.17s/it, loss=0.1873, batch_acc=1.0000, running_acc=0.9855, grad=27.7408]Training epoch 35:  18%|█▊        | 29/163 [00:39<02:37,  1.17s/it, loss=0.2161, batch_acc=1.0000, running_acc=0.9860, grad=13.9531]Training epoch 35:  18%|█▊        | 30/163 [00:40<02:24,  1.09s/it, loss=0.2161, batch_acc=1.0000, running_acc=0.9860, grad=13.9531]Training epoch 35:  18%|█▊        | 30/163 [00:40<02:24,  1.09s/it, loss=0.1309, batch_acc=1.0000, running_acc=0.9865, grad=12.1175]Training epoch 35:  19%|█▉        | 31/163 [00:41<02:17,  1.04s/it, loss=0.1309, batch_acc=1.0000, running_acc=0.9865, grad=12.1175]Training epoch 35:  19%|█▉        | 31/163 [00:41<02:17,  1.04s/it, loss=0.1754, batch_acc=0.9688, running_acc=0.9859, grad=21.5534]Training epoch 35:  20%|█▉        | 32/163 [00:42<02:33,  1.17s/it, loss=0.1754, batch_acc=0.9688, running_acc=0.9859, grad=21.5534]Training epoch 35:  20%|█▉        | 32/163 [00:42<02:33,  1.17s/it, loss=0.1533, batch_acc=0.9688, running_acc=0.9854, grad=12.8012]Training epoch 35:  20%|██        | 33/163 [00:43<02:20,  1.08s/it, loss=0.1533, batch_acc=0.9688, running_acc=0.9854, grad=12.8012]Training epoch 35:  20%|██        | 33/163 [00:43<02:20,  1.08s/it, loss=0.1639, batch_acc=1.0000, running_acc=0.9858, grad=14.8138]Training epoch 35:  21%|██        | 34/163 [00:44<02:11,  1.02s/it, loss=0.1639, batch_acc=1.0000, running_acc=0.9858, grad=14.8138]Training epoch 35:  21%|██        | 34/163 [00:44<02:11,  1.02s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9862, grad=8.8908] Training epoch 35:  21%|██▏       | 35/163 [00:45<02:05,  1.02it/s, loss=0.1306, batch_acc=1.0000, running_acc=0.9862, grad=8.8908]Training epoch 35:  21%|██▏       | 35/163 [00:45<02:05,  1.02it/s, loss=0.1206, batch_acc=0.9688, running_acc=0.9857, grad=7.5069]Training epoch 35:  22%|██▏       | 36/163 [00:47<02:36,  1.23s/it, loss=0.1206, batch_acc=0.9688, running_acc=0.9857, grad=7.5069]Training epoch 35:  22%|██▏       | 36/163 [00:47<02:36,  1.23s/it, loss=0.2304, batch_acc=0.9688, running_acc=0.9852, grad=16.7220]Training epoch 35:  23%|██▎       | 37/163 [00:48<02:21,  1.12s/it, loss=0.2304, batch_acc=0.9688, running_acc=0.9852, grad=16.7220]Training epoch 35:  23%|██▎       | 37/163 [00:48<02:21,  1.12s/it, loss=0.1813, batch_acc=1.0000, running_acc=0.9856, grad=21.5460]Training epoch 35:  23%|██▎       | 38/163 [00:48<02:11,  1.05s/it, loss=0.1813, batch_acc=1.0000, running_acc=0.9856, grad=21.5460]Training epoch 35:  23%|██▎       | 38/163 [00:48<02:11,  1.05s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9852, grad=9.7465] Training epoch 35:  24%|██▍       | 39/163 [00:49<02:03,  1.00it/s, loss=0.1136, batch_acc=0.9688, running_acc=0.9852, grad=9.7465]Training epoch 35:  24%|██▍       | 39/163 [00:49<02:03,  1.00it/s, loss=0.1329, batch_acc=1.0000, running_acc=0.9856, grad=10.4744]Training epoch 35:  25%|██▍       | 40/163 [00:52<02:52,  1.41s/it, loss=0.1329, batch_acc=1.0000, running_acc=0.9856, grad=10.4744]Training epoch 35:  25%|██▍       | 40/163 [00:52<02:52,  1.41s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9859, grad=9.5547] Training epoch 35:  25%|██▌       | 41/163 [00:53<02:32,  1.25s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9859, grad=9.5547]Training epoch 35:  25%|██▌       | 41/163 [00:53<02:32,  1.25s/it, loss=0.1353, batch_acc=0.9688, running_acc=0.9855, grad=16.5118]Training epoch 35:  26%|██▌       | 42/163 [00:53<02:17,  1.14s/it, loss=0.1353, batch_acc=0.9688, running_acc=0.9855, grad=16.5118]Training epoch 35:  26%|██▌       | 42/163 [00:53<02:17,  1.14s/it, loss=0.1292, batch_acc=1.0000, running_acc=0.9859, grad=11.4066]Training epoch 35:  26%|██▋       | 43/163 [00:54<02:07,  1.06s/it, loss=0.1292, batch_acc=1.0000, running_acc=0.9859, grad=11.4066]Training epoch 35:  26%|██▋       | 43/163 [00:54<02:07,  1.06s/it, loss=0.1409, batch_acc=1.0000, running_acc=0.9862, grad=17.6926]Training epoch 35:  27%|██▋       | 44/163 [00:56<02:39,  1.34s/it, loss=0.1409, batch_acc=1.0000, running_acc=0.9862, grad=17.6926]Training epoch 35:  27%|██▋       | 44/163 [00:56<02:39,  1.34s/it, loss=0.1852, batch_acc=0.9688, running_acc=0.9858, grad=14.3664]Training epoch 35:  28%|██▊       | 45/163 [00:57<02:21,  1.20s/it, loss=0.1852, batch_acc=0.9688, running_acc=0.9858, grad=14.3664]Training epoch 35:  28%|██▊       | 45/163 [00:57<02:21,  1.20s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9861, grad=10.9028]Training epoch 35:  28%|██▊       | 46/163 [00:58<02:09,  1.10s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9861, grad=10.9028]Training epoch 35:  28%|██▊       | 46/163 [00:58<02:09,  1.10s/it, loss=0.2283, batch_acc=0.9688, running_acc=0.9857, grad=15.2547]Training epoch 35:  29%|██▉       | 47/163 [00:59<02:00,  1.04s/it, loss=0.2283, batch_acc=0.9688, running_acc=0.9857, grad=15.2547]Training epoch 35:  29%|██▉       | 47/163 [00:59<02:00,  1.04s/it, loss=0.1956, batch_acc=0.9375, running_acc=0.9847, grad=11.0336]Training epoch 35:  29%|██▉       | 48/163 [01:01<02:34,  1.34s/it, loss=0.1956, batch_acc=0.9375, running_acc=0.9847, grad=11.0336]Training epoch 35:  29%|██▉       | 48/163 [01:01<02:34,  1.34s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9850, grad=11.9887]Training epoch 35:  30%|███       | 49/163 [01:02<02:17,  1.20s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9850, grad=11.9887]Training epoch 35:  30%|███       | 49/163 [01:02<02:17,  1.20s/it, loss=0.1475, batch_acc=1.0000, running_acc=0.9853, grad=10.7426]Training epoch 35:  31%|███       | 50/163 [01:03<02:05,  1.11s/it, loss=0.1475, batch_acc=1.0000, running_acc=0.9853, grad=10.7426]Training epoch 35:  31%|███       | 50/163 [01:03<02:05,  1.11s/it, loss=0.1707, batch_acc=1.0000, running_acc=0.9856, grad=18.4701]Training epoch 35:  31%|███▏      | 51/163 [01:04<01:56,  1.04s/it, loss=0.1707, batch_acc=1.0000, running_acc=0.9856, grad=18.4701]Training epoch 35:  31%|███▏      | 51/163 [01:04<01:56,  1.04s/it, loss=0.2508, batch_acc=0.9375, running_acc=0.9847, grad=15.1633]Training epoch 35:  32%|███▏      | 52/163 [01:05<02:12,  1.19s/it, loss=0.2508, batch_acc=0.9375, running_acc=0.9847, grad=15.1633]Training epoch 35:  32%|███▏      | 52/163 [01:05<02:12,  1.19s/it, loss=0.1417, batch_acc=1.0000, running_acc=0.9850, grad=11.8690]Training epoch 35:  33%|███▎      | 53/163 [01:06<02:01,  1.10s/it, loss=0.1417, batch_acc=1.0000, running_acc=0.9850, grad=11.8690]Training epoch 35:  33%|███▎      | 53/163 [01:06<02:01,  1.10s/it, loss=0.1919, batch_acc=1.0000, running_acc=0.9853, grad=22.5112]Training epoch 35:  33%|███▎      | 54/163 [01:07<01:52,  1.03s/it, loss=0.1919, batch_acc=1.0000, running_acc=0.9853, grad=22.5112]Training epoch 35:  33%|███▎      | 54/163 [01:07<01:52,  1.03s/it, loss=0.2276, batch_acc=0.9688, running_acc=0.9850, grad=24.6467]Training epoch 35:  34%|███▎      | 55/163 [01:08<01:46,  1.01it/s, loss=0.2276, batch_acc=0.9688, running_acc=0.9850, grad=24.6467]Training epoch 35:  34%|███▎      | 55/163 [01:08<01:46,  1.01it/s, loss=0.1467, batch_acc=1.0000, running_acc=0.9852, grad=13.6724]Training epoch 35:  34%|███▍      | 56/163 [01:09<02:03,  1.15s/it, loss=0.1467, batch_acc=1.0000, running_acc=0.9852, grad=13.6724]Training epoch 35:  34%|███▍      | 56/163 [01:09<02:03,  1.15s/it, loss=0.1304, batch_acc=0.9688, running_acc=0.9849, grad=8.3307] Training epoch 35:  35%|███▍      | 57/163 [01:10<01:53,  1.07s/it, loss=0.1304, batch_acc=0.9688, running_acc=0.9849, grad=8.3307]Training epoch 35:  35%|███▍      | 57/163 [01:10<01:53,  1.07s/it, loss=0.1444, batch_acc=1.0000, running_acc=0.9852, grad=12.9108]Training epoch 35:  36%|███▌      | 58/163 [01:11<01:46,  1.01s/it, loss=0.1444, batch_acc=1.0000, running_acc=0.9852, grad=12.9108]Training epoch 35:  36%|███▌      | 58/163 [01:11<01:46,  1.01s/it, loss=0.1117, batch_acc=1.0000, running_acc=0.9855, grad=10.2786]Training epoch 35:  36%|███▌      | 59/163 [01:12<01:41,  1.03it/s, loss=0.1117, batch_acc=1.0000, running_acc=0.9855, grad=10.2786]Training epoch 35:  36%|███▌      | 59/163 [01:12<01:41,  1.03it/s, loss=0.1192, batch_acc=1.0000, running_acc=0.9857, grad=11.0149]Training epoch 35:  37%|███▋      | 60/163 [01:14<02:17,  1.33s/it, loss=0.1192, batch_acc=1.0000, running_acc=0.9857, grad=11.0149]Training epoch 35:  37%|███▋      | 60/163 [01:14<02:17,  1.33s/it, loss=0.1427, batch_acc=0.9688, running_acc=0.9854, grad=9.3472] Training epoch 35:  37%|███▋      | 61/163 [01:15<02:02,  1.20s/it, loss=0.1427, batch_acc=0.9688, running_acc=0.9854, grad=9.3472]Training epoch 35:  37%|███▋      | 61/163 [01:15<02:02,  1.20s/it, loss=0.2549, batch_acc=0.9688, running_acc=0.9851, grad=19.0122]Training epoch 35:  38%|███▊      | 62/163 [01:16<01:51,  1.10s/it, loss=0.2549, batch_acc=0.9688, running_acc=0.9851, grad=19.0122]Training epoch 35:  38%|███▊      | 62/163 [01:16<01:51,  1.10s/it, loss=0.2373, batch_acc=0.9688, running_acc=0.9849, grad=18.6209]Training epoch 35:  39%|███▊      | 63/163 [01:17<01:43,  1.04s/it, loss=0.2373, batch_acc=0.9688, running_acc=0.9849, grad=18.6209]Training epoch 35:  39%|███▊      | 63/163 [01:17<01:43,  1.04s/it, loss=0.2020, batch_acc=0.9688, running_acc=0.9846, grad=11.1588]Training epoch 35:  39%|███▉      | 64/163 [01:19<02:24,  1.46s/it, loss=0.2020, batch_acc=0.9688, running_acc=0.9846, grad=11.1588]Training epoch 35:  39%|███▉      | 64/163 [01:19<02:24,  1.46s/it, loss=0.1588, batch_acc=1.0000, running_acc=0.9849, grad=10.3833]Training epoch 35:  40%|███▉      | 65/163 [01:20<02:06,  1.29s/it, loss=0.1588, batch_acc=1.0000, running_acc=0.9849, grad=10.3833]Training epoch 35:  40%|███▉      | 65/163 [01:20<02:06,  1.29s/it, loss=0.1390, batch_acc=1.0000, running_acc=0.9851, grad=11.9300]Training epoch 35:  40%|████      | 66/163 [01:21<01:52,  1.16s/it, loss=0.1390, batch_acc=1.0000, running_acc=0.9851, grad=11.9300]Training epoch 35:  40%|████      | 66/163 [01:21<01:52,  1.16s/it, loss=0.1044, batch_acc=1.0000, running_acc=0.9853, grad=14.8885]Training epoch 35:  41%|████      | 67/163 [01:22<01:43,  1.08s/it, loss=0.1044, batch_acc=1.0000, running_acc=0.9853, grad=14.8885]Training epoch 35:  41%|████      | 67/163 [01:22<01:43,  1.08s/it, loss=0.2077, batch_acc=0.9062, running_acc=0.9841, grad=19.5460]Training epoch 35:  42%|████▏     | 68/163 [01:24<02:09,  1.36s/it, loss=0.2077, batch_acc=0.9062, running_acc=0.9841, grad=19.5460]Training epoch 35:  42%|████▏     | 68/163 [01:24<02:09,  1.36s/it, loss=0.1380, batch_acc=1.0000, running_acc=0.9844, grad=14.3053]Training epoch 35:  42%|████▏     | 69/163 [01:25<01:54,  1.21s/it, loss=0.1380, batch_acc=1.0000, running_acc=0.9844, grad=14.3053]Training epoch 35:  42%|████▏     | 69/163 [01:25<01:54,  1.21s/it, loss=0.1357, batch_acc=1.0000, running_acc=0.9846, grad=11.0169]Training epoch 35:  43%|████▎     | 70/163 [01:26<01:43,  1.11s/it, loss=0.1357, batch_acc=1.0000, running_acc=0.9846, grad=11.0169]Training epoch 35:  43%|████▎     | 70/163 [01:26<01:43,  1.11s/it, loss=0.2093, batch_acc=0.9375, running_acc=0.9839, grad=14.1496]Training epoch 35:  44%|████▎     | 71/163 [01:27<01:35,  1.04s/it, loss=0.2093, batch_acc=0.9375, running_acc=0.9839, grad=14.1496]Training epoch 35:  44%|████▎     | 71/163 [01:27<01:35,  1.04s/it, loss=0.2245, batch_acc=0.9688, running_acc=0.9837, grad=21.5066]Training epoch 35:  44%|████▍     | 72/163 [01:29<02:07,  1.40s/it, loss=0.2245, batch_acc=0.9688, running_acc=0.9837, grad=21.5066]Training epoch 35:  44%|████▍     | 72/163 [01:29<02:07,  1.40s/it, loss=0.1441, batch_acc=0.9688, running_acc=0.9835, grad=10.7601]Training epoch 35:  45%|████▍     | 73/163 [01:30<01:52,  1.25s/it, loss=0.1441, batch_acc=0.9688, running_acc=0.9835, grad=10.7601]Training epoch 35:  45%|████▍     | 73/163 [01:30<01:52,  1.25s/it, loss=0.1370, batch_acc=1.0000, running_acc=0.9837, grad=9.5284] Training epoch 35:  45%|████▌     | 74/163 [01:31<01:41,  1.14s/it, loss=0.1370, batch_acc=1.0000, running_acc=0.9837, grad=9.5284]Training epoch 35:  45%|████▌     | 74/163 [01:31<01:41,  1.14s/it, loss=0.1852, batch_acc=1.0000, running_acc=0.9840, grad=19.4592]Training epoch 35:  46%|████▌     | 75/163 [01:31<01:33,  1.06s/it, loss=0.1852, batch_acc=1.0000, running_acc=0.9840, grad=19.4592]Training epoch 35:  46%|████▌     | 75/163 [01:31<01:33,  1.06s/it, loss=0.1702, batch_acc=0.9688, running_acc=0.9838, grad=12.0180]Training epoch 35:  47%|████▋     | 76/163 [01:33<01:48,  1.25s/it, loss=0.1702, batch_acc=0.9688, running_acc=0.9838, grad=12.0180]Training epoch 35:  47%|████▋     | 76/163 [01:33<01:48,  1.25s/it, loss=0.1359, batch_acc=1.0000, running_acc=0.9840, grad=11.1394]Training epoch 35:  47%|████▋     | 77/163 [01:34<01:37,  1.14s/it, loss=0.1359, batch_acc=1.0000, running_acc=0.9840, grad=11.1394]Training epoch 35:  47%|████▋     | 77/163 [01:34<01:37,  1.14s/it, loss=0.1931, batch_acc=0.9688, running_acc=0.9838, grad=20.9605]Training epoch 35:  48%|████▊     | 78/163 [01:35<01:30,  1.06s/it, loss=0.1931, batch_acc=0.9688, running_acc=0.9838, grad=20.9605]Training epoch 35:  48%|████▊     | 78/163 [01:35<01:30,  1.06s/it, loss=0.1712, batch_acc=0.9375, running_acc=0.9832, grad=10.6503]Training epoch 35:  48%|████▊     | 79/163 [01:36<01:24,  1.01s/it, loss=0.1712, batch_acc=0.9375, running_acc=0.9832, grad=10.6503]Training epoch 35:  48%|████▊     | 79/163 [01:36<01:24,  1.01s/it, loss=0.1418, batch_acc=1.0000, running_acc=0.9834, grad=12.0357]Training epoch 35:  49%|████▉     | 80/163 [01:38<01:58,  1.43s/it, loss=0.1418, batch_acc=1.0000, running_acc=0.9834, grad=12.0357]Training epoch 35:  49%|████▉     | 80/163 [01:38<01:58,  1.43s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9836, grad=10.0330]Training epoch 35:  50%|████▉     | 81/163 [01:39<01:43,  1.26s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9836, grad=10.0330]Training epoch 35:  50%|████▉     | 81/163 [01:39<01:43,  1.26s/it, loss=0.1418, batch_acc=0.9688, running_acc=0.9834, grad=10.4421]Training epoch 35:  50%|█████     | 82/163 [01:40<01:33,  1.15s/it, loss=0.1418, batch_acc=0.9688, running_acc=0.9834, grad=10.4421]Training epoch 35:  50%|█████     | 82/163 [01:40<01:33,  1.15s/it, loss=0.2047, batch_acc=0.9375, running_acc=0.9829, grad=13.0354]Training epoch 35:  51%|█████     | 83/163 [01:41<01:25,  1.07s/it, loss=0.2047, batch_acc=0.9375, running_acc=0.9829, grad=13.0354]Training epoch 35:  51%|█████     | 83/163 [01:41<01:25,  1.07s/it, loss=0.1114, batch_acc=1.0000, running_acc=0.9831, grad=7.8897] Training epoch 35:  52%|█████▏    | 84/163 [01:43<01:44,  1.32s/it, loss=0.1114, batch_acc=1.0000, running_acc=0.9831, grad=7.8897]Training epoch 35:  52%|█████▏    | 84/163 [01:43<01:44,  1.32s/it, loss=0.1633, batch_acc=1.0000, running_acc=0.9833, grad=16.1800]Training epoch 35:  52%|█████▏    | 85/163 [01:44<01:32,  1.19s/it, loss=0.1633, batch_acc=1.0000, running_acc=0.9833, grad=16.1800]Training epoch 35:  52%|█████▏    | 85/163 [01:44<01:32,  1.19s/it, loss=0.2108, batch_acc=0.9688, running_acc=0.9831, grad=15.8944]Training epoch 35:  53%|█████▎    | 86/163 [01:45<01:24,  1.10s/it, loss=0.2108, batch_acc=0.9688, running_acc=0.9831, grad=15.8944]Training epoch 35:  53%|█████▎    | 86/163 [01:45<01:24,  1.10s/it, loss=0.1957, batch_acc=0.9375, running_acc=0.9826, grad=13.1526]Training epoch 35:  53%|█████▎    | 87/163 [01:45<01:18,  1.03s/it, loss=0.1957, batch_acc=0.9375, running_acc=0.9826, grad=13.1526]Training epoch 35:  53%|█████▎    | 87/163 [01:45<01:18,  1.03s/it, loss=0.1168, batch_acc=0.9688, running_acc=0.9824, grad=6.7361] Training epoch 35:  54%|█████▍    | 88/163 [01:47<01:36,  1.28s/it, loss=0.1168, batch_acc=0.9688, running_acc=0.9824, grad=6.7361]Training epoch 35:  54%|█████▍    | 88/163 [01:47<01:36,  1.28s/it, loss=0.1685, batch_acc=1.0000, running_acc=0.9826, grad=12.0866]Training epoch 35:  55%|█████▍    | 89/163 [01:48<01:25,  1.16s/it, loss=0.1685, batch_acc=1.0000, running_acc=0.9826, grad=12.0866]Training epoch 35:  55%|█████▍    | 89/163 [01:48<01:25,  1.16s/it, loss=0.1090, batch_acc=1.0000, running_acc=0.9828, grad=11.8935]Training epoch 35:  55%|█████▌    | 90/163 [01:49<01:18,  1.08s/it, loss=0.1090, batch_acc=1.0000, running_acc=0.9828, grad=11.8935]Training epoch 35:  55%|█████▌    | 90/163 [01:49<01:18,  1.08s/it, loss=0.1204, batch_acc=1.0000, running_acc=0.9830, grad=7.9765] Training epoch 35:  56%|█████▌    | 91/163 [01:50<01:13,  1.02s/it, loss=0.1204, batch_acc=1.0000, running_acc=0.9830, grad=7.9765]Training epoch 35:  56%|█████▌    | 91/163 [01:50<01:13,  1.02s/it, loss=0.1548, batch_acc=1.0000, running_acc=0.9832, grad=10.4514]Training epoch 35:  56%|█████▋    | 92/163 [01:52<01:33,  1.31s/it, loss=0.1548, batch_acc=1.0000, running_acc=0.9832, grad=10.4514]Training epoch 35:  56%|█████▋    | 92/163 [01:52<01:33,  1.31s/it, loss=0.2070, batch_acc=0.9062, running_acc=0.9823, grad=17.7854]Training epoch 35:  57%|█████▋    | 93/163 [01:53<01:22,  1.18s/it, loss=0.2070, batch_acc=0.9062, running_acc=0.9823, grad=17.7854]Training epoch 35:  57%|█████▋    | 93/163 [01:53<01:22,  1.18s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9825, grad=11.0620]Training epoch 35:  58%|█████▊    | 94/163 [01:54<01:15,  1.09s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9825, grad=11.0620]Training epoch 35:  58%|█████▊    | 94/163 [01:54<01:15,  1.09s/it, loss=0.1699, batch_acc=0.9688, running_acc=0.9824, grad=14.5786]Training epoch 35:  58%|█████▊    | 95/163 [01:55<01:09,  1.03s/it, loss=0.1699, batch_acc=0.9688, running_acc=0.9824, grad=14.5786]Training epoch 35:  58%|█████▊    | 95/163 [01:55<01:09,  1.03s/it, loss=0.1946, batch_acc=0.9375, running_acc=0.9819, grad=11.8197]Training epoch 35:  59%|█████▉    | 96/163 [01:56<01:21,  1.21s/it, loss=0.1946, batch_acc=0.9375, running_acc=0.9819, grad=11.8197]Training epoch 35:  59%|█████▉    | 96/163 [01:56<01:21,  1.21s/it, loss=0.2144, batch_acc=0.9375, running_acc=0.9814, grad=20.1998]Training epoch 35:  60%|█████▉    | 97/163 [01:57<01:13,  1.11s/it, loss=0.2144, batch_acc=0.9375, running_acc=0.9814, grad=20.1998]Training epoch 35:  60%|█████▉    | 97/163 [01:57<01:13,  1.11s/it, loss=0.1609, batch_acc=0.9688, running_acc=0.9813, grad=10.3366]Training epoch 35:  60%|██████    | 98/163 [01:58<01:07,  1.04s/it, loss=0.1609, batch_acc=0.9688, running_acc=0.9813, grad=10.3366]Training epoch 35:  60%|██████    | 98/163 [01:58<01:07,  1.04s/it, loss=0.1380, batch_acc=1.0000, running_acc=0.9815, grad=10.6742]Training epoch 35:  61%|██████    | 99/163 [01:59<01:03,  1.01it/s, loss=0.1380, batch_acc=1.0000, running_acc=0.9815, grad=10.6742]Training epoch 35:  61%|██████    | 99/163 [01:59<01:03,  1.01it/s, loss=0.0945, batch_acc=1.0000, running_acc=0.9817, grad=7.1779] Training epoch 35:  61%|██████▏   | 100/163 [02:01<01:20,  1.27s/it, loss=0.0945, batch_acc=1.0000, running_acc=0.9817, grad=7.1779]Training epoch 35:  61%|██████▏   | 100/163 [02:01<01:20,  1.27s/it, loss=0.1225, batch_acc=1.0000, running_acc=0.9819, grad=9.7014]Training epoch 35:  62%|██████▏   | 101/163 [02:02<01:11,  1.15s/it, loss=0.1225, batch_acc=1.0000, running_acc=0.9819, grad=9.7014]Training epoch 35:  62%|██████▏   | 101/163 [02:02<01:11,  1.15s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9821, grad=8.4352]Training epoch 35:  63%|██████▎   | 102/163 [02:03<01:05,  1.07s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9821, grad=8.4352]Training epoch 35:  63%|██████▎   | 102/163 [02:03<01:05,  1.07s/it, loss=0.2130, batch_acc=0.9062, running_acc=0.9813, grad=14.2202]Training epoch 35:  63%|██████▎   | 103/163 [02:03<01:00,  1.01s/it, loss=0.2130, batch_acc=0.9062, running_acc=0.9813, grad=14.2202]Training epoch 35:  63%|██████▎   | 103/163 [02:03<01:00,  1.01s/it, loss=0.1453, batch_acc=1.0000, running_acc=0.9815, grad=14.4847]Training epoch 35:  64%|██████▍   | 104/163 [02:05<01:17,  1.31s/it, loss=0.1453, batch_acc=1.0000, running_acc=0.9815, grad=14.4847]Training epoch 35:  64%|██████▍   | 104/163 [02:05<01:17,  1.31s/it, loss=0.1454, batch_acc=0.9688, running_acc=0.9814, grad=12.0284]Training epoch 35:  64%|██████▍   | 105/163 [02:06<01:08,  1.18s/it, loss=0.1454, batch_acc=0.9688, running_acc=0.9814, grad=12.0284]Training epoch 35:  64%|██████▍   | 105/163 [02:06<01:08,  1.18s/it, loss=0.1553, batch_acc=0.9688, running_acc=0.9812, grad=9.4846] Training epoch 35:  65%|██████▌   | 106/163 [02:07<01:02,  1.09s/it, loss=0.1553, batch_acc=0.9688, running_acc=0.9812, grad=9.4846]Training epoch 35:  65%|██████▌   | 106/163 [02:07<01:02,  1.09s/it, loss=0.1246, batch_acc=1.0000, running_acc=0.9814, grad=9.6261]Training epoch 35:  66%|██████▌   | 107/163 [02:08<00:57,  1.03s/it, loss=0.1246, batch_acc=1.0000, running_acc=0.9814, grad=9.6261]Training epoch 35:  66%|██████▌   | 107/163 [02:08<00:57,  1.03s/it, loss=0.1211, batch_acc=1.0000, running_acc=0.9816, grad=10.3906]Training epoch 35:  66%|██████▋   | 108/163 [02:10<01:07,  1.24s/it, loss=0.1211, batch_acc=1.0000, running_acc=0.9816, grad=10.3906]Training epoch 35:  66%|██████▋   | 108/163 [02:10<01:07,  1.24s/it, loss=0.1946, batch_acc=0.9688, running_acc=0.9815, grad=12.4000]Training epoch 35:  67%|██████▋   | 109/163 [02:11<01:00,  1.13s/it, loss=0.1946, batch_acc=0.9688, running_acc=0.9815, grad=12.4000]Training epoch 35:  67%|██████▋   | 109/163 [02:11<01:00,  1.13s/it, loss=0.1281, batch_acc=0.9688, running_acc=0.9814, grad=8.9680] Training epoch 35:  67%|██████▋   | 110/163 [02:12<00:55,  1.05s/it, loss=0.1281, batch_acc=0.9688, running_acc=0.9814, grad=8.9680]Training epoch 35:  67%|██████▋   | 110/163 [02:12<00:55,  1.05s/it, loss=0.1590, batch_acc=0.9375, running_acc=0.9810, grad=8.0231]Training epoch 35:  68%|██████▊   | 111/163 [02:12<00:52,  1.00s/it, loss=0.1590, batch_acc=0.9375, running_acc=0.9810, grad=8.0231]Training epoch 35:  68%|██████▊   | 111/163 [02:12<00:52,  1.00s/it, loss=0.1911, batch_acc=1.0000, running_acc=0.9811, grad=16.0516]Training epoch 35:  69%|██████▊   | 112/163 [02:14<01:01,  1.20s/it, loss=0.1911, batch_acc=1.0000, running_acc=0.9811, grad=16.0516]Training epoch 35:  69%|██████▊   | 112/163 [02:14<01:01,  1.20s/it, loss=0.1450, batch_acc=1.0000, running_acc=0.9813, grad=10.9099]Training epoch 35:  69%|██████▉   | 113/163 [02:15<00:55,  1.10s/it, loss=0.1450, batch_acc=1.0000, running_acc=0.9813, grad=10.9099]Training epoch 35:  69%|██████▉   | 113/163 [02:15<00:55,  1.10s/it, loss=0.1034, batch_acc=1.0000, running_acc=0.9815, grad=7.8029] Training epoch 35:  70%|██████▉   | 114/163 [02:16<00:50,  1.04s/it, loss=0.1034, batch_acc=1.0000, running_acc=0.9815, grad=7.8029]Training epoch 35:  70%|██████▉   | 114/163 [02:16<00:50,  1.04s/it, loss=0.1623, batch_acc=1.0000, running_acc=0.9816, grad=11.2981]Training epoch 35:  71%|███████   | 115/163 [02:17<00:47,  1.01it/s, loss=0.1623, batch_acc=1.0000, running_acc=0.9816, grad=11.2981]Training epoch 35:  71%|███████   | 115/163 [02:17<00:47,  1.01it/s, loss=0.1820, batch_acc=0.9688, running_acc=0.9815, grad=8.3948] Training epoch 35:  71%|███████   | 116/163 [02:19<01:03,  1.35s/it, loss=0.1820, batch_acc=0.9688, running_acc=0.9815, grad=8.3948]Training epoch 35:  71%|███████   | 116/163 [02:19<01:03,  1.35s/it, loss=0.1721, batch_acc=1.0000, running_acc=0.9817, grad=14.6432]Training epoch 35:  72%|███████▏  | 117/163 [02:20<00:55,  1.21s/it, loss=0.1721, batch_acc=1.0000, running_acc=0.9817, grad=14.6432]Training epoch 35:  72%|███████▏  | 117/163 [02:20<00:55,  1.21s/it, loss=0.1188, batch_acc=0.9688, running_acc=0.9816, grad=7.2828] Training epoch 35:  72%|███████▏  | 118/163 [02:21<00:49,  1.11s/it, loss=0.1188, batch_acc=0.9688, running_acc=0.9816, grad=7.2828]Training epoch 35:  72%|███████▏  | 118/163 [02:21<00:49,  1.11s/it, loss=0.2018, batch_acc=0.9375, running_acc=0.9812, grad=12.9172]Training epoch 35:  73%|███████▎  | 119/163 [02:22<00:45,  1.04s/it, loss=0.2018, batch_acc=0.9375, running_acc=0.9812, grad=12.9172]Training epoch 35:  73%|███████▎  | 119/163 [02:22<00:45,  1.04s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9808, grad=10.0260]Training epoch 35:  74%|███████▎  | 120/163 [02:24<01:04,  1.49s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9808, grad=10.0260]Training epoch 35:  74%|███████▎  | 120/163 [02:24<01:04,  1.49s/it, loss=0.1694, batch_acc=0.9688, running_acc=0.9807, grad=13.9186]Training epoch 35:  74%|███████▍  | 121/163 [02:25<00:54,  1.31s/it, loss=0.1694, batch_acc=0.9688, running_acc=0.9807, grad=13.9186]Training epoch 35:  74%|███████▍  | 121/163 [02:25<00:54,  1.31s/it, loss=0.1602, batch_acc=1.0000, running_acc=0.9809, grad=14.6042]Training epoch 35:  75%|███████▍  | 122/163 [02:26<00:48,  1.18s/it, loss=0.1602, batch_acc=1.0000, running_acc=0.9809, grad=14.6042]Training epoch 35:  75%|███████▍  | 122/163 [02:26<00:48,  1.18s/it, loss=0.1154, batch_acc=1.0000, running_acc=0.9810, grad=7.2367] Training epoch 35:  75%|███████▌  | 123/163 [02:27<00:43,  1.09s/it, loss=0.1154, batch_acc=1.0000, running_acc=0.9810, grad=7.2367]Training epoch 35:  75%|███████▌  | 123/163 [02:27<00:43,  1.09s/it, loss=0.1701, batch_acc=0.9688, running_acc=0.9809, grad=9.9598]Training epoch 35:  76%|███████▌  | 124/163 [02:29<00:54,  1.41s/it, loss=0.1701, batch_acc=0.9688, running_acc=0.9809, grad=9.9598]Training epoch 35:  76%|███████▌  | 124/163 [02:29<00:54,  1.41s/it, loss=0.1696, batch_acc=1.0000, running_acc=0.9811, grad=12.7322]Training epoch 35:  77%|███████▋  | 125/163 [02:30<00:47,  1.25s/it, loss=0.1696, batch_acc=1.0000, running_acc=0.9811, grad=12.7322]Training epoch 35:  77%|███████▋  | 125/163 [02:30<00:47,  1.25s/it, loss=0.1575, batch_acc=0.9688, running_acc=0.9810, grad=12.5748]Training epoch 35:  77%|███████▋  | 126/163 [02:31<00:42,  1.14s/it, loss=0.1575, batch_acc=0.9688, running_acc=0.9810, grad=12.5748]Training epoch 35:  77%|███████▋  | 126/163 [02:31<00:42,  1.14s/it, loss=0.1194, batch_acc=1.0000, running_acc=0.9812, grad=11.7401]Training epoch 35:  78%|███████▊  | 127/163 [02:31<00:38,  1.06s/it, loss=0.1194, batch_acc=1.0000, running_acc=0.9812, grad=11.7401]Training epoch 35:  78%|███████▊  | 127/163 [02:31<00:38,  1.06s/it, loss=0.1471, batch_acc=1.0000, running_acc=0.9813, grad=10.5757]Training epoch 35:  79%|███████▊  | 128/163 [02:34<00:48,  1.37s/it, loss=0.1471, batch_acc=1.0000, running_acc=0.9813, grad=10.5757]Training epoch 35:  79%|███████▊  | 128/163 [02:34<00:48,  1.37s/it, loss=0.1564, batch_acc=1.0000, running_acc=0.9814, grad=14.0457]Training epoch 35:  79%|███████▉  | 129/163 [02:34<00:41,  1.22s/it, loss=0.1564, batch_acc=1.0000, running_acc=0.9814, grad=14.0457]Training epoch 35:  79%|███████▉  | 129/163 [02:34<00:41,  1.22s/it, loss=0.1489, batch_acc=0.9688, running_acc=0.9813, grad=11.2696]Training epoch 35:  80%|███████▉  | 130/163 [02:35<00:36,  1.12s/it, loss=0.1489, batch_acc=0.9688, running_acc=0.9813, grad=11.2696]Training epoch 35:  80%|███████▉  | 130/163 [02:35<00:36,  1.12s/it, loss=0.2089, batch_acc=0.9688, running_acc=0.9812, grad=14.3707]Training epoch 35:  80%|████████  | 131/163 [02:36<00:33,  1.05s/it, loss=0.2089, batch_acc=0.9688, running_acc=0.9812, grad=14.3707]Training epoch 35:  80%|████████  | 131/163 [02:36<00:33,  1.05s/it, loss=0.1576, batch_acc=1.0000, running_acc=0.9814, grad=11.2829]Training epoch 35:  81%|████████  | 132/163 [02:38<00:37,  1.21s/it, loss=0.1576, batch_acc=1.0000, running_acc=0.9814, grad=11.2829]Training epoch 35:  81%|████████  | 132/163 [02:38<00:37,  1.21s/it, loss=0.1407, batch_acc=0.9688, running_acc=0.9813, grad=8.2084] Training epoch 35:  82%|████████▏ | 133/163 [02:39<00:33,  1.11s/it, loss=0.1407, batch_acc=0.9688, running_acc=0.9813, grad=8.2084]Training epoch 35:  82%|████████▏ | 133/163 [02:39<00:33,  1.11s/it, loss=0.2535, batch_acc=0.9375, running_acc=0.9810, grad=15.3337]Training epoch 35:  82%|████████▏ | 134/163 [02:40<00:30,  1.04s/it, loss=0.2535, batch_acc=0.9375, running_acc=0.9810, grad=15.3337]Training epoch 35:  82%|████████▏ | 134/163 [02:40<00:30,  1.04s/it, loss=0.1726, batch_acc=0.9688, running_acc=0.9809, grad=12.7511]Training epoch 35:  83%|████████▎ | 135/163 [02:40<00:27,  1.01it/s, loss=0.1726, batch_acc=0.9688, running_acc=0.9809, grad=12.7511]Training epoch 35:  83%|████████▎ | 135/163 [02:40<00:27,  1.01it/s, loss=0.0894, batch_acc=1.0000, running_acc=0.9810, grad=7.5092] Training epoch 35:  83%|████████▎ | 136/163 [02:42<00:33,  1.26s/it, loss=0.0894, batch_acc=1.0000, running_acc=0.9810, grad=7.5092]Training epoch 35:  83%|████████▎ | 136/163 [02:42<00:33,  1.26s/it, loss=0.1721, batch_acc=0.9375, running_acc=0.9807, grad=14.4698]Training epoch 35:  84%|████████▍ | 137/163 [02:43<00:29,  1.14s/it, loss=0.1721, batch_acc=0.9375, running_acc=0.9807, grad=14.4698]Training epoch 35:  84%|████████▍ | 137/163 [02:43<00:29,  1.14s/it, loss=0.2329, batch_acc=0.9375, running_acc=0.9804, grad=16.7747]Training epoch 35:  85%|████████▍ | 138/163 [02:44<00:26,  1.06s/it, loss=0.2329, batch_acc=0.9375, running_acc=0.9804, grad=16.7747]Training epoch 35:  85%|████████▍ | 138/163 [02:44<00:26,  1.06s/it, loss=0.1533, batch_acc=0.9688, running_acc=0.9803, grad=9.8534] Training epoch 35:  85%|████████▌ | 139/163 [02:45<00:24,  1.01s/it, loss=0.1533, batch_acc=0.9688, running_acc=0.9803, grad=9.8534]Training epoch 35:  85%|████████▌ | 139/163 [02:45<00:24,  1.01s/it, loss=0.1441, batch_acc=1.0000, running_acc=0.9804, grad=8.7999]Training epoch 35:  86%|████████▌ | 140/163 [02:47<00:30,  1.32s/it, loss=0.1441, batch_acc=1.0000, running_acc=0.9804, grad=8.7999]Training epoch 35:  86%|████████▌ | 140/163 [02:47<00:30,  1.32s/it, loss=0.1697, batch_acc=0.9688, running_acc=0.9804, grad=13.4691]Training epoch 35:  87%|████████▋ | 141/163 [02:48<00:26,  1.18s/it, loss=0.1697, batch_acc=0.9688, running_acc=0.9804, grad=13.4691]Training epoch 35:  87%|████████▋ | 141/163 [02:48<00:26,  1.18s/it, loss=0.1162, batch_acc=0.9688, running_acc=0.9803, grad=10.6847]Training epoch 35:  87%|████████▋ | 142/163 [02:49<00:22,  1.09s/it, loss=0.1162, batch_acc=0.9688, running_acc=0.9803, grad=10.6847]Training epoch 35:  87%|████████▋ | 142/163 [02:49<00:22,  1.09s/it, loss=0.1386, batch_acc=0.9688, running_acc=0.9802, grad=10.7067]Training epoch 35:  88%|████████▊ | 143/163 [02:50<00:20,  1.03s/it, loss=0.1386, batch_acc=0.9688, running_acc=0.9802, grad=10.7067]Training epoch 35:  88%|████████▊ | 143/163 [02:50<00:20,  1.03s/it, loss=0.1701, batch_acc=0.9688, running_acc=0.9801, grad=11.5206]Training epoch 35:  88%|████████▊ | 144/163 [02:52<00:24,  1.30s/it, loss=0.1701, batch_acc=0.9688, running_acc=0.9801, grad=11.5206]Training epoch 35:  88%|████████▊ | 144/163 [02:52<00:24,  1.30s/it, loss=0.1799, batch_acc=0.9375, running_acc=0.9798, grad=9.0352] Training epoch 35:  89%|████████▉ | 145/163 [02:52<00:21,  1.18s/it, loss=0.1799, batch_acc=0.9375, running_acc=0.9798, grad=9.0352]Training epoch 35:  89%|████████▉ | 145/163 [02:52<00:21,  1.18s/it, loss=0.1701, batch_acc=0.9688, running_acc=0.9797, grad=13.8947]Training epoch 35:  90%|████████▉ | 146/163 [02:53<00:18,  1.09s/it, loss=0.1701, batch_acc=0.9688, running_acc=0.9797, grad=13.8947]Training epoch 35:  90%|████████▉ | 146/163 [02:53<00:18,  1.09s/it, loss=0.1462, batch_acc=0.9688, running_acc=0.9797, grad=9.9900] Training epoch 35:  90%|█████████ | 147/163 [02:54<00:16,  1.03s/it, loss=0.1462, batch_acc=0.9688, running_acc=0.9797, grad=9.9900]Training epoch 35:  90%|█████████ | 147/163 [02:54<00:16,  1.03s/it, loss=0.1600, batch_acc=0.9375, running_acc=0.9794, grad=13.3504]Training epoch 35:  91%|█████████ | 148/163 [02:56<00:20,  1.36s/it, loss=0.1600, batch_acc=0.9375, running_acc=0.9794, grad=13.3504]Training epoch 35:  91%|█████████ | 148/163 [02:56<00:20,  1.36s/it, loss=0.1449, batch_acc=1.0000, running_acc=0.9795, grad=11.7781]Training epoch 35:  91%|█████████▏| 149/163 [02:57<00:17,  1.22s/it, loss=0.1449, batch_acc=1.0000, running_acc=0.9795, grad=11.7781]Training epoch 35:  91%|█████████▏| 149/163 [02:57<00:17,  1.22s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9797, grad=8.4245] Training epoch 35:  92%|█████████▏| 150/163 [02:58<00:14,  1.12s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9797, grad=8.4245]Training epoch 35:  92%|█████████▏| 150/163 [02:58<00:14,  1.12s/it, loss=0.1373, batch_acc=1.0000, running_acc=0.9798, grad=10.0546]Training epoch 35:  93%|█████████▎| 151/163 [02:59<00:12,  1.04s/it, loss=0.1373, batch_acc=1.0000, running_acc=0.9798, grad=10.0546]Training epoch 35:  93%|█████████▎| 151/163 [02:59<00:12,  1.04s/it, loss=0.1194, batch_acc=0.9688, running_acc=0.9797, grad=8.2630] Training epoch 35:  93%|█████████▎| 152/163 [03:01<00:14,  1.30s/it, loss=0.1194, batch_acc=0.9688, running_acc=0.9797, grad=8.2630]Training epoch 35:  93%|█████████▎| 152/163 [03:01<00:14,  1.30s/it, loss=0.1795, batch_acc=0.9375, running_acc=0.9794, grad=14.1118]Training epoch 35:  94%|█████████▍| 153/163 [03:02<00:11,  1.17s/it, loss=0.1795, batch_acc=0.9375, running_acc=0.9794, grad=14.1118]Training epoch 35:  94%|█████████▍| 153/163 [03:02<00:11,  1.17s/it, loss=0.1831, batch_acc=0.9688, running_acc=0.9794, grad=13.2132]Training epoch 35:  94%|█████████▍| 154/163 [03:03<00:09,  1.08s/it, loss=0.1831, batch_acc=0.9688, running_acc=0.9794, grad=13.2132]Training epoch 35:  94%|█████████▍| 154/163 [03:03<00:09,  1.08s/it, loss=0.1637, batch_acc=1.0000, running_acc=0.9795, grad=15.4947]Training epoch 35:  95%|█████████▌| 155/163 [03:04<00:08,  1.02s/it, loss=0.1637, batch_acc=1.0000, running_acc=0.9795, grad=15.4947]Training epoch 35:  95%|█████████▌| 155/163 [03:04<00:08,  1.02s/it, loss=0.1476, batch_acc=0.9688, running_acc=0.9794, grad=11.6508]Training epoch 35:  96%|█████████▌| 156/163 [03:05<00:08,  1.19s/it, loss=0.1476, batch_acc=0.9688, running_acc=0.9794, grad=11.6508]Training epoch 35:  96%|█████████▌| 156/163 [03:05<00:08,  1.19s/it, loss=0.1948, batch_acc=0.9688, running_acc=0.9794, grad=13.4496]Training epoch 35:  96%|█████████▋| 157/163 [03:06<00:06,  1.10s/it, loss=0.1948, batch_acc=0.9688, running_acc=0.9794, grad=13.4496]Training epoch 35:  96%|█████████▋| 157/163 [03:06<00:06,  1.10s/it, loss=0.1955, batch_acc=0.9688, running_acc=0.9793, grad=18.5981]Training epoch 35:  97%|█████████▋| 158/163 [03:07<00:05,  1.03s/it, loss=0.1955, batch_acc=0.9688, running_acc=0.9793, grad=18.5981]Training epoch 35:  97%|█████████▋| 158/163 [03:07<00:05,  1.03s/it, loss=0.1289, batch_acc=0.9688, running_acc=0.9792, grad=7.5252] Training epoch 35:  98%|█████████▊| 159/163 [03:08<00:03,  1.02it/s, loss=0.1289, batch_acc=0.9688, running_acc=0.9792, grad=7.5252]Training epoch 35:  98%|█████████▊| 159/163 [03:08<00:03,  1.02it/s, loss=0.1357, batch_acc=0.9688, running_acc=0.9792, grad=11.2403]Training epoch 35:  98%|█████████▊| 160/163 [03:10<00:04,  1.34s/it, loss=0.1357, batch_acc=0.9688, running_acc=0.9792, grad=11.2403]Training epoch 35:  98%|█████████▊| 160/163 [03:10<00:04,  1.34s/it, loss=0.1213, batch_acc=1.0000, running_acc=0.9793, grad=10.1840]Training epoch 35:  99%|█████████▉| 161/163 [03:11<00:02,  1.20s/it, loss=0.1213, batch_acc=1.0000, running_acc=0.9793, grad=10.1840]Training epoch 35:  99%|█████████▉| 161/163 [03:11<00:02,  1.20s/it, loss=0.1877, batch_acc=0.9688, running_acc=0.9792, grad=14.4120]Training epoch 35:  99%|█████████▉| 162/163 [03:12<00:01,  1.10s/it, loss=0.1877, batch_acc=0.9688, running_acc=0.9792, grad=14.4120]Training epoch 35:  99%|█████████▉| 162/163 [03:12<00:01,  1.10s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9794, grad=10.6508]Training epoch 35: 100%|██████████| 163/163 [03:12<00:00,  1.04it/s, loss=0.1356, batch_acc=1.0000, running_acc=0.9794, grad=10.6508]Training epoch 35: 100%|██████████| 163/163 [03:12<00:00,  1.04it/s, loss=0.1518, batch_acc=0.9524, running_acc=0.9793, grad=11.2146]Training epoch 35: 100%|██████████| 163/163 [03:12<00:00,  1.18s/it, loss=0.1518, batch_acc=0.9524, running_acc=0.9793, grad=11.2146]
Evaluation epoch 35:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 35:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it]Evaluation epoch 35:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it, loss=0.3888, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 35:   7%|▋         | 2/28 [00:05<00:57,  2.23s/it, loss=0.3888, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 35:   7%|▋         | 2/28 [00:05<00:57,  2.23s/it, loss=0.2334, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 35:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.2334, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 35:  11%|█         | 3/28 [00:05<00:33,  1.33s/it, loss=0.3727, batch_acc=0.9375, running_acc=0.9479]Evaluation epoch 35:  14%|█▍        | 4/28 [00:09<01:00,  2.52s/it, loss=0.3727, batch_acc=0.9375, running_acc=0.9479]Evaluation epoch 35:  14%|█▍        | 4/28 [00:09<01:00,  2.52s/it, loss=0.4691, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 35:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=0.4691, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 35:  18%|█▊        | 5/28 [00:10<00:39,  1.70s/it, loss=1.4194, batch_acc=0.6875, running_acc=0.8875]Evaluation epoch 35:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=1.4194, batch_acc=0.6875, running_acc=0.8875]Evaluation epoch 35:  21%|██▏       | 6/28 [00:10<00:26,  1.21s/it, loss=0.5295, batch_acc=0.9062, running_acc=0.8906]Evaluation epoch 35:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.5295, batch_acc=0.9062, running_acc=0.8906]Evaluation epoch 35:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.7303, batch_acc=0.8750, running_acc=0.8884]Evaluation epoch 35:  29%|██▊       | 8/28 [00:14<00:34,  1.70s/it, loss=0.7303, batch_acc=0.8750, running_acc=0.8884]Evaluation epoch 35:  29%|██▊       | 8/28 [00:14<00:34,  1.70s/it, loss=0.4663, batch_acc=0.8438, running_acc=0.8828]Evaluation epoch 35:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=0.4663, batch_acc=0.8438, running_acc=0.8828]Evaluation epoch 35:  32%|███▏      | 9/28 [00:14<00:24,  1.28s/it, loss=0.4407, batch_acc=0.9062, running_acc=0.8854]Evaluation epoch 35:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.4407, batch_acc=0.9062, running_acc=0.8854]Evaluation epoch 35:  36%|███▌      | 10/28 [00:14<00:17,  1.03it/s, loss=0.4407, batch_acc=0.9375, running_acc=0.8906]Evaluation epoch 35:  39%|███▉      | 11/28 [00:14<00:12,  1.33it/s, loss=0.4407, batch_acc=0.9375, running_acc=0.8906]Evaluation epoch 35:  39%|███▉      | 11/28 [00:14<00:12,  1.33it/s, loss=0.3641, batch_acc=0.9375, running_acc=0.8949]Evaluation epoch 35:  43%|████▎     | 12/28 [00:20<00:36,  2.30s/it, loss=0.3641, batch_acc=0.9375, running_acc=0.8949]Evaluation epoch 35:  43%|████▎     | 12/28 [00:20<00:36,  2.30s/it, loss=0.8837, batch_acc=0.8125, running_acc=0.8880]Evaluation epoch 35:  46%|████▋     | 13/28 [00:21<00:25,  1.68s/it, loss=0.8837, batch_acc=0.8125, running_acc=0.8880]Evaluation epoch 35:  46%|████▋     | 13/28 [00:21<00:25,  1.68s/it, loss=0.2878, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 35:  50%|█████     | 14/28 [00:21<00:17,  1.25s/it, loss=0.2878, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 35:  50%|█████     | 14/28 [00:21<00:17,  1.25s/it, loss=0.9522, batch_acc=0.7500, running_acc=0.8817]Evaluation epoch 35:  54%|█████▎    | 15/28 [00:21<00:12,  1.05it/s, loss=0.9522, batch_acc=0.7500, running_acc=0.8817]Evaluation epoch 35:  54%|█████▎    | 15/28 [00:21<00:12,  1.05it/s, loss=1.0237, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 35:  57%|█████▋    | 16/28 [00:24<00:18,  1.55s/it, loss=1.0237, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 35:  57%|█████▋    | 16/28 [00:24<00:18,  1.55s/it, loss=0.7191, batch_acc=0.7812, running_acc=0.8691]Evaluation epoch 35:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=0.7191, batch_acc=0.7812, running_acc=0.8691]Evaluation epoch 35:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=0.5876, batch_acc=0.7500, running_acc=0.8621]Evaluation epoch 35:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=0.5876, batch_acc=0.7500, running_acc=0.8621]Evaluation epoch 35:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=0.6289, batch_acc=0.8438, running_acc=0.8611]Evaluation epoch 35:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=0.6289, batch_acc=0.8438, running_acc=0.8611]Evaluation epoch 35:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=0.9231, batch_acc=0.6250, running_acc=0.8487]Evaluation epoch 35:  71%|███████▏  | 20/28 [00:28<00:10,  1.36s/it, loss=0.9231, batch_acc=0.6250, running_acc=0.8487]Evaluation epoch 35:  71%|███████▏  | 20/28 [00:28<00:10,  1.36s/it, loss=0.5792, batch_acc=0.7188, running_acc=0.8422]Evaluation epoch 35:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5792, batch_acc=0.7188, running_acc=0.8422]Evaluation epoch 35:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5916, batch_acc=0.8438, running_acc=0.8423]Evaluation epoch 35:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5916, batch_acc=0.8438, running_acc=0.8423]Evaluation epoch 35:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5135, batch_acc=0.9375, running_acc=0.8466]Evaluation epoch 35:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.5135, batch_acc=0.9375, running_acc=0.8466]Evaluation epoch 35:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.8865, batch_acc=0.7500, running_acc=0.8424]Evaluation epoch 35:  86%|████████▌ | 24/28 [00:34<00:08,  2.05s/it, loss=0.8865, batch_acc=0.7500, running_acc=0.8424]Evaluation epoch 35:  86%|████████▌ | 24/28 [00:34<00:08,  2.05s/it, loss=0.3768, batch_acc=0.9375, running_acc=0.8464]Evaluation epoch 35:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.3768, batch_acc=0.9375, running_acc=0.8464]Evaluation epoch 35:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.1607, batch_acc=1.0000, running_acc=0.8525]Evaluation epoch 35:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.1607, batch_acc=1.0000, running_acc=0.8525]Evaluation epoch 35:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.8327, batch_acc=0.7500, running_acc=0.8486]Evaluation epoch 35:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.8327, batch_acc=0.7500, running_acc=0.8486]Evaluation epoch 35:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.8043, batch_acc=0.7812, running_acc=0.8461]Evaluation epoch 35: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.3796, batch_acc=0.6667, running_acc=0.8454]Evaluation epoch 35: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.3796, batch_acc=0.6667, running_acc=0.8454]
Training epoch 36:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 36:   1%|          | 1/163 [00:05<15:43,  5.82s/it]Training epoch 36:   1%|          | 1/163 [00:05<15:43,  5.82s/it, loss=0.0890, batch_acc=1.0000, running_acc=1.0000, grad=7.2855]Training epoch 36:   1%|          | 2/163 [00:06<07:49,  2.91s/it, loss=0.0890, batch_acc=1.0000, running_acc=1.0000, grad=7.2855]Training epoch 36:   1%|          | 2/163 [00:06<07:49,  2.91s/it, loss=0.1402, batch_acc=1.0000, running_acc=1.0000, grad=12.3198]Training epoch 36:   2%|▏         | 3/163 [00:07<05:17,  1.99s/it, loss=0.1402, batch_acc=1.0000, running_acc=1.0000, grad=12.3198]Training epoch 36:   2%|▏         | 3/163 [00:07<05:17,  1.99s/it, loss=0.1930, batch_acc=1.0000, running_acc=1.0000, grad=15.6873]Training epoch 36:   2%|▏         | 4/163 [00:10<05:56,  2.24s/it, loss=0.1930, batch_acc=1.0000, running_acc=1.0000, grad=15.6873]Training epoch 36:   2%|▏         | 4/163 [00:10<05:56,  2.24s/it, loss=0.1905, batch_acc=0.9688, running_acc=0.9922, grad=15.8501]Training epoch 36:   3%|▎         | 5/163 [00:11<04:36,  1.75s/it, loss=0.1905, batch_acc=0.9688, running_acc=0.9922, grad=15.8501]Training epoch 36:   3%|▎         | 5/163 [00:11<04:36,  1.75s/it, loss=0.1640, batch_acc=0.9375, running_acc=0.9812, grad=12.8206]Training epoch 36:   4%|▎         | 6/163 [00:11<03:48,  1.46s/it, loss=0.1640, batch_acc=0.9375, running_acc=0.9812, grad=12.8206]Training epoch 36:   4%|▎         | 6/163 [00:11<03:48,  1.46s/it, loss=0.1348, batch_acc=0.9688, running_acc=0.9792, grad=10.2895]Training epoch 36:   4%|▍         | 7/163 [00:12<03:17,  1.27s/it, loss=0.1348, batch_acc=0.9688, running_acc=0.9792, grad=10.2895]Training epoch 36:   4%|▍         | 7/163 [00:12<03:17,  1.27s/it, loss=0.1737, batch_acc=0.9688, running_acc=0.9777, grad=12.0036]Training epoch 36:   5%|▍         | 8/163 [00:15<04:18,  1.67s/it, loss=0.1737, batch_acc=0.9688, running_acc=0.9777, grad=12.0036]Training epoch 36:   5%|▍         | 8/163 [00:15<04:18,  1.67s/it, loss=0.1335, batch_acc=1.0000, running_acc=0.9805, grad=8.9210] Training epoch 36:   6%|▌         | 9/163 [00:16<03:38,  1.42s/it, loss=0.1335, batch_acc=1.0000, running_acc=0.9805, grad=8.9210]Training epoch 36:   6%|▌         | 9/163 [00:16<03:38,  1.42s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9826, grad=5.3596]Training epoch 36:   6%|▌         | 10/163 [00:17<03:11,  1.25s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9826, grad=5.3596]Training epoch 36:   6%|▌         | 10/163 [00:17<03:11,  1.25s/it, loss=0.1473, batch_acc=1.0000, running_acc=0.9844, grad=17.7170]Training epoch 36:   7%|▋         | 11/163 [00:18<02:53,  1.14s/it, loss=0.1473, batch_acc=1.0000, running_acc=0.9844, grad=17.7170]Training epoch 36:   7%|▋         | 11/163 [00:18<02:53,  1.14s/it, loss=0.1404, batch_acc=1.0000, running_acc=0.9858, grad=14.4469]Training epoch 36:   7%|▋         | 12/163 [00:19<03:19,  1.32s/it, loss=0.1404, batch_acc=1.0000, running_acc=0.9858, grad=14.4469]Training epoch 36:   7%|▋         | 12/163 [00:19<03:19,  1.32s/it, loss=0.1287, batch_acc=1.0000, running_acc=0.9870, grad=9.1417] Training epoch 36:   8%|▊         | 13/163 [00:20<02:58,  1.19s/it, loss=0.1287, batch_acc=1.0000, running_acc=0.9870, grad=9.1417]Training epoch 36:   8%|▊         | 13/163 [00:20<02:58,  1.19s/it, loss=0.1106, batch_acc=1.0000, running_acc=0.9880, grad=6.9704]Training epoch 36:   9%|▊         | 14/163 [00:21<02:42,  1.09s/it, loss=0.1106, batch_acc=1.0000, running_acc=0.9880, grad=6.9704]Training epoch 36:   9%|▊         | 14/163 [00:21<02:42,  1.09s/it, loss=0.0747, batch_acc=1.0000, running_acc=0.9888, grad=6.5867]Training epoch 36:   9%|▉         | 15/163 [00:22<02:32,  1.03s/it, loss=0.0747, batch_acc=1.0000, running_acc=0.9888, grad=6.5867]Training epoch 36:   9%|▉         | 15/163 [00:22<02:32,  1.03s/it, loss=0.1458, batch_acc=0.9688, running_acc=0.9875, grad=12.5222]Training epoch 36:  10%|▉         | 16/163 [00:23<02:54,  1.19s/it, loss=0.1458, batch_acc=0.9688, running_acc=0.9875, grad=12.5222]Training epoch 36:  10%|▉         | 16/163 [00:23<02:54,  1.19s/it, loss=0.1676, batch_acc=1.0000, running_acc=0.9883, grad=13.2633]Training epoch 36:  10%|█         | 17/163 [00:24<02:39,  1.09s/it, loss=0.1676, batch_acc=1.0000, running_acc=0.9883, grad=13.2633]Training epoch 36:  10%|█         | 17/163 [00:24<02:39,  1.09s/it, loss=0.1950, batch_acc=1.0000, running_acc=0.9890, grad=19.6543]Training epoch 36:  11%|█         | 18/163 [00:25<02:28,  1.03s/it, loss=0.1950, batch_acc=1.0000, running_acc=0.9890, grad=19.6543]Training epoch 36:  11%|█         | 18/163 [00:25<02:28,  1.03s/it, loss=0.1713, batch_acc=0.9688, running_acc=0.9878, grad=12.1297]Training epoch 36:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.1713, batch_acc=0.9688, running_acc=0.9878, grad=12.1297]Training epoch 36:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.1313, batch_acc=1.0000, running_acc=0.9885, grad=9.5817] Training epoch 36:  12%|█▏        | 20/163 [00:27<02:31,  1.06s/it, loss=0.1313, batch_acc=1.0000, running_acc=0.9885, grad=9.5817]Training epoch 36:  12%|█▏        | 20/163 [00:27<02:31,  1.06s/it, loss=0.1206, batch_acc=1.0000, running_acc=0.9891, grad=8.4674]Training epoch 36:  13%|█▎        | 21/163 [00:28<02:22,  1.01s/it, loss=0.1206, batch_acc=1.0000, running_acc=0.9891, grad=8.4674]Training epoch 36:  13%|█▎        | 21/163 [00:28<02:22,  1.01s/it, loss=0.1644, batch_acc=1.0000, running_acc=0.9896, grad=12.4183]Training epoch 36:  13%|█▎        | 22/163 [00:29<02:16,  1.03it/s, loss=0.1644, batch_acc=1.0000, running_acc=0.9896, grad=12.4183]Training epoch 36:  13%|█▎        | 22/163 [00:29<02:16,  1.03it/s, loss=0.1726, batch_acc=0.9688, running_acc=0.9886, grad=19.8464]Training epoch 36:  14%|█▍        | 23/163 [00:30<02:11,  1.06it/s, loss=0.1726, batch_acc=0.9688, running_acc=0.9886, grad=19.8464]Training epoch 36:  14%|█▍        | 23/163 [00:30<02:11,  1.06it/s, loss=0.1546, batch_acc=0.9688, running_acc=0.9878, grad=9.2644] Training epoch 36:  15%|█▍        | 24/163 [00:32<02:48,  1.21s/it, loss=0.1546, batch_acc=0.9688, running_acc=0.9878, grad=9.2644]Training epoch 36:  15%|█▍        | 24/163 [00:32<02:48,  1.21s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9870, grad=12.8708]Training epoch 36:  15%|█▌        | 25/163 [00:33<02:33,  1.11s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9870, grad=12.8708]Training epoch 36:  15%|█▌        | 25/163 [00:33<02:33,  1.11s/it, loss=0.1912, batch_acc=0.9688, running_acc=0.9862, grad=13.1034]Training epoch 36:  16%|█▌        | 26/163 [00:34<02:22,  1.04s/it, loss=0.1912, batch_acc=0.9688, running_acc=0.9862, grad=13.1034]Training epoch 36:  16%|█▌        | 26/163 [00:34<02:22,  1.04s/it, loss=0.1746, batch_acc=1.0000, running_acc=0.9868, grad=11.7038]Training epoch 36:  17%|█▋        | 27/163 [00:34<02:15,  1.01it/s, loss=0.1746, batch_acc=1.0000, running_acc=0.9868, grad=11.7038]Training epoch 36:  17%|█▋        | 27/163 [00:34<02:15,  1.01it/s, loss=0.1841, batch_acc=0.9688, running_acc=0.9861, grad=11.4279]Training epoch 36:  17%|█▋        | 28/163 [00:36<02:45,  1.23s/it, loss=0.1841, batch_acc=0.9688, running_acc=0.9861, grad=11.4279]Training epoch 36:  17%|█▋        | 28/163 [00:36<02:45,  1.23s/it, loss=0.1079, batch_acc=0.9688, running_acc=0.9855, grad=8.0775] Training epoch 36:  18%|█▊        | 29/163 [00:37<02:30,  1.12s/it, loss=0.1079, batch_acc=0.9688, running_acc=0.9855, grad=8.0775]Training epoch 36:  18%|█▊        | 29/163 [00:37<02:30,  1.12s/it, loss=0.1609, batch_acc=0.9688, running_acc=0.9849, grad=14.4744]Training epoch 36:  18%|█▊        | 30/163 [00:38<02:19,  1.05s/it, loss=0.1609, batch_acc=0.9688, running_acc=0.9849, grad=14.4744]Training epoch 36:  18%|█▊        | 30/163 [00:38<02:19,  1.05s/it, loss=0.1584, batch_acc=0.9375, running_acc=0.9833, grad=13.6411]Training epoch 36:  19%|█▉        | 31/163 [00:39<02:11,  1.00it/s, loss=0.1584, batch_acc=0.9375, running_acc=0.9833, grad=13.6411]Training epoch 36:  19%|█▉        | 31/163 [00:39<02:11,  1.00it/s, loss=0.0850, batch_acc=1.0000, running_acc=0.9839, grad=7.6426] Training epoch 36:  20%|█▉        | 32/163 [00:41<02:43,  1.24s/it, loss=0.0850, batch_acc=1.0000, running_acc=0.9839, grad=7.6426]Training epoch 36:  20%|█▉        | 32/163 [00:41<02:43,  1.24s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9844, grad=8.8671]Training epoch 36:  20%|██        | 33/163 [00:42<02:27,  1.14s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9844, grad=8.8671]Training epoch 36:  20%|██        | 33/163 [00:42<02:27,  1.14s/it, loss=0.1448, batch_acc=0.9688, running_acc=0.9839, grad=9.9100]Training epoch 36:  21%|██        | 34/163 [00:42<02:16,  1.06s/it, loss=0.1448, batch_acc=0.9688, running_acc=0.9839, grad=9.9100]Training epoch 36:  21%|██        | 34/163 [00:42<02:16,  1.06s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9844, grad=7.5043]Training epoch 36:  21%|██▏       | 35/163 [00:43<02:08,  1.01s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9844, grad=7.5043]Training epoch 36:  21%|██▏       | 35/163 [00:43<02:08,  1.01s/it, loss=0.1046, batch_acc=1.0000, running_acc=0.9848, grad=11.2084]Training epoch 36:  22%|██▏       | 36/163 [00:45<02:38,  1.25s/it, loss=0.1046, batch_acc=1.0000, running_acc=0.9848, grad=11.2084]Training epoch 36:  22%|██▏       | 36/163 [00:45<02:38,  1.25s/it, loss=0.1258, batch_acc=0.9688, running_acc=0.9844, grad=8.4213] Training epoch 36:  23%|██▎       | 37/163 [00:46<02:23,  1.14s/it, loss=0.1258, batch_acc=0.9688, running_acc=0.9844, grad=8.4213]Training epoch 36:  23%|██▎       | 37/163 [00:46<02:23,  1.14s/it, loss=0.1795, batch_acc=0.9688, running_acc=0.9840, grad=12.7892]Training epoch 36:  23%|██▎       | 38/163 [00:47<02:12,  1.06s/it, loss=0.1795, batch_acc=0.9688, running_acc=0.9840, grad=12.7892]Training epoch 36:  23%|██▎       | 38/163 [00:47<02:12,  1.06s/it, loss=0.1266, batch_acc=1.0000, running_acc=0.9844, grad=12.8698]Training epoch 36:  24%|██▍       | 39/163 [00:48<02:04,  1.00s/it, loss=0.1266, batch_acc=1.0000, running_acc=0.9844, grad=12.8698]Training epoch 36:  24%|██▍       | 39/163 [00:48<02:04,  1.00s/it, loss=0.1822, batch_acc=1.0000, running_acc=0.9848, grad=11.5752]Training epoch 36:  25%|██▍       | 40/163 [00:50<02:34,  1.25s/it, loss=0.1822, batch_acc=1.0000, running_acc=0.9848, grad=11.5752]Training epoch 36:  25%|██▍       | 40/163 [00:50<02:34,  1.25s/it, loss=0.1602, batch_acc=0.9688, running_acc=0.9844, grad=10.5846]Training epoch 36:  25%|██▌       | 41/163 [00:50<02:19,  1.14s/it, loss=0.1602, batch_acc=0.9688, running_acc=0.9844, grad=10.5846]Training epoch 36:  25%|██▌       | 41/163 [00:50<02:19,  1.14s/it, loss=0.1218, batch_acc=1.0000, running_acc=0.9848, grad=11.2664]Training epoch 36:  26%|██▌       | 42/163 [00:51<02:08,  1.06s/it, loss=0.1218, batch_acc=1.0000, running_acc=0.9848, grad=11.2664]Training epoch 36:  26%|██▌       | 42/163 [00:51<02:08,  1.06s/it, loss=0.1405, batch_acc=1.0000, running_acc=0.9851, grad=10.0395]Training epoch 36:  26%|██▋       | 43/163 [00:52<02:00,  1.01s/it, loss=0.1405, batch_acc=1.0000, running_acc=0.9851, grad=10.0395]Training epoch 36:  26%|██▋       | 43/163 [00:52<02:00,  1.01s/it, loss=0.1477, batch_acc=0.9688, running_acc=0.9847, grad=10.7054]Training epoch 36:  27%|██▋       | 44/163 [00:54<02:27,  1.24s/it, loss=0.1477, batch_acc=0.9688, running_acc=0.9847, grad=10.7054]Training epoch 36:  27%|██▋       | 44/163 [00:54<02:27,  1.24s/it, loss=0.1618, batch_acc=0.9688, running_acc=0.9844, grad=15.8332]Training epoch 36:  28%|██▊       | 45/163 [00:55<02:13,  1.13s/it, loss=0.1618, batch_acc=0.9688, running_acc=0.9844, grad=15.8332]Training epoch 36:  28%|██▊       | 45/163 [00:55<02:13,  1.13s/it, loss=0.1645, batch_acc=0.9688, running_acc=0.9840, grad=13.3586]Training epoch 36:  28%|██▊       | 46/163 [00:56<02:03,  1.06s/it, loss=0.1645, batch_acc=0.9688, running_acc=0.9840, grad=13.3586]Training epoch 36:  28%|██▊       | 46/163 [00:56<02:03,  1.06s/it, loss=0.0926, batch_acc=1.0000, running_acc=0.9844, grad=8.2091] Training epoch 36:  29%|██▉       | 47/163 [00:57<01:56,  1.00s/it, loss=0.0926, batch_acc=1.0000, running_acc=0.9844, grad=8.2091]Training epoch 36:  29%|██▉       | 47/163 [00:57<01:56,  1.00s/it, loss=0.1708, batch_acc=1.0000, running_acc=0.9847, grad=11.5021]Training epoch 36:  29%|██▉       | 48/163 [00:59<02:38,  1.38s/it, loss=0.1708, batch_acc=1.0000, running_acc=0.9847, grad=11.5021]Training epoch 36:  29%|██▉       | 48/163 [00:59<02:38,  1.38s/it, loss=0.1291, batch_acc=0.9688, running_acc=0.9844, grad=12.3775]Training epoch 36:  30%|███       | 49/163 [01:00<02:19,  1.23s/it, loss=0.1291, batch_acc=0.9688, running_acc=0.9844, grad=12.3775]Training epoch 36:  30%|███       | 49/163 [01:00<02:19,  1.23s/it, loss=0.1193, batch_acc=1.0000, running_acc=0.9847, grad=9.9409] Training epoch 36:  31%|███       | 50/163 [01:01<02:06,  1.12s/it, loss=0.1193, batch_acc=1.0000, running_acc=0.9847, grad=9.9409]Training epoch 36:  31%|███       | 50/163 [01:01<02:06,  1.12s/it, loss=0.1422, batch_acc=0.9688, running_acc=0.9844, grad=11.3941]Training epoch 36:  31%|███▏      | 51/163 [01:02<01:57,  1.05s/it, loss=0.1422, batch_acc=0.9688, running_acc=0.9844, grad=11.3941]Training epoch 36:  31%|███▏      | 51/163 [01:02<01:57,  1.05s/it, loss=0.1357, batch_acc=1.0000, running_acc=0.9847, grad=10.4426]Training epoch 36:  32%|███▏      | 52/163 [01:04<02:31,  1.36s/it, loss=0.1357, batch_acc=1.0000, running_acc=0.9847, grad=10.4426]Training epoch 36:  32%|███▏      | 52/163 [01:04<02:31,  1.36s/it, loss=0.1702, batch_acc=0.9375, running_acc=0.9838, grad=13.7114]Training epoch 36:  33%|███▎      | 53/163 [01:05<02:13,  1.22s/it, loss=0.1702, batch_acc=0.9375, running_acc=0.9838, grad=13.7114]Training epoch 36:  33%|███▎      | 53/163 [01:05<02:13,  1.22s/it, loss=0.1294, batch_acc=1.0000, running_acc=0.9841, grad=14.5726]Training epoch 36:  33%|███▎      | 54/163 [01:05<02:01,  1.12s/it, loss=0.1294, batch_acc=1.0000, running_acc=0.9841, grad=14.5726]Training epoch 36:  33%|███▎      | 54/163 [01:05<02:01,  1.12s/it, loss=0.1759, batch_acc=1.0000, running_acc=0.9844, grad=17.1551]Training epoch 36:  34%|███▎      | 55/163 [01:06<01:52,  1.05s/it, loss=0.1759, batch_acc=1.0000, running_acc=0.9844, grad=17.1551]Training epoch 36:  34%|███▎      | 55/163 [01:06<01:52,  1.05s/it, loss=0.1812, batch_acc=0.9688, running_acc=0.9841, grad=17.2307]Training epoch 36:  34%|███▍      | 56/163 [01:08<02:27,  1.38s/it, loss=0.1812, batch_acc=0.9688, running_acc=0.9841, grad=17.2307]Training epoch 36:  34%|███▍      | 56/163 [01:08<02:27,  1.38s/it, loss=0.1791, batch_acc=1.0000, running_acc=0.9844, grad=18.5384]Training epoch 36:  35%|███▍      | 57/163 [01:09<02:10,  1.23s/it, loss=0.1791, batch_acc=1.0000, running_acc=0.9844, grad=18.5384]Training epoch 36:  35%|███▍      | 57/163 [01:09<02:10,  1.23s/it, loss=0.1750, batch_acc=0.9688, running_acc=0.9841, grad=21.0245]Training epoch 36:  36%|███▌      | 58/163 [01:10<01:57,  1.12s/it, loss=0.1750, batch_acc=0.9688, running_acc=0.9841, grad=21.0245]Training epoch 36:  36%|███▌      | 58/163 [01:10<01:57,  1.12s/it, loss=0.1266, batch_acc=1.0000, running_acc=0.9844, grad=9.6846] Training epoch 36:  36%|███▌      | 59/163 [01:11<01:49,  1.05s/it, loss=0.1266, batch_acc=1.0000, running_acc=0.9844, grad=9.6846]Training epoch 36:  36%|███▌      | 59/163 [01:11<01:49,  1.05s/it, loss=0.1506, batch_acc=0.9688, running_acc=0.9841, grad=9.7242]Training epoch 36:  37%|███▋      | 60/163 [01:13<02:24,  1.40s/it, loss=0.1506, batch_acc=0.9688, running_acc=0.9841, grad=9.7242]Training epoch 36:  37%|███▋      | 60/163 [01:13<02:24,  1.40s/it, loss=0.2109, batch_acc=0.9375, running_acc=0.9833, grad=17.2967]Training epoch 36:  37%|███▋      | 61/163 [01:14<02:06,  1.24s/it, loss=0.2109, batch_acc=0.9375, running_acc=0.9833, grad=17.2967]Training epoch 36:  37%|███▋      | 61/163 [01:14<02:06,  1.24s/it, loss=0.1462, batch_acc=0.9688, running_acc=0.9831, grad=12.1751]Training epoch 36:  38%|███▊      | 62/163 [01:15<01:54,  1.13s/it, loss=0.1462, batch_acc=0.9688, running_acc=0.9831, grad=12.1751]Training epoch 36:  38%|███▊      | 62/163 [01:15<01:54,  1.13s/it, loss=0.1744, batch_acc=1.0000, running_acc=0.9834, grad=24.2343]Training epoch 36:  39%|███▊      | 63/163 [01:16<01:45,  1.06s/it, loss=0.1744, batch_acc=1.0000, running_acc=0.9834, grad=24.2343]Training epoch 36:  39%|███▊      | 63/163 [01:16<01:45,  1.06s/it, loss=0.0911, batch_acc=1.0000, running_acc=0.9836, grad=8.7175] Training epoch 36:  39%|███▉      | 64/163 [01:18<02:05,  1.26s/it, loss=0.0911, batch_acc=1.0000, running_acc=0.9836, grad=8.7175]Training epoch 36:  39%|███▉      | 64/163 [01:18<02:05,  1.26s/it, loss=0.1421, batch_acc=0.9688, running_acc=0.9834, grad=13.1412]Training epoch 36:  40%|███▉      | 65/163 [01:19<01:52,  1.15s/it, loss=0.1421, batch_acc=0.9688, running_acc=0.9834, grad=13.1412]Training epoch 36:  40%|███▉      | 65/163 [01:19<01:52,  1.15s/it, loss=0.1428, batch_acc=1.0000, running_acc=0.9837, grad=12.3565]Training epoch 36:  40%|████      | 66/163 [01:19<01:43,  1.07s/it, loss=0.1428, batch_acc=1.0000, running_acc=0.9837, grad=12.3565]Training epoch 36:  40%|████      | 66/163 [01:19<01:43,  1.07s/it, loss=0.1269, batch_acc=0.9688, running_acc=0.9834, grad=12.9433]Training epoch 36:  41%|████      | 67/163 [01:20<01:37,  1.01s/it, loss=0.1269, batch_acc=0.9688, running_acc=0.9834, grad=12.9433]Training epoch 36:  41%|████      | 67/163 [01:20<01:37,  1.01s/it, loss=0.1563, batch_acc=1.0000, running_acc=0.9837, grad=7.5475] Training epoch 36:  42%|████▏     | 68/163 [01:22<01:49,  1.16s/it, loss=0.1563, batch_acc=1.0000, running_acc=0.9837, grad=7.5475]Training epoch 36:  42%|████▏     | 68/163 [01:22<01:49,  1.16s/it, loss=0.1317, batch_acc=0.9688, running_acc=0.9835, grad=10.1019]Training epoch 36:  42%|████▏     | 69/163 [01:23<01:40,  1.07s/it, loss=0.1317, batch_acc=0.9688, running_acc=0.9835, grad=10.1019]Training epoch 36:  42%|████▏     | 69/163 [01:23<01:40,  1.07s/it, loss=0.1584, batch_acc=0.9688, running_acc=0.9832, grad=8.3960] Training epoch 36:  43%|████▎     | 70/163 [01:24<01:34,  1.02s/it, loss=0.1584, batch_acc=0.9688, running_acc=0.9832, grad=8.3960]Training epoch 36:  43%|████▎     | 70/163 [01:24<01:34,  1.02s/it, loss=0.2376, batch_acc=0.8750, running_acc=0.9817, grad=20.0133]Training epoch 36:  44%|████▎     | 71/163 [01:24<01:29,  1.03it/s, loss=0.2376, batch_acc=0.8750, running_acc=0.9817, grad=20.0133]Training epoch 36:  44%|████▎     | 71/163 [01:24<01:29,  1.03it/s, loss=0.2314, batch_acc=0.9688, running_acc=0.9815, grad=25.0883]Training epoch 36:  44%|████▍     | 72/163 [01:26<01:37,  1.07s/it, loss=0.2314, batch_acc=0.9688, running_acc=0.9815, grad=25.0883]Training epoch 36:  44%|████▍     | 72/163 [01:26<01:37,  1.07s/it, loss=0.1707, batch_acc=1.0000, running_acc=0.9818, grad=13.8372]Training epoch 36:  45%|████▍     | 73/163 [01:27<01:31,  1.01s/it, loss=0.1707, batch_acc=1.0000, running_acc=0.9818, grad=13.8372]Training epoch 36:  45%|████▍     | 73/163 [01:27<01:31,  1.01s/it, loss=0.1317, batch_acc=0.9688, running_acc=0.9816, grad=7.0925] Training epoch 36:  45%|████▌     | 74/163 [01:27<01:26,  1.03it/s, loss=0.1317, batch_acc=0.9688, running_acc=0.9816, grad=7.0925]Training epoch 36:  45%|████▌     | 74/163 [01:27<01:26,  1.03it/s, loss=0.1214, batch_acc=1.0000, running_acc=0.9818, grad=9.8463]Training epoch 36:  46%|████▌     | 75/163 [01:28<01:23,  1.06it/s, loss=0.1214, batch_acc=1.0000, running_acc=0.9818, grad=9.8463]Training epoch 36:  46%|████▌     | 75/163 [01:28<01:23,  1.06it/s, loss=0.1724, batch_acc=1.0000, running_acc=0.9821, grad=11.8912]Training epoch 36:  47%|████▋     | 76/163 [01:30<01:48,  1.25s/it, loss=0.1724, batch_acc=1.0000, running_acc=0.9821, grad=11.8912]Training epoch 36:  47%|████▋     | 76/163 [01:30<01:48,  1.25s/it, loss=0.1361, batch_acc=1.0000, running_acc=0.9823, grad=12.8002]Training epoch 36:  47%|████▋     | 77/163 [01:31<01:37,  1.14s/it, loss=0.1361, batch_acc=1.0000, running_acc=0.9823, grad=12.8002]Training epoch 36:  47%|████▋     | 77/163 [01:31<01:37,  1.14s/it, loss=0.1406, batch_acc=1.0000, running_acc=0.9825, grad=13.8628]Training epoch 36:  48%|████▊     | 78/163 [01:32<01:30,  1.06s/it, loss=0.1406, batch_acc=1.0000, running_acc=0.9825, grad=13.8628]Training epoch 36:  48%|████▊     | 78/163 [01:32<01:30,  1.06s/it, loss=0.1160, batch_acc=1.0000, running_acc=0.9828, grad=8.3400] Training epoch 36:  48%|████▊     | 79/163 [01:33<01:24,  1.01s/it, loss=0.1160, batch_acc=1.0000, running_acc=0.9828, grad=8.3400]Training epoch 36:  48%|████▊     | 79/163 [01:33<01:24,  1.01s/it, loss=0.1676, batch_acc=0.9688, running_acc=0.9826, grad=12.1437]Training epoch 36:  49%|████▉     | 80/163 [01:35<01:42,  1.24s/it, loss=0.1676, batch_acc=0.9688, running_acc=0.9826, grad=12.1437]Training epoch 36:  49%|████▉     | 80/163 [01:35<01:42,  1.24s/it, loss=0.1144, batch_acc=1.0000, running_acc=0.9828, grad=8.8974] Training epoch 36:  50%|████▉     | 81/163 [01:36<01:32,  1.13s/it, loss=0.1144, batch_acc=1.0000, running_acc=0.9828, grad=8.8974]Training epoch 36:  50%|████▉     | 81/163 [01:36<01:32,  1.13s/it, loss=0.1342, batch_acc=0.9688, running_acc=0.9826, grad=7.6815]Training epoch 36:  50%|█████     | 82/163 [01:37<01:25,  1.05s/it, loss=0.1342, batch_acc=0.9688, running_acc=0.9826, grad=7.6815]Training epoch 36:  50%|█████     | 82/163 [01:37<01:25,  1.05s/it, loss=0.1459, batch_acc=0.9688, running_acc=0.9825, grad=8.2678]Training epoch 36:  51%|█████     | 83/163 [01:37<01:20,  1.00s/it, loss=0.1459, batch_acc=0.9688, running_acc=0.9825, grad=8.2678]Training epoch 36:  51%|█████     | 83/163 [01:37<01:20,  1.00s/it, loss=0.1972, batch_acc=1.0000, running_acc=0.9827, grad=16.5002]Training epoch 36:  52%|█████▏    | 84/163 [01:39<01:28,  1.12s/it, loss=0.1972, batch_acc=1.0000, running_acc=0.9827, grad=16.5002]Training epoch 36:  52%|█████▏    | 84/163 [01:39<01:28,  1.12s/it, loss=0.1934, batch_acc=1.0000, running_acc=0.9829, grad=15.0463]Training epoch 36:  52%|█████▏    | 85/163 [01:40<01:21,  1.05s/it, loss=0.1934, batch_acc=1.0000, running_acc=0.9829, grad=15.0463]Training epoch 36:  52%|█████▏    | 85/163 [01:40<01:21,  1.05s/it, loss=0.1236, batch_acc=0.9688, running_acc=0.9827, grad=14.0248]Training epoch 36:  53%|█████▎    | 86/163 [01:41<01:16,  1.00it/s, loss=0.1236, batch_acc=0.9688, running_acc=0.9827, grad=14.0248]Training epoch 36:  53%|█████▎    | 86/163 [01:41<01:16,  1.00it/s, loss=0.1135, batch_acc=1.0000, running_acc=0.9829, grad=9.9705] Training epoch 36:  53%|█████▎    | 87/163 [01:41<01:13,  1.04it/s, loss=0.1135, batch_acc=1.0000, running_acc=0.9829, grad=9.9705]Training epoch 36:  53%|█████▎    | 87/163 [01:41<01:13,  1.04it/s, loss=0.1120, batch_acc=1.0000, running_acc=0.9831, grad=8.9668]Training epoch 36:  54%|█████▍    | 88/163 [01:43<01:30,  1.20s/it, loss=0.1120, batch_acc=1.0000, running_acc=0.9831, grad=8.9668]Training epoch 36:  54%|█████▍    | 88/163 [01:43<01:30,  1.20s/it, loss=0.1428, batch_acc=1.0000, running_acc=0.9833, grad=10.8299]Training epoch 36:  55%|█████▍    | 89/163 [01:44<01:21,  1.11s/it, loss=0.1428, batch_acc=1.0000, running_acc=0.9833, grad=10.8299]Training epoch 36:  55%|█████▍    | 89/163 [01:44<01:21,  1.11s/it, loss=0.1478, batch_acc=0.9688, running_acc=0.9831, grad=11.2929]Training epoch 36:  55%|█████▌    | 90/163 [01:45<01:15,  1.04s/it, loss=0.1478, batch_acc=0.9688, running_acc=0.9831, grad=11.2929]Training epoch 36:  55%|█████▌    | 90/163 [01:45<01:15,  1.04s/it, loss=0.2138, batch_acc=0.9688, running_acc=0.9830, grad=14.6303]Training epoch 36:  56%|█████▌    | 91/163 [01:46<01:11,  1.01it/s, loss=0.2138, batch_acc=0.9688, running_acc=0.9830, grad=14.6303]Training epoch 36:  56%|█████▌    | 91/163 [01:46<01:11,  1.01it/s, loss=0.1285, batch_acc=1.0000, running_acc=0.9832, grad=12.1262]Training epoch 36:  56%|█████▋    | 92/163 [01:48<01:28,  1.24s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9832, grad=12.1262]Training epoch 36:  56%|█████▋    | 92/163 [01:48<01:28,  1.24s/it, loss=0.2116, batch_acc=0.9688, running_acc=0.9830, grad=18.8774]Training epoch 36:  57%|█████▋    | 93/163 [01:49<01:19,  1.13s/it, loss=0.2116, batch_acc=0.9688, running_acc=0.9830, grad=18.8774]Training epoch 36:  57%|█████▋    | 93/163 [01:49<01:19,  1.13s/it, loss=0.1271, batch_acc=1.0000, running_acc=0.9832, grad=13.2356]Training epoch 36:  58%|█████▊    | 94/163 [01:49<01:12,  1.06s/it, loss=0.1271, batch_acc=1.0000, running_acc=0.9832, grad=13.2356]Training epoch 36:  58%|█████▊    | 94/163 [01:49<01:12,  1.06s/it, loss=0.1065, batch_acc=1.0000, running_acc=0.9834, grad=13.0003]Training epoch 36:  58%|█████▊    | 95/163 [01:50<01:08,  1.00s/it, loss=0.1065, batch_acc=1.0000, running_acc=0.9834, grad=13.0003]Training epoch 36:  58%|█████▊    | 95/163 [01:50<01:08,  1.00s/it, loss=0.1781, batch_acc=0.9375, running_acc=0.9829, grad=7.6265] Training epoch 36:  59%|█████▉    | 96/163 [01:52<01:26,  1.29s/it, loss=0.1781, batch_acc=0.9375, running_acc=0.9829, grad=7.6265]Training epoch 36:  59%|█████▉    | 96/163 [01:52<01:26,  1.29s/it, loss=0.1974, batch_acc=0.9375, running_acc=0.9824, grad=19.3065]Training epoch 36:  60%|█████▉    | 97/163 [01:53<01:17,  1.17s/it, loss=0.1974, batch_acc=0.9375, running_acc=0.9824, grad=19.3065]Training epoch 36:  60%|█████▉    | 97/163 [01:53<01:17,  1.17s/it, loss=0.1812, batch_acc=0.9375, running_acc=0.9820, grad=10.2941]Training epoch 36:  60%|██████    | 98/163 [01:54<01:10,  1.08s/it, loss=0.1812, batch_acc=0.9375, running_acc=0.9820, grad=10.2941]Training epoch 36:  60%|██████    | 98/163 [01:54<01:10,  1.08s/it, loss=0.1034, batch_acc=1.0000, running_acc=0.9821, grad=7.0544] Training epoch 36:  61%|██████    | 99/163 [01:55<01:05,  1.02s/it, loss=0.1034, batch_acc=1.0000, running_acc=0.9821, grad=7.0544]Training epoch 36:  61%|██████    | 99/163 [01:55<01:05,  1.02s/it, loss=0.1539, batch_acc=1.0000, running_acc=0.9823, grad=14.9476]Training epoch 36:  61%|██████▏   | 100/163 [01:57<01:25,  1.36s/it, loss=0.1539, batch_acc=1.0000, running_acc=0.9823, grad=14.9476]Training epoch 36:  61%|██████▏   | 100/163 [01:57<01:25,  1.36s/it, loss=0.1446, batch_acc=1.0000, running_acc=0.9825, grad=10.7745]Training epoch 36:  62%|██████▏   | 101/163 [01:58<01:15,  1.22s/it, loss=0.1446, batch_acc=1.0000, running_acc=0.9825, grad=10.7745]Training epoch 36:  62%|██████▏   | 101/163 [01:58<01:15,  1.22s/it, loss=0.1321, batch_acc=1.0000, running_acc=0.9827, grad=12.1377]Training epoch 36:  63%|██████▎   | 102/163 [01:59<01:08,  1.11s/it, loss=0.1321, batch_acc=1.0000, running_acc=0.9827, grad=12.1377]Training epoch 36:  63%|██████▎   | 102/163 [01:59<01:08,  1.11s/it, loss=0.1824, batch_acc=0.9688, running_acc=0.9825, grad=18.6075]Training epoch 36:  63%|██████▎   | 103/163 [02:00<01:02,  1.04s/it, loss=0.1824, batch_acc=0.9688, running_acc=0.9825, grad=18.6075]Training epoch 36:  63%|██████▎   | 103/163 [02:00<01:02,  1.04s/it, loss=0.1316, batch_acc=0.9688, running_acc=0.9824, grad=7.5364] Training epoch 36:  64%|██████▍   | 104/163 [02:01<01:13,  1.24s/it, loss=0.1316, batch_acc=0.9688, running_acc=0.9824, grad=7.5364]Training epoch 36:  64%|██████▍   | 104/163 [02:01<01:13,  1.24s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9826, grad=8.5955]Training epoch 36:  64%|██████▍   | 105/163 [02:02<01:05,  1.13s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9826, grad=8.5955]Training epoch 36:  64%|██████▍   | 105/163 [02:02<01:05,  1.13s/it, loss=0.1690, batch_acc=0.9688, running_acc=0.9824, grad=13.3207]Training epoch 36:  65%|██████▌   | 106/163 [02:03<01:00,  1.06s/it, loss=0.1690, batch_acc=0.9688, running_acc=0.9824, grad=13.3207]Training epoch 36:  65%|██████▌   | 106/163 [02:03<01:00,  1.06s/it, loss=0.1280, batch_acc=1.0000, running_acc=0.9826, grad=10.3709]Training epoch 36:  66%|██████▌   | 107/163 [02:04<00:56,  1.01s/it, loss=0.1280, batch_acc=1.0000, running_acc=0.9826, grad=10.3709]Training epoch 36:  66%|██████▌   | 107/163 [02:04<00:56,  1.01s/it, loss=0.1772, batch_acc=1.0000, running_acc=0.9828, grad=13.6635]Training epoch 36:  66%|██████▋   | 108/163 [02:06<01:03,  1.15s/it, loss=0.1772, batch_acc=1.0000, running_acc=0.9828, grad=13.6635]Training epoch 36:  66%|██████▋   | 108/163 [02:06<01:03,  1.15s/it, loss=0.1202, batch_acc=1.0000, running_acc=0.9829, grad=10.4095]Training epoch 36:  67%|██████▋   | 109/163 [02:06<00:57,  1.07s/it, loss=0.1202, batch_acc=1.0000, running_acc=0.9829, grad=10.4095]Training epoch 36:  67%|██████▋   | 109/163 [02:06<00:57,  1.07s/it, loss=0.1749, batch_acc=1.0000, running_acc=0.9831, grad=17.1539]Training epoch 36:  67%|██████▋   | 110/163 [02:07<00:53,  1.01s/it, loss=0.1749, batch_acc=1.0000, running_acc=0.9831, grad=17.1539]Training epoch 36:  67%|██████▋   | 110/163 [02:07<00:53,  1.01s/it, loss=0.1882, batch_acc=1.0000, running_acc=0.9832, grad=15.8003]Training epoch 36:  68%|██████▊   | 111/163 [02:08<00:50,  1.03it/s, loss=0.1882, batch_acc=1.0000, running_acc=0.9832, grad=15.8003]Training epoch 36:  68%|██████▊   | 111/163 [02:08<00:50,  1.03it/s, loss=0.1598, batch_acc=0.9688, running_acc=0.9831, grad=14.3491]Training epoch 36:  69%|██████▊   | 112/163 [02:10<00:59,  1.16s/it, loss=0.1598, batch_acc=0.9688, running_acc=0.9831, grad=14.3491]Training epoch 36:  69%|██████▊   | 112/163 [02:10<00:59,  1.16s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9830, grad=11.5252]Training epoch 36:  69%|██████▉   | 113/163 [02:11<00:53,  1.08s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9830, grad=11.5252]Training epoch 36:  69%|██████▉   | 113/163 [02:11<00:53,  1.08s/it, loss=0.1523, batch_acc=0.9688, running_acc=0.9829, grad=8.5401] Training epoch 36:  70%|██████▉   | 114/163 [02:12<00:49,  1.02s/it, loss=0.1523, batch_acc=0.9688, running_acc=0.9829, grad=8.5401]Training epoch 36:  70%|██████▉   | 114/163 [02:12<00:49,  1.02s/it, loss=0.1684, batch_acc=0.9688, running_acc=0.9827, grad=10.1861]Training epoch 36:  71%|███████   | 115/163 [02:12<00:46,  1.02it/s, loss=0.1684, batch_acc=0.9688, running_acc=0.9827, grad=10.1861]Training epoch 36:  71%|███████   | 115/163 [02:12<00:46,  1.02it/s, loss=0.1270, batch_acc=1.0000, running_acc=0.9829, grad=8.6073] Training epoch 36:  71%|███████   | 116/163 [02:14<00:56,  1.20s/it, loss=0.1270, batch_acc=1.0000, running_acc=0.9829, grad=8.6073]Training epoch 36:  71%|███████   | 116/163 [02:14<00:56,  1.20s/it, loss=0.1717, batch_acc=0.9688, running_acc=0.9828, grad=10.4877]Training epoch 36:  72%|███████▏  | 117/163 [02:15<00:50,  1.10s/it, loss=0.1717, batch_acc=0.9688, running_acc=0.9828, grad=10.4877]Training epoch 36:  72%|███████▏  | 117/163 [02:15<00:50,  1.10s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9826, grad=14.0774]Training epoch 36:  72%|███████▏  | 118/163 [02:16<00:46,  1.04s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9826, grad=14.0774]Training epoch 36:  72%|███████▏  | 118/163 [02:16<00:46,  1.04s/it, loss=0.1863, batch_acc=0.9688, running_acc=0.9825, grad=12.8575]Training epoch 36:  73%|███████▎  | 119/163 [02:17<00:43,  1.01it/s, loss=0.1863, batch_acc=0.9688, running_acc=0.9825, grad=12.8575]Training epoch 36:  73%|███████▎  | 119/163 [02:17<00:43,  1.01it/s, loss=0.1436, batch_acc=0.9688, running_acc=0.9824, grad=11.6875]Training epoch 36:  74%|███████▎  | 120/163 [02:18<00:47,  1.10s/it, loss=0.1436, batch_acc=0.9688, running_acc=0.9824, grad=11.6875]Training epoch 36:  74%|███████▎  | 120/163 [02:18<00:47,  1.10s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9823, grad=6.2893] Training epoch 36:  74%|███████▍  | 121/163 [02:19<00:43,  1.03s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9823, grad=6.2893]Training epoch 36:  74%|███████▍  | 121/163 [02:19<00:43,  1.03s/it, loss=0.2272, batch_acc=0.9062, running_acc=0.9817, grad=14.2830]Training epoch 36:  75%|███████▍  | 122/163 [02:20<00:40,  1.01it/s, loss=0.2272, batch_acc=0.9062, running_acc=0.9817, grad=14.2830]Training epoch 36:  75%|███████▍  | 122/163 [02:20<00:40,  1.01it/s, loss=0.1158, batch_acc=0.9688, running_acc=0.9816, grad=7.1302] Training epoch 36:  75%|███████▌  | 123/163 [02:21<00:38,  1.05it/s, loss=0.1158, batch_acc=0.9688, running_acc=0.9816, grad=7.1302]Training epoch 36:  75%|███████▌  | 123/163 [02:21<00:38,  1.05it/s, loss=0.2144, batch_acc=0.9688, running_acc=0.9815, grad=21.4195]Training epoch 36:  76%|███████▌  | 124/163 [02:22<00:44,  1.13s/it, loss=0.2144, batch_acc=0.9688, running_acc=0.9815, grad=21.4195]Training epoch 36:  76%|███████▌  | 124/163 [02:22<00:44,  1.13s/it, loss=0.1482, batch_acc=1.0000, running_acc=0.9816, grad=12.1466]Training epoch 36:  77%|███████▋  | 125/163 [02:23<00:40,  1.06s/it, loss=0.1482, batch_acc=1.0000, running_acc=0.9816, grad=12.1466]Training epoch 36:  77%|███████▋  | 125/163 [02:23<00:40,  1.06s/it, loss=0.1245, batch_acc=1.0000, running_acc=0.9818, grad=9.3918] Training epoch 36:  77%|███████▋  | 126/163 [02:24<00:37,  1.00s/it, loss=0.1245, batch_acc=1.0000, running_acc=0.9818, grad=9.3918]Training epoch 36:  77%|███████▋  | 126/163 [02:24<00:37,  1.00s/it, loss=0.1520, batch_acc=0.9688, running_acc=0.9816, grad=10.1987]Training epoch 36:  78%|███████▊  | 127/163 [02:25<00:34,  1.04it/s, loss=0.1520, batch_acc=0.9688, running_acc=0.9816, grad=10.1987]Training epoch 36:  78%|███████▊  | 127/163 [02:25<00:34,  1.04it/s, loss=0.2507, batch_acc=0.9062, running_acc=0.9811, grad=17.7862]Training epoch 36:  79%|███████▊  | 128/163 [02:27<00:49,  1.41s/it, loss=0.2507, batch_acc=0.9062, running_acc=0.9811, grad=17.7862]Training epoch 36:  79%|███████▊  | 128/163 [02:27<00:49,  1.41s/it, loss=0.1117, batch_acc=0.9688, running_acc=0.9810, grad=8.3746] Training epoch 36:  79%|███████▉  | 129/163 [02:28<00:42,  1.25s/it, loss=0.1117, batch_acc=0.9688, running_acc=0.9810, grad=8.3746]Training epoch 36:  79%|███████▉  | 129/163 [02:28<00:42,  1.25s/it, loss=0.2101, batch_acc=0.9375, running_acc=0.9806, grad=11.8369]Training epoch 36:  80%|███████▉  | 130/163 [02:29<00:37,  1.14s/it, loss=0.2101, batch_acc=0.9375, running_acc=0.9806, grad=11.8369]Training epoch 36:  80%|███████▉  | 130/163 [02:29<00:37,  1.14s/it, loss=0.1470, batch_acc=0.9688, running_acc=0.9805, grad=13.1811]Training epoch 36:  80%|████████  | 131/163 [02:30<00:33,  1.06s/it, loss=0.1470, batch_acc=0.9688, running_acc=0.9805, grad=13.1811]Training epoch 36:  80%|████████  | 131/163 [02:30<00:33,  1.06s/it, loss=0.1240, batch_acc=1.0000, running_acc=0.9807, grad=8.6430] Training epoch 36:  81%|████████  | 132/163 [02:32<00:40,  1.31s/it, loss=0.1240, batch_acc=1.0000, running_acc=0.9807, grad=8.6430]Training epoch 36:  81%|████████  | 132/163 [02:32<00:40,  1.31s/it, loss=0.1340, batch_acc=1.0000, running_acc=0.9808, grad=18.5997]Training epoch 36:  82%|████████▏ | 133/163 [02:33<00:35,  1.18s/it, loss=0.1340, batch_acc=1.0000, running_acc=0.9808, grad=18.5997]Training epoch 36:  82%|████████▏ | 133/163 [02:33<00:35,  1.18s/it, loss=0.1810, batch_acc=1.0000, running_acc=0.9810, grad=17.1663]Training epoch 36:  82%|████████▏ | 134/163 [02:34<00:31,  1.09s/it, loss=0.1810, batch_acc=1.0000, running_acc=0.9810, grad=17.1663]Training epoch 36:  82%|████████▏ | 134/163 [02:34<00:31,  1.09s/it, loss=0.1751, batch_acc=0.9688, running_acc=0.9809, grad=10.6441]Training epoch 36:  83%|████████▎ | 135/163 [02:35<00:28,  1.03s/it, loss=0.1751, batch_acc=0.9688, running_acc=0.9809, grad=10.6441]Training epoch 36:  83%|████████▎ | 135/163 [02:35<00:28,  1.03s/it, loss=0.1439, batch_acc=0.9688, running_acc=0.9808, grad=13.0279]Training epoch 36:  83%|████████▎ | 136/163 [02:36<00:30,  1.13s/it, loss=0.1439, batch_acc=0.9688, running_acc=0.9808, grad=13.0279]Training epoch 36:  83%|████████▎ | 136/163 [02:36<00:30,  1.13s/it, loss=0.2376, batch_acc=0.9688, running_acc=0.9807, grad=19.2476]Training epoch 36:  84%|████████▍ | 137/163 [02:37<00:27,  1.05s/it, loss=0.2376, batch_acc=0.9688, running_acc=0.9807, grad=19.2476]Training epoch 36:  84%|████████▍ | 137/163 [02:37<00:27,  1.05s/it, loss=0.2372, batch_acc=0.9375, running_acc=0.9804, grad=17.4679]Training epoch 36:  85%|████████▍ | 138/163 [02:38<00:25,  1.00s/it, loss=0.2372, batch_acc=0.9375, running_acc=0.9804, grad=17.4679]Training epoch 36:  85%|████████▍ | 138/163 [02:38<00:25,  1.00s/it, loss=0.1885, batch_acc=0.9375, running_acc=0.9801, grad=17.2114]Training epoch 36:  85%|████████▌ | 139/163 [02:39<00:23,  1.04it/s, loss=0.1885, batch_acc=0.9375, running_acc=0.9801, grad=17.2114]Training epoch 36:  85%|████████▌ | 139/163 [02:39<00:23,  1.04it/s, loss=0.2347, batch_acc=0.9375, running_acc=0.9798, grad=24.9346]Training epoch 36:  86%|████████▌ | 140/163 [02:40<00:26,  1.15s/it, loss=0.2347, batch_acc=0.9375, running_acc=0.9798, grad=24.9346]Training epoch 36:  86%|████████▌ | 140/163 [02:40<00:26,  1.15s/it, loss=0.1928, batch_acc=0.9688, running_acc=0.9797, grad=11.5195]Training epoch 36:  87%|████████▋ | 141/163 [02:41<00:23,  1.07s/it, loss=0.1928, batch_acc=0.9688, running_acc=0.9797, grad=11.5195]Training epoch 36:  87%|████████▋ | 141/163 [02:41<00:23,  1.07s/it, loss=0.1455, batch_acc=1.0000, running_acc=0.9798, grad=9.0789] Training epoch 36:  87%|████████▋ | 142/163 [02:42<00:21,  1.01s/it, loss=0.1455, batch_acc=1.0000, running_acc=0.9798, grad=9.0789]Training epoch 36:  87%|████████▋ | 142/163 [02:42<00:21,  1.01s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9800, grad=6.3871]Training epoch 36:  88%|████████▊ | 143/163 [02:43<00:19,  1.03it/s, loss=0.0845, batch_acc=1.0000, running_acc=0.9800, grad=6.3871]Training epoch 36:  88%|████████▊ | 143/163 [02:43<00:19,  1.03it/s, loss=0.1163, batch_acc=1.0000, running_acc=0.9801, grad=14.5431]Training epoch 36:  88%|████████▊ | 144/163 [02:44<00:19,  1.05s/it, loss=0.1163, batch_acc=1.0000, running_acc=0.9801, grad=14.5431]Training epoch 36:  88%|████████▊ | 144/163 [02:44<00:19,  1.05s/it, loss=0.1088, batch_acc=1.0000, running_acc=0.9803, grad=7.9354] Training epoch 36:  89%|████████▉ | 145/163 [02:45<00:18,  1.02s/it, loss=0.1088, batch_acc=1.0000, running_acc=0.9803, grad=7.9354]Training epoch 36:  89%|████████▉ | 145/163 [02:45<00:18,  1.02s/it, loss=0.1771, batch_acc=0.9688, running_acc=0.9802, grad=12.7552]Training epoch 36:  90%|████████▉ | 146/163 [02:46<00:16,  1.02it/s, loss=0.1771, batch_acc=0.9688, running_acc=0.9802, grad=12.7552]Training epoch 36:  90%|████████▉ | 146/163 [02:46<00:16,  1.02it/s, loss=0.1321, batch_acc=1.0000, running_acc=0.9803, grad=11.1432]Training epoch 36:  90%|█████████ | 147/163 [02:47<00:15,  1.05it/s, loss=0.1321, batch_acc=1.0000, running_acc=0.9803, grad=11.1432]Training epoch 36:  90%|█████████ | 147/163 [02:47<00:15,  1.05it/s, loss=0.1075, batch_acc=1.0000, running_acc=0.9804, grad=10.2723]Training epoch 36:  91%|█████████ | 148/163 [02:48<00:14,  1.00it/s, loss=0.1075, batch_acc=1.0000, running_acc=0.9804, grad=10.2723]Training epoch 36:  91%|█████████ | 148/163 [02:48<00:14,  1.00it/s, loss=0.1614, batch_acc=0.9688, running_acc=0.9804, grad=10.0685]Training epoch 36:  91%|█████████▏| 149/163 [02:49<00:13,  1.04it/s, loss=0.1614, batch_acc=0.9688, running_acc=0.9804, grad=10.0685]Training epoch 36:  91%|█████████▏| 149/163 [02:49<00:13,  1.04it/s, loss=0.1277, batch_acc=1.0000, running_acc=0.9805, grad=12.0413]Training epoch 36:  92%|█████████▏| 150/163 [02:50<00:12,  1.07it/s, loss=0.1277, batch_acc=1.0000, running_acc=0.9805, grad=12.0413]Training epoch 36:  92%|█████████▏| 150/163 [02:50<00:12,  1.07it/s, loss=0.1522, batch_acc=0.9688, running_acc=0.9804, grad=11.3358]Training epoch 36:  93%|█████████▎| 151/163 [02:50<00:11,  1.09it/s, loss=0.1522, batch_acc=0.9688, running_acc=0.9804, grad=11.3358]Training epoch 36:  93%|█████████▎| 151/163 [02:50<00:11,  1.09it/s, loss=0.1295, batch_acc=0.9688, running_acc=0.9803, grad=9.3495] Training epoch 36:  93%|█████████▎| 152/163 [02:53<00:14,  1.28s/it, loss=0.1295, batch_acc=0.9688, running_acc=0.9803, grad=9.3495]Training epoch 36:  93%|█████████▎| 152/163 [02:53<00:14,  1.28s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9803, grad=12.4683]Training epoch 36:  94%|█████████▍| 153/163 [02:53<00:11,  1.16s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9803, grad=12.4683]Training epoch 36:  94%|█████████▍| 153/163 [02:53<00:11,  1.16s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9804, grad=8.9530] Training epoch 36:  94%|█████████▍| 154/163 [02:54<00:09,  1.08s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9804, grad=8.9530]Training epoch 36:  94%|█████████▍| 154/163 [02:54<00:09,  1.08s/it, loss=0.0704, batch_acc=1.0000, running_acc=0.9805, grad=6.2620]Training epoch 36:  95%|█████████▌| 155/163 [02:55<00:08,  1.02s/it, loss=0.0704, batch_acc=1.0000, running_acc=0.9805, grad=6.2620]Training epoch 36:  95%|█████████▌| 155/163 [02:55<00:08,  1.02s/it, loss=0.1415, batch_acc=1.0000, running_acc=0.9806, grad=11.6797]Training epoch 36:  96%|█████████▌| 156/163 [02:57<00:08,  1.24s/it, loss=0.1415, batch_acc=1.0000, running_acc=0.9806, grad=11.6797]Training epoch 36:  96%|█████████▌| 156/163 [02:57<00:08,  1.24s/it, loss=0.1308, batch_acc=0.9688, running_acc=0.9806, grad=12.5964]Training epoch 36:  96%|█████████▋| 157/163 [02:58<00:06,  1.13s/it, loss=0.1308, batch_acc=0.9688, running_acc=0.9806, grad=12.5964]Training epoch 36:  96%|█████████▋| 157/163 [02:58<00:06,  1.13s/it, loss=0.1278, batch_acc=1.0000, running_acc=0.9807, grad=9.2895] Training epoch 36:  97%|█████████▋| 158/163 [02:59<00:05,  1.06s/it, loss=0.1278, batch_acc=1.0000, running_acc=0.9807, grad=9.2895]Training epoch 36:  97%|█████████▋| 158/163 [02:59<00:05,  1.06s/it, loss=0.2016, batch_acc=0.9688, running_acc=0.9806, grad=14.1466]Training epoch 36:  98%|█████████▊| 159/163 [03:00<00:04,  1.00s/it, loss=0.2016, batch_acc=0.9688, running_acc=0.9806, grad=14.1466]Training epoch 36:  98%|█████████▊| 159/163 [03:00<00:04,  1.00s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9807, grad=7.6190] Training epoch 36:  98%|█████████▊| 160/163 [03:01<00:03,  1.20s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9807, grad=7.6190]Training epoch 36:  98%|█████████▊| 160/163 [03:01<00:03,  1.20s/it, loss=0.1030, batch_acc=1.0000, running_acc=0.9809, grad=8.0884]Training epoch 36:  99%|█████████▉| 161/163 [03:02<00:02,  1.10s/it, loss=0.1030, batch_acc=1.0000, running_acc=0.9809, grad=8.0884]Training epoch 36:  99%|█████████▉| 161/163 [03:02<00:02,  1.10s/it, loss=0.1338, batch_acc=1.0000, running_acc=0.9810, grad=9.8862]Training epoch 36:  99%|█████████▉| 162/163 [03:03<00:01,  1.04s/it, loss=0.1338, batch_acc=1.0000, running_acc=0.9810, grad=9.8862]Training epoch 36:  99%|█████████▉| 162/163 [03:03<00:01,  1.04s/it, loss=0.0948, batch_acc=1.0000, running_acc=0.9811, grad=8.4702]Training epoch 36: 100%|██████████| 163/163 [03:04<00:00,  1.09it/s, loss=0.0948, batch_acc=1.0000, running_acc=0.9811, grad=8.4702]Training epoch 36: 100%|██████████| 163/163 [03:04<00:00,  1.09it/s, loss=0.1539, batch_acc=1.0000, running_acc=0.9812, grad=12.5179]Training epoch 36: 100%|██████████| 163/163 [03:04<00:00,  1.13s/it, loss=0.1539, batch_acc=1.0000, running_acc=0.9812, grad=12.5179]
Evaluation epoch 36:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 36:   4%|▎         | 1/28 [00:04<02:10,  4.85s/it]Evaluation epoch 36:   4%|▎         | 1/28 [00:04<02:10,  4.85s/it, loss=0.4013, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 36:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.4013, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 36:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.3116, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 36:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3116, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 36:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3435, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 36:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.3435, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 36:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.4342, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 36:  18%|█▊        | 5/28 [00:09<00:38,  1.67s/it, loss=0.4342, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 36:  18%|█▊        | 5/28 [00:09<00:38,  1.67s/it, loss=1.3683, batch_acc=0.6562, running_acc=0.8875]Evaluation epoch 36:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=1.3683, batch_acc=0.6562, running_acc=0.8875]Evaluation epoch 36:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=0.5601, batch_acc=0.8750, running_acc=0.8854]Evaluation epoch 36:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.5601, batch_acc=0.8750, running_acc=0.8854]Evaluation epoch 36:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.5793, batch_acc=0.8438, running_acc=0.8795]Evaluation epoch 36:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.5793, batch_acc=0.8438, running_acc=0.8795]Evaluation epoch 36:  29%|██▊       | 8/28 [00:13<00:33,  1.67s/it, loss=0.4791, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 36:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.4791, batch_acc=0.8438, running_acc=0.8750]Evaluation epoch 36:  32%|███▏      | 9/28 [00:14<00:24,  1.29s/it, loss=0.4307, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 36:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.4307, batch_acc=0.9062, running_acc=0.8785]Evaluation epoch 36:  36%|███▌      | 10/28 [00:14<00:17,  1.02it/s, loss=0.4538, batch_acc=0.9375, running_acc=0.8844]Evaluation epoch 36:  39%|███▉      | 11/28 [00:14<00:12,  1.32it/s, loss=0.4538, batch_acc=0.9375, running_acc=0.8844]Evaluation epoch 36:  39%|███▉      | 11/28 [00:14<00:12,  1.32it/s, loss=0.3757, batch_acc=0.9375, running_acc=0.8892]Evaluation epoch 36:  43%|████▎     | 12/28 [00:20<00:35,  2.19s/it, loss=0.3757, batch_acc=0.9375, running_acc=0.8892]Evaluation epoch 36:  43%|████▎     | 12/28 [00:20<00:35,  2.19s/it, loss=1.0889, batch_acc=0.7812, running_acc=0.8802]Evaluation epoch 36:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=1.0889, batch_acc=0.7812, running_acc=0.8802]Evaluation epoch 36:  46%|████▋     | 13/28 [00:20<00:24,  1.61s/it, loss=0.3437, batch_acc=0.9375, running_acc=0.8846]Evaluation epoch 36:  50%|█████     | 14/28 [00:20<00:16,  1.20s/it, loss=0.3437, batch_acc=0.9375, running_acc=0.8846]Evaluation epoch 36:  50%|█████     | 14/28 [00:20<00:16,  1.20s/it, loss=0.8865, batch_acc=0.7812, running_acc=0.8772]Evaluation epoch 36:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=0.8865, batch_acc=0.7812, running_acc=0.8772]Evaluation epoch 36:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=0.9765, batch_acc=0.8125, running_acc=0.8729]Evaluation epoch 36:  57%|█████▋    | 16/28 [00:23<00:18,  1.52s/it, loss=0.9765, batch_acc=0.8125, running_acc=0.8729]Evaluation epoch 36:  57%|█████▋    | 16/28 [00:23<00:18,  1.52s/it, loss=0.7103, batch_acc=0.7812, running_acc=0.8672]Evaluation epoch 36:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.7103, batch_acc=0.7812, running_acc=0.8672]Evaluation epoch 36:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.5596, batch_acc=0.7500, running_acc=0.8603]Evaluation epoch 36:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.5596, batch_acc=0.7500, running_acc=0.8603]Evaluation epoch 36:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.6652, batch_acc=0.7812, running_acc=0.8559]Evaluation epoch 36:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.6652, batch_acc=0.7812, running_acc=0.8559]Evaluation epoch 36:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.9764, batch_acc=0.6250, running_acc=0.8438]Evaluation epoch 36:  71%|███████▏  | 20/28 [00:27<00:11,  1.38s/it, loss=0.9764, batch_acc=0.6250, running_acc=0.8438]Evaluation epoch 36:  71%|███████▏  | 20/28 [00:27<00:11,  1.38s/it, loss=0.6263, batch_acc=0.7188, running_acc=0.8375]Evaluation epoch 36:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.6263, batch_acc=0.7188, running_acc=0.8375]Evaluation epoch 36:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.5698, batch_acc=0.8438, running_acc=0.8378]Evaluation epoch 36:  79%|███████▊  | 22/28 [00:28<00:04,  1.23it/s, loss=0.5698, batch_acc=0.8438, running_acc=0.8378]Evaluation epoch 36:  79%|███████▊  | 22/28 [00:28<00:04,  1.23it/s, loss=0.4502, batch_acc=0.9375, running_acc=0.8423]Evaluation epoch 36:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=0.4502, batch_acc=0.9375, running_acc=0.8423]Evaluation epoch 36:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=0.8194, batch_acc=0.7500, running_acc=0.8383]Evaluation epoch 36:  86%|████████▌ | 24/28 [00:33<00:08,  2.03s/it, loss=0.8194, batch_acc=0.7500, running_acc=0.8383]Evaluation epoch 36:  86%|████████▌ | 24/28 [00:33<00:08,  2.03s/it, loss=0.3635, batch_acc=0.9062, running_acc=0.8411]Evaluation epoch 36:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=0.3635, batch_acc=0.9062, running_acc=0.8411]Evaluation epoch 36:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=0.1751, batch_acc=1.0000, running_acc=0.8475]Evaluation epoch 36:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.1751, batch_acc=1.0000, running_acc=0.8475]Evaluation epoch 36:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.5842, batch_acc=0.8125, running_acc=0.8462]Evaluation epoch 36:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.5842, batch_acc=0.8125, running_acc=0.8462]Evaluation epoch 36:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.9507, batch_acc=0.7188, running_acc=0.8414]Evaluation epoch 36: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=1.0569, batch_acc=0.6667, running_acc=0.8408]Evaluation epoch 36: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.0569, batch_acc=0.6667, running_acc=0.8408]
Training epoch 37:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 37:   1%|          | 1/163 [00:06<16:21,  6.06s/it]Training epoch 37:   1%|          | 1/163 [00:06<16:21,  6.06s/it, loss=0.1129, batch_acc=1.0000, running_acc=1.0000, grad=9.1829]Training epoch 37:   1%|          | 2/163 [00:06<08:04,  3.01s/it, loss=0.1129, batch_acc=1.0000, running_acc=1.0000, grad=9.1829]Training epoch 37:   1%|          | 2/163 [00:06<08:04,  3.01s/it, loss=0.1828, batch_acc=0.9688, running_acc=0.9844, grad=22.9568]Training epoch 37:   2%|▏         | 3/163 [00:07<05:25,  2.04s/it, loss=0.1828, batch_acc=0.9688, running_acc=0.9844, grad=22.9568]Training epoch 37:   2%|▏         | 3/163 [00:07<05:25,  2.04s/it, loss=0.1273, batch_acc=0.9688, running_acc=0.9792, grad=9.6842] Training epoch 37:   2%|▏         | 4/163 [00:10<06:26,  2.43s/it, loss=0.1273, batch_acc=0.9688, running_acc=0.9792, grad=9.6842]Training epoch 37:   2%|▏         | 4/163 [00:10<06:26,  2.43s/it, loss=0.1439, batch_acc=0.9688, running_acc=0.9766, grad=13.4141]Training epoch 37:   3%|▎         | 5/163 [00:11<04:55,  1.87s/it, loss=0.1439, batch_acc=0.9688, running_acc=0.9766, grad=13.4141]Training epoch 37:   3%|▎         | 5/163 [00:11<04:55,  1.87s/it, loss=0.1374, batch_acc=1.0000, running_acc=0.9812, grad=12.2429]Training epoch 37:   4%|▎         | 6/163 [00:12<04:00,  1.53s/it, loss=0.1374, batch_acc=1.0000, running_acc=0.9812, grad=12.2429]Training epoch 37:   4%|▎         | 6/163 [00:12<04:00,  1.53s/it, loss=0.1256, batch_acc=1.0000, running_acc=0.9844, grad=8.2448] Training epoch 37:   4%|▍         | 7/163 [00:13<03:25,  1.32s/it, loss=0.1256, batch_acc=1.0000, running_acc=0.9844, grad=8.2448]Training epoch 37:   4%|▍         | 7/163 [00:13<03:25,  1.32s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9866, grad=9.1853]Training epoch 37:   5%|▍         | 8/163 [00:15<03:58,  1.54s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9866, grad=9.1853]Training epoch 37:   5%|▍         | 8/163 [00:15<03:58,  1.54s/it, loss=0.1422, batch_acc=0.9688, running_acc=0.9844, grad=11.8318]Training epoch 37:   6%|▌         | 9/163 [00:16<03:25,  1.33s/it, loss=0.1422, batch_acc=0.9688, running_acc=0.9844, grad=11.8318]Training epoch 37:   6%|▌         | 9/163 [00:16<03:25,  1.33s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9861, grad=8.9590] Training epoch 37:   6%|▌         | 10/163 [00:17<03:02,  1.19s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9861, grad=8.9590]Training epoch 37:   6%|▌         | 10/163 [00:17<03:02,  1.19s/it, loss=0.1469, batch_acc=1.0000, running_acc=0.9875, grad=12.9264]Training epoch 37:   7%|▋         | 11/163 [00:18<02:46,  1.10s/it, loss=0.1469, batch_acc=1.0000, running_acc=0.9875, grad=12.9264]Training epoch 37:   7%|▋         | 11/163 [00:18<02:46,  1.10s/it, loss=0.1322, batch_acc=0.9688, running_acc=0.9858, grad=10.2869]Training epoch 37:   7%|▋         | 12/163 [00:20<03:46,  1.50s/it, loss=0.1322, batch_acc=0.9688, running_acc=0.9858, grad=10.2869]Training epoch 37:   7%|▋         | 12/163 [00:20<03:46,  1.50s/it, loss=0.1252, batch_acc=1.0000, running_acc=0.9870, grad=8.7678] Training epoch 37:   8%|▊         | 13/163 [00:21<03:17,  1.31s/it, loss=0.1252, batch_acc=1.0000, running_acc=0.9870, grad=8.7678]Training epoch 37:   8%|▊         | 13/163 [00:21<03:17,  1.31s/it, loss=0.1651, batch_acc=0.9375, running_acc=0.9832, grad=12.2871]Training epoch 37:   9%|▊         | 14/163 [00:22<02:56,  1.18s/it, loss=0.1651, batch_acc=0.9375, running_acc=0.9832, grad=12.2871]Training epoch 37:   9%|▊         | 14/163 [00:22<02:56,  1.18s/it, loss=0.1121, batch_acc=1.0000, running_acc=0.9844, grad=12.9893]Training epoch 37:   9%|▉         | 15/163 [00:23<02:41,  1.09s/it, loss=0.1121, batch_acc=1.0000, running_acc=0.9844, grad=12.9893]Training epoch 37:   9%|▉         | 15/163 [00:23<02:41,  1.09s/it, loss=0.1021, batch_acc=1.0000, running_acc=0.9854, grad=7.3178] Training epoch 37:  10%|▉         | 16/163 [00:25<03:39,  1.49s/it, loss=0.1021, batch_acc=1.0000, running_acc=0.9854, grad=7.3178]Training epoch 37:  10%|▉         | 16/163 [00:25<03:39,  1.49s/it, loss=0.1202, batch_acc=1.0000, running_acc=0.9863, grad=7.2032]Training epoch 37:  10%|█         | 17/163 [00:26<03:10,  1.31s/it, loss=0.1202, batch_acc=1.0000, running_acc=0.9863, grad=7.2032]Training epoch 37:  10%|█         | 17/163 [00:26<03:10,  1.31s/it, loss=0.0988, batch_acc=1.0000, running_acc=0.9871, grad=7.1453]Training epoch 37:  11%|█         | 18/163 [00:27<02:50,  1.18s/it, loss=0.0988, batch_acc=1.0000, running_acc=0.9871, grad=7.1453]Training epoch 37:  11%|█         | 18/163 [00:27<02:50,  1.18s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9878, grad=9.3048]Training epoch 37:  12%|█▏        | 19/163 [00:28<02:36,  1.09s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9878, grad=9.3048]Training epoch 37:  12%|█▏        | 19/163 [00:28<02:36,  1.09s/it, loss=0.0990, batch_acc=1.0000, running_acc=0.9885, grad=7.3502]Training epoch 37:  12%|█▏        | 20/163 [00:29<03:00,  1.26s/it, loss=0.0990, batch_acc=1.0000, running_acc=0.9885, grad=7.3502]Training epoch 37:  12%|█▏        | 20/163 [00:29<03:00,  1.26s/it, loss=0.1466, batch_acc=1.0000, running_acc=0.9891, grad=13.0687]Training epoch 37:  13%|█▎        | 21/163 [00:30<02:42,  1.15s/it, loss=0.1466, batch_acc=1.0000, running_acc=0.9891, grad=13.0687]Training epoch 37:  13%|█▎        | 21/163 [00:30<02:42,  1.15s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9896, grad=9.5494] Training epoch 37:  13%|█▎        | 22/163 [00:31<02:30,  1.07s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9896, grad=9.5494]Training epoch 37:  13%|█▎        | 22/163 [00:31<02:30,  1.07s/it, loss=0.1477, batch_acc=1.0000, running_acc=0.9901, grad=10.3041]Training epoch 37:  14%|█▍        | 23/163 [00:32<02:21,  1.01s/it, loss=0.1477, batch_acc=1.0000, running_acc=0.9901, grad=10.3041]Training epoch 37:  14%|█▍        | 23/163 [00:32<02:21,  1.01s/it, loss=0.1730, batch_acc=0.9375, running_acc=0.9878, grad=11.5347]Training epoch 37:  15%|█▍        | 24/163 [00:34<02:59,  1.29s/it, loss=0.1730, batch_acc=0.9375, running_acc=0.9878, grad=11.5347]Training epoch 37:  15%|█▍        | 24/163 [00:34<02:59,  1.29s/it, loss=0.1318, batch_acc=1.0000, running_acc=0.9883, grad=8.6822] Training epoch 37:  15%|█▌        | 25/163 [00:35<02:41,  1.17s/it, loss=0.1318, batch_acc=1.0000, running_acc=0.9883, grad=8.6822]Training epoch 37:  15%|█▌        | 25/163 [00:35<02:41,  1.17s/it, loss=0.1504, batch_acc=1.0000, running_acc=0.9888, grad=14.1611]Training epoch 37:  16%|█▌        | 26/163 [00:36<02:28,  1.08s/it, loss=0.1504, batch_acc=1.0000, running_acc=0.9888, grad=14.1611]Training epoch 37:  16%|█▌        | 26/163 [00:36<02:28,  1.08s/it, loss=0.1696, batch_acc=1.0000, running_acc=0.9892, grad=11.9618]Training epoch 37:  17%|█▋        | 27/163 [00:37<02:18,  1.02s/it, loss=0.1696, batch_acc=1.0000, running_acc=0.9892, grad=11.9618]Training epoch 37:  17%|█▋        | 27/163 [00:37<02:18,  1.02s/it, loss=0.2431, batch_acc=0.9375, running_acc=0.9873, grad=17.2085]Training epoch 37:  17%|█▋        | 28/163 [00:39<03:10,  1.41s/it, loss=0.2431, batch_acc=0.9375, running_acc=0.9873, grad=17.2085]Training epoch 37:  17%|█▋        | 28/163 [00:39<03:10,  1.41s/it, loss=0.1084, batch_acc=1.0000, running_acc=0.9877, grad=8.8594] Training epoch 37:  18%|█▊        | 29/163 [00:40<02:47,  1.25s/it, loss=0.1084, batch_acc=1.0000, running_acc=0.9877, grad=8.8594]Training epoch 37:  18%|█▊        | 29/163 [00:40<02:47,  1.25s/it, loss=0.1539, batch_acc=1.0000, running_acc=0.9881, grad=15.8308]Training epoch 37:  18%|█▊        | 30/163 [00:41<02:31,  1.14s/it, loss=0.1539, batch_acc=1.0000, running_acc=0.9881, grad=15.8308]Training epoch 37:  18%|█▊        | 30/163 [00:41<02:31,  1.14s/it, loss=0.1088, batch_acc=1.0000, running_acc=0.9885, grad=11.1662]Training epoch 37:  19%|█▉        | 31/163 [00:42<02:19,  1.06s/it, loss=0.1088, batch_acc=1.0000, running_acc=0.9885, grad=11.1662]Training epoch 37:  19%|█▉        | 31/163 [00:42<02:19,  1.06s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9889, grad=9.0536] Training epoch 37:  20%|█▉        | 32/163 [00:43<02:47,  1.28s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9889, grad=9.0536]Training epoch 37:  20%|█▉        | 32/163 [00:43<02:47,  1.28s/it, loss=0.2034, batch_acc=1.0000, running_acc=0.9893, grad=14.0894]Training epoch 37:  20%|██        | 33/163 [00:44<02:30,  1.16s/it, loss=0.2034, batch_acc=1.0000, running_acc=0.9893, grad=14.0894]Training epoch 37:  20%|██        | 33/163 [00:44<02:30,  1.16s/it, loss=0.1624, batch_acc=1.0000, running_acc=0.9896, grad=22.0663]Training epoch 37:  21%|██        | 34/163 [00:45<02:18,  1.07s/it, loss=0.1624, batch_acc=1.0000, running_acc=0.9896, grad=22.0663]Training epoch 37:  21%|██        | 34/163 [00:45<02:18,  1.07s/it, loss=0.1140, batch_acc=1.0000, running_acc=0.9899, grad=9.4713] Training epoch 37:  21%|██▏       | 35/163 [00:46<02:09,  1.02s/it, loss=0.1140, batch_acc=1.0000, running_acc=0.9899, grad=9.4713]Training epoch 37:  21%|██▏       | 35/163 [00:46<02:09,  1.02s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9902, grad=5.5162]Training epoch 37:  22%|██▏       | 36/163 [00:48<02:28,  1.17s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9902, grad=5.5162]Training epoch 37:  22%|██▏       | 36/163 [00:48<02:28,  1.17s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9905, grad=6.6836]Training epoch 37:  23%|██▎       | 37/163 [00:48<02:16,  1.08s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9905, grad=6.6836]Training epoch 37:  23%|██▎       | 37/163 [00:48<02:16,  1.08s/it, loss=0.1622, batch_acc=1.0000, running_acc=0.9907, grad=12.7988]Training epoch 37:  23%|██▎       | 38/163 [00:49<02:07,  1.02s/it, loss=0.1622, batch_acc=1.0000, running_acc=0.9907, grad=12.7988]Training epoch 37:  23%|██▎       | 38/163 [00:49<02:07,  1.02s/it, loss=0.1174, batch_acc=1.0000, running_acc=0.9910, grad=12.4525]Training epoch 37:  24%|██▍       | 39/163 [00:50<02:01,  1.02it/s, loss=0.1174, batch_acc=1.0000, running_acc=0.9910, grad=12.4525]Training epoch 37:  24%|██▍       | 39/163 [00:50<02:01,  1.02it/s, loss=0.1330, batch_acc=0.9688, running_acc=0.9904, grad=8.4996] Training epoch 37:  25%|██▍       | 40/163 [00:52<02:19,  1.14s/it, loss=0.1330, batch_acc=0.9688, running_acc=0.9904, grad=8.4996]Training epoch 37:  25%|██▍       | 40/163 [00:52<02:19,  1.14s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.9906, grad=10.7641]Training epoch 37:  25%|██▌       | 41/163 [00:53<02:09,  1.06s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.9906, grad=10.7641]Training epoch 37:  25%|██▌       | 41/163 [00:53<02:09,  1.06s/it, loss=0.1536, batch_acc=0.9688, running_acc=0.9901, grad=14.0548]Training epoch 37:  26%|██▌       | 42/163 [00:53<02:01,  1.01s/it, loss=0.1536, batch_acc=0.9688, running_acc=0.9901, grad=14.0548]Training epoch 37:  26%|██▌       | 42/163 [00:53<02:01,  1.01s/it, loss=0.1440, batch_acc=0.9688, running_acc=0.9896, grad=10.0690]Training epoch 37:  26%|██▋       | 43/163 [00:54<01:56,  1.03it/s, loss=0.1440, batch_acc=0.9688, running_acc=0.9896, grad=10.0690]Training epoch 37:  26%|██▋       | 43/163 [00:54<01:56,  1.03it/s, loss=0.1606, batch_acc=0.9688, running_acc=0.9891, grad=11.8583]Training epoch 37:  27%|██▋       | 44/163 [00:56<02:22,  1.19s/it, loss=0.1606, batch_acc=0.9688, running_acc=0.9891, grad=11.8583]Training epoch 37:  27%|██▋       | 44/163 [00:56<02:22,  1.19s/it, loss=0.1425, batch_acc=1.0000, running_acc=0.9893, grad=12.5115]Training epoch 37:  28%|██▊       | 45/163 [00:57<02:09,  1.10s/it, loss=0.1425, batch_acc=1.0000, running_acc=0.9893, grad=12.5115]Training epoch 37:  28%|██▊       | 45/163 [00:57<02:09,  1.10s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9889, grad=11.3871]Training epoch 37:  28%|██▊       | 46/163 [00:58<02:01,  1.03s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9889, grad=11.3871]Training epoch 37:  28%|██▊       | 46/163 [00:58<02:01,  1.03s/it, loss=0.1838, batch_acc=0.9062, running_acc=0.9871, grad=11.5605]Training epoch 37:  29%|██▉       | 47/163 [00:59<01:54,  1.01it/s, loss=0.1838, batch_acc=0.9062, running_acc=0.9871, grad=11.5605]Training epoch 37:  29%|██▉       | 47/163 [00:59<01:54,  1.01it/s, loss=0.1981, batch_acc=0.9375, running_acc=0.9860, grad=16.2288]Training epoch 37:  29%|██▉       | 48/163 [01:01<02:29,  1.30s/it, loss=0.1981, batch_acc=0.9375, running_acc=0.9860, grad=16.2288]Training epoch 37:  29%|██▉       | 48/163 [01:01<02:29,  1.30s/it, loss=0.1633, batch_acc=0.9375, running_acc=0.9850, grad=8.7377] Training epoch 37:  30%|███       | 49/163 [01:02<02:14,  1.18s/it, loss=0.1633, batch_acc=0.9375, running_acc=0.9850, grad=8.7377]Training epoch 37:  30%|███       | 49/163 [01:02<02:14,  1.18s/it, loss=0.1811, batch_acc=0.9375, running_acc=0.9841, grad=11.3114]Training epoch 37:  31%|███       | 50/163 [01:03<02:02,  1.09s/it, loss=0.1811, batch_acc=0.9375, running_acc=0.9841, grad=11.3114]Training epoch 37:  31%|███       | 50/163 [01:03<02:02,  1.09s/it, loss=0.0771, batch_acc=1.0000, running_acc=0.9844, grad=6.2222] Training epoch 37:  31%|███▏      | 51/163 [01:03<01:54,  1.03s/it, loss=0.0771, batch_acc=1.0000, running_acc=0.9844, grad=6.2222]Training epoch 37:  31%|███▏      | 51/163 [01:03<01:54,  1.03s/it, loss=0.1671, batch_acc=1.0000, running_acc=0.9847, grad=13.4630]Training epoch 37:  32%|███▏      | 52/163 [01:05<02:29,  1.35s/it, loss=0.1671, batch_acc=1.0000, running_acc=0.9847, grad=13.4630]Training epoch 37:  32%|███▏      | 52/163 [01:05<02:29,  1.35s/it, loss=0.1685, batch_acc=0.9688, running_acc=0.9844, grad=17.1619]Training epoch 37:  33%|███▎      | 53/163 [01:06<02:12,  1.21s/it, loss=0.1685, batch_acc=0.9688, running_acc=0.9844, grad=17.1619]Training epoch 37:  33%|███▎      | 53/163 [01:06<02:12,  1.21s/it, loss=0.2052, batch_acc=0.9688, running_acc=0.9841, grad=13.4399]Training epoch 37:  33%|███▎      | 54/163 [01:07<02:01,  1.11s/it, loss=0.2052, batch_acc=0.9688, running_acc=0.9841, grad=13.4399]Training epoch 37:  33%|███▎      | 54/163 [01:07<02:01,  1.11s/it, loss=0.1354, batch_acc=0.9688, running_acc=0.9838, grad=11.4220]Training epoch 37:  34%|███▎      | 55/163 [01:08<01:52,  1.04s/it, loss=0.1354, batch_acc=0.9688, running_acc=0.9838, grad=11.4220]Training epoch 37:  34%|███▎      | 55/163 [01:08<01:52,  1.04s/it, loss=0.1170, batch_acc=1.0000, running_acc=0.9841, grad=8.6640] Training epoch 37:  34%|███▍      | 56/163 [01:10<02:14,  1.25s/it, loss=0.1170, batch_acc=1.0000, running_acc=0.9841, grad=8.6640]Training epoch 37:  34%|███▍      | 56/163 [01:10<02:14,  1.25s/it, loss=0.1381, batch_acc=1.0000, running_acc=0.9844, grad=11.2278]Training epoch 37:  35%|███▍      | 57/163 [01:11<02:01,  1.14s/it, loss=0.1381, batch_acc=1.0000, running_acc=0.9844, grad=11.2278]Training epoch 37:  35%|███▍      | 57/163 [01:11<02:01,  1.14s/it, loss=0.1872, batch_acc=0.9688, running_acc=0.9841, grad=11.4366]Training epoch 37:  36%|███▌      | 58/163 [01:12<01:51,  1.06s/it, loss=0.1872, batch_acc=0.9688, running_acc=0.9841, grad=11.4366]Training epoch 37:  36%|███▌      | 58/163 [01:12<01:51,  1.06s/it, loss=0.1525, batch_acc=0.9375, running_acc=0.9833, grad=11.5099]Training epoch 37:  36%|███▌      | 59/163 [01:13<01:44,  1.01s/it, loss=0.1525, batch_acc=0.9375, running_acc=0.9833, grad=11.5099]Training epoch 37:  36%|███▌      | 59/163 [01:13<01:44,  1.01s/it, loss=0.1657, batch_acc=1.0000, running_acc=0.9836, grad=14.8990]Training epoch 37:  37%|███▋      | 60/163 [01:14<02:01,  1.18s/it, loss=0.1657, batch_acc=1.0000, running_acc=0.9836, grad=14.8990]Training epoch 37:  37%|███▋      | 60/163 [01:14<02:01,  1.18s/it, loss=0.2344, batch_acc=1.0000, running_acc=0.9839, grad=21.2076]Training epoch 37:  37%|███▋      | 61/163 [01:15<01:51,  1.09s/it, loss=0.2344, batch_acc=1.0000, running_acc=0.9839, grad=21.2076]Training epoch 37:  37%|███▋      | 61/163 [01:15<01:51,  1.09s/it, loss=0.1712, batch_acc=0.9688, running_acc=0.9836, grad=11.3935]Training epoch 37:  38%|███▊      | 62/163 [01:16<01:44,  1.03s/it, loss=0.1712, batch_acc=0.9688, running_acc=0.9836, grad=11.3935]Training epoch 37:  38%|███▊      | 62/163 [01:16<01:44,  1.03s/it, loss=0.1018, batch_acc=1.0000, running_acc=0.9839, grad=6.9036] Training epoch 37:  39%|███▊      | 63/163 [01:17<01:38,  1.01it/s, loss=0.1018, batch_acc=1.0000, running_acc=0.9839, grad=6.9036]Training epoch 37:  39%|███▊      | 63/163 [01:17<01:38,  1.01it/s, loss=0.1548, batch_acc=1.0000, running_acc=0.9841, grad=11.7098]Training epoch 37:  39%|███▉      | 64/163 [01:18<01:50,  1.11s/it, loss=0.1548, batch_acc=1.0000, running_acc=0.9841, grad=11.7098]Training epoch 37:  39%|███▉      | 64/163 [01:18<01:50,  1.11s/it, loss=0.1526, batch_acc=1.0000, running_acc=0.9844, grad=19.3206]Training epoch 37:  40%|███▉      | 65/163 [01:19<01:42,  1.04s/it, loss=0.1526, batch_acc=1.0000, running_acc=0.9844, grad=19.3206]Training epoch 37:  40%|███▉      | 65/163 [01:19<01:42,  1.04s/it, loss=0.1343, batch_acc=0.9688, running_acc=0.9841, grad=9.7641] Training epoch 37:  40%|████      | 66/163 [01:20<01:36,  1.00it/s, loss=0.1343, batch_acc=0.9688, running_acc=0.9841, grad=9.7641]Training epoch 37:  40%|████      | 66/163 [01:20<01:36,  1.00it/s, loss=0.1906, batch_acc=0.9688, running_acc=0.9839, grad=13.5162]Training epoch 37:  41%|████      | 67/163 [01:21<01:32,  1.04it/s, loss=0.1906, batch_acc=0.9688, running_acc=0.9839, grad=13.5162]Training epoch 37:  41%|████      | 67/163 [01:21<01:32,  1.04it/s, loss=0.1359, batch_acc=0.9688, running_acc=0.9837, grad=9.9891] Training epoch 37:  42%|████▏     | 68/163 [01:22<01:50,  1.16s/it, loss=0.1359, batch_acc=0.9688, running_acc=0.9837, grad=9.9891]Training epoch 37:  42%|████▏     | 68/163 [01:22<01:50,  1.16s/it, loss=0.1207, batch_acc=1.0000, running_acc=0.9839, grad=11.0021]Training epoch 37:  42%|████▏     | 69/163 [01:23<01:41,  1.08s/it, loss=0.1207, batch_acc=1.0000, running_acc=0.9839, grad=11.0021]Training epoch 37:  42%|████▏     | 69/163 [01:23<01:41,  1.08s/it, loss=0.1009, batch_acc=0.9688, running_acc=0.9837, grad=8.6946] Training epoch 37:  43%|████▎     | 70/163 [01:24<01:34,  1.02s/it, loss=0.1009, batch_acc=0.9688, running_acc=0.9837, grad=8.6946]Training epoch 37:  43%|████▎     | 70/163 [01:24<01:34,  1.02s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9839, grad=8.8518]Training epoch 37:  44%|████▎     | 71/163 [01:25<01:29,  1.02it/s, loss=0.0772, batch_acc=1.0000, running_acc=0.9839, grad=8.8518]Training epoch 37:  44%|████▎     | 71/163 [01:25<01:29,  1.02it/s, loss=0.1514, batch_acc=1.0000, running_acc=0.9842, grad=14.3951]Training epoch 37:  44%|████▍     | 72/163 [01:26<01:36,  1.06s/it, loss=0.1514, batch_acc=1.0000, running_acc=0.9842, grad=14.3951]Training epoch 37:  44%|████▍     | 72/163 [01:26<01:36,  1.06s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9844, grad=10.8196]Training epoch 37:  45%|████▍     | 73/163 [01:27<01:30,  1.01s/it, loss=0.1261, batch_acc=1.0000, running_acc=0.9844, grad=10.8196]Training epoch 37:  45%|████▍     | 73/163 [01:27<01:30,  1.01s/it, loss=0.1650, batch_acc=0.9688, running_acc=0.9842, grad=10.4670]Training epoch 37:  45%|████▌     | 74/163 [01:28<01:26,  1.03it/s, loss=0.1650, batch_acc=0.9688, running_acc=0.9842, grad=10.4670]Training epoch 37:  45%|████▌     | 74/163 [01:28<01:26,  1.03it/s, loss=0.1239, batch_acc=0.9688, running_acc=0.9840, grad=10.1566]Training epoch 37:  46%|████▌     | 75/163 [01:29<01:22,  1.06it/s, loss=0.1239, batch_acc=0.9688, running_acc=0.9840, grad=10.1566]Training epoch 37:  46%|████▌     | 75/163 [01:29<01:22,  1.06it/s, loss=0.1103, batch_acc=1.0000, running_acc=0.9842, grad=9.3578] Training epoch 37:  47%|████▋     | 76/163 [01:31<01:41,  1.17s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9842, grad=9.3578]Training epoch 37:  47%|████▋     | 76/163 [01:31<01:41,  1.17s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9836, grad=16.3890]Training epoch 37:  47%|████▋     | 77/163 [01:32<01:33,  1.08s/it, loss=0.1966, batch_acc=0.9375, running_acc=0.9836, grad=16.3890]Training epoch 37:  47%|████▋     | 77/163 [01:32<01:33,  1.08s/it, loss=0.1062, batch_acc=1.0000, running_acc=0.9838, grad=7.8419] Training epoch 37:  48%|████▊     | 78/163 [01:32<01:26,  1.02s/it, loss=0.1062, batch_acc=1.0000, running_acc=0.9838, grad=7.8419]Training epoch 37:  48%|████▊     | 78/163 [01:32<01:26,  1.02s/it, loss=0.1908, batch_acc=0.9688, running_acc=0.9836, grad=11.0257]Training epoch 37:  48%|████▊     | 79/163 [01:33<01:22,  1.02it/s, loss=0.1908, batch_acc=0.9688, running_acc=0.9836, grad=11.0257]Training epoch 37:  48%|████▊     | 79/163 [01:33<01:22,  1.02it/s, loss=0.1613, batch_acc=1.0000, running_acc=0.9838, grad=13.8514]Training epoch 37:  49%|████▉     | 80/163 [01:35<01:32,  1.11s/it, loss=0.1613, batch_acc=1.0000, running_acc=0.9838, grad=13.8514]Training epoch 37:  49%|████▉     | 80/163 [01:35<01:32,  1.11s/it, loss=0.1383, batch_acc=1.0000, running_acc=0.9840, grad=8.6925] Training epoch 37:  50%|████▉     | 81/163 [01:36<01:25,  1.04s/it, loss=0.1383, batch_acc=1.0000, running_acc=0.9840, grad=8.6925]Training epoch 37:  50%|████▉     | 81/163 [01:36<01:25,  1.04s/it, loss=0.1578, batch_acc=0.9688, running_acc=0.9838, grad=9.6683]Training epoch 37:  50%|█████     | 82/163 [01:37<01:20,  1.00it/s, loss=0.1578, batch_acc=0.9688, running_acc=0.9838, grad=9.6683]Training epoch 37:  50%|█████     | 82/163 [01:37<01:20,  1.00it/s, loss=0.0993, batch_acc=1.0000, running_acc=0.9840, grad=7.1773]Training epoch 37:  51%|█████     | 83/163 [01:37<01:16,  1.04it/s, loss=0.0993, batch_acc=1.0000, running_acc=0.9840, grad=7.1773]Training epoch 37:  51%|█████     | 83/163 [01:37<01:16,  1.04it/s, loss=0.1254, batch_acc=1.0000, running_acc=0.9842, grad=8.8795]Training epoch 37:  52%|█████▏    | 84/163 [01:39<01:29,  1.14s/it, loss=0.1254, batch_acc=1.0000, running_acc=0.9842, grad=8.8795]Training epoch 37:  52%|█████▏    | 84/163 [01:39<01:29,  1.14s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9844, grad=7.0528]Training epoch 37:  52%|█████▏    | 85/163 [01:40<01:22,  1.06s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9844, grad=7.0528]Training epoch 37:  52%|█████▏    | 85/163 [01:40<01:22,  1.06s/it, loss=0.1768, batch_acc=0.9688, running_acc=0.9842, grad=16.6381]Training epoch 37:  53%|█████▎    | 86/163 [01:41<01:17,  1.01s/it, loss=0.1768, batch_acc=0.9688, running_acc=0.9842, grad=16.6381]Training epoch 37:  53%|█████▎    | 86/163 [01:41<01:17,  1.01s/it, loss=0.0964, batch_acc=1.0000, running_acc=0.9844, grad=9.2379] Training epoch 37:  53%|█████▎    | 87/163 [01:42<01:13,  1.03it/s, loss=0.0964, batch_acc=1.0000, running_acc=0.9844, grad=9.2379]Training epoch 37:  53%|█████▎    | 87/163 [01:42<01:13,  1.03it/s, loss=0.1392, batch_acc=1.0000, running_acc=0.9846, grad=9.9763]Training epoch 37:  54%|█████▍    | 88/163 [01:43<01:16,  1.02s/it, loss=0.1392, batch_acc=1.0000, running_acc=0.9846, grad=9.9763]Training epoch 37:  54%|█████▍    | 88/163 [01:43<01:16,  1.02s/it, loss=0.1625, batch_acc=0.9688, running_acc=0.9844, grad=11.2012]Training epoch 37:  55%|█████▍    | 89/163 [01:44<01:12,  1.03it/s, loss=0.1625, batch_acc=0.9688, running_acc=0.9844, grad=11.2012]Training epoch 37:  55%|█████▍    | 89/163 [01:44<01:12,  1.03it/s, loss=0.1371, batch_acc=0.9688, running_acc=0.9842, grad=8.6565] Training epoch 37:  55%|█████▌    | 90/163 [01:44<01:09,  1.06it/s, loss=0.1371, batch_acc=0.9688, running_acc=0.9842, grad=8.6565]Training epoch 37:  55%|█████▌    | 90/163 [01:44<01:09,  1.06it/s, loss=0.1055, batch_acc=1.0000, running_acc=0.9844, grad=7.3004]Training epoch 37:  56%|█████▌    | 91/163 [01:45<01:06,  1.08it/s, loss=0.1055, batch_acc=1.0000, running_acc=0.9844, grad=7.3004]Training epoch 37:  56%|█████▌    | 91/163 [01:45<01:06,  1.08it/s, loss=0.1291, batch_acc=0.9688, running_acc=0.9842, grad=11.3424]Training epoch 37:  56%|█████▋    | 92/163 [01:47<01:20,  1.13s/it, loss=0.1291, batch_acc=0.9688, running_acc=0.9842, grad=11.3424]Training epoch 37:  56%|█████▋    | 92/163 [01:47<01:20,  1.13s/it, loss=0.1072, batch_acc=1.0000, running_acc=0.9844, grad=10.4537]Training epoch 37:  57%|█████▋    | 93/163 [01:48<01:13,  1.06s/it, loss=0.1072, batch_acc=1.0000, running_acc=0.9844, grad=10.4537]Training epoch 37:  57%|█████▋    | 93/163 [01:48<01:13,  1.06s/it, loss=0.1119, batch_acc=0.9688, running_acc=0.9842, grad=9.6496] Training epoch 37:  58%|█████▊    | 94/163 [01:49<01:09,  1.00s/it, loss=0.1119, batch_acc=0.9688, running_acc=0.9842, grad=9.6496]Training epoch 37:  58%|█████▊    | 94/163 [01:49<01:09,  1.00s/it, loss=0.2070, batch_acc=0.9375, running_acc=0.9837, grad=16.8385]Training epoch 37:  58%|█████▊    | 95/163 [01:50<01:05,  1.03it/s, loss=0.2070, batch_acc=0.9375, running_acc=0.9837, grad=16.8385]Training epoch 37:  58%|█████▊    | 95/163 [01:50<01:05,  1.03it/s, loss=0.1557, batch_acc=0.9688, running_acc=0.9836, grad=11.7281]Training epoch 37:  59%|█████▉    | 96/163 [01:52<01:24,  1.26s/it, loss=0.1557, batch_acc=0.9688, running_acc=0.9836, grad=11.7281]Training epoch 37:  59%|█████▉    | 96/163 [01:52<01:24,  1.26s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9837, grad=11.8797]Training epoch 37:  60%|█████▉    | 97/163 [01:52<01:15,  1.15s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9837, grad=11.8797]Training epoch 37:  60%|█████▉    | 97/163 [01:52<01:15,  1.15s/it, loss=0.1199, batch_acc=1.0000, running_acc=0.9839, grad=9.1971] Training epoch 37:  60%|██████    | 98/163 [01:53<01:09,  1.07s/it, loss=0.1199, batch_acc=1.0000, running_acc=0.9839, grad=9.1971]Training epoch 37:  60%|██████    | 98/163 [01:53<01:09,  1.07s/it, loss=0.1638, batch_acc=0.9688, running_acc=0.9837, grad=11.5091]Training epoch 37:  61%|██████    | 99/163 [01:54<01:04,  1.01s/it, loss=0.1638, batch_acc=0.9688, running_acc=0.9837, grad=11.5091]Training epoch 37:  61%|██████    | 99/163 [01:54<01:04,  1.01s/it, loss=0.1451, batch_acc=0.9688, running_acc=0.9836, grad=8.8946] Training epoch 37:  61%|██████▏   | 100/163 [01:56<01:09,  1.10s/it, loss=0.1451, batch_acc=0.9688, running_acc=0.9836, grad=8.8946]Training epoch 37:  61%|██████▏   | 100/163 [01:56<01:09,  1.10s/it, loss=0.1089, batch_acc=1.0000, running_acc=0.9838, grad=12.3972]Training epoch 37:  62%|██████▏   | 101/163 [01:56<01:04,  1.03s/it, loss=0.1089, batch_acc=1.0000, running_acc=0.9838, grad=12.3972]Training epoch 37:  62%|██████▏   | 101/163 [01:56<01:04,  1.03s/it, loss=0.1281, batch_acc=1.0000, running_acc=0.9839, grad=11.1739]Training epoch 37:  63%|██████▎   | 102/163 [01:57<01:00,  1.01it/s, loss=0.1281, batch_acc=1.0000, running_acc=0.9839, grad=11.1739]Training epoch 37:  63%|██████▎   | 102/163 [01:57<01:00,  1.01it/s, loss=0.1035, batch_acc=1.0000, running_acc=0.9841, grad=7.1249] Training epoch 37:  63%|██████▎   | 103/163 [01:58<00:57,  1.05it/s, loss=0.1035, batch_acc=1.0000, running_acc=0.9841, grad=7.1249]Training epoch 37:  63%|██████▎   | 103/163 [01:58<00:57,  1.05it/s, loss=0.2038, batch_acc=0.9688, running_acc=0.9839, grad=13.2120]Training epoch 37:  64%|██████▍   | 104/163 [02:00<01:12,  1.23s/it, loss=0.2038, batch_acc=0.9688, running_acc=0.9839, grad=13.2120]Training epoch 37:  64%|██████▍   | 104/163 [02:00<01:12,  1.23s/it, loss=0.1328, batch_acc=1.0000, running_acc=0.9841, grad=14.5246]Training epoch 37:  64%|██████▍   | 105/163 [02:01<01:05,  1.13s/it, loss=0.1328, batch_acc=1.0000, running_acc=0.9841, grad=14.5246]Training epoch 37:  64%|██████▍   | 105/163 [02:01<01:05,  1.13s/it, loss=0.1128, batch_acc=1.0000, running_acc=0.9842, grad=10.9815]Training epoch 37:  65%|██████▌   | 106/163 [02:02<01:00,  1.05s/it, loss=0.1128, batch_acc=1.0000, running_acc=0.9842, grad=10.9815]Training epoch 37:  65%|██████▌   | 106/163 [02:02<01:00,  1.05s/it, loss=0.2401, batch_acc=0.9375, running_acc=0.9838, grad=18.9264]Training epoch 37:  66%|██████▌   | 107/163 [02:03<00:56,  1.00s/it, loss=0.2401, batch_acc=0.9375, running_acc=0.9838, grad=18.9264]Training epoch 37:  66%|██████▌   | 107/163 [02:03<00:56,  1.00s/it, loss=0.2572, batch_acc=0.9375, running_acc=0.9834, grad=18.5372]Training epoch 37:  66%|██████▋   | 108/163 [02:04<01:05,  1.20s/it, loss=0.2572, batch_acc=0.9375, running_acc=0.9834, grad=18.5372]Training epoch 37:  66%|██████▋   | 108/163 [02:04<01:05,  1.20s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9832, grad=10.7912]Training epoch 37:  67%|██████▋   | 109/163 [02:05<00:59,  1.10s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9832, grad=10.7912]Training epoch 37:  67%|██████▋   | 109/163 [02:05<00:59,  1.10s/it, loss=0.1623, batch_acc=0.9375, running_acc=0.9828, grad=11.4258]Training epoch 37:  67%|██████▋   | 110/163 [02:06<00:54,  1.04s/it, loss=0.1623, batch_acc=0.9375, running_acc=0.9828, grad=11.4258]Training epoch 37:  67%|██████▋   | 110/163 [02:06<00:54,  1.04s/it, loss=0.1584, batch_acc=0.9688, running_acc=0.9827, grad=15.6512]Training epoch 37:  68%|██████▊   | 111/163 [02:07<00:51,  1.01it/s, loss=0.1584, batch_acc=0.9688, running_acc=0.9827, grad=15.6512]Training epoch 37:  68%|██████▊   | 111/163 [02:07<00:51,  1.01it/s, loss=0.1434, batch_acc=1.0000, running_acc=0.9828, grad=15.8928]Training epoch 37:  69%|██████▊   | 112/163 [02:09<01:08,  1.34s/it, loss=0.1434, batch_acc=1.0000, running_acc=0.9828, grad=15.8928]Training epoch 37:  69%|██████▊   | 112/163 [02:09<01:08,  1.34s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9830, grad=10.3580]Training epoch 37:  69%|██████▉   | 113/163 [02:10<01:00,  1.20s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9830, grad=10.3580]Training epoch 37:  69%|██████▉   | 113/163 [02:10<01:00,  1.20s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9831, grad=7.5519] Training epoch 37:  70%|██████▉   | 114/163 [02:11<00:54,  1.11s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9831, grad=7.5519]Training epoch 37:  70%|██████▉   | 114/163 [02:11<00:54,  1.11s/it, loss=0.1801, batch_acc=1.0000, running_acc=0.9833, grad=15.9803]Training epoch 37:  71%|███████   | 115/163 [02:12<00:49,  1.04s/it, loss=0.1801, batch_acc=1.0000, running_acc=0.9833, grad=15.9803]Training epoch 37:  71%|███████   | 115/163 [02:12<00:49,  1.04s/it, loss=0.1369, batch_acc=0.9688, running_acc=0.9832, grad=10.5912]Training epoch 37:  71%|███████   | 116/163 [02:13<00:50,  1.07s/it, loss=0.1369, batch_acc=0.9688, running_acc=0.9832, grad=10.5912]Training epoch 37:  71%|███████   | 116/163 [02:13<00:50,  1.07s/it, loss=0.1565, batch_acc=0.9688, running_acc=0.9830, grad=12.2332]Training epoch 37:  72%|███████▏  | 117/163 [02:14<00:46,  1.02s/it, loss=0.1565, batch_acc=0.9688, running_acc=0.9830, grad=12.2332]Training epoch 37:  72%|███████▏  | 117/163 [02:14<00:46,  1.02s/it, loss=0.2032, batch_acc=0.9688, running_acc=0.9829, grad=18.3369]Training epoch 37:  72%|███████▏  | 118/163 [02:15<00:43,  1.02it/s, loss=0.2032, batch_acc=0.9688, running_acc=0.9829, grad=18.3369]Training epoch 37:  72%|███████▏  | 118/163 [02:15<00:43,  1.02it/s, loss=0.2459, batch_acc=0.9062, running_acc=0.9823, grad=16.3445]Training epoch 37:  73%|███████▎  | 119/163 [02:16<00:41,  1.05it/s, loss=0.2459, batch_acc=0.9062, running_acc=0.9823, grad=16.3445]Training epoch 37:  73%|███████▎  | 119/163 [02:16<00:41,  1.05it/s, loss=0.0984, batch_acc=1.0000, running_acc=0.9824, grad=8.9862] Training epoch 37:  74%|███████▎  | 120/163 [02:17<00:48,  1.13s/it, loss=0.0984, batch_acc=1.0000, running_acc=0.9824, grad=8.9862]Training epoch 37:  74%|███████▎  | 120/163 [02:17<00:48,  1.13s/it, loss=0.1064, batch_acc=1.0000, running_acc=0.9826, grad=8.2000]Training epoch 37:  74%|███████▍  | 121/163 [02:18<00:44,  1.05s/it, loss=0.1064, batch_acc=1.0000, running_acc=0.9826, grad=8.2000]Training epoch 37:  74%|███████▍  | 121/163 [02:18<00:44,  1.05s/it, loss=0.1301, batch_acc=0.9688, running_acc=0.9824, grad=7.5634]Training epoch 37:  75%|███████▍  | 122/163 [02:19<00:41,  1.00s/it, loss=0.1301, batch_acc=0.9688, running_acc=0.9824, grad=7.5634]Training epoch 37:  75%|███████▍  | 122/163 [02:19<00:41,  1.00s/it, loss=0.1287, batch_acc=1.0000, running_acc=0.9826, grad=11.3401]Training epoch 37:  75%|███████▌  | 123/163 [02:20<00:38,  1.04it/s, loss=0.1287, batch_acc=1.0000, running_acc=0.9826, grad=11.3401]Training epoch 37:  75%|███████▌  | 123/163 [02:20<00:38,  1.04it/s, loss=0.1258, batch_acc=1.0000, running_acc=0.9827, grad=9.1622] Training epoch 37:  76%|███████▌  | 124/163 [02:22<00:50,  1.29s/it, loss=0.1258, batch_acc=1.0000, running_acc=0.9827, grad=9.1622]Training epoch 37:  76%|███████▌  | 124/163 [02:22<00:50,  1.29s/it, loss=0.2515, batch_acc=0.9375, running_acc=0.9824, grad=14.8509]Training epoch 37:  77%|███████▋  | 125/163 [02:23<00:44,  1.17s/it, loss=0.2515, batch_acc=0.9375, running_acc=0.9824, grad=14.8509]Training epoch 37:  77%|███████▋  | 125/163 [02:23<00:44,  1.17s/it, loss=0.1158, batch_acc=1.0000, running_acc=0.9825, grad=16.7077]Training epoch 37:  77%|███████▋  | 126/163 [02:24<00:40,  1.08s/it, loss=0.1158, batch_acc=1.0000, running_acc=0.9825, grad=16.7077]Training epoch 37:  77%|███████▋  | 126/163 [02:24<00:40,  1.08s/it, loss=0.1256, batch_acc=0.9688, running_acc=0.9824, grad=12.2783]Training epoch 37:  78%|███████▊  | 127/163 [02:24<00:36,  1.02s/it, loss=0.1256, batch_acc=0.9688, running_acc=0.9824, grad=12.2783]Training epoch 37:  78%|███████▊  | 127/163 [02:24<00:36,  1.02s/it, loss=0.1551, batch_acc=1.0000, running_acc=0.9825, grad=20.9696]Training epoch 37:  79%|███████▊  | 128/163 [02:27<00:54,  1.56s/it, loss=0.1551, batch_acc=1.0000, running_acc=0.9825, grad=20.9696]Training epoch 37:  79%|███████▊  | 128/163 [02:27<00:54,  1.56s/it, loss=0.1425, batch_acc=0.9375, running_acc=0.9822, grad=10.5941]Training epoch 37:  79%|███████▉  | 129/163 [02:28<00:46,  1.36s/it, loss=0.1425, batch_acc=0.9375, running_acc=0.9822, grad=10.5941]Training epoch 37:  79%|███████▉  | 129/163 [02:28<00:46,  1.36s/it, loss=0.1369, batch_acc=1.0000, running_acc=0.9823, grad=11.5694]Training epoch 37:  80%|███████▉  | 130/163 [02:29<00:40,  1.21s/it, loss=0.1369, batch_acc=1.0000, running_acc=0.9823, grad=11.5694]Training epoch 37:  80%|███████▉  | 130/163 [02:29<00:40,  1.21s/it, loss=0.1687, batch_acc=1.0000, running_acc=0.9825, grad=14.4010]Training epoch 37:  80%|████████  | 131/163 [02:30<00:35,  1.11s/it, loss=0.1687, batch_acc=1.0000, running_acc=0.9825, grad=14.4010]Training epoch 37:  80%|████████  | 131/163 [02:30<00:35,  1.11s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.9826, grad=9.0997] Training epoch 37:  81%|████████  | 132/163 [02:31<00:37,  1.20s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.9826, grad=9.0997]Training epoch 37:  81%|████████  | 132/163 [02:31<00:37,  1.20s/it, loss=0.1401, batch_acc=1.0000, running_acc=0.9827, grad=12.0087]Training epoch 37:  82%|████████▏ | 133/163 [02:32<00:33,  1.11s/it, loss=0.1401, batch_acc=1.0000, running_acc=0.9827, grad=12.0087]Training epoch 37:  82%|████████▏ | 133/163 [02:32<00:33,  1.11s/it, loss=0.1295, batch_acc=0.9688, running_acc=0.9826, grad=8.7818] Training epoch 37:  82%|████████▏ | 134/163 [02:33<00:30,  1.04s/it, loss=0.1295, batch_acc=0.9688, running_acc=0.9826, grad=8.7818]Training epoch 37:  82%|████████▏ | 134/163 [02:33<00:30,  1.04s/it, loss=0.1219, batch_acc=1.0000, running_acc=0.9827, grad=10.5087]Training epoch 37:  83%|████████▎ | 135/163 [02:34<00:27,  1.01it/s, loss=0.1219, batch_acc=1.0000, running_acc=0.9827, grad=10.5087]Training epoch 37:  83%|████████▎ | 135/163 [02:34<00:27,  1.01it/s, loss=0.1252, batch_acc=0.9688, running_acc=0.9826, grad=10.6148]Training epoch 37:  83%|████████▎ | 136/163 [02:36<00:32,  1.20s/it, loss=0.1252, batch_acc=0.9688, running_acc=0.9826, grad=10.6148]Training epoch 37:  83%|████████▎ | 136/163 [02:36<00:32,  1.20s/it, loss=0.1304, batch_acc=1.0000, running_acc=0.9828, grad=11.1065]Training epoch 37:  84%|████████▍ | 137/163 [02:37<00:28,  1.10s/it, loss=0.1304, batch_acc=1.0000, running_acc=0.9828, grad=11.1065]Training epoch 37:  84%|████████▍ | 137/163 [02:37<00:28,  1.10s/it, loss=0.1988, batch_acc=0.9688, running_acc=0.9827, grad=20.8816]Training epoch 37:  85%|████████▍ | 138/163 [02:37<00:25,  1.04s/it, loss=0.1988, batch_acc=0.9688, running_acc=0.9827, grad=20.8816]Training epoch 37:  85%|████████▍ | 138/163 [02:37<00:25,  1.04s/it, loss=0.1092, batch_acc=1.0000, running_acc=0.9828, grad=13.4482]Training epoch 37:  85%|████████▌ | 139/163 [02:38<00:23,  1.01it/s, loss=0.1092, batch_acc=1.0000, running_acc=0.9828, grad=13.4482]Training epoch 37:  85%|████████▌ | 139/163 [02:38<00:23,  1.01it/s, loss=0.1193, batch_acc=1.0000, running_acc=0.9829, grad=9.2781] Training epoch 37:  86%|████████▌ | 140/163 [02:40<00:29,  1.29s/it, loss=0.1193, batch_acc=1.0000, running_acc=0.9829, grad=9.2781]Training epoch 37:  86%|████████▌ | 140/163 [02:40<00:29,  1.29s/it, loss=0.1553, batch_acc=1.0000, running_acc=0.9830, grad=11.7400]Training epoch 37:  87%|████████▋ | 141/163 [02:41<00:25,  1.17s/it, loss=0.1553, batch_acc=1.0000, running_acc=0.9830, grad=11.7400]Training epoch 37:  87%|████████▋ | 141/163 [02:41<00:25,  1.17s/it, loss=0.0852, batch_acc=1.0000, running_acc=0.9832, grad=9.4060] Training epoch 37:  87%|████████▋ | 142/163 [02:42<00:22,  1.08s/it, loss=0.0852, batch_acc=1.0000, running_acc=0.9832, grad=9.4060]Training epoch 37:  87%|████████▋ | 142/163 [02:42<00:22,  1.08s/it, loss=0.1302, batch_acc=0.9688, running_acc=0.9831, grad=9.4614]Training epoch 37:  88%|████████▊ | 143/163 [02:43<00:20,  1.02s/it, loss=0.1302, batch_acc=0.9688, running_acc=0.9831, grad=9.4614]Training epoch 37:  88%|████████▊ | 143/163 [02:43<00:20,  1.02s/it, loss=0.1294, batch_acc=0.9375, running_acc=0.9827, grad=6.9709]Training epoch 37:  88%|████████▊ | 144/163 [02:44<00:21,  1.15s/it, loss=0.1294, batch_acc=0.9375, running_acc=0.9827, grad=6.9709]Training epoch 37:  88%|████████▊ | 144/163 [02:44<00:21,  1.15s/it, loss=0.1960, batch_acc=0.9688, running_acc=0.9826, grad=16.6394]Training epoch 37:  89%|████████▉ | 145/163 [02:45<00:19,  1.07s/it, loss=0.1960, batch_acc=0.9688, running_acc=0.9826, grad=16.6394]Training epoch 37:  89%|████████▉ | 145/163 [02:45<00:19,  1.07s/it, loss=0.1387, batch_acc=0.9688, running_acc=0.9825, grad=12.4279]Training epoch 37:  90%|████████▉ | 146/163 [02:46<00:17,  1.01s/it, loss=0.1387, batch_acc=0.9688, running_acc=0.9825, grad=12.4279]Training epoch 37:  90%|████████▉ | 146/163 [02:46<00:17,  1.01s/it, loss=0.1164, batch_acc=1.0000, running_acc=0.9827, grad=9.0832] Training epoch 37:  90%|█████████ | 147/163 [02:47<00:15,  1.03it/s, loss=0.1164, batch_acc=1.0000, running_acc=0.9827, grad=9.0832]Training epoch 37:  90%|█████████ | 147/163 [02:47<00:15,  1.03it/s, loss=0.1667, batch_acc=0.9688, running_acc=0.9826, grad=20.2259]Training epoch 37:  91%|█████████ | 148/163 [02:49<00:19,  1.27s/it, loss=0.1667, batch_acc=0.9688, running_acc=0.9826, grad=20.2259]Training epoch 37:  91%|█████████ | 148/163 [02:49<00:19,  1.27s/it, loss=0.2021, batch_acc=0.9375, running_acc=0.9823, grad=12.5950]Training epoch 37:  91%|█████████▏| 149/163 [02:50<00:16,  1.15s/it, loss=0.2021, batch_acc=0.9375, running_acc=0.9823, grad=12.5950]Training epoch 37:  91%|█████████▏| 149/163 [02:50<00:16,  1.15s/it, loss=0.1121, batch_acc=0.9688, running_acc=0.9822, grad=11.2885]Training epoch 37:  92%|█████████▏| 150/163 [02:51<00:13,  1.07s/it, loss=0.1121, batch_acc=0.9688, running_acc=0.9822, grad=11.2885]Training epoch 37:  92%|█████████▏| 150/163 [02:51<00:13,  1.07s/it, loss=0.1697, batch_acc=0.9688, running_acc=0.9821, grad=12.4997]Training epoch 37:  93%|█████████▎| 151/163 [02:52<00:12,  1.01s/it, loss=0.1697, batch_acc=0.9688, running_acc=0.9821, grad=12.4997]Training epoch 37:  93%|█████████▎| 151/163 [02:52<00:12,  1.01s/it, loss=0.1705, batch_acc=1.0000, running_acc=0.9822, grad=22.4367]Training epoch 37:  93%|█████████▎| 152/163 [02:54<00:15,  1.38s/it, loss=0.1705, batch_acc=1.0000, running_acc=0.9822, grad=22.4367]Training epoch 37:  93%|█████████▎| 152/163 [02:54<00:15,  1.38s/it, loss=0.1491, batch_acc=0.9688, running_acc=0.9821, grad=7.6871] Training epoch 37:  94%|█████████▍| 153/163 [02:55<00:12,  1.23s/it, loss=0.1491, batch_acc=0.9688, running_acc=0.9821, grad=7.6871]Training epoch 37:  94%|█████████▍| 153/163 [02:55<00:12,  1.23s/it, loss=0.1855, batch_acc=0.9688, running_acc=0.9820, grad=17.8515]Training epoch 37:  94%|█████████▍| 154/163 [02:56<00:10,  1.12s/it, loss=0.1855, batch_acc=0.9688, running_acc=0.9820, grad=17.8515]Training epoch 37:  94%|█████████▍| 154/163 [02:56<00:10,  1.12s/it, loss=0.0959, batch_acc=1.0000, running_acc=0.9821, grad=9.4870] Training epoch 37:  95%|█████████▌| 155/163 [02:56<00:08,  1.05s/it, loss=0.0959, batch_acc=1.0000, running_acc=0.9821, grad=9.4870]Training epoch 37:  95%|█████████▌| 155/163 [02:56<00:08,  1.05s/it, loss=0.1788, batch_acc=1.0000, running_acc=0.9823, grad=14.6684]Training epoch 37:  96%|█████████▌| 156/163 [02:58<00:09,  1.31s/it, loss=0.1788, batch_acc=1.0000, running_acc=0.9823, grad=14.6684]Training epoch 37:  96%|█████████▌| 156/163 [02:58<00:09,  1.31s/it, loss=0.1279, batch_acc=0.9688, running_acc=0.9822, grad=7.1342] Training epoch 37:  96%|█████████▋| 157/163 [02:59<00:07,  1.18s/it, loss=0.1279, batch_acc=0.9688, running_acc=0.9822, grad=7.1342]Training epoch 37:  96%|█████████▋| 157/163 [02:59<00:07,  1.18s/it, loss=0.0723, batch_acc=1.0000, running_acc=0.9823, grad=6.1690]Training epoch 37:  97%|█████████▋| 158/163 [03:00<00:05,  1.09s/it, loss=0.0723, batch_acc=1.0000, running_acc=0.9823, grad=6.1690]Training epoch 37:  97%|█████████▋| 158/163 [03:00<00:05,  1.09s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9824, grad=9.5645]Training epoch 37:  98%|█████████▊| 159/163 [03:01<00:04,  1.03s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9824, grad=9.5645]Training epoch 37:  98%|█████████▊| 159/163 [03:01<00:04,  1.03s/it, loss=0.1052, batch_acc=1.0000, running_acc=0.9825, grad=6.9732]Training epoch 37:  98%|█████████▊| 160/163 [03:03<00:03,  1.21s/it, loss=0.1052, batch_acc=1.0000, running_acc=0.9825, grad=6.9732]Training epoch 37:  98%|█████████▊| 160/163 [03:03<00:03,  1.21s/it, loss=0.1535, batch_acc=0.9688, running_acc=0.9824, grad=10.0956]Training epoch 37:  99%|█████████▉| 161/163 [03:04<00:02,  1.11s/it, loss=0.1535, batch_acc=0.9688, running_acc=0.9824, grad=10.0956]Training epoch 37:  99%|█████████▉| 161/163 [03:04<00:02,  1.11s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9823, grad=7.6574] Training epoch 37:  99%|█████████▉| 162/163 [03:04<00:01,  1.04s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9823, grad=7.6574]Training epoch 37:  99%|█████████▉| 162/163 [03:04<00:01,  1.04s/it, loss=0.1219, batch_acc=1.0000, running_acc=0.9824, grad=9.0746]Training epoch 37: 100%|██████████| 163/163 [03:05<00:00,  1.09it/s, loss=0.1219, batch_acc=1.0000, running_acc=0.9824, grad=9.0746]Training epoch 37: 100%|██████████| 163/163 [03:05<00:00,  1.09it/s, loss=0.1270, batch_acc=1.0000, running_acc=0.9825, grad=10.8492]Training epoch 37: 100%|██████████| 163/163 [03:05<00:00,  1.14s/it, loss=0.1270, batch_acc=1.0000, running_acc=0.9825, grad=10.8492]
Evaluation epoch 37:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 37:   4%|▎         | 1/28 [00:04<02:11,  4.86s/it]Evaluation epoch 37:   4%|▎         | 1/28 [00:04<02:11,  4.86s/it, loss=0.4272, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 37:   7%|▋         | 2/28 [00:05<00:56,  2.16s/it, loss=0.4272, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 37:   7%|▋         | 2/28 [00:05<00:56,  2.16s/it, loss=0.2840, batch_acc=1.0000, running_acc=0.9375]Evaluation epoch 37:  11%|█         | 3/28 [00:05<00:32,  1.29s/it, loss=0.2840, batch_acc=1.0000, running_acc=0.9375]Evaluation epoch 37:  11%|█         | 3/28 [00:05<00:32,  1.29s/it, loss=0.3210, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 37:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.3210, batch_acc=0.9688, running_acc=0.9479]Evaluation epoch 37:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.4163, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 37:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=0.4163, batch_acc=0.9375, running_acc=0.9453]Evaluation epoch 37:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=1.2634, batch_acc=0.7188, running_acc=0.9000]Evaluation epoch 37:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=1.2634, batch_acc=0.7188, running_acc=0.9000]Evaluation epoch 37:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=0.5868, batch_acc=0.9062, running_acc=0.9010]Evaluation epoch 37:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.5868, batch_acc=0.9062, running_acc=0.9010]Evaluation epoch 37:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.6516, batch_acc=0.8750, running_acc=0.8973]Evaluation epoch 37:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.6516, batch_acc=0.8750, running_acc=0.8973]Evaluation epoch 37:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.4360, batch_acc=0.8438, running_acc=0.8906]Evaluation epoch 37:  32%|███▏      | 9/28 [00:14<00:26,  1.39s/it, loss=0.4360, batch_acc=0.8438, running_acc=0.8906]Evaluation epoch 37:  32%|███▏      | 9/28 [00:14<00:26,  1.39s/it, loss=0.4366, batch_acc=0.9062, running_acc=0.8924]Evaluation epoch 37:  36%|███▌      | 10/28 [00:14<00:18,  1.04s/it, loss=0.4366, batch_acc=0.9062, running_acc=0.8924]Evaluation epoch 37:  36%|███▌      | 10/28 [00:14<00:18,  1.04s/it, loss=0.4836, batch_acc=0.9062, running_acc=0.8938]Evaluation epoch 37:  39%|███▉      | 11/28 [00:15<00:13,  1.25it/s, loss=0.4836, batch_acc=0.9062, running_acc=0.8938]Evaluation epoch 37:  39%|███▉      | 11/28 [00:15<00:13,  1.25it/s, loss=0.3301, batch_acc=0.9375, running_acc=0.8977]Evaluation epoch 37:  43%|████▎     | 12/28 [00:20<00:33,  2.10s/it, loss=0.3301, batch_acc=0.9375, running_acc=0.8977]Evaluation epoch 37:  43%|████▎     | 12/28 [00:20<00:33,  2.10s/it, loss=0.9888, batch_acc=0.7812, running_acc=0.8880]Evaluation epoch 37:  46%|████▋     | 13/28 [00:20<00:23,  1.54s/it, loss=0.9888, batch_acc=0.7812, running_acc=0.8880]Evaluation epoch 37:  46%|████▋     | 13/28 [00:20<00:23,  1.54s/it, loss=0.3092, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 37:  50%|█████     | 14/28 [00:20<00:16,  1.15s/it, loss=0.3092, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 37:  50%|█████     | 14/28 [00:20<00:16,  1.15s/it, loss=0.8410, batch_acc=0.7812, running_acc=0.8839]Evaluation epoch 37:  54%|█████▎    | 15/28 [00:20<00:11,  1.13it/s, loss=0.8410, batch_acc=0.7812, running_acc=0.8839]Evaluation epoch 37:  54%|█████▎    | 15/28 [00:20<00:11,  1.13it/s, loss=1.0002, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 37:  57%|█████▋    | 16/28 [00:23<00:18,  1.50s/it, loss=1.0002, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 37:  57%|█████▋    | 16/28 [00:23<00:18,  1.50s/it, loss=0.7322, batch_acc=0.7500, running_acc=0.8730]Evaluation epoch 37:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.7322, batch_acc=0.7500, running_acc=0.8730]Evaluation epoch 37:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.5841, batch_acc=0.7500, running_acc=0.8658]Evaluation epoch 37:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5841, batch_acc=0.7500, running_acc=0.8658]Evaluation epoch 37:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5433, batch_acc=0.8750, running_acc=0.8663]Evaluation epoch 37:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.5433, batch_acc=0.8750, running_acc=0.8663]Evaluation epoch 37:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.8881, batch_acc=0.6250, running_acc=0.8536]Evaluation epoch 37:  71%|███████▏  | 20/28 [00:27<00:10,  1.36s/it, loss=0.8881, batch_acc=0.6250, running_acc=0.8536]Evaluation epoch 37:  71%|███████▏  | 20/28 [00:27<00:10,  1.36s/it, loss=0.6232, batch_acc=0.7188, running_acc=0.8469]Evaluation epoch 37:  75%|███████▌  | 21/28 [00:27<00:07,  1.03s/it, loss=0.6232, batch_acc=0.7188, running_acc=0.8469]Evaluation epoch 37:  75%|███████▌  | 21/28 [00:27<00:07,  1.03s/it, loss=0.5639, batch_acc=0.8438, running_acc=0.8467]Evaluation epoch 37:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5639, batch_acc=0.8438, running_acc=0.8467]Evaluation epoch 37:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.4530, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 37:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=0.4530, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 37:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=0.9182, batch_acc=0.7500, running_acc=0.8478]Evaluation epoch 37:  86%|████████▌ | 24/28 [00:33<00:08,  2.05s/it, loss=0.9182, batch_acc=0.7500, running_acc=0.8478]Evaluation epoch 37:  86%|████████▌ | 24/28 [00:33<00:08,  2.05s/it, loss=0.3575, batch_acc=0.9375, running_acc=0.8516]Evaluation epoch 37:  89%|████████▉ | 25/28 [00:33<00:04,  1.51s/it, loss=0.3575, batch_acc=0.9375, running_acc=0.8516]Evaluation epoch 37:  89%|████████▉ | 25/28 [00:33<00:04,  1.51s/it, loss=0.1474, batch_acc=1.0000, running_acc=0.8575]Evaluation epoch 37:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.1474, batch_acc=1.0000, running_acc=0.8575]Evaluation epoch 37:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.6017, batch_acc=0.8438, running_acc=0.8570]Evaluation epoch 37:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.6017, batch_acc=0.8438, running_acc=0.8570]Evaluation epoch 37:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.8598, batch_acc=0.7812, running_acc=0.8542]Evaluation epoch 37: 100%|██████████| 28/28 [00:34<00:00,  1.14it/s, loss=1.2636, batch_acc=0.6667, running_acc=0.8535]Evaluation epoch 37: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=1.2636, batch_acc=0.6667, running_acc=0.8535]
Training epoch 38:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 38:   1%|          | 1/163 [00:05<15:08,  5.61s/it]Training epoch 38:   1%|          | 1/163 [00:05<15:08,  5.61s/it, loss=0.1174, batch_acc=1.0000, running_acc=1.0000, grad=11.0838]Training epoch 38:   1%|          | 2/163 [00:06<07:35,  2.83s/it, loss=0.1174, batch_acc=1.0000, running_acc=1.0000, grad=11.0838]Training epoch 38:   1%|          | 2/163 [00:06<07:35,  2.83s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9844, grad=6.8324] Training epoch 38:   2%|▏         | 3/163 [00:07<05:10,  1.94s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9844, grad=6.8324]Training epoch 38:   2%|▏         | 3/163 [00:07<05:10,  1.94s/it, loss=0.1312, batch_acc=0.9688, running_acc=0.9792, grad=6.7862]Training epoch 38:   2%|▏         | 4/163 [00:09<05:27,  2.06s/it, loss=0.1312, batch_acc=0.9688, running_acc=0.9792, grad=6.7862]Training epoch 38:   2%|▏         | 4/163 [00:09<05:27,  2.06s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9844, grad=8.9164]Training epoch 38:   3%|▎         | 5/163 [00:10<04:17,  1.63s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9844, grad=8.9164]Training epoch 38:   3%|▎         | 5/163 [00:10<04:17,  1.63s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9875, grad=7.4332]Training epoch 38:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9875, grad=7.4332]Training epoch 38:   4%|▎         | 6/163 [00:11<03:36,  1.38s/it, loss=0.0852, batch_acc=1.0000, running_acc=0.9896, grad=5.2219]Training epoch 38:   4%|▍         | 7/163 [00:12<03:09,  1.21s/it, loss=0.0852, batch_acc=1.0000, running_acc=0.9896, grad=5.2219]Training epoch 38:   4%|▍         | 7/163 [00:12<03:09,  1.21s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9911, grad=11.9282]Training epoch 38:   5%|▍         | 8/163 [00:13<03:26,  1.33s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9911, grad=11.9282]Training epoch 38:   5%|▍         | 8/163 [00:13<03:26,  1.33s/it, loss=0.1167, batch_acc=1.0000, running_acc=0.9922, grad=11.2966]Training epoch 38:   6%|▌         | 9/163 [00:14<03:03,  1.19s/it, loss=0.1167, batch_acc=1.0000, running_acc=0.9922, grad=11.2966]Training epoch 38:   6%|▌         | 9/163 [00:14<03:03,  1.19s/it, loss=0.1339, batch_acc=0.9688, running_acc=0.9896, grad=7.6200] Training epoch 38:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=0.1339, batch_acc=0.9688, running_acc=0.9896, grad=7.6200]Training epoch 38:   6%|▌         | 10/163 [00:15<02:47,  1.10s/it, loss=0.1443, batch_acc=1.0000, running_acc=0.9906, grad=17.1588]Training epoch 38:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=0.1443, batch_acc=1.0000, running_acc=0.9906, grad=17.1588]Training epoch 38:   7%|▋         | 11/163 [00:16<02:36,  1.03s/it, loss=0.2000, batch_acc=1.0000, running_acc=0.9915, grad=22.8208]Training epoch 38:   7%|▋         | 12/163 [00:17<02:53,  1.15s/it, loss=0.2000, batch_acc=1.0000, running_acc=0.9915, grad=22.8208]Training epoch 38:   7%|▋         | 12/163 [00:17<02:53,  1.15s/it, loss=0.0908, batch_acc=1.0000, running_acc=0.9922, grad=5.9776] Training epoch 38:   8%|▊         | 13/163 [00:18<02:43,  1.09s/it, loss=0.0908, batch_acc=1.0000, running_acc=0.9922, grad=5.9776]Training epoch 38:   8%|▊         | 13/163 [00:18<02:43,  1.09s/it, loss=0.1349, batch_acc=0.9375, running_acc=0.9880, grad=9.9770]Training epoch 38:   9%|▊         | 14/163 [00:19<02:32,  1.03s/it, loss=0.1349, batch_acc=0.9375, running_acc=0.9880, grad=9.9770]Training epoch 38:   9%|▊         | 14/163 [00:19<02:32,  1.03s/it, loss=0.1073, batch_acc=1.0000, running_acc=0.9888, grad=7.6229]Training epoch 38:   9%|▉         | 15/163 [00:20<02:25,  1.02it/s, loss=0.1073, batch_acc=1.0000, running_acc=0.9888, grad=7.6229]Training epoch 38:   9%|▉         | 15/163 [00:20<02:25,  1.02it/s, loss=0.1976, batch_acc=0.9688, running_acc=0.9875, grad=14.0907]Training epoch 38:  10%|▉         | 16/163 [00:22<02:54,  1.19s/it, loss=0.1976, batch_acc=0.9688, running_acc=0.9875, grad=14.0907]Training epoch 38:  10%|▉         | 16/163 [00:22<02:54,  1.19s/it, loss=0.1145, batch_acc=1.0000, running_acc=0.9883, grad=9.0470] Training epoch 38:  10%|█         | 17/163 [00:23<02:44,  1.12s/it, loss=0.1145, batch_acc=1.0000, running_acc=0.9883, grad=9.0470]Training epoch 38:  10%|█         | 17/163 [00:23<02:44,  1.12s/it, loss=0.1517, batch_acc=0.9688, running_acc=0.9871, grad=15.3869]Training epoch 38:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.1517, batch_acc=0.9688, running_acc=0.9871, grad=15.3869]Training epoch 38:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.1618, batch_acc=0.9688, running_acc=0.9861, grad=13.6450]Training epoch 38:  12%|█▏        | 19/163 [00:25<02:27,  1.03s/it, loss=0.1618, batch_acc=0.9688, running_acc=0.9861, grad=13.6450]Training epoch 38:  12%|█▏        | 19/163 [00:25<02:27,  1.03s/it, loss=0.1886, batch_acc=0.9375, running_acc=0.9836, grad=16.2582]Training epoch 38:  12%|█▏        | 20/163 [00:26<02:34,  1.08s/it, loss=0.1886, batch_acc=0.9375, running_acc=0.9836, grad=16.2582]Training epoch 38:  12%|█▏        | 20/163 [00:26<02:34,  1.08s/it, loss=0.1104, batch_acc=1.0000, running_acc=0.9844, grad=9.8230] Training epoch 38:  13%|█▎        | 21/163 [00:27<02:39,  1.12s/it, loss=0.1104, batch_acc=1.0000, running_acc=0.9844, grad=9.8230]Training epoch 38:  13%|█▎        | 21/163 [00:27<02:39,  1.12s/it, loss=0.0946, batch_acc=1.0000, running_acc=0.9851, grad=8.2829]Training epoch 38:  13%|█▎        | 22/163 [00:28<02:28,  1.05s/it, loss=0.0946, batch_acc=1.0000, running_acc=0.9851, grad=8.2829]Training epoch 38:  13%|█▎        | 22/163 [00:28<02:28,  1.05s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9844, grad=6.9564]Training epoch 38:  14%|█▍        | 23/163 [00:29<02:19,  1.00it/s, loss=0.1050, batch_acc=0.9688, running_acc=0.9844, grad=6.9564]Training epoch 38:  14%|█▍        | 23/163 [00:29<02:19,  1.00it/s, loss=0.1028, batch_acc=1.0000, running_acc=0.9851, grad=9.7645]Training epoch 38:  15%|█▍        | 24/163 [00:30<02:27,  1.06s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9851, grad=9.7645]Training epoch 38:  15%|█▍        | 24/163 [00:30<02:27,  1.06s/it, loss=0.0881, batch_acc=1.0000, running_acc=0.9857, grad=7.6670]Training epoch 38:  15%|█▌        | 25/163 [00:31<02:31,  1.10s/it, loss=0.0881, batch_acc=1.0000, running_acc=0.9857, grad=7.6670]Training epoch 38:  15%|█▌        | 25/163 [00:31<02:31,  1.10s/it, loss=0.1105, batch_acc=1.0000, running_acc=0.9862, grad=8.1771]Training epoch 38:  16%|█▌        | 26/163 [00:32<02:21,  1.03s/it, loss=0.1105, batch_acc=1.0000, running_acc=0.9862, grad=8.1771]Training epoch 38:  16%|█▌        | 26/163 [00:32<02:21,  1.03s/it, loss=0.1037, batch_acc=1.0000, running_acc=0.9868, grad=8.5116]Training epoch 38:  17%|█▋        | 27/163 [00:33<02:26,  1.08s/it, loss=0.1037, batch_acc=1.0000, running_acc=0.9868, grad=8.5116]Training epoch 38:  17%|█▋        | 27/163 [00:33<02:26,  1.08s/it, loss=0.1249, batch_acc=0.9688, running_acc=0.9861, grad=10.2850]Training epoch 38:  17%|█▋        | 28/163 [00:34<02:29,  1.11s/it, loss=0.1249, batch_acc=0.9688, running_acc=0.9861, grad=10.2850]Training epoch 38:  17%|█▋        | 28/163 [00:34<02:29,  1.11s/it, loss=0.1514, batch_acc=0.9375, running_acc=0.9844, grad=11.7895]Training epoch 38:  18%|█▊        | 29/163 [00:35<02:19,  1.04s/it, loss=0.1514, batch_acc=0.9375, running_acc=0.9844, grad=11.7895]Training epoch 38:  18%|█▊        | 29/163 [00:35<02:19,  1.04s/it, loss=0.1349, batch_acc=0.9688, running_acc=0.9838, grad=12.1853]Training epoch 38:  18%|█▊        | 30/163 [00:36<02:11,  1.01it/s, loss=0.1349, batch_acc=0.9688, running_acc=0.9838, grad=12.1853]Training epoch 38:  18%|█▊        | 30/163 [00:36<02:11,  1.01it/s, loss=0.1151, batch_acc=1.0000, running_acc=0.9844, grad=8.5126] Training epoch 38:  19%|█▉        | 31/163 [00:38<02:27,  1.12s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9844, grad=8.5126]Training epoch 38:  19%|█▉        | 31/163 [00:38<02:27,  1.12s/it, loss=0.1546, batch_acc=1.0000, running_acc=0.9849, grad=15.6152]Training epoch 38:  20%|█▉        | 32/163 [00:38<02:16,  1.04s/it, loss=0.1546, batch_acc=1.0000, running_acc=0.9849, grad=15.6152]Training epoch 38:  20%|█▉        | 32/163 [00:38<02:16,  1.04s/it, loss=0.1046, batch_acc=1.0000, running_acc=0.9854, grad=8.4205] Training epoch 38:  20%|██        | 33/163 [00:40<02:32,  1.17s/it, loss=0.1046, batch_acc=1.0000, running_acc=0.9854, grad=8.4205]Training epoch 38:  20%|██        | 33/163 [00:40<02:32,  1.17s/it, loss=0.0754, batch_acc=1.0000, running_acc=0.9858, grad=6.3633]Training epoch 38:  21%|██        | 34/163 [00:41<02:20,  1.09s/it, loss=0.0754, batch_acc=1.0000, running_acc=0.9858, grad=6.3633]Training epoch 38:  21%|██        | 34/163 [00:41<02:20,  1.09s/it, loss=0.1160, batch_acc=1.0000, running_acc=0.9862, grad=10.2176]Training epoch 38:  21%|██▏       | 35/163 [00:42<02:20,  1.10s/it, loss=0.1160, batch_acc=1.0000, running_acc=0.9862, grad=10.2176]Training epoch 38:  21%|██▏       | 35/163 [00:42<02:20,  1.10s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9866, grad=12.7909]Training epoch 38:  22%|██▏       | 36/163 [00:43<02:11,  1.03s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9866, grad=12.7909]Training epoch 38:  22%|██▏       | 36/163 [00:43<02:11,  1.03s/it, loss=0.1140, batch_acc=0.9688, running_acc=0.9861, grad=7.4069] Training epoch 38:  23%|██▎       | 37/163 [00:44<02:22,  1.13s/it, loss=0.1140, batch_acc=0.9688, running_acc=0.9861, grad=7.4069]Training epoch 38:  23%|██▎       | 37/163 [00:44<02:22,  1.13s/it, loss=0.1927, batch_acc=1.0000, running_acc=0.9865, grad=10.4424]Training epoch 38:  23%|██▎       | 38/163 [00:45<02:11,  1.06s/it, loss=0.1927, batch_acc=1.0000, running_acc=0.9865, grad=10.4424]Training epoch 38:  23%|██▎       | 38/163 [00:45<02:11,  1.06s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9868, grad=12.6611]Training epoch 38:  24%|██▍       | 39/163 [00:46<02:15,  1.09s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9868, grad=12.6611]Training epoch 38:  24%|██▍       | 39/163 [00:46<02:15,  1.09s/it, loss=0.1593, batch_acc=0.9375, running_acc=0.9856, grad=11.0018]Training epoch 38:  25%|██▍       | 40/163 [00:47<02:06,  1.03s/it, loss=0.1593, batch_acc=0.9375, running_acc=0.9856, grad=11.0018]Training epoch 38:  25%|██▍       | 40/163 [00:47<02:06,  1.03s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9859, grad=13.9824]Training epoch 38:  25%|██▌       | 41/163 [00:48<02:15,  1.11s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9859, grad=13.9824]Training epoch 38:  25%|██▌       | 41/163 [00:48<02:15,  1.11s/it, loss=0.1106, batch_acc=1.0000, running_acc=0.9863, grad=9.1075] Training epoch 38:  26%|██▌       | 42/163 [00:49<02:06,  1.04s/it, loss=0.1106, batch_acc=1.0000, running_acc=0.9863, grad=9.1075]Training epoch 38:  26%|██▌       | 42/163 [00:49<02:06,  1.04s/it, loss=0.1273, batch_acc=1.0000, running_acc=0.9866, grad=11.8035]Training epoch 38:  26%|██▋       | 43/163 [00:51<02:18,  1.16s/it, loss=0.1273, batch_acc=1.0000, running_acc=0.9866, grad=11.8035]Training epoch 38:  26%|██▋       | 43/163 [00:51<02:18,  1.16s/it, loss=0.1567, batch_acc=0.9688, running_acc=0.9862, grad=14.2390]Training epoch 38:  27%|██▋       | 44/163 [00:52<02:07,  1.07s/it, loss=0.1567, batch_acc=0.9688, running_acc=0.9862, grad=14.2390]Training epoch 38:  27%|██▋       | 44/163 [00:52<02:07,  1.07s/it, loss=0.1181, batch_acc=1.0000, running_acc=0.9865, grad=9.1997] Training epoch 38:  28%|██▊       | 45/163 [00:52<01:59,  1.02s/it, loss=0.1181, batch_acc=1.0000, running_acc=0.9865, grad=9.1997]Training epoch 38:  28%|██▊       | 45/163 [00:52<01:59,  1.02s/it, loss=0.1241, batch_acc=1.0000, running_acc=0.9868, grad=10.4612]Training epoch 38:  28%|██▊       | 46/163 [00:53<01:54,  1.03it/s, loss=0.1241, batch_acc=1.0000, running_acc=0.9868, grad=10.4612]Training epoch 38:  28%|██▊       | 46/163 [00:53<01:54,  1.03it/s, loss=0.1399, batch_acc=0.9375, running_acc=0.9857, grad=15.3886]Training epoch 38:  29%|██▉       | 47/163 [00:55<02:13,  1.15s/it, loss=0.1399, batch_acc=0.9375, running_acc=0.9857, grad=15.3886]Training epoch 38:  29%|██▉       | 47/163 [00:55<02:13,  1.15s/it, loss=0.1220, batch_acc=0.9688, running_acc=0.9854, grad=7.1614] Training epoch 38:  29%|██▉       | 48/163 [00:56<02:02,  1.07s/it, loss=0.1220, batch_acc=0.9688, running_acc=0.9854, grad=7.1614]Training epoch 38:  29%|██▉       | 48/163 [00:56<02:02,  1.07s/it, loss=0.1723, batch_acc=0.9688, running_acc=0.9850, grad=10.7321]Training epoch 38:  30%|███       | 49/163 [00:57<01:58,  1.04s/it, loss=0.1723, batch_acc=0.9688, running_acc=0.9850, grad=10.7321]Training epoch 38:  30%|███       | 49/163 [00:57<01:58,  1.04s/it, loss=0.1813, batch_acc=0.9688, running_acc=0.9847, grad=13.6530]Training epoch 38:  31%|███       | 50/163 [00:58<01:51,  1.01it/s, loss=0.1813, batch_acc=0.9688, running_acc=0.9847, grad=13.6530]Training epoch 38:  31%|███       | 50/163 [00:58<01:51,  1.01it/s, loss=0.1258, batch_acc=1.0000, running_acc=0.9850, grad=9.6938] Training epoch 38:  31%|███▏      | 51/163 [00:59<02:08,  1.15s/it, loss=0.1258, batch_acc=1.0000, running_acc=0.9850, grad=9.6938]Training epoch 38:  31%|███▏      | 51/163 [00:59<02:08,  1.15s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9853, grad=9.4685]Training epoch 38:  32%|███▏      | 52/163 [01:00<01:58,  1.07s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9853, grad=9.4685]Training epoch 38:  32%|███▏      | 52/163 [01:00<01:58,  1.07s/it, loss=0.1542, batch_acc=0.9688, running_acc=0.9850, grad=9.7408]Training epoch 38:  33%|███▎      | 53/163 [01:01<01:51,  1.01s/it, loss=0.1542, batch_acc=0.9688, running_acc=0.9850, grad=9.7408]Training epoch 38:  33%|███▎      | 53/163 [01:01<01:51,  1.01s/it, loss=0.1513, batch_acc=0.9375, running_acc=0.9841, grad=10.1469]Training epoch 38:  33%|███▎      | 54/163 [01:02<01:46,  1.03it/s, loss=0.1513, batch_acc=0.9375, running_acc=0.9841, grad=10.1469]Training epoch 38:  33%|███▎      | 54/163 [01:02<01:46,  1.03it/s, loss=0.1227, batch_acc=1.0000, running_acc=0.9844, grad=16.1704]Training epoch 38:  34%|███▎      | 55/163 [01:04<02:16,  1.27s/it, loss=0.1227, batch_acc=1.0000, running_acc=0.9844, grad=16.1704]Training epoch 38:  34%|███▎      | 55/163 [01:04<02:16,  1.27s/it, loss=0.1697, batch_acc=1.0000, running_acc=0.9847, grad=16.6608]Training epoch 38:  34%|███▍      | 56/163 [01:05<02:03,  1.15s/it, loss=0.1697, batch_acc=1.0000, running_acc=0.9847, grad=16.6608]Training epoch 38:  34%|███▍      | 56/163 [01:05<02:03,  1.15s/it, loss=0.1279, batch_acc=1.0000, running_acc=0.9849, grad=10.0690]Training epoch 38:  35%|███▍      | 57/163 [01:06<01:57,  1.10s/it, loss=0.1279, batch_acc=1.0000, running_acc=0.9849, grad=10.0690]Training epoch 38:  35%|███▍      | 57/163 [01:06<01:57,  1.10s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9852, grad=6.8712] Training epoch 38:  36%|███▌      | 58/163 [01:07<01:48,  1.04s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9852, grad=6.8712]Training epoch 38:  36%|███▌      | 58/163 [01:07<01:48,  1.04s/it, loss=0.1476, batch_acc=0.9688, running_acc=0.9849, grad=10.4590]Training epoch 38:  36%|███▌      | 59/163 [01:08<01:56,  1.12s/it, loss=0.1476, batch_acc=0.9688, running_acc=0.9849, grad=10.4590]Training epoch 38:  36%|███▌      | 59/163 [01:08<01:56,  1.12s/it, loss=0.1171, batch_acc=1.0000, running_acc=0.9852, grad=10.9689]Training epoch 38:  37%|███▋      | 60/163 [01:09<01:48,  1.05s/it, loss=0.1171, batch_acc=1.0000, running_acc=0.9852, grad=10.9689]Training epoch 38:  37%|███▋      | 60/163 [01:09<01:48,  1.05s/it, loss=0.1579, batch_acc=1.0000, running_acc=0.9854, grad=20.5034]Training epoch 38:  37%|███▋      | 61/163 [01:10<01:42,  1.00s/it, loss=0.1579, batch_acc=1.0000, running_acc=0.9854, grad=20.5034]Training epoch 38:  37%|███▋      | 61/163 [01:10<01:42,  1.00s/it, loss=0.2020, batch_acc=0.9375, running_acc=0.9846, grad=12.2199]Training epoch 38:  38%|███▊      | 62/163 [01:10<01:37,  1.04it/s, loss=0.2020, batch_acc=0.9375, running_acc=0.9846, grad=12.2199]Training epoch 38:  38%|███▊      | 62/163 [01:10<01:37,  1.04it/s, loss=0.1534, batch_acc=1.0000, running_acc=0.9849, grad=12.6304]Training epoch 38:  39%|███▊      | 63/163 [01:12<01:43,  1.03s/it, loss=0.1534, batch_acc=1.0000, running_acc=0.9849, grad=12.6304]Training epoch 38:  39%|███▊      | 63/163 [01:12<01:43,  1.03s/it, loss=0.1213, batch_acc=0.9688, running_acc=0.9846, grad=10.0121]Training epoch 38:  39%|███▉      | 64/163 [01:13<01:37,  1.01it/s, loss=0.1213, batch_acc=0.9688, running_acc=0.9846, grad=10.0121]Training epoch 38:  39%|███▉      | 64/163 [01:13<01:37,  1.01it/s, loss=0.1249, batch_acc=1.0000, running_acc=0.9849, grad=12.4485]Training epoch 38:  40%|███▉      | 65/163 [01:13<01:33,  1.05it/s, loss=0.1249, batch_acc=1.0000, running_acc=0.9849, grad=12.4485]Training epoch 38:  40%|███▉      | 65/163 [01:13<01:33,  1.05it/s, loss=0.0880, batch_acc=1.0000, running_acc=0.9851, grad=7.7919] Training epoch 38:  40%|████      | 66/163 [01:14<01:30,  1.07it/s, loss=0.0880, batch_acc=1.0000, running_acc=0.9851, grad=7.7919]Training epoch 38:  40%|████      | 66/163 [01:14<01:30,  1.07it/s, loss=0.1563, batch_acc=0.9375, running_acc=0.9844, grad=12.8190]Training epoch 38:  41%|████      | 67/163 [01:16<01:40,  1.04s/it, loss=0.1563, batch_acc=0.9375, running_acc=0.9844, grad=12.8190]Training epoch 38:  41%|████      | 67/163 [01:16<01:40,  1.04s/it, loss=0.1948, batch_acc=0.9688, running_acc=0.9841, grad=10.8451]Training epoch 38:  42%|████▏     | 68/163 [01:17<01:34,  1.01it/s, loss=0.1948, batch_acc=0.9688, running_acc=0.9841, grad=10.8451]Training epoch 38:  42%|████▏     | 68/163 [01:17<01:34,  1.01it/s, loss=0.1681, batch_acc=0.9688, running_acc=0.9839, grad=17.9055]Training epoch 38:  42%|████▏     | 69/163 [01:18<01:35,  1.02s/it, loss=0.1681, batch_acc=0.9688, running_acc=0.9839, grad=17.9055]Training epoch 38:  42%|████▏     | 69/163 [01:18<01:35,  1.02s/it, loss=0.1326, batch_acc=0.9688, running_acc=0.9837, grad=18.1744]Training epoch 38:  43%|████▎     | 70/163 [01:18<01:30,  1.02it/s, loss=0.1326, batch_acc=0.9688, running_acc=0.9837, grad=18.1744]Training epoch 38:  43%|████▎     | 70/163 [01:18<01:30,  1.02it/s, loss=0.1465, batch_acc=0.9688, running_acc=0.9835, grad=9.7056] Training epoch 38:  44%|████▎     | 71/163 [01:20<01:34,  1.02s/it, loss=0.1465, batch_acc=0.9688, running_acc=0.9835, grad=9.7056]Training epoch 38:  44%|████▎     | 71/163 [01:20<01:34,  1.02s/it, loss=0.1411, batch_acc=0.9688, running_acc=0.9833, grad=10.4988]Training epoch 38:  44%|████▍     | 72/163 [01:20<01:29,  1.02it/s, loss=0.1411, batch_acc=0.9688, running_acc=0.9833, grad=10.4988]Training epoch 38:  44%|████▍     | 72/163 [01:20<01:29,  1.02it/s, loss=0.1438, batch_acc=0.9688, running_acc=0.9831, grad=11.4585]Training epoch 38:  45%|████▍     | 73/163 [01:22<01:47,  1.19s/it, loss=0.1438, batch_acc=0.9688, running_acc=0.9831, grad=11.4585]Training epoch 38:  45%|████▍     | 73/163 [01:22<01:47,  1.19s/it, loss=0.1683, batch_acc=0.9688, running_acc=0.9829, grad=12.1809]Training epoch 38:  45%|████▌     | 74/163 [01:23<01:37,  1.10s/it, loss=0.1683, batch_acc=0.9688, running_acc=0.9829, grad=12.1809]Training epoch 38:  45%|████▌     | 74/163 [01:23<01:37,  1.10s/it, loss=0.1435, batch_acc=0.9688, running_acc=0.9827, grad=9.4979] Training epoch 38:  46%|████▌     | 75/163 [01:24<01:38,  1.12s/it, loss=0.1435, batch_acc=0.9688, running_acc=0.9827, grad=9.4979]Training epoch 38:  46%|████▌     | 75/163 [01:24<01:38,  1.12s/it, loss=0.1547, batch_acc=1.0000, running_acc=0.9829, grad=13.6641]Training epoch 38:  47%|████▋     | 76/163 [01:25<01:31,  1.05s/it, loss=0.1547, batch_acc=1.0000, running_acc=0.9829, grad=13.6641]Training epoch 38:  47%|████▋     | 76/163 [01:25<01:31,  1.05s/it, loss=0.1335, batch_acc=1.0000, running_acc=0.9831, grad=11.6435]Training epoch 38:  47%|████▋     | 77/163 [01:26<01:32,  1.08s/it, loss=0.1335, batch_acc=1.0000, running_acc=0.9831, grad=11.6435]Training epoch 38:  47%|████▋     | 77/163 [01:26<01:32,  1.08s/it, loss=0.1545, batch_acc=0.9688, running_acc=0.9830, grad=10.6759]Training epoch 38:  48%|████▊     | 78/163 [01:27<01:26,  1.02s/it, loss=0.1545, batch_acc=0.9688, running_acc=0.9830, grad=10.6759]Training epoch 38:  48%|████▊     | 78/163 [01:27<01:26,  1.02s/it, loss=0.1999, batch_acc=0.9688, running_acc=0.9828, grad=11.3335]Training epoch 38:  48%|████▊     | 79/163 [01:28<01:26,  1.03s/it, loss=0.1999, batch_acc=0.9688, running_acc=0.9828, grad=11.3335]Training epoch 38:  48%|████▊     | 79/163 [01:28<01:26,  1.03s/it, loss=0.1685, batch_acc=0.9688, running_acc=0.9826, grad=14.3257]Training epoch 38:  49%|████▉     | 80/163 [01:29<01:21,  1.01it/s, loss=0.1685, batch_acc=0.9688, running_acc=0.9826, grad=14.3257]Training epoch 38:  49%|████▉     | 80/163 [01:29<01:21,  1.01it/s, loss=0.1252, batch_acc=1.0000, running_acc=0.9828, grad=10.1295]Training epoch 38:  50%|████▉     | 81/163 [01:31<01:35,  1.16s/it, loss=0.1252, batch_acc=1.0000, running_acc=0.9828, grad=10.1295]Training epoch 38:  50%|████▉     | 81/163 [01:31<01:35,  1.16s/it, loss=0.0821, batch_acc=1.0000, running_acc=0.9830, grad=7.9579] Training epoch 38:  50%|█████     | 82/163 [01:32<01:27,  1.08s/it, loss=0.0821, batch_acc=1.0000, running_acc=0.9830, grad=7.9579]Training epoch 38:  50%|█████     | 82/163 [01:32<01:27,  1.08s/it, loss=0.1176, batch_acc=1.0000, running_acc=0.9832, grad=9.5408]Training epoch 38:  51%|█████     | 83/163 [01:32<01:23,  1.05s/it, loss=0.1176, batch_acc=1.0000, running_acc=0.9832, grad=9.5408]Training epoch 38:  51%|█████     | 83/163 [01:32<01:23,  1.05s/it, loss=0.2008, batch_acc=0.9062, running_acc=0.9823, grad=18.7864]Training epoch 38:  52%|█████▏    | 84/163 [01:33<01:18,  1.00it/s, loss=0.2008, batch_acc=0.9062, running_acc=0.9823, grad=18.7864]Training epoch 38:  52%|█████▏    | 84/163 [01:33<01:18,  1.00it/s, loss=0.1650, batch_acc=0.9688, running_acc=0.9821, grad=15.9054]Training epoch 38:  52%|█████▏    | 85/163 [01:35<01:34,  1.21s/it, loss=0.1650, batch_acc=0.9688, running_acc=0.9821, grad=15.9054]Training epoch 38:  52%|█████▏    | 85/163 [01:35<01:34,  1.21s/it, loss=0.1159, batch_acc=1.0000, running_acc=0.9824, grad=10.4949]Training epoch 38:  53%|█████▎    | 86/163 [01:36<01:25,  1.11s/it, loss=0.1159, batch_acc=1.0000, running_acc=0.9824, grad=10.4949]Training epoch 38:  53%|█████▎    | 86/163 [01:36<01:25,  1.11s/it, loss=0.1199, batch_acc=0.9688, running_acc=0.9822, grad=9.7034] Training epoch 38:  53%|█████▎    | 87/163 [01:37<01:26,  1.14s/it, loss=0.1199, batch_acc=0.9688, running_acc=0.9822, grad=9.7034]Training epoch 38:  53%|█████▎    | 87/163 [01:37<01:26,  1.14s/it, loss=0.1006, batch_acc=1.0000, running_acc=0.9824, grad=9.9716]Training epoch 38:  54%|█████▍    | 88/163 [01:38<01:19,  1.06s/it, loss=0.1006, batch_acc=1.0000, running_acc=0.9824, grad=9.9716]Training epoch 38:  54%|█████▍    | 88/163 [01:38<01:19,  1.06s/it, loss=0.1507, batch_acc=0.9688, running_acc=0.9822, grad=9.3723]Training epoch 38:  55%|█████▍    | 89/163 [01:40<01:32,  1.25s/it, loss=0.1507, batch_acc=0.9688, running_acc=0.9822, grad=9.3723]Training epoch 38:  55%|█████▍    | 89/163 [01:40<01:32,  1.25s/it, loss=0.1606, batch_acc=1.0000, running_acc=0.9824, grad=10.1796]Training epoch 38:  55%|█████▌    | 90/163 [01:41<01:23,  1.14s/it, loss=0.1606, batch_acc=1.0000, running_acc=0.9824, grad=10.1796]Training epoch 38:  55%|█████▌    | 90/163 [01:41<01:23,  1.14s/it, loss=0.1058, batch_acc=1.0000, running_acc=0.9826, grad=10.4477]Training epoch 38:  56%|█████▌    | 91/163 [01:41<01:16,  1.06s/it, loss=0.1058, batch_acc=1.0000, running_acc=0.9826, grad=10.4477]Training epoch 38:  56%|█████▌    | 91/163 [01:41<01:16,  1.06s/it, loss=0.1438, batch_acc=0.9688, running_acc=0.9825, grad=15.1703]Training epoch 38:  56%|█████▋    | 92/163 [01:42<01:11,  1.01s/it, loss=0.1438, batch_acc=0.9688, running_acc=0.9825, grad=15.1703]Training epoch 38:  56%|█████▋    | 92/163 [01:42<01:11,  1.01s/it, loss=0.1490, batch_acc=0.9688, running_acc=0.9823, grad=12.2499]Training epoch 38:  57%|█████▋    | 93/163 [01:44<01:24,  1.20s/it, loss=0.1490, batch_acc=0.9688, running_acc=0.9823, grad=12.2499]Training epoch 38:  57%|█████▋    | 93/163 [01:44<01:24,  1.20s/it, loss=0.0799, batch_acc=1.0000, running_acc=0.9825, grad=7.7547] Training epoch 38:  58%|█████▊    | 94/163 [01:45<01:16,  1.10s/it, loss=0.0799, batch_acc=1.0000, running_acc=0.9825, grad=7.7547]Training epoch 38:  58%|█████▊    | 94/163 [01:45<01:16,  1.10s/it, loss=0.1743, batch_acc=0.9375, running_acc=0.9820, grad=12.9067]Training epoch 38:  58%|█████▊    | 95/163 [01:46<01:12,  1.07s/it, loss=0.1743, batch_acc=0.9375, running_acc=0.9820, grad=12.9067]Training epoch 38:  58%|█████▊    | 95/163 [01:46<01:12,  1.07s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9822, grad=9.1010] Training epoch 38:  59%|█████▉    | 96/163 [01:47<01:07,  1.01s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9822, grad=9.1010]Training epoch 38:  59%|█████▉    | 96/163 [01:47<01:07,  1.01s/it, loss=0.1540, batch_acc=1.0000, running_acc=0.9824, grad=15.4632]Training epoch 38:  60%|█████▉    | 97/163 [01:48<01:07,  1.02s/it, loss=0.1540, batch_acc=1.0000, running_acc=0.9824, grad=15.4632]Training epoch 38:  60%|█████▉    | 97/163 [01:48<01:07,  1.02s/it, loss=0.2399, batch_acc=0.9688, running_acc=0.9823, grad=13.8397]Training epoch 38:  60%|██████    | 98/163 [01:49<01:03,  1.02it/s, loss=0.2399, batch_acc=0.9688, running_acc=0.9823, grad=13.8397]Training epoch 38:  60%|██████    | 98/163 [01:49<01:03,  1.02it/s, loss=0.1982, batch_acc=1.0000, running_acc=0.9825, grad=25.2855]Training epoch 38:  61%|██████    | 99/163 [01:50<01:13,  1.15s/it, loss=0.1982, batch_acc=1.0000, running_acc=0.9825, grad=25.2855]Training epoch 38:  61%|██████    | 99/163 [01:50<01:13,  1.15s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9826, grad=10.7985]Training epoch 38:  61%|██████▏   | 100/163 [01:51<01:07,  1.07s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9826, grad=10.7985]Training epoch 38:  61%|██████▏   | 100/163 [01:51<01:07,  1.07s/it, loss=0.1394, batch_acc=1.0000, running_acc=0.9828, grad=10.0414]Training epoch 38:  62%|██████▏   | 101/163 [01:52<01:03,  1.02s/it, loss=0.1394, batch_acc=1.0000, running_acc=0.9828, grad=10.0414]Training epoch 38:  62%|██████▏   | 101/163 [01:52<01:03,  1.02s/it, loss=0.0923, batch_acc=1.0000, running_acc=0.9830, grad=6.7532] Training epoch 38:  63%|██████▎   | 102/163 [01:53<00:59,  1.02it/s, loss=0.0923, batch_acc=1.0000, running_acc=0.9830, grad=6.7532]Training epoch 38:  63%|██████▎   | 102/163 [01:53<00:59,  1.02it/s, loss=0.1564, batch_acc=0.9375, running_acc=0.9825, grad=11.6060]Training epoch 38:  63%|██████▎   | 103/163 [01:54<01:05,  1.10s/it, loss=0.1564, batch_acc=0.9375, running_acc=0.9825, grad=11.6060]Training epoch 38:  63%|██████▎   | 103/163 [01:54<01:05,  1.10s/it, loss=0.1538, batch_acc=0.9688, running_acc=0.9824, grad=13.1133]Training epoch 38:  64%|██████▍   | 104/163 [01:55<01:00,  1.03s/it, loss=0.1538, batch_acc=0.9688, running_acc=0.9824, grad=13.1133]Training epoch 38:  64%|██████▍   | 104/163 [01:55<01:00,  1.03s/it, loss=0.0854, batch_acc=1.0000, running_acc=0.9826, grad=6.7200] Training epoch 38:  64%|██████▍   | 105/163 [01:56<00:57,  1.01it/s, loss=0.0854, batch_acc=1.0000, running_acc=0.9826, grad=6.7200]Training epoch 38:  64%|██████▍   | 105/163 [01:56<00:57,  1.01it/s, loss=0.1499, batch_acc=1.0000, running_acc=0.9827, grad=13.9830]Training epoch 38:  65%|██████▌   | 106/163 [01:57<00:54,  1.04it/s, loss=0.1499, batch_acc=1.0000, running_acc=0.9827, grad=13.9830]Training epoch 38:  65%|██████▌   | 106/163 [01:57<00:54,  1.04it/s, loss=0.1097, batch_acc=1.0000, running_acc=0.9829, grad=9.5994] Training epoch 38:  66%|██████▌   | 107/163 [02:01<01:38,  1.76s/it, loss=0.1097, batch_acc=1.0000, running_acc=0.9829, grad=9.5994]Training epoch 38:  66%|██████▌   | 107/163 [02:01<01:38,  1.76s/it, loss=0.1006, batch_acc=1.0000, running_acc=0.9831, grad=5.7867]Training epoch 38:  66%|██████▋   | 108/163 [02:01<01:22,  1.50s/it, loss=0.1006, batch_acc=1.0000, running_acc=0.9831, grad=5.7867]Training epoch 38:  66%|██████▋   | 108/163 [02:01<01:22,  1.50s/it, loss=0.1225, batch_acc=0.9688, running_acc=0.9829, grad=7.5275]Training epoch 38:  67%|██████▋   | 109/163 [02:03<01:16,  1.41s/it, loss=0.1225, batch_acc=0.9688, running_acc=0.9829, grad=7.5275]Training epoch 38:  67%|██████▋   | 109/163 [02:03<01:16,  1.41s/it, loss=0.1321, batch_acc=1.0000, running_acc=0.9831, grad=10.4128]Training epoch 38:  67%|██████▋   | 110/163 [02:04<01:06,  1.25s/it, loss=0.1321, batch_acc=1.0000, running_acc=0.9831, grad=10.4128]Training epoch 38:  67%|██████▋   | 110/163 [02:04<01:06,  1.25s/it, loss=0.1075, batch_acc=1.0000, running_acc=0.9832, grad=8.5562] Training epoch 38:  68%|██████▊   | 111/163 [02:05<01:03,  1.22s/it, loss=0.1075, batch_acc=1.0000, running_acc=0.9832, grad=8.5562]Training epoch 38:  68%|██████▊   | 111/163 [02:05<01:03,  1.22s/it, loss=0.2059, batch_acc=0.9688, running_acc=0.9831, grad=18.6557]Training epoch 38:  69%|██████▊   | 112/163 [02:06<00:56,  1.12s/it, loss=0.2059, batch_acc=0.9688, running_acc=0.9831, grad=18.6557]Training epoch 38:  69%|██████▊   | 112/163 [02:06<00:56,  1.12s/it, loss=0.1430, batch_acc=1.0000, running_acc=0.9833, grad=22.1901]Training epoch 38:  69%|██████▉   | 113/163 [02:07<00:59,  1.19s/it, loss=0.1430, batch_acc=1.0000, running_acc=0.9833, grad=22.1901]Training epoch 38:  69%|██████▉   | 113/163 [02:07<00:59,  1.19s/it, loss=0.1227, batch_acc=1.0000, running_acc=0.9834, grad=12.4250]Training epoch 38:  70%|██████▉   | 114/163 [02:08<00:53,  1.10s/it, loss=0.1227, batch_acc=1.0000, running_acc=0.9834, grad=12.4250]Training epoch 38:  70%|██████▉   | 114/163 [02:08<00:53,  1.10s/it, loss=0.2618, batch_acc=0.8750, running_acc=0.9825, grad=20.3517]Training epoch 38:  71%|███████   | 115/163 [02:09<00:57,  1.20s/it, loss=0.2618, batch_acc=0.8750, running_acc=0.9825, grad=20.3517]Training epoch 38:  71%|███████   | 115/163 [02:09<00:57,  1.20s/it, loss=0.1702, batch_acc=1.0000, running_acc=0.9826, grad=18.1678]Training epoch 38:  71%|███████   | 116/163 [02:10<00:51,  1.10s/it, loss=0.1702, batch_acc=1.0000, running_acc=0.9826, grad=18.1678]Training epoch 38:  71%|███████   | 116/163 [02:10<00:51,  1.10s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9828, grad=7.3531] Training epoch 38:  72%|███████▏  | 117/163 [02:12<01:01,  1.35s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9828, grad=7.3531]Training epoch 38:  72%|███████▏  | 117/163 [02:12<01:01,  1.35s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9829, grad=8.7710]Training epoch 38:  72%|███████▏  | 118/163 [02:13<00:54,  1.21s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9829, grad=8.7710]Training epoch 38:  72%|███████▏  | 118/163 [02:13<00:54,  1.21s/it, loss=0.1159, batch_acc=1.0000, running_acc=0.9831, grad=9.2702]Training epoch 38:  73%|███████▎  | 119/163 [02:14<00:51,  1.17s/it, loss=0.1159, batch_acc=1.0000, running_acc=0.9831, grad=9.2702]Training epoch 38:  73%|███████▎  | 119/163 [02:14<00:51,  1.17s/it, loss=0.1666, batch_acc=0.9688, running_acc=0.9829, grad=10.8700]Training epoch 38:  74%|███████▎  | 120/163 [02:15<00:46,  1.08s/it, loss=0.1666, batch_acc=0.9688, running_acc=0.9829, grad=10.8700]Training epoch 38:  74%|███████▎  | 120/163 [02:15<00:46,  1.08s/it, loss=0.1160, batch_acc=1.0000, running_acc=0.9831, grad=9.1388] Training epoch 38:  74%|███████▍  | 121/163 [02:17<00:52,  1.25s/it, loss=0.1160, batch_acc=1.0000, running_acc=0.9831, grad=9.1388]Training epoch 38:  74%|███████▍  | 121/163 [02:17<00:52,  1.25s/it, loss=0.1804, batch_acc=0.9688, running_acc=0.9830, grad=11.7458]Training epoch 38:  75%|███████▍  | 122/163 [02:17<00:46,  1.14s/it, loss=0.1804, batch_acc=0.9688, running_acc=0.9830, grad=11.7458]Training epoch 38:  75%|███████▍  | 122/163 [02:17<00:46,  1.14s/it, loss=0.0984, batch_acc=1.0000, running_acc=0.9831, grad=11.6443]Training epoch 38:  75%|███████▌  | 123/163 [02:19<00:47,  1.18s/it, loss=0.0984, batch_acc=1.0000, running_acc=0.9831, grad=11.6443]Training epoch 38:  75%|███████▌  | 123/163 [02:19<00:47,  1.18s/it, loss=0.1754, batch_acc=1.0000, running_acc=0.9832, grad=13.9133]Training epoch 38:  76%|███████▌  | 124/163 [02:20<00:42,  1.09s/it, loss=0.1754, batch_acc=1.0000, running_acc=0.9832, grad=13.9133]Training epoch 38:  76%|███████▌  | 124/163 [02:20<00:42,  1.09s/it, loss=0.2074, batch_acc=0.9375, running_acc=0.9829, grad=18.8045]Training epoch 38:  77%|███████▋  | 125/163 [02:22<00:54,  1.44s/it, loss=0.2074, batch_acc=0.9375, running_acc=0.9829, grad=18.8045]Training epoch 38:  77%|███████▋  | 125/163 [02:22<00:54,  1.44s/it, loss=0.0928, batch_acc=0.9688, running_acc=0.9828, grad=7.1353] Training epoch 38:  77%|███████▋  | 126/163 [02:23<00:47,  1.27s/it, loss=0.0928, batch_acc=0.9688, running_acc=0.9828, grad=7.1353]Training epoch 38:  77%|███████▋  | 126/163 [02:23<00:47,  1.27s/it, loss=0.1397, batch_acc=0.9375, running_acc=0.9824, grad=10.8383]Training epoch 38:  78%|███████▊  | 127/163 [02:24<00:41,  1.15s/it, loss=0.1397, batch_acc=0.9375, running_acc=0.9824, grad=10.8383]Training epoch 38:  78%|███████▊  | 127/163 [02:24<00:41,  1.15s/it, loss=0.1604, batch_acc=0.9688, running_acc=0.9823, grad=10.3852]Training epoch 38:  79%|███████▊  | 128/163 [02:24<00:37,  1.07s/it, loss=0.1604, batch_acc=0.9688, running_acc=0.9823, grad=10.3852]Training epoch 38:  79%|███████▊  | 128/163 [02:24<00:37,  1.07s/it, loss=0.1565, batch_acc=0.9375, running_acc=0.9819, grad=11.7648]Training epoch 38:  79%|███████▉  | 129/163 [02:26<00:42,  1.26s/it, loss=0.1565, batch_acc=0.9375, running_acc=0.9819, grad=11.7648]Training epoch 38:  79%|███████▉  | 129/163 [02:26<00:42,  1.26s/it, loss=0.1384, batch_acc=0.9688, running_acc=0.9818, grad=12.1868]Training epoch 38:  80%|███████▉  | 130/163 [02:27<00:37,  1.15s/it, loss=0.1384, batch_acc=0.9688, running_acc=0.9818, grad=12.1868]Training epoch 38:  80%|███████▉  | 130/163 [02:27<00:37,  1.15s/it, loss=0.1490, batch_acc=0.9688, running_acc=0.9817, grad=16.6729]Training epoch 38:  80%|████████  | 131/163 [02:28<00:35,  1.10s/it, loss=0.1490, batch_acc=0.9688, running_acc=0.9817, grad=16.6729]Training epoch 38:  80%|████████  | 131/163 [02:28<00:35,  1.10s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9819, grad=15.2499]Training epoch 38:  81%|████████  | 132/163 [02:29<00:32,  1.03s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9819, grad=15.2499]Training epoch 38:  81%|████████  | 132/163 [02:29<00:32,  1.03s/it, loss=0.0966, batch_acc=1.0000, running_acc=0.9820, grad=7.5775] Training epoch 38:  82%|████████▏ | 133/163 [02:31<00:39,  1.31s/it, loss=0.0966, batch_acc=1.0000, running_acc=0.9820, grad=7.5775]Training epoch 38:  82%|████████▏ | 133/163 [02:31<00:39,  1.31s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9821, grad=11.7796]Training epoch 38:  82%|████████▏ | 134/163 [02:32<00:34,  1.18s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9821, grad=11.7796]Training epoch 38:  82%|████████▏ | 134/163 [02:32<00:34,  1.18s/it, loss=0.0785, batch_acc=1.0000, running_acc=0.9823, grad=6.2790] Training epoch 38:  83%|████████▎ | 135/163 [02:33<00:31,  1.11s/it, loss=0.0785, batch_acc=1.0000, running_acc=0.9823, grad=6.2790]Training epoch 38:  83%|████████▎ | 135/163 [02:33<00:31,  1.11s/it, loss=0.1231, batch_acc=1.0000, running_acc=0.9824, grad=16.8300]Training epoch 38:  83%|████████▎ | 136/163 [02:34<00:28,  1.04s/it, loss=0.1231, batch_acc=1.0000, running_acc=0.9824, grad=16.8300]Training epoch 38:  83%|████████▎ | 136/163 [02:34<00:28,  1.04s/it, loss=0.1187, batch_acc=0.9688, running_acc=0.9823, grad=9.9227] Training epoch 38:  84%|████████▍ | 137/163 [02:35<00:30,  1.15s/it, loss=0.1187, batch_acc=0.9688, running_acc=0.9823, grad=9.9227]Training epoch 38:  84%|████████▍ | 137/163 [02:35<00:30,  1.15s/it, loss=0.1729, batch_acc=0.9688, running_acc=0.9822, grad=15.4932]Training epoch 38:  85%|████████▍ | 138/163 [02:36<00:26,  1.07s/it, loss=0.1729, batch_acc=0.9688, running_acc=0.9822, grad=15.4932]Training epoch 38:  85%|████████▍ | 138/163 [02:36<00:26,  1.07s/it, loss=0.1899, batch_acc=0.9375, running_acc=0.9819, grad=9.6432] Training epoch 38:  85%|████████▌ | 139/163 [02:37<00:24,  1.02s/it, loss=0.1899, batch_acc=0.9375, running_acc=0.9819, grad=9.6432]Training epoch 38:  85%|████████▌ | 139/163 [02:37<00:24,  1.02s/it, loss=0.1361, batch_acc=0.9688, running_acc=0.9818, grad=11.1761]Training epoch 38:  86%|████████▌ | 140/163 [02:38<00:22,  1.03it/s, loss=0.1361, batch_acc=0.9688, running_acc=0.9818, grad=11.1761]Training epoch 38:  86%|████████▌ | 140/163 [02:38<00:22,  1.03it/s, loss=0.1035, batch_acc=1.0000, running_acc=0.9819, grad=7.9908] Training epoch 38:  87%|████████▋ | 141/163 [02:39<00:24,  1.10s/it, loss=0.1035, batch_acc=1.0000, running_acc=0.9819, grad=7.9908]Training epoch 38:  87%|████████▋ | 141/163 [02:39<00:24,  1.10s/it, loss=0.1343, batch_acc=0.9688, running_acc=0.9818, grad=12.8517]Training epoch 38:  87%|████████▋ | 142/163 [02:40<00:21,  1.03s/it, loss=0.1343, batch_acc=0.9688, running_acc=0.9818, grad=12.8517]Training epoch 38:  87%|████████▋ | 142/163 [02:40<00:21,  1.03s/it, loss=0.1647, batch_acc=1.0000, running_acc=0.9820, grad=14.8080]Training epoch 38:  88%|████████▊ | 143/163 [02:41<00:19,  1.01it/s, loss=0.1647, batch_acc=1.0000, running_acc=0.9820, grad=14.8080]Training epoch 38:  88%|████████▊ | 143/163 [02:41<00:19,  1.01it/s, loss=0.1558, batch_acc=1.0000, running_acc=0.9821, grad=12.2328]Training epoch 38:  88%|████████▊ | 144/163 [02:42<00:18,  1.05it/s, loss=0.1558, batch_acc=1.0000, running_acc=0.9821, grad=12.2328]Training epoch 38:  88%|████████▊ | 144/163 [02:42<00:18,  1.05it/s, loss=0.1737, batch_acc=0.9375, running_acc=0.9818, grad=11.0977]Training epoch 38:  89%|████████▉ | 145/163 [02:43<00:19,  1.11s/it, loss=0.1737, batch_acc=0.9375, running_acc=0.9818, grad=11.0977]Training epoch 38:  89%|████████▉ | 145/163 [02:43<00:19,  1.11s/it, loss=0.0796, batch_acc=1.0000, running_acc=0.9819, grad=7.9757] Training epoch 38:  90%|████████▉ | 146/163 [02:44<00:17,  1.04s/it, loss=0.0796, batch_acc=1.0000, running_acc=0.9819, grad=7.9757]Training epoch 38:  90%|████████▉ | 146/163 [02:44<00:17,  1.04s/it, loss=0.1278, batch_acc=0.9688, running_acc=0.9818, grad=10.3519]Training epoch 38:  90%|█████████ | 147/163 [02:45<00:16,  1.00s/it, loss=0.1278, batch_acc=0.9688, running_acc=0.9818, grad=10.3519]Training epoch 38:  90%|█████████ | 147/163 [02:45<00:16,  1.00s/it, loss=0.1499, batch_acc=0.9688, running_acc=0.9817, grad=6.6689] Training epoch 38:  91%|█████████ | 148/163 [02:46<00:14,  1.04it/s, loss=0.1499, batch_acc=0.9688, running_acc=0.9817, grad=6.6689]Training epoch 38:  91%|█████████ | 148/163 [02:46<00:14,  1.04it/s, loss=0.1189, batch_acc=1.0000, running_acc=0.9818, grad=11.8700]Training epoch 38:  91%|█████████▏| 149/163 [02:47<00:13,  1.02it/s, loss=0.1189, batch_acc=1.0000, running_acc=0.9818, grad=11.8700]Training epoch 38:  91%|█████████▏| 149/163 [02:47<00:13,  1.02it/s, loss=0.1298, batch_acc=1.0000, running_acc=0.9820, grad=11.3094]Training epoch 38:  92%|█████████▏| 150/163 [02:48<00:12,  1.05it/s, loss=0.1298, batch_acc=1.0000, running_acc=0.9820, grad=11.3094]Training epoch 38:  92%|█████████▏| 150/163 [02:48<00:12,  1.05it/s, loss=0.1232, batch_acc=1.0000, running_acc=0.9821, grad=9.8723] Training epoch 38:  93%|█████████▎| 151/163 [02:50<00:15,  1.30s/it, loss=0.1232, batch_acc=1.0000, running_acc=0.9821, grad=9.8723]Training epoch 38:  93%|█████████▎| 151/163 [02:50<00:15,  1.30s/it, loss=0.1342, batch_acc=1.0000, running_acc=0.9822, grad=11.3314]Training epoch 38:  93%|█████████▎| 152/163 [02:51<00:12,  1.17s/it, loss=0.1342, batch_acc=1.0000, running_acc=0.9822, grad=11.3314]Training epoch 38:  93%|█████████▎| 152/163 [02:51<00:12,  1.17s/it, loss=0.1319, batch_acc=0.9688, running_acc=0.9821, grad=11.2780]Training epoch 38:  94%|█████████▍| 153/163 [02:52<00:10,  1.10s/it, loss=0.1319, batch_acc=0.9688, running_acc=0.9821, grad=11.2780]Training epoch 38:  94%|█████████▍| 153/163 [02:52<00:10,  1.10s/it, loss=0.1695, batch_acc=0.9688, running_acc=0.9820, grad=9.3913] Training epoch 38:  94%|█████████▍| 154/163 [02:52<00:09,  1.03s/it, loss=0.1695, batch_acc=0.9688, running_acc=0.9820, grad=9.3913]Training epoch 38:  94%|█████████▍| 154/163 [02:52<00:09,  1.03s/it, loss=0.1020, batch_acc=0.9688, running_acc=0.9819, grad=7.2449]Training epoch 38:  95%|█████████▌| 155/163 [02:54<00:09,  1.21s/it, loss=0.1020, batch_acc=0.9688, running_acc=0.9819, grad=7.2449]Training epoch 38:  95%|█████████▌| 155/163 [02:54<00:09,  1.21s/it, loss=0.1087, batch_acc=0.9688, running_acc=0.9819, grad=7.5775]Training epoch 38:  96%|█████████▌| 156/163 [02:55<00:07,  1.11s/it, loss=0.1087, batch_acc=0.9688, running_acc=0.9819, grad=7.5775]Training epoch 38:  96%|█████████▌| 156/163 [02:55<00:07,  1.11s/it, loss=0.1709, batch_acc=0.9688, running_acc=0.9818, grad=14.0841]Training epoch 38:  96%|█████████▋| 157/163 [02:56<00:06,  1.04s/it, loss=0.1709, batch_acc=0.9688, running_acc=0.9818, grad=14.0841]Training epoch 38:  96%|█████████▋| 157/163 [02:56<00:06,  1.04s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9819, grad=12.3155]Training epoch 38:  97%|█████████▋| 158/163 [02:57<00:04,  1.01it/s, loss=0.0970, batch_acc=1.0000, running_acc=0.9819, grad=12.3155]Training epoch 38:  97%|█████████▋| 158/163 [02:57<00:04,  1.01it/s, loss=0.1661, batch_acc=1.0000, running_acc=0.9820, grad=15.5071]Training epoch 38:  98%|█████████▊| 159/163 [02:58<00:04,  1.15s/it, loss=0.1661, batch_acc=1.0000, running_acc=0.9820, grad=15.5071]Training epoch 38:  98%|█████████▊| 159/163 [02:58<00:04,  1.15s/it, loss=0.1473, batch_acc=0.9688, running_acc=0.9819, grad=11.8698]Training epoch 38:  98%|█████████▊| 160/163 [02:59<00:03,  1.07s/it, loss=0.1473, batch_acc=0.9688, running_acc=0.9819, grad=11.8698]Training epoch 38:  98%|█████████▊| 160/163 [02:59<00:03,  1.07s/it, loss=0.1512, batch_acc=0.9688, running_acc=0.9818, grad=9.6513] Training epoch 38:  99%|█████████▉| 161/163 [03:00<00:02,  1.01s/it, loss=0.1512, batch_acc=0.9688, running_acc=0.9818, grad=9.6513]Training epoch 38:  99%|█████████▉| 161/163 [03:00<00:02,  1.01s/it, loss=0.1449, batch_acc=0.9688, running_acc=0.9818, grad=12.3157]Training epoch 38:  99%|█████████▉| 162/163 [03:01<00:00,  1.03it/s, loss=0.1449, batch_acc=0.9688, running_acc=0.9818, grad=12.3157]Training epoch 38:  99%|█████████▉| 162/163 [03:01<00:00,  1.03it/s, loss=0.1746, batch_acc=1.0000, running_acc=0.9819, grad=13.0545]Training epoch 38: 100%|██████████| 163/163 [03:02<00:00,  1.15it/s, loss=0.1746, batch_acc=1.0000, running_acc=0.9819, grad=13.0545]Training epoch 38: 100%|██████████| 163/163 [03:02<00:00,  1.15it/s, loss=0.1061, batch_acc=1.0000, running_acc=0.9819, grad=11.7016]Training epoch 38: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.1061, batch_acc=1.0000, running_acc=0.9819, grad=11.7016]
Evaluation epoch 38:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 38:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it]Evaluation epoch 38:   4%|▎         | 1/28 [00:05<02:16,  5.05s/it, loss=0.4151, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 38:   7%|▋         | 2/28 [00:05<00:59,  2.30s/it, loss=0.4151, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 38:   7%|▋         | 2/28 [00:05<00:59,  2.30s/it, loss=0.2347, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 38:  11%|█         | 3/28 [00:05<00:34,  1.37s/it, loss=0.2347, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 38:  11%|█         | 3/28 [00:05<00:34,  1.37s/it, loss=0.3500, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 38:  14%|█▍        | 4/28 [00:10<01:00,  2.54s/it, loss=0.3500, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 38:  14%|█▍        | 4/28 [00:10<01:00,  2.54s/it, loss=0.4069, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 38:  18%|█▊        | 5/28 [00:10<00:39,  1.72s/it, loss=0.4069, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 38:  18%|█▊        | 5/28 [00:10<00:39,  1.72s/it, loss=1.2541, batch_acc=0.7188, running_acc=0.9000]Evaluation epoch 38:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.2541, batch_acc=0.7188, running_acc=0.9000]Evaluation epoch 38:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=0.5778, batch_acc=0.8750, running_acc=0.8958]Evaluation epoch 38:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.5778, batch_acc=0.8750, running_acc=0.8958]Evaluation epoch 38:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.6352, batch_acc=0.9062, running_acc=0.8973]Evaluation epoch 38:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=0.6352, batch_acc=0.9062, running_acc=0.8973]Evaluation epoch 38:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=0.3767, batch_acc=0.8750, running_acc=0.8945]Evaluation epoch 38:  32%|███▏      | 9/28 [00:14<00:26,  1.37s/it, loss=0.3767, batch_acc=0.8750, running_acc=0.8945]Evaluation epoch 38:  32%|███▏      | 9/28 [00:14<00:26,  1.37s/it, loss=0.4418, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 38:  36%|███▌      | 10/28 [00:15<00:18,  1.03s/it, loss=0.4418, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 38:  36%|███▌      | 10/28 [00:15<00:18,  1.03s/it, loss=0.4491, batch_acc=0.9375, running_acc=0.9000]Evaluation epoch 38:  39%|███▉      | 11/28 [00:15<00:13,  1.26it/s, loss=0.4491, batch_acc=0.9375, running_acc=0.9000]Evaluation epoch 38:  39%|███▉      | 11/28 [00:15<00:13,  1.26it/s, loss=0.3050, batch_acc=0.9688, running_acc=0.9062]Evaluation epoch 38:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=0.3050, batch_acc=0.9688, running_acc=0.9062]Evaluation epoch 38:  43%|████▎     | 12/28 [00:20<00:35,  2.20s/it, loss=0.8427, batch_acc=0.8125, running_acc=0.8984]Evaluation epoch 38:  46%|████▋     | 13/28 [00:21<00:24,  1.61s/it, loss=0.8427, batch_acc=0.8125, running_acc=0.8984]Evaluation epoch 38:  46%|████▋     | 13/28 [00:21<00:24,  1.61s/it, loss=0.2944, batch_acc=0.9375, running_acc=0.9014]Evaluation epoch 38:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=0.2944, batch_acc=0.9375, running_acc=0.9014]Evaluation epoch 38:  50%|█████     | 14/28 [00:21<00:16,  1.21s/it, loss=0.9527, batch_acc=0.7500, running_acc=0.8906]Evaluation epoch 38:  54%|█████▎    | 15/28 [00:21<00:11,  1.08it/s, loss=0.9527, batch_acc=0.7500, running_acc=0.8906]Evaluation epoch 38:  54%|█████▎    | 15/28 [00:21<00:11,  1.08it/s, loss=1.0261, batch_acc=0.7812, running_acc=0.8833]Evaluation epoch 38:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=1.0261, batch_acc=0.7812, running_acc=0.8833]Evaluation epoch 38:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=0.8770, batch_acc=0.7500, running_acc=0.8750]Evaluation epoch 38:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.8770, batch_acc=0.7500, running_acc=0.8750]Evaluation epoch 38:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.6873, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 38:  64%|██████▍   | 18/28 [00:25<00:08,  1.14it/s, loss=0.6873, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 38:  64%|██████▍   | 18/28 [00:25<00:08,  1.14it/s, loss=0.4942, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 38:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=0.4942, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 38:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=0.8496, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 38:  71%|███████▏  | 20/28 [00:28<00:11,  1.39s/it, loss=0.8496, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 38:  71%|███████▏  | 20/28 [00:28<00:11,  1.39s/it, loss=0.5835, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 38:  75%|███████▌  | 21/28 [00:28<00:07,  1.05s/it, loss=0.5835, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 38:  75%|███████▌  | 21/28 [00:28<00:07,  1.05s/it, loss=0.6169, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 38:  79%|███████▊  | 22/28 [00:28<00:04,  1.23it/s, loss=0.6169, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 38:  79%|███████▊  | 22/28 [00:28<00:04,  1.23it/s, loss=0.4811, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 38:  82%|████████▏ | 23/28 [00:29<00:03,  1.54it/s, loss=0.4811, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 38:  82%|████████▏ | 23/28 [00:29<00:03,  1.54it/s, loss=0.8698, batch_acc=0.7500, running_acc=0.8478]Evaluation epoch 38:  86%|████████▌ | 24/28 [00:34<00:08,  2.01s/it, loss=0.8698, batch_acc=0.7500, running_acc=0.8478]Evaluation epoch 38:  86%|████████▌ | 24/28 [00:34<00:08,  2.01s/it, loss=0.3802, batch_acc=0.9375, running_acc=0.8516]Evaluation epoch 38:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.3802, batch_acc=0.9375, running_acc=0.8516]Evaluation epoch 38:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.1469, batch_acc=1.0000, running_acc=0.8575]Evaluation epoch 38:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.1469, batch_acc=1.0000, running_acc=0.8575]Evaluation epoch 38:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.5259, batch_acc=0.8750, running_acc=0.8582]Evaluation epoch 38:  96%|█████████▋| 27/28 [00:35<00:00,  1.16it/s, loss=0.5259, batch_acc=0.8750, running_acc=0.8582]Evaluation epoch 38:  96%|█████████▋| 27/28 [00:35<00:00,  1.16it/s, loss=0.8012, batch_acc=0.7812, running_acc=0.8553]Evaluation epoch 38: 100%|██████████| 28/28 [00:35<00:00,  1.16it/s, loss=1.2069, batch_acc=0.6667, running_acc=0.8547]Evaluation epoch 38: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.2069, batch_acc=0.6667, running_acc=0.8547]
Training epoch 39:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 39:   1%|          | 1/163 [00:06<17:21,  6.43s/it]Training epoch 39:   1%|          | 1/163 [00:06<17:21,  6.43s/it, loss=0.1538, batch_acc=0.9688, running_acc=0.9688, grad=12.4241]Training epoch 39:   1%|          | 2/163 [00:07<08:29,  3.16s/it, loss=0.1538, batch_acc=0.9688, running_acc=0.9688, grad=12.4241]Training epoch 39:   1%|          | 2/163 [00:07<08:29,  3.16s/it, loss=0.1811, batch_acc=0.9688, running_acc=0.9688, grad=17.6805]Training epoch 39:   2%|▏         | 3/163 [00:08<05:39,  2.12s/it, loss=0.1811, batch_acc=0.9688, running_acc=0.9688, grad=17.6805]Training epoch 39:   2%|▏         | 3/163 [00:08<05:39,  2.12s/it, loss=0.1610, batch_acc=0.9688, running_acc=0.9688, grad=11.9684]Training epoch 39:   2%|▏         | 4/163 [00:10<06:18,  2.38s/it, loss=0.1610, batch_acc=0.9688, running_acc=0.9688, grad=11.9684]Training epoch 39:   2%|▏         | 4/163 [00:10<06:18,  2.38s/it, loss=0.1566, batch_acc=0.9688, running_acc=0.9688, grad=11.0145]Training epoch 39:   3%|▎         | 5/163 [00:11<04:50,  1.84s/it, loss=0.1566, batch_acc=0.9688, running_acc=0.9688, grad=11.0145]Training epoch 39:   3%|▎         | 5/163 [00:11<04:50,  1.84s/it, loss=0.1094, batch_acc=0.9688, running_acc=0.9688, grad=7.4706] Training epoch 39:   4%|▎         | 6/163 [00:12<03:57,  1.51s/it, loss=0.1094, batch_acc=0.9688, running_acc=0.9688, grad=7.4706]Training epoch 39:   4%|▎         | 6/163 [00:12<03:57,  1.51s/it, loss=0.1081, batch_acc=1.0000, running_acc=0.9740, grad=11.2637]Training epoch 39:   4%|▍         | 7/163 [00:13<03:23,  1.31s/it, loss=0.1081, batch_acc=1.0000, running_acc=0.9740, grad=11.2637]Training epoch 39:   4%|▍         | 7/163 [00:13<03:23,  1.31s/it, loss=0.0863, batch_acc=1.0000, running_acc=0.9777, grad=8.3745] Training epoch 39:   5%|▍         | 8/163 [00:15<04:02,  1.56s/it, loss=0.0863, batch_acc=1.0000, running_acc=0.9777, grad=8.3745]Training epoch 39:   5%|▍         | 8/163 [00:15<04:02,  1.56s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9805, grad=7.3498]Training epoch 39:   6%|▌         | 9/163 [00:16<03:27,  1.35s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9805, grad=7.3498]Training epoch 39:   6%|▌         | 9/163 [00:16<03:27,  1.35s/it, loss=0.1099, batch_acc=1.0000, running_acc=0.9826, grad=7.4103]Training epoch 39:   6%|▌         | 10/163 [00:17<03:04,  1.20s/it, loss=0.1099, batch_acc=1.0000, running_acc=0.9826, grad=7.4103]Training epoch 39:   6%|▌         | 10/163 [00:17<03:04,  1.20s/it, loss=0.1491, batch_acc=0.9375, running_acc=0.9781, grad=10.8262]Training epoch 39:   7%|▋         | 11/163 [00:18<02:47,  1.10s/it, loss=0.1491, batch_acc=0.9375, running_acc=0.9781, grad=10.8262]Training epoch 39:   7%|▋         | 11/163 [00:18<02:47,  1.10s/it, loss=0.1594, batch_acc=1.0000, running_acc=0.9801, grad=17.1618]Training epoch 39:   7%|▋         | 12/163 [00:20<03:29,  1.39s/it, loss=0.1594, batch_acc=1.0000, running_acc=0.9801, grad=17.1618]Training epoch 39:   7%|▋         | 12/163 [00:20<03:29,  1.39s/it, loss=0.0974, batch_acc=1.0000, running_acc=0.9818, grad=8.5748] Training epoch 39:   8%|▊         | 13/163 [00:21<03:04,  1.23s/it, loss=0.0974, batch_acc=1.0000, running_acc=0.9818, grad=8.5748]Training epoch 39:   8%|▊         | 13/163 [00:21<03:04,  1.23s/it, loss=0.1390, batch_acc=1.0000, running_acc=0.9832, grad=10.1780]Training epoch 39:   9%|▊         | 14/163 [00:22<02:47,  1.13s/it, loss=0.1390, batch_acc=1.0000, running_acc=0.9832, grad=10.1780]Training epoch 39:   9%|▊         | 14/163 [00:22<02:47,  1.13s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9844, grad=6.1282] Training epoch 39:   9%|▉         | 15/163 [00:23<02:35,  1.05s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9844, grad=6.1282]Training epoch 39:   9%|▉         | 15/163 [00:23<02:35,  1.05s/it, loss=0.1312, batch_acc=0.9688, running_acc=0.9833, grad=8.7917]Training epoch 39:  10%|▉         | 16/163 [00:24<02:39,  1.08s/it, loss=0.1312, batch_acc=0.9688, running_acc=0.9833, grad=8.7917]Training epoch 39:  10%|▉         | 16/163 [00:24<02:39,  1.08s/it, loss=0.0840, batch_acc=1.0000, running_acc=0.9844, grad=8.4102]Training epoch 39:  10%|█         | 17/163 [00:25<02:29,  1.02s/it, loss=0.0840, batch_acc=1.0000, running_acc=0.9844, grad=8.4102]Training epoch 39:  10%|█         | 17/163 [00:25<02:29,  1.02s/it, loss=0.1374, batch_acc=0.9375, running_acc=0.9816, grad=11.2408]Training epoch 39:  11%|█         | 18/163 [00:25<02:21,  1.02it/s, loss=0.1374, batch_acc=0.9375, running_acc=0.9816, grad=11.2408]Training epoch 39:  11%|█         | 18/163 [00:25<02:21,  1.02it/s, loss=0.1225, batch_acc=1.0000, running_acc=0.9826, grad=8.8426] Training epoch 39:  12%|█▏        | 19/163 [00:26<02:16,  1.05it/s, loss=0.1225, batch_acc=1.0000, running_acc=0.9826, grad=8.8426]Training epoch 39:  12%|█▏        | 19/163 [00:26<02:16,  1.05it/s, loss=0.1628, batch_acc=1.0000, running_acc=0.9836, grad=9.3393]Training epoch 39:  12%|█▏        | 20/163 [00:28<02:51,  1.20s/it, loss=0.1628, batch_acc=1.0000, running_acc=0.9836, grad=9.3393]Training epoch 39:  12%|█▏        | 20/163 [00:28<02:51,  1.20s/it, loss=0.1331, batch_acc=0.9688, running_acc=0.9828, grad=9.9531]Training epoch 39:  13%|█▎        | 21/163 [00:29<02:36,  1.10s/it, loss=0.1331, batch_acc=0.9688, running_acc=0.9828, grad=9.9531]Training epoch 39:  13%|█▎        | 21/163 [00:29<02:36,  1.10s/it, loss=0.1126, batch_acc=1.0000, running_acc=0.9836, grad=7.8322]Training epoch 39:  13%|█▎        | 22/163 [00:30<02:26,  1.04s/it, loss=0.1126, batch_acc=1.0000, running_acc=0.9836, grad=7.8322]Training epoch 39:  13%|█▎        | 22/163 [00:30<02:26,  1.04s/it, loss=0.1230, batch_acc=1.0000, running_acc=0.9844, grad=11.1207]Training epoch 39:  14%|█▍        | 23/163 [00:31<02:18,  1.01it/s, loss=0.1230, batch_acc=1.0000, running_acc=0.9844, grad=11.1207]Training epoch 39:  14%|█▍        | 23/163 [00:31<02:18,  1.01it/s, loss=0.1355, batch_acc=1.0000, running_acc=0.9851, grad=10.9590]Training epoch 39:  15%|█▍        | 24/163 [00:33<03:07,  1.35s/it, loss=0.1355, batch_acc=1.0000, running_acc=0.9851, grad=10.9590]Training epoch 39:  15%|█▍        | 24/163 [00:33<03:07,  1.35s/it, loss=0.1319, batch_acc=0.9688, running_acc=0.9844, grad=12.3599]Training epoch 39:  15%|█▌        | 25/163 [00:34<02:46,  1.21s/it, loss=0.1319, batch_acc=0.9688, running_acc=0.9844, grad=12.3599]Training epoch 39:  15%|█▌        | 25/163 [00:34<02:46,  1.21s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9850, grad=10.5657]Training epoch 39:  16%|█▌        | 26/163 [00:35<02:31,  1.11s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9850, grad=10.5657]Training epoch 39:  16%|█▌        | 26/163 [00:35<02:31,  1.11s/it, loss=0.2403, batch_acc=0.9375, running_acc=0.9832, grad=16.3959]Training epoch 39:  17%|█▋        | 27/163 [00:36<02:21,  1.04s/it, loss=0.2403, batch_acc=0.9375, running_acc=0.9832, grad=16.3959]Training epoch 39:  17%|█▋        | 27/163 [00:36<02:21,  1.04s/it, loss=0.2084, batch_acc=0.9375, running_acc=0.9815, grad=14.1540]Training epoch 39:  17%|█▋        | 28/163 [00:37<02:32,  1.13s/it, loss=0.2084, batch_acc=0.9375, running_acc=0.9815, grad=14.1540]Training epoch 39:  17%|█▋        | 28/163 [00:37<02:32,  1.13s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9821, grad=8.1619] Training epoch 39:  18%|█▊        | 29/163 [00:38<02:21,  1.06s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9821, grad=8.1619]Training epoch 39:  18%|█▊        | 29/163 [00:38<02:21,  1.06s/it, loss=0.1372, batch_acc=0.9688, running_acc=0.9817, grad=7.3891]Training epoch 39:  18%|█▊        | 30/163 [00:39<02:13,  1.00s/it, loss=0.1372, batch_acc=0.9688, running_acc=0.9817, grad=7.3891]Training epoch 39:  18%|█▊        | 30/163 [00:39<02:13,  1.00s/it, loss=0.1645, batch_acc=1.0000, running_acc=0.9823, grad=9.1994]Training epoch 39:  19%|█▉        | 31/163 [00:40<02:07,  1.04it/s, loss=0.1645, batch_acc=1.0000, running_acc=0.9823, grad=9.1994]Training epoch 39:  19%|█▉        | 31/163 [00:40<02:07,  1.04it/s, loss=0.1614, batch_acc=1.0000, running_acc=0.9829, grad=14.5572]Training epoch 39:  20%|█▉        | 32/163 [00:41<02:23,  1.10s/it, loss=0.1614, batch_acc=1.0000, running_acc=0.9829, grad=14.5572]Training epoch 39:  20%|█▉        | 32/163 [00:41<02:23,  1.10s/it, loss=0.1272, batch_acc=1.0000, running_acc=0.9834, grad=9.3301] Training epoch 39:  20%|██        | 33/163 [00:42<02:14,  1.03s/it, loss=0.1272, batch_acc=1.0000, running_acc=0.9834, grad=9.3301]Training epoch 39:  20%|██        | 33/163 [00:42<02:14,  1.03s/it, loss=0.0810, batch_acc=1.0000, running_acc=0.9839, grad=7.3638]Training epoch 39:  21%|██        | 34/163 [00:43<02:07,  1.01it/s, loss=0.0810, batch_acc=1.0000, running_acc=0.9839, grad=7.3638]Training epoch 39:  21%|██        | 34/163 [00:43<02:07,  1.01it/s, loss=0.1020, batch_acc=1.0000, running_acc=0.9844, grad=9.2597]Training epoch 39:  21%|██▏       | 35/163 [00:44<02:02,  1.05it/s, loss=0.1020, batch_acc=1.0000, running_acc=0.9844, grad=9.2597]Training epoch 39:  21%|██▏       | 35/163 [00:44<02:02,  1.05it/s, loss=0.0788, batch_acc=1.0000, running_acc=0.9848, grad=7.0102]Training epoch 39:  22%|██▏       | 36/163 [00:45<02:30,  1.19s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9848, grad=7.0102]Training epoch 39:  22%|██▏       | 36/163 [00:45<02:30,  1.19s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9852, grad=8.0036]Training epoch 39:  23%|██▎       | 37/163 [00:46<02:18,  1.10s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9852, grad=8.0036]Training epoch 39:  23%|██▎       | 37/163 [00:46<02:18,  1.10s/it, loss=0.1671, batch_acc=0.9688, running_acc=0.9848, grad=13.4379]Training epoch 39:  23%|██▎       | 38/163 [00:47<02:08,  1.03s/it, loss=0.1671, batch_acc=0.9688, running_acc=0.9848, grad=13.4379]Training epoch 39:  23%|██▎       | 38/163 [00:47<02:08,  1.03s/it, loss=0.1408, batch_acc=1.0000, running_acc=0.9852, grad=14.4023]Training epoch 39:  24%|██▍       | 39/163 [00:48<02:02,  1.01it/s, loss=0.1408, batch_acc=1.0000, running_acc=0.9852, grad=14.4023]Training epoch 39:  24%|██▍       | 39/163 [00:48<02:02,  1.01it/s, loss=0.1392, batch_acc=1.0000, running_acc=0.9856, grad=16.0013]Training epoch 39:  25%|██▍       | 40/163 [00:50<02:32,  1.24s/it, loss=0.1392, batch_acc=1.0000, running_acc=0.9856, grad=16.0013]Training epoch 39:  25%|██▍       | 40/163 [00:50<02:32,  1.24s/it, loss=0.1125, batch_acc=1.0000, running_acc=0.9859, grad=9.8688] Training epoch 39:  25%|██▌       | 41/163 [00:51<02:18,  1.13s/it, loss=0.1125, batch_acc=1.0000, running_acc=0.9859, grad=9.8688]Training epoch 39:  25%|██▌       | 41/163 [00:51<02:18,  1.13s/it, loss=0.1775, batch_acc=0.9062, running_acc=0.9840, grad=17.2462]Training epoch 39:  26%|██▌       | 42/163 [00:52<02:07,  1.06s/it, loss=0.1775, batch_acc=0.9062, running_acc=0.9840, grad=17.2462]Training epoch 39:  26%|██▌       | 42/163 [00:52<02:07,  1.06s/it, loss=0.1907, batch_acc=0.9688, running_acc=0.9836, grad=21.7788]Training epoch 39:  26%|██▋       | 43/163 [00:52<02:00,  1.00s/it, loss=0.1907, batch_acc=0.9688, running_acc=0.9836, grad=21.7788]Training epoch 39:  26%|██▋       | 43/163 [00:52<02:00,  1.00s/it, loss=0.1122, batch_acc=1.0000, running_acc=0.9840, grad=9.3257] Training epoch 39:  27%|██▋       | 44/163 [00:54<02:17,  1.16s/it, loss=0.1122, batch_acc=1.0000, running_acc=0.9840, grad=9.3257]Training epoch 39:  27%|██▋       | 44/163 [00:54<02:17,  1.16s/it, loss=0.1580, batch_acc=1.0000, running_acc=0.9844, grad=11.6389]Training epoch 39:  28%|██▊       | 45/163 [00:55<02:06,  1.08s/it, loss=0.1580, batch_acc=1.0000, running_acc=0.9844, grad=11.6389]Training epoch 39:  28%|██▊       | 45/163 [00:55<02:06,  1.08s/it, loss=0.1559, batch_acc=0.9375, running_acc=0.9833, grad=7.3759] Training epoch 39:  28%|██▊       | 46/163 [00:56<01:58,  1.02s/it, loss=0.1559, batch_acc=0.9375, running_acc=0.9833, grad=7.3759]Training epoch 39:  28%|██▊       | 46/163 [00:56<01:58,  1.02s/it, loss=0.0867, batch_acc=1.0000, running_acc=0.9837, grad=6.9892]Training epoch 39:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.0867, batch_acc=1.0000, running_acc=0.9837, grad=6.9892]Training epoch 39:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.0947, batch_acc=1.0000, running_acc=0.9840, grad=7.1718]Training epoch 39:  29%|██▉       | 48/163 [00:58<02:16,  1.19s/it, loss=0.0947, batch_acc=1.0000, running_acc=0.9840, grad=7.1718]Training epoch 39:  29%|██▉       | 48/163 [00:58<02:16,  1.19s/it, loss=0.1495, batch_acc=1.0000, running_acc=0.9844, grad=7.5915]Training epoch 39:  30%|███       | 49/163 [00:59<02:05,  1.10s/it, loss=0.1495, batch_acc=1.0000, running_acc=0.9844, grad=7.5915]Training epoch 39:  30%|███       | 49/163 [00:59<02:05,  1.10s/it, loss=0.1255, batch_acc=1.0000, running_acc=0.9847, grad=9.6011]Training epoch 39:  31%|███       | 50/163 [01:00<01:56,  1.03s/it, loss=0.1255, batch_acc=1.0000, running_acc=0.9847, grad=9.6011]Training epoch 39:  31%|███       | 50/163 [01:00<01:56,  1.03s/it, loss=0.0739, batch_acc=1.0000, running_acc=0.9850, grad=4.8332]Training epoch 39:  31%|███▏      | 51/163 [01:01<01:50,  1.01it/s, loss=0.0739, batch_acc=1.0000, running_acc=0.9850, grad=4.8332]Training epoch 39:  31%|███▏      | 51/163 [01:01<01:50,  1.01it/s, loss=0.1023, batch_acc=1.0000, running_acc=0.9853, grad=7.5953]Training epoch 39:  32%|███▏      | 52/163 [01:03<02:14,  1.21s/it, loss=0.1023, batch_acc=1.0000, running_acc=0.9853, grad=7.5953]Training epoch 39:  32%|███▏      | 52/163 [01:03<02:14,  1.21s/it, loss=0.0880, batch_acc=1.0000, running_acc=0.9856, grad=7.7690]Training epoch 39:  33%|███▎      | 53/163 [01:04<02:02,  1.11s/it, loss=0.0880, batch_acc=1.0000, running_acc=0.9856, grad=7.7690]Training epoch 39:  33%|███▎      | 53/163 [01:04<02:02,  1.11s/it, loss=0.1068, batch_acc=1.0000, running_acc=0.9858, grad=7.1435]Training epoch 39:  33%|███▎      | 54/163 [01:04<01:53,  1.04s/it, loss=0.1068, batch_acc=1.0000, running_acc=0.9858, grad=7.1435]Training epoch 39:  33%|███▎      | 54/163 [01:04<01:53,  1.04s/it, loss=0.1512, batch_acc=0.9688, running_acc=0.9855, grad=14.6629]Training epoch 39:  34%|███▎      | 55/163 [01:05<01:47,  1.01it/s, loss=0.1512, batch_acc=0.9688, running_acc=0.9855, grad=14.6629]Training epoch 39:  34%|███▎      | 55/163 [01:05<01:47,  1.01it/s, loss=0.1449, batch_acc=0.9688, running_acc=0.9852, grad=9.3286] Training epoch 39:  34%|███▍      | 56/163 [01:07<02:04,  1.16s/it, loss=0.1449, batch_acc=0.9688, running_acc=0.9852, grad=9.3286]Training epoch 39:  34%|███▍      | 56/163 [01:07<02:04,  1.16s/it, loss=0.1529, batch_acc=0.9688, running_acc=0.9849, grad=11.5326]Training epoch 39:  35%|███▍      | 57/163 [01:08<01:54,  1.08s/it, loss=0.1529, batch_acc=0.9688, running_acc=0.9849, grad=11.5326]Training epoch 39:  35%|███▍      | 57/163 [01:08<01:54,  1.08s/it, loss=0.1612, batch_acc=0.9375, running_acc=0.9841, grad=14.2050]Training epoch 39:  36%|███▌      | 58/163 [01:09<01:47,  1.02s/it, loss=0.1612, batch_acc=0.9375, running_acc=0.9841, grad=14.2050]Training epoch 39:  36%|███▌      | 58/163 [01:09<01:47,  1.02s/it, loss=0.1583, batch_acc=0.9688, running_acc=0.9838, grad=13.1873]Training epoch 39:  36%|███▌      | 59/163 [01:10<01:41,  1.02it/s, loss=0.1583, batch_acc=0.9688, running_acc=0.9838, grad=13.1873]Training epoch 39:  36%|███▌      | 59/163 [01:10<01:41,  1.02it/s, loss=0.1018, batch_acc=1.0000, running_acc=0.9841, grad=8.4455] Training epoch 39:  37%|███▋      | 60/163 [01:11<01:49,  1.06s/it, loss=0.1018, batch_acc=1.0000, running_acc=0.9841, grad=8.4455]Training epoch 39:  37%|███▋      | 60/163 [01:11<01:49,  1.06s/it, loss=0.1002, batch_acc=1.0000, running_acc=0.9844, grad=10.3551]Training epoch 39:  37%|███▋      | 61/163 [01:12<01:42,  1.01s/it, loss=0.1002, batch_acc=1.0000, running_acc=0.9844, grad=10.3551]Training epoch 39:  37%|███▋      | 61/163 [01:12<01:42,  1.01s/it, loss=0.1515, batch_acc=0.9688, running_acc=0.9841, grad=9.7977] Training epoch 39:  38%|███▊      | 62/163 [01:13<01:37,  1.03it/s, loss=0.1515, batch_acc=0.9688, running_acc=0.9841, grad=9.7977]Training epoch 39:  38%|███▊      | 62/163 [01:13<01:37,  1.03it/s, loss=0.0768, batch_acc=1.0000, running_acc=0.9844, grad=7.9610]Training epoch 39:  39%|███▊      | 63/163 [01:13<01:34,  1.06it/s, loss=0.0768, batch_acc=1.0000, running_acc=0.9844, grad=7.9610]Training epoch 39:  39%|███▊      | 63/163 [01:13<01:34,  1.06it/s, loss=0.1078, batch_acc=1.0000, running_acc=0.9846, grad=9.2840]Training epoch 39:  39%|███▉      | 64/163 [01:15<01:44,  1.05s/it, loss=0.1078, batch_acc=1.0000, running_acc=0.9846, grad=9.2840]Training epoch 39:  39%|███▉      | 64/163 [01:15<01:44,  1.05s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9849, grad=7.7777]Training epoch 39:  40%|███▉      | 65/163 [01:16<01:38,  1.00s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9849, grad=7.7777]Training epoch 39:  40%|███▉      | 65/163 [01:16<01:38,  1.00s/it, loss=0.1355, batch_acc=0.9688, running_acc=0.9846, grad=11.5486]Training epoch 39:  40%|████      | 66/163 [01:17<01:36,  1.01it/s, loss=0.1355, batch_acc=0.9688, running_acc=0.9846, grad=11.5486]Training epoch 39:  40%|████      | 66/163 [01:17<01:36,  1.01it/s, loss=0.1107, batch_acc=0.9688, running_acc=0.9844, grad=10.5348]Training epoch 39:  41%|████      | 67/163 [01:17<01:31,  1.04it/s, loss=0.1107, batch_acc=0.9688, running_acc=0.9844, grad=10.5348]Training epoch 39:  41%|████      | 67/163 [01:17<01:31,  1.04it/s, loss=0.0963, batch_acc=1.0000, running_acc=0.9846, grad=9.4979] Training epoch 39:  42%|████▏     | 68/163 [01:19<01:38,  1.04s/it, loss=0.0963, batch_acc=1.0000, running_acc=0.9846, grad=9.4979]Training epoch 39:  42%|████▏     | 68/163 [01:19<01:38,  1.04s/it, loss=0.0894, batch_acc=1.0000, running_acc=0.9848, grad=6.9009]Training epoch 39:  42%|████▏     | 69/163 [01:20<01:33,  1.01it/s, loss=0.0894, batch_acc=1.0000, running_acc=0.9848, grad=6.9009]Training epoch 39:  42%|████▏     | 69/163 [01:20<01:33,  1.01it/s, loss=0.0933, batch_acc=1.0000, running_acc=0.9851, grad=8.5599]Training epoch 39:  43%|████▎     | 70/163 [01:21<01:31,  1.01it/s, loss=0.0933, batch_acc=1.0000, running_acc=0.9851, grad=8.5599]Training epoch 39:  43%|████▎     | 70/163 [01:21<01:31,  1.01it/s, loss=0.1240, batch_acc=0.9688, running_acc=0.9848, grad=8.4441]Training epoch 39:  44%|████▎     | 71/163 [01:21<01:27,  1.05it/s, loss=0.1240, batch_acc=0.9688, running_acc=0.9848, grad=8.4441]Training epoch 39:  44%|████▎     | 71/163 [01:21<01:27,  1.05it/s, loss=0.0910, batch_acc=1.0000, running_acc=0.9850, grad=7.0650]Training epoch 39:  44%|████▍     | 72/163 [01:23<01:45,  1.16s/it, loss=0.0910, batch_acc=1.0000, running_acc=0.9850, grad=7.0650]Training epoch 39:  44%|████▍     | 72/163 [01:23<01:45,  1.16s/it, loss=0.1454, batch_acc=0.9375, running_acc=0.9844, grad=11.4611]Training epoch 39:  45%|████▍     | 73/163 [01:24<01:36,  1.07s/it, loss=0.1454, batch_acc=0.9375, running_acc=0.9844, grad=11.4611]Training epoch 39:  45%|████▍     | 73/163 [01:24<01:36,  1.07s/it, loss=0.0542, batch_acc=1.0000, running_acc=0.9846, grad=5.8735] Training epoch 39:  45%|████▌     | 74/163 [01:25<01:30,  1.02s/it, loss=0.0542, batch_acc=1.0000, running_acc=0.9846, grad=5.8735]Training epoch 39:  45%|████▌     | 74/163 [01:25<01:30,  1.02s/it, loss=0.0883, batch_acc=1.0000, running_acc=0.9848, grad=7.0566]Training epoch 39:  46%|████▌     | 75/163 [01:26<01:25,  1.02it/s, loss=0.0883, batch_acc=1.0000, running_acc=0.9848, grad=7.0566]Training epoch 39:  46%|████▌     | 75/163 [01:26<01:25,  1.02it/s, loss=0.1352, batch_acc=0.9688, running_acc=0.9846, grad=10.1982]Training epoch 39:  47%|████▋     | 76/163 [01:27<01:23,  1.05it/s, loss=0.1352, batch_acc=0.9688, running_acc=0.9846, grad=10.1982]Training epoch 39:  47%|████▋     | 76/163 [01:27<01:23,  1.05it/s, loss=0.2216, batch_acc=0.9062, running_acc=0.9836, grad=14.1940]Training epoch 39:  47%|████▋     | 77/163 [01:27<01:20,  1.07it/s, loss=0.2216, batch_acc=0.9062, running_acc=0.9836, grad=14.1940]Training epoch 39:  47%|████▋     | 77/163 [01:27<01:20,  1.07it/s, loss=0.0841, batch_acc=1.0000, running_acc=0.9838, grad=7.4847] Training epoch 39:  48%|████▊     | 78/163 [01:29<01:25,  1.00s/it, loss=0.0841, batch_acc=1.0000, running_acc=0.9838, grad=7.4847]Training epoch 39:  48%|████▊     | 78/163 [01:29<01:25,  1.00s/it, loss=0.2077, batch_acc=0.9688, running_acc=0.9836, grad=13.9695]Training epoch 39:  48%|████▊     | 79/163 [01:30<01:21,  1.03it/s, loss=0.2077, batch_acc=0.9688, running_acc=0.9836, grad=13.9695]Training epoch 39:  48%|████▊     | 79/163 [01:30<01:21,  1.03it/s, loss=0.1606, batch_acc=0.9688, running_acc=0.9834, grad=12.1061]Training epoch 39:  49%|████▉     | 80/163 [01:30<01:18,  1.06it/s, loss=0.1606, batch_acc=0.9688, running_acc=0.9834, grad=12.1061]Training epoch 39:  49%|████▉     | 80/163 [01:30<01:18,  1.06it/s, loss=0.1244, batch_acc=1.0000, running_acc=0.9836, grad=10.7743]Training epoch 39:  50%|████▉     | 81/163 [01:31<01:15,  1.08it/s, loss=0.1244, batch_acc=1.0000, running_acc=0.9836, grad=10.7743]Training epoch 39:  50%|████▉     | 81/163 [01:31<01:15,  1.08it/s, loss=0.1343, batch_acc=1.0000, running_acc=0.9838, grad=11.0512]Training epoch 39:  50%|█████     | 82/163 [01:33<01:39,  1.23s/it, loss=0.1343, batch_acc=1.0000, running_acc=0.9838, grad=11.0512]Training epoch 39:  50%|█████     | 82/163 [01:33<01:39,  1.23s/it, loss=0.1249, batch_acc=0.9688, running_acc=0.9836, grad=9.1284] Training epoch 39:  51%|█████     | 83/163 [01:34<01:29,  1.12s/it, loss=0.1249, batch_acc=0.9688, running_acc=0.9836, grad=9.1284]Training epoch 39:  51%|█████     | 83/163 [01:34<01:29,  1.12s/it, loss=0.1235, batch_acc=1.0000, running_acc=0.9838, grad=11.7331]Training epoch 39:  52%|█████▏    | 84/163 [01:35<01:23,  1.05s/it, loss=0.1235, batch_acc=1.0000, running_acc=0.9838, grad=11.7331]Training epoch 39:  52%|█████▏    | 84/163 [01:35<01:23,  1.05s/it, loss=0.1056, batch_acc=1.0000, running_acc=0.9840, grad=6.0189] Training epoch 39:  52%|█████▏    | 85/163 [01:36<01:18,  1.00s/it, loss=0.1056, batch_acc=1.0000, running_acc=0.9840, grad=6.0189]Training epoch 39:  52%|█████▏    | 85/163 [01:36<01:18,  1.00s/it, loss=0.1314, batch_acc=1.0000, running_acc=0.9842, grad=10.2901]Training epoch 39:  53%|█████▎    | 86/163 [01:38<01:41,  1.31s/it, loss=0.1314, batch_acc=1.0000, running_acc=0.9842, grad=10.2901]Training epoch 39:  53%|█████▎    | 86/163 [01:38<01:41,  1.31s/it, loss=0.1172, batch_acc=0.9688, running_acc=0.9840, grad=7.7791] Training epoch 39:  53%|█████▎    | 87/163 [01:39<01:30,  1.18s/it, loss=0.1172, batch_acc=0.9688, running_acc=0.9840, grad=7.7791]Training epoch 39:  53%|█████▎    | 87/163 [01:39<01:30,  1.18s/it, loss=0.0928, batch_acc=1.0000, running_acc=0.9842, grad=9.0847]Training epoch 39:  54%|█████▍    | 88/163 [01:40<01:21,  1.09s/it, loss=0.0928, batch_acc=1.0000, running_acc=0.9842, grad=9.0847]Training epoch 39:  54%|█████▍    | 88/163 [01:40<01:21,  1.09s/it, loss=0.1335, batch_acc=1.0000, running_acc=0.9844, grad=13.7032]Training epoch 39:  55%|█████▍    | 89/163 [01:41<01:16,  1.03s/it, loss=0.1335, batch_acc=1.0000, running_acc=0.9844, grad=13.7032]Training epoch 39:  55%|█████▍    | 89/163 [01:41<01:16,  1.03s/it, loss=0.1941, batch_acc=0.9688, running_acc=0.9842, grad=12.2946]Training epoch 39:  55%|█████▌    | 90/163 [01:42<01:25,  1.18s/it, loss=0.1941, batch_acc=0.9688, running_acc=0.9842, grad=12.2946]Training epoch 39:  55%|█████▌    | 90/163 [01:42<01:25,  1.18s/it, loss=0.1345, batch_acc=1.0000, running_acc=0.9844, grad=8.8682] Training epoch 39:  56%|█████▌    | 91/163 [01:43<01:18,  1.09s/it, loss=0.1345, batch_acc=1.0000, running_acc=0.9844, grad=8.8682]Training epoch 39:  56%|█████▌    | 91/163 [01:43<01:18,  1.09s/it, loss=0.1165, batch_acc=1.0000, running_acc=0.9845, grad=9.5699]Training epoch 39:  56%|█████▋    | 92/163 [01:44<01:15,  1.06s/it, loss=0.1165, batch_acc=1.0000, running_acc=0.9845, grad=9.5699]Training epoch 39:  56%|█████▋    | 92/163 [01:44<01:15,  1.06s/it, loss=0.1380, batch_acc=0.9688, running_acc=0.9844, grad=17.3415]Training epoch 39:  57%|█████▋    | 93/163 [01:45<01:10,  1.01s/it, loss=0.1380, batch_acc=0.9688, running_acc=0.9844, grad=17.3415]Training epoch 39:  57%|█████▋    | 93/163 [01:45<01:10,  1.01s/it, loss=0.1152, batch_acc=1.0000, running_acc=0.9845, grad=8.5199] Training epoch 39:  58%|█████▊    | 94/163 [01:47<01:33,  1.36s/it, loss=0.1152, batch_acc=1.0000, running_acc=0.9845, grad=8.5199]Training epoch 39:  58%|█████▊    | 94/163 [01:47<01:33,  1.36s/it, loss=0.1303, batch_acc=0.9688, running_acc=0.9844, grad=9.1757]Training epoch 39:  58%|█████▊    | 95/163 [01:48<01:22,  1.22s/it, loss=0.1303, batch_acc=0.9688, running_acc=0.9844, grad=9.1757]Training epoch 39:  58%|█████▊    | 95/163 [01:48<01:22,  1.22s/it, loss=0.1204, batch_acc=1.0000, running_acc=0.9845, grad=12.2102]Training epoch 39:  59%|█████▉    | 96/163 [01:49<01:14,  1.12s/it, loss=0.1204, batch_acc=1.0000, running_acc=0.9845, grad=12.2102]Training epoch 39:  59%|█████▉    | 96/163 [01:49<01:14,  1.12s/it, loss=0.1128, batch_acc=1.0000, running_acc=0.9847, grad=12.6181]Training epoch 39:  60%|█████▉    | 97/163 [01:50<01:09,  1.05s/it, loss=0.1128, batch_acc=1.0000, running_acc=0.9847, grad=12.6181]Training epoch 39:  60%|█████▉    | 97/163 [01:50<01:09,  1.05s/it, loss=0.1116, batch_acc=1.0000, running_acc=0.9849, grad=9.8834] Training epoch 39:  60%|██████    | 98/163 [01:51<01:17,  1.19s/it, loss=0.1116, batch_acc=1.0000, running_acc=0.9849, grad=9.8834]Training epoch 39:  60%|██████    | 98/163 [01:51<01:17,  1.19s/it, loss=0.1180, batch_acc=1.0000, running_acc=0.9850, grad=13.4741]Training epoch 39:  61%|██████    | 99/163 [01:52<01:10,  1.10s/it, loss=0.1180, batch_acc=1.0000, running_acc=0.9850, grad=13.4741]Training epoch 39:  61%|██████    | 99/163 [01:52<01:10,  1.10s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9852, grad=7.1977] Training epoch 39:  61%|██████▏   | 100/163 [01:53<01:05,  1.03s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9852, grad=7.1977]Training epoch 39:  61%|██████▏   | 100/163 [01:53<01:05,  1.03s/it, loss=0.1092, batch_acc=1.0000, running_acc=0.9853, grad=12.3546]Training epoch 39:  62%|██████▏   | 101/163 [01:54<01:01,  1.01it/s, loss=0.1092, batch_acc=1.0000, running_acc=0.9853, grad=12.3546]Training epoch 39:  62%|██████▏   | 101/163 [01:54<01:01,  1.01it/s, loss=0.1180, batch_acc=0.9688, running_acc=0.9851, grad=7.9006] Training epoch 39:  63%|██████▎   | 102/163 [01:55<01:11,  1.18s/it, loss=0.1180, batch_acc=0.9688, running_acc=0.9851, grad=7.9006]Training epoch 39:  63%|██████▎   | 102/163 [01:55<01:11,  1.18s/it, loss=0.1646, batch_acc=0.9375, running_acc=0.9847, grad=12.0300]Training epoch 39:  63%|██████▎   | 103/163 [01:56<01:05,  1.09s/it, loss=0.1646, batch_acc=0.9375, running_acc=0.9847, grad=12.0300]Training epoch 39:  63%|██████▎   | 103/163 [01:56<01:05,  1.09s/it, loss=0.1348, batch_acc=0.9375, running_acc=0.9842, grad=10.1853]Training epoch 39:  64%|██████▍   | 104/163 [01:57<01:00,  1.03s/it, loss=0.1348, batch_acc=0.9375, running_acc=0.9842, grad=10.1853]Training epoch 39:  64%|██████▍   | 104/163 [01:57<01:00,  1.03s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9844, grad=7.4896] Training epoch 39:  64%|██████▍   | 105/163 [01:58<00:57,  1.01it/s, loss=0.0902, batch_acc=1.0000, running_acc=0.9844, grad=7.4896]Training epoch 39:  64%|██████▍   | 105/163 [01:58<00:57,  1.01it/s, loss=0.1358, batch_acc=0.9688, running_acc=0.9842, grad=15.5595]Training epoch 39:  65%|██████▌   | 106/163 [02:00<01:07,  1.19s/it, loss=0.1358, batch_acc=0.9688, running_acc=0.9842, grad=15.5595]Training epoch 39:  65%|██████▌   | 106/163 [02:00<01:07,  1.19s/it, loss=0.1127, batch_acc=1.0000, running_acc=0.9844, grad=10.0483]Training epoch 39:  66%|██████▌   | 107/163 [02:01<01:01,  1.10s/it, loss=0.1127, batch_acc=1.0000, running_acc=0.9844, grad=10.0483]Training epoch 39:  66%|██████▌   | 107/163 [02:01<01:01,  1.10s/it, loss=0.1674, batch_acc=0.9375, running_acc=0.9839, grad=12.7526]Training epoch 39:  66%|██████▋   | 108/163 [02:02<00:57,  1.04s/it, loss=0.1674, batch_acc=0.9375, running_acc=0.9839, grad=12.7526]Training epoch 39:  66%|██████▋   | 108/163 [02:02<00:57,  1.04s/it, loss=0.1839, batch_acc=0.9375, running_acc=0.9835, grad=16.2104]Training epoch 39:  67%|██████▋   | 109/163 [02:02<00:53,  1.01it/s, loss=0.1839, batch_acc=0.9375, running_acc=0.9835, grad=16.2104]Training epoch 39:  67%|██████▋   | 109/163 [02:02<00:53,  1.01it/s, loss=0.1325, batch_acc=0.9688, running_acc=0.9834, grad=7.4027] Training epoch 39:  67%|██████▋   | 110/163 [02:04<01:08,  1.30s/it, loss=0.1325, batch_acc=0.9688, running_acc=0.9834, grad=7.4027]Training epoch 39:  67%|██████▋   | 110/163 [02:04<01:08,  1.30s/it, loss=0.1219, batch_acc=0.9688, running_acc=0.9832, grad=10.0639]Training epoch 39:  68%|██████▊   | 111/163 [02:05<01:00,  1.17s/it, loss=0.1219, batch_acc=0.9688, running_acc=0.9832, grad=10.0639]Training epoch 39:  68%|██████▊   | 111/163 [02:05<01:00,  1.17s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9834, grad=9.9252] Training epoch 39:  69%|██████▊   | 112/163 [02:06<00:55,  1.08s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9834, grad=9.9252]Training epoch 39:  69%|██████▊   | 112/163 [02:06<00:55,  1.08s/it, loss=0.0913, batch_acc=1.0000, running_acc=0.9835, grad=7.0371]Training epoch 39:  69%|██████▉   | 113/163 [02:07<00:51,  1.02s/it, loss=0.0913, batch_acc=1.0000, running_acc=0.9835, grad=7.0371]Training epoch 39:  69%|██████▉   | 113/163 [02:07<00:51,  1.02s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9837, grad=11.2053]Training epoch 39:  70%|██████▉   | 114/163 [02:08<00:53,  1.09s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9837, grad=11.2053]Training epoch 39:  70%|██████▉   | 114/163 [02:08<00:53,  1.09s/it, loss=0.1429, batch_acc=1.0000, running_acc=0.9838, grad=12.6601]Training epoch 39:  71%|███████   | 115/163 [02:09<00:49,  1.02s/it, loss=0.1429, batch_acc=1.0000, running_acc=0.9838, grad=12.6601]Training epoch 39:  71%|███████   | 115/163 [02:09<00:49,  1.02s/it, loss=0.0938, batch_acc=1.0000, running_acc=0.9840, grad=8.5453] Training epoch 39:  71%|███████   | 116/163 [02:10<00:46,  1.02it/s, loss=0.0938, batch_acc=1.0000, running_acc=0.9840, grad=8.5453]Training epoch 39:  71%|███████   | 116/163 [02:10<00:46,  1.02it/s, loss=0.1587, batch_acc=0.9688, running_acc=0.9838, grad=8.4229]Training epoch 39:  72%|███████▏  | 117/163 [02:11<00:43,  1.05it/s, loss=0.1587, batch_acc=0.9688, running_acc=0.9838, grad=8.4229]Training epoch 39:  72%|███████▏  | 117/163 [02:11<00:43,  1.05it/s, loss=0.1487, batch_acc=0.9688, running_acc=0.9837, grad=11.4504]Training epoch 39:  72%|███████▏  | 118/163 [02:13<00:52,  1.16s/it, loss=0.1487, batch_acc=0.9688, running_acc=0.9837, grad=11.4504]Training epoch 39:  72%|███████▏  | 118/163 [02:13<00:52,  1.16s/it, loss=0.1388, batch_acc=0.9688, running_acc=0.9836, grad=18.2672]Training epoch 39:  73%|███████▎  | 119/163 [02:14<00:47,  1.08s/it, loss=0.1388, batch_acc=0.9688, running_acc=0.9836, grad=18.2672]Training epoch 39:  73%|███████▎  | 119/163 [02:14<00:47,  1.08s/it, loss=0.1368, batch_acc=1.0000, running_acc=0.9837, grad=14.4695]Training epoch 39:  74%|███████▎  | 120/163 [02:14<00:43,  1.02s/it, loss=0.1368, batch_acc=1.0000, running_acc=0.9837, grad=14.4695]Training epoch 39:  74%|███████▎  | 120/163 [02:14<00:43,  1.02s/it, loss=0.1223, batch_acc=1.0000, running_acc=0.9839, grad=9.2291] Training epoch 39:  74%|███████▍  | 121/163 [02:15<00:41,  1.02it/s, loss=0.1223, batch_acc=1.0000, running_acc=0.9839, grad=9.2291]Training epoch 39:  74%|███████▍  | 121/163 [02:15<00:41,  1.02it/s, loss=0.1598, batch_acc=0.9688, running_acc=0.9837, grad=15.5221]Training epoch 39:  75%|███████▍  | 122/163 [02:17<00:52,  1.29s/it, loss=0.1598, batch_acc=0.9688, running_acc=0.9837, grad=15.5221]Training epoch 39:  75%|███████▍  | 122/163 [02:17<00:52,  1.29s/it, loss=0.1702, batch_acc=0.9375, running_acc=0.9834, grad=14.3418]Training epoch 39:  75%|███████▌  | 123/163 [02:18<00:46,  1.17s/it, loss=0.1702, batch_acc=0.9375, running_acc=0.9834, grad=14.3418]Training epoch 39:  75%|███████▌  | 123/163 [02:18<00:46,  1.17s/it, loss=0.1593, batch_acc=1.0000, running_acc=0.9835, grad=9.9150] Training epoch 39:  76%|███████▌  | 124/163 [02:19<00:42,  1.08s/it, loss=0.1593, batch_acc=1.0000, running_acc=0.9835, grad=9.9150]Training epoch 39:  76%|███████▌  | 124/163 [02:19<00:42,  1.08s/it, loss=0.1338, batch_acc=1.0000, running_acc=0.9836, grad=16.2795]Training epoch 39:  77%|███████▋  | 125/163 [02:20<00:38,  1.02s/it, loss=0.1338, batch_acc=1.0000, running_acc=0.9836, grad=16.2795]Training epoch 39:  77%|███████▋  | 125/163 [02:20<00:38,  1.02s/it, loss=0.1393, batch_acc=0.9688, running_acc=0.9835, grad=12.5746]Training epoch 39:  77%|███████▋  | 126/163 [02:22<00:50,  1.35s/it, loss=0.1393, batch_acc=0.9688, running_acc=0.9835, grad=12.5746]Training epoch 39:  77%|███████▋  | 126/163 [02:22<00:50,  1.35s/it, loss=0.1818, batch_acc=0.9688, running_acc=0.9834, grad=24.5828]Training epoch 39:  78%|███████▊  | 127/163 [02:23<00:43,  1.21s/it, loss=0.1818, batch_acc=0.9688, running_acc=0.9834, grad=24.5828]Training epoch 39:  78%|███████▊  | 127/163 [02:23<00:43,  1.21s/it, loss=0.0962, batch_acc=1.0000, running_acc=0.9835, grad=10.8395]Training epoch 39:  79%|███████▊  | 128/163 [02:24<00:38,  1.11s/it, loss=0.0962, batch_acc=1.0000, running_acc=0.9835, grad=10.8395]Training epoch 39:  79%|███████▊  | 128/163 [02:24<00:38,  1.11s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9836, grad=7.4937] Training epoch 39:  79%|███████▉  | 129/163 [02:25<00:35,  1.04s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9836, grad=7.4937]Training epoch 39:  79%|███████▉  | 129/163 [02:25<00:35,  1.04s/it, loss=0.1582, batch_acc=0.9688, running_acc=0.9835, grad=9.2455]Training epoch 39:  80%|███████▉  | 130/163 [02:27<00:42,  1.28s/it, loss=0.1582, batch_acc=0.9688, running_acc=0.9835, grad=9.2455]Training epoch 39:  80%|███████▉  | 130/163 [02:27<00:42,  1.28s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9837, grad=10.1698]Training epoch 39:  80%|████████  | 131/163 [02:27<00:37,  1.16s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9837, grad=10.1698]Training epoch 39:  80%|████████  | 131/163 [02:27<00:37,  1.16s/it, loss=0.0937, batch_acc=1.0000, running_acc=0.9838, grad=8.6407] Training epoch 39:  81%|████████  | 132/163 [02:28<00:33,  1.07s/it, loss=0.0937, batch_acc=1.0000, running_acc=0.9838, grad=8.6407]Training epoch 39:  81%|████████  | 132/163 [02:28<00:33,  1.07s/it, loss=0.2028, batch_acc=0.9375, running_acc=0.9834, grad=11.2972]Training epoch 39:  82%|████████▏ | 133/163 [02:29<00:30,  1.02s/it, loss=0.2028, batch_acc=0.9375, running_acc=0.9834, grad=11.2972]Training epoch 39:  82%|████████▏ | 133/163 [02:29<00:30,  1.02s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9836, grad=6.8853] Training epoch 39:  82%|████████▏ | 134/163 [02:32<00:41,  1.42s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9836, grad=6.8853]Training epoch 39:  82%|████████▏ | 134/163 [02:32<00:41,  1.42s/it, loss=0.0965, batch_acc=1.0000, running_acc=0.9837, grad=10.0517]Training epoch 39:  83%|████████▎ | 135/163 [02:32<00:35,  1.26s/it, loss=0.0965, batch_acc=1.0000, running_acc=0.9837, grad=10.0517]Training epoch 39:  83%|████████▎ | 135/163 [02:32<00:35,  1.26s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9838, grad=8.3302] Training epoch 39:  83%|████████▎ | 136/163 [02:33<00:30,  1.15s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9838, grad=8.3302]Training epoch 39:  83%|████████▎ | 136/163 [02:33<00:30,  1.15s/it, loss=0.0855, batch_acc=1.0000, running_acc=0.9839, grad=12.8876]Training epoch 39:  84%|████████▍ | 137/163 [02:34<00:27,  1.07s/it, loss=0.0855, batch_acc=1.0000, running_acc=0.9839, grad=12.8876]Training epoch 39:  84%|████████▍ | 137/163 [02:34<00:27,  1.07s/it, loss=0.1040, batch_acc=1.0000, running_acc=0.9840, grad=10.0690]Training epoch 39:  85%|████████▍ | 138/163 [02:36<00:30,  1.23s/it, loss=0.1040, batch_acc=1.0000, running_acc=0.9840, grad=10.0690]Training epoch 39:  85%|████████▍ | 138/163 [02:36<00:30,  1.23s/it, loss=0.1085, batch_acc=0.9688, running_acc=0.9839, grad=7.3804] Training epoch 39:  85%|████████▌ | 139/163 [02:37<00:26,  1.12s/it, loss=0.1085, batch_acc=0.9688, running_acc=0.9839, grad=7.3804]Training epoch 39:  85%|████████▌ | 139/163 [02:37<00:26,  1.12s/it, loss=0.1427, batch_acc=0.9688, running_acc=0.9838, grad=8.8210]Training epoch 39:  86%|████████▌ | 140/163 [02:38<00:24,  1.05s/it, loss=0.1427, batch_acc=0.9688, running_acc=0.9838, grad=8.8210]Training epoch 39:  86%|████████▌ | 140/163 [02:38<00:24,  1.05s/it, loss=0.1659, batch_acc=0.9375, running_acc=0.9835, grad=12.7375]Training epoch 39:  87%|████████▋ | 141/163 [02:38<00:21,  1.00it/s, loss=0.1659, batch_acc=0.9375, running_acc=0.9835, grad=12.7375]Training epoch 39:  87%|████████▋ | 141/163 [02:38<00:21,  1.00it/s, loss=0.1282, batch_acc=1.0000, running_acc=0.9836, grad=9.0026] Training epoch 39:  87%|████████▋ | 142/163 [02:41<00:29,  1.39s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9836, grad=9.0026]Training epoch 39:  87%|████████▋ | 142/163 [02:41<00:29,  1.39s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.9837, grad=12.9434]Training epoch 39:  88%|████████▊ | 143/163 [02:42<00:24,  1.24s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.9837, grad=12.9434]Training epoch 39:  88%|████████▊ | 143/163 [02:42<00:24,  1.24s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9838, grad=12.3797]Training epoch 39:  88%|████████▊ | 144/163 [02:43<00:21,  1.13s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9838, grad=12.3797]Training epoch 39:  88%|████████▊ | 144/163 [02:43<00:21,  1.13s/it, loss=0.1054, batch_acc=0.9688, running_acc=0.9837, grad=7.4126] Training epoch 39:  89%|████████▉ | 145/163 [02:43<00:19,  1.06s/it, loss=0.1054, batch_acc=0.9688, running_acc=0.9837, grad=7.4126]Training epoch 39:  89%|████████▉ | 145/163 [02:43<00:19,  1.06s/it, loss=0.1606, batch_acc=0.9375, running_acc=0.9834, grad=13.1013]Training epoch 39:  90%|████████▉ | 146/163 [02:45<00:22,  1.30s/it, loss=0.1606, batch_acc=0.9375, running_acc=0.9834, grad=13.1013]Training epoch 39:  90%|████████▉ | 146/163 [02:45<00:22,  1.30s/it, loss=0.0867, batch_acc=1.0000, running_acc=0.9835, grad=10.9368]Training epoch 39:  90%|█████████ | 147/163 [02:46<00:18,  1.17s/it, loss=0.0867, batch_acc=1.0000, running_acc=0.9835, grad=10.9368]Training epoch 39:  90%|█████████ | 147/163 [02:46<00:18,  1.17s/it, loss=0.1358, batch_acc=0.9375, running_acc=0.9832, grad=7.3131] Training epoch 39:  91%|█████████ | 148/163 [02:47<00:16,  1.09s/it, loss=0.1358, batch_acc=0.9375, running_acc=0.9832, grad=7.3131]Training epoch 39:  91%|█████████ | 148/163 [02:47<00:16,  1.09s/it, loss=0.1577, batch_acc=0.9688, running_acc=0.9831, grad=15.2103]Training epoch 39:  91%|█████████▏| 149/163 [02:48<00:14,  1.02s/it, loss=0.1577, batch_acc=0.9688, running_acc=0.9831, grad=15.2103]Training epoch 39:  91%|█████████▏| 149/163 [02:48<00:14,  1.02s/it, loss=0.1278, batch_acc=0.9688, running_acc=0.9830, grad=6.7328] Training epoch 39:  92%|█████████▏| 150/163 [02:49<00:15,  1.18s/it, loss=0.1278, batch_acc=0.9688, running_acc=0.9830, grad=6.7328]Training epoch 39:  92%|█████████▏| 150/163 [02:49<00:15,  1.18s/it, loss=0.1254, batch_acc=0.9375, running_acc=0.9827, grad=8.5662]Training epoch 39:  93%|█████████▎| 151/163 [02:50<00:13,  1.09s/it, loss=0.1254, batch_acc=0.9375, running_acc=0.9827, grad=8.5662]Training epoch 39:  93%|█████████▎| 151/163 [02:50<00:13,  1.09s/it, loss=0.2036, batch_acc=0.9688, running_acc=0.9826, grad=21.4356]Training epoch 39:  93%|█████████▎| 152/163 [02:51<00:11,  1.03s/it, loss=0.2036, batch_acc=0.9688, running_acc=0.9826, grad=21.4356]Training epoch 39:  93%|█████████▎| 152/163 [02:51<00:11,  1.03s/it, loss=0.2031, batch_acc=0.9688, running_acc=0.9825, grad=14.0971]Training epoch 39:  94%|█████████▍| 153/163 [02:52<00:09,  1.02it/s, loss=0.2031, batch_acc=0.9688, running_acc=0.9825, grad=14.0971]Training epoch 39:  94%|█████████▍| 153/163 [02:52<00:09,  1.02it/s, loss=0.1058, batch_acc=1.0000, running_acc=0.9826, grad=7.9194] Training epoch 39:  94%|█████████▍| 154/163 [02:54<00:10,  1.19s/it, loss=0.1058, batch_acc=1.0000, running_acc=0.9826, grad=7.9194]Training epoch 39:  94%|█████████▍| 154/163 [02:54<00:10,  1.19s/it, loss=0.1119, batch_acc=1.0000, running_acc=0.9828, grad=7.4374]Training epoch 39:  95%|█████████▌| 155/163 [02:55<00:08,  1.10s/it, loss=0.1119, batch_acc=1.0000, running_acc=0.9828, grad=7.4374]Training epoch 39:  95%|█████████▌| 155/163 [02:55<00:08,  1.10s/it, loss=0.1356, batch_acc=0.9688, running_acc=0.9827, grad=14.6177]Training epoch 39:  96%|█████████▌| 156/163 [02:56<00:07,  1.03s/it, loss=0.1356, batch_acc=0.9688, running_acc=0.9827, grad=14.6177]Training epoch 39:  96%|█████████▌| 156/163 [02:56<00:07,  1.03s/it, loss=0.1056, batch_acc=0.9688, running_acc=0.9826, grad=8.4792] Training epoch 39:  96%|█████████▋| 157/163 [02:56<00:05,  1.01it/s, loss=0.1056, batch_acc=0.9688, running_acc=0.9826, grad=8.4792]Training epoch 39:  96%|█████████▋| 157/163 [02:56<00:05,  1.01it/s, loss=0.1174, batch_acc=1.0000, running_acc=0.9827, grad=9.5461]Training epoch 39:  97%|█████████▋| 158/163 [02:58<00:05,  1.11s/it, loss=0.1174, batch_acc=1.0000, running_acc=0.9827, grad=9.5461]Training epoch 39:  97%|█████████▋| 158/163 [02:58<00:05,  1.11s/it, loss=0.1192, batch_acc=1.0000, running_acc=0.9828, grad=8.0397]Training epoch 39:  98%|█████████▊| 159/163 [02:59<00:04,  1.04s/it, loss=0.1192, batch_acc=1.0000, running_acc=0.9828, grad=8.0397]Training epoch 39:  98%|█████████▊| 159/163 [02:59<00:04,  1.04s/it, loss=0.0720, batch_acc=1.0000, running_acc=0.9829, grad=6.0393]Training epoch 39:  98%|█████████▊| 160/163 [03:00<00:02,  1.01it/s, loss=0.0720, batch_acc=1.0000, running_acc=0.9829, grad=6.0393]Training epoch 39:  98%|█████████▊| 160/163 [03:00<00:02,  1.01it/s, loss=0.2144, batch_acc=0.9375, running_acc=0.9826, grad=10.9110]Training epoch 39:  99%|█████████▉| 161/163 [03:00<00:01,  1.04it/s, loss=0.2144, batch_acc=0.9375, running_acc=0.9826, grad=10.9110]Training epoch 39:  99%|█████████▉| 161/163 [03:00<00:01,  1.04it/s, loss=0.0934, batch_acc=1.0000, running_acc=0.9827, grad=7.8334] Training epoch 39:  99%|█████████▉| 162/163 [03:01<00:00,  1.07it/s, loss=0.0934, batch_acc=1.0000, running_acc=0.9827, grad=7.8334]Training epoch 39:  99%|█████████▉| 162/163 [03:01<00:00,  1.07it/s, loss=0.1459, batch_acc=1.0000, running_acc=0.9828, grad=11.2930]Training epoch 39: 100%|██████████| 163/163 [03:02<00:00,  1.18it/s, loss=0.1459, batch_acc=1.0000, running_acc=0.9828, grad=11.2930]Training epoch 39: 100%|██████████| 163/163 [03:02<00:00,  1.18it/s, loss=0.1902, batch_acc=0.9524, running_acc=0.9827, grad=20.9885]Training epoch 39: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.1902, batch_acc=0.9524, running_acc=0.9827, grad=20.9885]
Evaluation epoch 39:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 39:   4%|▎         | 1/28 [00:04<02:09,  4.80s/it]Evaluation epoch 39:   4%|▎         | 1/28 [00:04<02:09,  4.80s/it, loss=0.3963, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 39:   7%|▋         | 2/28 [00:05<00:55,  2.13s/it, loss=0.3963, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 39:   7%|▋         | 2/28 [00:05<00:55,  2.13s/it, loss=0.2057, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 39:  11%|█         | 3/28 [00:05<00:31,  1.28s/it, loss=0.2057, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 39:  11%|█         | 3/28 [00:05<00:31,  1.28s/it, loss=0.3808, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 39:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.3808, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 39:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.4158, batch_acc=0.9375, running_acc=0.9531]Evaluation epoch 39:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=0.4158, batch_acc=0.9375, running_acc=0.9531]Evaluation epoch 39:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=1.3634, batch_acc=0.6875, running_acc=0.9000]Evaluation epoch 39:  21%|██▏       | 6/28 [00:10<00:26,  1.18s/it, loss=1.3634, batch_acc=0.6875, running_acc=0.9000]Evaluation epoch 39:  21%|██▏       | 6/28 [00:10<00:26,  1.18s/it, loss=0.5973, batch_acc=0.9062, running_acc=0.9010]Evaluation epoch 39:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.5973, batch_acc=0.9062, running_acc=0.9010]Evaluation epoch 39:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.6811, batch_acc=0.8438, running_acc=0.8929]Evaluation epoch 39:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.6811, batch_acc=0.8438, running_acc=0.8929]Evaluation epoch 39:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.4520, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 39:  32%|███▏      | 9/28 [00:14<00:26,  1.38s/it, loss=0.4520, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 39:  32%|███▏      | 9/28 [00:14<00:26,  1.38s/it, loss=0.4512, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 39:  36%|███▌      | 10/28 [00:14<00:18,  1.03s/it, loss=0.4512, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 39:  36%|███▌      | 10/28 [00:14<00:18,  1.03s/it, loss=0.4342, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 39:  39%|███▉      | 11/28 [00:14<00:13,  1.25it/s, loss=0.4342, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 39:  39%|███▉      | 11/28 [00:14<00:13,  1.25it/s, loss=0.3197, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 39:  43%|████▎     | 12/28 [00:19<00:32,  2.06s/it, loss=0.3197, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 39:  43%|████▎     | 12/28 [00:19<00:32,  2.06s/it, loss=0.7818, batch_acc=0.8750, running_acc=0.8984]Evaluation epoch 39:  46%|████▋     | 13/28 [00:20<00:22,  1.52s/it, loss=0.7818, batch_acc=0.8750, running_acc=0.8984]Evaluation epoch 39:  46%|████▋     | 13/28 [00:20<00:22,  1.52s/it, loss=0.2874, batch_acc=0.9375, running_acc=0.9014]Evaluation epoch 39:  50%|█████     | 14/28 [00:20<00:15,  1.14s/it, loss=0.2874, batch_acc=0.9375, running_acc=0.9014]Evaluation epoch 39:  50%|█████     | 14/28 [00:20<00:15,  1.14s/it, loss=0.8834, batch_acc=0.7500, running_acc=0.8906]Evaluation epoch 39:  54%|█████▎    | 15/28 [00:20<00:11,  1.14it/s, loss=0.8834, batch_acc=0.7500, running_acc=0.8906]Evaluation epoch 39:  54%|█████▎    | 15/28 [00:20<00:11,  1.14it/s, loss=0.9792, batch_acc=0.8125, running_acc=0.8854]Evaluation epoch 39:  57%|█████▋    | 16/28 [00:23<00:17,  1.45s/it, loss=0.9792, batch_acc=0.8125, running_acc=0.8854]Evaluation epoch 39:  57%|█████▋    | 16/28 [00:23<00:17,  1.45s/it, loss=0.6587, batch_acc=0.7812, running_acc=0.8789]Evaluation epoch 39:  61%|██████    | 17/28 [00:23<00:12,  1.09s/it, loss=0.6587, batch_acc=0.7812, running_acc=0.8789]Evaluation epoch 39:  61%|██████    | 17/28 [00:23<00:12,  1.09s/it, loss=0.5266, batch_acc=0.7188, running_acc=0.8695]Evaluation epoch 39:  64%|██████▍   | 18/28 [00:23<00:08,  1.18it/s, loss=0.5266, batch_acc=0.7188, running_acc=0.8695]Evaluation epoch 39:  64%|██████▍   | 18/28 [00:23<00:08,  1.18it/s, loss=0.5206, batch_acc=0.8438, running_acc=0.8681]Evaluation epoch 39:  68%|██████▊   | 19/28 [00:24<00:06,  1.49it/s, loss=0.5206, batch_acc=0.8438, running_acc=0.8681]Evaluation epoch 39:  68%|██████▊   | 19/28 [00:24<00:06,  1.49it/s, loss=0.8951, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 39:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.8951, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 39:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.6421, batch_acc=0.6875, running_acc=0.8469]Evaluation epoch 39:  75%|███████▌  | 21/28 [00:27<00:07,  1.02s/it, loss=0.6421, batch_acc=0.6875, running_acc=0.8469]Evaluation epoch 39:  75%|███████▌  | 21/28 [00:27<00:07,  1.02s/it, loss=0.6006, batch_acc=0.8125, running_acc=0.8452]Evaluation epoch 39:  79%|███████▊  | 22/28 [00:27<00:04,  1.27it/s, loss=0.6006, batch_acc=0.8125, running_acc=0.8452]Evaluation epoch 39:  79%|███████▊  | 22/28 [00:27<00:04,  1.27it/s, loss=0.5431, batch_acc=0.8438, running_acc=0.8452]Evaluation epoch 39:  82%|████████▏ | 23/28 [00:27<00:03,  1.58it/s, loss=0.5431, batch_acc=0.8438, running_acc=0.8452]Evaluation epoch 39:  82%|████████▏ | 23/28 [00:27<00:03,  1.58it/s, loss=0.7523, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 39:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=0.7523, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 39:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=0.3590, batch_acc=0.9375, running_acc=0.8477]Evaluation epoch 39:  89%|████████▉ | 25/28 [00:33<00:04,  1.50s/it, loss=0.3590, batch_acc=0.9375, running_acc=0.8477]Evaluation epoch 39:  89%|████████▉ | 25/28 [00:33<00:04,  1.50s/it, loss=0.1673, batch_acc=0.9688, running_acc=0.8525]Evaluation epoch 39:  93%|█████████▎| 26/28 [00:33<00:02,  1.13s/it, loss=0.1673, batch_acc=0.9688, running_acc=0.8525]Evaluation epoch 39:  93%|█████████▎| 26/28 [00:33<00:02,  1.13s/it, loss=0.5612, batch_acc=0.8438, running_acc=0.8522]Evaluation epoch 39:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.5612, batch_acc=0.8438, running_acc=0.8522]Evaluation epoch 39:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.8834, batch_acc=0.7500, running_acc=0.8484]Evaluation epoch 39: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=1.2146, batch_acc=0.6667, running_acc=0.8478]Evaluation epoch 39: 100%|██████████| 28/28 [00:34<00:00,  1.22s/it, loss=1.2146, batch_acc=0.6667, running_acc=0.8478]
Training epoch 40:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 40:   1%|          | 1/163 [00:05<15:25,  5.71s/it]Training epoch 40:   1%|          | 1/163 [00:05<15:25,  5.71s/it, loss=0.1124, batch_acc=1.0000, running_acc=1.0000, grad=8.7825]Training epoch 40:   1%|          | 2/163 [00:06<07:41,  2.87s/it, loss=0.1124, batch_acc=1.0000, running_acc=1.0000, grad=8.7825]Training epoch 40:   1%|          | 2/163 [00:06<07:41,  2.87s/it, loss=0.0966, batch_acc=1.0000, running_acc=1.0000, grad=9.3181]Training epoch 40:   2%|▏         | 3/163 [00:07<05:13,  1.96s/it, loss=0.0966, batch_acc=1.0000, running_acc=1.0000, grad=9.3181]Training epoch 40:   2%|▏         | 3/163 [00:07<05:13,  1.96s/it, loss=0.1444, batch_acc=0.9688, running_acc=0.9896, grad=6.7467]Training epoch 40:   2%|▏         | 4/163 [00:10<06:07,  2.31s/it, loss=0.1444, batch_acc=0.9688, running_acc=0.9896, grad=6.7467]Training epoch 40:   2%|▏         | 4/163 [00:10<06:07,  2.31s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9844, grad=12.6172]Training epoch 40:   3%|▎         | 5/163 [00:11<04:43,  1.79s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9844, grad=12.6172]Training epoch 40:   3%|▎         | 5/163 [00:11<04:43,  1.79s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9875, grad=9.1414] Training epoch 40:   4%|▎         | 6/163 [00:12<03:53,  1.48s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9875, grad=9.1414]Training epoch 40:   4%|▎         | 6/163 [00:12<03:53,  1.48s/it, loss=0.1714, batch_acc=0.9375, running_acc=0.9792, grad=14.1819]Training epoch 40:   4%|▍         | 7/163 [00:12<03:20,  1.29s/it, loss=0.1714, batch_acc=0.9375, running_acc=0.9792, grad=14.1819]Training epoch 40:   4%|▍         | 7/163 [00:12<03:20,  1.29s/it, loss=0.0997, batch_acc=1.0000, running_acc=0.9821, grad=8.9851] Training epoch 40:   5%|▍         | 8/163 [00:14<03:34,  1.38s/it, loss=0.0997, batch_acc=1.0000, running_acc=0.9821, grad=8.9851]Training epoch 40:   5%|▍         | 8/163 [00:14<03:34,  1.38s/it, loss=0.0932, batch_acc=1.0000, running_acc=0.9844, grad=10.2274]Training epoch 40:   6%|▌         | 9/163 [00:15<03:08,  1.23s/it, loss=0.0932, batch_acc=1.0000, running_acc=0.9844, grad=10.2274]Training epoch 40:   6%|▌         | 9/163 [00:15<03:08,  1.23s/it, loss=0.1005, batch_acc=1.0000, running_acc=0.9861, grad=8.1322] Training epoch 40:   6%|▌         | 10/163 [00:16<02:51,  1.12s/it, loss=0.1005, batch_acc=1.0000, running_acc=0.9861, grad=8.1322]Training epoch 40:   6%|▌         | 10/163 [00:16<02:51,  1.12s/it, loss=0.1272, batch_acc=0.9688, running_acc=0.9844, grad=10.4813]Training epoch 40:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.1272, batch_acc=0.9688, running_acc=0.9844, grad=10.4813]Training epoch 40:   7%|▋         | 11/163 [00:17<02:39,  1.05s/it, loss=0.1311, batch_acc=0.9688, running_acc=0.9830, grad=9.0704] Training epoch 40:   7%|▋         | 12/163 [00:18<03:02,  1.21s/it, loss=0.1311, batch_acc=0.9688, running_acc=0.9830, grad=9.0704]Training epoch 40:   7%|▋         | 12/163 [00:18<03:02,  1.21s/it, loss=0.2035, batch_acc=0.9375, running_acc=0.9792, grad=14.2273]Training epoch 40:   8%|▊         | 13/163 [00:19<02:46,  1.11s/it, loss=0.2035, batch_acc=0.9375, running_acc=0.9792, grad=14.2273]Training epoch 40:   8%|▊         | 13/163 [00:19<02:46,  1.11s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9808, grad=7.6952] Training epoch 40:   9%|▊         | 14/163 [00:20<02:35,  1.04s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9808, grad=7.6952]Training epoch 40:   9%|▊         | 14/163 [00:20<02:35,  1.04s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9821, grad=12.3333]Training epoch 40:   9%|▉         | 15/163 [00:21<02:27,  1.01it/s, loss=0.1190, batch_acc=1.0000, running_acc=0.9821, grad=12.3333]Training epoch 40:   9%|▉         | 15/163 [00:21<02:27,  1.01it/s, loss=0.0662, batch_acc=1.0000, running_acc=0.9833, grad=4.7523] Training epoch 40:  10%|▉         | 16/163 [00:22<02:45,  1.13s/it, loss=0.0662, batch_acc=1.0000, running_acc=0.9833, grad=4.7523]Training epoch 40:  10%|▉         | 16/163 [00:22<02:45,  1.13s/it, loss=0.1745, batch_acc=0.9688, running_acc=0.9824, grad=15.4298]Training epoch 40:  10%|█         | 17/163 [00:23<02:33,  1.05s/it, loss=0.1745, batch_acc=0.9688, running_acc=0.9824, grad=15.4298]Training epoch 40:  10%|█         | 17/163 [00:23<02:33,  1.05s/it, loss=0.1131, batch_acc=1.0000, running_acc=0.9835, grad=7.8983] Training epoch 40:  11%|█         | 18/163 [00:24<02:25,  1.00s/it, loss=0.1131, batch_acc=1.0000, running_acc=0.9835, grad=7.8983]Training epoch 40:  11%|█         | 18/163 [00:24<02:25,  1.00s/it, loss=0.1469, batch_acc=0.9688, running_acc=0.9826, grad=12.2610]Training epoch 40:  12%|█▏        | 19/163 [00:25<02:19,  1.04it/s, loss=0.1469, batch_acc=0.9688, running_acc=0.9826, grad=12.2610]Training epoch 40:  12%|█▏        | 19/163 [00:25<02:19,  1.04it/s, loss=0.1368, batch_acc=1.0000, running_acc=0.9836, grad=15.1411]Training epoch 40:  12%|█▏        | 20/163 [00:27<03:00,  1.26s/it, loss=0.1368, batch_acc=1.0000, running_acc=0.9836, grad=15.1411]Training epoch 40:  12%|█▏        | 20/163 [00:27<03:00,  1.26s/it, loss=0.1095, batch_acc=1.0000, running_acc=0.9844, grad=9.3014] Training epoch 40:  13%|█▎        | 21/163 [00:28<02:42,  1.15s/it, loss=0.1095, batch_acc=1.0000, running_acc=0.9844, grad=9.3014]Training epoch 40:  13%|█▎        | 21/163 [00:28<02:42,  1.15s/it, loss=0.1717, batch_acc=0.9375, running_acc=0.9821, grad=14.2949]Training epoch 40:  13%|█▎        | 22/163 [00:29<02:30,  1.07s/it, loss=0.1717, batch_acc=0.9375, running_acc=0.9821, grad=14.2949]Training epoch 40:  13%|█▎        | 22/163 [00:29<02:30,  1.07s/it, loss=0.0945, batch_acc=0.9688, running_acc=0.9815, grad=6.5603] Training epoch 40:  14%|█▍        | 23/163 [00:30<02:21,  1.01s/it, loss=0.0945, batch_acc=0.9688, running_acc=0.9815, grad=6.5603]Training epoch 40:  14%|█▍        | 23/163 [00:30<02:21,  1.01s/it, loss=0.1403, batch_acc=0.9688, running_acc=0.9810, grad=8.9922]Training epoch 40:  15%|█▍        | 24/163 [00:31<02:49,  1.22s/it, loss=0.1403, batch_acc=0.9688, running_acc=0.9810, grad=8.9922]Training epoch 40:  15%|█▍        | 24/163 [00:31<02:49,  1.22s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9818, grad=12.7615]Training epoch 40:  15%|█▌        | 25/163 [00:32<02:34,  1.12s/it, loss=0.1190, batch_acc=1.0000, running_acc=0.9818, grad=12.7615]Training epoch 40:  15%|█▌        | 25/163 [00:32<02:34,  1.12s/it, loss=0.0827, batch_acc=1.0000, running_acc=0.9825, grad=6.8024] Training epoch 40:  16%|█▌        | 26/163 [00:33<02:23,  1.05s/it, loss=0.0827, batch_acc=1.0000, running_acc=0.9825, grad=6.8024]Training epoch 40:  16%|█▌        | 26/163 [00:33<02:23,  1.05s/it, loss=0.1464, batch_acc=1.0000, running_acc=0.9832, grad=19.8954]Training epoch 40:  17%|█▋        | 27/163 [00:34<02:15,  1.00it/s, loss=0.1464, batch_acc=1.0000, running_acc=0.9832, grad=19.8954]Training epoch 40:  17%|█▋        | 27/163 [00:34<02:15,  1.00it/s, loss=0.0820, batch_acc=1.0000, running_acc=0.9838, grad=6.2455] Training epoch 40:  17%|█▋        | 28/163 [00:36<02:57,  1.31s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9838, grad=6.2455]Training epoch 40:  17%|█▋        | 28/163 [00:36<02:57,  1.31s/it, loss=0.1558, batch_acc=0.9688, running_acc=0.9833, grad=11.2245]Training epoch 40:  18%|█▊        | 29/163 [00:37<02:38,  1.18s/it, loss=0.1558, batch_acc=0.9688, running_acc=0.9833, grad=11.2245]Training epoch 40:  18%|█▊        | 29/163 [00:37<02:38,  1.18s/it, loss=0.1397, batch_acc=0.9688, running_acc=0.9828, grad=11.4169]Training epoch 40:  18%|█▊        | 30/163 [00:38<02:25,  1.09s/it, loss=0.1397, batch_acc=0.9688, running_acc=0.9828, grad=11.4169]Training epoch 40:  18%|█▊        | 30/163 [00:38<02:25,  1.09s/it, loss=0.1426, batch_acc=1.0000, running_acc=0.9833, grad=11.8940]Training epoch 40:  19%|█▉        | 31/163 [00:39<02:15,  1.03s/it, loss=0.1426, batch_acc=1.0000, running_acc=0.9833, grad=11.8940]Training epoch 40:  19%|█▉        | 31/163 [00:39<02:15,  1.03s/it, loss=0.1210, batch_acc=1.0000, running_acc=0.9839, grad=9.6180] Training epoch 40:  20%|█▉        | 32/163 [00:41<03:15,  1.49s/it, loss=0.1210, batch_acc=1.0000, running_acc=0.9839, grad=9.6180]Training epoch 40:  20%|█▉        | 32/163 [00:41<03:15,  1.49s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9844, grad=7.0640]Training epoch 40:  20%|██        | 33/163 [00:42<02:50,  1.31s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9844, grad=7.0640]Training epoch 40:  20%|██        | 33/163 [00:42<02:50,  1.31s/it, loss=0.1505, batch_acc=0.9688, running_acc=0.9839, grad=10.0100]Training epoch 40:  21%|██        | 34/163 [00:43<02:32,  1.18s/it, loss=0.1505, batch_acc=0.9688, running_acc=0.9839, grad=10.0100]Training epoch 40:  21%|██        | 34/163 [00:43<02:32,  1.18s/it, loss=0.1430, batch_acc=0.9688, running_acc=0.9835, grad=8.1639] Training epoch 40:  21%|██▏       | 35/163 [00:44<02:19,  1.09s/it, loss=0.1430, batch_acc=0.9688, running_acc=0.9835, grad=8.1639]Training epoch 40:  21%|██▏       | 35/163 [00:44<02:19,  1.09s/it, loss=0.1159, batch_acc=1.0000, running_acc=0.9839, grad=10.3602]Training epoch 40:  22%|██▏       | 36/163 [00:46<02:56,  1.39s/it, loss=0.1159, batch_acc=1.0000, running_acc=0.9839, grad=10.3602]Training epoch 40:  22%|██▏       | 36/163 [00:46<02:56,  1.39s/it, loss=0.0719, batch_acc=1.0000, running_acc=0.9844, grad=7.4432] Training epoch 40:  23%|██▎       | 37/163 [00:47<02:36,  1.24s/it, loss=0.0719, batch_acc=1.0000, running_acc=0.9844, grad=7.4432]Training epoch 40:  23%|██▎       | 37/163 [00:47<02:36,  1.24s/it, loss=0.1183, batch_acc=1.0000, running_acc=0.9848, grad=9.7307]Training epoch 40:  23%|██▎       | 38/163 [00:48<02:21,  1.13s/it, loss=0.1183, batch_acc=1.0000, running_acc=0.9848, grad=9.7307]Training epoch 40:  23%|██▎       | 38/163 [00:48<02:21,  1.13s/it, loss=0.1164, batch_acc=1.0000, running_acc=0.9852, grad=8.8371]Training epoch 40:  24%|██▍       | 39/163 [00:49<02:11,  1.06s/it, loss=0.1164, batch_acc=1.0000, running_acc=0.9852, grad=8.8371]Training epoch 40:  24%|██▍       | 39/163 [00:49<02:11,  1.06s/it, loss=0.1779, batch_acc=0.9375, running_acc=0.9840, grad=13.6482]Training epoch 40:  25%|██▍       | 40/163 [00:50<02:40,  1.30s/it, loss=0.1779, batch_acc=0.9375, running_acc=0.9840, grad=13.6482]Training epoch 40:  25%|██▍       | 40/163 [00:50<02:40,  1.30s/it, loss=0.1117, batch_acc=1.0000, running_acc=0.9844, grad=12.4820]Training epoch 40:  25%|██▌       | 41/163 [00:51<02:23,  1.18s/it, loss=0.1117, batch_acc=1.0000, running_acc=0.9844, grad=12.4820]Training epoch 40:  25%|██▌       | 41/163 [00:51<02:23,  1.18s/it, loss=0.1211, batch_acc=1.0000, running_acc=0.9848, grad=12.6930]Training epoch 40:  26%|██▌       | 42/163 [00:52<02:11,  1.09s/it, loss=0.1211, batch_acc=1.0000, running_acc=0.9848, grad=12.6930]Training epoch 40:  26%|██▌       | 42/163 [00:52<02:11,  1.09s/it, loss=0.1562, batch_acc=0.9688, running_acc=0.9844, grad=18.0908]Training epoch 40:  26%|██▋       | 43/163 [00:53<02:03,  1.03s/it, loss=0.1562, batch_acc=0.9688, running_acc=0.9844, grad=18.0908]Training epoch 40:  26%|██▋       | 43/163 [00:53<02:03,  1.03s/it, loss=0.0843, batch_acc=1.0000, running_acc=0.9847, grad=6.9828] Training epoch 40:  27%|██▋       | 44/163 [00:55<02:19,  1.17s/it, loss=0.0843, batch_acc=1.0000, running_acc=0.9847, grad=6.9828]Training epoch 40:  27%|██▋       | 44/163 [00:55<02:19,  1.17s/it, loss=0.1461, batch_acc=0.9688, running_acc=0.9844, grad=10.9102]Training epoch 40:  28%|██▊       | 45/163 [00:56<02:08,  1.09s/it, loss=0.1461, batch_acc=0.9688, running_acc=0.9844, grad=10.9102]Training epoch 40:  28%|██▊       | 45/163 [00:56<02:08,  1.09s/it, loss=0.2325, batch_acc=0.8750, running_acc=0.9819, grad=17.6347]Training epoch 40:  28%|██▊       | 46/163 [00:56<01:59,  1.02s/it, loss=0.2325, batch_acc=0.8750, running_acc=0.9819, grad=17.6347]Training epoch 40:  28%|██▊       | 46/163 [00:56<01:59,  1.02s/it, loss=0.0959, batch_acc=1.0000, running_acc=0.9823, grad=9.6928] Training epoch 40:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.0959, batch_acc=1.0000, running_acc=0.9823, grad=9.6928]Training epoch 40:  29%|██▉       | 47/163 [00:57<01:53,  1.02it/s, loss=0.1570, batch_acc=0.9688, running_acc=0.9820, grad=16.9855]Training epoch 40:  29%|██▉       | 48/163 [00:59<02:13,  1.16s/it, loss=0.1570, batch_acc=0.9688, running_acc=0.9820, grad=16.9855]Training epoch 40:  29%|██▉       | 48/163 [00:59<02:13,  1.16s/it, loss=0.0977, batch_acc=1.0000, running_acc=0.9824, grad=5.9712] Training epoch 40:  30%|███       | 49/163 [01:00<02:02,  1.08s/it, loss=0.0977, batch_acc=1.0000, running_acc=0.9824, grad=5.9712]Training epoch 40:  30%|███       | 49/163 [01:00<02:02,  1.08s/it, loss=0.0771, batch_acc=1.0000, running_acc=0.9828, grad=6.0869]Training epoch 40:  31%|███       | 50/163 [01:01<01:55,  1.02s/it, loss=0.0771, batch_acc=1.0000, running_acc=0.9828, grad=6.0869]Training epoch 40:  31%|███       | 50/163 [01:01<01:55,  1.02s/it, loss=0.1379, batch_acc=1.0000, running_acc=0.9831, grad=12.7620]Training epoch 40:  31%|███▏      | 51/163 [01:02<01:49,  1.02it/s, loss=0.1379, batch_acc=1.0000, running_acc=0.9831, grad=12.7620]Training epoch 40:  31%|███▏      | 51/163 [01:02<01:49,  1.02it/s, loss=0.0954, batch_acc=1.0000, running_acc=0.9835, grad=8.5678] Training epoch 40:  32%|███▏      | 52/163 [01:03<02:17,  1.24s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9835, grad=8.5678]Training epoch 40:  32%|███▏      | 52/163 [01:03<02:17,  1.24s/it, loss=0.1966, batch_acc=0.9062, running_acc=0.9820, grad=10.4861]Training epoch 40:  33%|███▎      | 53/163 [01:04<02:04,  1.13s/it, loss=0.1966, batch_acc=0.9062, running_acc=0.9820, grad=10.4861]Training epoch 40:  33%|███▎      | 53/163 [01:04<02:04,  1.13s/it, loss=0.1223, batch_acc=0.9688, running_acc=0.9817, grad=11.4981]Training epoch 40:  33%|███▎      | 54/163 [01:05<01:55,  1.06s/it, loss=0.1223, batch_acc=0.9688, running_acc=0.9817, grad=11.4981]Training epoch 40:  33%|███▎      | 54/163 [01:05<01:55,  1.06s/it, loss=0.1317, batch_acc=1.0000, running_acc=0.9821, grad=10.3068]Training epoch 40:  34%|███▎      | 55/163 [01:06<01:48,  1.00s/it, loss=0.1317, batch_acc=1.0000, running_acc=0.9821, grad=10.3068]Training epoch 40:  34%|███▎      | 55/163 [01:06<01:48,  1.00s/it, loss=0.0679, batch_acc=1.0000, running_acc=0.9824, grad=4.8631] Training epoch 40:  34%|███▍      | 56/163 [01:08<02:10,  1.22s/it, loss=0.0679, batch_acc=1.0000, running_acc=0.9824, grad=4.8631]Training epoch 40:  34%|███▍      | 56/163 [01:08<02:10,  1.22s/it, loss=0.1101, batch_acc=0.9688, running_acc=0.9821, grad=8.2587]Training epoch 40:  35%|███▍      | 57/163 [01:09<01:58,  1.12s/it, loss=0.1101, batch_acc=0.9688, running_acc=0.9821, grad=8.2587]Training epoch 40:  35%|███▍      | 57/163 [01:09<01:58,  1.12s/it, loss=0.0972, batch_acc=1.0000, running_acc=0.9825, grad=7.1220]Training epoch 40:  36%|███▌      | 58/163 [01:09<01:49,  1.05s/it, loss=0.0972, batch_acc=1.0000, running_acc=0.9825, grad=7.1220]Training epoch 40:  36%|███▌      | 58/163 [01:09<01:49,  1.05s/it, loss=0.0841, batch_acc=1.0000, running_acc=0.9828, grad=8.7642]Training epoch 40:  36%|███▌      | 59/163 [01:10<01:43,  1.00it/s, loss=0.0841, batch_acc=1.0000, running_acc=0.9828, grad=8.7642]Training epoch 40:  36%|███▌      | 59/163 [01:10<01:43,  1.00it/s, loss=0.1261, batch_acc=0.9688, running_acc=0.9825, grad=10.9735]Training epoch 40:  37%|███▋      | 60/163 [01:12<02:15,  1.32s/it, loss=0.1261, batch_acc=0.9688, running_acc=0.9825, grad=10.9735]Training epoch 40:  37%|███▋      | 60/163 [01:12<02:15,  1.32s/it, loss=0.1124, batch_acc=0.9688, running_acc=0.9823, grad=8.1794] Training epoch 40:  37%|███▋      | 61/163 [01:13<02:00,  1.18s/it, loss=0.1124, batch_acc=0.9688, running_acc=0.9823, grad=8.1794]Training epoch 40:  37%|███▋      | 61/163 [01:13<02:00,  1.18s/it, loss=0.1061, batch_acc=1.0000, running_acc=0.9826, grad=14.5867]Training epoch 40:  38%|███▊      | 62/163 [01:14<01:50,  1.09s/it, loss=0.1061, batch_acc=1.0000, running_acc=0.9826, grad=14.5867]Training epoch 40:  38%|███▊      | 62/163 [01:14<01:50,  1.09s/it, loss=0.1508, batch_acc=0.9688, running_acc=0.9824, grad=16.1258]Training epoch 40:  39%|███▊      | 63/163 [01:15<01:42,  1.03s/it, loss=0.1508, batch_acc=0.9688, running_acc=0.9824, grad=16.1258]Training epoch 40:  39%|███▊      | 63/163 [01:15<01:42,  1.03s/it, loss=0.1563, batch_acc=1.0000, running_acc=0.9826, grad=14.9556]Training epoch 40:  39%|███▉      | 64/163 [01:17<02:07,  1.29s/it, loss=0.1563, batch_acc=1.0000, running_acc=0.9826, grad=14.9556]Training epoch 40:  39%|███▉      | 64/163 [01:17<02:07,  1.29s/it, loss=0.1056, batch_acc=1.0000, running_acc=0.9829, grad=8.8339] Training epoch 40:  40%|███▉      | 65/163 [01:18<01:54,  1.17s/it, loss=0.1056, batch_acc=1.0000, running_acc=0.9829, grad=8.8339]Training epoch 40:  40%|███▉      | 65/163 [01:18<01:54,  1.17s/it, loss=0.1114, batch_acc=0.9688, running_acc=0.9827, grad=7.4239]Training epoch 40:  40%|████      | 66/163 [01:19<01:44,  1.08s/it, loss=0.1114, batch_acc=0.9688, running_acc=0.9827, grad=7.4239]Training epoch 40:  40%|████      | 66/163 [01:19<01:44,  1.08s/it, loss=0.1425, batch_acc=1.0000, running_acc=0.9830, grad=12.8761]Training epoch 40:  41%|████      | 67/163 [01:20<01:37,  1.02s/it, loss=0.1425, batch_acc=1.0000, running_acc=0.9830, grad=12.8761]Training epoch 40:  41%|████      | 67/163 [01:20<01:37,  1.02s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9832, grad=7.0845] Training epoch 40:  42%|████▏     | 68/163 [01:21<01:48,  1.14s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9832, grad=7.0845]Training epoch 40:  42%|████▏     | 68/163 [01:21<01:48,  1.14s/it, loss=0.1243, batch_acc=1.0000, running_acc=0.9835, grad=14.6664]Training epoch 40:  42%|████▏     | 69/163 [01:22<01:40,  1.06s/it, loss=0.1243, batch_acc=1.0000, running_acc=0.9835, grad=14.6664]Training epoch 40:  42%|████▏     | 69/163 [01:22<01:40,  1.06s/it, loss=0.0879, batch_acc=1.0000, running_acc=0.9837, grad=7.7905] Training epoch 40:  43%|████▎     | 70/163 [01:23<01:33,  1.01s/it, loss=0.0879, batch_acc=1.0000, running_acc=0.9837, grad=7.7905]Training epoch 40:  43%|████▎     | 70/163 [01:23<01:33,  1.01s/it, loss=0.1183, batch_acc=1.0000, running_acc=0.9839, grad=9.8456]Training epoch 40:  44%|████▎     | 71/163 [01:24<01:29,  1.03it/s, loss=0.1183, batch_acc=1.0000, running_acc=0.9839, grad=9.8456]Training epoch 40:  44%|████▎     | 71/163 [01:24<01:29,  1.03it/s, loss=0.0797, batch_acc=1.0000, running_acc=0.9842, grad=7.0989]Training epoch 40:  44%|████▍     | 72/163 [01:25<01:45,  1.15s/it, loss=0.0797, batch_acc=1.0000, running_acc=0.9842, grad=7.0989]Training epoch 40:  44%|████▍     | 72/163 [01:25<01:45,  1.15s/it, loss=0.1504, batch_acc=1.0000, running_acc=0.9844, grad=10.7346]Training epoch 40:  45%|████▍     | 73/163 [01:26<01:36,  1.07s/it, loss=0.1504, batch_acc=1.0000, running_acc=0.9844, grad=10.7346]Training epoch 40:  45%|████▍     | 73/163 [01:26<01:36,  1.07s/it, loss=0.1149, batch_acc=0.9688, running_acc=0.9842, grad=7.1262] Training epoch 40:  45%|████▌     | 74/163 [01:27<01:30,  1.01s/it, loss=0.1149, batch_acc=0.9688, running_acc=0.9842, grad=7.1262]Training epoch 40:  45%|████▌     | 74/163 [01:27<01:30,  1.01s/it, loss=0.1914, batch_acc=0.9375, running_acc=0.9835, grad=13.7943]Training epoch 40:  46%|████▌     | 75/163 [01:28<01:25,  1.03it/s, loss=0.1914, batch_acc=0.9375, running_acc=0.9835, grad=13.7943]Training epoch 40:  46%|████▌     | 75/163 [01:28<01:25,  1.03it/s, loss=0.1485, batch_acc=0.9688, running_acc=0.9833, grad=10.7731]Training epoch 40:  47%|████▋     | 76/163 [01:29<01:38,  1.13s/it, loss=0.1485, batch_acc=0.9688, running_acc=0.9833, grad=10.7731]Training epoch 40:  47%|████▋     | 76/163 [01:29<01:38,  1.13s/it, loss=0.1224, batch_acc=0.9688, running_acc=0.9831, grad=9.8619] Training epoch 40:  47%|████▋     | 77/163 [01:30<01:30,  1.06s/it, loss=0.1224, batch_acc=0.9688, running_acc=0.9831, grad=9.8619]Training epoch 40:  47%|████▋     | 77/163 [01:30<01:30,  1.06s/it, loss=0.1586, batch_acc=0.9688, running_acc=0.9830, grad=15.3002]Training epoch 40:  48%|████▊     | 78/163 [01:31<01:25,  1.00s/it, loss=0.1586, batch_acc=0.9688, running_acc=0.9830, grad=15.3002]Training epoch 40:  48%|████▊     | 78/163 [01:31<01:25,  1.00s/it, loss=0.0670, batch_acc=1.0000, running_acc=0.9832, grad=5.2437] Training epoch 40:  48%|████▊     | 79/163 [01:32<01:21,  1.03it/s, loss=0.0670, batch_acc=1.0000, running_acc=0.9832, grad=5.2437]Training epoch 40:  48%|████▊     | 79/163 [01:32<01:21,  1.03it/s, loss=0.1908, batch_acc=0.9375, running_acc=0.9826, grad=14.3832]Training epoch 40:  49%|████▉     | 80/163 [01:34<01:45,  1.28s/it, loss=0.1908, batch_acc=0.9375, running_acc=0.9826, grad=14.3832]Training epoch 40:  49%|████▉     | 80/163 [01:34<01:45,  1.28s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9824, grad=12.4355]Training epoch 40:  50%|████▉     | 81/163 [01:35<01:34,  1.16s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9824, grad=12.4355]Training epoch 40:  50%|████▉     | 81/163 [01:35<01:34,  1.16s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9826, grad=5.9160] Training epoch 40:  50%|█████     | 82/163 [01:36<01:27,  1.07s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9826, grad=5.9160]Training epoch 40:  50%|█████     | 82/163 [01:36<01:27,  1.07s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9829, grad=6.3360]Training epoch 40:  51%|█████     | 83/163 [01:37<01:21,  1.02s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9829, grad=6.3360]Training epoch 40:  51%|█████     | 83/163 [01:37<01:21,  1.02s/it, loss=0.0732, batch_acc=1.0000, running_acc=0.9831, grad=5.2530]Training epoch 40:  52%|█████▏    | 84/163 [01:38<01:38,  1.25s/it, loss=0.0732, batch_acc=1.0000, running_acc=0.9831, grad=5.2530]Training epoch 40:  52%|█████▏    | 84/163 [01:38<01:38,  1.25s/it, loss=0.0689, batch_acc=1.0000, running_acc=0.9833, grad=5.4461]Training epoch 40:  52%|█████▏    | 85/163 [01:39<01:28,  1.14s/it, loss=0.0689, batch_acc=1.0000, running_acc=0.9833, grad=5.4461]Training epoch 40:  52%|█████▏    | 85/163 [01:39<01:28,  1.14s/it, loss=0.1036, batch_acc=0.9688, running_acc=0.9831, grad=10.4759]Training epoch 40:  53%|█████▎    | 86/163 [01:40<01:21,  1.06s/it, loss=0.1036, batch_acc=0.9688, running_acc=0.9831, grad=10.4759]Training epoch 40:  53%|█████▎    | 86/163 [01:40<01:21,  1.06s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9833, grad=13.6004]Training epoch 40:  53%|█████▎    | 87/163 [01:41<01:16,  1.01s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9833, grad=13.6004]Training epoch 40:  53%|█████▎    | 87/163 [01:41<01:16,  1.01s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9831, grad=9.7978] Training epoch 40:  54%|█████▍    | 88/163 [01:44<01:47,  1.43s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9831, grad=9.7978]Training epoch 40:  54%|█████▍    | 88/163 [01:44<01:47,  1.43s/it, loss=0.1017, batch_acc=1.0000, running_acc=0.9833, grad=8.2891]Training epoch 40:  55%|█████▍    | 89/163 [01:44<01:33,  1.26s/it, loss=0.1017, batch_acc=1.0000, running_acc=0.9833, grad=8.2891]Training epoch 40:  55%|█████▍    | 89/163 [01:44<01:33,  1.26s/it, loss=0.1781, batch_acc=0.9375, running_acc=0.9828, grad=14.6864]Training epoch 40:  55%|█████▌    | 90/163 [01:45<01:23,  1.15s/it, loss=0.1781, batch_acc=0.9375, running_acc=0.9828, grad=14.6864]Training epoch 40:  55%|█████▌    | 90/163 [01:45<01:23,  1.15s/it, loss=0.1332, batch_acc=0.9688, running_acc=0.9826, grad=8.0274] Training epoch 40:  56%|█████▌    | 91/163 [01:46<01:16,  1.07s/it, loss=0.1332, batch_acc=0.9688, running_acc=0.9826, grad=8.0274]Training epoch 40:  56%|█████▌    | 91/163 [01:46<01:16,  1.07s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9828, grad=7.7600]Training epoch 40:  56%|█████▋    | 92/163 [01:48<01:32,  1.31s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9828, grad=7.7600]Training epoch 40:  56%|█████▋    | 92/163 [01:48<01:32,  1.31s/it, loss=0.1523, batch_acc=0.9688, running_acc=0.9827, grad=15.4957]Training epoch 40:  57%|█████▋    | 93/163 [01:49<01:22,  1.18s/it, loss=0.1523, batch_acc=0.9688, running_acc=0.9827, grad=15.4957]Training epoch 40:  57%|█████▋    | 93/163 [01:49<01:22,  1.18s/it, loss=0.1208, batch_acc=0.9688, running_acc=0.9825, grad=9.3183] Training epoch 40:  58%|█████▊    | 94/163 [01:50<01:15,  1.09s/it, loss=0.1208, batch_acc=0.9688, running_acc=0.9825, grad=9.3183]Training epoch 40:  58%|█████▊    | 94/163 [01:50<01:15,  1.09s/it, loss=0.1769, batch_acc=0.9375, running_acc=0.9820, grad=13.1978]Training epoch 40:  58%|█████▊    | 95/163 [01:51<01:09,  1.03s/it, loss=0.1769, batch_acc=0.9375, running_acc=0.9820, grad=13.1978]Training epoch 40:  58%|█████▊    | 95/163 [01:51<01:09,  1.03s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9822, grad=10.9075]Training epoch 40:  59%|█████▉    | 96/163 [01:52<01:18,  1.18s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9822, grad=10.9075]Training epoch 40:  59%|█████▉    | 96/163 [01:52<01:18,  1.18s/it, loss=0.1315, batch_acc=0.9688, running_acc=0.9821, grad=12.0917]Training epoch 40:  60%|█████▉    | 97/163 [01:53<01:11,  1.09s/it, loss=0.1315, batch_acc=0.9688, running_acc=0.9821, grad=12.0917]Training epoch 40:  60%|█████▉    | 97/163 [01:53<01:11,  1.09s/it, loss=0.1070, batch_acc=1.0000, running_acc=0.9823, grad=9.0685] Training epoch 40:  60%|██████    | 98/163 [01:54<01:06,  1.03s/it, loss=0.1070, batch_acc=1.0000, running_acc=0.9823, grad=9.0685]Training epoch 40:  60%|██████    | 98/163 [01:54<01:06,  1.03s/it, loss=0.1526, batch_acc=0.9688, running_acc=0.9821, grad=11.3021]Training epoch 40:  61%|██████    | 99/163 [01:55<01:02,  1.02it/s, loss=0.1526, batch_acc=0.9688, running_acc=0.9821, grad=11.3021]Training epoch 40:  61%|██████    | 99/163 [01:55<01:02,  1.02it/s, loss=0.1285, batch_acc=1.0000, running_acc=0.9823, grad=9.9253] Training epoch 40:  61%|██████▏   | 100/163 [01:56<01:09,  1.11s/it, loss=0.1285, batch_acc=1.0000, running_acc=0.9823, grad=9.9253]Training epoch 40:  61%|██████▏   | 100/163 [01:56<01:09,  1.11s/it, loss=0.0790, batch_acc=1.0000, running_acc=0.9825, grad=7.7751]Training epoch 40:  62%|██████▏   | 101/163 [01:57<01:04,  1.04s/it, loss=0.0790, batch_acc=1.0000, running_acc=0.9825, grad=7.7751]Training epoch 40:  62%|██████▏   | 101/163 [01:57<01:04,  1.04s/it, loss=0.0887, batch_acc=1.0000, running_acc=0.9827, grad=6.5150]Training epoch 40:  63%|██████▎   | 102/163 [01:58<01:00,  1.01it/s, loss=0.0887, batch_acc=1.0000, running_acc=0.9827, grad=6.5150]Training epoch 40:  63%|██████▎   | 102/163 [01:58<01:00,  1.01it/s, loss=0.1312, batch_acc=0.9688, running_acc=0.9825, grad=10.7889]Training epoch 40:  63%|██████▎   | 103/163 [01:59<00:57,  1.04it/s, loss=0.1312, batch_acc=0.9688, running_acc=0.9825, grad=10.7889]Training epoch 40:  63%|██████▎   | 103/163 [01:59<00:57,  1.04it/s, loss=0.1364, batch_acc=0.9688, running_acc=0.9824, grad=9.5268] Training epoch 40:  64%|██████▍   | 104/163 [02:01<01:19,  1.34s/it, loss=0.1364, batch_acc=0.9688, running_acc=0.9824, grad=9.5268]Training epoch 40:  64%|██████▍   | 104/163 [02:01<01:19,  1.34s/it, loss=0.1313, batch_acc=0.9688, running_acc=0.9823, grad=12.2725]Training epoch 40:  64%|██████▍   | 105/163 [02:02<01:09,  1.20s/it, loss=0.1313, batch_acc=0.9688, running_acc=0.9823, grad=12.2725]Training epoch 40:  64%|██████▍   | 105/163 [02:02<01:09,  1.20s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9824, grad=9.8192] Training epoch 40:  65%|██████▌   | 106/163 [02:03<01:03,  1.11s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9824, grad=9.8192]Training epoch 40:  65%|██████▌   | 106/163 [02:03<01:03,  1.11s/it, loss=0.1184, batch_acc=1.0000, running_acc=0.9826, grad=11.6175]Training epoch 40:  66%|██████▌   | 107/163 [02:04<00:58,  1.04s/it, loss=0.1184, batch_acc=1.0000, running_acc=0.9826, grad=11.6175]Training epoch 40:  66%|██████▌   | 107/163 [02:04<00:58,  1.04s/it, loss=0.0751, batch_acc=1.0000, running_acc=0.9828, grad=6.2856] Training epoch 40:  66%|██████▋   | 108/163 [02:05<01:03,  1.16s/it, loss=0.0751, batch_acc=1.0000, running_acc=0.9828, grad=6.2856]Training epoch 40:  66%|██████▋   | 108/163 [02:05<01:03,  1.16s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9829, grad=6.9608]Training epoch 40:  67%|██████▋   | 109/163 [02:06<00:57,  1.07s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9829, grad=6.9608]Training epoch 40:  67%|██████▋   | 109/163 [02:06<00:57,  1.07s/it, loss=0.1618, batch_acc=0.9375, running_acc=0.9825, grad=11.8943]Training epoch 40:  67%|██████▋   | 110/163 [02:07<00:53,  1.02s/it, loss=0.1618, batch_acc=0.9375, running_acc=0.9825, grad=11.8943]Training epoch 40:  67%|██████▋   | 110/163 [02:07<00:53,  1.02s/it, loss=0.1507, batch_acc=0.9688, running_acc=0.9824, grad=15.0255]Training epoch 40:  68%|██████▊   | 111/163 [02:08<00:50,  1.03it/s, loss=0.1507, batch_acc=0.9688, running_acc=0.9824, grad=15.0255]Training epoch 40:  68%|██████▊   | 111/163 [02:08<00:50,  1.03it/s, loss=0.0827, batch_acc=1.0000, running_acc=0.9825, grad=7.9587] Training epoch 40:  69%|██████▊   | 112/163 [02:10<01:06,  1.31s/it, loss=0.0827, batch_acc=1.0000, running_acc=0.9825, grad=7.9587]Training epoch 40:  69%|██████▊   | 112/163 [02:10<01:06,  1.31s/it, loss=0.1244, batch_acc=0.9688, running_acc=0.9824, grad=8.8164]Training epoch 40:  69%|██████▉   | 113/163 [02:11<00:58,  1.18s/it, loss=0.1244, batch_acc=0.9688, running_acc=0.9824, grad=8.8164]Training epoch 40:  69%|██████▉   | 113/163 [02:11<00:58,  1.18s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9826, grad=6.5933]Training epoch 40:  70%|██████▉   | 114/163 [02:12<00:53,  1.09s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9826, grad=6.5933]Training epoch 40:  70%|██████▉   | 114/163 [02:12<00:53,  1.09s/it, loss=0.0904, batch_acc=1.0000, running_acc=0.9827, grad=8.8898]Training epoch 40:  71%|███████   | 115/163 [02:13<00:49,  1.03s/it, loss=0.0904, batch_acc=1.0000, running_acc=0.9827, grad=8.8898]Training epoch 40:  71%|███████   | 115/163 [02:13<00:49,  1.03s/it, loss=0.1330, batch_acc=0.9688, running_acc=0.9826, grad=8.6043]Training epoch 40:  71%|███████   | 116/163 [02:14<00:58,  1.24s/it, loss=0.1330, batch_acc=0.9688, running_acc=0.9826, grad=8.6043]Training epoch 40:  71%|███████   | 116/163 [02:14<00:58,  1.24s/it, loss=0.1576, batch_acc=0.9375, running_acc=0.9822, grad=14.3136]Training epoch 40:  72%|███████▏  | 117/163 [02:15<00:52,  1.14s/it, loss=0.1576, batch_acc=0.9375, running_acc=0.9822, grad=14.3136]Training epoch 40:  72%|███████▏  | 117/163 [02:15<00:52,  1.14s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9824, grad=7.0478] Training epoch 40:  72%|███████▏  | 118/163 [02:16<00:47,  1.06s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9824, grad=7.0478]Training epoch 40:  72%|███████▏  | 118/163 [02:16<00:47,  1.06s/it, loss=0.1384, batch_acc=1.0000, running_acc=0.9825, grad=12.9995]Training epoch 40:  73%|███████▎  | 119/163 [02:17<00:44,  1.01s/it, loss=0.1384, batch_acc=1.0000, running_acc=0.9825, grad=12.9995]Training epoch 40:  73%|███████▎  | 119/163 [02:17<00:44,  1.01s/it, loss=0.1114, batch_acc=1.0000, running_acc=0.9827, grad=10.9589]Training epoch 40:  74%|███████▎  | 120/163 [02:19<00:59,  1.39s/it, loss=0.1114, batch_acc=1.0000, running_acc=0.9827, grad=10.9589]Training epoch 40:  74%|███████▎  | 120/163 [02:19<00:59,  1.39s/it, loss=0.1192, batch_acc=1.0000, running_acc=0.9828, grad=17.0273]Training epoch 40:  74%|███████▍  | 121/163 [02:20<00:51,  1.24s/it, loss=0.1192, batch_acc=1.0000, running_acc=0.9828, grad=17.0273]Training epoch 40:  74%|███████▍  | 121/163 [02:20<00:51,  1.24s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9830, grad=10.0828]Training epoch 40:  75%|███████▍  | 122/163 [02:21<00:46,  1.13s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9830, grad=10.0828]Training epoch 40:  75%|███████▍  | 122/163 [02:21<00:46,  1.13s/it, loss=0.0931, batch_acc=1.0000, running_acc=0.9831, grad=8.7929] Training epoch 40:  75%|███████▌  | 123/163 [02:22<00:42,  1.05s/it, loss=0.0931, batch_acc=1.0000, running_acc=0.9831, grad=8.7929]Training epoch 40:  75%|███████▌  | 123/163 [02:22<00:42,  1.05s/it, loss=0.0823, batch_acc=1.0000, running_acc=0.9832, grad=7.9244]Training epoch 40:  76%|███████▌  | 124/163 [02:23<00:44,  1.15s/it, loss=0.0823, batch_acc=1.0000, running_acc=0.9832, grad=7.9244]Training epoch 40:  76%|███████▌  | 124/163 [02:23<00:44,  1.15s/it, loss=0.1650, batch_acc=0.9062, running_acc=0.9826, grad=9.9095]Training epoch 40:  77%|███████▋  | 125/163 [02:24<00:40,  1.07s/it, loss=0.1650, batch_acc=0.9062, running_acc=0.9826, grad=9.9095]Training epoch 40:  77%|███████▋  | 125/163 [02:24<00:40,  1.07s/it, loss=0.0810, batch_acc=1.0000, running_acc=0.9828, grad=7.8238]Training epoch 40:  77%|███████▋  | 126/163 [02:25<00:37,  1.01s/it, loss=0.0810, batch_acc=1.0000, running_acc=0.9828, grad=7.8238]Training epoch 40:  77%|███████▋  | 126/163 [02:25<00:37,  1.01s/it, loss=0.1319, batch_acc=1.0000, running_acc=0.9829, grad=6.2565]Training epoch 40:  78%|███████▊  | 127/163 [02:26<00:35,  1.03it/s, loss=0.1319, batch_acc=1.0000, running_acc=0.9829, grad=6.2565]Training epoch 40:  78%|███████▊  | 127/163 [02:26<00:35,  1.03it/s, loss=0.1337, batch_acc=0.9688, running_acc=0.9828, grad=10.9825]Training epoch 40:  79%|███████▊  | 128/163 [02:27<00:34,  1.01it/s, loss=0.1337, batch_acc=0.9688, running_acc=0.9828, grad=10.9825]Training epoch 40:  79%|███████▊  | 128/163 [02:27<00:34,  1.01it/s, loss=0.1471, batch_acc=0.9688, running_acc=0.9827, grad=12.3964]Training epoch 40:  79%|███████▉  | 129/163 [02:28<00:32,  1.05it/s, loss=0.1471, batch_acc=0.9688, running_acc=0.9827, grad=12.3964]Training epoch 40:  79%|███████▉  | 129/163 [02:28<00:32,  1.05it/s, loss=0.1571, batch_acc=1.0000, running_acc=0.9828, grad=10.2835]Training epoch 40:  80%|███████▉  | 130/163 [02:29<00:30,  1.07it/s, loss=0.1571, batch_acc=1.0000, running_acc=0.9828, grad=10.2835]Training epoch 40:  80%|███████▉  | 130/163 [02:29<00:30,  1.07it/s, loss=0.1386, batch_acc=0.9688, running_acc=0.9827, grad=7.4441] Training epoch 40:  80%|████████  | 131/163 [02:30<00:29,  1.09it/s, loss=0.1386, batch_acc=0.9688, running_acc=0.9827, grad=7.4441]Training epoch 40:  80%|████████  | 131/163 [02:30<00:29,  1.09it/s, loss=0.1169, batch_acc=0.9688, running_acc=0.9826, grad=23.2027]Training epoch 40:  81%|████████  | 132/163 [02:31<00:34,  1.13s/it, loss=0.1169, batch_acc=0.9688, running_acc=0.9826, grad=23.2027]Training epoch 40:  81%|████████  | 132/163 [02:31<00:34,  1.13s/it, loss=0.1325, batch_acc=0.9688, running_acc=0.9825, grad=16.8381]Training epoch 40:  82%|████████▏ | 133/163 [02:32<00:31,  1.05s/it, loss=0.1325, batch_acc=0.9688, running_acc=0.9825, grad=16.8381]Training epoch 40:  82%|████████▏ | 133/163 [02:32<00:31,  1.05s/it, loss=0.0869, batch_acc=1.0000, running_acc=0.9826, grad=7.8067] Training epoch 40:  82%|████████▏ | 134/163 [02:33<00:29,  1.00s/it, loss=0.0869, batch_acc=1.0000, running_acc=0.9826, grad=7.8067]Training epoch 40:  82%|████████▏ | 134/163 [02:33<00:29,  1.00s/it, loss=0.1422, batch_acc=1.0000, running_acc=0.9827, grad=13.4167]Training epoch 40:  83%|████████▎ | 135/163 [02:34<00:27,  1.04it/s, loss=0.1422, batch_acc=1.0000, running_acc=0.9827, grad=13.4167]Training epoch 40:  83%|████████▎ | 135/163 [02:34<00:27,  1.04it/s, loss=0.0957, batch_acc=1.0000, running_acc=0.9829, grad=6.4372] Training epoch 40:  83%|████████▎ | 136/163 [02:36<00:32,  1.20s/it, loss=0.0957, batch_acc=1.0000, running_acc=0.9829, grad=6.4372]Training epoch 40:  83%|████████▎ | 136/163 [02:36<00:32,  1.20s/it, loss=0.1455, batch_acc=0.9375, running_acc=0.9825, grad=6.4219]Training epoch 40:  84%|████████▍ | 137/163 [02:36<00:28,  1.10s/it, loss=0.1455, batch_acc=0.9375, running_acc=0.9825, grad=6.4219]Training epoch 40:  84%|████████▍ | 137/163 [02:36<00:28,  1.10s/it, loss=0.1729, batch_acc=0.9688, running_acc=0.9824, grad=12.1712]Training epoch 40:  85%|████████▍ | 138/163 [02:37<00:25,  1.04s/it, loss=0.1729, batch_acc=0.9688, running_acc=0.9824, grad=12.1712]Training epoch 40:  85%|████████▍ | 138/163 [02:37<00:25,  1.04s/it, loss=0.1378, batch_acc=1.0000, running_acc=0.9826, grad=10.2545]Training epoch 40:  85%|████████▌ | 139/163 [02:38<00:23,  1.01it/s, loss=0.1378, batch_acc=1.0000, running_acc=0.9826, grad=10.2545]Training epoch 40:  85%|████████▌ | 139/163 [02:38<00:23,  1.01it/s, loss=0.1404, batch_acc=0.9688, running_acc=0.9825, grad=10.0572]Training epoch 40:  86%|████████▌ | 140/163 [02:40<00:25,  1.09s/it, loss=0.1404, batch_acc=0.9688, running_acc=0.9825, grad=10.0572]Training epoch 40:  86%|████████▌ | 140/163 [02:40<00:25,  1.09s/it, loss=0.1332, batch_acc=1.0000, running_acc=0.9826, grad=11.3549]Training epoch 40:  87%|████████▋ | 141/163 [02:40<00:22,  1.03s/it, loss=0.1332, batch_acc=1.0000, running_acc=0.9826, grad=11.3549]Training epoch 40:  87%|████████▋ | 141/163 [02:40<00:22,  1.03s/it, loss=0.1363, batch_acc=0.9688, running_acc=0.9825, grad=9.2342] Training epoch 40:  87%|████████▋ | 142/163 [02:41<00:20,  1.02it/s, loss=0.1363, batch_acc=0.9688, running_acc=0.9825, grad=9.2342]Training epoch 40:  87%|████████▋ | 142/163 [02:41<00:20,  1.02it/s, loss=0.1171, batch_acc=1.0000, running_acc=0.9826, grad=15.6129]Training epoch 40:  88%|████████▊ | 143/163 [02:42<00:19,  1.05it/s, loss=0.1171, batch_acc=1.0000, running_acc=0.9826, grad=15.6129]Training epoch 40:  88%|████████▊ | 143/163 [02:42<00:19,  1.05it/s, loss=0.1132, batch_acc=0.9688, running_acc=0.9825, grad=11.6140]Training epoch 40:  88%|████████▊ | 144/163 [02:44<00:22,  1.20s/it, loss=0.1132, batch_acc=0.9688, running_acc=0.9825, grad=11.6140]Training epoch 40:  88%|████████▊ | 144/163 [02:44<00:22,  1.20s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9826, grad=9.7400] Training epoch 40:  89%|████████▉ | 145/163 [02:45<00:19,  1.10s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9826, grad=9.7400]Training epoch 40:  89%|████████▉ | 145/163 [02:45<00:19,  1.10s/it, loss=0.1884, batch_acc=1.0000, running_acc=0.9828, grad=18.5432]Training epoch 40:  90%|████████▉ | 146/163 [02:46<00:17,  1.04s/it, loss=0.1884, batch_acc=1.0000, running_acc=0.9828, grad=18.5432]Training epoch 40:  90%|████████▉ | 146/163 [02:46<00:17,  1.04s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9829, grad=11.6850]Training epoch 40:  90%|█████████ | 147/163 [02:47<00:15,  1.01it/s, loss=0.0970, batch_acc=1.0000, running_acc=0.9829, grad=11.6850]Training epoch 40:  90%|█████████ | 147/163 [02:47<00:15,  1.01it/s, loss=0.1372, batch_acc=0.9688, running_acc=0.9828, grad=12.0667]Training epoch 40:  91%|█████████ | 148/163 [02:48<00:18,  1.21s/it, loss=0.1372, batch_acc=0.9688, running_acc=0.9828, grad=12.0667]Training epoch 40:  91%|█████████ | 148/163 [02:48<00:18,  1.21s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9829, grad=8.9003] Training epoch 40:  91%|█████████▏| 149/163 [02:49<00:15,  1.11s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9829, grad=8.9003]Training epoch 40:  91%|█████████▏| 149/163 [02:49<00:15,  1.11s/it, loss=0.1165, batch_acc=1.0000, running_acc=0.9830, grad=11.5393]Training epoch 40:  92%|█████████▏| 150/163 [02:50<00:13,  1.04s/it, loss=0.1165, batch_acc=1.0000, running_acc=0.9830, grad=11.5393]Training epoch 40:  92%|█████████▏| 150/163 [02:50<00:13,  1.04s/it, loss=0.0908, batch_acc=1.0000, running_acc=0.9831, grad=7.8328] Training epoch 40:  93%|█████████▎| 151/163 [02:51<00:11,  1.01it/s, loss=0.0908, batch_acc=1.0000, running_acc=0.9831, grad=7.8328]Training epoch 40:  93%|█████████▎| 151/163 [02:51<00:11,  1.01it/s, loss=0.1336, batch_acc=1.0000, running_acc=0.9832, grad=11.7822]Training epoch 40:  93%|█████████▎| 152/163 [02:52<00:10,  1.01it/s, loss=0.1336, batch_acc=1.0000, running_acc=0.9832, grad=11.7822]Training epoch 40:  93%|█████████▎| 152/163 [02:52<00:10,  1.01it/s, loss=0.1302, batch_acc=0.9688, running_acc=0.9831, grad=9.3902] Training epoch 40:  94%|█████████▍| 153/163 [02:53<00:09,  1.05it/s, loss=0.1302, batch_acc=0.9688, running_acc=0.9831, grad=9.3902]Training epoch 40:  94%|█████████▍| 153/163 [02:53<00:09,  1.05it/s, loss=0.1679, batch_acc=0.9688, running_acc=0.9830, grad=11.5963]Training epoch 40:  94%|█████████▍| 154/163 [02:54<00:08,  1.07it/s, loss=0.1679, batch_acc=0.9688, running_acc=0.9830, grad=11.5963]Training epoch 40:  94%|█████████▍| 154/163 [02:54<00:08,  1.07it/s, loss=0.1779, batch_acc=0.9688, running_acc=0.9830, grad=19.0097]Training epoch 40:  95%|█████████▌| 155/163 [02:55<00:07,  1.09it/s, loss=0.1779, batch_acc=0.9688, running_acc=0.9830, grad=19.0097]Training epoch 40:  95%|█████████▌| 155/163 [02:55<00:07,  1.09it/s, loss=0.1575, batch_acc=0.9688, running_acc=0.9829, grad=15.5382]Training epoch 40:  96%|█████████▌| 156/163 [02:56<00:08,  1.21s/it, loss=0.1575, batch_acc=0.9688, running_acc=0.9829, grad=15.5382]Training epoch 40:  96%|█████████▌| 156/163 [02:56<00:08,  1.21s/it, loss=0.1789, batch_acc=1.0000, running_acc=0.9830, grad=14.4678]Training epoch 40:  96%|█████████▋| 157/163 [02:57<00:06,  1.11s/it, loss=0.1789, batch_acc=1.0000, running_acc=0.9830, grad=14.4678]Training epoch 40:  96%|█████████▋| 157/163 [02:57<00:06,  1.11s/it, loss=0.1455, batch_acc=1.0000, running_acc=0.9831, grad=12.4641]Training epoch 40:  97%|█████████▋| 158/163 [02:58<00:05,  1.04s/it, loss=0.1455, batch_acc=1.0000, running_acc=0.9831, grad=12.4641]Training epoch 40:  97%|█████████▋| 158/163 [02:58<00:05,  1.04s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9830, grad=8.4638] Training epoch 40:  98%|█████████▊| 159/163 [02:59<00:03,  1.00it/s, loss=0.1457, batch_acc=0.9688, running_acc=0.9830, grad=8.4638]Training epoch 40:  98%|█████████▊| 159/163 [02:59<00:03,  1.00it/s, loss=0.1235, batch_acc=1.0000, running_acc=0.9831, grad=9.7769]Training epoch 40:  98%|█████████▊| 160/163 [03:00<00:03,  1.03s/it, loss=0.1235, batch_acc=1.0000, running_acc=0.9831, grad=9.7769]Training epoch 40:  98%|█████████▊| 160/163 [03:00<00:03,  1.03s/it, loss=0.0953, batch_acc=1.0000, running_acc=0.9832, grad=8.1204]Training epoch 40:  99%|█████████▉| 161/163 [03:01<00:01,  1.02it/s, loss=0.0953, batch_acc=1.0000, running_acc=0.9832, grad=8.1204]Training epoch 40:  99%|█████████▉| 161/163 [03:01<00:01,  1.02it/s, loss=0.0918, batch_acc=1.0000, running_acc=0.9833, grad=7.2607]Training epoch 40:  99%|█████████▉| 162/163 [03:02<00:00,  1.05it/s, loss=0.0918, batch_acc=1.0000, running_acc=0.9833, grad=7.2607]Training epoch 40:  99%|█████████▉| 162/163 [03:02<00:00,  1.05it/s, loss=0.0655, batch_acc=1.0000, running_acc=0.9834, grad=5.7981]Training epoch 40: 100%|██████████| 163/163 [03:03<00:00,  1.17it/s, loss=0.0655, batch_acc=1.0000, running_acc=0.9834, grad=5.7981]Training epoch 40: 100%|██████████| 163/163 [03:03<00:00,  1.17it/s, loss=0.0773, batch_acc=1.0000, running_acc=0.9835, grad=8.6009]Training epoch 40: 100%|██████████| 163/163 [03:03<00:00,  1.12s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9835, grad=8.6009]
Evaluation epoch 40:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 40:   4%|▎         | 1/28 [00:04<02:12,  4.93s/it]Evaluation epoch 40:   4%|▎         | 1/28 [00:04<02:12,  4.93s/it, loss=0.4048, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 40:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.4048, batch_acc=0.8750, running_acc=0.8750]Evaluation epoch 40:   7%|▋         | 2/28 [00:05<00:57,  2.22s/it, loss=0.2262, batch_acc=0.9688, running_acc=0.9219]Evaluation epoch 40:  11%|█         | 3/28 [00:05<00:33,  1.32s/it, loss=0.2262, batch_acc=0.9688, running_acc=0.9219]Evaluation epoch 40:  11%|█         | 3/28 [00:05<00:33,  1.32s/it, loss=0.3054, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 40:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.3054, batch_acc=0.9688, running_acc=0.9375]Evaluation epoch 40:  14%|█▍        | 4/28 [00:09<00:59,  2.47s/it, loss=0.4732, batch_acc=0.9062, running_acc=0.9297]Evaluation epoch 40:  18%|█▊        | 5/28 [00:09<00:38,  1.67s/it, loss=0.4732, batch_acc=0.9062, running_acc=0.9297]Evaluation epoch 40:  18%|█▊        | 5/28 [00:09<00:38,  1.67s/it, loss=1.2829, batch_acc=0.7188, running_acc=0.8875]Evaluation epoch 40:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=1.2829, batch_acc=0.7188, running_acc=0.8875]Evaluation epoch 40:  21%|██▏       | 6/28 [00:10<00:26,  1.19s/it, loss=0.4977, batch_acc=0.9062, running_acc=0.8906]Evaluation epoch 40:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.4977, batch_acc=0.9062, running_acc=0.8906]Evaluation epoch 40:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.5924, batch_acc=0.9062, running_acc=0.8929]Evaluation epoch 40:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.5924, batch_acc=0.9062, running_acc=0.8929]Evaluation epoch 40:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.4192, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 40:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=0.4192, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 40:  32%|███▏      | 9/28 [00:14<00:25,  1.36s/it, loss=0.4073, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 40:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.4073, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 40:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.4203, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 40:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.4203, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 40:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.3047, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 40:  43%|████▎     | 12/28 [00:20<00:34,  2.15s/it, loss=0.3047, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 40:  43%|████▎     | 12/28 [00:20<00:34,  2.15s/it, loss=0.8862, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 40:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.8862, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 40:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.2898, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 40:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.2898, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 40:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.8679, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 40:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=0.8679, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 40:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=0.9652, batch_acc=0.8125, running_acc=0.8792]Evaluation epoch 40:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=0.9652, batch_acc=0.8125, running_acc=0.8792]Evaluation epoch 40:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=0.9609, batch_acc=0.7188, running_acc=0.8691]Evaluation epoch 40:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.9609, batch_acc=0.7188, running_acc=0.8691]Evaluation epoch 40:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.7393, batch_acc=0.7188, running_acc=0.8603]Evaluation epoch 40:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.7393, batch_acc=0.7188, running_acc=0.8603]Evaluation epoch 40:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5692, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 40:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.5692, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 40:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.8581, batch_acc=0.6875, running_acc=0.8503]Evaluation epoch 40:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.8581, batch_acc=0.6875, running_acc=0.8503]Evaluation epoch 40:  71%|███████▏  | 20/28 [00:27<00:10,  1.34s/it, loss=0.5056, batch_acc=0.7500, running_acc=0.8453]Evaluation epoch 40:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=0.5056, batch_acc=0.7500, running_acc=0.8453]Evaluation epoch 40:  75%|███████▌  | 21/28 [00:27<00:07,  1.01s/it, loss=0.5899, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 40:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.5899, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 40:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.3710, batch_acc=0.9688, running_acc=0.8494]Evaluation epoch 40:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=0.3710, batch_acc=0.9688, running_acc=0.8494]Evaluation epoch 40:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=0.9924, batch_acc=0.7500, running_acc=0.8451]Evaluation epoch 40:  86%|████████▌ | 24/28 [00:33<00:08,  2.01s/it, loss=0.9924, batch_acc=0.7500, running_acc=0.8451]Evaluation epoch 40:  86%|████████▌ | 24/28 [00:33<00:08,  2.01s/it, loss=0.3101, batch_acc=0.9375, running_acc=0.8490]Evaluation epoch 40:  89%|████████▉ | 25/28 [00:33<00:04,  1.49s/it, loss=0.3101, batch_acc=0.9375, running_acc=0.8490]Evaluation epoch 40:  89%|████████▉ | 25/28 [00:33<00:04,  1.49s/it, loss=0.1274, batch_acc=1.0000, running_acc=0.8550]Evaluation epoch 40:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.1274, batch_acc=1.0000, running_acc=0.8550]Evaluation epoch 40:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.5597, batch_acc=0.8438, running_acc=0.8546]Evaluation epoch 40:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.5597, batch_acc=0.8438, running_acc=0.8546]Evaluation epoch 40:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.8078, batch_acc=0.7812, running_acc=0.8519]Evaluation epoch 40: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=1.1882, batch_acc=0.6667, running_acc=0.8512]Evaluation epoch 40: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=1.1882, batch_acc=0.6667, running_acc=0.8512]
Training epoch 41:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 41:   1%|          | 1/163 [00:05<14:45,  5.47s/it]Training epoch 41:   1%|          | 1/163 [00:05<14:45,  5.47s/it, loss=0.0789, batch_acc=1.0000, running_acc=1.0000, grad=5.5709]Training epoch 41:   1%|          | 2/163 [00:06<07:31,  2.81s/it, loss=0.0789, batch_acc=1.0000, running_acc=1.0000, grad=5.5709]Training epoch 41:   1%|          | 2/163 [00:06<07:31,  2.81s/it, loss=0.1332, batch_acc=1.0000, running_acc=1.0000, grad=11.7041]Training epoch 41:   2%|▏         | 3/163 [00:07<05:07,  1.92s/it, loss=0.1332, batch_acc=1.0000, running_acc=1.0000, grad=11.7041]Training epoch 41:   2%|▏         | 3/163 [00:07<05:07,  1.92s/it, loss=0.1008, batch_acc=1.0000, running_acc=1.0000, grad=7.2611] Training epoch 41:   2%|▏         | 4/163 [00:10<06:21,  2.40s/it, loss=0.1008, batch_acc=1.0000, running_acc=1.0000, grad=7.2611]Training epoch 41:   2%|▏         | 4/163 [00:10<06:21,  2.40s/it, loss=0.1826, batch_acc=0.9062, running_acc=0.9766, grad=16.2887]Training epoch 41:   3%|▎         | 5/163 [00:11<04:52,  1.85s/it, loss=0.1826, batch_acc=0.9062, running_acc=0.9766, grad=16.2887]Training epoch 41:   3%|▎         | 5/163 [00:11<04:52,  1.85s/it, loss=0.1096, batch_acc=1.0000, running_acc=0.9812, grad=10.7363]Training epoch 41:   4%|▎         | 6/163 [00:12<03:58,  1.52s/it, loss=0.1096, batch_acc=1.0000, running_acc=0.9812, grad=10.7363]Training epoch 41:   4%|▎         | 6/163 [00:12<03:58,  1.52s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9792, grad=10.6518]Training epoch 41:   4%|▍         | 7/163 [00:13<03:24,  1.31s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9792, grad=10.6518]Training epoch 41:   4%|▍         | 7/163 [00:13<03:24,  1.31s/it, loss=0.1180, batch_acc=1.0000, running_acc=0.9821, grad=9.6039] Training epoch 41:   5%|▍         | 8/163 [00:14<03:20,  1.29s/it, loss=0.1180, batch_acc=1.0000, running_acc=0.9821, grad=9.6039]Training epoch 41:   5%|▍         | 8/163 [00:14<03:20,  1.29s/it, loss=0.0742, batch_acc=1.0000, running_acc=0.9844, grad=6.0709]Training epoch 41:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.0742, batch_acc=1.0000, running_acc=0.9844, grad=6.0709]Training epoch 41:   6%|▌         | 9/163 [00:15<03:12,  1.25s/it, loss=0.0992, batch_acc=1.0000, running_acc=0.9861, grad=9.6653]Training epoch 41:   6%|▌         | 10/163 [00:16<02:53,  1.14s/it, loss=0.0992, batch_acc=1.0000, running_acc=0.9861, grad=9.6653]Training epoch 41:   6%|▌         | 10/163 [00:16<02:53,  1.14s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9875, grad=7.7363]Training epoch 41:   7%|▋         | 11/163 [00:17<02:40,  1.06s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9875, grad=7.7363]Training epoch 41:   7%|▋         | 11/163 [00:17<02:40,  1.06s/it, loss=0.1189, batch_acc=1.0000, running_acc=0.9886, grad=8.6360]Training epoch 41:   7%|▋         | 12/163 [00:18<02:48,  1.12s/it, loss=0.1189, batch_acc=1.0000, running_acc=0.9886, grad=8.6360]Training epoch 41:   7%|▋         | 12/163 [00:18<02:48,  1.12s/it, loss=0.1087, batch_acc=1.0000, running_acc=0.9896, grad=6.2331]Training epoch 41:   8%|▊         | 13/163 [00:19<02:41,  1.08s/it, loss=0.1087, batch_acc=1.0000, running_acc=0.9896, grad=6.2331]Training epoch 41:   8%|▊         | 13/163 [00:19<02:41,  1.08s/it, loss=0.1344, batch_acc=0.9688, running_acc=0.9880, grad=12.9034]Training epoch 41:   9%|▊         | 14/163 [00:20<02:31,  1.02s/it, loss=0.1344, batch_acc=0.9688, running_acc=0.9880, grad=12.9034]Training epoch 41:   9%|▊         | 14/163 [00:20<02:31,  1.02s/it, loss=0.1032, batch_acc=1.0000, running_acc=0.9888, grad=9.5547] Training epoch 41:   9%|▉         | 15/163 [00:21<02:24,  1.02it/s, loss=0.1032, batch_acc=1.0000, running_acc=0.9888, grad=9.5547]Training epoch 41:   9%|▉         | 15/163 [00:21<02:24,  1.02it/s, loss=0.1257, batch_acc=1.0000, running_acc=0.9896, grad=11.2633]Training epoch 41:  10%|▉         | 16/163 [00:22<02:29,  1.02s/it, loss=0.1257, batch_acc=1.0000, running_acc=0.9896, grad=11.2633]Training epoch 41:  10%|▉         | 16/163 [00:22<02:29,  1.02s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9902, grad=7.8786] Training epoch 41:  10%|█         | 17/163 [00:23<02:44,  1.13s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9902, grad=7.8786]Training epoch 41:  10%|█         | 17/163 [00:23<02:44,  1.13s/it, loss=0.1097, batch_acc=0.9688, running_acc=0.9890, grad=8.0961]Training epoch 41:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.1097, batch_acc=0.9688, running_acc=0.9890, grad=8.0961]Training epoch 41:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.1500, batch_acc=0.9688, running_acc=0.9878, grad=17.8093]Training epoch 41:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.1500, batch_acc=0.9688, running_acc=0.9878, grad=17.8093]Training epoch 41:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.0927, batch_acc=1.0000, running_acc=0.9885, grad=8.1212] Training epoch 41:  12%|█▏        | 20/163 [00:26<02:17,  1.04it/s, loss=0.0927, batch_acc=1.0000, running_acc=0.9885, grad=8.1212]Training epoch 41:  12%|█▏        | 20/163 [00:26<02:17,  1.04it/s, loss=0.2102, batch_acc=0.9375, running_acc=0.9859, grad=14.5893]Training epoch 41:  13%|█▎        | 21/163 [00:27<02:36,  1.10s/it, loss=0.2102, batch_acc=0.9375, running_acc=0.9859, grad=14.5893]Training epoch 41:  13%|█▎        | 21/163 [00:27<02:36,  1.10s/it, loss=0.1226, batch_acc=1.0000, running_acc=0.9866, grad=7.6376] Training epoch 41:  13%|█▎        | 22/163 [00:28<02:26,  1.04s/it, loss=0.1226, batch_acc=1.0000, running_acc=0.9866, grad=7.6376]Training epoch 41:  13%|█▎        | 22/163 [00:28<02:26,  1.04s/it, loss=0.0835, batch_acc=1.0000, running_acc=0.9872, grad=5.7690]Training epoch 41:  14%|█▍        | 23/163 [00:29<02:18,  1.01it/s, loss=0.0835, batch_acc=1.0000, running_acc=0.9872, grad=5.7690]Training epoch 41:  14%|█▍        | 23/163 [00:29<02:18,  1.01it/s, loss=0.1378, batch_acc=0.9688, running_acc=0.9864, grad=10.1152]Training epoch 41:  15%|█▍        | 24/163 [00:30<02:12,  1.05it/s, loss=0.1378, batch_acc=0.9688, running_acc=0.9864, grad=10.1152]Training epoch 41:  15%|█▍        | 24/163 [00:30<02:12,  1.05it/s, loss=0.1044, batch_acc=0.9688, running_acc=0.9857, grad=8.5498] Training epoch 41:  15%|█▌        | 25/163 [00:32<03:16,  1.43s/it, loss=0.1044, batch_acc=0.9688, running_acc=0.9857, grad=8.5498]Training epoch 41:  15%|█▌        | 25/163 [00:32<03:16,  1.43s/it, loss=0.1302, batch_acc=0.9688, running_acc=0.9850, grad=10.7686]Training epoch 41:  16%|█▌        | 26/163 [00:33<02:52,  1.26s/it, loss=0.1302, batch_acc=0.9688, running_acc=0.9850, grad=10.7686]Training epoch 41:  16%|█▌        | 26/163 [00:33<02:52,  1.26s/it, loss=0.1370, batch_acc=0.9688, running_acc=0.9844, grad=10.6524]Training epoch 41:  17%|█▋        | 27/163 [00:34<02:35,  1.15s/it, loss=0.1370, batch_acc=0.9688, running_acc=0.9844, grad=10.6524]Training epoch 41:  17%|█▋        | 27/163 [00:34<02:35,  1.15s/it, loss=0.0776, batch_acc=1.0000, running_acc=0.9850, grad=6.2792] Training epoch 41:  17%|█▋        | 28/163 [00:35<02:23,  1.07s/it, loss=0.0776, batch_acc=1.0000, running_acc=0.9850, grad=6.2792]Training epoch 41:  17%|█▋        | 28/163 [00:35<02:23,  1.07s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9833, grad=8.4259]Training epoch 41:  18%|█▊        | 29/163 [00:36<02:32,  1.13s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9833, grad=8.4259]Training epoch 41:  18%|█▊        | 29/163 [00:36<02:32,  1.13s/it, loss=0.1320, batch_acc=1.0000, running_acc=0.9838, grad=9.6893]Training epoch 41:  18%|█▊        | 30/163 [00:37<02:20,  1.06s/it, loss=0.1320, batch_acc=1.0000, running_acc=0.9838, grad=9.6893]Training epoch 41:  18%|█▊        | 30/163 [00:37<02:20,  1.06s/it, loss=0.1575, batch_acc=0.9688, running_acc=0.9833, grad=13.1668]Training epoch 41:  19%|█▉        | 31/163 [00:38<02:12,  1.00s/it, loss=0.1575, batch_acc=0.9688, running_acc=0.9833, grad=13.1668]Training epoch 41:  19%|█▉        | 31/163 [00:38<02:12,  1.00s/it, loss=0.1255, batch_acc=1.0000, running_acc=0.9839, grad=8.9806] Training epoch 41:  20%|█▉        | 32/163 [00:39<02:06,  1.04it/s, loss=0.1255, batch_acc=1.0000, running_acc=0.9839, grad=8.9806]Training epoch 41:  20%|█▉        | 32/163 [00:39<02:06,  1.04it/s, loss=0.1389, batch_acc=0.9688, running_acc=0.9834, grad=14.7353]Training epoch 41:  20%|██        | 33/163 [00:41<02:31,  1.17s/it, loss=0.1389, batch_acc=0.9688, running_acc=0.9834, grad=14.7353]Training epoch 41:  20%|██        | 33/163 [00:41<02:31,  1.17s/it, loss=0.1063, batch_acc=0.9688, running_acc=0.9830, grad=6.9944] Training epoch 41:  21%|██        | 34/163 [00:42<02:19,  1.08s/it, loss=0.1063, batch_acc=0.9688, running_acc=0.9830, grad=6.9944]Training epoch 41:  21%|██        | 34/163 [00:42<02:19,  1.08s/it, loss=0.1199, batch_acc=1.0000, running_acc=0.9835, grad=12.2535]Training epoch 41:  21%|██▏       | 35/163 [00:42<02:10,  1.02s/it, loss=0.1199, batch_acc=1.0000, running_acc=0.9835, grad=12.2535]Training epoch 41:  21%|██▏       | 35/163 [00:42<02:10,  1.02s/it, loss=0.0765, batch_acc=1.0000, running_acc=0.9839, grad=7.6295] Training epoch 41:  22%|██▏       | 36/163 [00:43<02:03,  1.02it/s, loss=0.0765, batch_acc=1.0000, running_acc=0.9839, grad=7.6295]Training epoch 41:  22%|██▏       | 36/163 [00:43<02:03,  1.02it/s, loss=0.1253, batch_acc=0.9688, running_acc=0.9835, grad=9.0476]Training epoch 41:  23%|██▎       | 37/163 [00:46<03:07,  1.49s/it, loss=0.1253, batch_acc=0.9688, running_acc=0.9835, grad=9.0476]Training epoch 41:  23%|██▎       | 37/163 [00:46<03:07,  1.49s/it, loss=0.1719, batch_acc=0.9688, running_acc=0.9831, grad=10.8747]Training epoch 41:  23%|██▎       | 38/163 [00:47<02:43,  1.31s/it, loss=0.1719, batch_acc=0.9688, running_acc=0.9831, grad=10.8747]Training epoch 41:  23%|██▎       | 38/163 [00:47<02:43,  1.31s/it, loss=0.1072, batch_acc=0.9688, running_acc=0.9827, grad=8.6845] Training epoch 41:  24%|██▍       | 39/163 [00:48<02:25,  1.18s/it, loss=0.1072, batch_acc=0.9688, running_acc=0.9827, grad=8.6845]Training epoch 41:  24%|██▍       | 39/163 [00:48<02:25,  1.18s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9832, grad=8.1962]Training epoch 41:  25%|██▍       | 40/163 [00:49<02:13,  1.09s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9832, grad=8.1962]Training epoch 41:  25%|██▍       | 40/163 [00:49<02:13,  1.09s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9836, grad=8.8382]Training epoch 41:  25%|██▌       | 41/163 [00:50<02:15,  1.11s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9836, grad=8.8382]Training epoch 41:  25%|██▌       | 41/163 [00:50<02:15,  1.11s/it, loss=0.1254, batch_acc=1.0000, running_acc=0.9840, grad=12.8640]Training epoch 41:  26%|██▌       | 42/163 [00:51<02:05,  1.04s/it, loss=0.1254, batch_acc=1.0000, running_acc=0.9840, grad=12.8640]Training epoch 41:  26%|██▌       | 42/163 [00:51<02:05,  1.04s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9844, grad=7.3997] Training epoch 41:  26%|██▋       | 43/163 [00:52<01:59,  1.01it/s, loss=0.0891, batch_acc=1.0000, running_acc=0.9844, grad=7.3997]Training epoch 41:  26%|██▋       | 43/163 [00:52<01:59,  1.01it/s, loss=0.1336, batch_acc=0.9688, running_acc=0.9840, grad=7.7612]Training epoch 41:  27%|██▋       | 44/163 [00:52<01:53,  1.04it/s, loss=0.1336, batch_acc=0.9688, running_acc=0.9840, grad=7.7612]Training epoch 41:  27%|██▋       | 44/163 [00:52<01:53,  1.04it/s, loss=0.1386, batch_acc=0.9688, running_acc=0.9837, grad=9.7307]Training epoch 41:  28%|██▊       | 45/163 [00:54<02:29,  1.26s/it, loss=0.1386, batch_acc=0.9688, running_acc=0.9837, grad=9.7307]Training epoch 41:  28%|██▊       | 45/163 [00:54<02:29,  1.26s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9840, grad=11.1917]Training epoch 41:  28%|██▊       | 46/163 [00:55<02:14,  1.15s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9840, grad=11.1917]Training epoch 41:  28%|██▊       | 46/163 [00:55<02:14,  1.15s/it, loss=0.0878, batch_acc=1.0000, running_acc=0.9844, grad=7.8219] Training epoch 41:  29%|██▉       | 47/163 [00:56<02:03,  1.07s/it, loss=0.0878, batch_acc=1.0000, running_acc=0.9844, grad=7.8219]Training epoch 41:  29%|██▉       | 47/163 [00:56<02:03,  1.07s/it, loss=0.1351, batch_acc=0.9688, running_acc=0.9840, grad=7.7050]Training epoch 41:  29%|██▉       | 48/163 [00:57<01:56,  1.01s/it, loss=0.1351, batch_acc=0.9688, running_acc=0.9840, grad=7.7050]Training epoch 41:  29%|██▉       | 48/163 [00:57<01:56,  1.01s/it, loss=0.1389, batch_acc=1.0000, running_acc=0.9844, grad=15.5758]Training epoch 41:  30%|███       | 49/163 [00:59<02:22,  1.25s/it, loss=0.1389, batch_acc=1.0000, running_acc=0.9844, grad=15.5758]Training epoch 41:  30%|███       | 49/163 [00:59<02:22,  1.25s/it, loss=0.1359, batch_acc=0.9688, running_acc=0.9841, grad=9.4644] Training epoch 41:  31%|███       | 50/163 [01:00<02:08,  1.14s/it, loss=0.1359, batch_acc=0.9688, running_acc=0.9841, grad=9.4644]Training epoch 41:  31%|███       | 50/163 [01:00<02:08,  1.14s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.9844, grad=16.2515]Training epoch 41:  31%|███▏      | 51/163 [01:01<01:58,  1.06s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.9844, grad=16.2515]Training epoch 41:  31%|███▏      | 51/163 [01:01<01:58,  1.06s/it, loss=0.0859, batch_acc=1.0000, running_acc=0.9847, grad=7.4012] Training epoch 41:  32%|███▏      | 52/163 [01:01<01:51,  1.01s/it, loss=0.0859, batch_acc=1.0000, running_acc=0.9847, grad=7.4012]Training epoch 41:  32%|███▏      | 52/163 [01:01<01:51,  1.01s/it, loss=0.1370, batch_acc=0.9375, running_acc=0.9838, grad=7.2753]Training epoch 41:  33%|███▎      | 53/163 [01:02<01:51,  1.01s/it, loss=0.1370, batch_acc=0.9375, running_acc=0.9838, grad=7.2753]Training epoch 41:  33%|███▎      | 53/163 [01:02<01:51,  1.01s/it, loss=0.0734, batch_acc=1.0000, running_acc=0.9841, grad=7.2940]Training epoch 41:  33%|███▎      | 54/163 [01:03<01:45,  1.03it/s, loss=0.0734, batch_acc=1.0000, running_acc=0.9841, grad=7.2940]Training epoch 41:  33%|███▎      | 54/163 [01:03<01:45,  1.03it/s, loss=0.1044, batch_acc=0.9688, running_acc=0.9838, grad=7.8731]Training epoch 41:  34%|███▎      | 55/163 [01:04<01:41,  1.06it/s, loss=0.1044, batch_acc=0.9688, running_acc=0.9838, grad=7.8731]Training epoch 41:  34%|███▎      | 55/163 [01:04<01:41,  1.06it/s, loss=0.1157, batch_acc=1.0000, running_acc=0.9841, grad=9.9289]Training epoch 41:  34%|███▍      | 56/163 [01:05<01:40,  1.07it/s, loss=0.1157, batch_acc=1.0000, running_acc=0.9841, grad=9.9289]Training epoch 41:  34%|███▍      | 56/163 [01:05<01:40,  1.07it/s, loss=0.1075, batch_acc=0.9688, running_acc=0.9838, grad=7.7948]Training epoch 41:  35%|███▍      | 57/163 [01:06<01:47,  1.01s/it, loss=0.1075, batch_acc=0.9688, running_acc=0.9838, grad=7.7948]Training epoch 41:  35%|███▍      | 57/163 [01:06<01:47,  1.01s/it, loss=0.1385, batch_acc=0.9688, running_acc=0.9836, grad=10.3100]Training epoch 41:  36%|███▌      | 58/163 [01:07<01:42,  1.03it/s, loss=0.1385, batch_acc=0.9688, running_acc=0.9836, grad=10.3100]Training epoch 41:  36%|███▌      | 58/163 [01:07<01:42,  1.03it/s, loss=0.1109, batch_acc=1.0000, running_acc=0.9838, grad=8.1391] Training epoch 41:  36%|███▌      | 59/163 [01:08<01:38,  1.06it/s, loss=0.1109, batch_acc=1.0000, running_acc=0.9838, grad=8.1391]Training epoch 41:  36%|███▌      | 59/163 [01:08<01:38,  1.06it/s, loss=0.0905, batch_acc=1.0000, running_acc=0.9841, grad=8.4684]Training epoch 41:  37%|███▋      | 60/163 [01:09<01:35,  1.08it/s, loss=0.0905, batch_acc=1.0000, running_acc=0.9841, grad=8.4684]Training epoch 41:  37%|███▋      | 60/163 [01:09<01:35,  1.08it/s, loss=0.0869, batch_acc=1.0000, running_acc=0.9844, grad=6.6738]Training epoch 41:  37%|███▋      | 61/163 [01:10<01:44,  1.02s/it, loss=0.0869, batch_acc=1.0000, running_acc=0.9844, grad=6.6738]Training epoch 41:  37%|███▋      | 61/163 [01:10<01:44,  1.02s/it, loss=0.1047, batch_acc=0.9688, running_acc=0.9841, grad=9.3442]Training epoch 41:  38%|███▊      | 62/163 [01:11<01:38,  1.02it/s, loss=0.1047, batch_acc=0.9688, running_acc=0.9841, grad=9.3442]Training epoch 41:  38%|███▊      | 62/163 [01:11<01:38,  1.02it/s, loss=0.1066, batch_acc=1.0000, running_acc=0.9844, grad=13.2465]Training epoch 41:  39%|███▊      | 63/163 [01:12<01:34,  1.05it/s, loss=0.1066, batch_acc=1.0000, running_acc=0.9844, grad=13.2465]Training epoch 41:  39%|███▊      | 63/163 [01:12<01:34,  1.05it/s, loss=0.1280, batch_acc=1.0000, running_acc=0.9846, grad=14.6384]Training epoch 41:  39%|███▉      | 64/163 [01:13<01:31,  1.08it/s, loss=0.1280, batch_acc=1.0000, running_acc=0.9846, grad=14.6384]Training epoch 41:  39%|███▉      | 64/163 [01:13<01:31,  1.08it/s, loss=0.1306, batch_acc=0.9688, running_acc=0.9844, grad=11.3376]Training epoch 41:  40%|███▉      | 65/163 [01:14<01:43,  1.06s/it, loss=0.1306, batch_acc=0.9688, running_acc=0.9844, grad=11.3376]Training epoch 41:  40%|███▉      | 65/163 [01:14<01:43,  1.06s/it, loss=0.0854, batch_acc=1.0000, running_acc=0.9846, grad=9.5025] Training epoch 41:  40%|████      | 66/163 [01:16<01:50,  1.13s/it, loss=0.0854, batch_acc=1.0000, running_acc=0.9846, grad=9.5025]Training epoch 41:  40%|████      | 66/163 [01:16<01:50,  1.13s/it, loss=0.2070, batch_acc=0.9375, running_acc=0.9839, grad=12.4624]Training epoch 41:  41%|████      | 67/163 [01:16<01:41,  1.06s/it, loss=0.2070, batch_acc=0.9375, running_acc=0.9839, grad=12.4624]Training epoch 41:  41%|████      | 67/163 [01:16<01:41,  1.06s/it, loss=0.1524, batch_acc=1.0000, running_acc=0.9841, grad=11.1547]Training epoch 41:  42%|████▏     | 68/163 [01:17<01:35,  1.00s/it, loss=0.1524, batch_acc=1.0000, running_acc=0.9841, grad=11.1547]Training epoch 41:  42%|████▏     | 68/163 [01:17<01:35,  1.00s/it, loss=0.0989, batch_acc=1.0000, running_acc=0.9844, grad=5.9232] Training epoch 41:  42%|████▏     | 69/163 [01:19<01:50,  1.17s/it, loss=0.0989, batch_acc=1.0000, running_acc=0.9844, grad=5.9232]Training epoch 41:  42%|████▏     | 69/163 [01:19<01:50,  1.17s/it, loss=0.1024, batch_acc=1.0000, running_acc=0.9846, grad=8.9645]Training epoch 41:  43%|████▎     | 70/163 [01:20<01:49,  1.17s/it, loss=0.1024, batch_acc=1.0000, running_acc=0.9846, grad=8.9645]Training epoch 41:  43%|████▎     | 70/163 [01:20<01:49,  1.17s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9848, grad=7.0462]Training epoch 41:  44%|████▎     | 71/163 [01:21<01:39,  1.08s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9848, grad=7.0462]Training epoch 41:  44%|████▎     | 71/163 [01:21<01:39,  1.08s/it, loss=0.1149, batch_acc=1.0000, running_acc=0.9850, grad=10.6306]Training epoch 41:  44%|████▍     | 72/163 [01:22<01:33,  1.02s/it, loss=0.1149, batch_acc=1.0000, running_acc=0.9850, grad=10.6306]Training epoch 41:  44%|████▍     | 72/163 [01:22<01:33,  1.02s/it, loss=0.1387, batch_acc=0.9375, running_acc=0.9844, grad=13.1164]Training epoch 41:  45%|████▍     | 73/163 [01:24<02:00,  1.34s/it, loss=0.1387, batch_acc=0.9375, running_acc=0.9844, grad=13.1164]Training epoch 41:  45%|████▍     | 73/163 [01:24<02:00,  1.34s/it, loss=0.1288, batch_acc=1.0000, running_acc=0.9846, grad=17.8350]Training epoch 41:  45%|████▌     | 74/163 [01:25<01:48,  1.22s/it, loss=0.1288, batch_acc=1.0000, running_acc=0.9846, grad=17.8350]Training epoch 41:  45%|████▌     | 74/163 [01:25<01:48,  1.22s/it, loss=0.0979, batch_acc=1.0000, running_acc=0.9848, grad=10.2789]Training epoch 41:  46%|████▌     | 75/163 [01:26<01:38,  1.12s/it, loss=0.0979, batch_acc=1.0000, running_acc=0.9848, grad=10.2789]Training epoch 41:  46%|████▌     | 75/163 [01:26<01:38,  1.12s/it, loss=0.1863, batch_acc=0.9688, running_acc=0.9846, grad=13.8559]Training epoch 41:  47%|████▋     | 76/163 [01:27<01:30,  1.04s/it, loss=0.1863, batch_acc=0.9688, running_acc=0.9846, grad=13.8559]Training epoch 41:  47%|████▋     | 76/163 [01:27<01:30,  1.04s/it, loss=0.1439, batch_acc=0.9688, running_acc=0.9844, grad=8.8562] Training epoch 41:  47%|████▋     | 77/163 [01:28<01:46,  1.24s/it, loss=0.1439, batch_acc=0.9688, running_acc=0.9844, grad=8.8562]Training epoch 41:  47%|████▋     | 77/163 [01:28<01:46,  1.24s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9846, grad=6.3436]Training epoch 41:  48%|████▊     | 78/163 [01:30<01:49,  1.29s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9846, grad=6.3436]Training epoch 41:  48%|████▊     | 78/163 [01:30<01:49,  1.29s/it, loss=0.1289, batch_acc=1.0000, running_acc=0.9848, grad=12.1807]Training epoch 41:  48%|████▊     | 79/163 [01:31<01:37,  1.16s/it, loss=0.1289, batch_acc=1.0000, running_acc=0.9848, grad=12.1807]Training epoch 41:  48%|████▊     | 79/163 [01:31<01:37,  1.16s/it, loss=0.0865, batch_acc=1.0000, running_acc=0.9850, grad=8.6265] Training epoch 41:  49%|████▉     | 80/163 [01:31<01:29,  1.08s/it, loss=0.0865, batch_acc=1.0000, running_acc=0.9850, grad=8.6265]Training epoch 41:  49%|████▉     | 80/163 [01:31<01:29,  1.08s/it, loss=0.1168, batch_acc=1.0000, running_acc=0.9852, grad=9.2236]Training epoch 41:  50%|████▉     | 81/163 [01:33<01:38,  1.20s/it, loss=0.1168, batch_acc=1.0000, running_acc=0.9852, grad=9.2236]Training epoch 41:  50%|████▉     | 81/163 [01:33<01:38,  1.20s/it, loss=0.1891, batch_acc=0.9375, running_acc=0.9846, grad=14.0108]Training epoch 41:  50%|█████     | 82/163 [01:35<01:49,  1.35s/it, loss=0.1891, batch_acc=0.9375, running_acc=0.9846, grad=14.0108]Training epoch 41:  50%|█████     | 82/163 [01:35<01:49,  1.35s/it, loss=0.0949, batch_acc=0.9688, running_acc=0.9844, grad=8.5891] Training epoch 41:  51%|█████     | 83/163 [01:35<01:36,  1.21s/it, loss=0.0949, batch_acc=0.9688, running_acc=0.9844, grad=8.5891]Training epoch 41:  51%|█████     | 83/163 [01:35<01:36,  1.21s/it, loss=0.0690, batch_acc=1.0000, running_acc=0.9846, grad=6.1676]Training epoch 41:  52%|█████▏    | 84/163 [01:36<01:27,  1.11s/it, loss=0.0690, batch_acc=1.0000, running_acc=0.9846, grad=6.1676]Training epoch 41:  52%|█████▏    | 84/163 [01:36<01:27,  1.11s/it, loss=0.1667, batch_acc=0.9375, running_acc=0.9840, grad=8.7868]Training epoch 41:  52%|█████▏    | 85/163 [01:38<01:28,  1.13s/it, loss=0.1667, batch_acc=0.9375, running_acc=0.9840, grad=8.7868]Training epoch 41:  52%|█████▏    | 85/163 [01:38<01:28,  1.13s/it, loss=0.1234, batch_acc=1.0000, running_acc=0.9842, grad=9.2190]Training epoch 41:  53%|█████▎    | 86/163 [01:39<01:42,  1.33s/it, loss=0.1234, batch_acc=1.0000, running_acc=0.9842, grad=9.2190]Training epoch 41:  53%|█████▎    | 86/163 [01:39<01:42,  1.33s/it, loss=0.1452, batch_acc=0.9375, running_acc=0.9836, grad=11.5756]Training epoch 41:  53%|█████▎    | 87/163 [01:40<01:30,  1.19s/it, loss=0.1452, batch_acc=0.9375, running_acc=0.9836, grad=11.5756]Training epoch 41:  53%|█████▎    | 87/163 [01:40<01:30,  1.19s/it, loss=0.1074, batch_acc=1.0000, running_acc=0.9838, grad=16.8012]Training epoch 41:  54%|█████▍    | 88/163 [01:41<01:22,  1.10s/it, loss=0.1074, batch_acc=1.0000, running_acc=0.9838, grad=16.8012]Training epoch 41:  54%|█████▍    | 88/163 [01:41<01:22,  1.10s/it, loss=0.1326, batch_acc=1.0000, running_acc=0.9840, grad=11.6679]Training epoch 41:  55%|█████▍    | 89/163 [01:42<01:16,  1.03s/it, loss=0.1326, batch_acc=1.0000, running_acc=0.9840, grad=11.6679]Training epoch 41:  55%|█████▍    | 89/163 [01:42<01:16,  1.03s/it, loss=0.0914, batch_acc=1.0000, running_acc=0.9842, grad=9.5646] Training epoch 41:  55%|█████▌    | 90/163 [01:44<01:47,  1.48s/it, loss=0.0914, batch_acc=1.0000, running_acc=0.9842, grad=9.5646]Training epoch 41:  55%|█████▌    | 90/163 [01:44<01:47,  1.48s/it, loss=0.0890, batch_acc=0.9688, running_acc=0.9840, grad=8.5314]Training epoch 41:  56%|█████▌    | 91/163 [01:45<01:33,  1.30s/it, loss=0.0890, batch_acc=0.9688, running_acc=0.9840, grad=8.5314]Training epoch 41:  56%|█████▌    | 91/163 [01:45<01:33,  1.30s/it, loss=0.1097, batch_acc=0.9688, running_acc=0.9839, grad=9.6056]Training epoch 41:  56%|█████▋    | 92/163 [01:46<01:23,  1.17s/it, loss=0.1097, batch_acc=0.9688, running_acc=0.9839, grad=9.6056]Training epoch 41:  56%|█████▋    | 92/163 [01:46<01:23,  1.17s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9840, grad=9.7294]Training epoch 41:  57%|█████▋    | 93/163 [01:47<01:15,  1.08s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9840, grad=9.7294]Training epoch 41:  57%|█████▋    | 93/163 [01:47<01:15,  1.08s/it, loss=0.1396, batch_acc=0.9688, running_acc=0.9839, grad=9.1269]Training epoch 41:  58%|█████▊    | 94/163 [01:49<01:35,  1.38s/it, loss=0.1396, batch_acc=0.9688, running_acc=0.9839, grad=9.1269]Training epoch 41:  58%|█████▊    | 94/163 [01:49<01:35,  1.38s/it, loss=0.1425, batch_acc=0.9375, running_acc=0.9834, grad=8.6347]Training epoch 41:  58%|█████▊    | 95/163 [01:50<01:23,  1.23s/it, loss=0.1425, batch_acc=0.9375, running_acc=0.9834, grad=8.6347]Training epoch 41:  58%|█████▊    | 95/163 [01:50<01:23,  1.23s/it, loss=0.0645, batch_acc=1.0000, running_acc=0.9836, grad=5.0280]Training epoch 41:  59%|█████▉    | 96/163 [01:51<01:15,  1.12s/it, loss=0.0645, batch_acc=1.0000, running_acc=0.9836, grad=5.0280]Training epoch 41:  59%|█████▉    | 96/163 [01:51<01:15,  1.12s/it, loss=0.1340, batch_acc=1.0000, running_acc=0.9837, grad=19.7291]Training epoch 41:  60%|█████▉    | 97/163 [01:52<01:11,  1.09s/it, loss=0.1340, batch_acc=1.0000, running_acc=0.9837, grad=19.7291]Training epoch 41:  60%|█████▉    | 97/163 [01:52<01:11,  1.09s/it, loss=0.0914, batch_acc=1.0000, running_acc=0.9839, grad=7.3005] Training epoch 41:  60%|██████    | 98/163 [01:54<01:23,  1.28s/it, loss=0.0914, batch_acc=1.0000, running_acc=0.9839, grad=7.3005]Training epoch 41:  60%|██████    | 98/163 [01:54<01:23,  1.28s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9841, grad=9.0505]Training epoch 41:  61%|██████    | 99/163 [01:55<01:14,  1.16s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9841, grad=9.0505]Training epoch 41:  61%|██████    | 99/163 [01:55<01:14,  1.16s/it, loss=0.0740, batch_acc=1.0000, running_acc=0.9842, grad=6.0124]Training epoch 41:  61%|██████▏   | 100/163 [01:55<01:07,  1.08s/it, loss=0.0740, batch_acc=1.0000, running_acc=0.9842, grad=6.0124]Training epoch 41:  61%|██████▏   | 100/163 [01:55<01:07,  1.08s/it, loss=0.1515, batch_acc=0.9688, running_acc=0.9841, grad=10.7915]Training epoch 41:  62%|██████▏   | 101/163 [01:56<01:03,  1.02s/it, loss=0.1515, batch_acc=0.9688, running_acc=0.9841, grad=10.7915]Training epoch 41:  62%|██████▏   | 101/163 [01:56<01:03,  1.02s/it, loss=0.1558, batch_acc=1.0000, running_acc=0.9842, grad=17.6643]Training epoch 41:  63%|██████▎   | 102/163 [01:58<01:13,  1.20s/it, loss=0.1558, batch_acc=1.0000, running_acc=0.9842, grad=17.6643]Training epoch 41:  63%|██████▎   | 102/163 [01:58<01:13,  1.20s/it, loss=0.1386, batch_acc=0.9375, running_acc=0.9838, grad=11.4921]Training epoch 41:  63%|██████▎   | 103/163 [01:59<01:06,  1.10s/it, loss=0.1386, batch_acc=0.9375, running_acc=0.9838, grad=11.4921]Training epoch 41:  63%|██████▎   | 103/163 [01:59<01:06,  1.10s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9836, grad=9.6220] Training epoch 41:  64%|██████▍   | 104/163 [02:00<01:01,  1.04s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9836, grad=9.6220]Training epoch 41:  64%|██████▍   | 104/163 [02:00<01:01,  1.04s/it, loss=0.1617, batch_acc=0.9375, running_acc=0.9832, grad=12.9904]Training epoch 41:  64%|██████▍   | 105/163 [02:01<00:57,  1.01it/s, loss=0.1617, batch_acc=0.9375, running_acc=0.9832, grad=12.9904]Training epoch 41:  64%|██████▍   | 105/163 [02:01<00:57,  1.01it/s, loss=0.1209, batch_acc=1.0000, running_acc=0.9833, grad=12.8198]Training epoch 41:  65%|██████▌   | 106/163 [02:02<01:07,  1.18s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9833, grad=12.8198]Training epoch 41:  65%|██████▌   | 106/163 [02:02<01:07,  1.18s/it, loss=0.1397, batch_acc=0.9375, running_acc=0.9829, grad=9.2448] Training epoch 41:  66%|██████▌   | 107/163 [02:03<01:01,  1.09s/it, loss=0.1397, batch_acc=0.9375, running_acc=0.9829, grad=9.2448]Training epoch 41:  66%|██████▌   | 107/163 [02:03<01:01,  1.09s/it, loss=0.1475, batch_acc=0.9688, running_acc=0.9828, grad=11.6406]Training epoch 41:  66%|██████▋   | 108/163 [02:04<00:56,  1.03s/it, loss=0.1475, batch_acc=0.9688, running_acc=0.9828, grad=11.6406]Training epoch 41:  66%|██████▋   | 108/163 [02:04<00:56,  1.03s/it, loss=0.1032, batch_acc=1.0000, running_acc=0.9829, grad=8.1782] Training epoch 41:  67%|██████▋   | 109/163 [02:05<00:53,  1.02it/s, loss=0.1032, batch_acc=1.0000, running_acc=0.9829, grad=8.1782]Training epoch 41:  67%|██████▋   | 109/163 [02:05<00:53,  1.02it/s, loss=0.1222, batch_acc=1.0000, running_acc=0.9831, grad=8.3601]Training epoch 41:  67%|██████▋   | 110/163 [02:06<00:59,  1.12s/it, loss=0.1222, batch_acc=1.0000, running_acc=0.9831, grad=8.3601]Training epoch 41:  67%|██████▋   | 110/163 [02:06<00:59,  1.12s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9832, grad=6.6894]Training epoch 41:  68%|██████▊   | 111/163 [02:07<00:54,  1.05s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9832, grad=6.6894]Training epoch 41:  68%|██████▊   | 111/163 [02:07<00:54,  1.05s/it, loss=0.1601, batch_acc=0.9688, running_acc=0.9831, grad=8.3894]Training epoch 41:  69%|██████▊   | 112/163 [02:08<00:50,  1.00it/s, loss=0.1601, batch_acc=0.9688, running_acc=0.9831, grad=8.3894]Training epoch 41:  69%|██████▊   | 112/163 [02:08<00:50,  1.00it/s, loss=0.0816, batch_acc=1.0000, running_acc=0.9833, grad=6.8631]Training epoch 41:  69%|██████▉   | 113/163 [02:09<00:48,  1.04it/s, loss=0.0816, batch_acc=1.0000, running_acc=0.9833, grad=6.8631]Training epoch 41:  69%|██████▉   | 113/163 [02:09<00:48,  1.04it/s, loss=0.1133, batch_acc=1.0000, running_acc=0.9834, grad=19.3392]Training epoch 41:  70%|██████▉   | 114/163 [02:11<01:00,  1.24s/it, loss=0.1133, batch_acc=1.0000, running_acc=0.9834, grad=19.3392]Training epoch 41:  70%|██████▉   | 114/163 [02:11<01:00,  1.24s/it, loss=0.0769, batch_acc=1.0000, running_acc=0.9836, grad=5.9194] Training epoch 41:  71%|███████   | 115/163 [02:12<00:54,  1.13s/it, loss=0.0769, batch_acc=1.0000, running_acc=0.9836, grad=5.9194]Training epoch 41:  71%|███████   | 115/163 [02:12<00:54,  1.13s/it, loss=0.0928, batch_acc=0.9688, running_acc=0.9834, grad=5.5175]Training epoch 41:  71%|███████   | 116/163 [02:13<00:49,  1.05s/it, loss=0.0928, batch_acc=0.9688, running_acc=0.9834, grad=5.5175]Training epoch 41:  71%|███████   | 116/163 [02:13<00:49,  1.05s/it, loss=0.1513, batch_acc=0.9688, running_acc=0.9833, grad=16.2950]Training epoch 41:  72%|███████▏  | 117/163 [02:13<00:46,  1.02s/it, loss=0.1513, batch_acc=0.9688, running_acc=0.9833, grad=16.2950]Training epoch 41:  72%|███████▏  | 117/163 [02:13<00:46,  1.02s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9834, grad=6.3543] Training epoch 41:  72%|███████▏  | 118/163 [02:15<00:52,  1.16s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9834, grad=6.3543]Training epoch 41:  72%|███████▏  | 118/163 [02:15<00:52,  1.16s/it, loss=0.1261, batch_acc=0.9688, running_acc=0.9833, grad=9.6527]Training epoch 41:  73%|███████▎  | 119/163 [02:16<00:47,  1.08s/it, loss=0.1261, batch_acc=0.9688, running_acc=0.9833, grad=9.6527]Training epoch 41:  73%|███████▎  | 119/163 [02:16<00:47,  1.08s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9832, grad=16.2397]Training epoch 41:  74%|███████▎  | 120/163 [02:17<00:43,  1.02s/it, loss=0.1662, batch_acc=0.9688, running_acc=0.9832, grad=16.2397]Training epoch 41:  74%|███████▎  | 120/163 [02:17<00:43,  1.02s/it, loss=0.2328, batch_acc=0.9062, running_acc=0.9826, grad=23.5746]Training epoch 41:  74%|███████▍  | 121/163 [02:18<00:40,  1.02it/s, loss=0.2328, batch_acc=0.9062, running_acc=0.9826, grad=23.5746]Training epoch 41:  74%|███████▍  | 121/163 [02:18<00:40,  1.02it/s, loss=0.1201, batch_acc=1.0000, running_acc=0.9827, grad=16.2482]Training epoch 41:  75%|███████▍  | 122/163 [02:19<00:47,  1.17s/it, loss=0.1201, batch_acc=1.0000, running_acc=0.9827, grad=16.2482]Training epoch 41:  75%|███████▍  | 122/163 [02:19<00:47,  1.17s/it, loss=0.1526, batch_acc=0.9375, running_acc=0.9823, grad=12.6187]Training epoch 41:  75%|███████▌  | 123/163 [02:20<00:43,  1.08s/it, loss=0.1526, batch_acc=0.9375, running_acc=0.9823, grad=12.6187]Training epoch 41:  75%|███████▌  | 123/163 [02:20<00:43,  1.08s/it, loss=0.1119, batch_acc=1.0000, running_acc=0.9825, grad=8.2317] Training epoch 41:  76%|███████▌  | 124/163 [02:21<00:39,  1.02s/it, loss=0.1119, batch_acc=1.0000, running_acc=0.9825, grad=8.2317]Training epoch 41:  76%|███████▌  | 124/163 [02:21<00:39,  1.02s/it, loss=0.0931, batch_acc=1.0000, running_acc=0.9826, grad=7.7623]Training epoch 41:  77%|███████▋  | 125/163 [02:22<00:42,  1.13s/it, loss=0.0931, batch_acc=1.0000, running_acc=0.9826, grad=7.7623]Training epoch 41:  77%|███████▋  | 125/163 [02:22<00:42,  1.13s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9828, grad=7.5965]Training epoch 41:  77%|███████▋  | 126/163 [02:23<00:41,  1.12s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9828, grad=7.5965]Training epoch 41:  77%|███████▋  | 126/163 [02:23<00:41,  1.12s/it, loss=0.0607, batch_acc=1.0000, running_acc=0.9829, grad=5.8205]Training epoch 41:  78%|███████▊  | 127/163 [02:24<00:37,  1.04s/it, loss=0.0607, batch_acc=1.0000, running_acc=0.9829, grad=5.8205]Training epoch 41:  78%|███████▊  | 127/163 [02:24<00:37,  1.04s/it, loss=0.0791, batch_acc=1.0000, running_acc=0.9830, grad=6.7209]Training epoch 41:  79%|███████▊  | 128/163 [02:25<00:34,  1.01it/s, loss=0.0791, batch_acc=1.0000, running_acc=0.9830, grad=6.7209]Training epoch 41:  79%|███████▊  | 128/163 [02:25<00:34,  1.01it/s, loss=0.1335, batch_acc=1.0000, running_acc=0.9832, grad=13.4913]Training epoch 41:  79%|███████▉  | 129/163 [02:26<00:32,  1.04it/s, loss=0.1335, batch_acc=1.0000, running_acc=0.9832, grad=13.4913]Training epoch 41:  79%|███████▉  | 129/163 [02:26<00:32,  1.04it/s, loss=0.1307, batch_acc=0.9688, running_acc=0.9830, grad=8.9409] Training epoch 41:  80%|███████▉  | 130/163 [02:28<00:43,  1.31s/it, loss=0.1307, batch_acc=0.9688, running_acc=0.9830, grad=8.9409]Training epoch 41:  80%|███████▉  | 130/163 [02:28<00:43,  1.31s/it, loss=0.1494, batch_acc=0.9375, running_acc=0.9827, grad=12.2943]Training epoch 41:  80%|████████  | 131/163 [02:29<00:37,  1.18s/it, loss=0.1494, batch_acc=0.9375, running_acc=0.9827, grad=12.2943]Training epoch 41:  80%|████████  | 131/163 [02:29<00:37,  1.18s/it, loss=0.1488, batch_acc=1.0000, running_acc=0.9828, grad=16.7747]Training epoch 41:  81%|████████  | 132/163 [02:30<00:33,  1.09s/it, loss=0.1488, batch_acc=1.0000, running_acc=0.9828, grad=16.7747]Training epoch 41:  81%|████████  | 132/163 [02:30<00:33,  1.09s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9830, grad=6.2328] Training epoch 41:  82%|████████▏ | 133/163 [02:31<00:31,  1.05s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9830, grad=6.2328]Training epoch 41:  82%|████████▏ | 133/163 [02:31<00:31,  1.05s/it, loss=0.1400, batch_acc=0.9375, running_acc=0.9826, grad=11.8625]Training epoch 41:  82%|████████▏ | 134/163 [02:33<00:35,  1.23s/it, loss=0.1400, batch_acc=0.9375, running_acc=0.9826, grad=11.8625]Training epoch 41:  82%|████████▏ | 134/163 [02:33<00:35,  1.23s/it, loss=0.0832, batch_acc=1.0000, running_acc=0.9827, grad=6.5679] Training epoch 41:  83%|████████▎ | 135/163 [02:33<00:31,  1.12s/it, loss=0.0832, batch_acc=1.0000, running_acc=0.9827, grad=6.5679]Training epoch 41:  83%|████████▎ | 135/163 [02:33<00:31,  1.12s/it, loss=0.1542, batch_acc=0.9375, running_acc=0.9824, grad=11.3709]Training epoch 41:  83%|████████▎ | 136/163 [02:34<00:28,  1.05s/it, loss=0.1542, batch_acc=0.9375, running_acc=0.9824, grad=11.3709]Training epoch 41:  83%|████████▎ | 136/163 [02:34<00:28,  1.05s/it, loss=0.1186, batch_acc=0.9688, running_acc=0.9823, grad=7.5692] Training epoch 41:  84%|████████▍ | 137/163 [02:35<00:26,  1.02s/it, loss=0.1186, batch_acc=0.9688, running_acc=0.9823, grad=7.5692]Training epoch 41:  84%|████████▍ | 137/163 [02:35<00:26,  1.02s/it, loss=0.1775, batch_acc=0.9375, running_acc=0.9820, grad=8.9264]Training epoch 41:  85%|████████▍ | 138/163 [02:37<00:31,  1.27s/it, loss=0.1775, batch_acc=0.9375, running_acc=0.9820, grad=8.9264]Training epoch 41:  85%|████████▍ | 138/163 [02:37<00:31,  1.27s/it, loss=0.1112, batch_acc=0.9688, running_acc=0.9819, grad=8.5395]Training epoch 41:  85%|████████▌ | 139/163 [02:38<00:27,  1.15s/it, loss=0.1112, batch_acc=0.9688, running_acc=0.9819, grad=8.5395]Training epoch 41:  85%|████████▌ | 139/163 [02:38<00:27,  1.15s/it, loss=0.0886, batch_acc=1.0000, running_acc=0.9820, grad=6.4075]Training epoch 41:  86%|████████▌ | 140/163 [02:39<00:24,  1.07s/it, loss=0.0886, batch_acc=1.0000, running_acc=0.9820, grad=6.4075]Training epoch 41:  86%|████████▌ | 140/163 [02:39<00:24,  1.07s/it, loss=0.1686, batch_acc=1.0000, running_acc=0.9821, grad=12.8478]Training epoch 41:  87%|████████▋ | 141/163 [02:40<00:22,  1.04s/it, loss=0.1686, batch_acc=1.0000, running_acc=0.9821, grad=12.8478]Training epoch 41:  87%|████████▋ | 141/163 [02:40<00:22,  1.04s/it, loss=0.1719, batch_acc=0.9375, running_acc=0.9818, grad=12.9997]Training epoch 41:  87%|████████▋ | 142/163 [02:42<00:26,  1.25s/it, loss=0.1719, batch_acc=0.9375, running_acc=0.9818, grad=12.9997]Training epoch 41:  87%|████████▋ | 142/163 [02:42<00:26,  1.25s/it, loss=0.1009, batch_acc=1.0000, running_acc=0.9820, grad=11.9640]Training epoch 41:  88%|████████▊ | 143/163 [02:42<00:22,  1.14s/it, loss=0.1009, batch_acc=1.0000, running_acc=0.9820, grad=11.9640]Training epoch 41:  88%|████████▊ | 143/163 [02:42<00:22,  1.14s/it, loss=0.1059, batch_acc=1.0000, running_acc=0.9821, grad=11.6281]Training epoch 41:  88%|████████▊ | 144/163 [02:43<00:20,  1.06s/it, loss=0.1059, batch_acc=1.0000, running_acc=0.9821, grad=11.6281]Training epoch 41:  88%|████████▊ | 144/163 [02:43<00:20,  1.06s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9822, grad=15.3320]Training epoch 41:  89%|████████▉ | 145/163 [02:44<00:18,  1.02s/it, loss=0.1306, batch_acc=1.0000, running_acc=0.9822, grad=15.3320]Training epoch 41:  89%|████████▉ | 145/163 [02:44<00:18,  1.02s/it, loss=0.1156, batch_acc=1.0000, running_acc=0.9823, grad=8.7588] Training epoch 41:  90%|████████▉ | 146/163 [02:46<00:20,  1.23s/it, loss=0.1156, batch_acc=1.0000, running_acc=0.9823, grad=8.7588]Training epoch 41:  90%|████████▉ | 146/163 [02:46<00:20,  1.23s/it, loss=0.1677, batch_acc=0.9375, running_acc=0.9820, grad=14.8641]Training epoch 41:  90%|█████████ | 147/163 [02:47<00:18,  1.13s/it, loss=0.1677, batch_acc=0.9375, running_acc=0.9820, grad=14.8641]Training epoch 41:  90%|█████████ | 147/163 [02:47<00:18,  1.13s/it, loss=0.1058, batch_acc=1.0000, running_acc=0.9821, grad=8.9548] Training epoch 41:  91%|█████████ | 148/163 [02:48<00:15,  1.05s/it, loss=0.1058, batch_acc=1.0000, running_acc=0.9821, grad=8.9548]Training epoch 41:  91%|█████████ | 148/163 [02:48<00:15,  1.05s/it, loss=0.0711, batch_acc=1.0000, running_acc=0.9823, grad=7.9524]Training epoch 41:  91%|█████████▏| 149/163 [02:49<00:14,  1.00s/it, loss=0.0711, batch_acc=1.0000, running_acc=0.9823, grad=7.9524]Training epoch 41:  91%|█████████▏| 149/163 [02:49<00:14,  1.00s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9822, grad=14.5533]Training epoch 41:  92%|█████████▏| 150/163 [02:51<00:17,  1.37s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9822, grad=14.5533]Training epoch 41:  92%|█████████▏| 150/163 [02:51<00:17,  1.37s/it, loss=0.1468, batch_acc=0.9688, running_acc=0.9821, grad=14.5997]Training epoch 41:  93%|█████████▎| 151/163 [02:52<00:14,  1.22s/it, loss=0.1468, batch_acc=0.9688, running_acc=0.9821, grad=14.5997]Training epoch 41:  93%|█████████▎| 151/163 [02:52<00:14,  1.22s/it, loss=0.1086, batch_acc=1.0000, running_acc=0.9822, grad=9.8270] Training epoch 41:  93%|█████████▎| 152/163 [02:53<00:12,  1.12s/it, loss=0.1086, batch_acc=1.0000, running_acc=0.9822, grad=9.8270]Training epoch 41:  93%|█████████▎| 152/163 [02:53<00:12,  1.12s/it, loss=0.1073, batch_acc=1.0000, running_acc=0.9823, grad=7.8053]Training epoch 41:  94%|█████████▍| 153/163 [02:53<00:10,  1.05s/it, loss=0.1073, batch_acc=1.0000, running_acc=0.9823, grad=7.8053]Training epoch 41:  94%|█████████▍| 153/163 [02:53<00:10,  1.05s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9824, grad=7.8794]Training epoch 41:  94%|█████████▍| 154/163 [02:55<00:10,  1.19s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9824, grad=7.8794]Training epoch 41:  94%|█████████▍| 154/163 [02:55<00:10,  1.19s/it, loss=0.1116, batch_acc=1.0000, running_acc=0.9825, grad=10.2555]Training epoch 41:  95%|█████████▌| 155/163 [02:56<00:08,  1.10s/it, loss=0.1116, batch_acc=1.0000, running_acc=0.9825, grad=10.2555]Training epoch 41:  95%|█████████▌| 155/163 [02:56<00:08,  1.10s/it, loss=0.0966, batch_acc=1.0000, running_acc=0.9827, grad=6.5208] Training epoch 41:  96%|█████████▌| 156/163 [02:57<00:07,  1.03s/it, loss=0.0966, batch_acc=1.0000, running_acc=0.9827, grad=6.5208]Training epoch 41:  96%|█████████▌| 156/163 [02:57<00:07,  1.03s/it, loss=0.1137, batch_acc=0.9688, running_acc=0.9826, grad=10.0945]Training epoch 41:  96%|█████████▋| 157/163 [02:58<00:05,  1.01it/s, loss=0.1137, batch_acc=0.9688, running_acc=0.9826, grad=10.0945]Training epoch 41:  96%|█████████▋| 157/163 [02:58<00:05,  1.01it/s, loss=0.1603, batch_acc=0.9688, running_acc=0.9825, grad=10.8001]Training epoch 41:  97%|█████████▋| 158/163 [03:00<00:07,  1.49s/it, loss=0.1603, batch_acc=0.9688, running_acc=0.9825, grad=10.8001]Training epoch 41:  97%|█████████▋| 158/163 [03:00<00:07,  1.49s/it, loss=0.0553, batch_acc=1.0000, running_acc=0.9826, grad=4.0710] Training epoch 41:  98%|█████████▊| 159/163 [03:01<00:05,  1.31s/it, loss=0.0553, batch_acc=1.0000, running_acc=0.9826, grad=4.0710]Training epoch 41:  98%|█████████▊| 159/163 [03:01<00:05,  1.31s/it, loss=0.1112, batch_acc=1.0000, running_acc=0.9827, grad=10.1572]Training epoch 41:  98%|█████████▊| 160/163 [03:02<00:03,  1.18s/it, loss=0.1112, batch_acc=1.0000, running_acc=0.9827, grad=10.1572]Training epoch 41:  98%|█████████▊| 160/163 [03:02<00:03,  1.18s/it, loss=0.1123, batch_acc=1.0000, running_acc=0.9828, grad=8.1557] Training epoch 41:  99%|█████████▉| 161/163 [03:03<00:02,  1.09s/it, loss=0.1123, batch_acc=1.0000, running_acc=0.9828, grad=8.1557]Training epoch 41:  99%|█████████▉| 161/163 [03:03<00:02,  1.09s/it, loss=0.0989, batch_acc=1.0000, running_acc=0.9829, grad=8.7892]Training epoch 41:  99%|█████████▉| 162/163 [03:04<00:01,  1.02s/it, loss=0.0989, batch_acc=1.0000, running_acc=0.9829, grad=8.7892]Training epoch 41:  99%|█████████▉| 162/163 [03:04<00:01,  1.02s/it, loss=0.1130, batch_acc=0.9688, running_acc=0.9828, grad=8.8454]Training epoch 41: 100%|██████████| 163/163 [03:04<00:00,  1.10it/s, loss=0.1130, batch_acc=0.9688, running_acc=0.9828, grad=8.8454]Training epoch 41: 100%|██████████| 163/163 [03:04<00:00,  1.10it/s, loss=0.1308, batch_acc=1.0000, running_acc=0.9829, grad=10.2905]Training epoch 41: 100%|██████████| 163/163 [03:04<00:00,  1.13s/it, loss=0.1308, batch_acc=1.0000, running_acc=0.9829, grad=10.2905]
Evaluation epoch 41:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 41:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it]Evaluation epoch 41:   4%|▎         | 1/28 [00:04<02:12,  4.90s/it, loss=0.3978, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 41:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.3978, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 41:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.2496, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 41:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.2496, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 41:  11%|█         | 3/28 [00:05<00:32,  1.30s/it, loss=0.3152, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 41:  14%|█▍        | 4/28 [00:09<01:01,  2.57s/it, loss=0.3152, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 41:  14%|█▍        | 4/28 [00:09<01:01,  2.57s/it, loss=0.3818, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 41:  18%|█▊        | 5/28 [00:10<00:39,  1.74s/it, loss=0.3818, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 41:  18%|█▊        | 5/28 [00:10<00:39,  1.74s/it, loss=1.3062, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 41:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=1.3062, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 41:  21%|██▏       | 6/28 [00:10<00:27,  1.24s/it, loss=0.5264, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 41:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.5264, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 41:  25%|██▌       | 7/28 [00:10<00:19,  1.09it/s, loss=0.6588, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 41:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=0.6588, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 41:  29%|██▊       | 8/28 [00:14<00:34,  1.71s/it, loss=0.3947, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 41:  32%|███▏      | 9/28 [00:14<00:26,  1.41s/it, loss=0.3947, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 41:  32%|███▏      | 9/28 [00:14<00:26,  1.41s/it, loss=0.4218, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 41:  36%|███▌      | 10/28 [00:15<00:18,  1.06s/it, loss=0.4218, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 41:  36%|███▌      | 10/28 [00:15<00:18,  1.06s/it, loss=0.4367, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 41:  39%|███▉      | 11/28 [00:15<00:13,  1.23it/s, loss=0.4367, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 41:  39%|███▉      | 11/28 [00:15<00:13,  1.23it/s, loss=0.3051, batch_acc=0.9375, running_acc=0.8977]Evaluation epoch 41:  43%|████▎     | 12/28 [00:20<00:35,  2.19s/it, loss=0.3051, batch_acc=0.9375, running_acc=0.8977]Evaluation epoch 41:  43%|████▎     | 12/28 [00:20<00:35,  2.19s/it, loss=0.8648, batch_acc=0.7812, running_acc=0.8880]Evaluation epoch 41:  46%|████▋     | 13/28 [00:21<00:24,  1.61s/it, loss=0.8648, batch_acc=0.7812, running_acc=0.8880]Evaluation epoch 41:  46%|████▋     | 13/28 [00:21<00:24,  1.61s/it, loss=0.2682, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 41:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=0.2682, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 41:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=0.8978, batch_acc=0.7500, running_acc=0.8817]Evaluation epoch 41:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=0.8978, batch_acc=0.7500, running_acc=0.8817]Evaluation epoch 41:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=0.9571, batch_acc=0.8125, running_acc=0.8771]Evaluation epoch 41:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=0.9571, batch_acc=0.8125, running_acc=0.8771]Evaluation epoch 41:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=0.6934, batch_acc=0.8125, running_acc=0.8730]Evaluation epoch 41:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.6934, batch_acc=0.8125, running_acc=0.8730]Evaluation epoch 41:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.5648, batch_acc=0.7188, running_acc=0.8640]Evaluation epoch 41:  64%|██████▍   | 18/28 [00:25<00:08,  1.13it/s, loss=0.5648, batch_acc=0.7188, running_acc=0.8640]Evaluation epoch 41:  64%|██████▍   | 18/28 [00:25<00:08,  1.13it/s, loss=0.5841, batch_acc=0.8438, running_acc=0.8628]Evaluation epoch 41:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=0.5841, batch_acc=0.8438, running_acc=0.8628]Evaluation epoch 41:  68%|██████▊   | 19/28 [00:25<00:06,  1.43it/s, loss=0.9262, batch_acc=0.6562, running_acc=0.8520]Evaluation epoch 41:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=0.9262, batch_acc=0.6562, running_acc=0.8520]Evaluation epoch 41:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=0.6630, batch_acc=0.7188, running_acc=0.8453]Evaluation epoch 41:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.6630, batch_acc=0.7188, running_acc=0.8453]Evaluation epoch 41:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5945, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 41:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5945, batch_acc=0.8125, running_acc=0.8438]Evaluation epoch 41:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.4561, batch_acc=0.9375, running_acc=0.8480]Evaluation epoch 41:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.4561, batch_acc=0.9375, running_acc=0.8480]Evaluation epoch 41:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.7511, batch_acc=0.7500, running_acc=0.8438]Evaluation epoch 41:  86%|████████▌ | 24/28 [00:34<00:08,  2.05s/it, loss=0.7511, batch_acc=0.7500, running_acc=0.8438]Evaluation epoch 41:  86%|████████▌ | 24/28 [00:34<00:08,  2.05s/it, loss=0.3095, batch_acc=0.9375, running_acc=0.8477]Evaluation epoch 41:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.3095, batch_acc=0.9375, running_acc=0.8477]Evaluation epoch 41:  89%|████████▉ | 25/28 [00:34<00:04,  1.51s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.8538]Evaluation epoch 41:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.8538]Evaluation epoch 41:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.5727, batch_acc=0.8438, running_acc=0.8534]Evaluation epoch 41:  96%|█████████▋| 27/28 [00:35<00:00,  1.15it/s, loss=0.5727, batch_acc=0.8438, running_acc=0.8534]Evaluation epoch 41:  96%|█████████▋| 27/28 [00:35<00:00,  1.15it/s, loss=0.8336, batch_acc=0.7812, running_acc=0.8507]Evaluation epoch 41: 100%|██████████| 28/28 [00:35<00:00,  1.15it/s, loss=1.1967, batch_acc=0.6667, running_acc=0.8501]Evaluation epoch 41: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.1967, batch_acc=0.6667, running_acc=0.8501]
Training epoch 42:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 42:   1%|          | 1/163 [00:06<16:53,  6.26s/it]Training epoch 42:   1%|          | 1/163 [00:06<16:53,  6.26s/it, loss=0.1554, batch_acc=0.9375, running_acc=0.9375, grad=11.7001]Training epoch 42:   1%|          | 2/163 [00:07<08:18,  3.10s/it, loss=0.1554, batch_acc=0.9375, running_acc=0.9375, grad=11.7001]Training epoch 42:   1%|          | 2/163 [00:07<08:18,  3.10s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9688, grad=8.1719] Training epoch 42:   2%|▏         | 3/163 [00:08<05:33,  2.08s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9688, grad=8.1719]Training epoch 42:   2%|▏         | 3/163 [00:08<05:33,  2.08s/it, loss=0.1180, batch_acc=0.9688, running_acc=0.9688, grad=9.1584]Training epoch 42:   2%|▏         | 4/163 [00:10<05:33,  2.09s/it, loss=0.1180, batch_acc=0.9688, running_acc=0.9688, grad=9.1584]Training epoch 42:   2%|▏         | 4/163 [00:10<05:33,  2.09s/it, loss=0.1063, batch_acc=0.9688, running_acc=0.9688, grad=7.7460]Training epoch 42:   3%|▎         | 5/163 [00:11<04:21,  1.66s/it, loss=0.1063, batch_acc=0.9688, running_acc=0.9688, grad=7.7460]Training epoch 42:   3%|▎         | 5/163 [00:11<04:21,  1.66s/it, loss=0.0759, batch_acc=1.0000, running_acc=0.9750, grad=5.8537]Training epoch 42:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=0.0759, batch_acc=1.0000, running_acc=0.9750, grad=5.8537]Training epoch 42:   4%|▎         | 6/163 [00:11<03:38,  1.39s/it, loss=0.2126, batch_acc=0.9062, running_acc=0.9635, grad=14.6758]Training epoch 42:   4%|▍         | 7/163 [00:12<03:11,  1.22s/it, loss=0.2126, batch_acc=0.9062, running_acc=0.9635, grad=14.6758]Training epoch 42:   4%|▍         | 7/163 [00:12<03:11,  1.22s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9688, grad=10.0602]Training epoch 42:   5%|▍         | 8/163 [00:14<03:45,  1.45s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9688, grad=10.0602]Training epoch 42:   5%|▍         | 8/163 [00:14<03:45,  1.45s/it, loss=0.1924, batch_acc=0.9062, running_acc=0.9609, grad=11.4429]Training epoch 42:   6%|▌         | 9/163 [00:15<03:16,  1.27s/it, loss=0.1924, batch_acc=0.9062, running_acc=0.9609, grad=11.4429]Training epoch 42:   6%|▌         | 9/163 [00:15<03:16,  1.27s/it, loss=0.1558, batch_acc=0.9375, running_acc=0.9583, grad=20.6892]Training epoch 42:   6%|▌         | 10/163 [00:16<02:56,  1.15s/it, loss=0.1558, batch_acc=0.9375, running_acc=0.9583, grad=20.6892]Training epoch 42:   6%|▌         | 10/163 [00:16<02:56,  1.15s/it, loss=0.0984, batch_acc=1.0000, running_acc=0.9625, grad=9.7458] Training epoch 42:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=0.0984, batch_acc=1.0000, running_acc=0.9625, grad=9.7458]Training epoch 42:   7%|▋         | 11/163 [00:17<02:42,  1.07s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9659, grad=9.1595]Training epoch 42:   7%|▋         | 12/163 [00:18<02:55,  1.16s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9659, grad=9.1595]Training epoch 42:   7%|▋         | 12/163 [00:18<02:55,  1.16s/it, loss=0.0784, batch_acc=1.0000, running_acc=0.9688, grad=6.1287]Training epoch 42:   8%|▊         | 13/163 [00:19<02:43,  1.09s/it, loss=0.0784, batch_acc=1.0000, running_acc=0.9688, grad=6.1287]Training epoch 42:   8%|▊         | 13/163 [00:19<02:43,  1.09s/it, loss=0.0936, batch_acc=1.0000, running_acc=0.9712, grad=6.8891]Training epoch 42:   9%|▊         | 14/163 [00:20<02:33,  1.03s/it, loss=0.0936, batch_acc=1.0000, running_acc=0.9712, grad=6.8891]Training epoch 42:   9%|▊         | 14/163 [00:20<02:33,  1.03s/it, loss=0.1051, batch_acc=1.0000, running_acc=0.9732, grad=7.9783]Training epoch 42:   9%|▉         | 15/163 [00:21<02:25,  1.02it/s, loss=0.1051, batch_acc=1.0000, running_acc=0.9732, grad=7.9783]Training epoch 42:   9%|▉         | 15/163 [00:21<02:25,  1.02it/s, loss=0.0833, batch_acc=1.0000, running_acc=0.9750, grad=7.7086]Training epoch 42:  10%|▉         | 16/163 [00:23<03:00,  1.23s/it, loss=0.0833, batch_acc=1.0000, running_acc=0.9750, grad=7.7086]Training epoch 42:  10%|▉         | 16/163 [00:23<03:00,  1.23s/it, loss=0.1238, batch_acc=1.0000, running_acc=0.9766, grad=11.4714]Training epoch 42:  10%|█         | 17/163 [00:24<02:44,  1.12s/it, loss=0.1238, batch_acc=1.0000, running_acc=0.9766, grad=11.4714]Training epoch 42:  10%|█         | 17/163 [00:24<02:44,  1.12s/it, loss=0.0763, batch_acc=1.0000, running_acc=0.9779, grad=6.9201] Training epoch 42:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.0763, batch_acc=1.0000, running_acc=0.9779, grad=6.9201]Training epoch 42:  11%|█         | 18/163 [00:24<02:32,  1.05s/it, loss=0.1677, batch_acc=0.9375, running_acc=0.9757, grad=11.4410]Training epoch 42:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.1677, batch_acc=0.9375, running_acc=0.9757, grad=11.4410]Training epoch 42:  12%|█▏        | 19/163 [00:25<02:23,  1.00it/s, loss=0.1023, batch_acc=1.0000, running_acc=0.9770, grad=11.7587]Training epoch 42:  12%|█▏        | 20/163 [00:27<02:49,  1.19s/it, loss=0.1023, batch_acc=1.0000, running_acc=0.9770, grad=11.7587]Training epoch 42:  12%|█▏        | 20/163 [00:27<02:49,  1.19s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9781, grad=12.9189]Training epoch 42:  13%|█▎        | 21/163 [00:28<02:35,  1.09s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9781, grad=12.9189]Training epoch 42:  13%|█▎        | 21/163 [00:28<02:35,  1.09s/it, loss=0.0737, batch_acc=1.0000, running_acc=0.9792, grad=5.5707] Training epoch 42:  13%|█▎        | 22/163 [00:29<02:25,  1.03s/it, loss=0.0737, batch_acc=1.0000, running_acc=0.9792, grad=5.5707]Training epoch 42:  13%|█▎        | 22/163 [00:29<02:25,  1.03s/it, loss=0.1147, batch_acc=0.9688, running_acc=0.9787, grad=11.0349]Training epoch 42:  14%|█▍        | 23/163 [00:30<02:17,  1.01it/s, loss=0.1147, batch_acc=0.9688, running_acc=0.9787, grad=11.0349]Training epoch 42:  14%|█▍        | 23/163 [00:30<02:17,  1.01it/s, loss=0.1421, batch_acc=1.0000, running_acc=0.9796, grad=12.5240]Training epoch 42:  15%|█▍        | 24/163 [00:31<02:35,  1.12s/it, loss=0.1421, batch_acc=1.0000, running_acc=0.9796, grad=12.5240]Training epoch 42:  15%|█▍        | 24/163 [00:31<02:35,  1.12s/it, loss=0.0726, batch_acc=1.0000, running_acc=0.9805, grad=5.2627] Training epoch 42:  15%|█▌        | 25/163 [00:32<02:24,  1.05s/it, loss=0.0726, batch_acc=1.0000, running_acc=0.9805, grad=5.2627]Training epoch 42:  15%|█▌        | 25/163 [00:32<02:24,  1.05s/it, loss=0.1231, batch_acc=1.0000, running_acc=0.9812, grad=14.6453]Training epoch 42:  16%|█▌        | 26/163 [00:33<02:16,  1.00it/s, loss=0.1231, batch_acc=1.0000, running_acc=0.9812, grad=14.6453]Training epoch 42:  16%|█▌        | 26/163 [00:33<02:16,  1.00it/s, loss=0.0742, batch_acc=1.0000, running_acc=0.9820, grad=5.5061] Training epoch 42:  17%|█▋        | 27/163 [00:34<02:10,  1.04it/s, loss=0.0742, batch_acc=1.0000, running_acc=0.9820, grad=5.5061]Training epoch 42:  17%|█▋        | 27/163 [00:34<02:10,  1.04it/s, loss=0.1753, batch_acc=0.9688, running_acc=0.9815, grad=11.9258]Training epoch 42:  17%|█▋        | 28/163 [00:35<02:41,  1.20s/it, loss=0.1753, batch_acc=0.9688, running_acc=0.9815, grad=11.9258]Training epoch 42:  17%|█▋        | 28/163 [00:35<02:41,  1.20s/it, loss=0.0792, batch_acc=1.0000, running_acc=0.9821, grad=6.7324] Training epoch 42:  18%|█▊        | 29/163 [00:36<02:27,  1.10s/it, loss=0.0792, batch_acc=1.0000, running_acc=0.9821, grad=6.7324]Training epoch 42:  18%|█▊        | 29/163 [00:36<02:27,  1.10s/it, loss=0.1387, batch_acc=0.9688, running_acc=0.9817, grad=8.9409]Training epoch 42:  18%|█▊        | 30/163 [00:37<02:17,  1.04s/it, loss=0.1387, batch_acc=0.9688, running_acc=0.9817, grad=8.9409]Training epoch 42:  18%|█▊        | 30/163 [00:37<02:17,  1.04s/it, loss=0.1180, batch_acc=0.9688, running_acc=0.9812, grad=7.9697]Training epoch 42:  19%|█▉        | 31/163 [00:38<02:10,  1.01it/s, loss=0.1180, batch_acc=0.9688, running_acc=0.9812, grad=7.9697]Training epoch 42:  19%|█▉        | 31/163 [00:38<02:10,  1.01it/s, loss=0.1465, batch_acc=0.9688, running_acc=0.9808, grad=9.9636]Training epoch 42:  20%|█▉        | 32/163 [00:39<02:20,  1.07s/it, loss=0.1465, batch_acc=0.9688, running_acc=0.9808, grad=9.9636]Training epoch 42:  20%|█▉        | 32/163 [00:39<02:20,  1.07s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9814, grad=6.9095]Training epoch 42:  20%|██        | 33/163 [00:40<02:11,  1.01s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9814, grad=6.9095]Training epoch 42:  20%|██        | 33/163 [00:40<02:11,  1.01s/it, loss=0.1241, batch_acc=1.0000, running_acc=0.9820, grad=9.2313]Training epoch 42:  21%|██        | 34/163 [00:41<02:05,  1.03it/s, loss=0.1241, batch_acc=1.0000, running_acc=0.9820, grad=9.2313]Training epoch 42:  21%|██        | 34/163 [00:41<02:05,  1.03it/s, loss=0.1276, batch_acc=0.9688, running_acc=0.9816, grad=7.6559]Training epoch 42:  21%|██▏       | 35/163 [00:42<02:01,  1.06it/s, loss=0.1276, batch_acc=0.9688, running_acc=0.9816, grad=7.6559]Training epoch 42:  21%|██▏       | 35/163 [00:42<02:01,  1.06it/s, loss=0.1277, batch_acc=0.9688, running_acc=0.9812, grad=8.9307]Training epoch 42:  22%|██▏       | 36/163 [00:44<02:34,  1.22s/it, loss=0.1277, batch_acc=0.9688, running_acc=0.9812, grad=8.9307]Training epoch 42:  22%|██▏       | 36/163 [00:44<02:34,  1.22s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9818, grad=5.5208]Training epoch 42:  23%|██▎       | 37/163 [00:45<02:22,  1.13s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9818, grad=5.5208]Training epoch 42:  23%|██▎       | 37/163 [00:45<02:22,  1.13s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9823, grad=10.9638]Training epoch 42:  23%|██▎       | 38/163 [00:46<02:11,  1.05s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9823, grad=10.9638]Training epoch 42:  23%|██▎       | 38/163 [00:46<02:11,  1.05s/it, loss=0.0559, batch_acc=1.0000, running_acc=0.9827, grad=5.1734] Training epoch 42:  24%|██▍       | 39/163 [00:47<02:04,  1.00s/it, loss=0.0559, batch_acc=1.0000, running_acc=0.9827, grad=5.1734]Training epoch 42:  24%|██▍       | 39/163 [00:47<02:04,  1.00s/it, loss=0.1208, batch_acc=0.9688, running_acc=0.9824, grad=7.8503]Training epoch 42:  25%|██▍       | 40/163 [00:48<02:26,  1.19s/it, loss=0.1208, batch_acc=0.9688, running_acc=0.9824, grad=7.8503]Training epoch 42:  25%|██▍       | 40/163 [00:48<02:26,  1.19s/it, loss=0.1087, batch_acc=1.0000, running_acc=0.9828, grad=8.5689]Training epoch 42:  25%|██▌       | 41/163 [00:49<02:17,  1.13s/it, loss=0.1087, batch_acc=1.0000, running_acc=0.9828, grad=8.5689]Training epoch 42:  25%|██▌       | 41/163 [00:49<02:17,  1.13s/it, loss=0.0747, batch_acc=1.0000, running_acc=0.9832, grad=6.9199]Training epoch 42:  26%|██▌       | 42/163 [00:50<02:07,  1.06s/it, loss=0.0747, batch_acc=1.0000, running_acc=0.9832, grad=6.9199]Training epoch 42:  26%|██▌       | 42/163 [00:50<02:07,  1.06s/it, loss=0.0849, batch_acc=1.0000, running_acc=0.9836, grad=7.3353]Training epoch 42:  26%|██▋       | 43/163 [00:51<02:00,  1.00s/it, loss=0.0849, batch_acc=1.0000, running_acc=0.9836, grad=7.3353]Training epoch 42:  26%|██▋       | 43/163 [00:51<02:00,  1.00s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9840, grad=6.5653]Training epoch 42:  27%|██▋       | 44/163 [00:53<02:33,  1.29s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9840, grad=6.5653]Training epoch 42:  27%|██▋       | 44/163 [00:53<02:33,  1.29s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9844, grad=6.6532]Training epoch 42:  28%|██▊       | 45/163 [00:54<02:17,  1.17s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9844, grad=6.6532]Training epoch 42:  28%|██▊       | 45/163 [00:54<02:17,  1.17s/it, loss=0.0920, batch_acc=1.0000, running_acc=0.9847, grad=15.0352]Training epoch 42:  28%|██▊       | 46/163 [00:55<02:06,  1.08s/it, loss=0.0920, batch_acc=1.0000, running_acc=0.9847, grad=15.0352]Training epoch 42:  28%|██▊       | 46/163 [00:55<02:06,  1.08s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9851, grad=6.7359] Training epoch 42:  29%|██▉       | 47/163 [00:56<01:58,  1.02s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9851, grad=6.7359]Training epoch 42:  29%|██▉       | 47/163 [00:56<01:58,  1.02s/it, loss=0.0870, batch_acc=1.0000, running_acc=0.9854, grad=6.5123]Training epoch 42:  29%|██▉       | 48/163 [00:57<02:12,  1.15s/it, loss=0.0870, batch_acc=1.0000, running_acc=0.9854, grad=6.5123]Training epoch 42:  29%|██▉       | 48/163 [00:57<02:12,  1.15s/it, loss=0.0582, batch_acc=1.0000, running_acc=0.9857, grad=5.3124]Training epoch 42:  30%|███       | 49/163 [00:58<02:02,  1.07s/it, loss=0.0582, batch_acc=1.0000, running_acc=0.9857, grad=5.3124]Training epoch 42:  30%|███       | 49/163 [00:58<02:02,  1.07s/it, loss=0.1101, batch_acc=1.0000, running_acc=0.9860, grad=9.6974]Training epoch 42:  31%|███       | 50/163 [00:59<01:54,  1.01s/it, loss=0.1101, batch_acc=1.0000, running_acc=0.9860, grad=9.6974]Training epoch 42:  31%|███       | 50/163 [00:59<01:54,  1.01s/it, loss=0.1343, batch_acc=0.9688, running_acc=0.9856, grad=10.1235]Training epoch 42:  31%|███▏      | 51/163 [01:00<01:49,  1.03it/s, loss=0.1343, batch_acc=0.9688, running_acc=0.9856, grad=10.1235]Training epoch 42:  31%|███▏      | 51/163 [01:00<01:49,  1.03it/s, loss=0.1345, batch_acc=0.9688, running_acc=0.9853, grad=8.9831] Training epoch 42:  32%|███▏      | 52/163 [01:02<02:26,  1.32s/it, loss=0.1345, batch_acc=0.9688, running_acc=0.9853, grad=8.9831]Training epoch 42:  32%|███▏      | 52/163 [01:02<02:26,  1.32s/it, loss=0.1325, batch_acc=0.9688, running_acc=0.9850, grad=13.4316]Training epoch 42:  33%|███▎      | 53/163 [01:03<02:10,  1.19s/it, loss=0.1325, batch_acc=0.9688, running_acc=0.9850, grad=13.4316]Training epoch 42:  33%|███▎      | 53/163 [01:03<02:10,  1.19s/it, loss=0.1587, batch_acc=0.9375, running_acc=0.9841, grad=11.1537]Training epoch 42:  33%|███▎      | 54/163 [01:03<01:59,  1.09s/it, loss=0.1587, batch_acc=0.9375, running_acc=0.9841, grad=11.1537]Training epoch 42:  33%|███▎      | 54/163 [01:03<01:59,  1.09s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9838, grad=12.5279]Training epoch 42:  34%|███▎      | 55/163 [01:04<01:51,  1.03s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9838, grad=12.5279]Training epoch 42:  34%|███▎      | 55/163 [01:04<01:51,  1.03s/it, loss=0.1242, batch_acc=0.9688, running_acc=0.9835, grad=6.9516] Training epoch 42:  34%|███▍      | 56/163 [01:06<01:55,  1.08s/it, loss=0.1242, batch_acc=0.9688, running_acc=0.9835, grad=6.9516]Training epoch 42:  34%|███▍      | 56/163 [01:06<01:55,  1.08s/it, loss=0.0743, batch_acc=1.0000, running_acc=0.9838, grad=6.0338]Training epoch 42:  35%|███▍      | 57/163 [01:06<01:48,  1.02s/it, loss=0.0743, batch_acc=1.0000, running_acc=0.9838, grad=6.0338]Training epoch 42:  35%|███▍      | 57/163 [01:06<01:48,  1.02s/it, loss=0.1513, batch_acc=0.9688, running_acc=0.9836, grad=18.8184]Training epoch 42:  36%|███▌      | 58/163 [01:07<01:42,  1.02it/s, loss=0.1513, batch_acc=0.9688, running_acc=0.9836, grad=18.8184]Training epoch 42:  36%|███▌      | 58/163 [01:07<01:42,  1.02it/s, loss=0.0837, batch_acc=1.0000, running_acc=0.9838, grad=6.4501] Training epoch 42:  36%|███▌      | 59/163 [01:08<01:38,  1.05it/s, loss=0.0837, batch_acc=1.0000, running_acc=0.9838, grad=6.4501]Training epoch 42:  36%|███▌      | 59/163 [01:08<01:38,  1.05it/s, loss=0.1079, batch_acc=1.0000, running_acc=0.9841, grad=8.4824]Training epoch 42:  37%|███▋      | 60/163 [01:10<02:00,  1.17s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9841, grad=8.4824]Training epoch 42:  37%|███▋      | 60/163 [01:10<02:00,  1.17s/it, loss=0.1117, batch_acc=0.9688, running_acc=0.9839, grad=10.1227]Training epoch 42:  37%|███▋      | 61/163 [01:11<01:50,  1.08s/it, loss=0.1117, batch_acc=0.9688, running_acc=0.9839, grad=10.1227]Training epoch 42:  37%|███▋      | 61/163 [01:11<01:50,  1.08s/it, loss=0.0832, batch_acc=1.0000, running_acc=0.9841, grad=6.5184] Training epoch 42:  38%|███▊      | 62/163 [01:12<01:43,  1.02s/it, loss=0.0832, batch_acc=1.0000, running_acc=0.9841, grad=6.5184]Training epoch 42:  38%|███▊      | 62/163 [01:12<01:43,  1.02s/it, loss=0.1499, batch_acc=0.9062, running_acc=0.9829, grad=11.1657]Training epoch 42:  39%|███▊      | 63/163 [01:13<01:37,  1.02it/s, loss=0.1499, batch_acc=0.9062, running_acc=0.9829, grad=11.1657]Training epoch 42:  39%|███▊      | 63/163 [01:13<01:37,  1.02it/s, loss=0.0707, batch_acc=1.0000, running_acc=0.9831, grad=7.9421] Training epoch 42:  39%|███▉      | 64/163 [01:14<01:46,  1.08s/it, loss=0.0707, batch_acc=1.0000, running_acc=0.9831, grad=7.9421]Training epoch 42:  39%|███▉      | 64/163 [01:14<01:46,  1.08s/it, loss=0.1372, batch_acc=0.9375, running_acc=0.9824, grad=8.0288]Training epoch 42:  40%|███▉      | 65/163 [01:15<01:39,  1.02s/it, loss=0.1372, batch_acc=0.9375, running_acc=0.9824, grad=8.0288]Training epoch 42:  40%|███▉      | 65/163 [01:15<01:39,  1.02s/it, loss=0.1471, batch_acc=1.0000, running_acc=0.9827, grad=11.9288]Training epoch 42:  40%|████      | 66/163 [01:16<01:34,  1.02it/s, loss=0.1471, batch_acc=1.0000, running_acc=0.9827, grad=11.9288]Training epoch 42:  40%|████      | 66/163 [01:16<01:34,  1.02it/s, loss=0.1076, batch_acc=1.0000, running_acc=0.9830, grad=8.1849] Training epoch 42:  41%|████      | 67/163 [01:16<01:30,  1.06it/s, loss=0.1076, batch_acc=1.0000, running_acc=0.9830, grad=8.1849]Training epoch 42:  41%|████      | 67/163 [01:16<01:30,  1.06it/s, loss=0.0871, batch_acc=1.0000, running_acc=0.9832, grad=7.9536]Training epoch 42:  42%|████▏     | 68/163 [01:18<01:49,  1.16s/it, loss=0.0871, batch_acc=1.0000, running_acc=0.9832, grad=7.9536]Training epoch 42:  42%|████▏     | 68/163 [01:18<01:49,  1.16s/it, loss=0.1443, batch_acc=1.0000, running_acc=0.9835, grad=13.2883]Training epoch 42:  42%|████▏     | 69/163 [01:19<01:40,  1.07s/it, loss=0.1443, batch_acc=1.0000, running_acc=0.9835, grad=13.2883]Training epoch 42:  42%|████▏     | 69/163 [01:19<01:40,  1.07s/it, loss=0.1044, batch_acc=1.0000, running_acc=0.9837, grad=7.2677] Training epoch 42:  43%|████▎     | 70/163 [01:20<01:34,  1.01s/it, loss=0.1044, batch_acc=1.0000, running_acc=0.9837, grad=7.2677]Training epoch 42:  43%|████▎     | 70/163 [01:20<01:34,  1.01s/it, loss=0.1249, batch_acc=0.9688, running_acc=0.9835, grad=9.6872]Training epoch 42:  44%|████▎     | 71/163 [01:21<01:29,  1.03it/s, loss=0.1249, batch_acc=0.9688, running_acc=0.9835, grad=9.6872]Training epoch 42:  44%|████▎     | 71/163 [01:21<01:29,  1.03it/s, loss=0.1013, batch_acc=1.0000, running_acc=0.9837, grad=7.4706]Training epoch 42:  44%|████▍     | 72/163 [01:22<01:33,  1.03s/it, loss=0.1013, batch_acc=1.0000, running_acc=0.9837, grad=7.4706]Training epoch 42:  44%|████▍     | 72/163 [01:22<01:33,  1.03s/it, loss=0.1010, batch_acc=1.0000, running_acc=0.9839, grad=8.2241]Training epoch 42:  45%|████▍     | 73/163 [01:23<01:33,  1.04s/it, loss=0.1010, batch_acc=1.0000, running_acc=0.9839, grad=8.2241]Training epoch 42:  45%|████▍     | 73/163 [01:23<01:33,  1.04s/it, loss=0.2032, batch_acc=0.8750, running_acc=0.9824, grad=16.5189]Training epoch 42:  45%|████▌     | 74/163 [01:24<01:28,  1.01it/s, loss=0.2032, batch_acc=0.8750, running_acc=0.9824, grad=16.5189]Training epoch 42:  45%|████▌     | 74/163 [01:24<01:28,  1.01it/s, loss=0.1151, batch_acc=1.0000, running_acc=0.9827, grad=11.3415]Training epoch 42:  46%|████▌     | 75/163 [01:25<01:24,  1.04it/s, loss=0.1151, batch_acc=1.0000, running_acc=0.9827, grad=11.3415]Training epoch 42:  46%|████▌     | 75/163 [01:25<01:24,  1.04it/s, loss=0.1199, batch_acc=0.9688, running_acc=0.9825, grad=9.8008] Training epoch 42:  47%|████▋     | 76/163 [01:26<01:27,  1.01s/it, loss=0.1199, batch_acc=0.9688, running_acc=0.9825, grad=9.8008]Training epoch 42:  47%|████▋     | 76/163 [01:26<01:27,  1.01s/it, loss=0.1101, batch_acc=1.0000, running_acc=0.9827, grad=7.4394]Training epoch 42:  47%|████▋     | 77/163 [01:27<01:35,  1.11s/it, loss=0.1101, batch_acc=1.0000, running_acc=0.9827, grad=7.4394]Training epoch 42:  47%|████▋     | 77/163 [01:27<01:35,  1.11s/it, loss=0.1639, batch_acc=0.9375, running_acc=0.9821, grad=12.8847]Training epoch 42:  48%|████▊     | 78/163 [01:28<01:28,  1.04s/it, loss=0.1639, batch_acc=0.9375, running_acc=0.9821, grad=12.8847]Training epoch 42:  48%|████▊     | 78/163 [01:28<01:28,  1.04s/it, loss=0.1557, batch_acc=0.9688, running_acc=0.9820, grad=12.7323]Training epoch 42:  48%|████▊     | 79/163 [01:29<01:23,  1.01it/s, loss=0.1557, batch_acc=0.9688, running_acc=0.9820, grad=12.7323]Training epoch 42:  48%|████▊     | 79/163 [01:29<01:23,  1.01it/s, loss=0.1393, batch_acc=0.9688, running_acc=0.9818, grad=12.6302]Training epoch 42:  49%|████▉     | 80/163 [01:30<01:23,  1.01s/it, loss=0.1393, batch_acc=0.9688, running_acc=0.9818, grad=12.6302]Training epoch 42:  49%|████▉     | 80/163 [01:30<01:23,  1.01s/it, loss=0.1056, batch_acc=0.9688, running_acc=0.9816, grad=7.5328] Training epoch 42:  50%|████▉     | 81/163 [01:32<01:39,  1.21s/it, loss=0.1056, batch_acc=0.9688, running_acc=0.9816, grad=7.5328]Training epoch 42:  50%|████▉     | 81/163 [01:32<01:39,  1.21s/it, loss=0.0999, batch_acc=1.0000, running_acc=0.9819, grad=7.8148]Training epoch 42:  50%|█████     | 82/163 [01:33<01:30,  1.11s/it, loss=0.0999, batch_acc=1.0000, running_acc=0.9819, grad=7.8148]Training epoch 42:  50%|█████     | 82/163 [01:33<01:30,  1.11s/it, loss=0.1096, batch_acc=0.9688, running_acc=0.9817, grad=7.8332]Training epoch 42:  51%|█████     | 83/163 [01:33<01:23,  1.04s/it, loss=0.1096, batch_acc=0.9688, running_acc=0.9817, grad=7.8332]Training epoch 42:  51%|█████     | 83/163 [01:33<01:23,  1.04s/it, loss=0.1045, batch_acc=0.9688, running_acc=0.9816, grad=10.2448]Training epoch 42:  52%|█████▏    | 84/163 [01:34<01:19,  1.01s/it, loss=0.1045, batch_acc=0.9688, running_acc=0.9816, grad=10.2448]Training epoch 42:  52%|█████▏    | 84/163 [01:34<01:19,  1.01s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9818, grad=7.4570] Training epoch 42:  52%|█████▏    | 85/163 [01:36<01:30,  1.16s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9818, grad=7.4570]Training epoch 42:  52%|█████▏    | 85/163 [01:36<01:30,  1.16s/it, loss=0.0704, batch_acc=1.0000, running_acc=0.9820, grad=6.8670]Training epoch 42:  53%|█████▎    | 86/163 [01:37<01:22,  1.07s/it, loss=0.0704, batch_acc=1.0000, running_acc=0.9820, grad=6.8670]Training epoch 42:  53%|█████▎    | 86/163 [01:37<01:22,  1.07s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9822, grad=8.0779]Training epoch 42:  53%|█████▎    | 87/163 [01:38<01:17,  1.01s/it, loss=0.0845, batch_acc=1.0000, running_acc=0.9822, grad=8.0779]Training epoch 42:  53%|█████▎    | 87/163 [01:38<01:17,  1.01s/it, loss=0.0940, batch_acc=1.0000, running_acc=0.9824, grad=9.6484]Training epoch 42:  54%|█████▍    | 88/163 [01:39<01:28,  1.18s/it, loss=0.0940, batch_acc=1.0000, running_acc=0.9824, grad=9.6484]Training epoch 42:  54%|█████▍    | 88/163 [01:39<01:28,  1.18s/it, loss=0.1582, batch_acc=0.9688, running_acc=0.9822, grad=13.6723]Training epoch 42:  55%|█████▍    | 89/163 [01:40<01:20,  1.09s/it, loss=0.1582, batch_acc=0.9688, running_acc=0.9822, grad=13.6723]Training epoch 42:  55%|█████▍    | 89/163 [01:40<01:20,  1.09s/it, loss=0.1167, batch_acc=0.9688, running_acc=0.9821, grad=7.3497] Training epoch 42:  55%|█████▌    | 90/163 [01:41<01:15,  1.03s/it, loss=0.1167, batch_acc=0.9688, running_acc=0.9821, grad=7.3497]Training epoch 42:  55%|█████▌    | 90/163 [01:41<01:15,  1.03s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9823, grad=8.8804]Training epoch 42:  56%|█████▌    | 91/163 [01:42<01:10,  1.02it/s, loss=0.0942, batch_acc=1.0000, running_acc=0.9823, grad=8.8804]Training epoch 42:  56%|█████▌    | 91/163 [01:42<01:10,  1.02it/s, loss=0.1461, batch_acc=0.9688, running_acc=0.9821, grad=8.4473]Training epoch 42:  56%|█████▋    | 92/163 [01:43<01:23,  1.18s/it, loss=0.1461, batch_acc=0.9688, running_acc=0.9821, grad=8.4473]Training epoch 42:  56%|█████▋    | 92/163 [01:43<01:23,  1.18s/it, loss=0.1730, batch_acc=0.9375, running_acc=0.9817, grad=15.7091]Training epoch 42:  57%|█████▋    | 93/163 [01:45<01:21,  1.17s/it, loss=0.1730, batch_acc=0.9375, running_acc=0.9817, grad=15.7091]Training epoch 42:  57%|█████▋    | 93/163 [01:45<01:21,  1.17s/it, loss=0.0995, batch_acc=1.0000, running_acc=0.9819, grad=10.3372]Training epoch 42:  58%|█████▊    | 94/163 [01:46<01:14,  1.08s/it, loss=0.0995, batch_acc=1.0000, running_acc=0.9819, grad=10.3372]Training epoch 42:  58%|█████▊    | 94/163 [01:46<01:14,  1.08s/it, loss=0.1202, batch_acc=0.9688, running_acc=0.9817, grad=8.7763] Training epoch 42:  58%|█████▊    | 95/163 [01:46<01:09,  1.02s/it, loss=0.1202, batch_acc=0.9688, running_acc=0.9817, grad=8.7763]Training epoch 42:  58%|█████▊    | 95/163 [01:46<01:09,  1.02s/it, loss=0.1352, batch_acc=0.9688, running_acc=0.9816, grad=10.6091]Training epoch 42:  59%|█████▉    | 96/163 [01:47<01:08,  1.02s/it, loss=0.1352, batch_acc=0.9688, running_acc=0.9816, grad=10.6091]Training epoch 42:  59%|█████▉    | 96/163 [01:47<01:08,  1.02s/it, loss=0.0829, batch_acc=1.0000, running_acc=0.9818, grad=7.1272] Training epoch 42:  60%|█████▉    | 97/163 [01:49<01:17,  1.17s/it, loss=0.0829, batch_acc=1.0000, running_acc=0.9818, grad=7.1272]Training epoch 42:  60%|█████▉    | 97/163 [01:49<01:17,  1.17s/it, loss=0.1138, batch_acc=0.9688, running_acc=0.9816, grad=8.5871]Training epoch 42:  60%|██████    | 98/163 [01:50<01:10,  1.08s/it, loss=0.1138, batch_acc=0.9688, running_acc=0.9816, grad=8.5871]Training epoch 42:  60%|██████    | 98/163 [01:50<01:10,  1.08s/it, loss=0.1038, batch_acc=1.0000, running_acc=0.9818, grad=8.1606]Training epoch 42:  61%|██████    | 99/163 [01:51<01:05,  1.02s/it, loss=0.1038, batch_acc=1.0000, running_acc=0.9818, grad=8.1606]Training epoch 42:  61%|██████    | 99/163 [01:51<01:05,  1.02s/it, loss=0.1573, batch_acc=0.9688, running_acc=0.9817, grad=14.0404]Training epoch 42:  61%|██████▏   | 100/163 [01:52<01:05,  1.04s/it, loss=0.1573, batch_acc=0.9688, running_acc=0.9817, grad=14.0404]Training epoch 42:  61%|██████▏   | 100/163 [01:52<01:05,  1.04s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9819, grad=8.6114] Training epoch 42:  62%|██████▏   | 101/163 [01:54<01:21,  1.31s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9819, grad=8.6114]Training epoch 42:  62%|██████▏   | 101/163 [01:54<01:21,  1.31s/it, loss=0.1053, batch_acc=1.0000, running_acc=0.9821, grad=15.5374]Training epoch 42:  63%|██████▎   | 102/163 [01:55<01:12,  1.18s/it, loss=0.1053, batch_acc=1.0000, running_acc=0.9821, grad=15.5374]Training epoch 42:  63%|██████▎   | 102/163 [01:55<01:12,  1.18s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9822, grad=17.3545]Training epoch 42:  63%|██████▎   | 103/163 [01:55<01:05,  1.09s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9822, grad=17.3545]Training epoch 42:  63%|██████▎   | 103/163 [01:55<01:05,  1.09s/it, loss=0.1168, batch_acc=1.0000, running_acc=0.9824, grad=8.9855] Training epoch 42:  64%|██████▍   | 104/163 [01:56<01:01,  1.04s/it, loss=0.1168, batch_acc=1.0000, running_acc=0.9824, grad=8.9855]Training epoch 42:  64%|██████▍   | 104/163 [01:56<01:01,  1.04s/it, loss=0.0667, batch_acc=1.0000, running_acc=0.9826, grad=5.7577]Training epoch 42:  64%|██████▍   | 105/163 [01:58<01:16,  1.32s/it, loss=0.0667, batch_acc=1.0000, running_acc=0.9826, grad=5.7577]Training epoch 42:  64%|██████▍   | 105/163 [01:58<01:16,  1.32s/it, loss=0.0815, batch_acc=1.0000, running_acc=0.9827, grad=6.4986]Training epoch 42:  65%|██████▌   | 106/163 [01:59<01:07,  1.18s/it, loss=0.0815, batch_acc=1.0000, running_acc=0.9827, grad=6.4986]Training epoch 42:  65%|██████▌   | 106/163 [01:59<01:07,  1.18s/it, loss=0.1346, batch_acc=1.0000, running_acc=0.9829, grad=14.8735]Training epoch 42:  66%|██████▌   | 107/163 [02:00<01:01,  1.09s/it, loss=0.1346, batch_acc=1.0000, running_acc=0.9829, grad=14.8735]Training epoch 42:  66%|██████▌   | 107/163 [02:00<01:01,  1.09s/it, loss=0.1281, batch_acc=1.0000, running_acc=0.9831, grad=13.1807]Training epoch 42:  66%|██████▋   | 108/163 [02:01<00:56,  1.03s/it, loss=0.1281, batch_acc=1.0000, running_acc=0.9831, grad=13.1807]Training epoch 42:  66%|██████▋   | 108/163 [02:01<00:56,  1.03s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9832, grad=8.2368] Training epoch 42:  67%|██████▋   | 109/163 [02:03<01:08,  1.27s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9832, grad=8.2368]Training epoch 42:  67%|██████▋   | 109/163 [02:03<01:08,  1.27s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9834, grad=7.8393]Training epoch 42:  67%|██████▋   | 110/163 [02:04<01:01,  1.15s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9834, grad=7.8393]Training epoch 42:  67%|██████▋   | 110/163 [02:04<01:01,  1.15s/it, loss=0.1030, batch_acc=1.0000, running_acc=0.9835, grad=9.7417]Training epoch 42:  68%|██████▊   | 111/163 [02:05<00:55,  1.07s/it, loss=0.1030, batch_acc=1.0000, running_acc=0.9835, grad=9.7417]Training epoch 42:  68%|██████▊   | 111/163 [02:05<00:55,  1.07s/it, loss=0.0742, batch_acc=1.0000, running_acc=0.9837, grad=6.8638]Training epoch 42:  69%|██████▊   | 112/163 [02:05<00:51,  1.01s/it, loss=0.0742, batch_acc=1.0000, running_acc=0.9837, grad=6.8638]Training epoch 42:  69%|██████▊   | 112/163 [02:05<00:51,  1.01s/it, loss=0.1166, batch_acc=0.9688, running_acc=0.9835, grad=9.5983]Training epoch 42:  69%|██████▉   | 113/163 [02:08<01:07,  1.35s/it, loss=0.1166, batch_acc=0.9688, running_acc=0.9835, grad=9.5983]Training epoch 42:  69%|██████▉   | 113/163 [02:08<01:07,  1.35s/it, loss=0.0958, batch_acc=1.0000, running_acc=0.9837, grad=11.1970]Training epoch 42:  70%|██████▉   | 114/163 [02:08<00:59,  1.21s/it, loss=0.0958, batch_acc=1.0000, running_acc=0.9837, grad=11.1970]Training epoch 42:  70%|██████▉   | 114/163 [02:08<00:59,  1.21s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9838, grad=9.4398] Training epoch 42:  71%|███████   | 115/163 [02:09<00:53,  1.11s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9838, grad=9.4398]Training epoch 42:  71%|███████   | 115/163 [02:09<00:53,  1.11s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9840, grad=8.0431]Training epoch 42:  71%|███████   | 116/163 [02:10<00:48,  1.04s/it, loss=0.0902, batch_acc=1.0000, running_acc=0.9840, grad=8.0431]Training epoch 42:  71%|███████   | 116/163 [02:10<00:48,  1.04s/it, loss=0.0876, batch_acc=1.0000, running_acc=0.9841, grad=8.4631]Training epoch 42:  72%|███████▏  | 117/163 [02:12<00:56,  1.23s/it, loss=0.0876, batch_acc=1.0000, running_acc=0.9841, grad=8.4631]Training epoch 42:  72%|███████▏  | 117/163 [02:12<00:56,  1.23s/it, loss=0.2018, batch_acc=0.9375, running_acc=0.9837, grad=21.4377]Training epoch 42:  72%|███████▏  | 118/163 [02:13<00:50,  1.12s/it, loss=0.2018, batch_acc=0.9375, running_acc=0.9837, grad=21.4377]Training epoch 42:  72%|███████▏  | 118/163 [02:13<00:50,  1.12s/it, loss=0.1310, batch_acc=0.9688, running_acc=0.9836, grad=9.3730] Training epoch 42:  73%|███████▎  | 119/163 [02:14<00:46,  1.05s/it, loss=0.1310, batch_acc=0.9688, running_acc=0.9836, grad=9.3730]Training epoch 42:  73%|███████▎  | 119/163 [02:14<00:46,  1.05s/it, loss=0.2243, batch_acc=0.9375, running_acc=0.9832, grad=18.6058]Training epoch 42:  74%|███████▎  | 120/163 [02:15<00:48,  1.14s/it, loss=0.2243, batch_acc=0.9375, running_acc=0.9832, grad=18.6058]Training epoch 42:  74%|███████▎  | 120/163 [02:15<00:48,  1.14s/it, loss=0.1508, batch_acc=0.9062, running_acc=0.9826, grad=11.4032]Training epoch 42:  74%|███████▍  | 121/163 [02:16<00:48,  1.14s/it, loss=0.1508, batch_acc=0.9062, running_acc=0.9826, grad=11.4032]Training epoch 42:  74%|███████▍  | 121/163 [02:16<00:48,  1.14s/it, loss=0.1722, batch_acc=0.9375, running_acc=0.9822, grad=10.1752]Training epoch 42:  75%|███████▍  | 122/163 [02:17<00:43,  1.06s/it, loss=0.1722, batch_acc=0.9375, running_acc=0.9822, grad=10.1752]Training epoch 42:  75%|███████▍  | 122/163 [02:17<00:43,  1.06s/it, loss=0.1428, batch_acc=0.9375, running_acc=0.9818, grad=12.0961]Training epoch 42:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.1428, batch_acc=0.9375, running_acc=0.9818, grad=12.0961]Training epoch 42:  75%|███████▌  | 123/163 [02:18<00:40,  1.01s/it, loss=0.0956, batch_acc=1.0000, running_acc=0.9820, grad=8.9519] Training epoch 42:  76%|███████▌  | 124/163 [02:19<00:41,  1.07s/it, loss=0.0956, batch_acc=1.0000, running_acc=0.9820, grad=8.9519]Training epoch 42:  76%|███████▌  | 124/163 [02:19<00:41,  1.07s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9821, grad=8.0202]Training epoch 42:  77%|███████▋  | 125/163 [02:21<00:45,  1.21s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9821, grad=8.0202]Training epoch 42:  77%|███████▋  | 125/163 [02:21<00:45,  1.21s/it, loss=0.1330, batch_acc=0.9688, running_acc=0.9820, grad=10.8245]Training epoch 42:  77%|███████▋  | 126/163 [02:22<00:41,  1.11s/it, loss=0.1330, batch_acc=0.9688, running_acc=0.9820, grad=10.8245]Training epoch 42:  77%|███████▋  | 126/163 [02:22<00:41,  1.11s/it, loss=0.1022, batch_acc=1.0000, running_acc=0.9821, grad=7.7137] Training epoch 42:  78%|███████▊  | 127/163 [02:22<00:37,  1.04s/it, loss=0.1022, batch_acc=1.0000, running_acc=0.9821, grad=7.7137]Training epoch 42:  78%|███████▊  | 127/163 [02:22<00:37,  1.04s/it, loss=0.0897, batch_acc=1.0000, running_acc=0.9823, grad=6.5532]Training epoch 42:  79%|███████▊  | 128/163 [02:23<00:34,  1.01it/s, loss=0.0897, batch_acc=1.0000, running_acc=0.9823, grad=6.5532]Training epoch 42:  79%|███████▊  | 128/163 [02:23<00:34,  1.01it/s, loss=0.0981, batch_acc=0.9688, running_acc=0.9822, grad=7.3082]Training epoch 42:  79%|███████▉  | 129/163 [02:25<00:37,  1.11s/it, loss=0.0981, batch_acc=0.9688, running_acc=0.9822, grad=7.3082]Training epoch 42:  79%|███████▉  | 129/163 [02:25<00:37,  1.11s/it, loss=0.1112, batch_acc=0.9688, running_acc=0.9821, grad=7.7363]Training epoch 42:  80%|███████▉  | 130/163 [02:26<00:34,  1.04s/it, loss=0.1112, batch_acc=0.9688, running_acc=0.9821, grad=7.7363]Training epoch 42:  80%|███████▉  | 130/163 [02:26<00:34,  1.04s/it, loss=0.0652, batch_acc=1.0000, running_acc=0.9822, grad=5.5675]Training epoch 42:  80%|████████  | 131/163 [02:26<00:31,  1.01it/s, loss=0.0652, batch_acc=1.0000, running_acc=0.9822, grad=5.5675]Training epoch 42:  80%|████████  | 131/163 [02:26<00:31,  1.01it/s, loss=0.1438, batch_acc=0.9688, running_acc=0.9821, grad=14.2260]Training epoch 42:  81%|████████  | 132/163 [02:27<00:29,  1.04it/s, loss=0.1438, batch_acc=0.9688, running_acc=0.9821, grad=14.2260]Training epoch 42:  81%|████████  | 132/163 [02:27<00:29,  1.04it/s, loss=0.1562, batch_acc=1.0000, running_acc=0.9822, grad=15.1514]Training epoch 42:  82%|████████▏ | 133/163 [02:29<00:37,  1.23s/it, loss=0.1562, batch_acc=1.0000, running_acc=0.9822, grad=15.1514]Training epoch 42:  82%|████████▏ | 133/163 [02:29<00:37,  1.23s/it, loss=0.1591, batch_acc=0.9688, running_acc=0.9821, grad=9.6255] Training epoch 42:  82%|████████▏ | 134/163 [02:30<00:32,  1.13s/it, loss=0.1591, batch_acc=0.9688, running_acc=0.9821, grad=9.6255]Training epoch 42:  82%|████████▏ | 134/163 [02:30<00:32,  1.13s/it, loss=0.1669, batch_acc=0.9688, running_acc=0.9820, grad=16.1827]Training epoch 42:  83%|████████▎ | 135/163 [02:31<00:29,  1.05s/it, loss=0.1669, batch_acc=0.9688, running_acc=0.9820, grad=16.1827]Training epoch 42:  83%|████████▎ | 135/163 [02:31<00:29,  1.05s/it, loss=0.1414, batch_acc=0.9688, running_acc=0.9819, grad=9.8380] Training epoch 42:  83%|████████▎ | 136/163 [02:32<00:27,  1.02s/it, loss=0.1414, batch_acc=0.9688, running_acc=0.9819, grad=9.8380]Training epoch 42:  83%|████████▎ | 136/163 [02:32<00:27,  1.02s/it, loss=0.1299, batch_acc=1.0000, running_acc=0.9821, grad=10.0475]Training epoch 42:  84%|████████▍ | 137/163 [02:34<00:32,  1.23s/it, loss=0.1299, batch_acc=1.0000, running_acc=0.9821, grad=10.0475]Training epoch 42:  84%|████████▍ | 137/163 [02:34<00:32,  1.23s/it, loss=0.1328, batch_acc=1.0000, running_acc=0.9822, grad=13.5263]Training epoch 42:  85%|████████▍ | 138/163 [02:34<00:28,  1.12s/it, loss=0.1328, batch_acc=1.0000, running_acc=0.9822, grad=13.5263]Training epoch 42:  85%|████████▍ | 138/163 [02:34<00:28,  1.12s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9823, grad=8.8028] Training epoch 42:  85%|████████▌ | 139/163 [02:35<00:25,  1.05s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9823, grad=8.8028]Training epoch 42:  85%|████████▌ | 139/163 [02:35<00:25,  1.05s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9825, grad=8.0074]Training epoch 42:  86%|████████▌ | 140/163 [02:36<00:22,  1.00it/s, loss=0.0812, batch_acc=1.0000, running_acc=0.9825, grad=8.0074]Training epoch 42:  86%|████████▌ | 140/163 [02:36<00:22,  1.00it/s, loss=0.1031, batch_acc=0.9688, running_acc=0.9824, grad=6.7323]Training epoch 42:  87%|████████▋ | 141/163 [02:38<00:23,  1.09s/it, loss=0.1031, batch_acc=0.9688, running_acc=0.9824, grad=6.7323]Training epoch 42:  87%|████████▋ | 141/163 [02:38<00:23,  1.09s/it, loss=0.1179, batch_acc=1.0000, running_acc=0.9825, grad=14.8649]Training epoch 42:  87%|████████▋ | 142/163 [02:38<00:21,  1.02s/it, loss=0.1179, batch_acc=1.0000, running_acc=0.9825, grad=14.8649]Training epoch 42:  87%|████████▋ | 142/163 [02:38<00:21,  1.02s/it, loss=0.1015, batch_acc=1.0000, running_acc=0.9826, grad=7.4951] Training epoch 42:  88%|████████▊ | 143/163 [02:39<00:19,  1.02it/s, loss=0.1015, batch_acc=1.0000, running_acc=0.9826, grad=7.4951]Training epoch 42:  88%|████████▊ | 143/163 [02:39<00:19,  1.02it/s, loss=0.1126, batch_acc=0.9688, running_acc=0.9825, grad=7.3144]Training epoch 42:  88%|████████▊ | 144/163 [02:40<00:18,  1.01it/s, loss=0.1126, batch_acc=0.9688, running_acc=0.9825, grad=7.3144]Training epoch 42:  88%|████████▊ | 144/163 [02:40<00:18,  1.01it/s, loss=0.1406, batch_acc=0.9688, running_acc=0.9824, grad=7.9452]Training epoch 42:  89%|████████▉ | 145/163 [02:42<00:21,  1.18s/it, loss=0.1406, batch_acc=0.9688, running_acc=0.9824, grad=7.9452]Training epoch 42:  89%|████████▉ | 145/163 [02:42<00:21,  1.18s/it, loss=0.1153, batch_acc=0.9375, running_acc=0.9821, grad=9.2321]Training epoch 42:  90%|████████▉ | 146/163 [02:43<00:18,  1.09s/it, loss=0.1153, batch_acc=0.9375, running_acc=0.9821, grad=9.2321]Training epoch 42:  90%|████████▉ | 146/163 [02:43<00:18,  1.09s/it, loss=0.0793, batch_acc=1.0000, running_acc=0.9822, grad=8.5223]Training epoch 42:  90%|█████████ | 147/163 [02:44<00:16,  1.02s/it, loss=0.0793, batch_acc=1.0000, running_acc=0.9822, grad=8.5223]Training epoch 42:  90%|█████████ | 147/163 [02:44<00:16,  1.02s/it, loss=0.0955, batch_acc=0.9688, running_acc=0.9821, grad=7.5307]Training epoch 42:  91%|█████████ | 148/163 [02:45<00:14,  1.02it/s, loss=0.0955, batch_acc=0.9688, running_acc=0.9821, grad=7.5307]Training epoch 42:  91%|█████████ | 148/163 [02:45<00:14,  1.02it/s, loss=0.0979, batch_acc=1.0000, running_acc=0.9823, grad=9.2356]Training epoch 42:  91%|█████████▏| 149/163 [02:46<00:17,  1.24s/it, loss=0.0979, batch_acc=1.0000, running_acc=0.9823, grad=9.2356]Training epoch 42:  91%|█████████▏| 149/163 [02:46<00:17,  1.24s/it, loss=0.0712, batch_acc=1.0000, running_acc=0.9824, grad=5.6746]Training epoch 42:  92%|█████████▏| 150/163 [02:47<00:14,  1.13s/it, loss=0.0712, batch_acc=1.0000, running_acc=0.9824, grad=5.6746]Training epoch 42:  92%|█████████▏| 150/163 [02:47<00:14,  1.13s/it, loss=0.1191, batch_acc=0.9688, running_acc=0.9823, grad=11.4399]Training epoch 42:  93%|█████████▎| 151/163 [02:48<00:12,  1.05s/it, loss=0.1191, batch_acc=0.9688, running_acc=0.9823, grad=11.4399]Training epoch 42:  93%|█████████▎| 151/163 [02:48<00:12,  1.05s/it, loss=0.1238, batch_acc=0.9688, running_acc=0.9822, grad=11.1613]Training epoch 42:  93%|█████████▎| 152/163 [02:49<00:11,  1.02s/it, loss=0.1238, batch_acc=0.9688, running_acc=0.9822, grad=11.1613]Training epoch 42:  93%|█████████▎| 152/163 [02:49<00:11,  1.02s/it, loss=0.1243, batch_acc=0.9688, running_acc=0.9821, grad=7.8190] Training epoch 42:  94%|█████████▍| 153/163 [02:51<00:11,  1.18s/it, loss=0.1243, batch_acc=0.9688, running_acc=0.9821, grad=7.8190]Training epoch 42:  94%|█████████▍| 153/163 [02:51<00:11,  1.18s/it, loss=0.1761, batch_acc=1.0000, running_acc=0.9822, grad=11.7722]Training epoch 42:  94%|█████████▍| 154/163 [02:52<00:09,  1.09s/it, loss=0.1761, batch_acc=1.0000, running_acc=0.9822, grad=11.7722]Training epoch 42:  94%|█████████▍| 154/163 [02:52<00:09,  1.09s/it, loss=0.1120, batch_acc=1.0000, running_acc=0.9823, grad=17.8867]Training epoch 42:  95%|█████████▌| 155/163 [02:52<00:08,  1.03s/it, loss=0.1120, batch_acc=1.0000, running_acc=0.9823, grad=17.8867]Training epoch 42:  95%|█████████▌| 155/163 [02:52<00:08,  1.03s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9825, grad=7.0077] Training epoch 42:  96%|█████████▌| 156/163 [02:53<00:06,  1.02it/s, loss=0.0826, batch_acc=1.0000, running_acc=0.9825, grad=7.0077]Training epoch 42:  96%|█████████▌| 156/163 [02:53<00:06,  1.02it/s, loss=0.1185, batch_acc=0.9688, running_acc=0.9824, grad=10.7898]Training epoch 42:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=0.1185, batch_acc=0.9688, running_acc=0.9824, grad=10.7898]Training epoch 42:  96%|█████████▋| 157/163 [02:55<00:07,  1.21s/it, loss=0.1161, batch_acc=1.0000, running_acc=0.9825, grad=13.3807]Training epoch 42:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=0.1161, batch_acc=1.0000, running_acc=0.9825, grad=13.3807]Training epoch 42:  97%|█████████▋| 158/163 [02:56<00:05,  1.11s/it, loss=0.0983, batch_acc=0.9688, running_acc=0.9824, grad=8.1752] Training epoch 42:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=0.0983, batch_acc=0.9688, running_acc=0.9824, grad=8.1752]Training epoch 42:  98%|█████████▊| 159/163 [02:57<00:04,  1.04s/it, loss=0.0981, batch_acc=0.9688, running_acc=0.9823, grad=8.9356]Training epoch 42:  98%|█████████▊| 160/163 [02:58<00:02,  1.01it/s, loss=0.0981, batch_acc=0.9688, running_acc=0.9823, grad=8.9356]Training epoch 42:  98%|█████████▊| 160/163 [02:58<00:02,  1.01it/s, loss=0.1593, batch_acc=0.9688, running_acc=0.9822, grad=13.8999]Training epoch 42:  99%|█████████▉| 161/163 [02:59<00:02,  1.20s/it, loss=0.1593, batch_acc=0.9688, running_acc=0.9822, grad=13.8999]Training epoch 42:  99%|█████████▉| 161/163 [02:59<00:02,  1.20s/it, loss=0.1177, batch_acc=1.0000, running_acc=0.9823, grad=8.5975] Training epoch 42:  99%|█████████▉| 162/163 [03:00<00:01,  1.10s/it, loss=0.1177, batch_acc=1.0000, running_acc=0.9823, grad=8.5975]Training epoch 42:  99%|█████████▉| 162/163 [03:00<00:01,  1.10s/it, loss=0.1406, batch_acc=0.9688, running_acc=0.9823, grad=12.4265]Training epoch 42: 100%|██████████| 163/163 [03:01<00:00,  1.04it/s, loss=0.1406, batch_acc=0.9688, running_acc=0.9823, grad=12.4265]Training epoch 42: 100%|██████████| 163/163 [03:01<00:00,  1.04it/s, loss=0.1317, batch_acc=1.0000, running_acc=0.9823, grad=13.8785]Training epoch 42: 100%|██████████| 163/163 [03:01<00:00,  1.11s/it, loss=0.1317, batch_acc=1.0000, running_acc=0.9823, grad=13.8785]
Evaluation epoch 42:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 42:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it]Evaluation epoch 42:   4%|▎         | 1/28 [00:05<02:15,  5.03s/it, loss=0.3696, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 42:   7%|▋         | 2/28 [00:05<00:59,  2.29s/it, loss=0.3696, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 42:   7%|▋         | 2/28 [00:05<00:59,  2.29s/it, loss=0.2038, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 42:  11%|█         | 3/28 [00:05<00:34,  1.36s/it, loss=0.2038, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 42:  11%|█         | 3/28 [00:05<00:34,  1.36s/it, loss=0.3250, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 42:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.3250, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 42:  14%|█▍        | 4/28 [00:09<00:59,  2.49s/it, loss=0.4233, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 42:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=0.4233, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 42:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=1.3983, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 42:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.3983, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 42:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.5084, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 42:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.5084, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 42:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.6137, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 42:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=0.6137, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 42:  29%|██▊       | 8/28 [00:14<00:33,  1.68s/it, loss=0.4019, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 42:  32%|███▏      | 9/28 [00:14<00:25,  1.33s/it, loss=0.4019, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 42:  32%|███▏      | 9/28 [00:14<00:25,  1.33s/it, loss=0.4123, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 42:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.4123, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 42:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.4296, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 42:  39%|███▉      | 11/28 [00:15<00:13,  1.29it/s, loss=0.4296, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 42:  39%|███▉      | 11/28 [00:15<00:13,  1.29it/s, loss=0.3150, batch_acc=0.9375, running_acc=0.8977]Evaluation epoch 42:  43%|████▎     | 12/28 [00:20<00:34,  2.16s/it, loss=0.3150, batch_acc=0.9375, running_acc=0.8977]Evaluation epoch 42:  43%|████▎     | 12/28 [00:20<00:34,  2.16s/it, loss=0.8882, batch_acc=0.7812, running_acc=0.8880]Evaluation epoch 42:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.8882, batch_acc=0.7812, running_acc=0.8880]Evaluation epoch 42:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.2647, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 42:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.2647, batch_acc=0.9375, running_acc=0.8918]Evaluation epoch 42:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.8551, batch_acc=0.7812, running_acc=0.8839]Evaluation epoch 42:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=0.8551, batch_acc=0.7812, running_acc=0.8839]Evaluation epoch 42:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=0.9309, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 42:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=0.9309, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 42:  57%|█████▋    | 16/28 [00:24<00:17,  1.50s/it, loss=0.7662, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 42:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.7662, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 42:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.6237, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 42:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.6237, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 42:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5409, batch_acc=0.8438, running_acc=0.8663]Evaluation epoch 42:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.5409, batch_acc=0.8438, running_acc=0.8663]Evaluation epoch 42:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.8945, batch_acc=0.6250, running_acc=0.8536]Evaluation epoch 42:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.8945, batch_acc=0.6250, running_acc=0.8536]Evaluation epoch 42:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.5499, batch_acc=0.7188, running_acc=0.8469]Evaluation epoch 42:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=0.5499, batch_acc=0.7188, running_acc=0.8469]Evaluation epoch 42:  75%|███████▌  | 21/28 [00:28<00:07,  1.02s/it, loss=0.6090, batch_acc=0.8125, running_acc=0.8452]Evaluation epoch 42:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=0.6090, batch_acc=0.8125, running_acc=0.8452]Evaluation epoch 42:  79%|███████▊  | 22/28 [00:28<00:04,  1.26it/s, loss=0.4388, batch_acc=0.9375, running_acc=0.8494]Evaluation epoch 42:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=0.4388, batch_acc=0.9375, running_acc=0.8494]Evaluation epoch 42:  82%|████████▏ | 23/28 [00:28<00:03,  1.58it/s, loss=0.7190, batch_acc=0.7812, running_acc=0.8465]Evaluation epoch 42:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=0.7190, batch_acc=0.7812, running_acc=0.8465]Evaluation epoch 42:  86%|████████▌ | 24/28 [00:33<00:08,  2.04s/it, loss=0.2860, batch_acc=0.9375, running_acc=0.8503]Evaluation epoch 42:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=0.2860, batch_acc=0.9375, running_acc=0.8503]Evaluation epoch 42:  89%|████████▉ | 25/28 [00:34<00:04,  1.50s/it, loss=0.1294, batch_acc=1.0000, running_acc=0.8562]Evaluation epoch 42:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.1294, batch_acc=1.0000, running_acc=0.8562]Evaluation epoch 42:  93%|█████████▎| 26/28 [00:34<00:02,  1.13s/it, loss=0.6891, batch_acc=0.7812, running_acc=0.8534]Evaluation epoch 42:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.6891, batch_acc=0.7812, running_acc=0.8534]Evaluation epoch 42:  96%|█████████▋| 27/28 [00:34<00:00,  1.15it/s, loss=0.7872, batch_acc=0.7500, running_acc=0.8495]Evaluation epoch 42: 100%|██████████| 28/28 [00:34<00:00,  1.15it/s, loss=1.0315, batch_acc=0.6667, running_acc=0.8489]Evaluation epoch 42: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.0315, batch_acc=0.6667, running_acc=0.8489]
Training epoch 43:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 43:   1%|          | 1/163 [00:05<15:44,  5.83s/it]Training epoch 43:   1%|          | 1/163 [00:05<15:44,  5.83s/it, loss=0.0874, batch_acc=1.0000, running_acc=1.0000, grad=8.7569]Training epoch 43:   1%|          | 2/163 [00:06<07:49,  2.92s/it, loss=0.0874, batch_acc=1.0000, running_acc=1.0000, grad=8.7569]Training epoch 43:   1%|          | 2/163 [00:06<07:49,  2.92s/it, loss=0.1240, batch_acc=0.9688, running_acc=0.9844, grad=9.5251]Training epoch 43:   2%|▏         | 3/163 [00:07<05:17,  1.99s/it, loss=0.1240, batch_acc=0.9688, running_acc=0.9844, grad=9.5251]Training epoch 43:   2%|▏         | 3/163 [00:07<05:17,  1.99s/it, loss=0.1079, batch_acc=0.9688, running_acc=0.9792, grad=7.4577]Training epoch 43:   2%|▏         | 4/163 [00:10<06:16,  2.37s/it, loss=0.1079, batch_acc=0.9688, running_acc=0.9792, grad=7.4577]Training epoch 43:   2%|▏         | 4/163 [00:10<06:16,  2.37s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9844, grad=7.8588]Training epoch 43:   3%|▎         | 5/163 [00:11<04:49,  1.83s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9844, grad=7.8588]Training epoch 43:   3%|▎         | 5/163 [00:11<04:49,  1.83s/it, loss=0.1214, batch_acc=1.0000, running_acc=0.9875, grad=10.2997]Training epoch 43:   4%|▎         | 6/163 [00:12<03:56,  1.51s/it, loss=0.1214, batch_acc=1.0000, running_acc=0.9875, grad=10.2997]Training epoch 43:   4%|▎         | 6/163 [00:12<03:56,  1.51s/it, loss=0.1331, batch_acc=0.9688, running_acc=0.9844, grad=7.6620] Training epoch 43:   4%|▍         | 7/163 [00:13<03:22,  1.30s/it, loss=0.1331, batch_acc=0.9688, running_acc=0.9844, grad=7.6620]Training epoch 43:   4%|▍         | 7/163 [00:13<03:22,  1.30s/it, loss=0.0780, batch_acc=0.9688, running_acc=0.9821, grad=5.1492]Training epoch 43:   5%|▍         | 8/163 [00:14<03:43,  1.44s/it, loss=0.0780, batch_acc=0.9688, running_acc=0.9821, grad=5.1492]Training epoch 43:   5%|▍         | 8/163 [00:14<03:43,  1.44s/it, loss=0.1852, batch_acc=0.9375, running_acc=0.9766, grad=16.5321]Training epoch 43:   6%|▌         | 9/163 [00:15<03:14,  1.27s/it, loss=0.1852, batch_acc=0.9375, running_acc=0.9766, grad=16.5321]Training epoch 43:   6%|▌         | 9/163 [00:15<03:14,  1.27s/it, loss=0.1573, batch_acc=0.9688, running_acc=0.9757, grad=8.9574] Training epoch 43:   6%|▌         | 10/163 [00:16<02:55,  1.15s/it, loss=0.1573, batch_acc=0.9688, running_acc=0.9757, grad=8.9574]Training epoch 43:   6%|▌         | 10/163 [00:16<02:55,  1.15s/it, loss=0.1433, batch_acc=0.9688, running_acc=0.9750, grad=21.3082]Training epoch 43:   7%|▋         | 11/163 [00:17<02:46,  1.10s/it, loss=0.1433, batch_acc=0.9688, running_acc=0.9750, grad=21.3082]Training epoch 43:   7%|▋         | 11/163 [00:17<02:46,  1.10s/it, loss=0.0783, batch_acc=1.0000, running_acc=0.9773, grad=4.9531] Training epoch 43:   7%|▋         | 12/163 [00:19<03:29,  1.38s/it, loss=0.0783, batch_acc=1.0000, running_acc=0.9773, grad=4.9531]Training epoch 43:   7%|▋         | 12/163 [00:19<03:29,  1.38s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9792, grad=7.9067]Training epoch 43:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9792, grad=7.9067]Training epoch 43:   8%|▊         | 13/163 [00:20<03:04,  1.23s/it, loss=0.1603, batch_acc=1.0000, running_acc=0.9808, grad=13.9206]Training epoch 43:   9%|▊         | 14/163 [00:21<02:47,  1.13s/it, loss=0.1603, batch_acc=1.0000, running_acc=0.9808, grad=13.9206]Training epoch 43:   9%|▊         | 14/163 [00:21<02:47,  1.13s/it, loss=0.1030, batch_acc=0.9688, running_acc=0.9799, grad=8.6557] Training epoch 43:   9%|▉         | 15/163 [00:22<02:35,  1.05s/it, loss=0.1030, batch_acc=0.9688, running_acc=0.9799, grad=8.6557]Training epoch 43:   9%|▉         | 15/163 [00:22<02:35,  1.05s/it, loss=0.0784, batch_acc=1.0000, running_acc=0.9812, grad=6.2609]Training epoch 43:  10%|▉         | 16/163 [00:23<03:01,  1.23s/it, loss=0.0784, batch_acc=1.0000, running_acc=0.9812, grad=6.2609]Training epoch 43:  10%|▉         | 16/163 [00:23<03:01,  1.23s/it, loss=0.1681, batch_acc=0.9375, running_acc=0.9785, grad=8.2458]Training epoch 43:  10%|█         | 17/163 [00:24<02:44,  1.13s/it, loss=0.1681, batch_acc=0.9375, running_acc=0.9785, grad=8.2458]Training epoch 43:  10%|█         | 17/163 [00:24<02:44,  1.13s/it, loss=0.1294, batch_acc=1.0000, running_acc=0.9798, grad=11.3891]Training epoch 43:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.1294, batch_acc=1.0000, running_acc=0.9798, grad=11.3891]Training epoch 43:  11%|█         | 18/163 [00:25<02:32,  1.05s/it, loss=0.1287, batch_acc=1.0000, running_acc=0.9809, grad=10.1472]Training epoch 43:  12%|█▏        | 19/163 [00:26<02:24,  1.00s/it, loss=0.1287, batch_acc=1.0000, running_acc=0.9809, grad=10.1472]Training epoch 43:  12%|█▏        | 19/163 [00:26<02:24,  1.00s/it, loss=0.1088, batch_acc=0.9688, running_acc=0.9803, grad=11.4498]Training epoch 43:  12%|█▏        | 20/163 [00:28<02:51,  1.20s/it, loss=0.1088, batch_acc=0.9688, running_acc=0.9803, grad=11.4498]Training epoch 43:  12%|█▏        | 20/163 [00:28<02:51,  1.20s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9812, grad=9.8746] Training epoch 43:  13%|█▎        | 21/163 [00:29<02:36,  1.10s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9812, grad=9.8746]Training epoch 43:  13%|█▎        | 21/163 [00:29<02:36,  1.10s/it, loss=0.0736, batch_acc=1.0000, running_acc=0.9821, grad=5.5270]Training epoch 43:  13%|█▎        | 22/163 [00:30<02:25,  1.03s/it, loss=0.0736, batch_acc=1.0000, running_acc=0.9821, grad=5.5270]Training epoch 43:  13%|█▎        | 22/163 [00:30<02:25,  1.03s/it, loss=0.1155, batch_acc=0.9688, running_acc=0.9815, grad=7.9139]Training epoch 43:  14%|█▍        | 23/163 [00:30<02:18,  1.01it/s, loss=0.1155, batch_acc=0.9688, running_acc=0.9815, grad=7.9139]Training epoch 43:  14%|█▍        | 23/163 [00:30<02:18,  1.01it/s, loss=0.1023, batch_acc=0.9688, running_acc=0.9810, grad=7.3823]Training epoch 43:  15%|█▍        | 24/163 [00:32<02:51,  1.23s/it, loss=0.1023, batch_acc=0.9688, running_acc=0.9810, grad=7.3823]Training epoch 43:  15%|█▍        | 24/163 [00:32<02:51,  1.23s/it, loss=0.1042, batch_acc=0.9688, running_acc=0.9805, grad=7.8723]Training epoch 43:  15%|█▌        | 25/163 [00:33<02:35,  1.13s/it, loss=0.1042, batch_acc=0.9688, running_acc=0.9805, grad=7.8723]Training epoch 43:  15%|█▌        | 25/163 [00:33<02:35,  1.13s/it, loss=0.1162, batch_acc=0.9688, running_acc=0.9800, grad=7.0975]Training epoch 43:  16%|█▌        | 26/163 [00:34<02:24,  1.05s/it, loss=0.1162, batch_acc=0.9688, running_acc=0.9800, grad=7.0975]Training epoch 43:  16%|█▌        | 26/163 [00:34<02:24,  1.05s/it, loss=0.1035, batch_acc=0.9688, running_acc=0.9796, grad=8.2886]Training epoch 43:  17%|█▋        | 27/163 [00:35<02:16,  1.00s/it, loss=0.1035, batch_acc=0.9688, running_acc=0.9796, grad=8.2886]Training epoch 43:  17%|█▋        | 27/163 [00:35<02:16,  1.00s/it, loss=0.1336, batch_acc=1.0000, running_acc=0.9803, grad=7.4567]Training epoch 43:  17%|█▋        | 28/163 [00:37<03:12,  1.42s/it, loss=0.1336, batch_acc=1.0000, running_acc=0.9803, grad=7.4567]Training epoch 43:  17%|█▋        | 28/163 [00:37<03:12,  1.42s/it, loss=0.1162, batch_acc=0.9688, running_acc=0.9799, grad=8.8912]Training epoch 43:  18%|█▊        | 29/163 [00:38<02:48,  1.26s/it, loss=0.1162, batch_acc=0.9688, running_acc=0.9799, grad=8.8912]Training epoch 43:  18%|█▊        | 29/163 [00:38<02:48,  1.26s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9806, grad=10.8653]Training epoch 43:  18%|█▊        | 30/163 [00:39<02:32,  1.15s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9806, grad=10.8653]Training epoch 43:  18%|█▊        | 30/163 [00:39<02:32,  1.15s/it, loss=0.0781, batch_acc=1.0000, running_acc=0.9812, grad=8.6223] Training epoch 43:  19%|█▉        | 31/163 [00:40<02:20,  1.07s/it, loss=0.0781, batch_acc=1.0000, running_acc=0.9812, grad=8.6223]Training epoch 43:  19%|█▉        | 31/163 [00:40<02:20,  1.07s/it, loss=0.1706, batch_acc=0.9688, running_acc=0.9808, grad=10.4481]Training epoch 43:  20%|█▉        | 32/163 [00:42<02:50,  1.30s/it, loss=0.1706, batch_acc=0.9688, running_acc=0.9808, grad=10.4481]Training epoch 43:  20%|█▉        | 32/163 [00:42<02:50,  1.30s/it, loss=0.1714, batch_acc=0.9688, running_acc=0.9805, grad=10.6445]Training epoch 43:  20%|██        | 33/163 [00:43<02:32,  1.17s/it, loss=0.1714, batch_acc=0.9688, running_acc=0.9805, grad=10.6445]Training epoch 43:  20%|██        | 33/163 [00:43<02:32,  1.17s/it, loss=0.1157, batch_acc=0.9688, running_acc=0.9801, grad=6.4589] Training epoch 43:  21%|██        | 34/163 [00:44<02:20,  1.09s/it, loss=0.1157, batch_acc=0.9688, running_acc=0.9801, grad=6.4589]Training epoch 43:  21%|██        | 34/163 [00:44<02:20,  1.09s/it, loss=0.1601, batch_acc=0.9688, running_acc=0.9798, grad=21.5025]Training epoch 43:  21%|██▏       | 35/163 [00:44<02:11,  1.02s/it, loss=0.1601, batch_acc=0.9688, running_acc=0.9798, grad=21.5025]Training epoch 43:  21%|██▏       | 35/163 [00:44<02:11,  1.02s/it, loss=0.1516, batch_acc=0.9688, running_acc=0.9795, grad=9.9875] Training epoch 43:  22%|██▏       | 36/163 [00:46<02:25,  1.15s/it, loss=0.1516, batch_acc=0.9688, running_acc=0.9795, grad=9.9875]Training epoch 43:  22%|██▏       | 36/163 [00:46<02:25,  1.15s/it, loss=0.0996, batch_acc=1.0000, running_acc=0.9800, grad=14.9486]Training epoch 43:  23%|██▎       | 37/163 [00:47<02:14,  1.07s/it, loss=0.0996, batch_acc=1.0000, running_acc=0.9800, grad=14.9486]Training epoch 43:  23%|██▎       | 37/163 [00:47<02:14,  1.07s/it, loss=0.1223, batch_acc=0.9375, running_acc=0.9789, grad=13.9373]Training epoch 43:  23%|██▎       | 38/163 [00:48<02:06,  1.01s/it, loss=0.1223, batch_acc=0.9375, running_acc=0.9789, grad=13.9373]Training epoch 43:  23%|██▎       | 38/163 [00:48<02:06,  1.01s/it, loss=0.0778, batch_acc=1.0000, running_acc=0.9794, grad=6.3941] Training epoch 43:  24%|██▍       | 39/163 [00:48<02:00,  1.03it/s, loss=0.0778, batch_acc=1.0000, running_acc=0.9794, grad=6.3941]Training epoch 43:  24%|██▍       | 39/163 [00:48<02:00,  1.03it/s, loss=0.0874, batch_acc=1.0000, running_acc=0.9800, grad=5.1412]Training epoch 43:  25%|██▍       | 40/163 [00:51<02:49,  1.38s/it, loss=0.0874, batch_acc=1.0000, running_acc=0.9800, grad=5.1412]Training epoch 43:  25%|██▍       | 40/163 [00:51<02:49,  1.38s/it, loss=0.0867, batch_acc=0.9688, running_acc=0.9797, grad=5.6928]Training epoch 43:  25%|██▌       | 41/163 [00:52<02:30,  1.23s/it, loss=0.0867, batch_acc=0.9688, running_acc=0.9797, grad=5.6928]Training epoch 43:  25%|██▌       | 41/163 [00:52<02:30,  1.23s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9802, grad=9.4562]Training epoch 43:  26%|██▌       | 42/163 [00:53<02:16,  1.12s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9802, grad=9.4562]Training epoch 43:  26%|██▌       | 42/163 [00:53<02:16,  1.12s/it, loss=0.0768, batch_acc=1.0000, running_acc=0.9807, grad=6.1750]Training epoch 43:  26%|██▋       | 43/163 [00:53<02:06,  1.05s/it, loss=0.0768, batch_acc=1.0000, running_acc=0.9807, grad=6.1750]Training epoch 43:  26%|██▋       | 43/163 [00:53<02:06,  1.05s/it, loss=0.1355, batch_acc=0.9375, running_acc=0.9797, grad=9.9406]Training epoch 43:  27%|██▋       | 44/163 [00:56<02:44,  1.38s/it, loss=0.1355, batch_acc=0.9375, running_acc=0.9797, grad=9.9406]Training epoch 43:  27%|██▋       | 44/163 [00:56<02:44,  1.38s/it, loss=0.0769, batch_acc=1.0000, running_acc=0.9801, grad=6.4209]Training epoch 43:  28%|██▊       | 45/163 [00:56<02:25,  1.23s/it, loss=0.0769, batch_acc=1.0000, running_acc=0.9801, grad=6.4209]Training epoch 43:  28%|██▊       | 45/163 [00:56<02:25,  1.23s/it, loss=0.1271, batch_acc=1.0000, running_acc=0.9806, grad=8.9612]Training epoch 43:  28%|██▊       | 46/163 [00:57<02:11,  1.13s/it, loss=0.1271, batch_acc=1.0000, running_acc=0.9806, grad=8.9612]Training epoch 43:  28%|██▊       | 46/163 [00:57<02:11,  1.13s/it, loss=0.1457, batch_acc=0.9375, running_acc=0.9796, grad=11.3130]Training epoch 43:  29%|██▉       | 47/163 [00:58<02:02,  1.05s/it, loss=0.1457, batch_acc=0.9375, running_acc=0.9796, grad=11.3130]Training epoch 43:  29%|██▉       | 47/163 [00:58<02:02,  1.05s/it, loss=0.1822, batch_acc=0.9062, running_acc=0.9781, grad=8.0088] Training epoch 43:  29%|██▉       | 48/163 [01:00<02:21,  1.23s/it, loss=0.1822, batch_acc=0.9062, running_acc=0.9781, grad=8.0088]Training epoch 43:  29%|██▉       | 48/163 [01:00<02:21,  1.23s/it, loss=0.1132, batch_acc=0.9688, running_acc=0.9779, grad=11.1218]Training epoch 43:  30%|███       | 49/163 [01:01<02:07,  1.12s/it, loss=0.1132, batch_acc=0.9688, running_acc=0.9779, grad=11.1218]Training epoch 43:  30%|███       | 49/163 [01:01<02:07,  1.12s/it, loss=0.1473, batch_acc=0.9688, running_acc=0.9777, grad=7.5709] Training epoch 43:  31%|███       | 50/163 [01:02<01:58,  1.05s/it, loss=0.1473, batch_acc=0.9688, running_acc=0.9777, grad=7.5709]Training epoch 43:  31%|███       | 50/163 [01:02<01:58,  1.05s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9781, grad=8.0040]Training epoch 43:  31%|███▏      | 51/163 [01:03<01:51,  1.00it/s, loss=0.0820, batch_acc=1.0000, running_acc=0.9781, grad=8.0040]Training epoch 43:  31%|███▏      | 51/163 [01:03<01:51,  1.00it/s, loss=0.1000, batch_acc=1.0000, running_acc=0.9786, grad=7.4705]Training epoch 43:  32%|███▏      | 52/163 [01:04<02:16,  1.23s/it, loss=0.1000, batch_acc=1.0000, running_acc=0.9786, grad=7.4705]Training epoch 43:  32%|███▏      | 52/163 [01:04<02:16,  1.23s/it, loss=0.1805, batch_acc=0.9688, running_acc=0.9784, grad=12.3005]Training epoch 43:  33%|███▎      | 53/163 [01:05<02:03,  1.13s/it, loss=0.1805, batch_acc=0.9688, running_acc=0.9784, grad=12.3005]Training epoch 43:  33%|███▎      | 53/163 [01:05<02:03,  1.13s/it, loss=0.1210, batch_acc=1.0000, running_acc=0.9788, grad=10.4658]Training epoch 43:  33%|███▎      | 54/163 [01:06<01:54,  1.05s/it, loss=0.1210, batch_acc=1.0000, running_acc=0.9788, grad=10.4658]Training epoch 43:  33%|███▎      | 54/163 [01:06<01:54,  1.05s/it, loss=0.0828, batch_acc=1.0000, running_acc=0.9792, grad=8.6283] Training epoch 43:  34%|███▎      | 55/163 [01:07<01:47,  1.00it/s, loss=0.0828, batch_acc=1.0000, running_acc=0.9792, grad=8.6283]Training epoch 43:  34%|███▎      | 55/163 [01:07<01:47,  1.00it/s, loss=0.0905, batch_acc=1.0000, running_acc=0.9795, grad=7.8488]Training epoch 43:  34%|███▍      | 56/163 [01:08<01:57,  1.10s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9795, grad=7.8488]Training epoch 43:  34%|███▍      | 56/163 [01:08<01:57,  1.10s/it, loss=0.1251, batch_acc=0.9688, running_acc=0.9794, grad=11.8661]Training epoch 43:  35%|███▍      | 57/163 [01:09<01:49,  1.03s/it, loss=0.1251, batch_acc=0.9688, running_acc=0.9794, grad=11.8661]Training epoch 43:  35%|███▍      | 57/163 [01:09<01:49,  1.03s/it, loss=0.1150, batch_acc=1.0000, running_acc=0.9797, grad=10.6199]Training epoch 43:  36%|███▌      | 58/163 [01:10<01:43,  1.01it/s, loss=0.1150, batch_acc=1.0000, running_acc=0.9797, grad=10.6199]Training epoch 43:  36%|███▌      | 58/163 [01:10<01:43,  1.01it/s, loss=0.1042, batch_acc=0.9688, running_acc=0.9795, grad=7.6100] Training epoch 43:  36%|███▌      | 59/163 [01:11<01:39,  1.05it/s, loss=0.1042, batch_acc=0.9688, running_acc=0.9795, grad=7.6100]Training epoch 43:  36%|███▌      | 59/163 [01:11<01:39,  1.05it/s, loss=0.0847, batch_acc=1.0000, running_acc=0.9799, grad=7.3243]Training epoch 43:  37%|███▋      | 60/163 [01:12<01:47,  1.05s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9799, grad=7.3243]Training epoch 43:  37%|███▋      | 60/163 [01:12<01:47,  1.05s/it, loss=0.0719, batch_acc=1.0000, running_acc=0.9802, grad=6.1882]Training epoch 43:  37%|███▋      | 61/163 [01:13<01:41,  1.00it/s, loss=0.0719, batch_acc=1.0000, running_acc=0.9802, grad=6.1882]Training epoch 43:  37%|███▋      | 61/163 [01:13<01:41,  1.00it/s, loss=0.0953, batch_acc=1.0000, running_acc=0.9805, grad=9.0730]Training epoch 43:  38%|███▊      | 62/163 [01:14<01:37,  1.04it/s, loss=0.0953, batch_acc=1.0000, running_acc=0.9805, grad=9.0730]Training epoch 43:  38%|███▊      | 62/163 [01:14<01:37,  1.04it/s, loss=0.0986, batch_acc=0.9688, running_acc=0.9803, grad=7.6467]Training epoch 43:  39%|███▊      | 63/163 [01:15<01:33,  1.07it/s, loss=0.0986, batch_acc=0.9688, running_acc=0.9803, grad=7.6467]Training epoch 43:  39%|███▊      | 63/163 [01:15<01:33,  1.07it/s, loss=0.1226, batch_acc=0.9688, running_acc=0.9802, grad=7.6733]Training epoch 43:  39%|███▉      | 64/163 [01:17<01:56,  1.18s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9802, grad=7.6733]Training epoch 43:  39%|███▉      | 64/163 [01:17<01:56,  1.18s/it, loss=0.1253, batch_acc=1.0000, running_acc=0.9805, grad=14.7696]Training epoch 43:  40%|███▉      | 65/163 [01:17<01:46,  1.09s/it, loss=0.1253, batch_acc=1.0000, running_acc=0.9805, grad=14.7696]Training epoch 43:  40%|███▉      | 65/163 [01:17<01:46,  1.09s/it, loss=0.0910, batch_acc=1.0000, running_acc=0.9808, grad=8.0122] Training epoch 43:  40%|████      | 66/163 [01:18<01:39,  1.03s/it, loss=0.0910, batch_acc=1.0000, running_acc=0.9808, grad=8.0122]Training epoch 43:  40%|████      | 66/163 [01:18<01:39,  1.03s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9811, grad=7.1457]Training epoch 43:  41%|████      | 67/163 [01:19<01:36,  1.00s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9811, grad=7.1457]Training epoch 43:  41%|████      | 67/163 [01:19<01:36,  1.00s/it, loss=0.1366, batch_acc=1.0000, running_acc=0.9813, grad=14.3593]Training epoch 43:  42%|████▏     | 68/163 [01:21<02:00,  1.27s/it, loss=0.1366, batch_acc=1.0000, running_acc=0.9813, grad=14.3593]Training epoch 43:  42%|████▏     | 68/163 [01:21<02:00,  1.27s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9816, grad=7.1979] Training epoch 43:  42%|████▏     | 69/163 [01:22<01:48,  1.15s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9816, grad=7.1979]Training epoch 43:  42%|████▏     | 69/163 [01:22<01:48,  1.15s/it, loss=0.2023, batch_acc=1.0000, running_acc=0.9819, grad=16.0796]Training epoch 43:  43%|████▎     | 70/163 [01:23<01:39,  1.07s/it, loss=0.2023, batch_acc=1.0000, running_acc=0.9819, grad=16.0796]Training epoch 43:  43%|████▎     | 70/163 [01:23<01:39,  1.07s/it, loss=0.1489, batch_acc=0.9688, running_acc=0.9817, grad=12.7493]Training epoch 43:  44%|████▎     | 71/163 [01:24<01:33,  1.01s/it, loss=0.1489, batch_acc=0.9688, running_acc=0.9817, grad=12.7493]Training epoch 43:  44%|████▎     | 71/163 [01:24<01:33,  1.01s/it, loss=0.0938, batch_acc=1.0000, running_acc=0.9820, grad=7.7489] Training epoch 43:  44%|████▍     | 72/163 [01:26<01:52,  1.23s/it, loss=0.0938, batch_acc=1.0000, running_acc=0.9820, grad=7.7489]Training epoch 43:  44%|████▍     | 72/163 [01:26<01:52,  1.23s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9822, grad=10.5818]Training epoch 43:  45%|████▍     | 73/163 [01:26<01:43,  1.15s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9822, grad=10.5818]Training epoch 43:  45%|████▍     | 73/163 [01:26<01:43,  1.15s/it, loss=0.0933, batch_acc=1.0000, running_acc=0.9824, grad=6.2021] Training epoch 43:  45%|████▌     | 74/163 [01:27<01:35,  1.07s/it, loss=0.0933, batch_acc=1.0000, running_acc=0.9824, grad=6.2021]Training epoch 43:  45%|████▌     | 74/163 [01:27<01:35,  1.07s/it, loss=0.1547, batch_acc=0.9375, running_acc=0.9818, grad=12.9879]Training epoch 43:  46%|████▌     | 75/163 [01:28<01:30,  1.03s/it, loss=0.1547, batch_acc=0.9375, running_acc=0.9818, grad=12.9879]Training epoch 43:  46%|████▌     | 75/163 [01:28<01:30,  1.03s/it, loss=0.0626, batch_acc=1.0000, running_acc=0.9821, grad=6.3307] Training epoch 43:  47%|████▋     | 76/163 [01:29<01:25,  1.02it/s, loss=0.0626, batch_acc=1.0000, running_acc=0.9821, grad=6.3307]Training epoch 43:  47%|████▋     | 76/163 [01:29<01:25,  1.02it/s, loss=0.0648, batch_acc=1.0000, running_acc=0.9823, grad=6.3162]Training epoch 43:  47%|████▋     | 77/163 [01:30<01:26,  1.01s/it, loss=0.0648, batch_acc=1.0000, running_acc=0.9823, grad=6.3162]Training epoch 43:  47%|████▋     | 77/163 [01:30<01:26,  1.01s/it, loss=0.1267, batch_acc=0.9688, running_acc=0.9821, grad=11.9268]Training epoch 43:  48%|████▊     | 78/163 [01:31<01:22,  1.03it/s, loss=0.1267, batch_acc=0.9688, running_acc=0.9821, grad=11.9268]Training epoch 43:  48%|████▊     | 78/163 [01:31<01:22,  1.03it/s, loss=0.0949, batch_acc=1.0000, running_acc=0.9824, grad=8.7450] Training epoch 43:  48%|████▊     | 79/163 [01:32<01:26,  1.02s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9824, grad=8.7450]Training epoch 43:  48%|████▊     | 79/163 [01:32<01:26,  1.02s/it, loss=0.0598, batch_acc=1.0000, running_acc=0.9826, grad=4.2727]Training epoch 43:  49%|████▉     | 80/163 [01:34<01:41,  1.22s/it, loss=0.0598, batch_acc=1.0000, running_acc=0.9826, grad=4.2727]Training epoch 43:  49%|████▉     | 80/163 [01:34<01:41,  1.22s/it, loss=0.0631, batch_acc=1.0000, running_acc=0.9828, grad=4.8511]Training epoch 43:  50%|████▉     | 81/163 [01:35<01:31,  1.12s/it, loss=0.0631, batch_acc=1.0000, running_acc=0.9828, grad=4.8511]Training epoch 43:  50%|████▉     | 81/163 [01:35<01:31,  1.12s/it, loss=0.1266, batch_acc=1.0000, running_acc=0.9830, grad=9.9530]Training epoch 43:  50%|█████     | 82/163 [01:36<01:24,  1.05s/it, loss=0.1266, batch_acc=1.0000, running_acc=0.9830, grad=9.9530]Training epoch 43:  50%|█████     | 82/163 [01:36<01:24,  1.05s/it, loss=0.1437, batch_acc=0.9688, running_acc=0.9829, grad=10.9744]Training epoch 43:  51%|█████     | 83/163 [01:37<01:35,  1.20s/it, loss=0.1437, batch_acc=0.9688, running_acc=0.9829, grad=10.9744]Training epoch 43:  51%|█████     | 83/163 [01:37<01:35,  1.20s/it, loss=0.1299, batch_acc=0.9688, running_acc=0.9827, grad=7.3027] Training epoch 43:  52%|█████▏    | 84/163 [01:38<01:28,  1.12s/it, loss=0.1299, batch_acc=0.9688, running_acc=0.9827, grad=7.3027]Training epoch 43:  52%|█████▏    | 84/163 [01:38<01:28,  1.12s/it, loss=0.0824, batch_acc=1.0000, running_acc=0.9829, grad=6.7634]Training epoch 43:  52%|█████▏    | 85/163 [01:39<01:25,  1.10s/it, loss=0.0824, batch_acc=1.0000, running_acc=0.9829, grad=6.7634]Training epoch 43:  52%|█████▏    | 85/163 [01:39<01:25,  1.10s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9827, grad=8.2484]Training epoch 43:  53%|█████▎    | 86/163 [01:40<01:19,  1.03s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9827, grad=8.2484]Training epoch 43:  53%|█████▎    | 86/163 [01:40<01:19,  1.03s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9829, grad=10.5215]Training epoch 43:  53%|█████▎    | 87/163 [01:41<01:25,  1.12s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9829, grad=10.5215]Training epoch 43:  53%|█████▎    | 87/163 [01:41<01:25,  1.12s/it, loss=0.1292, batch_acc=1.0000, running_acc=0.9831, grad=8.5133] Training epoch 43:  54%|█████▍    | 88/163 [01:42<01:18,  1.05s/it, loss=0.1292, batch_acc=1.0000, running_acc=0.9831, grad=8.5133]Training epoch 43:  54%|█████▍    | 88/163 [01:42<01:18,  1.05s/it, loss=0.1031, batch_acc=1.0000, running_acc=0.9833, grad=9.2571]Training epoch 43:  55%|█████▍    | 89/163 [01:44<01:25,  1.15s/it, loss=0.1031, batch_acc=1.0000, running_acc=0.9833, grad=9.2571]Training epoch 43:  55%|█████▍    | 89/163 [01:44<01:25,  1.15s/it, loss=0.0897, batch_acc=0.9688, running_acc=0.9831, grad=6.9974]Training epoch 43:  55%|█████▌    | 90/163 [01:45<01:18,  1.07s/it, loss=0.0897, batch_acc=0.9688, running_acc=0.9831, grad=6.9974]Training epoch 43:  55%|█████▌    | 90/163 [01:45<01:18,  1.07s/it, loss=0.0756, batch_acc=1.0000, running_acc=0.9833, grad=6.3466]Training epoch 43:  56%|█████▌    | 91/163 [01:46<01:26,  1.20s/it, loss=0.0756, batch_acc=1.0000, running_acc=0.9833, grad=6.3466]Training epoch 43:  56%|█████▌    | 91/163 [01:46<01:26,  1.20s/it, loss=0.0888, batch_acc=1.0000, running_acc=0.9835, grad=10.9087]Training epoch 43:  56%|█████▋    | 92/163 [01:47<01:22,  1.16s/it, loss=0.0888, batch_acc=1.0000, running_acc=0.9835, grad=10.9087]Training epoch 43:  56%|█████▋    | 92/163 [01:47<01:22,  1.16s/it, loss=0.1246, batch_acc=1.0000, running_acc=0.9837, grad=9.8044] Training epoch 43:  57%|█████▋    | 93/163 [01:48<01:21,  1.16s/it, loss=0.1246, batch_acc=1.0000, running_acc=0.9837, grad=9.8044]Training epoch 43:  57%|█████▋    | 93/163 [01:48<01:21,  1.16s/it, loss=0.1144, batch_acc=0.9688, running_acc=0.9835, grad=7.2104]Training epoch 43:  58%|█████▊    | 94/163 [01:49<01:14,  1.08s/it, loss=0.1144, batch_acc=0.9688, running_acc=0.9835, grad=7.2104]Training epoch 43:  58%|█████▊    | 94/163 [01:49<01:14,  1.08s/it, loss=0.1076, batch_acc=0.9688, running_acc=0.9834, grad=8.5854]Training epoch 43:  58%|█████▊    | 95/163 [01:50<01:11,  1.05s/it, loss=0.1076, batch_acc=0.9688, running_acc=0.9834, grad=8.5854]Training epoch 43:  58%|█████▊    | 95/163 [01:50<01:11,  1.05s/it, loss=0.1424, batch_acc=0.9688, running_acc=0.9832, grad=13.6508]Training epoch 43:  59%|█████▉    | 96/163 [01:51<01:11,  1.06s/it, loss=0.1424, batch_acc=0.9688, running_acc=0.9832, grad=13.6508]Training epoch 43:  59%|█████▉    | 96/163 [01:51<01:11,  1.06s/it, loss=0.0847, batch_acc=0.9688, running_acc=0.9831, grad=6.5283] Training epoch 43:  60%|█████▉    | 97/163 [01:53<01:26,  1.32s/it, loss=0.0847, batch_acc=0.9688, running_acc=0.9831, grad=6.5283]Training epoch 43:  60%|█████▉    | 97/163 [01:53<01:26,  1.32s/it, loss=0.1373, batch_acc=0.9688, running_acc=0.9829, grad=11.4864]Training epoch 43:  60%|██████    | 98/163 [01:54<01:16,  1.18s/it, loss=0.1373, batch_acc=0.9688, running_acc=0.9829, grad=11.4864]Training epoch 43:  60%|██████    | 98/163 [01:54<01:16,  1.18s/it, loss=0.1293, batch_acc=0.9688, running_acc=0.9828, grad=9.6939] Training epoch 43:  61%|██████    | 99/163 [01:55<01:09,  1.09s/it, loss=0.1293, batch_acc=0.9688, running_acc=0.9828, grad=9.6939]Training epoch 43:  61%|██████    | 99/163 [01:55<01:09,  1.09s/it, loss=0.0798, batch_acc=1.0000, running_acc=0.9830, grad=7.2069]Training epoch 43:  61%|██████▏   | 100/163 [01:56<01:06,  1.05s/it, loss=0.0798, batch_acc=1.0000, running_acc=0.9830, grad=7.2069]Training epoch 43:  61%|██████▏   | 100/163 [01:56<01:06,  1.05s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9831, grad=9.9049]Training epoch 43:  62%|██████▏   | 101/163 [01:58<01:16,  1.24s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9831, grad=9.9049]Training epoch 43:  62%|██████▏   | 101/163 [01:58<01:16,  1.24s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9833, grad=7.4461]Training epoch 43:  63%|██████▎   | 102/163 [01:58<01:08,  1.13s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9833, grad=7.4461]Training epoch 43:  63%|██████▎   | 102/163 [01:58<01:08,  1.13s/it, loss=0.1213, batch_acc=0.9375, running_acc=0.9828, grad=7.3587]Training epoch 43:  63%|██████▎   | 103/163 [01:59<01:05,  1.08s/it, loss=0.1213, batch_acc=0.9375, running_acc=0.9828, grad=7.3587]Training epoch 43:  63%|██████▎   | 103/163 [01:59<01:05,  1.08s/it, loss=0.1093, batch_acc=0.9688, running_acc=0.9827, grad=7.0278]Training epoch 43:  64%|██████▍   | 104/163 [02:00<01:00,  1.02s/it, loss=0.1093, batch_acc=0.9688, running_acc=0.9827, grad=7.0278]Training epoch 43:  64%|██████▍   | 104/163 [02:00<01:00,  1.02s/it, loss=0.0899, batch_acc=1.0000, running_acc=0.9829, grad=8.5658]Training epoch 43:  64%|██████▍   | 105/163 [02:02<01:11,  1.24s/it, loss=0.0899, batch_acc=1.0000, running_acc=0.9829, grad=8.5658]Training epoch 43:  64%|██████▍   | 105/163 [02:02<01:11,  1.24s/it, loss=0.0717, batch_acc=1.0000, running_acc=0.9830, grad=6.6474]Training epoch 43:  65%|██████▌   | 106/163 [02:03<01:04,  1.13s/it, loss=0.0717, batch_acc=1.0000, running_acc=0.9830, grad=6.6474]Training epoch 43:  65%|██████▌   | 106/163 [02:03<01:04,  1.13s/it, loss=0.1047, batch_acc=0.9688, running_acc=0.9829, grad=8.4791]Training epoch 43:  66%|██████▌   | 107/163 [02:04<00:59,  1.07s/it, loss=0.1047, batch_acc=0.9688, running_acc=0.9829, grad=8.4791]Training epoch 43:  66%|██████▌   | 107/163 [02:04<00:59,  1.07s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9831, grad=5.8387]Training epoch 43:  66%|██████▋   | 108/163 [02:05<00:55,  1.01s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9831, grad=5.8387]Training epoch 43:  66%|██████▋   | 108/163 [02:05<00:55,  1.01s/it, loss=0.0652, batch_acc=1.0000, running_acc=0.9832, grad=4.7035]Training epoch 43:  67%|██████▋   | 109/163 [02:07<01:07,  1.26s/it, loss=0.0652, batch_acc=1.0000, running_acc=0.9832, grad=4.7035]Training epoch 43:  67%|██████▋   | 109/163 [02:07<01:07,  1.26s/it, loss=0.1394, batch_acc=0.9688, running_acc=0.9831, grad=11.6454]Training epoch 43:  67%|██████▋   | 110/163 [02:07<01:00,  1.14s/it, loss=0.1394, batch_acc=0.9688, running_acc=0.9831, grad=11.6454]Training epoch 43:  67%|██████▋   | 110/163 [02:07<01:00,  1.14s/it, loss=0.1307, batch_acc=1.0000, running_acc=0.9832, grad=13.2412]Training epoch 43:  68%|██████▊   | 111/163 [02:08<00:55,  1.07s/it, loss=0.1307, batch_acc=1.0000, running_acc=0.9832, grad=13.2412]Training epoch 43:  68%|██████▊   | 111/163 [02:08<00:55,  1.07s/it, loss=0.0734, batch_acc=1.0000, running_acc=0.9834, grad=5.7829] Training epoch 43:  69%|██████▊   | 112/163 [02:09<00:51,  1.01s/it, loss=0.0734, batch_acc=1.0000, running_acc=0.9834, grad=5.7829]Training epoch 43:  69%|██████▊   | 112/163 [02:09<00:51,  1.01s/it, loss=0.1066, batch_acc=1.0000, running_acc=0.9835, grad=8.8337]Training epoch 43:  69%|██████▉   | 113/163 [02:11<01:05,  1.31s/it, loss=0.1066, batch_acc=1.0000, running_acc=0.9835, grad=8.8337]Training epoch 43:  69%|██████▉   | 113/163 [02:11<01:05,  1.31s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9837, grad=8.8727]Training epoch 43:  70%|██████▉   | 114/163 [02:12<00:57,  1.18s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9837, grad=8.8727]Training epoch 43:  70%|██████▉   | 114/163 [02:12<00:57,  1.18s/it, loss=0.1252, batch_acc=1.0000, running_acc=0.9838, grad=12.2622]Training epoch 43:  71%|███████   | 115/163 [02:13<00:52,  1.09s/it, loss=0.1252, batch_acc=1.0000, running_acc=0.9838, grad=12.2622]Training epoch 43:  71%|███████   | 115/163 [02:13<00:52,  1.09s/it, loss=0.1522, batch_acc=0.9375, running_acc=0.9834, grad=8.5848] Training epoch 43:  71%|███████   | 116/163 [02:14<00:48,  1.03s/it, loss=0.1522, batch_acc=0.9375, running_acc=0.9834, grad=8.5848]Training epoch 43:  71%|███████   | 116/163 [02:14<00:48,  1.03s/it, loss=0.1219, batch_acc=1.0000, running_acc=0.9836, grad=11.5701]Training epoch 43:  72%|███████▏  | 117/163 [02:16<00:59,  1.30s/it, loss=0.1219, batch_acc=1.0000, running_acc=0.9836, grad=11.5701]Training epoch 43:  72%|███████▏  | 117/163 [02:16<00:59,  1.30s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9837, grad=6.9487] Training epoch 43:  72%|███████▏  | 118/163 [02:17<00:52,  1.17s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9837, grad=6.9487]Training epoch 43:  72%|███████▏  | 118/163 [02:17<00:52,  1.17s/it, loss=0.1460, batch_acc=1.0000, running_acc=0.9838, grad=10.8532]Training epoch 43:  73%|███████▎  | 119/163 [02:18<00:47,  1.09s/it, loss=0.1460, batch_acc=1.0000, running_acc=0.9838, grad=10.8532]Training epoch 43:  73%|███████▎  | 119/163 [02:18<00:47,  1.09s/it, loss=0.1371, batch_acc=1.0000, running_acc=0.9840, grad=9.5518] Training epoch 43:  74%|███████▎  | 120/163 [02:18<00:44,  1.02s/it, loss=0.1371, batch_acc=1.0000, running_acc=0.9840, grad=9.5518]Training epoch 43:  74%|███████▎  | 120/163 [02:18<00:44,  1.02s/it, loss=0.0896, batch_acc=0.9688, running_acc=0.9839, grad=6.2762]Training epoch 43:  74%|███████▍  | 121/163 [02:20<00:55,  1.33s/it, loss=0.0896, batch_acc=0.9688, running_acc=0.9839, grad=6.2762]Training epoch 43:  74%|███████▍  | 121/163 [02:20<00:55,  1.33s/it, loss=0.1393, batch_acc=0.9688, running_acc=0.9837, grad=10.7330]Training epoch 43:  75%|███████▍  | 122/163 [02:21<00:48,  1.19s/it, loss=0.1393, batch_acc=0.9688, running_acc=0.9837, grad=10.7330]Training epoch 43:  75%|███████▍  | 122/163 [02:21<00:48,  1.19s/it, loss=0.1346, batch_acc=0.9375, running_acc=0.9834, grad=10.0975]Training epoch 43:  75%|███████▌  | 123/163 [02:22<00:43,  1.10s/it, loss=0.1346, batch_acc=0.9375, running_acc=0.9834, grad=10.0975]Training epoch 43:  75%|███████▌  | 123/163 [02:22<00:43,  1.10s/it, loss=0.0677, batch_acc=1.0000, running_acc=0.9835, grad=5.5013] Training epoch 43:  76%|███████▌  | 124/163 [02:23<00:40,  1.03s/it, loss=0.0677, batch_acc=1.0000, running_acc=0.9835, grad=5.5013]Training epoch 43:  76%|███████▌  | 124/163 [02:23<00:40,  1.03s/it, loss=0.0971, batch_acc=1.0000, running_acc=0.9836, grad=7.4984]Training epoch 43:  77%|███████▋  | 125/163 [02:25<00:50,  1.32s/it, loss=0.0971, batch_acc=1.0000, running_acc=0.9836, grad=7.4984]Training epoch 43:  77%|███████▋  | 125/163 [02:25<00:50,  1.32s/it, loss=0.1036, batch_acc=1.0000, running_acc=0.9838, grad=14.4036]Training epoch 43:  77%|███████▋  | 126/163 [02:26<00:43,  1.18s/it, loss=0.1036, batch_acc=1.0000, running_acc=0.9838, grad=14.4036]Training epoch 43:  77%|███████▋  | 126/163 [02:26<00:43,  1.18s/it, loss=0.0977, batch_acc=0.9688, running_acc=0.9836, grad=6.2435] Training epoch 43:  78%|███████▊  | 127/163 [02:27<00:39,  1.09s/it, loss=0.0977, batch_acc=0.9688, running_acc=0.9836, grad=6.2435]Training epoch 43:  78%|███████▊  | 127/163 [02:27<00:39,  1.09s/it, loss=0.0632, batch_acc=1.0000, running_acc=0.9838, grad=5.4312]Training epoch 43:  79%|███████▊  | 128/163 [02:28<00:36,  1.05s/it, loss=0.0632, batch_acc=1.0000, running_acc=0.9838, grad=5.4312]Training epoch 43:  79%|███████▊  | 128/163 [02:28<00:36,  1.05s/it, loss=0.1006, batch_acc=1.0000, running_acc=0.9839, grad=9.9365]Training epoch 43:  79%|███████▉  | 129/163 [02:30<00:50,  1.48s/it, loss=0.1006, batch_acc=1.0000, running_acc=0.9839, grad=9.9365]Training epoch 43:  79%|███████▉  | 129/163 [02:30<00:50,  1.48s/it, loss=0.0925, batch_acc=0.9688, running_acc=0.9838, grad=6.8872]Training epoch 43:  80%|███████▉  | 130/163 [02:31<00:42,  1.30s/it, loss=0.0925, batch_acc=0.9688, running_acc=0.9838, grad=6.8872]Training epoch 43:  80%|███████▉  | 130/163 [02:31<00:42,  1.30s/it, loss=0.1376, batch_acc=0.9688, running_acc=0.9837, grad=10.3948]Training epoch 43:  80%|████████  | 131/163 [02:32<00:37,  1.18s/it, loss=0.1376, batch_acc=0.9688, running_acc=0.9837, grad=10.3948]Training epoch 43:  80%|████████  | 131/163 [02:32<00:37,  1.18s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9838, grad=9.1409] Training epoch 43:  81%|████████  | 132/163 [02:33<00:33,  1.09s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9838, grad=9.1409]Training epoch 43:  81%|████████  | 132/163 [02:33<00:33,  1.09s/it, loss=0.0898, batch_acc=1.0000, running_acc=0.9839, grad=6.7770]Training epoch 43:  82%|████████▏ | 133/163 [02:34<00:35,  1.20s/it, loss=0.0898, batch_acc=1.0000, running_acc=0.9839, grad=6.7770]Training epoch 43:  82%|████████▏ | 133/163 [02:34<00:35,  1.20s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9840, grad=5.8648]Training epoch 43:  82%|████████▏ | 134/163 [02:35<00:31,  1.10s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9840, grad=5.8648]Training epoch 43:  82%|████████▏ | 134/163 [02:35<00:31,  1.10s/it, loss=0.1365, batch_acc=0.9375, running_acc=0.9837, grad=9.8057]Training epoch 43:  83%|████████▎ | 135/163 [02:36<00:28,  1.03s/it, loss=0.1365, batch_acc=0.9375, running_acc=0.9837, grad=9.8057]Training epoch 43:  83%|████████▎ | 135/163 [02:36<00:28,  1.03s/it, loss=0.1298, batch_acc=1.0000, running_acc=0.9838, grad=9.3273]Training epoch 43:  83%|████████▎ | 136/163 [02:37<00:26,  1.01it/s, loss=0.1298, batch_acc=1.0000, running_acc=0.9838, grad=9.3273]Training epoch 43:  83%|████████▎ | 136/163 [02:37<00:26,  1.01it/s, loss=0.1094, batch_acc=1.0000, running_acc=0.9839, grad=11.5402]Training epoch 43:  84%|████████▍ | 137/163 [02:39<00:35,  1.35s/it, loss=0.1094, batch_acc=1.0000, running_acc=0.9839, grad=11.5402]Training epoch 43:  84%|████████▍ | 137/163 [02:39<00:35,  1.35s/it, loss=0.1209, batch_acc=0.9688, running_acc=0.9838, grad=8.8366] Training epoch 43:  85%|████████▍ | 138/163 [02:40<00:30,  1.21s/it, loss=0.1209, batch_acc=0.9688, running_acc=0.9838, grad=8.8366]Training epoch 43:  85%|████████▍ | 138/163 [02:40<00:30,  1.21s/it, loss=0.1210, batch_acc=0.9688, running_acc=0.9837, grad=8.5443]Training epoch 43:  85%|████████▌ | 139/163 [02:41<00:26,  1.11s/it, loss=0.1210, batch_acc=0.9688, running_acc=0.9837, grad=8.5443]Training epoch 43:  85%|████████▌ | 139/163 [02:41<00:26,  1.11s/it, loss=0.1413, batch_acc=0.9375, running_acc=0.9834, grad=8.1409]Training epoch 43:  86%|████████▌ | 140/163 [02:42<00:23,  1.04s/it, loss=0.1413, batch_acc=0.9375, running_acc=0.9834, grad=8.1409]Training epoch 43:  86%|████████▌ | 140/163 [02:42<00:23,  1.04s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9835, grad=12.2169]Training epoch 43:  87%|████████▋ | 141/163 [02:44<00:29,  1.36s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9835, grad=12.2169]Training epoch 43:  87%|████████▋ | 141/163 [02:44<00:29,  1.36s/it, loss=0.1006, batch_acc=0.9688, running_acc=0.9834, grad=11.3496]Training epoch 43:  87%|████████▋ | 142/163 [02:45<00:25,  1.22s/it, loss=0.1006, batch_acc=0.9688, running_acc=0.9834, grad=11.3496]Training epoch 43:  87%|████████▋ | 142/163 [02:45<00:25,  1.22s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9833, grad=9.0998] Training epoch 43:  88%|████████▊ | 143/163 [02:46<00:22,  1.11s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9833, grad=9.0998]Training epoch 43:  88%|████████▊ | 143/163 [02:46<00:22,  1.11s/it, loss=0.1393, batch_acc=0.9375, running_acc=0.9830, grad=8.9285]Training epoch 43:  88%|████████▊ | 144/163 [02:47<00:19,  1.04s/it, loss=0.1393, batch_acc=0.9375, running_acc=0.9830, grad=8.9285]Training epoch 43:  88%|████████▊ | 144/163 [02:47<00:19,  1.04s/it, loss=0.1005, batch_acc=1.0000, running_acc=0.9831, grad=14.1301]Training epoch 43:  89%|████████▉ | 145/163 [02:48<00:22,  1.27s/it, loss=0.1005, batch_acc=1.0000, running_acc=0.9831, grad=14.1301]Training epoch 43:  89%|████████▉ | 145/163 [02:48<00:22,  1.27s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9830, grad=15.4401]Training epoch 43:  90%|████████▉ | 146/163 [02:49<00:19,  1.15s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9830, grad=15.4401]Training epoch 43:  90%|████████▉ | 146/163 [02:49<00:19,  1.15s/it, loss=0.1029, batch_acc=1.0000, running_acc=0.9831, grad=6.8725] Training epoch 43:  90%|█████████ | 147/163 [02:50<00:17,  1.07s/it, loss=0.1029, batch_acc=1.0000, running_acc=0.9831, grad=6.8725]Training epoch 43:  90%|█████████ | 147/163 [02:50<00:17,  1.07s/it, loss=0.0973, batch_acc=1.0000, running_acc=0.9832, grad=10.9561]Training epoch 43:  91%|█████████ | 148/163 [02:51<00:15,  1.01s/it, loss=0.0973, batch_acc=1.0000, running_acc=0.9832, grad=10.9561]Training epoch 43:  91%|█████████ | 148/163 [02:51<00:15,  1.01s/it, loss=0.1333, batch_acc=1.0000, running_acc=0.9833, grad=10.7660]Training epoch 43:  91%|█████████▏| 149/163 [02:54<00:20,  1.46s/it, loss=0.1333, batch_acc=1.0000, running_acc=0.9833, grad=10.7660]Training epoch 43:  91%|█████████▏| 149/163 [02:54<00:20,  1.46s/it, loss=0.1457, batch_acc=0.9375, running_acc=0.9830, grad=14.9333]Training epoch 43:  92%|█████████▏| 150/163 [02:54<00:16,  1.29s/it, loss=0.1457, batch_acc=0.9375, running_acc=0.9830, grad=14.9333]Training epoch 43:  92%|█████████▏| 150/163 [02:54<00:16,  1.29s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9831, grad=8.0292] Training epoch 43:  93%|█████████▎| 151/163 [02:55<00:13,  1.16s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9831, grad=8.0292]Training epoch 43:  93%|█████████▎| 151/163 [02:55<00:13,  1.16s/it, loss=0.1205, batch_acc=0.9375, running_acc=0.9828, grad=5.7170]Training epoch 43:  93%|█████████▎| 152/163 [02:56<00:11,  1.08s/it, loss=0.1205, batch_acc=0.9375, running_acc=0.9828, grad=5.7170]Training epoch 43:  93%|█████████▎| 152/163 [02:56<00:11,  1.08s/it, loss=0.1108, batch_acc=0.9688, running_acc=0.9827, grad=9.2515]Training epoch 43:  94%|█████████▍| 153/163 [02:58<00:11,  1.20s/it, loss=0.1108, batch_acc=0.9688, running_acc=0.9827, grad=9.2515]Training epoch 43:  94%|█████████▍| 153/163 [02:58<00:11,  1.20s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9826, grad=11.9424]Training epoch 43:  94%|█████████▍| 154/163 [02:59<00:09,  1.10s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9826, grad=11.9424]Training epoch 43:  94%|█████████▍| 154/163 [02:59<00:09,  1.10s/it, loss=0.0913, batch_acc=0.9688, running_acc=0.9825, grad=7.3943] Training epoch 43:  95%|█████████▌| 155/163 [02:59<00:08,  1.04s/it, loss=0.0913, batch_acc=0.9688, running_acc=0.9825, grad=7.3943]Training epoch 43:  95%|█████████▌| 155/163 [02:59<00:08,  1.04s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9823, grad=12.5370]Training epoch 43:  96%|█████████▌| 156/163 [03:00<00:06,  1.01it/s, loss=0.1417, batch_acc=0.9375, running_acc=0.9823, grad=12.5370]Training epoch 43:  96%|█████████▌| 156/163 [03:00<00:06,  1.01it/s, loss=0.1596, batch_acc=0.9688, running_acc=0.9822, grad=17.8345]Training epoch 43:  96%|█████████▋| 157/163 [03:03<00:08,  1.38s/it, loss=0.1596, batch_acc=0.9688, running_acc=0.9822, grad=17.8345]Training epoch 43:  96%|█████████▋| 157/163 [03:03<00:08,  1.38s/it, loss=0.1583, batch_acc=0.9375, running_acc=0.9819, grad=9.3036] Training epoch 43:  97%|█████████▋| 158/163 [03:03<00:06,  1.23s/it, loss=0.1583, batch_acc=0.9375, running_acc=0.9819, grad=9.3036]Training epoch 43:  97%|█████████▋| 158/163 [03:03<00:06,  1.23s/it, loss=0.0638, batch_acc=1.0000, running_acc=0.9820, grad=4.8989]Training epoch 43:  98%|█████████▊| 159/163 [03:04<00:04,  1.13s/it, loss=0.0638, batch_acc=1.0000, running_acc=0.9820, grad=4.8989]Training epoch 43:  98%|█████████▊| 159/163 [03:04<00:04,  1.13s/it, loss=0.1174, batch_acc=1.0000, running_acc=0.9821, grad=14.3655]Training epoch 43:  98%|█████████▊| 160/163 [03:05<00:03,  1.05s/it, loss=0.1174, batch_acc=1.0000, running_acc=0.9821, grad=14.3655]Training epoch 43:  98%|█████████▊| 160/163 [03:05<00:03,  1.05s/it, loss=0.0868, batch_acc=1.0000, running_acc=0.9822, grad=6.4612] Training epoch 43:  99%|█████████▉| 161/163 [03:07<00:02,  1.23s/it, loss=0.0868, batch_acc=1.0000, running_acc=0.9822, grad=6.4612]Training epoch 43:  99%|█████████▉| 161/163 [03:07<00:02,  1.23s/it, loss=0.0718, batch_acc=1.0000, running_acc=0.9823, grad=8.5818]Training epoch 43:  99%|█████████▉| 162/163 [03:08<00:01,  1.12s/it, loss=0.0718, batch_acc=1.0000, running_acc=0.9823, grad=8.5818]Training epoch 43:  99%|█████████▉| 162/163 [03:08<00:01,  1.12s/it, loss=0.1022, batch_acc=1.0000, running_acc=0.9824, grad=18.1804]Training epoch 43: 100%|██████████| 163/163 [03:08<00:00,  1.02it/s, loss=0.1022, batch_acc=1.0000, running_acc=0.9824, grad=18.1804]Training epoch 43: 100%|██████████| 163/163 [03:08<00:00,  1.02it/s, loss=0.1528, batch_acc=1.0000, running_acc=0.9825, grad=10.4916]Training epoch 43: 100%|██████████| 163/163 [03:08<00:00,  1.16s/it, loss=0.1528, batch_acc=1.0000, running_acc=0.9825, grad=10.4916]
Evaluation epoch 43:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 43:   4%|▎         | 1/28 [00:05<02:15,  5.01s/it]Evaluation epoch 43:   4%|▎         | 1/28 [00:05<02:15,  5.01s/it, loss=0.3893, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 43:   7%|▋         | 2/28 [00:05<00:58,  2.25s/it, loss=0.3893, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 43:   7%|▋         | 2/28 [00:05<00:58,  2.25s/it, loss=0.2299, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 43:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.2299, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 43:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.3004, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 43:  14%|█▍        | 4/28 [00:09<01:01,  2.55s/it, loss=0.3004, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 43:  14%|█▍        | 4/28 [00:09<01:01,  2.55s/it, loss=0.4050, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 43:  18%|█▊        | 5/28 [00:10<00:39,  1.72s/it, loss=0.4050, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 43:  18%|█▊        | 5/28 [00:10<00:39,  1.72s/it, loss=1.2521, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 43:  21%|██▏       | 6/28 [00:10<00:26,  1.23s/it, loss=1.2521, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 43:  21%|██▏       | 6/28 [00:10<00:26,  1.23s/it, loss=0.5055, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 43:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.5055, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 43:  25%|██▌       | 7/28 [00:10<00:19,  1.10it/s, loss=0.6480, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 43:  29%|██▊       | 8/28 [00:14<00:33,  1.67s/it, loss=0.6480, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 43:  29%|██▊       | 8/28 [00:14<00:33,  1.67s/it, loss=0.4433, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 43:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=0.4433, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 43:  32%|███▏      | 9/28 [00:14<00:25,  1.35s/it, loss=0.4059, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 43:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.4059, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 43:  36%|███▌      | 10/28 [00:14<00:18,  1.02s/it, loss=0.4436, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 43:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.4436, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 43:  39%|███▉      | 11/28 [00:15<00:13,  1.27it/s, loss=0.3059, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 43:  43%|████▎     | 12/28 [00:20<00:34,  2.18s/it, loss=0.3059, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 43:  43%|████▎     | 12/28 [00:20<00:34,  2.18s/it, loss=0.8988, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 43:  46%|████▋     | 13/28 [00:20<00:23,  1.60s/it, loss=0.8988, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 43:  46%|████▋     | 13/28 [00:20<00:23,  1.60s/it, loss=0.2603, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 43:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=0.2603, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 43:  50%|█████     | 14/28 [00:21<00:16,  1.20s/it, loss=0.8939, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 43:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=0.8939, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 43:  54%|█████▎    | 15/28 [00:21<00:11,  1.09it/s, loss=0.9315, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 43:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=0.9315, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 43:  57%|█████▋    | 16/28 [00:24<00:18,  1.52s/it, loss=0.7787, batch_acc=0.7500, running_acc=0.8730]Evaluation epoch 43:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.7787, batch_acc=0.7500, running_acc=0.8730]Evaluation epoch 43:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.6284, batch_acc=0.7188, running_acc=0.8640]Evaluation epoch 43:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.6284, batch_acc=0.7188, running_acc=0.8640]Evaluation epoch 43:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.5160, batch_acc=0.8750, running_acc=0.8646]Evaluation epoch 43:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=0.5160, batch_acc=0.8750, running_acc=0.8646]Evaluation epoch 43:  68%|██████▊   | 19/28 [00:25<00:06,  1.44it/s, loss=0.8374, batch_acc=0.6562, running_acc=0.8536]Evaluation epoch 43:  71%|███████▏  | 20/28 [00:28<00:11,  1.47s/it, loss=0.8374, batch_acc=0.6562, running_acc=0.8536]Evaluation epoch 43:  71%|███████▏  | 20/28 [00:28<00:11,  1.47s/it, loss=0.5728, batch_acc=0.7188, running_acc=0.8469]Evaluation epoch 43:  75%|███████▌  | 21/28 [00:28<00:07,  1.11s/it, loss=0.5728, batch_acc=0.7188, running_acc=0.8469]Evaluation epoch 43:  75%|███████▌  | 21/28 [00:28<00:07,  1.11s/it, loss=0.5569, batch_acc=0.8125, running_acc=0.8452]Evaluation epoch 43:  79%|███████▊  | 22/28 [00:28<00:05,  1.17it/s, loss=0.5569, batch_acc=0.8125, running_acc=0.8452]Evaluation epoch 43:  79%|███████▊  | 22/28 [00:28<00:05,  1.17it/s, loss=0.4591, batch_acc=0.9062, running_acc=0.8480]Evaluation epoch 43:  82%|████████▏ | 23/28 [00:29<00:03,  1.48it/s, loss=0.4591, batch_acc=0.9062, running_acc=0.8480]Evaluation epoch 43:  82%|████████▏ | 23/28 [00:29<00:03,  1.48it/s, loss=0.7863, batch_acc=0.7812, running_acc=0.8451]Evaluation epoch 43:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.7863, batch_acc=0.7812, running_acc=0.8451]Evaluation epoch 43:  86%|████████▌ | 24/28 [00:34<00:08,  2.06s/it, loss=0.3141, batch_acc=0.9375, running_acc=0.8490]Evaluation epoch 43:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.3141, batch_acc=0.9375, running_acc=0.8490]Evaluation epoch 43:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.1205, batch_acc=1.0000, running_acc=0.8550]Evaluation epoch 43:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.1205, batch_acc=1.0000, running_acc=0.8550]Evaluation epoch 43:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.5526, batch_acc=0.8438, running_acc=0.8546]Evaluation epoch 43:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.5526, batch_acc=0.8438, running_acc=0.8546]Evaluation epoch 43:  96%|█████████▋| 27/28 [00:35<00:00,  1.14it/s, loss=0.8355, batch_acc=0.7500, running_acc=0.8507]Evaluation epoch 43: 100%|██████████| 28/28 [00:35<00:00,  1.14it/s, loss=1.0321, batch_acc=0.6667, running_acc=0.8501]Evaluation epoch 43: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.0321, batch_acc=0.6667, running_acc=0.8501]
Training epoch 44:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 44:   1%|          | 1/163 [00:05<15:31,  5.75s/it]Training epoch 44:   1%|          | 1/163 [00:05<15:31,  5.75s/it, loss=0.0908, batch_acc=1.0000, running_acc=1.0000, grad=5.2264]Training epoch 44:   1%|          | 2/163 [00:06<07:44,  2.89s/it, loss=0.0908, batch_acc=1.0000, running_acc=1.0000, grad=5.2264]Training epoch 44:   1%|          | 2/163 [00:06<07:44,  2.89s/it, loss=0.0753, batch_acc=1.0000, running_acc=1.0000, grad=8.0741]Training epoch 44:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=0.0753, batch_acc=1.0000, running_acc=1.0000, grad=8.0741]Training epoch 44:   2%|▏         | 3/163 [00:07<05:15,  1.97s/it, loss=0.0810, batch_acc=1.0000, running_acc=1.0000, grad=5.9184]Training epoch 44:   2%|▏         | 4/163 [00:10<06:42,  2.53s/it, loss=0.0810, batch_acc=1.0000, running_acc=1.0000, grad=5.9184]Training epoch 44:   2%|▏         | 4/163 [00:10<06:42,  2.53s/it, loss=0.1142, batch_acc=1.0000, running_acc=1.0000, grad=14.2588]Training epoch 44:   3%|▎         | 5/163 [00:11<05:05,  1.93s/it, loss=0.1142, batch_acc=1.0000, running_acc=1.0000, grad=14.2588]Training epoch 44:   3%|▎         | 5/163 [00:11<05:05,  1.93s/it, loss=0.0962, batch_acc=1.0000, running_acc=1.0000, grad=6.5571] Training epoch 44:   4%|▎         | 6/163 [00:12<04:07,  1.58s/it, loss=0.0962, batch_acc=1.0000, running_acc=1.0000, grad=6.5571]Training epoch 44:   4%|▎         | 6/163 [00:12<04:07,  1.58s/it, loss=0.0704, batch_acc=1.0000, running_acc=1.0000, grad=6.4415]Training epoch 44:   4%|▍         | 7/163 [00:13<03:30,  1.35s/it, loss=0.0704, batch_acc=1.0000, running_acc=1.0000, grad=6.4415]Training epoch 44:   4%|▍         | 7/163 [00:13<03:30,  1.35s/it, loss=0.1096, batch_acc=0.9688, running_acc=0.9955, grad=13.0070]Training epoch 44:   5%|▍         | 8/163 [00:15<04:05,  1.58s/it, loss=0.1096, batch_acc=0.9688, running_acc=0.9955, grad=13.0070]Training epoch 44:   5%|▍         | 8/163 [00:15<04:05,  1.58s/it, loss=0.0906, batch_acc=1.0000, running_acc=0.9961, grad=6.9346] Training epoch 44:   6%|▌         | 9/163 [00:16<03:29,  1.36s/it, loss=0.0906, batch_acc=1.0000, running_acc=0.9961, grad=6.9346]Training epoch 44:   6%|▌         | 9/163 [00:16<03:29,  1.36s/it, loss=0.1122, batch_acc=0.9688, running_acc=0.9931, grad=6.4231]Training epoch 44:   6%|▌         | 10/163 [00:17<03:05,  1.21s/it, loss=0.1122, batch_acc=0.9688, running_acc=0.9931, grad=6.4231]Training epoch 44:   6%|▌         | 10/163 [00:17<03:05,  1.21s/it, loss=0.0649, batch_acc=1.0000, running_acc=0.9938, grad=4.3365]Training epoch 44:   7%|▋         | 11/163 [00:18<02:48,  1.11s/it, loss=0.0649, batch_acc=1.0000, running_acc=0.9938, grad=4.3365]Training epoch 44:   7%|▋         | 11/163 [00:18<02:48,  1.11s/it, loss=0.0892, batch_acc=1.0000, running_acc=0.9943, grad=9.7939]Training epoch 44:   7%|▋         | 12/163 [00:19<03:08,  1.25s/it, loss=0.0892, batch_acc=1.0000, running_acc=0.9943, grad=9.7939]Training epoch 44:   7%|▋         | 12/163 [00:19<03:08,  1.25s/it, loss=0.1045, batch_acc=1.0000, running_acc=0.9948, grad=6.3290]Training epoch 44:   8%|▊         | 13/163 [00:20<02:50,  1.14s/it, loss=0.1045, batch_acc=1.0000, running_acc=0.9948, grad=6.3290]Training epoch 44:   8%|▊         | 13/163 [00:20<02:50,  1.14s/it, loss=0.1417, batch_acc=1.0000, running_acc=0.9952, grad=10.0096]Training epoch 44:   9%|▊         | 14/163 [00:21<02:37,  1.06s/it, loss=0.1417, batch_acc=1.0000, running_acc=0.9952, grad=10.0096]Training epoch 44:   9%|▊         | 14/163 [00:21<02:37,  1.06s/it, loss=0.1079, batch_acc=0.9688, running_acc=0.9933, grad=5.0980] Training epoch 44:   9%|▉         | 15/163 [00:22<02:28,  1.00s/it, loss=0.1079, batch_acc=0.9688, running_acc=0.9933, grad=5.0980]Training epoch 44:   9%|▉         | 15/163 [00:22<02:28,  1.00s/it, loss=0.1412, batch_acc=0.9688, running_acc=0.9917, grad=8.6978]Training epoch 44:  10%|▉         | 16/163 [00:23<02:48,  1.15s/it, loss=0.1412, batch_acc=0.9688, running_acc=0.9917, grad=8.6978]Training epoch 44:  10%|▉         | 16/163 [00:23<02:48,  1.15s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9902, grad=8.4984]Training epoch 44:  10%|█         | 17/163 [00:24<02:38,  1.09s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9902, grad=8.4984]Training epoch 44:  10%|█         | 17/163 [00:24<02:38,  1.09s/it, loss=0.1352, batch_acc=0.9688, running_acc=0.9890, grad=13.8534]Training epoch 44:  11%|█         | 18/163 [00:25<02:28,  1.02s/it, loss=0.1352, batch_acc=0.9688, running_acc=0.9890, grad=13.8534]Training epoch 44:  11%|█         | 18/163 [00:25<02:28,  1.02s/it, loss=0.0995, batch_acc=1.0000, running_acc=0.9896, grad=8.2263] Training epoch 44:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.0995, batch_acc=1.0000, running_acc=0.9896, grad=8.2263]Training epoch 44:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.0857, batch_acc=1.0000, running_acc=0.9901, grad=8.2876]Training epoch 44:  12%|█▏        | 20/163 [00:28<03:09,  1.32s/it, loss=0.0857, batch_acc=1.0000, running_acc=0.9901, grad=8.2876]Training epoch 44:  12%|█▏        | 20/163 [00:28<03:09,  1.32s/it, loss=0.0853, batch_acc=1.0000, running_acc=0.9906, grad=6.5295]Training epoch 44:  13%|█▎        | 21/163 [00:29<02:49,  1.19s/it, loss=0.0853, batch_acc=1.0000, running_acc=0.9906, grad=6.5295]Training epoch 44:  13%|█▎        | 21/163 [00:29<02:49,  1.19s/it, loss=0.0530, batch_acc=1.0000, running_acc=0.9911, grad=3.9944]Training epoch 44:  13%|█▎        | 22/163 [00:30<02:34,  1.10s/it, loss=0.0530, batch_acc=1.0000, running_acc=0.9911, grad=3.9944]Training epoch 44:  13%|█▎        | 22/163 [00:30<02:34,  1.10s/it, loss=0.1150, batch_acc=0.9688, running_acc=0.9901, grad=9.0086]Training epoch 44:  14%|█▍        | 23/163 [00:31<02:24,  1.03s/it, loss=0.1150, batch_acc=0.9688, running_acc=0.9901, grad=9.0086]Training epoch 44:  14%|█▍        | 23/163 [00:31<02:24,  1.03s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9891, grad=15.0425]Training epoch 44:  15%|█▍        | 24/163 [00:33<02:57,  1.28s/it, loss=0.1350, batch_acc=0.9688, running_acc=0.9891, grad=15.0425]Training epoch 44:  15%|█▍        | 24/163 [00:33<02:57,  1.28s/it, loss=0.0896, batch_acc=1.0000, running_acc=0.9896, grad=7.2286] Training epoch 44:  15%|█▌        | 25/163 [00:34<02:42,  1.18s/it, loss=0.0896, batch_acc=1.0000, running_acc=0.9896, grad=7.2286]Training epoch 44:  15%|█▌        | 25/163 [00:34<02:42,  1.18s/it, loss=0.0955, batch_acc=1.0000, running_acc=0.9900, grad=10.8584]Training epoch 44:  16%|█▌        | 26/163 [00:35<02:29,  1.09s/it, loss=0.0955, batch_acc=1.0000, running_acc=0.9900, grad=10.8584]Training epoch 44:  16%|█▌        | 26/163 [00:35<02:29,  1.09s/it, loss=0.1202, batch_acc=0.9688, running_acc=0.9892, grad=10.7551]Training epoch 44:  17%|█▋        | 27/163 [00:35<02:19,  1.03s/it, loss=0.1202, batch_acc=0.9688, running_acc=0.9892, grad=10.7551]Training epoch 44:  17%|█▋        | 27/163 [00:35<02:19,  1.03s/it, loss=0.1038, batch_acc=0.9688, running_acc=0.9884, grad=7.3392] Training epoch 44:  17%|█▋        | 28/163 [00:37<02:31,  1.13s/it, loss=0.1038, batch_acc=0.9688, running_acc=0.9884, grad=7.3392]Training epoch 44:  17%|█▋        | 28/163 [00:37<02:31,  1.13s/it, loss=0.0569, batch_acc=1.0000, running_acc=0.9888, grad=6.3345]Training epoch 44:  18%|█▊        | 29/163 [00:38<02:20,  1.05s/it, loss=0.0569, batch_acc=1.0000, running_acc=0.9888, grad=6.3345]Training epoch 44:  18%|█▊        | 29/163 [00:38<02:20,  1.05s/it, loss=0.1195, batch_acc=0.9688, running_acc=0.9881, grad=11.1160]Training epoch 44:  18%|█▊        | 30/163 [00:39<02:12,  1.00it/s, loss=0.1195, batch_acc=0.9688, running_acc=0.9881, grad=11.1160]Training epoch 44:  18%|█▊        | 30/163 [00:39<02:12,  1.00it/s, loss=0.0890, batch_acc=1.0000, running_acc=0.9885, grad=9.3459] Training epoch 44:  19%|█▉        | 31/163 [00:39<02:07,  1.04it/s, loss=0.0890, batch_acc=1.0000, running_acc=0.9885, grad=9.3459]Training epoch 44:  19%|█▉        | 31/163 [00:39<02:07,  1.04it/s, loss=0.1878, batch_acc=0.9688, running_acc=0.9879, grad=15.7068]Training epoch 44:  20%|█▉        | 32/163 [00:41<02:37,  1.20s/it, loss=0.1878, batch_acc=0.9688, running_acc=0.9879, grad=15.7068]Training epoch 44:  20%|█▉        | 32/163 [00:41<02:37,  1.20s/it, loss=0.0808, batch_acc=1.0000, running_acc=0.9883, grad=6.6825] Training epoch 44:  20%|██        | 33/163 [00:42<02:27,  1.13s/it, loss=0.0808, batch_acc=1.0000, running_acc=0.9883, grad=6.6825]Training epoch 44:  20%|██        | 33/163 [00:42<02:27,  1.13s/it, loss=0.1026, batch_acc=1.0000, running_acc=0.9886, grad=6.6072]Training epoch 44:  21%|██        | 34/163 [00:43<02:16,  1.06s/it, loss=0.1026, batch_acc=1.0000, running_acc=0.9886, grad=6.6072]Training epoch 44:  21%|██        | 34/163 [00:43<02:16,  1.06s/it, loss=0.0833, batch_acc=1.0000, running_acc=0.9890, grad=9.2811]Training epoch 44:  21%|██▏       | 35/163 [00:44<02:08,  1.00s/it, loss=0.0833, batch_acc=1.0000, running_acc=0.9890, grad=9.2811]Training epoch 44:  21%|██▏       | 35/163 [00:44<02:08,  1.00s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9893, grad=7.1506]Training epoch 44:  22%|██▏       | 36/163 [00:46<02:50,  1.34s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9893, grad=7.1506]Training epoch 44:  22%|██▏       | 36/163 [00:46<02:50,  1.34s/it, loss=0.1267, batch_acc=1.0000, running_acc=0.9896, grad=11.3225]Training epoch 44:  23%|██▎       | 37/163 [00:47<02:31,  1.20s/it, loss=0.1267, batch_acc=1.0000, running_acc=0.9896, grad=11.3225]Training epoch 44:  23%|██▎       | 37/163 [00:47<02:31,  1.20s/it, loss=0.0806, batch_acc=1.0000, running_acc=0.9899, grad=7.5839] Training epoch 44:  23%|██▎       | 38/163 [00:48<02:18,  1.10s/it, loss=0.0806, batch_acc=1.0000, running_acc=0.9899, grad=7.5839]Training epoch 44:  23%|██▎       | 38/163 [00:48<02:18,  1.10s/it, loss=0.0824, batch_acc=1.0000, running_acc=0.9901, grad=5.9755]Training epoch 44:  24%|██▍       | 39/163 [00:49<02:08,  1.04s/it, loss=0.0824, batch_acc=1.0000, running_acc=0.9901, grad=5.9755]Training epoch 44:  24%|██▍       | 39/163 [00:49<02:08,  1.04s/it, loss=0.1164, batch_acc=1.0000, running_acc=0.9904, grad=8.9040]Training epoch 44:  25%|██▍       | 40/163 [00:51<02:36,  1.27s/it, loss=0.1164, batch_acc=1.0000, running_acc=0.9904, grad=8.9040]Training epoch 44:  25%|██▍       | 40/163 [00:51<02:36,  1.27s/it, loss=0.1601, batch_acc=0.9375, running_acc=0.9891, grad=10.2398]Training epoch 44:  25%|██▌       | 41/163 [00:51<02:20,  1.15s/it, loss=0.1601, batch_acc=0.9375, running_acc=0.9891, grad=10.2398]Training epoch 44:  25%|██▌       | 41/163 [00:51<02:20,  1.15s/it, loss=0.1691, batch_acc=0.9062, running_acc=0.9870, grad=14.2623]Training epoch 44:  26%|██▌       | 42/163 [00:52<02:09,  1.07s/it, loss=0.1691, batch_acc=0.9062, running_acc=0.9870, grad=14.2623]Training epoch 44:  26%|██▌       | 42/163 [00:52<02:09,  1.07s/it, loss=0.1169, batch_acc=0.9688, running_acc=0.9866, grad=10.9876]Training epoch 44:  26%|██▋       | 43/163 [00:53<02:01,  1.01s/it, loss=0.1169, batch_acc=0.9688, running_acc=0.9866, grad=10.9876]Training epoch 44:  26%|██▋       | 43/163 [00:53<02:01,  1.01s/it, loss=0.1086, batch_acc=0.9688, running_acc=0.9862, grad=9.2916] Training epoch 44:  27%|██▋       | 44/163 [00:56<02:58,  1.50s/it, loss=0.1086, batch_acc=0.9688, running_acc=0.9862, grad=9.2916]Training epoch 44:  27%|██▋       | 44/163 [00:56<02:58,  1.50s/it, loss=0.1080, batch_acc=1.0000, running_acc=0.9865, grad=8.3033]Training epoch 44:  28%|██▊       | 45/163 [00:57<02:35,  1.31s/it, loss=0.1080, batch_acc=1.0000, running_acc=0.9865, grad=8.3033]Training epoch 44:  28%|██▊       | 45/163 [00:57<02:35,  1.31s/it, loss=0.0902, batch_acc=0.9688, running_acc=0.9861, grad=5.7355]Training epoch 44:  28%|██▊       | 46/163 [00:58<02:18,  1.18s/it, loss=0.0902, batch_acc=0.9688, running_acc=0.9861, grad=5.7355]Training epoch 44:  28%|██▊       | 46/163 [00:58<02:18,  1.18s/it, loss=0.1113, batch_acc=0.9688, running_acc=0.9857, grad=5.7050]Training epoch 44:  29%|██▉       | 47/163 [00:58<02:06,  1.09s/it, loss=0.1113, batch_acc=0.9688, running_acc=0.9857, grad=5.7050]Training epoch 44:  29%|██▉       | 47/163 [00:58<02:06,  1.09s/it, loss=0.1007, batch_acc=1.0000, running_acc=0.9860, grad=9.9957]Training epoch 44:  29%|██▉       | 48/163 [01:01<02:42,  1.41s/it, loss=0.1007, batch_acc=1.0000, running_acc=0.9860, grad=9.9957]Training epoch 44:  29%|██▉       | 48/163 [01:01<02:42,  1.41s/it, loss=0.1089, batch_acc=1.0000, running_acc=0.9863, grad=11.9190]Training epoch 44:  30%|███       | 49/163 [01:01<02:22,  1.25s/it, loss=0.1089, batch_acc=1.0000, running_acc=0.9863, grad=11.9190]Training epoch 44:  30%|███       | 49/163 [01:01<02:22,  1.25s/it, loss=0.1029, batch_acc=0.9688, running_acc=0.9860, grad=7.7298] Training epoch 44:  31%|███       | 50/163 [01:02<02:08,  1.14s/it, loss=0.1029, batch_acc=0.9688, running_acc=0.9860, grad=7.7298]Training epoch 44:  31%|███       | 50/163 [01:02<02:08,  1.14s/it, loss=0.1706, batch_acc=0.9375, running_acc=0.9850, grad=11.5505]Training epoch 44:  31%|███▏      | 51/163 [01:03<01:59,  1.06s/it, loss=0.1706, batch_acc=0.9375, running_acc=0.9850, grad=11.5505]Training epoch 44:  31%|███▏      | 51/163 [01:03<01:59,  1.06s/it, loss=0.1013, batch_acc=0.9688, running_acc=0.9847, grad=7.3225] Training epoch 44:  32%|███▏      | 52/163 [01:05<02:15,  1.22s/it, loss=0.1013, batch_acc=0.9688, running_acc=0.9847, grad=7.3225]Training epoch 44:  32%|███▏      | 52/163 [01:05<02:15,  1.22s/it, loss=0.1408, batch_acc=0.9688, running_acc=0.9844, grad=7.7283]Training epoch 44:  33%|███▎      | 53/163 [01:06<02:03,  1.12s/it, loss=0.1408, batch_acc=0.9688, running_acc=0.9844, grad=7.7283]Training epoch 44:  33%|███▎      | 53/163 [01:06<02:03,  1.12s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9847, grad=7.3135]Training epoch 44:  33%|███▎      | 54/163 [01:07<01:54,  1.05s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9847, grad=7.3135]Training epoch 44:  33%|███▎      | 54/163 [01:07<01:54,  1.05s/it, loss=0.1012, batch_acc=1.0000, running_acc=0.9850, grad=12.3745]Training epoch 44:  34%|███▎      | 55/163 [01:07<01:47,  1.00it/s, loss=0.1012, batch_acc=1.0000, running_acc=0.9850, grad=12.3745]Training epoch 44:  34%|███▎      | 55/163 [01:07<01:47,  1.00it/s, loss=0.1233, batch_acc=0.9688, running_acc=0.9847, grad=8.7385] Training epoch 44:  34%|███▍      | 56/163 [01:09<01:58,  1.10s/it, loss=0.1233, batch_acc=0.9688, running_acc=0.9847, grad=8.7385]Training epoch 44:  34%|███▍      | 56/163 [01:09<01:58,  1.10s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9844, grad=8.5604]Training epoch 44:  35%|███▍      | 57/163 [01:10<01:49,  1.04s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9844, grad=8.5604]Training epoch 44:  35%|███▍      | 57/163 [01:10<01:49,  1.04s/it, loss=0.0837, batch_acc=1.0000, running_acc=0.9846, grad=5.9055]Training epoch 44:  36%|███▌      | 58/163 [01:11<01:43,  1.01it/s, loss=0.0837, batch_acc=1.0000, running_acc=0.9846, grad=5.9055]Training epoch 44:  36%|███▌      | 58/163 [01:11<01:43,  1.01it/s, loss=0.0695, batch_acc=1.0000, running_acc=0.9849, grad=4.6733]Training epoch 44:  36%|███▌      | 59/163 [01:11<01:39,  1.05it/s, loss=0.0695, batch_acc=1.0000, running_acc=0.9849, grad=4.6733]Training epoch 44:  36%|███▌      | 59/163 [01:11<01:39,  1.05it/s, loss=0.1119, batch_acc=1.0000, running_acc=0.9852, grad=15.8570]Training epoch 44:  37%|███▋      | 60/163 [01:13<02:00,  1.17s/it, loss=0.1119, batch_acc=1.0000, running_acc=0.9852, grad=15.8570]Training epoch 44:  37%|███▋      | 60/163 [01:13<02:00,  1.17s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9854, grad=11.0986]Training epoch 44:  37%|███▋      | 61/163 [01:14<01:50,  1.08s/it, loss=0.1282, batch_acc=1.0000, running_acc=0.9854, grad=11.0986]Training epoch 44:  37%|███▋      | 61/163 [01:14<01:50,  1.08s/it, loss=0.0853, batch_acc=1.0000, running_acc=0.9857, grad=5.9323] Training epoch 44:  38%|███▊      | 62/163 [01:15<01:43,  1.02s/it, loss=0.0853, batch_acc=1.0000, running_acc=0.9857, grad=5.9323]Training epoch 44:  38%|███▊      | 62/163 [01:15<01:43,  1.02s/it, loss=0.1598, batch_acc=0.9688, running_acc=0.9854, grad=10.2222]Training epoch 44:  39%|███▊      | 63/163 [01:16<01:37,  1.02it/s, loss=0.1598, batch_acc=0.9688, running_acc=0.9854, grad=10.2222]Training epoch 44:  39%|███▊      | 63/163 [01:16<01:37,  1.02it/s, loss=0.0969, batch_acc=1.0000, running_acc=0.9856, grad=8.7848] Training epoch 44:  39%|███▉      | 64/163 [01:18<02:00,  1.21s/it, loss=0.0969, batch_acc=1.0000, running_acc=0.9856, grad=8.7848]Training epoch 44:  39%|███▉      | 64/163 [01:18<02:00,  1.21s/it, loss=0.1073, batch_acc=1.0000, running_acc=0.9858, grad=13.1502]Training epoch 44:  40%|███▉      | 65/163 [01:18<01:49,  1.11s/it, loss=0.1073, batch_acc=1.0000, running_acc=0.9858, grad=13.1502]Training epoch 44:  40%|███▉      | 65/163 [01:18<01:49,  1.11s/it, loss=0.1289, batch_acc=0.9375, running_acc=0.9851, grad=8.8129] Training epoch 44:  40%|████      | 66/163 [01:19<01:41,  1.04s/it, loss=0.1289, batch_acc=0.9375, running_acc=0.9851, grad=8.8129]Training epoch 44:  40%|████      | 66/163 [01:19<01:41,  1.04s/it, loss=0.1014, batch_acc=0.9688, running_acc=0.9848, grad=7.6586]Training epoch 44:  41%|████      | 67/163 [01:20<01:35,  1.00it/s, loss=0.1014, batch_acc=0.9688, running_acc=0.9848, grad=7.6586]Training epoch 44:  41%|████      | 67/163 [01:20<01:35,  1.00it/s, loss=0.0739, batch_acc=1.0000, running_acc=0.9851, grad=5.9432]Training epoch 44:  42%|████▏     | 68/163 [01:22<01:50,  1.16s/it, loss=0.0739, batch_acc=1.0000, running_acc=0.9851, grad=5.9432]Training epoch 44:  42%|████▏     | 68/163 [01:22<01:50,  1.16s/it, loss=0.0941, batch_acc=1.0000, running_acc=0.9853, grad=8.4103]Training epoch 44:  42%|████▏     | 69/163 [01:23<01:41,  1.08s/it, loss=0.0941, batch_acc=1.0000, running_acc=0.9853, grad=8.4103]Training epoch 44:  42%|████▏     | 69/163 [01:23<01:41,  1.08s/it, loss=0.1213, batch_acc=0.9375, running_acc=0.9846, grad=10.3075]Training epoch 44:  43%|████▎     | 70/163 [01:23<01:34,  1.02s/it, loss=0.1213, batch_acc=0.9375, running_acc=0.9846, grad=10.3075]Training epoch 44:  43%|████▎     | 70/163 [01:23<01:34,  1.02s/it, loss=0.0921, batch_acc=1.0000, running_acc=0.9848, grad=10.8024]Training epoch 44:  44%|████▎     | 71/163 [01:24<01:29,  1.02it/s, loss=0.0921, batch_acc=1.0000, running_acc=0.9848, grad=10.8024]Training epoch 44:  44%|████▎     | 71/163 [01:24<01:29,  1.02it/s, loss=0.0976, batch_acc=1.0000, running_acc=0.9850, grad=9.4261] Training epoch 44:  44%|████▍     | 72/163 [01:27<02:02,  1.35s/it, loss=0.0976, batch_acc=1.0000, running_acc=0.9850, grad=9.4261]Training epoch 44:  44%|████▍     | 72/163 [01:27<02:02,  1.35s/it, loss=0.1167, batch_acc=0.9688, running_acc=0.9848, grad=11.1716]Training epoch 44:  45%|████▍     | 73/163 [01:27<01:48,  1.21s/it, loss=0.1167, batch_acc=0.9688, running_acc=0.9848, grad=11.1716]Training epoch 44:  45%|████▍     | 73/163 [01:27<01:48,  1.21s/it, loss=0.0991, batch_acc=0.9688, running_acc=0.9846, grad=10.2527]Training epoch 44:  45%|████▌     | 74/163 [01:28<01:38,  1.11s/it, loss=0.0991, batch_acc=0.9688, running_acc=0.9846, grad=10.2527]Training epoch 44:  45%|████▌     | 74/163 [01:28<01:38,  1.11s/it, loss=0.1202, batch_acc=0.9688, running_acc=0.9844, grad=7.8622] Training epoch 44:  46%|████▌     | 75/163 [01:29<01:31,  1.04s/it, loss=0.1202, batch_acc=0.9688, running_acc=0.9844, grad=7.8622]Training epoch 44:  46%|████▌     | 75/163 [01:29<01:31,  1.04s/it, loss=0.1143, batch_acc=1.0000, running_acc=0.9846, grad=11.1667]Training epoch 44:  47%|████▋     | 76/163 [01:31<01:52,  1.30s/it, loss=0.1143, batch_acc=1.0000, running_acc=0.9846, grad=11.1667]Training epoch 44:  47%|████▋     | 76/163 [01:31<01:52,  1.30s/it, loss=0.0990, batch_acc=1.0000, running_acc=0.9848, grad=7.2740] Training epoch 44:  47%|████▋     | 77/163 [01:32<01:40,  1.17s/it, loss=0.0990, batch_acc=1.0000, running_acc=0.9848, grad=7.2740]Training epoch 44:  47%|████▋     | 77/163 [01:32<01:40,  1.17s/it, loss=0.1169, batch_acc=0.9375, running_acc=0.9842, grad=10.8272]Training epoch 44:  48%|████▊     | 78/163 [01:33<01:32,  1.08s/it, loss=0.1169, batch_acc=0.9375, running_acc=0.9842, grad=10.8272]Training epoch 44:  48%|████▊     | 78/163 [01:33<01:32,  1.08s/it, loss=0.0947, batch_acc=1.0000, running_acc=0.9844, grad=7.4621] Training epoch 44:  48%|████▊     | 79/163 [01:34<01:25,  1.02s/it, loss=0.0947, batch_acc=1.0000, running_acc=0.9844, grad=7.4621]Training epoch 44:  48%|████▊     | 79/163 [01:34<01:25,  1.02s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9838, grad=8.2563]Training epoch 44:  49%|████▉     | 80/163 [01:36<01:58,  1.43s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9838, grad=8.2563]Training epoch 44:  49%|████▉     | 80/163 [01:36<01:58,  1.43s/it, loss=0.1363, batch_acc=0.9375, running_acc=0.9832, grad=8.1566]Training epoch 44:  50%|████▉     | 81/163 [01:37<01:43,  1.26s/it, loss=0.1363, batch_acc=0.9375, running_acc=0.9832, grad=8.1566]Training epoch 44:  50%|████▉     | 81/163 [01:37<01:43,  1.26s/it, loss=0.1074, batch_acc=1.0000, running_acc=0.9834, grad=8.7918]Training epoch 44:  50%|█████     | 82/163 [01:38<01:32,  1.15s/it, loss=0.1074, batch_acc=1.0000, running_acc=0.9834, grad=8.7918]Training epoch 44:  50%|█████     | 82/163 [01:38<01:32,  1.15s/it, loss=0.2009, batch_acc=0.9375, running_acc=0.9829, grad=16.6071]Training epoch 44:  51%|█████     | 83/163 [01:39<01:25,  1.07s/it, loss=0.2009, batch_acc=0.9375, running_acc=0.9829, grad=16.6071]Training epoch 44:  51%|█████     | 83/163 [01:39<01:25,  1.07s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9831, grad=7.8934] Training epoch 44:  52%|█████▏    | 84/163 [01:40<01:25,  1.08s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9831, grad=7.8934]Training epoch 44:  52%|█████▏    | 84/163 [01:40<01:25,  1.08s/it, loss=0.1553, batch_acc=0.9375, running_acc=0.9825, grad=12.9640]Training epoch 44:  52%|█████▏    | 85/163 [01:41<01:19,  1.02s/it, loss=0.1553, batch_acc=0.9375, running_acc=0.9825, grad=12.9640]Training epoch 44:  52%|█████▏    | 85/163 [01:41<01:19,  1.02s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9827, grad=7.3694] Training epoch 44:  53%|█████▎    | 86/163 [01:42<01:15,  1.02it/s, loss=0.1016, batch_acc=1.0000, running_acc=0.9827, grad=7.3694]Training epoch 44:  53%|█████▎    | 86/163 [01:42<01:15,  1.02it/s, loss=0.1273, batch_acc=0.9688, running_acc=0.9826, grad=9.3148]Training epoch 44:  53%|█████▎    | 87/163 [01:43<01:12,  1.05it/s, loss=0.1273, batch_acc=0.9688, running_acc=0.9826, grad=9.3148]Training epoch 44:  53%|█████▎    | 87/163 [01:43<01:12,  1.05it/s, loss=0.0952, batch_acc=1.0000, running_acc=0.9828, grad=8.3151]Training epoch 44:  54%|█████▍    | 88/163 [01:44<01:33,  1.24s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9828, grad=8.3151]Training epoch 44:  54%|█████▍    | 88/163 [01:44<01:33,  1.24s/it, loss=0.1395, batch_acc=0.9688, running_acc=0.9826, grad=8.5185]Training epoch 44:  55%|█████▍    | 89/163 [01:45<01:23,  1.13s/it, loss=0.1395, batch_acc=0.9688, running_acc=0.9826, grad=8.5185]Training epoch 44:  55%|█████▍    | 89/163 [01:45<01:23,  1.13s/it, loss=0.1305, batch_acc=0.9688, running_acc=0.9824, grad=10.1293]Training epoch 44:  55%|█████▌    | 90/163 [01:46<01:17,  1.06s/it, loss=0.1305, batch_acc=0.9688, running_acc=0.9824, grad=10.1293]Training epoch 44:  55%|█████▌    | 90/163 [01:46<01:17,  1.06s/it, loss=0.0690, batch_acc=1.0000, running_acc=0.9826, grad=5.9005] Training epoch 44:  56%|█████▌    | 91/163 [01:47<01:12,  1.00s/it, loss=0.0690, batch_acc=1.0000, running_acc=0.9826, grad=5.9005]Training epoch 44:  56%|█████▌    | 91/163 [01:47<01:12,  1.00s/it, loss=0.1270, batch_acc=0.9688, running_acc=0.9825, grad=9.8787]Training epoch 44:  56%|█████▋    | 92/163 [01:49<01:29,  1.26s/it, loss=0.1270, batch_acc=0.9688, running_acc=0.9825, grad=9.8787]Training epoch 44:  56%|█████▋    | 92/163 [01:49<01:29,  1.26s/it, loss=0.0999, batch_acc=0.9688, running_acc=0.9823, grad=8.1844]Training epoch 44:  57%|█████▋    | 93/163 [01:50<01:20,  1.15s/it, loss=0.0999, batch_acc=0.9688, running_acc=0.9823, grad=8.1844]Training epoch 44:  57%|█████▋    | 93/163 [01:50<01:20,  1.15s/it, loss=0.0951, batch_acc=1.0000, running_acc=0.9825, grad=8.2440]Training epoch 44:  58%|█████▊    | 94/163 [01:51<01:13,  1.07s/it, loss=0.0951, batch_acc=1.0000, running_acc=0.9825, grad=8.2440]Training epoch 44:  58%|█████▊    | 94/163 [01:51<01:13,  1.07s/it, loss=0.0630, batch_acc=1.0000, running_acc=0.9827, grad=5.3465]Training epoch 44:  58%|█████▊    | 95/163 [01:52<01:08,  1.01s/it, loss=0.0630, batch_acc=1.0000, running_acc=0.9827, grad=5.3465]Training epoch 44:  58%|█████▊    | 95/163 [01:52<01:08,  1.01s/it, loss=0.0708, batch_acc=1.0000, running_acc=0.9829, grad=7.7617]Training epoch 44:  59%|█████▉    | 96/163 [01:54<01:28,  1.33s/it, loss=0.0708, batch_acc=1.0000, running_acc=0.9829, grad=7.7617]Training epoch 44:  59%|█████▉    | 96/163 [01:54<01:28,  1.33s/it, loss=0.1184, batch_acc=0.9688, running_acc=0.9827, grad=8.8283]Training epoch 44:  60%|█████▉    | 97/163 [01:55<01:18,  1.19s/it, loss=0.1184, batch_acc=0.9688, running_acc=0.9827, grad=8.8283]Training epoch 44:  60%|█████▉    | 97/163 [01:55<01:18,  1.19s/it, loss=0.0595, batch_acc=1.0000, running_acc=0.9829, grad=5.1128]Training epoch 44:  60%|██████    | 98/163 [01:55<01:11,  1.10s/it, loss=0.0595, batch_acc=1.0000, running_acc=0.9829, grad=5.1128]Training epoch 44:  60%|██████    | 98/163 [01:55<01:11,  1.10s/it, loss=0.1562, batch_acc=0.9375, running_acc=0.9825, grad=15.9221]Training epoch 44:  61%|██████    | 99/163 [01:56<01:06,  1.03s/it, loss=0.1562, batch_acc=0.9375, running_acc=0.9825, grad=15.9221]Training epoch 44:  61%|██████    | 99/163 [01:56<01:06,  1.03s/it, loss=0.1138, batch_acc=1.0000, running_acc=0.9826, grad=9.8962] Training epoch 44:  61%|██████▏   | 100/163 [01:58<01:22,  1.31s/it, loss=0.1138, batch_acc=1.0000, running_acc=0.9826, grad=9.8962]Training epoch 44:  61%|██████▏   | 100/163 [01:58<01:22,  1.31s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9825, grad=7.5471]Training epoch 44:  62%|██████▏   | 101/163 [01:59<01:13,  1.18s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9825, grad=7.5471]Training epoch 44:  62%|██████▏   | 101/163 [01:59<01:13,  1.18s/it, loss=0.1322, batch_acc=1.0000, running_acc=0.9827, grad=15.8817]Training epoch 44:  63%|██████▎   | 102/163 [02:00<01:06,  1.09s/it, loss=0.1322, batch_acc=1.0000, running_acc=0.9827, grad=15.8817]Training epoch 44:  63%|██████▎   | 102/163 [02:00<01:06,  1.09s/it, loss=0.1033, batch_acc=0.9688, running_acc=0.9825, grad=10.9414]Training epoch 44:  63%|██████▎   | 103/163 [02:01<01:01,  1.03s/it, loss=0.1033, batch_acc=0.9688, running_acc=0.9825, grad=10.9414]Training epoch 44:  63%|██████▎   | 103/163 [02:01<01:01,  1.03s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9827, grad=5.9696] Training epoch 44:  64%|██████▍   | 104/163 [02:02<01:11,  1.20s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9827, grad=5.9696]Training epoch 44:  64%|██████▍   | 104/163 [02:02<01:11,  1.20s/it, loss=0.0662, batch_acc=1.0000, running_acc=0.9829, grad=6.1268]Training epoch 44:  64%|██████▍   | 105/163 [02:03<01:04,  1.11s/it, loss=0.0662, batch_acc=1.0000, running_acc=0.9829, grad=6.1268]Training epoch 44:  64%|██████▍   | 105/163 [02:03<01:04,  1.11s/it, loss=0.1259, batch_acc=0.9375, running_acc=0.9824, grad=8.6649]Training epoch 44:  65%|██████▌   | 106/163 [02:04<00:59,  1.04s/it, loss=0.1259, batch_acc=0.9375, running_acc=0.9824, grad=8.6649]Training epoch 44:  65%|██████▌   | 106/163 [02:04<00:59,  1.04s/it, loss=0.1130, batch_acc=1.0000, running_acc=0.9826, grad=10.1189]Training epoch 44:  66%|██████▌   | 107/163 [02:05<00:55,  1.01it/s, loss=0.1130, batch_acc=1.0000, running_acc=0.9826, grad=10.1189]Training epoch 44:  66%|██████▌   | 107/163 [02:05<00:55,  1.01it/s, loss=0.0951, batch_acc=1.0000, running_acc=0.9828, grad=9.2080] Training epoch 44:  66%|██████▋   | 108/163 [02:07<01:11,  1.30s/it, loss=0.0951, batch_acc=1.0000, running_acc=0.9828, grad=9.2080]Training epoch 44:  66%|██████▋   | 108/163 [02:07<01:11,  1.30s/it, loss=0.1258, batch_acc=0.9688, running_acc=0.9826, grad=9.7556]Training epoch 44:  67%|██████▋   | 109/163 [02:08<01:03,  1.17s/it, loss=0.1258, batch_acc=0.9688, running_acc=0.9826, grad=9.7556]Training epoch 44:  67%|██████▋   | 109/163 [02:08<01:03,  1.17s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9828, grad=6.3975]Training epoch 44:  67%|██████▋   | 110/163 [02:09<00:57,  1.09s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9828, grad=6.3975]Training epoch 44:  67%|██████▋   | 110/163 [02:09<00:57,  1.09s/it, loss=0.1271, batch_acc=0.9688, running_acc=0.9827, grad=6.6680]Training epoch 44:  68%|██████▊   | 111/163 [02:10<00:53,  1.02s/it, loss=0.1271, batch_acc=0.9688, running_acc=0.9827, grad=6.6680]Training epoch 44:  68%|██████▊   | 111/163 [02:10<00:53,  1.02s/it, loss=0.0911, batch_acc=0.9688, running_acc=0.9825, grad=6.4068]Training epoch 44:  69%|██████▊   | 112/163 [02:11<00:54,  1.06s/it, loss=0.0911, batch_acc=0.9688, running_acc=0.9825, grad=6.4068]Training epoch 44:  69%|██████▊   | 112/163 [02:11<00:54,  1.06s/it, loss=0.1592, batch_acc=0.9688, running_acc=0.9824, grad=10.6375]Training epoch 44:  69%|██████▉   | 113/163 [02:12<00:50,  1.01s/it, loss=0.1592, batch_acc=0.9688, running_acc=0.9824, grad=10.6375]Training epoch 44:  69%|██████▉   | 113/163 [02:12<00:50,  1.01s/it, loss=0.1068, batch_acc=1.0000, running_acc=0.9826, grad=18.6252]Training epoch 44:  70%|██████▉   | 114/163 [02:13<00:47,  1.03it/s, loss=0.1068, batch_acc=1.0000, running_acc=0.9826, grad=18.6252]Training epoch 44:  70%|██████▉   | 114/163 [02:13<00:47,  1.03it/s, loss=0.1051, batch_acc=0.9688, running_acc=0.9825, grad=10.3876]Training epoch 44:  71%|███████   | 115/163 [02:14<00:45,  1.06it/s, loss=0.1051, batch_acc=0.9688, running_acc=0.9825, grad=10.3876]Training epoch 44:  71%|███████   | 115/163 [02:14<00:45,  1.06it/s, loss=0.1172, batch_acc=1.0000, running_acc=0.9826, grad=12.6065]Training epoch 44:  71%|███████   | 116/163 [02:15<00:57,  1.22s/it, loss=0.1172, batch_acc=1.0000, running_acc=0.9826, grad=12.6065]Training epoch 44:  71%|███████   | 116/163 [02:15<00:57,  1.22s/it, loss=0.1362, batch_acc=0.9688, running_acc=0.9825, grad=15.2001]Training epoch 44:  72%|███████▏  | 117/163 [02:16<00:51,  1.12s/it, loss=0.1362, batch_acc=0.9688, running_acc=0.9825, grad=15.2001]Training epoch 44:  72%|███████▏  | 117/163 [02:16<00:51,  1.12s/it, loss=0.1013, batch_acc=1.0000, running_acc=0.9826, grad=9.3213] Training epoch 44:  72%|███████▏  | 118/163 [02:17<00:47,  1.05s/it, loss=0.1013, batch_acc=1.0000, running_acc=0.9826, grad=9.3213]Training epoch 44:  72%|███████▏  | 118/163 [02:17<00:47,  1.05s/it, loss=0.1365, batch_acc=1.0000, running_acc=0.9828, grad=16.7303]Training epoch 44:  73%|███████▎  | 119/163 [02:18<00:43,  1.00it/s, loss=0.1365, batch_acc=1.0000, running_acc=0.9828, grad=16.7303]Training epoch 44:  73%|███████▎  | 119/163 [02:18<00:43,  1.00it/s, loss=0.0779, batch_acc=1.0000, running_acc=0.9829, grad=10.5734]Training epoch 44:  74%|███████▎  | 120/163 [02:20<00:49,  1.15s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9829, grad=10.5734]Training epoch 44:  74%|███████▎  | 120/163 [02:20<00:49,  1.15s/it, loss=0.1145, batch_acc=1.0000, running_acc=0.9831, grad=8.5585] Training epoch 44:  74%|███████▍  | 121/163 [02:20<00:44,  1.07s/it, loss=0.1145, batch_acc=1.0000, running_acc=0.9831, grad=8.5585]Training epoch 44:  74%|███████▍  | 121/163 [02:20<00:44,  1.07s/it, loss=0.1542, batch_acc=0.9688, running_acc=0.9830, grad=9.9226]Training epoch 44:  75%|███████▍  | 122/163 [02:21<00:41,  1.01s/it, loss=0.1542, batch_acc=0.9688, running_acc=0.9830, grad=9.9226]Training epoch 44:  75%|███████▍  | 122/163 [02:21<00:41,  1.01s/it, loss=0.1394, batch_acc=1.0000, running_acc=0.9831, grad=14.6086]Training epoch 44:  75%|███████▌  | 123/163 [02:22<00:38,  1.03it/s, loss=0.1394, batch_acc=1.0000, running_acc=0.9831, grad=14.6086]Training epoch 44:  75%|███████▌  | 123/163 [02:22<00:38,  1.03it/s, loss=0.1188, batch_acc=1.0000, running_acc=0.9832, grad=8.9659] Training epoch 44:  76%|███████▌  | 124/163 [02:24<00:48,  1.24s/it, loss=0.1188, batch_acc=1.0000, running_acc=0.9832, grad=8.9659]Training epoch 44:  76%|███████▌  | 124/163 [02:24<00:48,  1.24s/it, loss=0.1399, batch_acc=0.9688, running_acc=0.9831, grad=10.6641]Training epoch 44:  77%|███████▋  | 125/163 [02:25<00:42,  1.13s/it, loss=0.1399, batch_acc=0.9688, running_acc=0.9831, grad=10.6641]Training epoch 44:  77%|███████▋  | 125/163 [02:25<00:42,  1.13s/it, loss=0.0662, batch_acc=1.0000, running_acc=0.9832, grad=6.0332] Training epoch 44:  77%|███████▋  | 126/163 [02:26<00:38,  1.05s/it, loss=0.0662, batch_acc=1.0000, running_acc=0.9832, grad=6.0332]Training epoch 44:  77%|███████▋  | 126/163 [02:26<00:38,  1.05s/it, loss=0.1140, batch_acc=1.0000, running_acc=0.9834, grad=10.5052]Training epoch 44:  78%|███████▊  | 127/163 [02:27<00:36,  1.00s/it, loss=0.1140, batch_acc=1.0000, running_acc=0.9834, grad=10.5052]Training epoch 44:  78%|███████▊  | 127/163 [02:27<00:36,  1.00s/it, loss=0.0864, batch_acc=1.0000, running_acc=0.9835, grad=7.8215] Training epoch 44:  79%|███████▊  | 128/163 [02:29<00:45,  1.29s/it, loss=0.0864, batch_acc=1.0000, running_acc=0.9835, grad=7.8215]Training epoch 44:  79%|███████▊  | 128/163 [02:29<00:45,  1.29s/it, loss=0.1047, batch_acc=1.0000, running_acc=0.9836, grad=7.7532]Training epoch 44:  79%|███████▉  | 129/163 [02:30<00:39,  1.17s/it, loss=0.1047, batch_acc=1.0000, running_acc=0.9836, grad=7.7532]Training epoch 44:  79%|███████▉  | 129/163 [02:30<00:39,  1.17s/it, loss=0.0692, batch_acc=1.0000, running_acc=0.9838, grad=5.4387]Training epoch 44:  80%|███████▉  | 130/163 [02:30<00:35,  1.08s/it, loss=0.0692, batch_acc=1.0000, running_acc=0.9838, grad=5.4387]Training epoch 44:  80%|███████▉  | 130/163 [02:30<00:35,  1.08s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9839, grad=7.8499]Training epoch 44:  80%|████████  | 131/163 [02:31<00:32,  1.02s/it, loss=0.1323, batch_acc=1.0000, running_acc=0.9839, grad=7.8499]Training epoch 44:  80%|████████  | 131/163 [02:31<00:32,  1.02s/it, loss=0.1456, batch_acc=0.9375, running_acc=0.9835, grad=19.0630]Training epoch 44:  81%|████████  | 132/163 [02:33<00:41,  1.33s/it, loss=0.1456, batch_acc=0.9375, running_acc=0.9835, grad=19.0630]Training epoch 44:  81%|████████  | 132/163 [02:33<00:41,  1.33s/it, loss=0.0993, batch_acc=1.0000, running_acc=0.9837, grad=9.6018] Training epoch 44:  82%|████████▏ | 133/163 [02:34<00:35,  1.20s/it, loss=0.0993, batch_acc=1.0000, running_acc=0.9837, grad=9.6018]Training epoch 44:  82%|████████▏ | 133/163 [02:34<00:35,  1.20s/it, loss=0.1171, batch_acc=1.0000, running_acc=0.9838, grad=8.5018]Training epoch 44:  82%|████████▏ | 134/163 [02:35<00:31,  1.10s/it, loss=0.1171, batch_acc=1.0000, running_acc=0.9838, grad=8.5018]Training epoch 44:  82%|████████▏ | 134/163 [02:35<00:31,  1.10s/it, loss=0.1721, batch_acc=0.9375, running_acc=0.9834, grad=11.5639]Training epoch 44:  83%|████████▎ | 135/163 [02:36<00:28,  1.03s/it, loss=0.1721, batch_acc=0.9375, running_acc=0.9834, grad=11.5639]Training epoch 44:  83%|████████▎ | 135/163 [02:36<00:28,  1.03s/it, loss=0.1570, batch_acc=1.0000, running_acc=0.9836, grad=11.2021]Training epoch 44:  83%|████████▎ | 136/163 [02:37<00:31,  1.15s/it, loss=0.1570, batch_acc=1.0000, running_acc=0.9836, grad=11.2021]Training epoch 44:  83%|████████▎ | 136/163 [02:37<00:31,  1.15s/it, loss=0.0735, batch_acc=1.0000, running_acc=0.9837, grad=7.3679] Training epoch 44:  84%|████████▍ | 137/163 [02:38<00:27,  1.07s/it, loss=0.0735, batch_acc=1.0000, running_acc=0.9837, grad=7.3679]Training epoch 44:  84%|████████▍ | 137/163 [02:38<00:27,  1.07s/it, loss=0.0610, batch_acc=1.0000, running_acc=0.9838, grad=5.0194]Training epoch 44:  85%|████████▍ | 138/163 [02:39<00:25,  1.01s/it, loss=0.0610, batch_acc=1.0000, running_acc=0.9838, grad=5.0194]Training epoch 44:  85%|████████▍ | 138/163 [02:39<00:25,  1.01s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9839, grad=9.8212]Training epoch 44:  85%|████████▌ | 139/163 [02:40<00:23,  1.03it/s, loss=0.0890, batch_acc=1.0000, running_acc=0.9839, grad=9.8212]Training epoch 44:  85%|████████▌ | 139/163 [02:40<00:23,  1.03it/s, loss=0.1283, batch_acc=0.9688, running_acc=0.9838, grad=15.0792]Training epoch 44:  86%|████████▌ | 140/163 [02:42<00:25,  1.13s/it, loss=0.1283, batch_acc=0.9688, running_acc=0.9838, grad=15.0792]Training epoch 44:  86%|████████▌ | 140/163 [02:42<00:25,  1.13s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9839, grad=5.8601] Training epoch 44:  87%|████████▋ | 141/163 [02:42<00:23,  1.05s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9839, grad=5.8601]Training epoch 44:  87%|████████▋ | 141/163 [02:42<00:23,  1.05s/it, loss=0.1260, batch_acc=0.9688, running_acc=0.9838, grad=8.9819]Training epoch 44:  87%|████████▋ | 142/163 [02:43<00:21,  1.00s/it, loss=0.1260, batch_acc=0.9688, running_acc=0.9838, grad=8.9819]Training epoch 44:  87%|████████▋ | 142/163 [02:43<00:21,  1.00s/it, loss=0.1200, batch_acc=1.0000, running_acc=0.9839, grad=9.4210]Training epoch 44:  88%|████████▊ | 143/163 [02:44<00:19,  1.04it/s, loss=0.1200, batch_acc=1.0000, running_acc=0.9839, grad=9.4210]Training epoch 44:  88%|████████▊ | 143/163 [02:44<00:19,  1.04it/s, loss=0.0977, batch_acc=0.9688, running_acc=0.9838, grad=7.8291]Training epoch 44:  88%|████████▊ | 144/163 [02:46<00:23,  1.22s/it, loss=0.0977, batch_acc=0.9688, running_acc=0.9838, grad=7.8291]Training epoch 44:  88%|████████▊ | 144/163 [02:46<00:23,  1.22s/it, loss=0.1208, batch_acc=1.0000, running_acc=0.9839, grad=14.6993]Training epoch 44:  89%|████████▉ | 145/163 [02:47<00:20,  1.12s/it, loss=0.1208, batch_acc=1.0000, running_acc=0.9839, grad=14.6993]Training epoch 44:  89%|████████▉ | 145/163 [02:47<00:20,  1.12s/it, loss=0.0837, batch_acc=1.0000, running_acc=0.9841, grad=5.9023] Training epoch 44:  90%|████████▉ | 146/163 [02:48<00:17,  1.05s/it, loss=0.0837, batch_acc=1.0000, running_acc=0.9841, grad=5.9023]Training epoch 44:  90%|████████▉ | 146/163 [02:48<00:17,  1.05s/it, loss=0.1376, batch_acc=0.9688, running_acc=0.9839, grad=10.5949]Training epoch 44:  90%|█████████ | 147/163 [02:49<00:15,  1.00it/s, loss=0.1376, batch_acc=0.9688, running_acc=0.9839, grad=10.5949]Training epoch 44:  90%|█████████ | 147/163 [02:49<00:15,  1.00it/s, loss=0.0969, batch_acc=0.9688, running_acc=0.9838, grad=7.6238] Training epoch 44:  91%|█████████ | 148/163 [02:50<00:17,  1.14s/it, loss=0.0969, batch_acc=0.9688, running_acc=0.9838, grad=7.6238]Training epoch 44:  91%|█████████ | 148/163 [02:50<00:17,  1.14s/it, loss=0.0976, batch_acc=1.0000, running_acc=0.9840, grad=7.5277]Training epoch 44:  91%|█████████▏| 149/163 [02:51<00:14,  1.06s/it, loss=0.0976, batch_acc=1.0000, running_acc=0.9840, grad=7.5277]Training epoch 44:  91%|█████████▏| 149/163 [02:51<00:14,  1.06s/it, loss=0.0955, batch_acc=1.0000, running_acc=0.9841, grad=8.9230]Training epoch 44:  92%|█████████▏| 150/163 [02:52<00:13,  1.01s/it, loss=0.0955, batch_acc=1.0000, running_acc=0.9841, grad=8.9230]Training epoch 44:  92%|█████████▏| 150/163 [02:52<00:13,  1.01s/it, loss=0.1140, batch_acc=0.9688, running_acc=0.9840, grad=8.9739]Training epoch 44:  93%|█████████▎| 151/163 [02:53<00:11,  1.03it/s, loss=0.1140, batch_acc=0.9688, running_acc=0.9840, grad=8.9739]Training epoch 44:  93%|█████████▎| 151/163 [02:53<00:11,  1.03it/s, loss=0.0742, batch_acc=1.0000, running_acc=0.9841, grad=9.2625]Training epoch 44:  93%|█████████▎| 152/163 [02:54<00:11,  1.06s/it, loss=0.0742, batch_acc=1.0000, running_acc=0.9841, grad=9.2625]Training epoch 44:  93%|█████████▎| 152/163 [02:54<00:11,  1.06s/it, loss=0.1248, batch_acc=0.9688, running_acc=0.9840, grad=13.4438]Training epoch 44:  94%|█████████▍| 153/163 [02:55<00:10,  1.01s/it, loss=0.1248, batch_acc=0.9688, running_acc=0.9840, grad=13.4438]Training epoch 44:  94%|█████████▍| 153/163 [02:55<00:10,  1.01s/it, loss=0.0906, batch_acc=1.0000, running_acc=0.9841, grad=8.8622] Training epoch 44:  94%|█████████▍| 154/163 [02:56<00:08,  1.03it/s, loss=0.0906, batch_acc=1.0000, running_acc=0.9841, grad=8.8622]Training epoch 44:  94%|█████████▍| 154/163 [02:56<00:08,  1.03it/s, loss=0.0951, batch_acc=1.0000, running_acc=0.9842, grad=7.9188]Training epoch 44:  95%|█████████▌| 155/163 [02:57<00:07,  1.06it/s, loss=0.0951, batch_acc=1.0000, running_acc=0.9842, grad=7.9188]Training epoch 44:  95%|█████████▌| 155/163 [02:57<00:07,  1.06it/s, loss=0.0928, batch_acc=0.9688, running_acc=0.9841, grad=6.7977]Training epoch 44:  96%|█████████▌| 156/163 [02:58<00:07,  1.05s/it, loss=0.0928, batch_acc=0.9688, running_acc=0.9841, grad=6.7977]Training epoch 44:  96%|█████████▌| 156/163 [02:58<00:07,  1.05s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9840, grad=8.5172]Training epoch 44:  96%|█████████▋| 157/163 [02:59<00:06,  1.03s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9840, grad=8.5172]Training epoch 44:  96%|█████████▋| 157/163 [02:59<00:06,  1.03s/it, loss=0.1345, batch_acc=0.9688, running_acc=0.9839, grad=9.6426]Training epoch 44:  97%|█████████▋| 158/163 [03:00<00:04,  1.01it/s, loss=0.1345, batch_acc=0.9688, running_acc=0.9839, grad=9.6426]Training epoch 44:  97%|█████████▋| 158/163 [03:00<00:04,  1.01it/s, loss=0.1536, batch_acc=0.9375, running_acc=0.9836, grad=9.1466]Training epoch 44:  98%|█████████▊| 159/163 [03:01<00:03,  1.05it/s, loss=0.1536, batch_acc=0.9375, running_acc=0.9836, grad=9.1466]Training epoch 44:  98%|█████████▊| 159/163 [03:01<00:03,  1.05it/s, loss=0.1059, batch_acc=1.0000, running_acc=0.9837, grad=10.3346]Training epoch 44:  98%|█████████▊| 160/163 [03:02<00:03,  1.11s/it, loss=0.1059, batch_acc=1.0000, running_acc=0.9837, grad=10.3346]Training epoch 44:  98%|█████████▊| 160/163 [03:02<00:03,  1.11s/it, loss=0.1840, batch_acc=0.9688, running_acc=0.9836, grad=9.7876] Training epoch 44:  99%|█████████▉| 161/163 [03:04<00:02,  1.26s/it, loss=0.1840, batch_acc=0.9688, running_acc=0.9836, grad=9.7876]Training epoch 44:  99%|█████████▉| 161/163 [03:04<00:02,  1.26s/it, loss=0.0966, batch_acc=1.0000, running_acc=0.9837, grad=8.3151]Training epoch 44:  99%|█████████▉| 162/163 [03:05<00:01,  1.15s/it, loss=0.0966, batch_acc=1.0000, running_acc=0.9837, grad=8.3151]Training epoch 44:  99%|█████████▉| 162/163 [03:05<00:01,  1.15s/it, loss=0.1342, batch_acc=0.9375, running_acc=0.9834, grad=13.1540]Training epoch 44: 100%|██████████| 163/163 [03:05<00:00,  1.01it/s, loss=0.1342, batch_acc=0.9375, running_acc=0.9834, grad=13.1540]Training epoch 44: 100%|██████████| 163/163 [03:05<00:00,  1.01it/s, loss=0.1278, batch_acc=1.0000, running_acc=0.9835, grad=10.0414]Training epoch 44: 100%|██████████| 163/163 [03:05<00:00,  1.14s/it, loss=0.1278, batch_acc=1.0000, running_acc=0.9835, grad=10.0414]
Evaluation epoch 44:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 44:   4%|▎         | 1/28 [00:04<02:07,  4.71s/it]Evaluation epoch 44:   4%|▎         | 1/28 [00:04<02:07,  4.71s/it, loss=0.3887, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 44:   7%|▋         | 2/28 [00:05<00:55,  2.13s/it, loss=0.3887, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 44:   7%|▋         | 2/28 [00:05<00:55,  2.13s/it, loss=0.2219, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 44:  11%|█         | 3/28 [00:05<00:31,  1.27s/it, loss=0.2219, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 44:  11%|█         | 3/28 [00:05<00:31,  1.27s/it, loss=0.2990, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 44:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.2990, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 44:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.4111, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 44:  18%|█▊        | 5/28 [00:09<00:38,  1.68s/it, loss=0.4111, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 44:  18%|█▊        | 5/28 [00:09<00:38,  1.68s/it, loss=1.3554, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 44:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.3554, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 44:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.5341, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 44:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.5341, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 44:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.6299, batch_acc=0.9062, running_acc=0.8973]Evaluation epoch 44:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.6299, batch_acc=0.9062, running_acc=0.8973]Evaluation epoch 44:  29%|██▊       | 8/28 [00:13<00:33,  1.68s/it, loss=0.3998, batch_acc=0.8438, running_acc=0.8906]Evaluation epoch 44:  32%|███▏      | 9/28 [00:14<00:28,  1.47s/it, loss=0.3998, batch_acc=0.8438, running_acc=0.8906]Evaluation epoch 44:  32%|███▏      | 9/28 [00:14<00:28,  1.47s/it, loss=0.4022, batch_acc=0.9062, running_acc=0.8924]Evaluation epoch 44:  36%|███▌      | 10/28 [00:15<00:19,  1.10s/it, loss=0.4022, batch_acc=0.9062, running_acc=0.8924]Evaluation epoch 44:  36%|███▌      | 10/28 [00:15<00:19,  1.10s/it, loss=0.4383, batch_acc=0.9375, running_acc=0.8969]Evaluation epoch 44:  39%|███▉      | 11/28 [00:15<00:14,  1.18it/s, loss=0.4383, batch_acc=0.9375, running_acc=0.8969]Evaluation epoch 44:  39%|███▉      | 11/28 [00:15<00:14,  1.18it/s, loss=0.2920, batch_acc=0.9688, running_acc=0.9034]Evaluation epoch 44:  43%|████▎     | 12/28 [00:20<00:33,  2.10s/it, loss=0.2920, batch_acc=0.9688, running_acc=0.9034]Evaluation epoch 44:  43%|████▎     | 12/28 [00:20<00:33,  2.10s/it, loss=0.8576, batch_acc=0.7812, running_acc=0.8932]Evaluation epoch 44:  46%|████▋     | 13/28 [00:20<00:23,  1.55s/it, loss=0.8576, batch_acc=0.7812, running_acc=0.8932]Evaluation epoch 44:  46%|████▋     | 13/28 [00:20<00:23,  1.55s/it, loss=0.2762, batch_acc=0.9375, running_acc=0.8966]Evaluation epoch 44:  50%|█████     | 14/28 [00:20<00:16,  1.16s/it, loss=0.2762, batch_acc=0.9375, running_acc=0.8966]Evaluation epoch 44:  50%|█████     | 14/28 [00:20<00:16,  1.16s/it, loss=0.8614, batch_acc=0.7500, running_acc=0.8862]Evaluation epoch 44:  54%|█████▎    | 15/28 [00:21<00:11,  1.13it/s, loss=0.8614, batch_acc=0.7500, running_acc=0.8862]Evaluation epoch 44:  54%|█████▎    | 15/28 [00:21<00:11,  1.13it/s, loss=0.9184, batch_acc=0.8438, running_acc=0.8833]Evaluation epoch 44:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=0.9184, batch_acc=0.8438, running_acc=0.8833]Evaluation epoch 44:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=0.8332, batch_acc=0.7812, running_acc=0.8770]Evaluation epoch 44:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.8332, batch_acc=0.7812, running_acc=0.8770]Evaluation epoch 44:  61%|██████    | 17/28 [00:24<00:12,  1.14s/it, loss=0.6638, batch_acc=0.7500, running_acc=0.8695]Evaluation epoch 44:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.6638, batch_acc=0.7500, running_acc=0.8695]Evaluation epoch 44:  64%|██████▍   | 18/28 [00:24<00:08,  1.14it/s, loss=0.5436, batch_acc=0.8438, running_acc=0.8681]Evaluation epoch 44:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.5436, batch_acc=0.8438, running_acc=0.8681]Evaluation epoch 44:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.8711, batch_acc=0.6562, running_acc=0.8569]Evaluation epoch 44:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=0.8711, batch_acc=0.6562, running_acc=0.8569]Evaluation epoch 44:  71%|███████▏  | 20/28 [00:27<00:10,  1.37s/it, loss=0.5397, batch_acc=0.7188, running_acc=0.8500]Evaluation epoch 44:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.5397, batch_acc=0.7188, running_acc=0.8500]Evaluation epoch 44:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.5306, batch_acc=0.8438, running_acc=0.8497]Evaluation epoch 44:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.5306, batch_acc=0.8438, running_acc=0.8497]Evaluation epoch 44:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.4064, batch_acc=0.9688, running_acc=0.8551]Evaluation epoch 44:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=0.4064, batch_acc=0.9688, running_acc=0.8551]Evaluation epoch 44:  82%|████████▏ | 23/28 [00:28<00:03,  1.56it/s, loss=0.8523, batch_acc=0.7500, running_acc=0.8505]Evaluation epoch 44:  86%|████████▌ | 24/28 [00:33<00:08,  2.06s/it, loss=0.8523, batch_acc=0.7500, running_acc=0.8505]Evaluation epoch 44:  86%|████████▌ | 24/28 [00:33<00:08,  2.06s/it, loss=0.2947, batch_acc=0.9375, running_acc=0.8542]Evaluation epoch 44:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.2947, batch_acc=0.9375, running_acc=0.8542]Evaluation epoch 44:  89%|████████▉ | 25/28 [00:34<00:04,  1.52s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.8600]Evaluation epoch 44:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.1242, batch_acc=1.0000, running_acc=0.8600]Evaluation epoch 44:  93%|█████████▎| 26/28 [00:34<00:02,  1.14s/it, loss=0.5175, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 44:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.5175, batch_acc=0.8438, running_acc=0.8594]Evaluation epoch 44:  96%|█████████▋| 27/28 [00:34<00:00,  1.14it/s, loss=0.8234, batch_acc=0.7812, running_acc=0.8565]Evaluation epoch 44: 100%|██████████| 28/28 [00:34<00:00,  1.14it/s, loss=1.1405, batch_acc=0.6667, running_acc=0.8558]Evaluation epoch 44: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.1405, batch_acc=0.6667, running_acc=0.8558]
Training epoch 45:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 45:   1%|          | 1/163 [00:06<17:21,  6.43s/it]Training epoch 45:   1%|          | 1/163 [00:06<17:21,  6.43s/it, loss=0.0657, batch_acc=1.0000, running_acc=1.0000, grad=5.8635]Training epoch 45:   1%|          | 2/163 [00:07<08:29,  3.16s/it, loss=0.0657, batch_acc=1.0000, running_acc=1.0000, grad=5.8635]Training epoch 45:   1%|          | 2/163 [00:07<08:29,  3.16s/it, loss=0.0972, batch_acc=1.0000, running_acc=1.0000, grad=8.0296]Training epoch 45:   2%|▏         | 3/163 [00:08<05:39,  2.12s/it, loss=0.0972, batch_acc=1.0000, running_acc=1.0000, grad=8.0296]Training epoch 45:   2%|▏         | 3/163 [00:08<05:39,  2.12s/it, loss=0.2087, batch_acc=0.9375, running_acc=0.9792, grad=18.5604]Training epoch 45:   2%|▏         | 4/163 [00:10<05:55,  2.23s/it, loss=0.2087, batch_acc=0.9375, running_acc=0.9792, grad=18.5604]Training epoch 45:   2%|▏         | 4/163 [00:10<05:55,  2.23s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9688, grad=11.2140]Training epoch 45:   3%|▎         | 5/163 [00:11<04:35,  1.74s/it, loss=0.1417, batch_acc=0.9375, running_acc=0.9688, grad=11.2140]Training epoch 45:   3%|▎         | 5/163 [00:11<04:35,  1.74s/it, loss=0.0897, batch_acc=0.9688, running_acc=0.9688, grad=6.2942] Training epoch 45:   4%|▎         | 6/163 [00:12<03:47,  1.45s/it, loss=0.0897, batch_acc=0.9688, running_acc=0.9688, grad=6.2942]Training epoch 45:   4%|▎         | 6/163 [00:12<03:47,  1.45s/it, loss=0.0935, batch_acc=0.9688, running_acc=0.9688, grad=7.8293]Training epoch 45:   4%|▍         | 7/163 [00:13<03:17,  1.26s/it, loss=0.0935, batch_acc=0.9688, running_acc=0.9688, grad=7.8293]Training epoch 45:   4%|▍         | 7/163 [00:13<03:17,  1.26s/it, loss=0.0942, batch_acc=0.9688, running_acc=0.9688, grad=7.4413]Training epoch 45:   5%|▍         | 8/163 [00:15<04:08,  1.60s/it, loss=0.0942, batch_acc=0.9688, running_acc=0.9688, grad=7.4413]Training epoch 45:   5%|▍         | 8/163 [00:15<04:08,  1.60s/it, loss=0.1577, batch_acc=0.9062, running_acc=0.9609, grad=15.0145]Training epoch 45:   6%|▌         | 9/163 [00:16<03:31,  1.38s/it, loss=0.1577, batch_acc=0.9062, running_acc=0.9609, grad=15.0145]Training epoch 45:   6%|▌         | 9/163 [00:16<03:31,  1.38s/it, loss=0.1007, batch_acc=1.0000, running_acc=0.9653, grad=10.3651]Training epoch 45:   6%|▌         | 10/163 [00:17<03:06,  1.22s/it, loss=0.1007, batch_acc=1.0000, running_acc=0.9653, grad=10.3651]Training epoch 45:   6%|▌         | 10/163 [00:17<03:06,  1.22s/it, loss=0.1396, batch_acc=0.9688, running_acc=0.9656, grad=11.5174]Training epoch 45:   7%|▋         | 11/163 [00:18<02:49,  1.12s/it, loss=0.1396, batch_acc=0.9688, running_acc=0.9656, grad=11.5174]Training epoch 45:   7%|▋         | 11/163 [00:18<02:49,  1.12s/it, loss=0.1387, batch_acc=0.9375, running_acc=0.9631, grad=8.7563] Training epoch 45:   7%|▋         | 12/163 [00:19<02:50,  1.13s/it, loss=0.1387, batch_acc=0.9375, running_acc=0.9631, grad=8.7563]Training epoch 45:   7%|▋         | 12/163 [00:19<02:50,  1.13s/it, loss=0.1297, batch_acc=0.9688, running_acc=0.9635, grad=10.3255]Training epoch 45:   8%|▊         | 13/163 [00:20<02:37,  1.05s/it, loss=0.1297, batch_acc=0.9688, running_acc=0.9635, grad=10.3255]Training epoch 45:   8%|▊         | 13/163 [00:20<02:37,  1.05s/it, loss=0.0934, batch_acc=1.0000, running_acc=0.9663, grad=12.9869]Training epoch 45:   9%|▊         | 14/163 [00:21<02:28,  1.00it/s, loss=0.0934, batch_acc=1.0000, running_acc=0.9663, grad=12.9869]Training epoch 45:   9%|▊         | 14/163 [00:21<02:28,  1.00it/s, loss=0.1140, batch_acc=1.0000, running_acc=0.9688, grad=9.5241] Training epoch 45:   9%|▉         | 15/163 [00:21<02:22,  1.04it/s, loss=0.1140, batch_acc=1.0000, running_acc=0.9688, grad=9.5241]Training epoch 45:   9%|▉         | 15/163 [00:21<02:22,  1.04it/s, loss=0.1176, batch_acc=1.0000, running_acc=0.9708, grad=8.6157]Training epoch 45:  10%|▉         | 16/163 [00:23<02:52,  1.18s/it, loss=0.1176, batch_acc=1.0000, running_acc=0.9708, grad=8.6157]Training epoch 45:  10%|▉         | 16/163 [00:23<02:52,  1.18s/it, loss=0.1102, batch_acc=0.9688, running_acc=0.9707, grad=7.0012]Training epoch 45:  10%|█         | 17/163 [00:24<02:38,  1.09s/it, loss=0.1102, batch_acc=0.9688, running_acc=0.9707, grad=7.0012]Training epoch 45:  10%|█         | 17/163 [00:24<02:38,  1.09s/it, loss=0.1037, batch_acc=1.0000, running_acc=0.9724, grad=7.7926]Training epoch 45:  11%|█         | 18/163 [00:25<02:28,  1.02s/it, loss=0.1037, batch_acc=1.0000, running_acc=0.9724, grad=7.7926]Training epoch 45:  11%|█         | 18/163 [00:25<02:28,  1.02s/it, loss=0.1060, batch_acc=1.0000, running_acc=0.9740, grad=8.9820]Training epoch 45:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.1060, batch_acc=1.0000, running_acc=0.9740, grad=8.9820]Training epoch 45:  12%|█▏        | 19/163 [00:26<02:21,  1.02it/s, loss=0.1108, batch_acc=1.0000, running_acc=0.9753, grad=11.6873]Training epoch 45:  12%|█▏        | 20/163 [00:27<02:35,  1.09s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9753, grad=11.6873]Training epoch 45:  12%|█▏        | 20/163 [00:27<02:35,  1.09s/it, loss=0.0963, batch_acc=1.0000, running_acc=0.9766, grad=8.8915] Training epoch 45:  13%|█▎        | 21/163 [00:28<02:25,  1.03s/it, loss=0.0963, batch_acc=1.0000, running_acc=0.9766, grad=8.8915]Training epoch 45:  13%|█▎        | 21/163 [00:28<02:25,  1.03s/it, loss=0.1262, batch_acc=1.0000, running_acc=0.9777, grad=6.7626]Training epoch 45:  13%|█▎        | 22/163 [00:29<02:18,  1.02it/s, loss=0.1262, batch_acc=1.0000, running_acc=0.9777, grad=6.7626]Training epoch 45:  13%|█▎        | 22/163 [00:29<02:18,  1.02it/s, loss=0.1508, batch_acc=0.9688, running_acc=0.9773, grad=14.3691]Training epoch 45:  14%|█▍        | 23/163 [00:30<02:13,  1.05it/s, loss=0.1508, batch_acc=0.9688, running_acc=0.9773, grad=14.3691]Training epoch 45:  14%|█▍        | 23/163 [00:30<02:13,  1.05it/s, loss=0.1077, batch_acc=1.0000, running_acc=0.9783, grad=8.1761] Training epoch 45:  15%|█▍        | 24/163 [00:32<02:54,  1.26s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9783, grad=8.1761]Training epoch 45:  15%|█▍        | 24/163 [00:32<02:54,  1.26s/it, loss=0.1071, batch_acc=1.0000, running_acc=0.9792, grad=7.6542]Training epoch 45:  15%|█▌        | 25/163 [00:33<02:37,  1.14s/it, loss=0.1071, batch_acc=1.0000, running_acc=0.9792, grad=7.6542]Training epoch 45:  15%|█▌        | 25/163 [00:33<02:37,  1.14s/it, loss=0.0664, batch_acc=1.0000, running_acc=0.9800, grad=6.8245]Training epoch 45:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.0664, batch_acc=1.0000, running_acc=0.9800, grad=6.8245]Training epoch 45:  16%|█▌        | 26/163 [00:33<02:25,  1.06s/it, loss=0.0642, batch_acc=1.0000, running_acc=0.9808, grad=5.5345]Training epoch 45:  17%|█▋        | 27/163 [00:34<02:16,  1.01s/it, loss=0.0642, batch_acc=1.0000, running_acc=0.9808, grad=5.5345]Training epoch 45:  17%|█▋        | 27/163 [00:34<02:16,  1.01s/it, loss=0.1117, batch_acc=1.0000, running_acc=0.9815, grad=7.0173]Training epoch 45:  17%|█▋        | 28/163 [00:36<02:53,  1.28s/it, loss=0.1117, batch_acc=1.0000, running_acc=0.9815, grad=7.0173]Training epoch 45:  17%|█▋        | 28/163 [00:36<02:53,  1.28s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9821, grad=9.4453]Training epoch 45:  18%|█▊        | 29/163 [00:37<02:35,  1.16s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9821, grad=9.4453]Training epoch 45:  18%|█▊        | 29/163 [00:37<02:35,  1.16s/it, loss=0.1548, batch_acc=0.9375, running_acc=0.9806, grad=12.5004]Training epoch 45:  18%|█▊        | 30/163 [00:38<02:23,  1.08s/it, loss=0.1548, batch_acc=0.9375, running_acc=0.9806, grad=12.5004]Training epoch 45:  18%|█▊        | 30/163 [00:38<02:23,  1.08s/it, loss=0.1130, batch_acc=0.9688, running_acc=0.9802, grad=9.8422] Training epoch 45:  19%|█▉        | 31/163 [00:39<02:14,  1.02s/it, loss=0.1130, batch_acc=0.9688, running_acc=0.9802, grad=9.8422]Training epoch 45:  19%|█▉        | 31/163 [00:39<02:14,  1.02s/it, loss=0.1167, batch_acc=0.9688, running_acc=0.9798, grad=9.0041]Training epoch 45:  20%|█▉        | 32/163 [00:42<03:37,  1.66s/it, loss=0.1167, batch_acc=0.9688, running_acc=0.9798, grad=9.0041]Training epoch 45:  20%|█▉        | 32/163 [00:42<03:37,  1.66s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9795, grad=14.0013]Training epoch 45:  20%|██        | 33/163 [00:43<03:05,  1.43s/it, loss=0.1274, batch_acc=0.9688, running_acc=0.9795, grad=14.0013]Training epoch 45:  20%|██        | 33/163 [00:43<03:05,  1.43s/it, loss=0.1036, batch_acc=1.0000, running_acc=0.9801, grad=8.5457] Training epoch 45:  21%|██        | 34/163 [00:44<02:42,  1.26s/it, loss=0.1036, batch_acc=1.0000, running_acc=0.9801, grad=8.5457]Training epoch 45:  21%|██        | 34/163 [00:44<02:42,  1.26s/it, loss=0.1782, batch_acc=0.9688, running_acc=0.9798, grad=17.8096]Training epoch 45:  21%|██▏       | 35/163 [00:45<02:26,  1.15s/it, loss=0.1782, batch_acc=0.9688, running_acc=0.9798, grad=17.8096]Training epoch 45:  21%|██▏       | 35/163 [00:45<02:26,  1.15s/it, loss=0.0837, batch_acc=1.0000, running_acc=0.9804, grad=6.8171] Training epoch 45:  22%|██▏       | 36/163 [00:47<02:53,  1.37s/it, loss=0.0837, batch_acc=1.0000, running_acc=0.9804, grad=6.8171]Training epoch 45:  22%|██▏       | 36/163 [00:47<02:53,  1.37s/it, loss=0.1023, batch_acc=1.0000, running_acc=0.9809, grad=8.9364]Training epoch 45:  23%|██▎       | 37/163 [00:47<02:33,  1.22s/it, loss=0.1023, batch_acc=1.0000, running_acc=0.9809, grad=8.9364]Training epoch 45:  23%|██▎       | 37/163 [00:47<02:33,  1.22s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9814, grad=12.3917]Training epoch 45:  23%|██▎       | 38/163 [00:48<02:19,  1.12s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9814, grad=12.3917]Training epoch 45:  23%|██▎       | 38/163 [00:48<02:19,  1.12s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9811, grad=18.7824]Training epoch 45:  24%|██▍       | 39/163 [00:49<02:09,  1.05s/it, loss=0.1853, batch_acc=0.9688, running_acc=0.9811, grad=18.7824]Training epoch 45:  24%|██▍       | 39/163 [00:49<02:09,  1.05s/it, loss=0.1207, batch_acc=0.9375, running_acc=0.9800, grad=5.7770] Training epoch 45:  25%|██▍       | 40/163 [00:52<02:55,  1.43s/it, loss=0.1207, batch_acc=0.9375, running_acc=0.9800, grad=5.7770]Training epoch 45:  25%|██▍       | 40/163 [00:52<02:55,  1.43s/it, loss=0.1144, batch_acc=1.0000, running_acc=0.9805, grad=10.4546]Training epoch 45:  25%|██▌       | 41/163 [00:52<02:33,  1.26s/it, loss=0.1144, batch_acc=1.0000, running_acc=0.9805, grad=10.4546]Training epoch 45:  25%|██▌       | 41/163 [00:52<02:33,  1.26s/it, loss=0.0658, batch_acc=1.0000, running_acc=0.9809, grad=4.6318] Training epoch 45:  26%|██▌       | 42/163 [00:53<02:18,  1.15s/it, loss=0.0658, batch_acc=1.0000, running_acc=0.9809, grad=4.6318]Training epoch 45:  26%|██▌       | 42/163 [00:53<02:18,  1.15s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9814, grad=6.3598]Training epoch 45:  26%|██▋       | 43/163 [00:54<02:07,  1.07s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9814, grad=6.3598]Training epoch 45:  26%|██▋       | 43/163 [00:54<02:07,  1.07s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9811, grad=9.9250]Training epoch 45:  27%|██▋       | 44/163 [00:57<02:53,  1.46s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9811, grad=9.9250]Training epoch 45:  27%|██▋       | 44/163 [00:57<02:53,  1.46s/it, loss=0.1753, batch_acc=1.0000, running_acc=0.9815, grad=12.7088]Training epoch 45:  28%|██▊       | 45/163 [00:57<02:31,  1.29s/it, loss=0.1753, batch_acc=1.0000, running_acc=0.9815, grad=12.7088]Training epoch 45:  28%|██▊       | 45/163 [00:57<02:31,  1.29s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9819, grad=9.8661] Training epoch 45:  28%|██▊       | 46/163 [00:58<02:15,  1.16s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9819, grad=9.8661]Training epoch 45:  28%|██▊       | 46/163 [00:58<02:15,  1.16s/it, loss=0.0975, batch_acc=0.9688, running_acc=0.9817, grad=6.0863]Training epoch 45:  29%|██▉       | 47/163 [00:59<02:04,  1.08s/it, loss=0.0975, batch_acc=0.9688, running_acc=0.9817, grad=6.0863]Training epoch 45:  29%|██▉       | 47/163 [00:59<02:04,  1.08s/it, loss=0.0572, batch_acc=1.0000, running_acc=0.9820, grad=3.7920]Training epoch 45:  29%|██▉       | 48/163 [01:01<02:28,  1.29s/it, loss=0.0572, batch_acc=1.0000, running_acc=0.9820, grad=3.7920]Training epoch 45:  29%|██▉       | 48/163 [01:01<02:28,  1.29s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9824, grad=14.2363]Training epoch 45:  30%|███       | 49/163 [01:02<02:13,  1.17s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9824, grad=14.2363]Training epoch 45:  30%|███       | 49/163 [01:02<02:13,  1.17s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9828, grad=8.3779] Training epoch 45:  31%|███       | 50/163 [01:03<02:02,  1.08s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9828, grad=8.3779]Training epoch 45:  31%|███       | 50/163 [01:03<02:02,  1.08s/it, loss=0.2376, batch_acc=0.9062, running_acc=0.9812, grad=11.7102]Training epoch 45:  31%|███▏      | 51/163 [01:04<01:54,  1.02s/it, loss=0.2376, batch_acc=0.9062, running_acc=0.9812, grad=11.7102]Training epoch 45:  31%|███▏      | 51/163 [01:04<01:54,  1.02s/it, loss=0.1643, batch_acc=0.9688, running_acc=0.9810, grad=19.3525]Training epoch 45:  32%|███▏      | 52/163 [01:05<02:19,  1.26s/it, loss=0.1643, batch_acc=0.9688, running_acc=0.9810, grad=19.3525]Training epoch 45:  32%|███▏      | 52/163 [01:05<02:19,  1.26s/it, loss=0.0760, batch_acc=1.0000, running_acc=0.9814, grad=6.2160] Training epoch 45:  33%|███▎      | 53/163 [01:06<02:05,  1.15s/it, loss=0.0760, batch_acc=1.0000, running_acc=0.9814, grad=6.2160]Training epoch 45:  33%|███▎      | 53/163 [01:06<02:05,  1.15s/it, loss=0.0787, batch_acc=1.0000, running_acc=0.9817, grad=6.4106]Training epoch 45:  33%|███▎      | 54/163 [01:07<01:56,  1.06s/it, loss=0.0787, batch_acc=1.0000, running_acc=0.9817, grad=6.4106]Training epoch 45:  33%|███▎      | 54/163 [01:07<01:56,  1.06s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9821, grad=6.2193]Training epoch 45:  34%|███▎      | 55/163 [01:08<01:48,  1.01s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9821, grad=6.2193]Training epoch 45:  34%|███▎      | 55/163 [01:08<01:48,  1.01s/it, loss=0.0780, batch_acc=1.0000, running_acc=0.9824, grad=5.5387]Training epoch 45:  34%|███▍      | 56/163 [01:10<02:14,  1.25s/it, loss=0.0780, batch_acc=1.0000, running_acc=0.9824, grad=5.5387]Training epoch 45:  34%|███▍      | 56/163 [01:10<02:14,  1.25s/it, loss=0.1382, batch_acc=0.9688, running_acc=0.9821, grad=10.8220]Training epoch 45:  35%|███▍      | 57/163 [01:11<02:00,  1.14s/it, loss=0.1382, batch_acc=0.9688, running_acc=0.9821, grad=10.8220]Training epoch 45:  35%|███▍      | 57/163 [01:11<02:00,  1.14s/it, loss=0.0986, batch_acc=1.0000, running_acc=0.9825, grad=12.5875]Training epoch 45:  36%|███▌      | 58/163 [01:12<01:51,  1.06s/it, loss=0.0986, batch_acc=1.0000, running_acc=0.9825, grad=12.5875]Training epoch 45:  36%|███▌      | 58/163 [01:12<01:51,  1.06s/it, loss=0.1107, batch_acc=1.0000, running_acc=0.9828, grad=10.8991]Training epoch 45:  36%|███▌      | 59/163 [01:13<01:44,  1.01s/it, loss=0.1107, batch_acc=1.0000, running_acc=0.9828, grad=10.8991]Training epoch 45:  36%|███▌      | 59/163 [01:13<01:44,  1.01s/it, loss=0.0932, batch_acc=1.0000, running_acc=0.9831, grad=6.2177] Training epoch 45:  37%|███▋      | 60/163 [01:14<02:03,  1.20s/it, loss=0.0932, batch_acc=1.0000, running_acc=0.9831, grad=6.2177]Training epoch 45:  37%|███▋      | 60/163 [01:14<02:03,  1.20s/it, loss=0.0850, batch_acc=1.0000, running_acc=0.9833, grad=8.4157]Training epoch 45:  37%|███▋      | 61/163 [01:15<01:52,  1.10s/it, loss=0.0850, batch_acc=1.0000, running_acc=0.9833, grad=8.4157]Training epoch 45:  37%|███▋      | 61/163 [01:15<01:52,  1.10s/it, loss=0.1594, batch_acc=0.9375, running_acc=0.9826, grad=14.9951]Training epoch 45:  38%|███▊      | 62/163 [01:16<01:44,  1.03s/it, loss=0.1594, batch_acc=0.9375, running_acc=0.9826, grad=14.9951]Training epoch 45:  38%|███▊      | 62/163 [01:16<01:44,  1.03s/it, loss=0.0984, batch_acc=1.0000, running_acc=0.9829, grad=8.0368] Training epoch 45:  39%|███▊      | 63/163 [01:17<01:38,  1.01it/s, loss=0.0984, batch_acc=1.0000, running_acc=0.9829, grad=8.0368]Training epoch 45:  39%|███▊      | 63/163 [01:17<01:38,  1.01it/s, loss=0.0822, batch_acc=1.0000, running_acc=0.9831, grad=7.5784]Training epoch 45:  39%|███▉      | 64/163 [01:19<02:09,  1.31s/it, loss=0.0822, batch_acc=1.0000, running_acc=0.9831, grad=7.5784]Training epoch 45:  39%|███▉      | 64/163 [01:19<02:09,  1.31s/it, loss=0.0746, batch_acc=1.0000, running_acc=0.9834, grad=7.1085]Training epoch 45:  40%|███▉      | 65/163 [01:20<01:55,  1.18s/it, loss=0.0746, batch_acc=1.0000, running_acc=0.9834, grad=7.1085]Training epoch 45:  40%|███▉      | 65/163 [01:20<01:55,  1.18s/it, loss=0.1376, batch_acc=0.9375, running_acc=0.9827, grad=7.6620]Training epoch 45:  40%|████      | 66/163 [01:21<01:45,  1.09s/it, loss=0.1376, batch_acc=0.9375, running_acc=0.9827, grad=7.6620]Training epoch 45:  40%|████      | 66/163 [01:21<01:45,  1.09s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9830, grad=6.7826]Training epoch 45:  41%|████      | 67/163 [01:21<01:38,  1.03s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9830, grad=6.7826]Training epoch 45:  41%|████      | 67/163 [01:21<01:38,  1.03s/it, loss=0.0919, batch_acc=1.0000, running_acc=0.9832, grad=8.3590]Training epoch 45:  42%|████▏     | 68/163 [01:23<01:46,  1.12s/it, loss=0.0919, batch_acc=1.0000, running_acc=0.9832, grad=8.3590]Training epoch 45:  42%|████▏     | 68/163 [01:23<01:46,  1.12s/it, loss=0.1011, batch_acc=1.0000, running_acc=0.9835, grad=8.8319]Training epoch 45:  42%|████▏     | 69/163 [01:24<01:38,  1.05s/it, loss=0.1011, batch_acc=1.0000, running_acc=0.9835, grad=8.8319]Training epoch 45:  42%|████▏     | 69/163 [01:24<01:38,  1.05s/it, loss=0.1207, batch_acc=0.9688, running_acc=0.9832, grad=8.9228]Training epoch 45:  43%|████▎     | 70/163 [01:25<01:32,  1.00it/s, loss=0.1207, batch_acc=0.9688, running_acc=0.9832, grad=8.9228]Training epoch 45:  43%|████▎     | 70/163 [01:25<01:32,  1.00it/s, loss=0.0809, batch_acc=1.0000, running_acc=0.9835, grad=5.9624]Training epoch 45:  44%|████▎     | 71/163 [01:25<01:28,  1.04it/s, loss=0.0809, batch_acc=1.0000, running_acc=0.9835, grad=5.9624]Training epoch 45:  44%|████▎     | 71/163 [01:25<01:28,  1.04it/s, loss=0.1106, batch_acc=1.0000, running_acc=0.9837, grad=7.3015]Training epoch 45:  44%|████▍     | 72/163 [01:27<01:46,  1.17s/it, loss=0.1106, batch_acc=1.0000, running_acc=0.9837, grad=7.3015]Training epoch 45:  44%|████▍     | 72/163 [01:27<01:46,  1.17s/it, loss=0.0909, batch_acc=1.0000, running_acc=0.9839, grad=8.1618]Training epoch 45:  45%|████▍     | 73/163 [01:28<01:37,  1.08s/it, loss=0.0909, batch_acc=1.0000, running_acc=0.9839, grad=8.1618]Training epoch 45:  45%|████▍     | 73/163 [01:28<01:37,  1.08s/it, loss=0.0568, batch_acc=1.0000, running_acc=0.9842, grad=4.9867]Training epoch 45:  45%|████▌     | 74/163 [01:29<01:30,  1.02s/it, loss=0.0568, batch_acc=1.0000, running_acc=0.9842, grad=4.9867]Training epoch 45:  45%|████▌     | 74/163 [01:29<01:30,  1.02s/it, loss=0.1089, batch_acc=0.9688, running_acc=0.9840, grad=8.7485]Training epoch 45:  46%|████▌     | 75/163 [01:30<01:26,  1.02it/s, loss=0.1089, batch_acc=0.9688, running_acc=0.9840, grad=8.7485]Training epoch 45:  46%|████▌     | 75/163 [01:30<01:26,  1.02it/s, loss=0.1188, batch_acc=0.9688, running_acc=0.9838, grad=11.0230]Training epoch 45:  47%|████▋     | 76/163 [01:31<01:34,  1.08s/it, loss=0.1188, batch_acc=0.9688, running_acc=0.9838, grad=11.0230]Training epoch 45:  47%|████▋     | 76/163 [01:31<01:34,  1.08s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9840, grad=9.3927] Training epoch 45:  47%|████▋     | 77/163 [01:32<01:27,  1.02s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9840, grad=9.3927]Training epoch 45:  47%|████▋     | 77/163 [01:32<01:27,  1.02s/it, loss=0.1031, batch_acc=0.9688, running_acc=0.9838, grad=7.6464]Training epoch 45:  48%|████▊     | 78/163 [01:33<01:23,  1.02it/s, loss=0.1031, batch_acc=0.9688, running_acc=0.9838, grad=7.6464]Training epoch 45:  48%|████▊     | 78/163 [01:33<01:23,  1.02it/s, loss=0.0792, batch_acc=1.0000, running_acc=0.9840, grad=5.8319]Training epoch 45:  48%|████▊     | 79/163 [01:34<01:19,  1.05it/s, loss=0.0792, batch_acc=1.0000, running_acc=0.9840, grad=5.8319]Training epoch 45:  48%|████▊     | 79/163 [01:34<01:19,  1.05it/s, loss=0.0930, batch_acc=1.0000, running_acc=0.9842, grad=9.3700]Training epoch 45:  49%|████▉     | 80/163 [01:36<01:39,  1.20s/it, loss=0.0930, batch_acc=1.0000, running_acc=0.9842, grad=9.3700]Training epoch 45:  49%|████▉     | 80/163 [01:36<01:39,  1.20s/it, loss=0.1436, batch_acc=0.9688, running_acc=0.9840, grad=12.4193]Training epoch 45:  50%|████▉     | 81/163 [01:36<01:30,  1.10s/it, loss=0.1436, batch_acc=0.9688, running_acc=0.9840, grad=12.4193]Training epoch 45:  50%|████▉     | 81/163 [01:36<01:30,  1.10s/it, loss=0.1027, batch_acc=0.9688, running_acc=0.9838, grad=7.5643] Training epoch 45:  50%|█████     | 82/163 [01:37<01:23,  1.03s/it, loss=0.1027, batch_acc=0.9688, running_acc=0.9838, grad=7.5643]Training epoch 45:  50%|█████     | 82/163 [01:37<01:23,  1.03s/it, loss=0.1369, batch_acc=0.9688, running_acc=0.9836, grad=10.1324]Training epoch 45:  51%|█████     | 83/163 [01:38<01:19,  1.01it/s, loss=0.1369, batch_acc=0.9688, running_acc=0.9836, grad=10.1324]Training epoch 45:  51%|█████     | 83/163 [01:38<01:19,  1.01it/s, loss=0.1017, batch_acc=1.0000, running_acc=0.9838, grad=9.8087] Training epoch 45:  52%|█████▏    | 84/163 [01:40<01:31,  1.16s/it, loss=0.1017, batch_acc=1.0000, running_acc=0.9838, grad=9.8087]Training epoch 45:  52%|█████▏    | 84/163 [01:40<01:31,  1.16s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9840, grad=8.3932]Training epoch 45:  52%|█████▏    | 85/163 [01:41<01:23,  1.08s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9840, grad=8.3932]Training epoch 45:  52%|█████▏    | 85/163 [01:41<01:23,  1.08s/it, loss=0.1219, batch_acc=0.9688, running_acc=0.9838, grad=6.8916]Training epoch 45:  53%|█████▎    | 86/163 [01:41<01:18,  1.02s/it, loss=0.1219, batch_acc=0.9688, running_acc=0.9838, grad=6.8916]Training epoch 45:  53%|█████▎    | 86/163 [01:41<01:18,  1.02s/it, loss=0.0959, batch_acc=1.0000, running_acc=0.9840, grad=9.4648]Training epoch 45:  53%|█████▎    | 87/163 [01:42<01:14,  1.03it/s, loss=0.0959, batch_acc=1.0000, running_acc=0.9840, grad=9.4648]Training epoch 45:  53%|█████▎    | 87/163 [01:42<01:14,  1.03it/s, loss=0.1012, batch_acc=1.0000, running_acc=0.9842, grad=8.4528]Training epoch 45:  54%|█████▍    | 88/163 [01:44<01:24,  1.12s/it, loss=0.1012, batch_acc=1.0000, running_acc=0.9842, grad=8.4528]Training epoch 45:  54%|█████▍    | 88/163 [01:44<01:24,  1.12s/it, loss=0.1014, batch_acc=0.9688, running_acc=0.9840, grad=7.5022]Training epoch 45:  55%|█████▍    | 89/163 [01:45<01:17,  1.05s/it, loss=0.1014, batch_acc=0.9688, running_acc=0.9840, grad=7.5022]Training epoch 45:  55%|█████▍    | 89/163 [01:45<01:17,  1.05s/it, loss=0.0618, batch_acc=1.0000, running_acc=0.9842, grad=5.7209]Training epoch 45:  55%|█████▌    | 90/163 [01:46<01:12,  1.00it/s, loss=0.0618, batch_acc=1.0000, running_acc=0.9842, grad=5.7209]Training epoch 45:  55%|█████▌    | 90/163 [01:46<01:12,  1.00it/s, loss=0.0894, batch_acc=1.0000, running_acc=0.9844, grad=9.7214]Training epoch 45:  56%|█████▌    | 91/163 [01:46<01:09,  1.04it/s, loss=0.0894, batch_acc=1.0000, running_acc=0.9844, grad=9.7214]Training epoch 45:  56%|█████▌    | 91/163 [01:46<01:09,  1.04it/s, loss=0.1207, batch_acc=0.9688, running_acc=0.9842, grad=8.2379]Training epoch 45:  56%|█████▋    | 92/163 [01:48<01:27,  1.23s/it, loss=0.1207, batch_acc=0.9688, running_acc=0.9842, grad=8.2379]Training epoch 45:  56%|█████▋    | 92/163 [01:48<01:27,  1.23s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9844, grad=7.9140]Training epoch 45:  57%|█████▋    | 93/163 [01:49<01:18,  1.12s/it, loss=0.0831, batch_acc=1.0000, running_acc=0.9844, grad=7.9140]Training epoch 45:  57%|█████▋    | 93/163 [01:49<01:18,  1.12s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9845, grad=5.0734]Training epoch 45:  58%|█████▊    | 94/163 [01:50<01:12,  1.05s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9845, grad=5.0734]Training epoch 45:  58%|█████▊    | 94/163 [01:50<01:12,  1.05s/it, loss=0.1104, batch_acc=1.0000, running_acc=0.9847, grad=9.6213]Training epoch 45:  58%|█████▊    | 95/163 [01:51<01:07,  1.00it/s, loss=0.1104, batch_acc=1.0000, running_acc=0.9847, grad=9.6213]Training epoch 45:  58%|█████▊    | 95/163 [01:51<01:07,  1.00it/s, loss=0.0905, batch_acc=1.0000, running_acc=0.9849, grad=8.2761]Training epoch 45:  59%|█████▉    | 96/163 [01:52<01:14,  1.12s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9849, grad=8.2761]Training epoch 45:  59%|█████▉    | 96/163 [01:52<01:14,  1.12s/it, loss=0.0752, batch_acc=1.0000, running_acc=0.9850, grad=6.6489]Training epoch 45:  60%|█████▉    | 97/163 [01:53<01:08,  1.04s/it, loss=0.0752, batch_acc=1.0000, running_acc=0.9850, grad=6.6489]Training epoch 45:  60%|█████▉    | 97/163 [01:53<01:08,  1.04s/it, loss=0.1037, batch_acc=0.9688, running_acc=0.9849, grad=8.5163]Training epoch 45:  60%|██████    | 98/163 [01:54<01:04,  1.01it/s, loss=0.1037, batch_acc=0.9688, running_acc=0.9849, grad=8.5163]Training epoch 45:  60%|██████    | 98/163 [01:54<01:04,  1.01it/s, loss=0.0840, batch_acc=1.0000, running_acc=0.9850, grad=7.2630]Training epoch 45:  61%|██████    | 99/163 [01:55<01:01,  1.04it/s, loss=0.0840, batch_acc=1.0000, running_acc=0.9850, grad=7.2630]Training epoch 45:  61%|██████    | 99/163 [01:55<01:01,  1.04it/s, loss=0.1394, batch_acc=0.9688, running_acc=0.9848, grad=10.2986]Training epoch 45:  61%|██████▏   | 100/163 [01:56<01:00,  1.04it/s, loss=0.1394, batch_acc=0.9688, running_acc=0.9848, grad=10.2986]Training epoch 45:  61%|██████▏   | 100/163 [01:56<01:00,  1.04it/s, loss=0.0946, batch_acc=1.0000, running_acc=0.9850, grad=7.3589] Training epoch 45:  62%|██████▏   | 101/163 [01:58<01:11,  1.15s/it, loss=0.0946, batch_acc=1.0000, running_acc=0.9850, grad=7.3589]Training epoch 45:  62%|██████▏   | 101/163 [01:58<01:11,  1.15s/it, loss=0.1288, batch_acc=0.9688, running_acc=0.9848, grad=12.6622]Training epoch 45:  63%|██████▎   | 102/163 [01:58<01:05,  1.07s/it, loss=0.1288, batch_acc=0.9688, running_acc=0.9848, grad=12.6622]Training epoch 45:  63%|██████▎   | 102/163 [01:58<01:05,  1.07s/it, loss=0.0707, batch_acc=1.0000, running_acc=0.9850, grad=6.0808] Training epoch 45:  63%|██████▎   | 103/163 [01:59<01:00,  1.01s/it, loss=0.0707, batch_acc=1.0000, running_acc=0.9850, grad=6.0808]Training epoch 45:  63%|██████▎   | 103/163 [01:59<01:00,  1.01s/it, loss=0.0910, batch_acc=1.0000, running_acc=0.9851, grad=8.8917]Training epoch 45:  64%|██████▍   | 104/163 [02:01<01:05,  1.11s/it, loss=0.0910, batch_acc=1.0000, running_acc=0.9851, grad=8.8917]Training epoch 45:  64%|██████▍   | 104/163 [02:01<01:05,  1.11s/it, loss=0.0744, batch_acc=1.0000, running_acc=0.9853, grad=6.7325]Training epoch 45:  64%|██████▍   | 105/163 [02:02<01:12,  1.26s/it, loss=0.0744, batch_acc=1.0000, running_acc=0.9853, grad=6.7325]Training epoch 45:  64%|██████▍   | 105/163 [02:02<01:12,  1.26s/it, loss=0.1899, batch_acc=0.9375, running_acc=0.9848, grad=12.3228]Training epoch 45:  65%|██████▌   | 106/163 [02:03<01:05,  1.14s/it, loss=0.1899, batch_acc=0.9375, running_acc=0.9848, grad=12.3228]Training epoch 45:  65%|██████▌   | 106/163 [02:03<01:05,  1.14s/it, loss=0.0951, batch_acc=0.9688, running_acc=0.9847, grad=8.5309] Training epoch 45:  66%|██████▌   | 107/163 [02:04<00:59,  1.06s/it, loss=0.0951, batch_acc=0.9688, running_acc=0.9847, grad=8.5309]Training epoch 45:  66%|██████▌   | 107/163 [02:04<00:59,  1.06s/it, loss=0.0995, batch_acc=1.0000, running_acc=0.9848, grad=13.1656]Training epoch 45:  66%|██████▋   | 108/163 [02:05<00:57,  1.05s/it, loss=0.0995, batch_acc=1.0000, running_acc=0.9848, grad=13.1656]Training epoch 45:  66%|██████▋   | 108/163 [02:05<00:57,  1.05s/it, loss=0.1417, batch_acc=0.9688, running_acc=0.9847, grad=11.8674]Training epoch 45:  67%|██████▋   | 109/163 [02:06<01:00,  1.11s/it, loss=0.1417, batch_acc=0.9688, running_acc=0.9847, grad=11.8674]Training epoch 45:  67%|██████▋   | 109/163 [02:06<01:00,  1.11s/it, loss=0.0865, batch_acc=1.0000, running_acc=0.9848, grad=5.7991] Training epoch 45:  67%|██████▋   | 110/163 [02:07<00:55,  1.04s/it, loss=0.0865, batch_acc=1.0000, running_acc=0.9848, grad=5.7991]Training epoch 45:  67%|██████▋   | 110/163 [02:07<00:55,  1.04s/it, loss=0.1098, batch_acc=1.0000, running_acc=0.9849, grad=9.7707]Training epoch 45:  68%|██████▊   | 111/163 [02:08<00:51,  1.01it/s, loss=0.1098, batch_acc=1.0000, running_acc=0.9849, grad=9.7707]Training epoch 45:  68%|██████▊   | 111/163 [02:08<00:51,  1.01it/s, loss=0.0819, batch_acc=1.0000, running_acc=0.9851, grad=7.0261]Training epoch 45:  69%|██████▊   | 112/163 [02:09<00:55,  1.10s/it, loss=0.0819, batch_acc=1.0000, running_acc=0.9851, grad=7.0261]Training epoch 45:  69%|██████▊   | 112/163 [02:09<00:55,  1.10s/it, loss=0.0868, batch_acc=1.0000, running_acc=0.9852, grad=5.4574]Training epoch 45:  69%|██████▉   | 113/163 [02:11<00:59,  1.18s/it, loss=0.0868, batch_acc=1.0000, running_acc=0.9852, grad=5.4574]Training epoch 45:  69%|██████▉   | 113/163 [02:11<00:59,  1.18s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9853, grad=6.0210]Training epoch 45:  70%|██████▉   | 114/163 [02:12<00:53,  1.09s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9853, grad=6.0210]Training epoch 45:  70%|██████▉   | 114/163 [02:12<00:53,  1.09s/it, loss=0.0942, batch_acc=0.9688, running_acc=0.9852, grad=7.9668]Training epoch 45:  71%|███████   | 115/163 [02:12<00:49,  1.03s/it, loss=0.0942, batch_acc=0.9688, running_acc=0.9852, grad=7.9668]Training epoch 45:  71%|███████   | 115/163 [02:12<00:49,  1.03s/it, loss=0.1038, batch_acc=1.0000, running_acc=0.9853, grad=9.4885]Training epoch 45:  71%|███████   | 116/163 [02:14<00:59,  1.27s/it, loss=0.1038, batch_acc=1.0000, running_acc=0.9853, grad=9.4885]Training epoch 45:  71%|███████   | 116/163 [02:14<00:59,  1.27s/it, loss=0.1165, batch_acc=0.9688, running_acc=0.9852, grad=7.4294]Training epoch 45:  72%|███████▏  | 117/163 [02:15<00:55,  1.21s/it, loss=0.1165, batch_acc=0.9688, running_acc=0.9852, grad=7.4294]Training epoch 45:  72%|███████▏  | 117/163 [02:15<00:55,  1.21s/it, loss=0.0932, batch_acc=1.0000, running_acc=0.9853, grad=8.5933]Training epoch 45:  72%|███████▏  | 118/163 [02:16<00:49,  1.11s/it, loss=0.0932, batch_acc=1.0000, running_acc=0.9853, grad=8.5933]Training epoch 45:  72%|███████▏  | 118/163 [02:16<00:49,  1.11s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9854, grad=7.4074]Training epoch 45:  73%|███████▎  | 119/163 [02:17<00:45,  1.04s/it, loss=0.0975, batch_acc=1.0000, running_acc=0.9854, grad=7.4074]Training epoch 45:  73%|███████▎  | 119/163 [02:17<00:45,  1.04s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9856, grad=8.6408]Training epoch 45:  74%|███████▎  | 120/163 [02:19<00:59,  1.38s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9856, grad=8.6408]Training epoch 45:  74%|███████▎  | 120/163 [02:19<00:59,  1.38s/it, loss=0.0923, batch_acc=0.9688, running_acc=0.9854, grad=7.1428]Training epoch 45:  74%|███████▍  | 121/163 [02:20<00:51,  1.24s/it, loss=0.0923, batch_acc=0.9688, running_acc=0.9854, grad=7.1428]Training epoch 45:  74%|███████▍  | 121/163 [02:20<00:51,  1.24s/it, loss=0.1522, batch_acc=0.9375, running_acc=0.9850, grad=14.5835]Training epoch 45:  75%|███████▍  | 122/163 [02:21<00:46,  1.13s/it, loss=0.1522, batch_acc=0.9375, running_acc=0.9850, grad=14.5835]Training epoch 45:  75%|███████▍  | 122/163 [02:21<00:46,  1.13s/it, loss=0.1097, batch_acc=0.9688, running_acc=0.9849, grad=7.0657] Training epoch 45:  75%|███████▌  | 123/163 [02:22<00:42,  1.05s/it, loss=0.1097, batch_acc=0.9688, running_acc=0.9849, grad=7.0657]Training epoch 45:  75%|███████▌  | 123/163 [02:22<00:42,  1.05s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9850, grad=9.2633]Training epoch 45:  76%|███████▌  | 124/163 [02:24<00:57,  1.47s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9850, grad=9.2633]Training epoch 45:  76%|███████▌  | 124/163 [02:24<00:57,  1.47s/it, loss=0.0844, batch_acc=1.0000, running_acc=0.9851, grad=7.2559]Training epoch 45:  77%|███████▋  | 125/163 [02:25<00:49,  1.29s/it, loss=0.0844, batch_acc=1.0000, running_acc=0.9851, grad=7.2559]Training epoch 45:  77%|███████▋  | 125/163 [02:25<00:49,  1.29s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9852, grad=13.3248]Training epoch 45:  77%|███████▋  | 126/163 [02:26<00:43,  1.17s/it, loss=0.1501, batch_acc=1.0000, running_acc=0.9852, grad=13.3248]Training epoch 45:  77%|███████▋  | 126/163 [02:26<00:43,  1.17s/it, loss=0.1133, batch_acc=0.9688, running_acc=0.9851, grad=8.6244] Training epoch 45:  78%|███████▊  | 127/163 [02:27<00:38,  1.08s/it, loss=0.1133, batch_acc=0.9688, running_acc=0.9851, grad=8.6244]Training epoch 45:  78%|███████▊  | 127/163 [02:27<00:38,  1.08s/it, loss=0.1255, batch_acc=0.9688, running_acc=0.9850, grad=16.9668]Training epoch 45:  79%|███████▊  | 128/163 [02:29<00:45,  1.29s/it, loss=0.1255, batch_acc=0.9688, running_acc=0.9850, grad=16.9668]Training epoch 45:  79%|███████▊  | 128/163 [02:29<00:45,  1.29s/it, loss=0.1726, batch_acc=0.9688, running_acc=0.9849, grad=19.1859]Training epoch 45:  79%|███████▉  | 129/163 [02:30<00:39,  1.17s/it, loss=0.1726, batch_acc=0.9688, running_acc=0.9849, grad=19.1859]Training epoch 45:  79%|███████▉  | 129/163 [02:30<00:39,  1.17s/it, loss=0.0896, batch_acc=1.0000, running_acc=0.9850, grad=7.5664] Training epoch 45:  80%|███████▉  | 130/163 [02:31<00:35,  1.08s/it, loss=0.0896, batch_acc=1.0000, running_acc=0.9850, grad=7.5664]Training epoch 45:  80%|███████▉  | 130/163 [02:31<00:35,  1.08s/it, loss=0.1508, batch_acc=0.9375, running_acc=0.9846, grad=14.1911]Training epoch 45:  80%|████████  | 131/163 [02:31<00:32,  1.02s/it, loss=0.1508, batch_acc=0.9375, running_acc=0.9846, grad=14.1911]Training epoch 45:  80%|████████  | 131/163 [02:31<00:32,  1.02s/it, loss=0.1383, batch_acc=0.9062, running_acc=0.9840, grad=12.0445]Training epoch 45:  81%|████████  | 132/163 [02:33<00:34,  1.10s/it, loss=0.1383, batch_acc=0.9062, running_acc=0.9840, grad=12.0445]Training epoch 45:  81%|████████  | 132/163 [02:33<00:34,  1.10s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9841, grad=7.1340] Training epoch 45:  82%|████████▏ | 133/163 [02:34<00:31,  1.03s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9841, grad=7.1340]Training epoch 45:  82%|████████▏ | 133/163 [02:34<00:31,  1.03s/it, loss=0.0668, batch_acc=1.0000, running_acc=0.9843, grad=6.0016]Training epoch 45:  82%|████████▏ | 134/163 [02:34<00:28,  1.01it/s, loss=0.0668, batch_acc=1.0000, running_acc=0.9843, grad=6.0016]Training epoch 45:  82%|████████▏ | 134/163 [02:34<00:28,  1.01it/s, loss=0.1267, batch_acc=0.9688, running_acc=0.9841, grad=10.0829]Training epoch 45:  83%|████████▎ | 135/163 [02:35<00:26,  1.05it/s, loss=0.1267, batch_acc=0.9688, running_acc=0.9841, grad=10.0829]Training epoch 45:  83%|████████▎ | 135/163 [02:35<00:26,  1.05it/s, loss=0.1434, batch_acc=0.9688, running_acc=0.9840, grad=9.4050] Training epoch 45:  83%|████████▎ | 136/163 [02:37<00:30,  1.15s/it, loss=0.1434, batch_acc=0.9688, running_acc=0.9840, grad=9.4050]Training epoch 45:  83%|████████▎ | 136/163 [02:37<00:30,  1.15s/it, loss=0.0944, batch_acc=0.9688, running_acc=0.9839, grad=6.8505]Training epoch 45:  84%|████████▍ | 137/163 [02:38<00:27,  1.06s/it, loss=0.0944, batch_acc=0.9688, running_acc=0.9839, grad=6.8505]Training epoch 45:  84%|████████▍ | 137/163 [02:38<00:27,  1.06s/it, loss=0.1354, batch_acc=1.0000, running_acc=0.9840, grad=10.1940]Training epoch 45:  85%|████████▍ | 138/163 [02:39<00:25,  1.01s/it, loss=0.1354, batch_acc=1.0000, running_acc=0.9840, grad=10.1940]Training epoch 45:  85%|████████▍ | 138/163 [02:39<00:25,  1.01s/it, loss=0.0570, batch_acc=1.0000, running_acc=0.9841, grad=6.2048] Training epoch 45:  85%|████████▌ | 139/163 [02:40<00:23,  1.03it/s, loss=0.0570, batch_acc=1.0000, running_acc=0.9841, grad=6.2048]Training epoch 45:  85%|████████▌ | 139/163 [02:40<00:23,  1.03it/s, loss=0.0859, batch_acc=0.9688, running_acc=0.9840, grad=6.4142]Training epoch 45:  86%|████████▌ | 140/163 [02:42<00:29,  1.29s/it, loss=0.0859, batch_acc=0.9688, running_acc=0.9840, grad=6.4142]Training epoch 45:  86%|████████▌ | 140/163 [02:42<00:29,  1.29s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9842, grad=9.2101]Training epoch 45:  87%|████████▋ | 141/163 [02:43<00:26,  1.20s/it, loss=0.0954, batch_acc=1.0000, running_acc=0.9842, grad=9.2101]Training epoch 45:  87%|████████▋ | 141/163 [02:43<00:26,  1.20s/it, loss=0.1573, batch_acc=0.9688, running_acc=0.9840, grad=9.5638]Training epoch 45:  87%|████████▋ | 142/163 [02:43<00:23,  1.10s/it, loss=0.1573, batch_acc=0.9688, running_acc=0.9840, grad=9.5638]Training epoch 45:  87%|████████▋ | 142/163 [02:43<00:23,  1.10s/it, loss=0.1071, batch_acc=1.0000, running_acc=0.9842, grad=15.6311]Training epoch 45:  88%|████████▊ | 143/163 [02:44<00:20,  1.03s/it, loss=0.1071, batch_acc=1.0000, running_acc=0.9842, grad=15.6311]Training epoch 45:  88%|████████▊ | 143/163 [02:44<00:20,  1.03s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9843, grad=7.9472] Training epoch 45:  88%|████████▊ | 144/163 [02:46<00:22,  1.19s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9843, grad=7.9472]Training epoch 45:  88%|████████▊ | 144/163 [02:46<00:22,  1.19s/it, loss=0.1189, batch_acc=0.9688, running_acc=0.9842, grad=10.3141]Training epoch 45:  89%|████████▉ | 145/163 [02:47<00:21,  1.22s/it, loss=0.1189, batch_acc=0.9688, running_acc=0.9842, grad=10.3141]Training epoch 45:  89%|████████▉ | 145/163 [02:47<00:21,  1.22s/it, loss=0.0748, batch_acc=1.0000, running_acc=0.9843, grad=6.5204] Training epoch 45:  90%|████████▉ | 146/163 [02:48<00:18,  1.12s/it, loss=0.0748, batch_acc=1.0000, running_acc=0.9843, grad=6.5204]Training epoch 45:  90%|████████▉ | 146/163 [02:48<00:18,  1.12s/it, loss=0.1256, batch_acc=0.9688, running_acc=0.9842, grad=12.1628]Training epoch 45:  90%|█████████ | 147/163 [02:49<00:16,  1.04s/it, loss=0.1256, batch_acc=0.9688, running_acc=0.9842, grad=12.1628]Training epoch 45:  90%|█████████ | 147/163 [02:49<00:16,  1.04s/it, loss=0.1214, batch_acc=0.9688, running_acc=0.9841, grad=11.4239]Training epoch 45:  91%|█████████ | 148/163 [02:50<00:16,  1.10s/it, loss=0.1214, batch_acc=0.9688, running_acc=0.9841, grad=11.4239]Training epoch 45:  91%|█████████ | 148/163 [02:50<00:16,  1.10s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9840, grad=8.4953] Training epoch 45:  91%|█████████▏| 149/163 [02:52<00:17,  1.27s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9840, grad=8.4953]Training epoch 45:  91%|█████████▏| 149/163 [02:52<00:17,  1.27s/it, loss=0.1358, batch_acc=0.9688, running_acc=0.9839, grad=10.9174]Training epoch 45:  92%|█████████▏| 150/163 [02:53<00:14,  1.15s/it, loss=0.1358, batch_acc=0.9688, running_acc=0.9839, grad=10.9174]Training epoch 45:  92%|█████████▏| 150/163 [02:53<00:14,  1.15s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9840, grad=8.2098] Training epoch 45:  93%|█████████▎| 151/163 [02:54<00:12,  1.07s/it, loss=0.1048, batch_acc=1.0000, running_acc=0.9840, grad=8.2098]Training epoch 45:  93%|█████████▎| 151/163 [02:54<00:12,  1.07s/it, loss=0.1012, batch_acc=0.9688, running_acc=0.9839, grad=9.5262]Training epoch 45:  93%|█████████▎| 152/163 [02:55<00:11,  1.06s/it, loss=0.1012, batch_acc=0.9688, running_acc=0.9839, grad=9.5262]Training epoch 45:  93%|█████████▎| 152/163 [02:55<00:11,  1.06s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9840, grad=7.8596]Training epoch 45:  94%|█████████▍| 153/163 [02:56<00:11,  1.11s/it, loss=0.1077, batch_acc=1.0000, running_acc=0.9840, grad=7.8596]Training epoch 45:  94%|█████████▍| 153/163 [02:56<00:11,  1.11s/it, loss=0.0897, batch_acc=1.0000, running_acc=0.9841, grad=9.1356]Training epoch 45:  94%|█████████▍| 154/163 [02:57<00:09,  1.04s/it, loss=0.0897, batch_acc=1.0000, running_acc=0.9841, grad=9.1356]Training epoch 45:  94%|█████████▍| 154/163 [02:57<00:09,  1.04s/it, loss=0.1047, batch_acc=0.9688, running_acc=0.9840, grad=5.3911]Training epoch 45:  95%|█████████▌| 155/163 [02:58<00:07,  1.01it/s, loss=0.1047, batch_acc=0.9688, running_acc=0.9840, grad=5.3911]Training epoch 45:  95%|█████████▌| 155/163 [02:58<00:07,  1.01it/s, loss=0.0997, batch_acc=0.9688, running_acc=0.9839, grad=7.0663]Training epoch 45:  96%|█████████▌| 156/163 [02:59<00:07,  1.06s/it, loss=0.0997, batch_acc=0.9688, running_acc=0.9839, grad=7.0663]Training epoch 45:  96%|█████████▌| 156/163 [02:59<00:07,  1.06s/it, loss=0.0722, batch_acc=1.0000, running_acc=0.9840, grad=8.3268]Training epoch 45:  96%|█████████▋| 157/163 [03:00<00:06,  1.10s/it, loss=0.0722, batch_acc=1.0000, running_acc=0.9840, grad=8.3268]Training epoch 45:  96%|█████████▋| 157/163 [03:00<00:06,  1.10s/it, loss=0.1602, batch_acc=0.9688, running_acc=0.9839, grad=12.4898]Training epoch 45:  97%|█████████▋| 158/163 [03:01<00:05,  1.03s/it, loss=0.1602, batch_acc=0.9688, running_acc=0.9839, grad=12.4898]Training epoch 45:  97%|█████████▋| 158/163 [03:01<00:05,  1.03s/it, loss=0.1363, batch_acc=0.9688, running_acc=0.9838, grad=11.5154]Training epoch 45:  98%|█████████▊| 159/163 [03:02<00:03,  1.02it/s, loss=0.1363, batch_acc=0.9688, running_acc=0.9838, grad=11.5154]Training epoch 45:  98%|█████████▊| 159/163 [03:02<00:03,  1.02it/s, loss=0.0837, batch_acc=1.0000, running_acc=0.9839, grad=6.5130] Training epoch 45:  98%|█████████▊| 160/163 [03:03<00:03,  1.15s/it, loss=0.0837, batch_acc=1.0000, running_acc=0.9839, grad=6.5130]Training epoch 45:  98%|█████████▊| 160/163 [03:03<00:03,  1.15s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9840, grad=8.4509]Training epoch 45:  99%|█████████▉| 161/163 [03:04<00:02,  1.07s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9840, grad=8.4509]Training epoch 45:  99%|█████████▉| 161/163 [03:04<00:02,  1.07s/it, loss=0.1253, batch_acc=0.9375, running_acc=0.9837, grad=9.3712]Training epoch 45:  99%|█████████▉| 162/163 [03:05<00:01,  1.01s/it, loss=0.1253, batch_acc=0.9375, running_acc=0.9837, grad=9.3712]Training epoch 45:  99%|█████████▉| 162/163 [03:05<00:01,  1.01s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9838, grad=8.5740]Training epoch 45: 100%|██████████| 163/163 [03:06<00:00,  1.11it/s, loss=0.1209, batch_acc=1.0000, running_acc=0.9838, grad=8.5740]Training epoch 45: 100%|██████████| 163/163 [03:06<00:00,  1.11it/s, loss=0.0717, batch_acc=1.0000, running_acc=0.9839, grad=5.0362]Training epoch 45: 100%|██████████| 163/163 [03:06<00:00,  1.14s/it, loss=0.0717, batch_acc=1.0000, running_acc=0.9839, grad=5.0362]
Evaluation epoch 45:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 45:   4%|▎         | 1/28 [00:05<02:16,  5.07s/it]Evaluation epoch 45:   4%|▎         | 1/28 [00:05<02:16,  5.07s/it, loss=0.3885, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 45:   7%|▋         | 2/28 [00:05<00:58,  2.24s/it, loss=0.3885, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 45:   7%|▋         | 2/28 [00:05<00:58,  2.24s/it, loss=0.2301, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 45:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.2301, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 45:  11%|█         | 3/28 [00:05<00:33,  1.34s/it, loss=0.2700, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 45:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.2700, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 45:  14%|█▍        | 4/28 [00:09<00:59,  2.48s/it, loss=0.4276, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 45:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=0.4276, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 45:  18%|█▊        | 5/28 [00:10<00:38,  1.68s/it, loss=1.2574, batch_acc=0.7500, running_acc=0.9062]Evaluation epoch 45:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=1.2574, batch_acc=0.7500, running_acc=0.9062]Evaluation epoch 45:  21%|██▏       | 6/28 [00:10<00:26,  1.20s/it, loss=0.5055, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 45:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.5055, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 45:  25%|██▌       | 7/28 [00:10<00:18,  1.12it/s, loss=0.5784, batch_acc=0.9375, running_acc=0.9107]Evaluation epoch 45:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.5784, batch_acc=0.9375, running_acc=0.9107]Evaluation epoch 45:  29%|██▊       | 8/28 [00:13<00:32,  1.64s/it, loss=0.3954, batch_acc=0.8438, running_acc=0.9023]Evaluation epoch 45:  32%|███▏      | 9/28 [00:14<00:25,  1.34s/it, loss=0.3954, batch_acc=0.8438, running_acc=0.9023]Evaluation epoch 45:  32%|███▏      | 9/28 [00:14<00:25,  1.34s/it, loss=0.4159, batch_acc=0.9062, running_acc=0.9028]Evaluation epoch 45:  36%|███▌      | 10/28 [00:14<00:18,  1.01s/it, loss=0.4159, batch_acc=0.9062, running_acc=0.9028]Evaluation epoch 45:  36%|███▌      | 10/28 [00:14<00:18,  1.01s/it, loss=0.4473, batch_acc=0.9062, running_acc=0.9031]Evaluation epoch 45:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=0.4473, batch_acc=0.9062, running_acc=0.9031]Evaluation epoch 45:  39%|███▉      | 11/28 [00:15<00:13,  1.28it/s, loss=0.3001, batch_acc=0.9688, running_acc=0.9091]Evaluation epoch 45:  43%|████▎     | 12/28 [00:20<00:34,  2.15s/it, loss=0.3001, batch_acc=0.9688, running_acc=0.9091]Evaluation epoch 45:  43%|████▎     | 12/28 [00:20<00:34,  2.15s/it, loss=0.9217, batch_acc=0.7812, running_acc=0.8984]Evaluation epoch 45:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.9217, batch_acc=0.7812, running_acc=0.8984]Evaluation epoch 45:  46%|████▋     | 13/28 [00:20<00:23,  1.58s/it, loss=0.2908, batch_acc=0.9375, running_acc=0.9014]Evaluation epoch 45:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.2908, batch_acc=0.9375, running_acc=0.9014]Evaluation epoch 45:  50%|█████     | 14/28 [00:20<00:16,  1.18s/it, loss=0.8557, batch_acc=0.7500, running_acc=0.8906]Evaluation epoch 45:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=0.8557, batch_acc=0.7500, running_acc=0.8906]Evaluation epoch 45:  54%|█████▎    | 15/28 [00:21<00:11,  1.11it/s, loss=0.9684, batch_acc=0.8438, running_acc=0.8875]Evaluation epoch 45:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=0.9684, batch_acc=0.8438, running_acc=0.8875]Evaluation epoch 45:  57%|█████▋    | 16/28 [00:24<00:18,  1.51s/it, loss=0.8083, batch_acc=0.7500, running_acc=0.8789]Evaluation epoch 45:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.8083, batch_acc=0.7500, running_acc=0.8789]Evaluation epoch 45:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.6582, batch_acc=0.7500, running_acc=0.8713]Evaluation epoch 45:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.6582, batch_acc=0.7500, running_acc=0.8713]Evaluation epoch 45:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5363, batch_acc=0.8750, running_acc=0.8715]Evaluation epoch 45:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.5363, batch_acc=0.8750, running_acc=0.8715]Evaluation epoch 45:  68%|██████▊   | 19/28 [00:24<00:06,  1.46it/s, loss=0.8521, batch_acc=0.6562, running_acc=0.8602]Evaluation epoch 45:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.8521, batch_acc=0.6562, running_acc=0.8602]Evaluation epoch 45:  71%|███████▏  | 20/28 [00:27<00:10,  1.35s/it, loss=0.5304, batch_acc=0.7188, running_acc=0.8531]Evaluation epoch 45:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5304, batch_acc=0.7188, running_acc=0.8531]Evaluation epoch 45:  75%|███████▌  | 21/28 [00:28<00:07,  1.03s/it, loss=0.5446, batch_acc=0.8125, running_acc=0.8512]Evaluation epoch 45:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.5446, batch_acc=0.8125, running_acc=0.8512]Evaluation epoch 45:  79%|███████▊  | 22/28 [00:28<00:04,  1.25it/s, loss=0.4207, batch_acc=0.9688, running_acc=0.8565]Evaluation epoch 45:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=0.4207, batch_acc=0.9688, running_acc=0.8565]Evaluation epoch 45:  82%|████████▏ | 23/28 [00:28<00:03,  1.57it/s, loss=0.8114, batch_acc=0.7812, running_acc=0.8533]Evaluation epoch 45:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=0.8114, batch_acc=0.7812, running_acc=0.8533]Evaluation epoch 45:  86%|████████▌ | 24/28 [00:33<00:08,  2.00s/it, loss=0.2910, batch_acc=0.9375, running_acc=0.8568]Evaluation epoch 45:  89%|████████▉ | 25/28 [00:33<00:04,  1.48s/it, loss=0.2910, batch_acc=0.9375, running_acc=0.8568]Evaluation epoch 45:  89%|████████▉ | 25/28 [00:33<00:04,  1.48s/it, loss=0.1221, batch_acc=1.0000, running_acc=0.8625]Evaluation epoch 45:  93%|█████████▎| 26/28 [00:34<00:02,  1.11s/it, loss=0.1221, batch_acc=1.0000, running_acc=0.8625]Evaluation epoch 45:  93%|█████████▎| 26/28 [00:34<00:02,  1.11s/it, loss=0.5500, batch_acc=0.8438, running_acc=0.8618]Evaluation epoch 45:  96%|█████████▋| 27/28 [00:34<00:00,  1.17it/s, loss=0.5500, batch_acc=0.8438, running_acc=0.8618]Evaluation epoch 45:  96%|█████████▋| 27/28 [00:34<00:00,  1.17it/s, loss=0.9033, batch_acc=0.7188, running_acc=0.8565]Evaluation epoch 45: 100%|██████████| 28/28 [00:34<00:00,  1.17it/s, loss=1.1033, batch_acc=0.6667, running_acc=0.8558]Evaluation epoch 45: 100%|██████████| 28/28 [00:34<00:00,  1.23s/it, loss=1.1033, batch_acc=0.6667, running_acc=0.8558]
Training epoch 46:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 46:   1%|          | 1/163 [00:06<16:40,  6.17s/it]Training epoch 46:   1%|          | 1/163 [00:06<16:40,  6.17s/it, loss=0.0900, batch_acc=1.0000, running_acc=1.0000, grad=6.6203]Training epoch 46:   1%|          | 2/163 [00:07<08:12,  3.06s/it, loss=0.0900, batch_acc=1.0000, running_acc=1.0000, grad=6.6203]Training epoch 46:   1%|          | 2/163 [00:07<08:12,  3.06s/it, loss=0.0743, batch_acc=1.0000, running_acc=1.0000, grad=5.8956]Training epoch 46:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=0.0743, batch_acc=1.0000, running_acc=1.0000, grad=5.8956]Training epoch 46:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=0.1114, batch_acc=1.0000, running_acc=1.0000, grad=8.1425]Training epoch 46:   2%|▏         | 4/163 [00:10<05:58,  2.25s/it, loss=0.1114, batch_acc=1.0000, running_acc=1.0000, grad=8.1425]Training epoch 46:   2%|▏         | 4/163 [00:10<05:58,  2.25s/it, loss=0.0846, batch_acc=1.0000, running_acc=1.0000, grad=6.4651]Training epoch 46:   3%|▎         | 5/163 [00:11<04:37,  1.76s/it, loss=0.0846, batch_acc=1.0000, running_acc=1.0000, grad=6.4651]Training epoch 46:   3%|▎         | 5/163 [00:11<04:37,  1.76s/it, loss=0.0915, batch_acc=1.0000, running_acc=1.0000, grad=7.5885]Training epoch 46:   4%|▎         | 6/163 [00:12<03:48,  1.46s/it, loss=0.0915, batch_acc=1.0000, running_acc=1.0000, grad=7.5885]Training epoch 46:   4%|▎         | 6/163 [00:12<03:48,  1.46s/it, loss=0.1409, batch_acc=0.9375, running_acc=0.9896, grad=9.5700]Training epoch 46:   4%|▍         | 7/163 [00:13<03:17,  1.27s/it, loss=0.1409, batch_acc=0.9375, running_acc=0.9896, grad=9.5700]Training epoch 46:   4%|▍         | 7/163 [00:13<03:17,  1.27s/it, loss=0.0932, batch_acc=0.9688, running_acc=0.9866, grad=5.4011]Training epoch 46:   5%|▍         | 8/163 [00:15<03:53,  1.51s/it, loss=0.0932, batch_acc=0.9688, running_acc=0.9866, grad=5.4011]Training epoch 46:   5%|▍         | 8/163 [00:15<03:53,  1.51s/it, loss=0.1251, batch_acc=1.0000, running_acc=0.9883, grad=8.9711]Training epoch 46:   6%|▌         | 9/163 [00:16<03:21,  1.31s/it, loss=0.1251, batch_acc=1.0000, running_acc=0.9883, grad=8.9711]Training epoch 46:   6%|▌         | 9/163 [00:16<03:21,  1.31s/it, loss=0.0907, batch_acc=0.9688, running_acc=0.9861, grad=8.0205]Training epoch 46:   6%|▌         | 10/163 [00:16<03:00,  1.18s/it, loss=0.0907, batch_acc=0.9688, running_acc=0.9861, grad=8.0205]Training epoch 46:   6%|▌         | 10/163 [00:16<03:00,  1.18s/it, loss=0.0780, batch_acc=1.0000, running_acc=0.9875, grad=7.4422]Training epoch 46:   7%|▋         | 11/163 [00:17<02:45,  1.09s/it, loss=0.0780, batch_acc=1.0000, running_acc=0.9875, grad=7.4422]Training epoch 46:   7%|▋         | 11/163 [00:17<02:45,  1.09s/it, loss=0.0875, batch_acc=1.0000, running_acc=0.9886, grad=11.4156]Training epoch 46:   7%|▋         | 12/163 [00:19<03:03,  1.22s/it, loss=0.0875, batch_acc=1.0000, running_acc=0.9886, grad=11.4156]Training epoch 46:   7%|▋         | 12/163 [00:19<03:03,  1.22s/it, loss=0.0739, batch_acc=1.0000, running_acc=0.9896, grad=7.6638] Training epoch 46:   8%|▊         | 13/163 [00:20<02:47,  1.11s/it, loss=0.0739, batch_acc=1.0000, running_acc=0.9896, grad=7.6638]Training epoch 46:   8%|▊         | 13/163 [00:20<02:47,  1.11s/it, loss=0.1526, batch_acc=1.0000, running_acc=0.9904, grad=11.0933]Training epoch 46:   9%|▊         | 14/163 [00:21<02:35,  1.04s/it, loss=0.1526, batch_acc=1.0000, running_acc=0.9904, grad=11.0933]Training epoch 46:   9%|▊         | 14/163 [00:21<02:35,  1.04s/it, loss=0.0827, batch_acc=1.0000, running_acc=0.9911, grad=10.8670]Training epoch 46:   9%|▉         | 15/163 [00:21<02:27,  1.01it/s, loss=0.0827, batch_acc=1.0000, running_acc=0.9911, grad=10.8670]Training epoch 46:   9%|▉         | 15/163 [00:21<02:27,  1.01it/s, loss=0.1087, batch_acc=1.0000, running_acc=0.9917, grad=8.6199] Training epoch 46:  10%|▉         | 16/163 [00:23<03:13,  1.32s/it, loss=0.1087, batch_acc=1.0000, running_acc=0.9917, grad=8.6199]Training epoch 46:  10%|▉         | 16/163 [00:23<03:13,  1.32s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9922, grad=6.2020]Training epoch 46:  10%|█         | 17/163 [00:24<02:52,  1.18s/it, loss=0.0891, batch_acc=1.0000, running_acc=0.9922, grad=6.2020]Training epoch 46:  10%|█         | 17/163 [00:24<02:52,  1.18s/it, loss=0.0869, batch_acc=1.0000, running_acc=0.9926, grad=7.2193]Training epoch 46:  11%|█         | 18/163 [00:25<02:38,  1.09s/it, loss=0.0869, batch_acc=1.0000, running_acc=0.9926, grad=7.2193]Training epoch 46:  11%|█         | 18/163 [00:25<02:38,  1.09s/it, loss=0.1132, batch_acc=0.9688, running_acc=0.9913, grad=7.2905]Training epoch 46:  12%|█▏        | 19/163 [00:26<02:27,  1.03s/it, loss=0.1132, batch_acc=0.9688, running_acc=0.9913, grad=7.2905]Training epoch 46:  12%|█▏        | 19/163 [00:26<02:27,  1.03s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9918, grad=10.9674]Training epoch 46:  12%|█▏        | 20/163 [00:28<03:03,  1.28s/it, loss=0.0985, batch_acc=1.0000, running_acc=0.9918, grad=10.9674]Training epoch 46:  12%|█▏        | 20/163 [00:28<03:03,  1.28s/it, loss=0.1124, batch_acc=0.9688, running_acc=0.9906, grad=8.0028] Training epoch 46:  13%|█▎        | 21/163 [00:29<02:44,  1.16s/it, loss=0.1124, batch_acc=0.9688, running_acc=0.9906, grad=8.0028]Training epoch 46:  13%|█▎        | 21/163 [00:29<02:44,  1.16s/it, loss=0.1488, batch_acc=0.9688, running_acc=0.9896, grad=18.5468]Training epoch 46:  13%|█▎        | 22/163 [00:30<02:31,  1.08s/it, loss=0.1488, batch_acc=0.9688, running_acc=0.9896, grad=18.5468]Training epoch 46:  13%|█▎        | 22/163 [00:30<02:31,  1.08s/it, loss=0.0968, batch_acc=1.0000, running_acc=0.9901, grad=7.3948] Training epoch 46:  14%|█▍        | 23/163 [00:31<02:22,  1.02s/it, loss=0.0968, batch_acc=1.0000, running_acc=0.9901, grad=7.3948]Training epoch 46:  14%|█▍        | 23/163 [00:31<02:22,  1.02s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9905, grad=9.3100]Training epoch 46:  15%|█▍        | 24/163 [00:33<02:57,  1.28s/it, loss=0.0949, batch_acc=1.0000, running_acc=0.9905, grad=9.3100]Training epoch 46:  15%|█▍        | 24/163 [00:33<02:57,  1.28s/it, loss=0.0967, batch_acc=1.0000, running_acc=0.9909, grad=7.6250]Training epoch 46:  15%|█▌        | 25/163 [00:33<02:39,  1.16s/it, loss=0.0967, batch_acc=1.0000, running_acc=0.9909, grad=7.6250]Training epoch 46:  15%|█▌        | 25/163 [00:33<02:39,  1.16s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9912, grad=7.4682]Training epoch 46:  16%|█▌        | 26/163 [00:34<02:26,  1.07s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9912, grad=7.4682]Training epoch 46:  16%|█▌        | 26/163 [00:34<02:26,  1.07s/it, loss=0.1065, batch_acc=0.9688, running_acc=0.9904, grad=10.3077]Training epoch 46:  17%|█▋        | 27/163 [00:35<02:18,  1.02s/it, loss=0.1065, batch_acc=0.9688, running_acc=0.9904, grad=10.3077]Training epoch 46:  17%|█▋        | 27/163 [00:35<02:18,  1.02s/it, loss=0.0940, batch_acc=0.9688, running_acc=0.9896, grad=8.9078] Training epoch 46:  17%|█▋        | 28/163 [00:37<03:08,  1.39s/it, loss=0.0940, batch_acc=0.9688, running_acc=0.9896, grad=8.9078]Training epoch 46:  17%|█▋        | 28/163 [00:37<03:08,  1.39s/it, loss=0.1261, batch_acc=0.9375, running_acc=0.9877, grad=10.9063]Training epoch 46:  18%|█▊        | 29/163 [00:38<02:46,  1.24s/it, loss=0.1261, batch_acc=0.9375, running_acc=0.9877, grad=10.9063]Training epoch 46:  18%|█▊        | 29/163 [00:38<02:46,  1.24s/it, loss=0.0975, batch_acc=0.9688, running_acc=0.9871, grad=7.7514] Training epoch 46:  18%|█▊        | 30/163 [00:39<02:30,  1.13s/it, loss=0.0975, batch_acc=0.9688, running_acc=0.9871, grad=7.7514]Training epoch 46:  18%|█▊        | 30/163 [00:39<02:30,  1.13s/it, loss=0.0749, batch_acc=1.0000, running_acc=0.9875, grad=7.6830]Training epoch 46:  19%|█▉        | 31/163 [00:40<02:19,  1.05s/it, loss=0.0749, batch_acc=1.0000, running_acc=0.9875, grad=7.6830]Training epoch 46:  19%|█▉        | 31/163 [00:40<02:19,  1.05s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9869, grad=13.1776]Training epoch 46:  20%|█▉        | 32/163 [00:42<02:50,  1.30s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9869, grad=13.1776]Training epoch 46:  20%|█▉        | 32/163 [00:42<02:50,  1.30s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9873, grad=6.9207] Training epoch 46:  20%|██        | 33/163 [00:43<02:32,  1.17s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9873, grad=6.9207]Training epoch 46:  20%|██        | 33/163 [00:43<02:32,  1.17s/it, loss=0.1102, batch_acc=0.9688, running_acc=0.9867, grad=8.6521]Training epoch 46:  21%|██        | 34/163 [00:44<02:20,  1.09s/it, loss=0.1102, batch_acc=0.9688, running_acc=0.9867, grad=8.6521]Training epoch 46:  21%|██        | 34/163 [00:44<02:20,  1.09s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9871, grad=7.1468]Training epoch 46:  21%|██▏       | 35/163 [00:45<02:10,  1.02s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9871, grad=7.1468]Training epoch 46:  21%|██▏       | 35/163 [00:45<02:10,  1.02s/it, loss=0.1040, batch_acc=0.9688, running_acc=0.9866, grad=11.4790]Training epoch 46:  22%|██▏       | 36/163 [00:46<02:33,  1.21s/it, loss=0.1040, batch_acc=0.9688, running_acc=0.9866, grad=11.4790]Training epoch 46:  22%|██▏       | 36/163 [00:46<02:33,  1.21s/it, loss=0.1524, batch_acc=0.9375, running_acc=0.9852, grad=9.4482] Training epoch 46:  23%|██▎       | 37/163 [00:47<02:19,  1.11s/it, loss=0.1524, batch_acc=0.9375, running_acc=0.9852, grad=9.4482]Training epoch 46:  23%|██▎       | 37/163 [00:47<02:19,  1.11s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9856, grad=7.1897]Training epoch 46:  23%|██▎       | 38/163 [00:48<02:10,  1.04s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9856, grad=7.1897]Training epoch 46:  23%|██▎       | 38/163 [00:48<02:10,  1.04s/it, loss=0.0797, batch_acc=1.0000, running_acc=0.9860, grad=7.1556]Training epoch 46:  24%|██▍       | 39/163 [00:49<02:02,  1.01it/s, loss=0.0797, batch_acc=1.0000, running_acc=0.9860, grad=7.1556]Training epoch 46:  24%|██▍       | 39/163 [00:49<02:02,  1.01it/s, loss=0.0652, batch_acc=1.0000, running_acc=0.9864, grad=5.3011]Training epoch 46:  25%|██▍       | 40/163 [00:50<02:17,  1.12s/it, loss=0.0652, batch_acc=1.0000, running_acc=0.9864, grad=5.3011]Training epoch 46:  25%|██▍       | 40/163 [00:50<02:17,  1.12s/it, loss=0.1004, batch_acc=1.0000, running_acc=0.9867, grad=6.2395]Training epoch 46:  25%|██▌       | 41/163 [00:51<02:07,  1.05s/it, loss=0.1004, batch_acc=1.0000, running_acc=0.9867, grad=6.2395]Training epoch 46:  25%|██▌       | 41/163 [00:51<02:07,  1.05s/it, loss=0.1281, batch_acc=1.0000, running_acc=0.9870, grad=14.5053]Training epoch 46:  26%|██▌       | 42/163 [00:52<02:00,  1.00it/s, loss=0.1281, batch_acc=1.0000, running_acc=0.9870, grad=14.5053]Training epoch 46:  26%|██▌       | 42/163 [00:52<02:00,  1.00it/s, loss=0.1444, batch_acc=0.9688, running_acc=0.9866, grad=12.2645]Training epoch 46:  26%|██▋       | 43/163 [00:53<01:55,  1.04it/s, loss=0.1444, batch_acc=0.9688, running_acc=0.9866, grad=12.2645]Training epoch 46:  26%|██▋       | 43/163 [00:53<01:55,  1.04it/s, loss=0.0977, batch_acc=0.9688, running_acc=0.9862, grad=7.4918] Training epoch 46:  27%|██▋       | 44/163 [00:55<02:42,  1.37s/it, loss=0.0977, batch_acc=0.9688, running_acc=0.9862, grad=7.4918]Training epoch 46:  27%|██▋       | 44/163 [00:55<02:42,  1.37s/it, loss=0.1444, batch_acc=1.0000, running_acc=0.9865, grad=19.3058]Training epoch 46:  28%|██▊       | 45/163 [00:56<02:23,  1.22s/it, loss=0.1444, batch_acc=1.0000, running_acc=0.9865, grad=19.3058]Training epoch 46:  28%|██▊       | 45/163 [00:56<02:23,  1.22s/it, loss=0.0936, batch_acc=0.9688, running_acc=0.9861, grad=5.0298] Training epoch 46:  28%|██▊       | 46/163 [00:57<02:10,  1.12s/it, loss=0.0936, batch_acc=0.9688, running_acc=0.9861, grad=5.0298]Training epoch 46:  28%|██▊       | 46/163 [00:57<02:10,  1.12s/it, loss=0.1292, batch_acc=0.9688, running_acc=0.9857, grad=13.1347]Training epoch 46:  29%|██▉       | 47/163 [00:58<02:01,  1.04s/it, loss=0.1292, batch_acc=0.9688, running_acc=0.9857, grad=13.1347]Training epoch 46:  29%|██▉       | 47/163 [00:58<02:01,  1.04s/it, loss=0.1286, batch_acc=0.9688, running_acc=0.9854, grad=17.1884]Training epoch 46:  29%|██▉       | 48/163 [01:00<02:45,  1.44s/it, loss=0.1286, batch_acc=0.9688, running_acc=0.9854, grad=17.1884]Training epoch 46:  29%|██▉       | 48/163 [01:00<02:45,  1.44s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9850, grad=9.8078] Training epoch 46:  30%|███       | 49/163 [01:01<02:24,  1.27s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9850, grad=9.8078]Training epoch 46:  30%|███       | 49/163 [01:01<02:24,  1.27s/it, loss=0.1039, batch_acc=1.0000, running_acc=0.9853, grad=9.1960]Training epoch 46:  31%|███       | 50/163 [01:02<02:10,  1.15s/it, loss=0.1039, batch_acc=1.0000, running_acc=0.9853, grad=9.1960]Training epoch 46:  31%|███       | 50/163 [01:02<02:10,  1.15s/it, loss=0.0993, batch_acc=1.0000, running_acc=0.9856, grad=7.3817]Training epoch 46:  31%|███▏      | 51/163 [01:03<01:59,  1.07s/it, loss=0.0993, batch_acc=1.0000, running_acc=0.9856, grad=7.3817]Training epoch 46:  31%|███▏      | 51/163 [01:03<01:59,  1.07s/it, loss=0.1283, batch_acc=1.0000, running_acc=0.9859, grad=10.8467]Training epoch 46:  32%|███▏      | 52/163 [01:05<02:44,  1.48s/it, loss=0.1283, batch_acc=1.0000, running_acc=0.9859, grad=10.8467]Training epoch 46:  32%|███▏      | 52/163 [01:05<02:44,  1.48s/it, loss=0.0832, batch_acc=0.9688, running_acc=0.9856, grad=6.9236] Training epoch 46:  33%|███▎      | 53/163 [01:06<02:22,  1.30s/it, loss=0.0832, batch_acc=0.9688, running_acc=0.9856, grad=6.9236]Training epoch 46:  33%|███▎      | 53/163 [01:06<02:22,  1.30s/it, loss=0.0726, batch_acc=1.0000, running_acc=0.9858, grad=4.8449]Training epoch 46:  33%|███▎      | 54/163 [01:07<02:07,  1.17s/it, loss=0.0726, batch_acc=1.0000, running_acc=0.9858, grad=4.8449]Training epoch 46:  33%|███▎      | 54/163 [01:07<02:07,  1.17s/it, loss=0.0989, batch_acc=0.9688, running_acc=0.9855, grad=6.9798]Training epoch 46:  34%|███▎      | 55/163 [01:08<01:56,  1.08s/it, loss=0.0989, batch_acc=0.9688, running_acc=0.9855, grad=6.9798]Training epoch 46:  34%|███▎      | 55/163 [01:08<01:56,  1.08s/it, loss=0.0578, batch_acc=1.0000, running_acc=0.9858, grad=4.8258]Training epoch 46:  34%|███▍      | 56/163 [01:10<02:28,  1.38s/it, loss=0.0578, batch_acc=1.0000, running_acc=0.9858, grad=4.8258]Training epoch 46:  34%|███▍      | 56/163 [01:10<02:28,  1.38s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9860, grad=7.2783]Training epoch 46:  35%|███▍      | 57/163 [01:11<02:10,  1.23s/it, loss=0.0820, batch_acc=1.0000, running_acc=0.9860, grad=7.2783]Training epoch 46:  35%|███▍      | 57/163 [01:11<02:10,  1.23s/it, loss=0.1604, batch_acc=1.0000, running_acc=0.9863, grad=20.4492]Training epoch 46:  36%|███▌      | 58/163 [01:12<01:58,  1.13s/it, loss=0.1604, batch_acc=1.0000, running_acc=0.9863, grad=20.4492]Training epoch 46:  36%|███▌      | 58/163 [01:12<01:58,  1.13s/it, loss=0.1428, batch_acc=0.9375, running_acc=0.9855, grad=9.1324] Training epoch 46:  36%|███▌      | 59/163 [01:13<01:49,  1.05s/it, loss=0.1428, batch_acc=0.9375, running_acc=0.9855, grad=9.1324]Training epoch 46:  36%|███▌      | 59/163 [01:13<01:49,  1.05s/it, loss=0.1316, batch_acc=0.9688, running_acc=0.9852, grad=8.9185]Training epoch 46:  37%|███▋      | 60/163 [01:15<02:25,  1.41s/it, loss=0.1316, batch_acc=0.9688, running_acc=0.9852, grad=8.9185]Training epoch 46:  37%|███▋      | 60/163 [01:15<02:25,  1.41s/it, loss=0.1096, batch_acc=0.9688, running_acc=0.9849, grad=4.9937]Training epoch 46:  37%|███▋      | 61/163 [01:16<02:07,  1.25s/it, loss=0.1096, batch_acc=0.9688, running_acc=0.9849, grad=4.9937]Training epoch 46:  37%|███▋      | 61/163 [01:16<02:07,  1.25s/it, loss=0.1248, batch_acc=0.9688, running_acc=0.9846, grad=12.4409]Training epoch 46:  38%|███▊      | 62/163 [01:17<01:55,  1.14s/it, loss=0.1248, batch_acc=0.9688, running_acc=0.9846, grad=12.4409]Training epoch 46:  38%|███▊      | 62/163 [01:17<01:55,  1.14s/it, loss=0.1507, batch_acc=1.0000, running_acc=0.9849, grad=12.6546]Training epoch 46:  39%|███▊      | 63/163 [01:17<01:46,  1.06s/it, loss=0.1507, batch_acc=1.0000, running_acc=0.9849, grad=12.6546]Training epoch 46:  39%|███▊      | 63/163 [01:17<01:46,  1.06s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9851, grad=7.5186] Training epoch 46:  39%|███▉      | 64/163 [01:20<02:15,  1.37s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9851, grad=7.5186]Training epoch 46:  39%|███▉      | 64/163 [01:20<02:15,  1.37s/it, loss=0.0608, batch_acc=1.0000, running_acc=0.9854, grad=6.0505]Training epoch 46:  40%|███▉      | 65/163 [01:20<01:59,  1.22s/it, loss=0.0608, batch_acc=1.0000, running_acc=0.9854, grad=6.0505]Training epoch 46:  40%|███▉      | 65/163 [01:20<01:59,  1.22s/it, loss=0.1329, batch_acc=0.9688, running_acc=0.9851, grad=10.3202]Training epoch 46:  40%|████      | 66/163 [01:21<01:48,  1.12s/it, loss=0.1329, batch_acc=0.9688, running_acc=0.9851, grad=10.3202]Training epoch 46:  40%|████      | 66/163 [01:21<01:48,  1.12s/it, loss=0.1137, batch_acc=0.9688, running_acc=0.9848, grad=8.9934] Training epoch 46:  41%|████      | 67/163 [01:22<01:40,  1.05s/it, loss=0.1137, batch_acc=0.9688, running_acc=0.9848, grad=8.9934]Training epoch 46:  41%|████      | 67/163 [01:22<01:40,  1.05s/it, loss=0.1237, batch_acc=0.9688, running_acc=0.9846, grad=9.1492]Training epoch 46:  42%|████▏     | 68/163 [01:24<01:57,  1.24s/it, loss=0.1237, batch_acc=0.9688, running_acc=0.9846, grad=9.1492]Training epoch 46:  42%|████▏     | 68/163 [01:24<01:57,  1.24s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9848, grad=6.2039]Training epoch 46:  42%|████▏     | 69/163 [01:25<01:46,  1.13s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9848, grad=6.2039]Training epoch 46:  42%|████▏     | 69/163 [01:25<01:46,  1.13s/it, loss=0.0711, batch_acc=0.9688, running_acc=0.9846, grad=5.3315]Training epoch 46:  43%|████▎     | 70/163 [01:26<01:38,  1.06s/it, loss=0.0711, batch_acc=0.9688, running_acc=0.9846, grad=5.3315]Training epoch 46:  43%|████▎     | 70/163 [01:26<01:38,  1.06s/it, loss=0.1302, batch_acc=0.9688, running_acc=0.9844, grad=9.2415]Training epoch 46:  44%|████▎     | 71/163 [01:27<01:32,  1.00s/it, loss=0.1302, batch_acc=0.9688, running_acc=0.9844, grad=9.2415]Training epoch 46:  44%|████▎     | 71/163 [01:27<01:32,  1.00s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9846, grad=9.8804]Training epoch 46:  44%|████▍     | 72/163 [01:29<02:03,  1.35s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9846, grad=9.8804]Training epoch 46:  44%|████▍     | 72/163 [01:29<02:03,  1.35s/it, loss=0.0613, batch_acc=1.0000, running_acc=0.9848, grad=4.7566]Training epoch 46:  45%|████▍     | 73/163 [01:30<01:48,  1.21s/it, loss=0.0613, batch_acc=1.0000, running_acc=0.9848, grad=4.7566]Training epoch 46:  45%|████▍     | 73/163 [01:30<01:48,  1.21s/it, loss=0.1040, batch_acc=0.9688, running_acc=0.9846, grad=8.1357]Training epoch 46:  45%|████▌     | 74/163 [01:30<01:38,  1.11s/it, loss=0.1040, batch_acc=0.9688, running_acc=0.9846, grad=8.1357]Training epoch 46:  45%|████▌     | 74/163 [01:30<01:38,  1.11s/it, loss=0.1180, batch_acc=1.0000, running_acc=0.9848, grad=11.8022]Training epoch 46:  46%|████▌     | 75/163 [01:31<01:31,  1.04s/it, loss=0.1180, batch_acc=1.0000, running_acc=0.9848, grad=11.8022]Training epoch 46:  46%|████▌     | 75/163 [01:31<01:31,  1.04s/it, loss=0.0660, batch_acc=1.0000, running_acc=0.9850, grad=4.4614] Training epoch 46:  47%|████▋     | 76/163 [01:33<01:51,  1.28s/it, loss=0.0660, batch_acc=1.0000, running_acc=0.9850, grad=4.4614]Training epoch 46:  47%|████▋     | 76/163 [01:33<01:51,  1.28s/it, loss=0.0904, batch_acc=1.0000, running_acc=0.9852, grad=7.6340]Training epoch 46:  47%|████▋     | 77/163 [01:34<01:39,  1.16s/it, loss=0.0904, batch_acc=1.0000, running_acc=0.9852, grad=7.6340]Training epoch 46:  47%|████▋     | 77/163 [01:34<01:39,  1.16s/it, loss=0.0872, batch_acc=1.0000, running_acc=0.9854, grad=6.2734]Training epoch 46:  48%|████▊     | 78/163 [01:35<01:31,  1.08s/it, loss=0.0872, batch_acc=1.0000, running_acc=0.9854, grad=6.2734]Training epoch 46:  48%|████▊     | 78/163 [01:35<01:31,  1.08s/it, loss=0.0881, batch_acc=1.0000, running_acc=0.9856, grad=6.6044]Training epoch 46:  48%|████▊     | 79/163 [01:36<01:25,  1.02s/it, loss=0.0881, batch_acc=1.0000, running_acc=0.9856, grad=6.6044]Training epoch 46:  48%|████▊     | 79/163 [01:36<01:25,  1.02s/it, loss=0.0778, batch_acc=1.0000, running_acc=0.9858, grad=7.6971]Training epoch 46:  49%|████▉     | 80/163 [01:38<01:44,  1.27s/it, loss=0.0778, batch_acc=1.0000, running_acc=0.9858, grad=7.6971]Training epoch 46:  49%|████▉     | 80/163 [01:38<01:44,  1.27s/it, loss=0.1002, batch_acc=1.0000, running_acc=0.9859, grad=7.0550]Training epoch 46:  50%|████▉     | 81/163 [01:39<01:34,  1.15s/it, loss=0.1002, batch_acc=1.0000, running_acc=0.9859, grad=7.0550]Training epoch 46:  50%|████▉     | 81/163 [01:39<01:34,  1.15s/it, loss=0.0585, batch_acc=1.0000, running_acc=0.9861, grad=4.4466]Training epoch 46:  50%|█████     | 82/163 [01:39<01:26,  1.07s/it, loss=0.0585, batch_acc=1.0000, running_acc=0.9861, grad=4.4466]Training epoch 46:  50%|█████     | 82/163 [01:39<01:26,  1.07s/it, loss=0.1007, batch_acc=1.0000, running_acc=0.9863, grad=8.2523]Training epoch 46:  51%|█████     | 83/163 [01:40<01:20,  1.01s/it, loss=0.1007, batch_acc=1.0000, running_acc=0.9863, grad=8.2523]Training epoch 46:  51%|█████     | 83/163 [01:40<01:20,  1.01s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9864, grad=5.5691]Training epoch 46:  52%|█████▏    | 84/163 [01:42<01:36,  1.22s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9864, grad=5.5691]Training epoch 46:  52%|█████▏    | 84/163 [01:42<01:36,  1.22s/it, loss=0.1109, batch_acc=0.9688, running_acc=0.9862, grad=8.6415]Training epoch 46:  52%|█████▏    | 85/163 [01:43<01:26,  1.11s/it, loss=0.1109, batch_acc=0.9688, running_acc=0.9862, grad=8.6415]Training epoch 46:  52%|█████▏    | 85/163 [01:43<01:26,  1.11s/it, loss=0.1182, batch_acc=1.0000, running_acc=0.9864, grad=7.2072]Training epoch 46:  53%|█████▎    | 86/163 [01:44<01:20,  1.04s/it, loss=0.1182, batch_acc=1.0000, running_acc=0.9864, grad=7.2072]Training epoch 46:  53%|█████▎    | 86/163 [01:44<01:20,  1.04s/it, loss=0.1665, batch_acc=0.9688, running_acc=0.9862, grad=15.2041]Training epoch 46:  53%|█████▎    | 87/163 [01:45<01:15,  1.01it/s, loss=0.1665, batch_acc=0.9688, running_acc=0.9862, grad=15.2041]Training epoch 46:  53%|█████▎    | 87/163 [01:45<01:15,  1.01it/s, loss=0.1788, batch_acc=0.9375, running_acc=0.9856, grad=14.5147]Training epoch 46:  54%|█████▍    | 88/163 [01:46<01:19,  1.06s/it, loss=0.1788, batch_acc=0.9375, running_acc=0.9856, grad=14.5147]Training epoch 46:  54%|█████▍    | 88/163 [01:46<01:19,  1.06s/it, loss=0.1076, batch_acc=1.0000, running_acc=0.9858, grad=6.2366] Training epoch 46:  55%|█████▍    | 89/163 [01:47<01:14,  1.01s/it, loss=0.1076, batch_acc=1.0000, running_acc=0.9858, grad=6.2366]Training epoch 46:  55%|█████▍    | 89/163 [01:47<01:14,  1.01s/it, loss=0.1453, batch_acc=0.9062, running_acc=0.9849, grad=8.5428]Training epoch 46:  55%|█████▌    | 90/163 [01:48<01:10,  1.03it/s, loss=0.1453, batch_acc=0.9062, running_acc=0.9849, grad=8.5428]Training epoch 46:  55%|█████▌    | 90/163 [01:48<01:10,  1.03it/s, loss=0.1057, batch_acc=0.9688, running_acc=0.9847, grad=9.2446]Training epoch 46:  56%|█████▌    | 91/163 [01:48<01:07,  1.06it/s, loss=0.1057, batch_acc=0.9688, running_acc=0.9847, grad=9.2446]Training epoch 46:  56%|█████▌    | 91/163 [01:48<01:07,  1.06it/s, loss=0.1308, batch_acc=0.9688, running_acc=0.9845, grad=9.6918]Training epoch 46:  56%|█████▋    | 92/163 [01:50<01:15,  1.07s/it, loss=0.1308, batch_acc=0.9688, running_acc=0.9845, grad=9.6918]Training epoch 46:  56%|█████▋    | 92/163 [01:50<01:15,  1.07s/it, loss=0.1132, batch_acc=1.0000, running_acc=0.9847, grad=10.0486]Training epoch 46:  57%|█████▋    | 93/163 [01:51<01:10,  1.01s/it, loss=0.1132, batch_acc=1.0000, running_acc=0.9847, grad=10.0486]Training epoch 46:  57%|█████▋    | 93/163 [01:51<01:10,  1.01s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9849, grad=9.5565] Training epoch 46:  58%|█████▊    | 94/163 [01:52<01:06,  1.03it/s, loss=0.1093, batch_acc=1.0000, running_acc=0.9849, grad=9.5565]Training epoch 46:  58%|█████▊    | 94/163 [01:52<01:06,  1.03it/s, loss=0.0777, batch_acc=1.0000, running_acc=0.9850, grad=6.3643]Training epoch 46:  58%|█████▊    | 95/163 [01:52<01:04,  1.06it/s, loss=0.0777, batch_acc=1.0000, running_acc=0.9850, grad=6.3643]Training epoch 46:  58%|█████▊    | 95/163 [01:52<01:04,  1.06it/s, loss=0.0656, batch_acc=1.0000, running_acc=0.9852, grad=6.5922]Training epoch 46:  59%|█████▉    | 96/163 [01:54<01:12,  1.09s/it, loss=0.0656, batch_acc=1.0000, running_acc=0.9852, grad=6.5922]Training epoch 46:  59%|█████▉    | 96/163 [01:54<01:12,  1.09s/it, loss=0.0903, batch_acc=1.0000, running_acc=0.9854, grad=7.4321]Training epoch 46:  60%|█████▉    | 97/163 [01:55<01:07,  1.02s/it, loss=0.0903, batch_acc=1.0000, running_acc=0.9854, grad=7.4321]Training epoch 46:  60%|█████▉    | 97/163 [01:55<01:07,  1.02s/it, loss=0.0740, batch_acc=1.0000, running_acc=0.9855, grad=9.8026]Training epoch 46:  60%|██████    | 98/163 [01:56<01:03,  1.02it/s, loss=0.0740, batch_acc=1.0000, running_acc=0.9855, grad=9.8026]Training epoch 46:  60%|██████    | 98/163 [01:56<01:03,  1.02it/s, loss=0.1320, batch_acc=0.9688, running_acc=0.9853, grad=12.0519]Training epoch 46:  61%|██████    | 99/163 [01:57<01:00,  1.05it/s, loss=0.1320, batch_acc=0.9688, running_acc=0.9853, grad=12.0519]Training epoch 46:  61%|██████    | 99/163 [01:57<01:00,  1.05it/s, loss=0.0818, batch_acc=1.0000, running_acc=0.9855, grad=6.9506] Training epoch 46:  61%|██████▏   | 100/163 [01:58<01:14,  1.18s/it, loss=0.0818, batch_acc=1.0000, running_acc=0.9855, grad=6.9506]Training epoch 46:  61%|██████▏   | 100/163 [01:58<01:14,  1.18s/it, loss=0.0896, batch_acc=1.0000, running_acc=0.9856, grad=8.1641]Training epoch 46:  62%|██████▏   | 101/163 [01:59<01:07,  1.09s/it, loss=0.0896, batch_acc=1.0000, running_acc=0.9856, grad=8.1641]Training epoch 46:  62%|██████▏   | 101/163 [01:59<01:07,  1.09s/it, loss=0.0909, batch_acc=1.0000, running_acc=0.9858, grad=7.2085]Training epoch 46:  63%|██████▎   | 102/163 [02:00<01:02,  1.03s/it, loss=0.0909, batch_acc=1.0000, running_acc=0.9858, grad=7.2085]Training epoch 46:  63%|██████▎   | 102/163 [02:00<01:02,  1.03s/it, loss=0.1054, batch_acc=0.9688, running_acc=0.9856, grad=9.4336]Training epoch 46:  63%|██████▎   | 103/163 [02:01<00:58,  1.02it/s, loss=0.1054, batch_acc=0.9688, running_acc=0.9856, grad=9.4336]Training epoch 46:  63%|██████▎   | 103/163 [02:01<00:58,  1.02it/s, loss=0.1179, batch_acc=0.9688, running_acc=0.9854, grad=8.1870]Training epoch 46:  64%|██████▍   | 104/163 [02:03<01:12,  1.23s/it, loss=0.1179, batch_acc=0.9688, running_acc=0.9854, grad=8.1870]Training epoch 46:  64%|██████▍   | 104/163 [02:03<01:12,  1.23s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9856, grad=8.3618]Training epoch 46:  64%|██████▍   | 105/163 [02:04<01:05,  1.12s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9856, grad=8.3618]Training epoch 46:  64%|██████▍   | 105/163 [02:04<01:05,  1.12s/it, loss=0.0825, batch_acc=0.9688, running_acc=0.9854, grad=6.1523]Training epoch 46:  65%|██████▌   | 106/163 [02:04<00:59,  1.05s/it, loss=0.0825, batch_acc=0.9688, running_acc=0.9854, grad=6.1523]Training epoch 46:  65%|██████▌   | 106/163 [02:04<00:59,  1.05s/it, loss=0.1293, batch_acc=0.9688, running_acc=0.9853, grad=11.0689]Training epoch 46:  66%|██████▌   | 107/163 [02:05<00:55,  1.00it/s, loss=0.1293, batch_acc=0.9688, running_acc=0.9853, grad=11.0689]Training epoch 46:  66%|██████▌   | 107/163 [02:05<00:55,  1.00it/s, loss=0.1327, batch_acc=0.9688, running_acc=0.9851, grad=14.8432]Training epoch 46:  66%|██████▋   | 108/163 [02:06<00:57,  1.05s/it, loss=0.1327, batch_acc=0.9688, running_acc=0.9851, grad=14.8432]Training epoch 46:  66%|██████▋   | 108/163 [02:06<00:57,  1.05s/it, loss=0.0861, batch_acc=1.0000, running_acc=0.9852, grad=7.8046] Training epoch 46:  67%|██████▋   | 109/163 [02:07<00:53,  1.01it/s, loss=0.0861, batch_acc=1.0000, running_acc=0.9852, grad=7.8046]Training epoch 46:  67%|██████▋   | 109/163 [02:07<00:53,  1.01it/s, loss=0.1035, batch_acc=0.9688, running_acc=0.9851, grad=8.0586]Training epoch 46:  67%|██████▋   | 110/163 [02:08<00:50,  1.04it/s, loss=0.1035, batch_acc=0.9688, running_acc=0.9851, grad=8.0586]Training epoch 46:  67%|██████▋   | 110/163 [02:08<00:50,  1.04it/s, loss=0.1109, batch_acc=0.9688, running_acc=0.9849, grad=7.9102]Training epoch 46:  68%|██████▊   | 111/163 [02:09<00:48,  1.07it/s, loss=0.1109, batch_acc=0.9688, running_acc=0.9849, grad=7.9102]Training epoch 46:  68%|██████▊   | 111/163 [02:09<00:48,  1.07it/s, loss=0.1541, batch_acc=0.9375, running_acc=0.9845, grad=11.4520]Training epoch 46:  69%|██████▊   | 112/163 [02:11<01:05,  1.28s/it, loss=0.1541, batch_acc=0.9375, running_acc=0.9845, grad=11.4520]Training epoch 46:  69%|██████▊   | 112/163 [02:11<01:05,  1.28s/it, loss=0.0801, batch_acc=1.0000, running_acc=0.9847, grad=6.8138] Training epoch 46:  69%|██████▉   | 113/163 [02:12<00:57,  1.16s/it, loss=0.0801, batch_acc=1.0000, running_acc=0.9847, grad=6.8138]Training epoch 46:  69%|██████▉   | 113/163 [02:12<00:57,  1.16s/it, loss=0.0858, batch_acc=0.9688, running_acc=0.9845, grad=9.3163]Training epoch 46:  70%|██████▉   | 114/163 [02:13<00:52,  1.07s/it, loss=0.0858, batch_acc=0.9688, running_acc=0.9845, grad=9.3163]Training epoch 46:  70%|██████▉   | 114/163 [02:13<00:52,  1.07s/it, loss=0.1675, batch_acc=0.9688, running_acc=0.9844, grad=11.0034]Training epoch 46:  71%|███████   | 115/163 [02:14<00:48,  1.01s/it, loss=0.1675, batch_acc=0.9688, running_acc=0.9844, grad=11.0034]Training epoch 46:  71%|███████   | 115/163 [02:14<00:48,  1.01s/it, loss=0.0555, batch_acc=1.0000, running_acc=0.9845, grad=5.6882] Training epoch 46:  71%|███████   | 116/163 [02:16<01:01,  1.31s/it, loss=0.0555, batch_acc=1.0000, running_acc=0.9845, grad=5.6882]Training epoch 46:  71%|███████   | 116/163 [02:16<01:01,  1.31s/it, loss=0.1439, batch_acc=0.9375, running_acc=0.9841, grad=10.9413]Training epoch 46:  72%|███████▏  | 117/163 [02:17<00:54,  1.18s/it, loss=0.1439, batch_acc=0.9375, running_acc=0.9841, grad=10.9413]Training epoch 46:  72%|███████▏  | 117/163 [02:17<00:54,  1.18s/it, loss=0.0590, batch_acc=1.0000, running_acc=0.9842, grad=4.3526] Training epoch 46:  72%|███████▏  | 118/163 [02:18<00:48,  1.09s/it, loss=0.0590, batch_acc=1.0000, running_acc=0.9842, grad=4.3526]Training epoch 46:  72%|███████▏  | 118/163 [02:18<00:48,  1.09s/it, loss=0.1243, batch_acc=1.0000, running_acc=0.9844, grad=10.8195]Training epoch 46:  73%|███████▎  | 119/163 [02:19<00:46,  1.05s/it, loss=0.1243, batch_acc=1.0000, running_acc=0.9844, grad=10.8195]Training epoch 46:  73%|███████▎  | 119/163 [02:19<00:46,  1.05s/it, loss=0.1052, batch_acc=0.9688, running_acc=0.9842, grad=14.3501]Training epoch 46:  74%|███████▎  | 120/163 [02:20<00:57,  1.33s/it, loss=0.1052, batch_acc=0.9688, running_acc=0.9842, grad=14.3501]Training epoch 46:  74%|███████▎  | 120/163 [02:20<00:57,  1.33s/it, loss=0.0894, batch_acc=1.0000, running_acc=0.9844, grad=7.3258] Training epoch 46:  74%|███████▍  | 121/163 [02:21<00:50,  1.19s/it, loss=0.0894, batch_acc=1.0000, running_acc=0.9844, grad=7.3258]Training epoch 46:  74%|███████▍  | 121/163 [02:21<00:50,  1.19s/it, loss=0.1562, batch_acc=0.9375, running_acc=0.9840, grad=9.0023]Training epoch 46:  75%|███████▍  | 122/163 [02:22<00:45,  1.10s/it, loss=0.1562, batch_acc=0.9375, running_acc=0.9840, grad=9.0023]Training epoch 46:  75%|███████▍  | 122/163 [02:22<00:45,  1.10s/it, loss=0.1494, batch_acc=1.0000, running_acc=0.9841, grad=19.8050]Training epoch 46:  75%|███████▌  | 123/163 [02:23<00:41,  1.03s/it, loss=0.1494, batch_acc=1.0000, running_acc=0.9841, grad=19.8050]Training epoch 46:  75%|███████▌  | 123/163 [02:23<00:41,  1.03s/it, loss=0.1309, batch_acc=1.0000, running_acc=0.9842, grad=11.5221]Training epoch 46:  76%|███████▌  | 124/163 [02:25<00:47,  1.22s/it, loss=0.1309, batch_acc=1.0000, running_acc=0.9842, grad=11.5221]Training epoch 46:  76%|███████▌  | 124/163 [02:25<00:47,  1.22s/it, loss=0.0982, batch_acc=0.9688, running_acc=0.9841, grad=8.4589] Training epoch 46:  77%|███████▋  | 125/163 [02:26<00:42,  1.11s/it, loss=0.0982, batch_acc=0.9688, running_acc=0.9841, grad=8.4589]Training epoch 46:  77%|███████▋  | 125/163 [02:26<00:42,  1.11s/it, loss=0.0944, batch_acc=0.9688, running_acc=0.9840, grad=7.9710]Training epoch 46:  77%|███████▋  | 126/163 [02:27<00:38,  1.04s/it, loss=0.0944, batch_acc=0.9688, running_acc=0.9840, grad=7.9710]Training epoch 46:  77%|███████▋  | 126/163 [02:27<00:38,  1.04s/it, loss=0.1487, batch_acc=0.9688, running_acc=0.9839, grad=9.6692]Training epoch 46:  78%|███████▊  | 127/163 [02:27<00:35,  1.00it/s, loss=0.1487, batch_acc=0.9688, running_acc=0.9839, grad=9.6692]Training epoch 46:  78%|███████▊  | 127/163 [02:27<00:35,  1.00it/s, loss=0.0881, batch_acc=1.0000, running_acc=0.9840, grad=8.0699]Training epoch 46:  79%|███████▊  | 128/163 [02:29<00:42,  1.23s/it, loss=0.0881, batch_acc=1.0000, running_acc=0.9840, grad=8.0699]Training epoch 46:  79%|███████▊  | 128/163 [02:29<00:42,  1.23s/it, loss=0.0700, batch_acc=1.0000, running_acc=0.9841, grad=10.6773]Training epoch 46:  79%|███████▉  | 129/163 [02:30<00:38,  1.12s/it, loss=0.0700, batch_acc=1.0000, running_acc=0.9841, grad=10.6773]Training epoch 46:  79%|███████▉  | 129/163 [02:30<00:38,  1.12s/it, loss=0.1230, batch_acc=0.9688, running_acc=0.9840, grad=8.7599] Training epoch 46:  80%|███████▉  | 130/163 [02:31<00:34,  1.05s/it, loss=0.1230, batch_acc=0.9688, running_acc=0.9840, grad=8.7599]Training epoch 46:  80%|███████▉  | 130/163 [02:31<00:34,  1.05s/it, loss=0.0875, batch_acc=1.0000, running_acc=0.9841, grad=7.0919]Training epoch 46:  80%|████████  | 131/163 [02:32<00:31,  1.00it/s, loss=0.0875, batch_acc=1.0000, running_acc=0.9841, grad=7.0919]Training epoch 46:  80%|████████  | 131/163 [02:32<00:31,  1.00it/s, loss=0.0712, batch_acc=1.0000, running_acc=0.9843, grad=6.6971]Training epoch 46:  81%|████████  | 132/163 [02:34<00:42,  1.36s/it, loss=0.0712, batch_acc=1.0000, running_acc=0.9843, grad=6.6971]Training epoch 46:  81%|████████  | 132/163 [02:34<00:42,  1.36s/it, loss=0.1109, batch_acc=1.0000, running_acc=0.9844, grad=7.8786]Training epoch 46:  82%|████████▏ | 133/163 [02:35<00:36,  1.21s/it, loss=0.1109, batch_acc=1.0000, running_acc=0.9844, grad=7.8786]Training epoch 46:  82%|████████▏ | 133/163 [02:35<00:36,  1.21s/it, loss=0.1490, batch_acc=1.0000, running_acc=0.9845, grad=15.5764]Training epoch 46:  82%|████████▏ | 134/163 [02:36<00:32,  1.11s/it, loss=0.1490, batch_acc=1.0000, running_acc=0.9845, grad=15.5764]Training epoch 46:  82%|████████▏ | 134/163 [02:36<00:32,  1.11s/it, loss=0.0818, batch_acc=0.9688, running_acc=0.9844, grad=7.8984] Training epoch 46:  83%|████████▎ | 135/163 [02:37<00:29,  1.07s/it, loss=0.0818, batch_acc=0.9688, running_acc=0.9844, grad=7.8984]Training epoch 46:  83%|████████▎ | 135/163 [02:37<00:29,  1.07s/it, loss=0.1416, batch_acc=0.9688, running_acc=0.9843, grad=14.4194]Training epoch 46:  83%|████████▎ | 136/163 [02:39<00:35,  1.32s/it, loss=0.1416, batch_acc=0.9688, running_acc=0.9843, grad=14.4194]Training epoch 46:  83%|████████▎ | 136/163 [02:39<00:35,  1.32s/it, loss=0.1052, batch_acc=1.0000, running_acc=0.9844, grad=10.9224]Training epoch 46:  84%|████████▍ | 137/163 [02:40<00:30,  1.18s/it, loss=0.1052, batch_acc=1.0000, running_acc=0.9844, grad=10.9224]Training epoch 46:  84%|████████▍ | 137/163 [02:40<00:30,  1.18s/it, loss=0.1432, batch_acc=0.9375, running_acc=0.9840, grad=9.3407] Training epoch 46:  85%|████████▍ | 138/163 [02:40<00:27,  1.09s/it, loss=0.1432, batch_acc=0.9375, running_acc=0.9840, grad=9.3407]Training epoch 46:  85%|████████▍ | 138/163 [02:40<00:27,  1.09s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9841, grad=6.7781]Training epoch 46:  85%|████████▌ | 139/163 [02:42<00:27,  1.13s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9841, grad=6.7781]Training epoch 46:  85%|████████▌ | 139/163 [02:42<00:27,  1.13s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9843, grad=7.7044]Training epoch 46:  86%|████████▌ | 140/163 [02:43<00:25,  1.12s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9843, grad=7.7044]Training epoch 46:  86%|████████▌ | 140/163 [02:43<00:25,  1.12s/it, loss=0.1909, batch_acc=0.9688, running_acc=0.9842, grad=11.5546]Training epoch 46:  87%|████████▋ | 141/163 [02:44<00:22,  1.04s/it, loss=0.1909, batch_acc=0.9688, running_acc=0.9842, grad=11.5546]Training epoch 46:  87%|████████▋ | 141/163 [02:44<00:22,  1.04s/it, loss=0.1407, batch_acc=0.9688, running_acc=0.9840, grad=8.9189] Training epoch 46:  87%|████████▋ | 142/163 [02:44<00:20,  1.01it/s, loss=0.1407, batch_acc=0.9688, running_acc=0.9840, grad=8.9189]Training epoch 46:  87%|████████▋ | 142/163 [02:44<00:20,  1.01it/s, loss=0.1484, batch_acc=0.9062, running_acc=0.9835, grad=16.2611]Training epoch 46:  88%|████████▊ | 143/163 [02:46<00:24,  1.22s/it, loss=0.1484, batch_acc=0.9062, running_acc=0.9835, grad=16.2611]Training epoch 46:  88%|████████▊ | 143/163 [02:46<00:24,  1.22s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9834, grad=11.3199]Training epoch 46:  88%|████████▊ | 144/163 [02:47<00:21,  1.14s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9834, grad=11.3199]Training epoch 46:  88%|████████▊ | 144/163 [02:47<00:21,  1.14s/it, loss=0.0718, batch_acc=1.0000, running_acc=0.9835, grad=5.5393] Training epoch 46:  89%|████████▉ | 145/163 [02:48<00:19,  1.06s/it, loss=0.0718, batch_acc=1.0000, running_acc=0.9835, grad=5.5393]Training epoch 46:  89%|████████▉ | 145/163 [02:48<00:19,  1.06s/it, loss=0.0965, batch_acc=1.0000, running_acc=0.9836, grad=7.7590]Training epoch 46:  90%|████████▉ | 146/163 [02:49<00:17,  1.01s/it, loss=0.0965, batch_acc=1.0000, running_acc=0.9836, grad=7.7590]Training epoch 46:  90%|████████▉ | 146/163 [02:49<00:17,  1.01s/it, loss=0.1377, batch_acc=0.9375, running_acc=0.9833, grad=13.1920]Training epoch 46:  90%|█████████ | 147/163 [02:51<00:18,  1.19s/it, loss=0.1377, batch_acc=0.9375, running_acc=0.9833, grad=13.1920]Training epoch 46:  90%|█████████ | 147/163 [02:51<00:18,  1.19s/it, loss=0.1419, batch_acc=0.9688, running_acc=0.9832, grad=12.3047]Training epoch 46:  91%|█████████ | 148/163 [02:51<00:16,  1.11s/it, loss=0.1419, batch_acc=0.9688, running_acc=0.9832, grad=12.3047]Training epoch 46:  91%|█████████ | 148/163 [02:51<00:16,  1.11s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9833, grad=5.4333] Training epoch 46:  91%|█████████▏| 149/163 [02:52<00:14,  1.04s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9833, grad=5.4333]Training epoch 46:  91%|█████████▏| 149/163 [02:52<00:14,  1.04s/it, loss=0.1071, batch_acc=0.9688, running_acc=0.9832, grad=7.2950]Training epoch 46:  92%|█████████▏| 150/163 [02:53<00:12,  1.01it/s, loss=0.1071, batch_acc=0.9688, running_acc=0.9832, grad=7.2950]Training epoch 46:  92%|█████████▏| 150/163 [02:53<00:12,  1.01it/s, loss=0.0980, batch_acc=1.0000, running_acc=0.9833, grad=8.5410]Training epoch 46:  93%|█████████▎| 151/163 [02:55<00:13,  1.17s/it, loss=0.0980, batch_acc=1.0000, running_acc=0.9833, grad=8.5410]Training epoch 46:  93%|█████████▎| 151/163 [02:55<00:13,  1.17s/it, loss=0.1178, batch_acc=1.0000, running_acc=0.9834, grad=8.3297]Training epoch 46:  93%|█████████▎| 152/163 [02:56<00:11,  1.08s/it, loss=0.1178, batch_acc=1.0000, running_acc=0.9834, grad=8.3297]Training epoch 46:  93%|█████████▎| 152/163 [02:56<00:11,  1.08s/it, loss=0.0986, batch_acc=1.0000, running_acc=0.9836, grad=8.0040]Training epoch 46:  94%|█████████▍| 153/163 [02:57<00:10,  1.02s/it, loss=0.0986, batch_acc=1.0000, running_acc=0.9836, grad=8.0040]Training epoch 46:  94%|█████████▍| 153/163 [02:57<00:10,  1.02s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9837, grad=7.9973]Training epoch 46:  94%|█████████▍| 154/163 [02:57<00:08,  1.02it/s, loss=0.1195, batch_acc=1.0000, running_acc=0.9837, grad=7.9973]Training epoch 46:  94%|█████████▍| 154/163 [02:57<00:08,  1.02it/s, loss=0.0877, batch_acc=1.0000, running_acc=0.9838, grad=6.1674]Training epoch 46:  95%|█████████▌| 155/163 [03:00<00:10,  1.36s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9838, grad=6.1674]Training epoch 46:  95%|█████████▌| 155/163 [03:00<00:10,  1.36s/it, loss=0.1113, batch_acc=1.0000, running_acc=0.9839, grad=7.9792]Training epoch 46:  96%|█████████▌| 156/163 [03:01<00:08,  1.21s/it, loss=0.1113, batch_acc=1.0000, running_acc=0.9839, grad=7.9792]Training epoch 46:  96%|█████████▌| 156/163 [03:01<00:08,  1.21s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9840, grad=9.4671]Training epoch 46:  96%|█████████▋| 157/163 [03:01<00:06,  1.11s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9840, grad=9.4671]Training epoch 46:  96%|█████████▋| 157/163 [03:01<00:06,  1.11s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9841, grad=5.1198]Training epoch 46:  97%|█████████▋| 158/163 [03:02<00:05,  1.04s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9841, grad=5.1198]Training epoch 46:  97%|█████████▋| 158/163 [03:02<00:05,  1.04s/it, loss=0.0879, batch_acc=1.0000, running_acc=0.9842, grad=6.2180]Training epoch 46:  98%|█████████▊| 159/163 [03:04<00:04,  1.16s/it, loss=0.0879, batch_acc=1.0000, running_acc=0.9842, grad=6.2180]Training epoch 46:  98%|█████████▊| 159/163 [03:04<00:04,  1.16s/it, loss=0.0834, batch_acc=1.0000, running_acc=0.9843, grad=7.7218]Training epoch 46:  98%|█████████▊| 160/163 [03:05<00:03,  1.08s/it, loss=0.0834, batch_acc=1.0000, running_acc=0.9843, grad=7.7218]Training epoch 46:  98%|█████████▊| 160/163 [03:05<00:03,  1.08s/it, loss=0.1735, batch_acc=0.9375, running_acc=0.9840, grad=13.7377]Training epoch 46:  99%|█████████▉| 161/163 [03:05<00:02,  1.02s/it, loss=0.1735, batch_acc=0.9375, running_acc=0.9840, grad=13.7377]Training epoch 46:  99%|█████████▉| 161/163 [03:05<00:02,  1.02s/it, loss=0.1198, batch_acc=1.0000, running_acc=0.9841, grad=11.1702]Training epoch 46:  99%|█████████▉| 162/163 [03:06<00:00,  1.02it/s, loss=0.1198, batch_acc=1.0000, running_acc=0.9841, grad=11.1702]Training epoch 46:  99%|█████████▉| 162/163 [03:06<00:00,  1.02it/s, loss=0.0603, batch_acc=1.0000, running_acc=0.9842, grad=5.6962] Training epoch 46: 100%|██████████| 163/163 [03:07<00:00,  1.14it/s, loss=0.0603, batch_acc=1.0000, running_acc=0.9842, grad=5.6962]Training epoch 46: 100%|██████████| 163/163 [03:07<00:00,  1.14it/s, loss=0.1295, batch_acc=0.9524, running_acc=0.9841, grad=20.2968]Training epoch 46: 100%|██████████| 163/163 [03:07<00:00,  1.15s/it, loss=0.1295, batch_acc=0.9524, running_acc=0.9841, grad=20.2968]
Evaluation epoch 46:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 46:   4%|▎         | 1/28 [00:04<02:12,  4.91s/it]Evaluation epoch 46:   4%|▎         | 1/28 [00:04<02:12,  4.91s/it, loss=0.3698, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 46:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.3698, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 46:   7%|▋         | 2/28 [00:05<00:56,  2.18s/it, loss=0.2284, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 46:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.2284, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 46:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3104, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 46:  14%|█▍        | 4/28 [00:10<01:02,  2.62s/it, loss=0.3104, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 46:  14%|█▍        | 4/28 [00:10<01:02,  2.62s/it, loss=0.3882, batch_acc=0.9375, running_acc=0.9531]Evaluation epoch 46:  18%|█▊        | 5/28 [00:10<00:40,  1.77s/it, loss=0.3882, batch_acc=0.9375, running_acc=0.9531]Evaluation epoch 46:  18%|█▊        | 5/28 [00:10<00:40,  1.77s/it, loss=1.2962, batch_acc=0.7188, running_acc=0.9062]Evaluation epoch 46:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=1.2962, batch_acc=0.7188, running_acc=0.9062]Evaluation epoch 46:  21%|██▏       | 6/28 [00:10<00:27,  1.26s/it, loss=0.5047, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 46:  25%|██▌       | 7/28 [00:10<00:19,  1.07it/s, loss=0.5047, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 46:  25%|██▌       | 7/28 [00:10<00:19,  1.07it/s, loss=0.6035, batch_acc=0.8750, running_acc=0.9018]Evaluation epoch 46:  29%|██▊       | 8/28 [00:14<00:34,  1.70s/it, loss=0.6035, batch_acc=0.8750, running_acc=0.9018]Evaluation epoch 46:  29%|██▊       | 8/28 [00:14<00:34,  1.70s/it, loss=0.3812, batch_acc=0.8438, running_acc=0.8945]Evaluation epoch 46:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.3812, batch_acc=0.8438, running_acc=0.8945]Evaluation epoch 46:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.4135, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 46:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.4135, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 46:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.4353, batch_acc=0.9375, running_acc=0.9000]Evaluation epoch 46:  39%|███▉      | 11/28 [00:15<00:12,  1.36it/s, loss=0.4353, batch_acc=0.9375, running_acc=0.9000]Evaluation epoch 46:  39%|███▉      | 11/28 [00:15<00:12,  1.36it/s, loss=0.3000, batch_acc=0.9688, running_acc=0.9062]Evaluation epoch 46:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=0.3000, batch_acc=0.9688, running_acc=0.9062]Evaluation epoch 46:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=0.8864, batch_acc=0.7812, running_acc=0.8958]Evaluation epoch 46:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=0.8864, batch_acc=0.7812, running_acc=0.8958]Evaluation epoch 46:  46%|████▋     | 13/28 [00:20<00:24,  1.63s/it, loss=0.2747, batch_acc=0.9375, running_acc=0.8990]Evaluation epoch 46:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=0.2747, batch_acc=0.9375, running_acc=0.8990]Evaluation epoch 46:  50%|█████     | 14/28 [00:21<00:17,  1.22s/it, loss=0.8583, batch_acc=0.7500, running_acc=0.8884]Evaluation epoch 46:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=0.8583, batch_acc=0.7500, running_acc=0.8884]Evaluation epoch 46:  54%|█████▎    | 15/28 [00:21<00:12,  1.08it/s, loss=0.9388, batch_acc=0.8438, running_acc=0.8854]Evaluation epoch 46:  57%|█████▋    | 16/28 [00:24<00:17,  1.48s/it, loss=0.9388, batch_acc=0.8438, running_acc=0.8854]Evaluation epoch 46:  57%|█████▋    | 16/28 [00:24<00:17,  1.48s/it, loss=0.7903, batch_acc=0.7812, running_acc=0.8789]Evaluation epoch 46:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=0.7903, batch_acc=0.7812, running_acc=0.8789]Evaluation epoch 46:  61%|██████    | 17/28 [00:24<00:12,  1.11s/it, loss=0.6435, batch_acc=0.7188, running_acc=0.8695]Evaluation epoch 46:  64%|██████▍   | 18/28 [00:24<00:08,  1.17it/s, loss=0.6435, batch_acc=0.7188, running_acc=0.8695]Evaluation epoch 46:  64%|██████▍   | 18/28 [00:24<00:08,  1.17it/s, loss=0.5323, batch_acc=0.8750, running_acc=0.8698]Evaluation epoch 46:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=0.5323, batch_acc=0.8750, running_acc=0.8698]Evaluation epoch 46:  68%|██████▊   | 19/28 [00:24<00:06,  1.48it/s, loss=0.8647, batch_acc=0.6562, running_acc=0.8586]Evaluation epoch 46:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=0.8647, batch_acc=0.6562, running_acc=0.8586]Evaluation epoch 46:  71%|███████▏  | 20/28 [00:27<00:10,  1.33s/it, loss=0.5474, batch_acc=0.7188, running_acc=0.8516]Evaluation epoch 46:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=0.5474, batch_acc=0.7188, running_acc=0.8516]Evaluation epoch 46:  75%|███████▌  | 21/28 [00:28<00:07,  1.01s/it, loss=0.5741, batch_acc=0.8125, running_acc=0.8497]Evaluation epoch 46:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.5741, batch_acc=0.8125, running_acc=0.8497]Evaluation epoch 46:  79%|███████▊  | 22/28 [00:28<00:04,  1.27it/s, loss=0.3917, batch_acc=0.9688, running_acc=0.8551]Evaluation epoch 46:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=0.3917, batch_acc=0.9688, running_acc=0.8551]Evaluation epoch 46:  82%|████████▏ | 23/28 [00:28<00:03,  1.59it/s, loss=0.7855, batch_acc=0.7812, running_acc=0.8519]Evaluation epoch 46:  86%|████████▌ | 24/28 [00:33<00:08,  2.01s/it, loss=0.7855, batch_acc=0.7812, running_acc=0.8519]Evaluation epoch 46:  86%|████████▌ | 24/28 [00:33<00:08,  2.01s/it, loss=0.2933, batch_acc=0.9375, running_acc=0.8555]Evaluation epoch 46:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.2933, batch_acc=0.9375, running_acc=0.8555]Evaluation epoch 46:  89%|████████▉ | 25/28 [00:34<00:04,  1.49s/it, loss=0.1304, batch_acc=1.0000, running_acc=0.8612]Evaluation epoch 46:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.1304, batch_acc=1.0000, running_acc=0.8612]Evaluation epoch 46:  93%|█████████▎| 26/28 [00:34<00:02,  1.12s/it, loss=0.5661, batch_acc=0.8438, running_acc=0.8606]Evaluation epoch 46:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.5661, batch_acc=0.8438, running_acc=0.8606]Evaluation epoch 46:  96%|█████████▋| 27/28 [00:34<00:00,  1.16it/s, loss=0.8142, batch_acc=0.7812, running_acc=0.8576]Evaluation epoch 46: 100%|██████████| 28/28 [00:34<00:00,  1.16it/s, loss=1.1324, batch_acc=0.6667, running_acc=0.8570]Evaluation epoch 46: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.1324, batch_acc=0.6667, running_acc=0.8570]
Training epoch 47:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 47:   1%|          | 1/163 [00:05<15:03,  5.57s/it]Training epoch 47:   1%|          | 1/163 [00:05<15:03,  5.57s/it, loss=0.1652, batch_acc=0.9688, running_acc=0.9688, grad=19.2781]Training epoch 47:   1%|          | 2/163 [00:06<07:33,  2.81s/it, loss=0.1652, batch_acc=0.9688, running_acc=0.9688, grad=19.2781]Training epoch 47:   1%|          | 2/163 [00:06<07:33,  2.81s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9844, grad=4.6743] Training epoch 47:   2%|▏         | 3/163 [00:07<05:09,  1.93s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9844, grad=4.6743]Training epoch 47:   2%|▏         | 3/163 [00:07<05:09,  1.93s/it, loss=0.0780, batch_acc=1.0000, running_acc=0.9896, grad=7.6580]Training epoch 47:   2%|▏         | 4/163 [00:09<05:21,  2.02s/it, loss=0.0780, batch_acc=1.0000, running_acc=0.9896, grad=7.6580]Training epoch 47:   2%|▏         | 4/163 [00:09<05:21,  2.02s/it, loss=0.1076, batch_acc=1.0000, running_acc=0.9922, grad=10.2811]Training epoch 47:   3%|▎         | 5/163 [00:10<04:14,  1.61s/it, loss=0.1076, batch_acc=1.0000, running_acc=0.9922, grad=10.2811]Training epoch 47:   3%|▎         | 5/163 [00:10<04:14,  1.61s/it, loss=0.1283, batch_acc=1.0000, running_acc=0.9938, grad=8.5553] Training epoch 47:   4%|▎         | 6/163 [00:11<03:33,  1.36s/it, loss=0.1283, batch_acc=1.0000, running_acc=0.9938, grad=8.5553]Training epoch 47:   4%|▎         | 6/163 [00:11<03:33,  1.36s/it, loss=0.1176, batch_acc=0.9688, running_acc=0.9896, grad=10.5144]Training epoch 47:   4%|▍         | 7/163 [00:12<03:07,  1.20s/it, loss=0.1176, batch_acc=0.9688, running_acc=0.9896, grad=10.5144]Training epoch 47:   4%|▍         | 7/163 [00:12<03:07,  1.20s/it, loss=0.1343, batch_acc=0.9375, running_acc=0.9821, grad=9.2676] Training epoch 47:   5%|▍         | 8/163 [00:13<03:24,  1.32s/it, loss=0.1343, batch_acc=0.9375, running_acc=0.9821, grad=9.2676]Training epoch 47:   5%|▍         | 8/163 [00:13<03:24,  1.32s/it, loss=0.1472, batch_acc=0.9688, running_acc=0.9805, grad=9.9976]Training epoch 47:   6%|▌         | 9/163 [00:14<03:02,  1.18s/it, loss=0.1472, batch_acc=0.9688, running_acc=0.9805, grad=9.9976]Training epoch 47:   6%|▌         | 9/163 [00:14<03:02,  1.18s/it, loss=0.1082, batch_acc=1.0000, running_acc=0.9826, grad=9.5621]Training epoch 47:   6%|▌         | 10/163 [00:15<02:46,  1.09s/it, loss=0.1082, batch_acc=1.0000, running_acc=0.9826, grad=9.5621]Training epoch 47:   6%|▌         | 10/163 [00:15<02:46,  1.09s/it, loss=0.1281, batch_acc=0.9688, running_acc=0.9812, grad=8.6984]Training epoch 47:   7%|▋         | 11/163 [00:16<02:37,  1.04s/it, loss=0.1281, batch_acc=0.9688, running_acc=0.9812, grad=8.6984]Training epoch 47:   7%|▋         | 11/163 [00:16<02:37,  1.04s/it, loss=0.1197, batch_acc=0.9688, running_acc=0.9801, grad=11.3108]Training epoch 47:   7%|▋         | 12/163 [00:18<03:29,  1.39s/it, loss=0.1197, batch_acc=0.9688, running_acc=0.9801, grad=11.3108]Training epoch 47:   7%|▋         | 12/163 [00:18<03:29,  1.39s/it, loss=0.1152, batch_acc=0.9688, running_acc=0.9792, grad=10.2350]Training epoch 47:   8%|▊         | 13/163 [00:19<03:05,  1.23s/it, loss=0.1152, batch_acc=0.9688, running_acc=0.9792, grad=10.2350]Training epoch 47:   8%|▊         | 13/163 [00:19<03:05,  1.23s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9808, grad=7.9133] Training epoch 47:   9%|▊         | 14/163 [00:20<02:47,  1.13s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9808, grad=7.9133]Training epoch 47:   9%|▊         | 14/163 [00:20<02:47,  1.13s/it, loss=0.0830, batch_acc=0.9688, running_acc=0.9799, grad=6.0579]Training epoch 47:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.0830, batch_acc=0.9688, running_acc=0.9799, grad=6.0579]Training epoch 47:   9%|▉         | 15/163 [00:21<02:35,  1.05s/it, loss=0.1015, batch_acc=0.9688, running_acc=0.9792, grad=9.6718]Training epoch 47:  10%|▉         | 16/163 [00:23<03:12,  1.31s/it, loss=0.1015, batch_acc=0.9688, running_acc=0.9792, grad=9.6718]Training epoch 47:  10%|▉         | 16/163 [00:23<03:12,  1.31s/it, loss=0.0614, batch_acc=1.0000, running_acc=0.9805, grad=5.2048]Training epoch 47:  10%|█         | 17/163 [00:24<02:52,  1.18s/it, loss=0.0614, batch_acc=1.0000, running_acc=0.9805, grad=5.2048]Training epoch 47:  10%|█         | 17/163 [00:24<02:52,  1.18s/it, loss=0.0969, batch_acc=0.9688, running_acc=0.9798, grad=6.6761]Training epoch 47:  11%|█         | 18/163 [00:24<02:38,  1.09s/it, loss=0.0969, batch_acc=0.9688, running_acc=0.9798, grad=6.6761]Training epoch 47:  11%|█         | 18/163 [00:24<02:38,  1.09s/it, loss=0.1592, batch_acc=0.9688, running_acc=0.9792, grad=8.7198]Training epoch 47:  12%|█▏        | 19/163 [00:25<02:28,  1.03s/it, loss=0.1592, batch_acc=0.9688, running_acc=0.9792, grad=8.7198]Training epoch 47:  12%|█▏        | 19/163 [00:25<02:28,  1.03s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9803, grad=6.5075]Training epoch 47:  12%|█▏        | 20/163 [00:27<02:44,  1.15s/it, loss=0.1001, batch_acc=1.0000, running_acc=0.9803, grad=6.5075]Training epoch 47:  12%|█▏        | 20/163 [00:27<02:44,  1.15s/it, loss=0.1243, batch_acc=0.9688, running_acc=0.9797, grad=10.3159]Training epoch 47:  13%|█▎        | 21/163 [00:28<02:31,  1.07s/it, loss=0.1243, batch_acc=0.9688, running_acc=0.9797, grad=10.3159]Training epoch 47:  13%|█▎        | 21/163 [00:28<02:31,  1.07s/it, loss=0.1051, batch_acc=0.9688, running_acc=0.9792, grad=9.3260] Training epoch 47:  13%|█▎        | 22/163 [00:28<02:22,  1.01s/it, loss=0.1051, batch_acc=0.9688, running_acc=0.9792, grad=9.3260]Training epoch 47:  13%|█▎        | 22/163 [00:28<02:22,  1.01s/it, loss=0.0931, batch_acc=1.0000, running_acc=0.9801, grad=7.5550]Training epoch 47:  14%|█▍        | 23/163 [00:29<02:15,  1.03it/s, loss=0.0931, batch_acc=1.0000, running_acc=0.9801, grad=7.5550]Training epoch 47:  14%|█▍        | 23/163 [00:29<02:15,  1.03it/s, loss=0.1590, batch_acc=0.9375, running_acc=0.9783, grad=12.4532]Training epoch 47:  15%|█▍        | 24/163 [00:31<02:45,  1.19s/it, loss=0.1590, batch_acc=0.9375, running_acc=0.9783, grad=12.4532]Training epoch 47:  15%|█▍        | 24/163 [00:31<02:45,  1.19s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9792, grad=6.3834] Training epoch 47:  15%|█▌        | 25/163 [00:32<02:31,  1.10s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9792, grad=6.3834]Training epoch 47:  15%|█▌        | 25/163 [00:32<02:31,  1.10s/it, loss=0.0796, batch_acc=1.0000, running_acc=0.9800, grad=17.0901]Training epoch 47:  16%|█▌        | 26/163 [00:33<02:21,  1.03s/it, loss=0.0796, batch_acc=1.0000, running_acc=0.9800, grad=17.0901]Training epoch 47:  16%|█▌        | 26/163 [00:33<02:21,  1.03s/it, loss=0.0980, batch_acc=1.0000, running_acc=0.9808, grad=6.7119] Training epoch 47:  17%|█▋        | 27/163 [00:34<02:17,  1.01s/it, loss=0.0980, batch_acc=1.0000, running_acc=0.9808, grad=6.7119]Training epoch 47:  17%|█▋        | 27/163 [00:34<02:17,  1.01s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9815, grad=13.8110]Training epoch 47:  17%|█▋        | 28/163 [00:36<02:45,  1.23s/it, loss=0.1209, batch_acc=1.0000, running_acc=0.9815, grad=13.8110]Training epoch 47:  17%|█▋        | 28/163 [00:36<02:45,  1.23s/it, loss=0.0776, batch_acc=1.0000, running_acc=0.9821, grad=6.4764] Training epoch 47:  18%|█▊        | 29/163 [00:36<02:30,  1.12s/it, loss=0.0776, batch_acc=1.0000, running_acc=0.9821, grad=6.4764]Training epoch 47:  18%|█▊        | 29/163 [00:36<02:30,  1.12s/it, loss=0.1287, batch_acc=0.9375, running_acc=0.9806, grad=6.5471]Training epoch 47:  18%|█▊        | 30/163 [00:37<02:19,  1.05s/it, loss=0.1287, batch_acc=0.9375, running_acc=0.9806, grad=6.5471]Training epoch 47:  18%|█▊        | 30/163 [00:37<02:19,  1.05s/it, loss=0.0871, batch_acc=1.0000, running_acc=0.9812, grad=8.8443]Training epoch 47:  19%|█▉        | 31/163 [00:38<02:11,  1.00it/s, loss=0.0871, batch_acc=1.0000, running_acc=0.9812, grad=8.8443]Training epoch 47:  19%|█▉        | 31/163 [00:38<02:11,  1.00it/s, loss=0.1118, batch_acc=0.9688, running_acc=0.9808, grad=12.1854]Training epoch 47:  20%|█▉        | 32/163 [00:40<02:50,  1.30s/it, loss=0.1118, batch_acc=0.9688, running_acc=0.9808, grad=12.1854]Training epoch 47:  20%|█▉        | 32/163 [00:40<02:50,  1.30s/it, loss=0.1115, batch_acc=0.9688, running_acc=0.9805, grad=9.2625] Training epoch 47:  20%|██        | 33/163 [00:41<02:32,  1.17s/it, loss=0.1115, batch_acc=0.9688, running_acc=0.9805, grad=9.2625]Training epoch 47:  20%|██        | 33/163 [00:41<02:32,  1.17s/it, loss=0.0543, batch_acc=1.0000, running_acc=0.9811, grad=4.0898]Training epoch 47:  21%|██        | 34/163 [00:42<02:19,  1.08s/it, loss=0.0543, batch_acc=1.0000, running_acc=0.9811, grad=4.0898]Training epoch 47:  21%|██        | 34/163 [00:42<02:19,  1.08s/it, loss=0.1044, batch_acc=0.9688, running_acc=0.9807, grad=8.2109]Training epoch 47:  21%|██▏       | 35/163 [00:43<02:10,  1.02s/it, loss=0.1044, batch_acc=0.9688, running_acc=0.9807, grad=8.2109]Training epoch 47:  21%|██▏       | 35/163 [00:43<02:10,  1.02s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9812, grad=10.8424]Training epoch 47:  22%|██▏       | 36/163 [00:45<02:45,  1.30s/it, loss=0.1103, batch_acc=1.0000, running_acc=0.9812, grad=10.8424]Training epoch 47:  22%|██▏       | 36/163 [00:45<02:45,  1.30s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9818, grad=6.2898] Training epoch 47:  23%|██▎       | 37/163 [00:46<02:27,  1.17s/it, loss=0.1083, batch_acc=1.0000, running_acc=0.9818, grad=6.2898]Training epoch 47:  23%|██▎       | 37/163 [00:46<02:27,  1.17s/it, loss=0.1292, batch_acc=0.9688, running_acc=0.9814, grad=14.9859]Training epoch 47:  23%|██▎       | 38/163 [00:46<02:15,  1.09s/it, loss=0.1292, batch_acc=0.9688, running_acc=0.9814, grad=14.9859]Training epoch 47:  23%|██▎       | 38/163 [00:46<02:15,  1.09s/it, loss=0.1139, batch_acc=0.9688, running_acc=0.9811, grad=10.0088]Training epoch 47:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=0.1139, batch_acc=0.9688, running_acc=0.9811, grad=10.0088]Training epoch 47:  24%|██▍       | 39/163 [00:47<02:06,  1.02s/it, loss=0.1314, batch_acc=0.9688, running_acc=0.9808, grad=10.9057]Training epoch 47:  25%|██▍       | 40/163 [00:49<02:46,  1.35s/it, loss=0.1314, batch_acc=0.9688, running_acc=0.9808, grad=10.9057]Training epoch 47:  25%|██▍       | 40/163 [00:49<02:46,  1.35s/it, loss=0.1403, batch_acc=1.0000, running_acc=0.9812, grad=17.0921]Training epoch 47:  25%|██▌       | 41/163 [00:50<02:27,  1.21s/it, loss=0.1403, batch_acc=1.0000, running_acc=0.9812, grad=17.0921]Training epoch 47:  25%|██▌       | 41/163 [00:50<02:27,  1.21s/it, loss=0.1137, batch_acc=0.9375, running_acc=0.9802, grad=9.7690] Training epoch 47:  26%|██▌       | 42/163 [00:51<02:14,  1.11s/it, loss=0.1137, batch_acc=0.9375, running_acc=0.9802, grad=9.7690]Training epoch 47:  26%|██▌       | 42/163 [00:51<02:14,  1.11s/it, loss=0.1272, batch_acc=1.0000, running_acc=0.9807, grad=9.3801]Training epoch 47:  26%|██▋       | 43/163 [00:52<02:04,  1.04s/it, loss=0.1272, batch_acc=1.0000, running_acc=0.9807, grad=9.3801]Training epoch 47:  26%|██▋       | 43/163 [00:52<02:04,  1.04s/it, loss=0.0795, batch_acc=1.0000, running_acc=0.9811, grad=6.5881]Training epoch 47:  27%|██▋       | 44/163 [00:53<02:13,  1.13s/it, loss=0.0795, batch_acc=1.0000, running_acc=0.9811, grad=6.5881]Training epoch 47:  27%|██▋       | 44/163 [00:53<02:13,  1.13s/it, loss=0.0926, batch_acc=0.9688, running_acc=0.9808, grad=10.2963]Training epoch 47:  28%|██▊       | 45/163 [00:54<02:03,  1.05s/it, loss=0.0926, batch_acc=0.9688, running_acc=0.9808, grad=10.2963]Training epoch 47:  28%|██▊       | 45/163 [00:54<02:03,  1.05s/it, loss=0.1291, batch_acc=0.9688, running_acc=0.9806, grad=8.3609] Training epoch 47:  28%|██▊       | 46/163 [00:55<01:56,  1.00it/s, loss=0.1291, batch_acc=0.9688, running_acc=0.9806, grad=8.3609]Training epoch 47:  28%|██▊       | 46/163 [00:55<01:56,  1.00it/s, loss=0.0963, batch_acc=1.0000, running_acc=0.9810, grad=7.2974]Training epoch 47:  29%|██▉       | 47/163 [00:56<01:51,  1.04it/s, loss=0.0963, batch_acc=1.0000, running_acc=0.9810, grad=7.2974]Training epoch 47:  29%|██▉       | 47/163 [00:56<01:51,  1.04it/s, loss=0.0544, batch_acc=1.0000, running_acc=0.9814, grad=7.1541]Training epoch 47:  29%|██▉       | 48/163 [00:58<02:14,  1.17s/it, loss=0.0544, batch_acc=1.0000, running_acc=0.9814, grad=7.1541]Training epoch 47:  29%|██▉       | 48/163 [00:58<02:14,  1.17s/it, loss=0.0871, batch_acc=1.0000, running_acc=0.9818, grad=6.5327]Training epoch 47:  30%|███       | 49/163 [00:59<02:03,  1.08s/it, loss=0.0871, batch_acc=1.0000, running_acc=0.9818, grad=6.5327]Training epoch 47:  30%|███       | 49/163 [00:59<02:03,  1.08s/it, loss=0.1471, batch_acc=0.9375, running_acc=0.9809, grad=11.1477]Training epoch 47:  31%|███       | 50/163 [00:59<01:55,  1.02s/it, loss=0.1471, batch_acc=0.9375, running_acc=0.9809, grad=11.1477]Training epoch 47:  31%|███       | 50/163 [00:59<01:55,  1.02s/it, loss=0.1203, batch_acc=1.0000, running_acc=0.9812, grad=8.8761] Training epoch 47:  31%|███▏      | 51/163 [01:00<01:49,  1.02it/s, loss=0.1203, batch_acc=1.0000, running_acc=0.9812, grad=8.8761]Training epoch 47:  31%|███▏      | 51/163 [01:00<01:49,  1.02it/s, loss=0.1067, batch_acc=1.0000, running_acc=0.9816, grad=8.3038]Training epoch 47:  32%|███▏      | 52/163 [01:02<02:16,  1.23s/it, loss=0.1067, batch_acc=1.0000, running_acc=0.9816, grad=8.3038]Training epoch 47:  32%|███▏      | 52/163 [01:02<02:16,  1.23s/it, loss=0.1339, batch_acc=0.9688, running_acc=0.9814, grad=12.6691]Training epoch 47:  33%|███▎      | 53/163 [01:03<02:03,  1.12s/it, loss=0.1339, batch_acc=0.9688, running_acc=0.9814, grad=12.6691]Training epoch 47:  33%|███▎      | 53/163 [01:03<02:03,  1.12s/it, loss=0.0816, batch_acc=1.0000, running_acc=0.9817, grad=6.5338] Training epoch 47:  33%|███▎      | 54/163 [01:04<01:54,  1.05s/it, loss=0.0816, batch_acc=1.0000, running_acc=0.9817, grad=6.5338]Training epoch 47:  33%|███▎      | 54/163 [01:04<01:54,  1.05s/it, loss=0.1009, batch_acc=1.0000, running_acc=0.9821, grad=7.9086]Training epoch 47:  34%|███▎      | 55/163 [01:05<01:47,  1.00it/s, loss=0.1009, batch_acc=1.0000, running_acc=0.9821, grad=7.9086]Training epoch 47:  34%|███▎      | 55/163 [01:05<01:47,  1.00it/s, loss=0.0940, batch_acc=1.0000, running_acc=0.9824, grad=6.4982]Training epoch 47:  34%|███▍      | 56/163 [01:07<02:17,  1.28s/it, loss=0.0940, batch_acc=1.0000, running_acc=0.9824, grad=6.4982]Training epoch 47:  34%|███▍      | 56/163 [01:07<02:17,  1.28s/it, loss=0.1058, batch_acc=0.9688, running_acc=0.9821, grad=8.4842]Training epoch 47:  35%|███▍      | 57/163 [01:08<02:03,  1.16s/it, loss=0.1058, batch_acc=0.9688, running_acc=0.9821, grad=8.4842]Training epoch 47:  35%|███▍      | 57/163 [01:08<02:03,  1.16s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9825, grad=7.6182]Training epoch 47:  36%|███▌      | 58/163 [01:09<01:53,  1.08s/it, loss=0.1079, batch_acc=1.0000, running_acc=0.9825, grad=7.6182]Training epoch 47:  36%|███▌      | 58/163 [01:09<01:53,  1.08s/it, loss=0.0766, batch_acc=1.0000, running_acc=0.9828, grad=6.3877]Training epoch 47:  36%|███▌      | 59/163 [01:09<01:45,  1.02s/it, loss=0.0766, batch_acc=1.0000, running_acc=0.9828, grad=6.3877]Training epoch 47:  36%|███▌      | 59/163 [01:09<01:45,  1.02s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9831, grad=8.1888]Training epoch 47:  37%|███▋      | 60/163 [01:11<01:54,  1.11s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9831, grad=8.1888]Training epoch 47:  37%|███▋      | 60/163 [01:11<01:54,  1.11s/it, loss=0.0836, batch_acc=1.0000, running_acc=0.9833, grad=6.7379]Training epoch 47:  37%|███▋      | 61/163 [01:12<01:45,  1.04s/it, loss=0.0836, batch_acc=1.0000, running_acc=0.9833, grad=6.7379]Training epoch 47:  37%|███▋      | 61/163 [01:12<01:45,  1.04s/it, loss=0.0805, batch_acc=0.9688, running_acc=0.9831, grad=6.2320]Training epoch 47:  38%|███▊      | 62/163 [01:13<01:43,  1.03s/it, loss=0.0805, batch_acc=0.9688, running_acc=0.9831, grad=6.2320]Training epoch 47:  38%|███▊      | 62/163 [01:13<01:43,  1.03s/it, loss=0.0988, batch_acc=1.0000, running_acc=0.9834, grad=5.7761]Training epoch 47:  39%|███▊      | 63/163 [01:13<01:38,  1.02it/s, loss=0.0988, batch_acc=1.0000, running_acc=0.9834, grad=5.7761]Training epoch 47:  39%|███▊      | 63/163 [01:13<01:38,  1.02it/s, loss=0.1174, batch_acc=1.0000, running_acc=0.9836, grad=9.9807]Training epoch 47:  39%|███▉      | 64/163 [01:16<02:19,  1.41s/it, loss=0.1174, batch_acc=1.0000, running_acc=0.9836, grad=9.9807]Training epoch 47:  39%|███▉      | 64/163 [01:16<02:19,  1.41s/it, loss=0.0857, batch_acc=1.0000, running_acc=0.9839, grad=7.5877]Training epoch 47:  40%|███▉      | 65/163 [01:17<02:02,  1.25s/it, loss=0.0857, batch_acc=1.0000, running_acc=0.9839, grad=7.5877]Training epoch 47:  40%|███▉      | 65/163 [01:17<02:02,  1.25s/it, loss=0.0755, batch_acc=1.0000, running_acc=0.9841, grad=5.7779]Training epoch 47:  40%|████      | 66/163 [01:18<01:50,  1.14s/it, loss=0.0755, batch_acc=1.0000, running_acc=0.9841, grad=5.7779]Training epoch 47:  40%|████      | 66/163 [01:18<01:50,  1.14s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9839, grad=13.6285]Training epoch 47:  41%|████      | 67/163 [01:19<01:41,  1.06s/it, loss=0.1323, batch_acc=0.9688, running_acc=0.9839, grad=13.6285]Training epoch 47:  41%|████      | 67/163 [01:19<01:41,  1.06s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9841, grad=9.9981] Training epoch 47:  42%|████▏     | 68/163 [01:20<02:01,  1.28s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9841, grad=9.9981]Training epoch 47:  42%|████▏     | 68/163 [01:20<02:01,  1.28s/it, loss=0.1362, batch_acc=0.9688, running_acc=0.9839, grad=9.6140]Training epoch 47:  42%|████▏     | 69/163 [01:21<01:48,  1.16s/it, loss=0.1362, batch_acc=0.9688, running_acc=0.9839, grad=9.6140]Training epoch 47:  42%|████▏     | 69/163 [01:21<01:48,  1.16s/it, loss=0.0957, batch_acc=0.9688, running_acc=0.9837, grad=7.7734]Training epoch 47:  43%|████▎     | 70/163 [01:22<01:40,  1.08s/it, loss=0.0957, batch_acc=0.9688, running_acc=0.9837, grad=7.7734]Training epoch 47:  43%|████▎     | 70/163 [01:22<01:40,  1.08s/it, loss=0.0616, batch_acc=1.0000, running_acc=0.9839, grad=5.0186]Training epoch 47:  44%|████▎     | 71/163 [01:23<01:33,  1.02s/it, loss=0.0616, batch_acc=1.0000, running_acc=0.9839, grad=5.0186]Training epoch 47:  44%|████▎     | 71/163 [01:23<01:33,  1.02s/it, loss=0.1126, batch_acc=1.0000, running_acc=0.9842, grad=8.6695]Training epoch 47:  44%|████▍     | 72/163 [01:25<02:01,  1.33s/it, loss=0.1126, batch_acc=1.0000, running_acc=0.9842, grad=8.6695]Training epoch 47:  44%|████▍     | 72/163 [01:25<02:01,  1.33s/it, loss=0.0846, batch_acc=1.0000, running_acc=0.9844, grad=5.7530]Training epoch 47:  45%|████▍     | 73/163 [01:26<01:47,  1.20s/it, loss=0.0846, batch_acc=1.0000, running_acc=0.9844, grad=5.7530]Training epoch 47:  45%|████▍     | 73/163 [01:26<01:47,  1.20s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9842, grad=9.7100]Training epoch 47:  45%|████▌     | 74/163 [01:27<01:38,  1.10s/it, loss=0.1221, batch_acc=0.9688, running_acc=0.9842, grad=9.7100]Training epoch 47:  45%|████▌     | 74/163 [01:27<01:38,  1.10s/it, loss=0.1421, batch_acc=1.0000, running_acc=0.9844, grad=8.6712]Training epoch 47:  46%|████▌     | 75/163 [01:28<01:31,  1.04s/it, loss=0.1421, batch_acc=1.0000, running_acc=0.9844, grad=8.6712]Training epoch 47:  46%|████▌     | 75/163 [01:28<01:31,  1.04s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9842, grad=6.9534]Training epoch 47:  47%|████▋     | 76/163 [01:30<02:02,  1.41s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9842, grad=6.9534]Training epoch 47:  47%|████▋     | 76/163 [01:30<02:02,  1.41s/it, loss=0.0759, batch_acc=0.9688, running_acc=0.9840, grad=6.4713]Training epoch 47:  47%|████▋     | 77/163 [01:31<01:47,  1.25s/it, loss=0.0759, batch_acc=0.9688, running_acc=0.9840, grad=6.4713]Training epoch 47:  47%|████▋     | 77/163 [01:31<01:47,  1.25s/it, loss=0.1152, batch_acc=1.0000, running_acc=0.9842, grad=7.5644]Training epoch 47:  48%|████▊     | 78/163 [01:32<01:36,  1.14s/it, loss=0.1152, batch_acc=1.0000, running_acc=0.9842, grad=7.5644]Training epoch 47:  48%|████▊     | 78/163 [01:32<01:36,  1.14s/it, loss=0.0753, batch_acc=1.0000, running_acc=0.9844, grad=7.9469]Training epoch 47:  48%|████▊     | 79/163 [01:33<01:29,  1.06s/it, loss=0.0753, batch_acc=1.0000, running_acc=0.9844, grad=7.9469]Training epoch 47:  48%|████▊     | 79/163 [01:33<01:29,  1.06s/it, loss=0.1488, batch_acc=0.9688, running_acc=0.9842, grad=12.9162]Training epoch 47:  49%|████▉     | 80/163 [01:34<01:35,  1.15s/it, loss=0.1488, batch_acc=0.9688, running_acc=0.9842, grad=12.9162]Training epoch 47:  49%|████▉     | 80/163 [01:34<01:35,  1.15s/it, loss=0.1063, batch_acc=0.9375, running_acc=0.9836, grad=9.6981] Training epoch 47:  50%|████▉     | 81/163 [01:35<01:27,  1.07s/it, loss=0.1063, batch_acc=0.9375, running_acc=0.9836, grad=9.6981]Training epoch 47:  50%|████▉     | 81/163 [01:35<01:27,  1.07s/it, loss=0.1229, batch_acc=0.9688, running_acc=0.9834, grad=10.4462]Training epoch 47:  50%|█████     | 82/163 [01:36<01:21,  1.01s/it, loss=0.1229, batch_acc=0.9688, running_acc=0.9834, grad=10.4462]Training epoch 47:  50%|█████     | 82/163 [01:36<01:21,  1.01s/it, loss=0.0754, batch_acc=1.0000, running_acc=0.9836, grad=7.1438] Training epoch 47:  51%|█████     | 83/163 [01:37<01:17,  1.03it/s, loss=0.0754, batch_acc=1.0000, running_acc=0.9836, grad=7.1438]Training epoch 47:  51%|█████     | 83/163 [01:37<01:17,  1.03it/s, loss=0.1144, batch_acc=0.9688, running_acc=0.9834, grad=11.8663]Training epoch 47:  52%|█████▏    | 84/163 [01:39<01:46,  1.34s/it, loss=0.1144, batch_acc=0.9688, running_acc=0.9834, grad=11.8663]Training epoch 47:  52%|█████▏    | 84/163 [01:39<01:46,  1.34s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9836, grad=9.1370] Training epoch 47:  52%|█████▏    | 85/163 [01:40<01:33,  1.20s/it, loss=0.0939, batch_acc=1.0000, running_acc=0.9836, grad=9.1370]Training epoch 47:  52%|█████▏    | 85/163 [01:40<01:33,  1.20s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9838, grad=7.0241]Training epoch 47:  53%|█████▎    | 86/163 [01:41<01:25,  1.11s/it, loss=0.0773, batch_acc=1.0000, running_acc=0.9838, grad=7.0241]Training epoch 47:  53%|█████▎    | 86/163 [01:41<01:25,  1.11s/it, loss=0.0922, batch_acc=1.0000, running_acc=0.9840, grad=6.3393]Training epoch 47:  53%|█████▎    | 87/163 [01:41<01:19,  1.04s/it, loss=0.0922, batch_acc=1.0000, running_acc=0.9840, grad=6.3393]Training epoch 47:  53%|█████▎    | 87/163 [01:41<01:19,  1.04s/it, loss=0.1645, batch_acc=0.9375, running_acc=0.9835, grad=8.0718]Training epoch 47:  54%|█████▍    | 88/163 [01:43<01:27,  1.16s/it, loss=0.1645, batch_acc=0.9375, running_acc=0.9835, grad=8.0718]Training epoch 47:  54%|█████▍    | 88/163 [01:43<01:27,  1.16s/it, loss=0.0907, batch_acc=1.0000, running_acc=0.9837, grad=8.0941]Training epoch 47:  55%|█████▍    | 89/163 [01:44<01:19,  1.08s/it, loss=0.0907, batch_acc=1.0000, running_acc=0.9837, grad=8.0941]Training epoch 47:  55%|█████▍    | 89/163 [01:44<01:19,  1.08s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9838, grad=7.8418]Training epoch 47:  55%|█████▌    | 90/163 [01:45<01:15,  1.04s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9838, grad=7.8418]Training epoch 47:  55%|█████▌    | 90/163 [01:45<01:15,  1.04s/it, loss=0.1027, batch_acc=1.0000, running_acc=0.9840, grad=6.2024]Training epoch 47:  56%|█████▌    | 91/163 [01:46<01:12,  1.00s/it, loss=0.1027, batch_acc=1.0000, running_acc=0.9840, grad=6.2024]Training epoch 47:  56%|█████▌    | 91/163 [01:46<01:12,  1.00s/it, loss=0.1026, batch_acc=1.0000, running_acc=0.9842, grad=8.1964]Training epoch 47:  56%|█████▋    | 92/163 [01:47<01:21,  1.15s/it, loss=0.1026, batch_acc=1.0000, running_acc=0.9842, grad=8.1964]Training epoch 47:  56%|█████▋    | 92/163 [01:47<01:21,  1.15s/it, loss=0.1043, batch_acc=0.9688, running_acc=0.9840, grad=7.4496]Training epoch 47:  57%|█████▋    | 93/163 [01:48<01:14,  1.07s/it, loss=0.1043, batch_acc=0.9688, running_acc=0.9840, grad=7.4496]Training epoch 47:  57%|█████▋    | 93/163 [01:48<01:14,  1.07s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9842, grad=9.1797]Training epoch 47:  58%|█████▊    | 94/163 [01:49<01:09,  1.01s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9842, grad=9.1797]Training epoch 47:  58%|█████▊    | 94/163 [01:49<01:09,  1.01s/it, loss=0.0901, batch_acc=0.9688, running_acc=0.9840, grad=6.5975]Training epoch 47:  58%|█████▊    | 95/163 [01:50<01:06,  1.03it/s, loss=0.0901, batch_acc=0.9688, running_acc=0.9840, grad=6.5975]Training epoch 47:  58%|█████▊    | 95/163 [01:50<01:06,  1.03it/s, loss=0.0944, batch_acc=1.0000, running_acc=0.9842, grad=10.5362]Training epoch 47:  59%|█████▉    | 96/163 [01:52<01:31,  1.37s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9842, grad=10.5362]Training epoch 47:  59%|█████▉    | 96/163 [01:52<01:31,  1.37s/it, loss=0.1733, batch_acc=0.9688, running_acc=0.9840, grad=10.2023]Training epoch 47:  60%|█████▉    | 97/163 [01:53<01:20,  1.22s/it, loss=0.1733, batch_acc=0.9688, running_acc=0.9840, grad=10.2023]Training epoch 47:  60%|█████▉    | 97/163 [01:53<01:20,  1.22s/it, loss=0.0730, batch_acc=1.0000, running_acc=0.9842, grad=6.6606] Training epoch 47:  60%|██████    | 98/163 [01:54<01:12,  1.12s/it, loss=0.0730, batch_acc=1.0000, running_acc=0.9842, grad=6.6606]Training epoch 47:  60%|██████    | 98/163 [01:54<01:12,  1.12s/it, loss=0.1105, batch_acc=1.0000, running_acc=0.9844, grad=6.1825]Training epoch 47:  61%|██████    | 99/163 [01:55<01:06,  1.05s/it, loss=0.1105, batch_acc=1.0000, running_acc=0.9844, grad=6.1825]Training epoch 47:  61%|██████    | 99/163 [01:55<01:06,  1.05s/it, loss=0.0674, batch_acc=1.0000, running_acc=0.9845, grad=5.8362]Training epoch 47:  61%|██████▏   | 100/163 [01:57<01:23,  1.32s/it, loss=0.0674, batch_acc=1.0000, running_acc=0.9845, grad=5.8362]Training epoch 47:  61%|██████▏   | 100/163 [01:57<01:23,  1.32s/it, loss=0.1267, batch_acc=0.9688, running_acc=0.9844, grad=7.8917]Training epoch 47:  62%|██████▏   | 101/163 [01:58<01:13,  1.19s/it, loss=0.1267, batch_acc=0.9688, running_acc=0.9844, grad=7.8917]Training epoch 47:  62%|██████▏   | 101/163 [01:58<01:13,  1.19s/it, loss=0.1031, batch_acc=0.9688, running_acc=0.9842, grad=7.1665]Training epoch 47:  63%|██████▎   | 102/163 [01:58<01:06,  1.09s/it, loss=0.1031, batch_acc=0.9688, running_acc=0.9842, grad=7.1665]Training epoch 47:  63%|██████▎   | 102/163 [01:58<01:06,  1.09s/it, loss=0.0848, batch_acc=1.0000, running_acc=0.9844, grad=7.4113]Training epoch 47:  63%|██████▎   | 103/163 [01:59<01:01,  1.03s/it, loss=0.0848, batch_acc=1.0000, running_acc=0.9844, grad=7.4113]Training epoch 47:  63%|██████▎   | 103/163 [01:59<01:01,  1.03s/it, loss=0.0851, batch_acc=1.0000, running_acc=0.9845, grad=7.4897]Training epoch 47:  64%|██████▍   | 104/163 [02:01<01:05,  1.10s/it, loss=0.0851, batch_acc=1.0000, running_acc=0.9845, grad=7.4897]Training epoch 47:  64%|██████▍   | 104/163 [02:01<01:05,  1.10s/it, loss=0.0879, batch_acc=1.0000, running_acc=0.9847, grad=10.9411]Training epoch 47:  64%|██████▍   | 105/163 [02:01<00:59,  1.03s/it, loss=0.0879, batch_acc=1.0000, running_acc=0.9847, grad=10.9411]Training epoch 47:  64%|██████▍   | 105/163 [02:01<00:59,  1.03s/it, loss=0.0943, batch_acc=0.9688, running_acc=0.9845, grad=5.9758] Training epoch 47:  65%|██████▌   | 106/163 [02:02<00:58,  1.02s/it, loss=0.0943, batch_acc=0.9688, running_acc=0.9845, grad=5.9758]Training epoch 47:  65%|██████▌   | 106/163 [02:02<00:58,  1.02s/it, loss=0.1052, batch_acc=0.9688, running_acc=0.9844, grad=11.1456]Training epoch 47:  66%|██████▌   | 107/163 [02:03<00:54,  1.02it/s, loss=0.1052, batch_acc=0.9688, running_acc=0.9844, grad=11.1456]Training epoch 47:  66%|██████▌   | 107/163 [02:03<00:54,  1.02it/s, loss=0.1171, batch_acc=0.9688, running_acc=0.9842, grad=7.7071] Training epoch 47:  66%|██████▋   | 108/163 [02:05<01:08,  1.24s/it, loss=0.1171, batch_acc=0.9688, running_acc=0.9842, grad=7.7071]Training epoch 47:  66%|██████▋   | 108/163 [02:05<01:08,  1.24s/it, loss=0.0647, batch_acc=1.0000, running_acc=0.9844, grad=5.7986]Training epoch 47:  67%|██████▋   | 109/163 [02:06<01:01,  1.13s/it, loss=0.0647, batch_acc=1.0000, running_acc=0.9844, grad=5.7986]Training epoch 47:  67%|██████▋   | 109/163 [02:06<01:01,  1.13s/it, loss=0.1193, batch_acc=0.9688, running_acc=0.9842, grad=10.3803]Training epoch 47:  67%|██████▋   | 110/163 [02:07<00:55,  1.06s/it, loss=0.1193, batch_acc=0.9688, running_acc=0.9842, grad=10.3803]Training epoch 47:  67%|██████▋   | 110/163 [02:07<00:55,  1.06s/it, loss=0.0599, batch_acc=1.0000, running_acc=0.9844, grad=4.5222] Training epoch 47:  68%|██████▊   | 111/163 [02:08<00:52,  1.00s/it, loss=0.0599, batch_acc=1.0000, running_acc=0.9844, grad=4.5222]Training epoch 47:  68%|██████▊   | 111/163 [02:08<00:52,  1.00s/it, loss=0.0764, batch_acc=1.0000, running_acc=0.9845, grad=6.5352]Training epoch 47:  69%|██████▊   | 112/163 [02:09<01:01,  1.21s/it, loss=0.0764, batch_acc=1.0000, running_acc=0.9845, grad=6.5352]Training epoch 47:  69%|██████▊   | 112/163 [02:09<01:01,  1.21s/it, loss=0.0765, batch_acc=1.0000, running_acc=0.9847, grad=6.2556]Training epoch 47:  69%|██████▉   | 113/163 [02:10<00:55,  1.11s/it, loss=0.0765, batch_acc=1.0000, running_acc=0.9847, grad=6.2556]Training epoch 47:  69%|██████▉   | 113/163 [02:10<00:55,  1.11s/it, loss=0.0883, batch_acc=0.9688, running_acc=0.9845, grad=7.5095]Training epoch 47:  70%|██████▉   | 114/163 [02:11<00:51,  1.04s/it, loss=0.0883, batch_acc=0.9688, running_acc=0.9845, grad=7.5095]Training epoch 47:  70%|██████▉   | 114/163 [02:11<00:51,  1.04s/it, loss=0.1134, batch_acc=1.0000, running_acc=0.9846, grad=16.1885]Training epoch 47:  71%|███████   | 115/163 [02:12<00:47,  1.01it/s, loss=0.1134, batch_acc=1.0000, running_acc=0.9846, grad=16.1885]Training epoch 47:  71%|███████   | 115/163 [02:12<00:47,  1.01it/s, loss=0.0826, batch_acc=1.0000, running_acc=0.9848, grad=11.9731]Training epoch 47:  71%|███████   | 116/163 [02:14<00:58,  1.25s/it, loss=0.0826, batch_acc=1.0000, running_acc=0.9848, grad=11.9731]Training epoch 47:  71%|███████   | 116/163 [02:14<00:58,  1.25s/it, loss=0.1177, batch_acc=0.9688, running_acc=0.9846, grad=9.7723] Training epoch 47:  72%|███████▏  | 117/163 [02:15<00:52,  1.14s/it, loss=0.1177, batch_acc=0.9688, running_acc=0.9846, grad=9.7723]Training epoch 47:  72%|███████▏  | 117/163 [02:15<00:52,  1.14s/it, loss=0.0818, batch_acc=1.0000, running_acc=0.9848, grad=7.7899]Training epoch 47:  72%|███████▏  | 118/163 [02:16<00:47,  1.06s/it, loss=0.0818, batch_acc=1.0000, running_acc=0.9848, grad=7.7899]Training epoch 47:  72%|███████▏  | 118/163 [02:16<00:47,  1.06s/it, loss=0.1343, batch_acc=0.9688, running_acc=0.9846, grad=9.7097]Training epoch 47:  73%|███████▎  | 119/163 [02:17<00:44,  1.01s/it, loss=0.1343, batch_acc=0.9688, running_acc=0.9846, grad=9.7097]Training epoch 47:  73%|███████▎  | 119/163 [02:17<00:44,  1.01s/it, loss=0.1193, batch_acc=0.9688, running_acc=0.9845, grad=12.4854]Training epoch 47:  74%|███████▎  | 120/163 [02:18<00:52,  1.22s/it, loss=0.1193, batch_acc=0.9688, running_acc=0.9845, grad=12.4854]Training epoch 47:  74%|███████▎  | 120/163 [02:18<00:52,  1.22s/it, loss=0.1218, batch_acc=1.0000, running_acc=0.9846, grad=8.4513] Training epoch 47:  74%|███████▍  | 121/163 [02:19<00:46,  1.12s/it, loss=0.1218, batch_acc=1.0000, running_acc=0.9846, grad=8.4513]Training epoch 47:  74%|███████▍  | 121/163 [02:19<00:46,  1.12s/it, loss=0.1105, batch_acc=1.0000, running_acc=0.9848, grad=10.7598]Training epoch 47:  75%|███████▍  | 122/163 [02:20<00:42,  1.05s/it, loss=0.1105, batch_acc=1.0000, running_acc=0.9848, grad=10.7598]Training epoch 47:  75%|███████▍  | 122/163 [02:20<00:42,  1.05s/it, loss=0.1163, batch_acc=0.9688, running_acc=0.9846, grad=13.8842]Training epoch 47:  75%|███████▌  | 123/163 [02:21<00:39,  1.00it/s, loss=0.1163, batch_acc=0.9688, running_acc=0.9846, grad=13.8842]Training epoch 47:  75%|███████▌  | 123/163 [02:21<00:39,  1.00it/s, loss=0.0690, batch_acc=1.0000, running_acc=0.9848, grad=6.2057] Training epoch 47:  76%|███████▌  | 124/163 [02:23<00:46,  1.19s/it, loss=0.0690, batch_acc=1.0000, running_acc=0.9848, grad=6.2057]Training epoch 47:  76%|███████▌  | 124/163 [02:23<00:46,  1.19s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9846, grad=8.0179]Training epoch 47:  77%|███████▋  | 125/163 [02:23<00:41,  1.10s/it, loss=0.1145, batch_acc=0.9688, running_acc=0.9846, grad=8.0179]Training epoch 47:  77%|███████▋  | 125/163 [02:23<00:41,  1.10s/it, loss=0.1070, batch_acc=0.9688, running_acc=0.9845, grad=7.5895]Training epoch 47:  77%|███████▋  | 126/163 [02:24<00:38,  1.03s/it, loss=0.1070, batch_acc=0.9688, running_acc=0.9845, grad=7.5895]Training epoch 47:  77%|███████▋  | 126/163 [02:24<00:38,  1.03s/it, loss=0.0961, batch_acc=1.0000, running_acc=0.9846, grad=9.6162]Training epoch 47:  78%|███████▊  | 127/163 [02:25<00:35,  1.01it/s, loss=0.0961, batch_acc=1.0000, running_acc=0.9846, grad=9.6162]Training epoch 47:  78%|███████▊  | 127/163 [02:25<00:35,  1.01it/s, loss=0.1170, batch_acc=0.9688, running_acc=0.9845, grad=11.8456]Training epoch 47:  79%|███████▊  | 128/163 [02:27<00:41,  1.18s/it, loss=0.1170, batch_acc=0.9688, running_acc=0.9845, grad=11.8456]Training epoch 47:  79%|███████▊  | 128/163 [02:27<00:41,  1.18s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9844, grad=11.2832]Training epoch 47:  79%|███████▉  | 129/163 [02:28<00:37,  1.09s/it, loss=0.1457, batch_acc=0.9688, running_acc=0.9844, grad=11.2832]Training epoch 47:  79%|███████▉  | 129/163 [02:28<00:37,  1.09s/it, loss=0.1510, batch_acc=0.9688, running_acc=0.9843, grad=20.3298]Training epoch 47:  80%|███████▉  | 130/163 [02:29<00:40,  1.22s/it, loss=0.1510, batch_acc=0.9688, running_acc=0.9843, grad=20.3298]Training epoch 47:  80%|███████▉  | 130/163 [02:29<00:40,  1.22s/it, loss=0.1078, batch_acc=1.0000, running_acc=0.9844, grad=13.3054]Training epoch 47:  80%|████████  | 131/163 [02:30<00:35,  1.12s/it, loss=0.1078, batch_acc=1.0000, running_acc=0.9844, grad=13.3054]Training epoch 47:  80%|████████  | 131/163 [02:30<00:35,  1.12s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9845, grad=10.4524]Training epoch 47:  81%|████████  | 132/163 [02:31<00:34,  1.11s/it, loss=0.0944, batch_acc=1.0000, running_acc=0.9845, grad=10.4524]Training epoch 47:  81%|████████  | 132/163 [02:31<00:34,  1.11s/it, loss=0.0667, batch_acc=1.0000, running_acc=0.9846, grad=6.3826] Training epoch 47:  82%|████████▏ | 133/163 [02:32<00:31,  1.04s/it, loss=0.0667, batch_acc=1.0000, running_acc=0.9846, grad=6.3826]Training epoch 47:  82%|████████▏ | 133/163 [02:32<00:31,  1.04s/it, loss=0.1092, batch_acc=1.0000, running_acc=0.9847, grad=11.2604]Training epoch 47:  82%|████████▏ | 134/163 [02:33<00:30,  1.05s/it, loss=0.1092, batch_acc=1.0000, running_acc=0.9847, grad=11.2604]Training epoch 47:  82%|████████▏ | 134/163 [02:33<00:30,  1.05s/it, loss=0.1154, batch_acc=0.9688, running_acc=0.9846, grad=9.9327] Training epoch 47:  83%|████████▎ | 135/163 [02:34<00:28,  1.00s/it, loss=0.1154, batch_acc=0.9688, running_acc=0.9846, grad=9.9327]Training epoch 47:  83%|████████▎ | 135/163 [02:34<00:28,  1.00s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9845, grad=7.4428]Training epoch 47:  83%|████████▎ | 136/163 [02:35<00:29,  1.11s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9845, grad=7.4428]Training epoch 47:  83%|████████▎ | 136/163 [02:35<00:29,  1.11s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9846, grad=7.7485]Training epoch 47:  84%|████████▍ | 137/163 [02:36<00:27,  1.04s/it, loss=0.0927, batch_acc=1.0000, running_acc=0.9846, grad=7.7485]Training epoch 47:  84%|████████▍ | 137/163 [02:36<00:27,  1.04s/it, loss=0.1209, batch_acc=0.9688, running_acc=0.9845, grad=9.7084]Training epoch 47:  85%|████████▍ | 138/163 [02:38<00:27,  1.10s/it, loss=0.1209, batch_acc=0.9688, running_acc=0.9845, grad=9.7084]Training epoch 47:  85%|████████▍ | 138/163 [02:38<00:27,  1.10s/it, loss=0.1098, batch_acc=0.9688, running_acc=0.9844, grad=7.9751]Training epoch 47:  85%|████████▌ | 139/163 [02:38<00:24,  1.03s/it, loss=0.1098, batch_acc=0.9688, running_acc=0.9844, grad=7.9751]Training epoch 47:  85%|████████▌ | 139/163 [02:38<00:24,  1.03s/it, loss=0.0808, batch_acc=1.0000, running_acc=0.9845, grad=7.4965]Training epoch 47:  86%|████████▌ | 140/163 [02:40<00:26,  1.17s/it, loss=0.0808, batch_acc=1.0000, running_acc=0.9845, grad=7.4965]Training epoch 47:  86%|████████▌ | 140/163 [02:40<00:26,  1.17s/it, loss=0.1047, batch_acc=1.0000, running_acc=0.9846, grad=6.9568]Training epoch 47:  87%|████████▋ | 141/163 [02:41<00:23,  1.08s/it, loss=0.1047, batch_acc=1.0000, running_acc=0.9846, grad=6.9568]Training epoch 47:  87%|████████▋ | 141/163 [02:41<00:23,  1.08s/it, loss=0.0926, batch_acc=1.0000, running_acc=0.9847, grad=7.9274]Training epoch 47:  87%|████████▋ | 142/163 [02:42<00:24,  1.17s/it, loss=0.0926, batch_acc=1.0000, running_acc=0.9847, grad=7.9274]Training epoch 47:  87%|████████▋ | 142/163 [02:42<00:24,  1.17s/it, loss=0.1373, batch_acc=0.9688, running_acc=0.9846, grad=8.8357]Training epoch 47:  88%|████████▊ | 143/163 [02:43<00:21,  1.09s/it, loss=0.1373, batch_acc=0.9688, running_acc=0.9846, grad=8.8357]Training epoch 47:  88%|████████▊ | 143/163 [02:43<00:21,  1.09s/it, loss=0.0652, batch_acc=1.0000, running_acc=0.9847, grad=5.5171]Training epoch 47:  88%|████████▊ | 144/163 [02:44<00:19,  1.04s/it, loss=0.0652, batch_acc=1.0000, running_acc=0.9847, grad=5.5171]Training epoch 47:  88%|████████▊ | 144/163 [02:44<00:19,  1.04s/it, loss=0.0869, batch_acc=1.0000, running_acc=0.9848, grad=9.6138]Training epoch 47:  89%|████████▉ | 145/163 [02:45<00:17,  1.01it/s, loss=0.0869, batch_acc=1.0000, running_acc=0.9848, grad=9.6138]Training epoch 47:  89%|████████▉ | 145/163 [02:45<00:17,  1.01it/s, loss=0.1365, batch_acc=0.9062, running_acc=0.9843, grad=7.3874]Training epoch 47:  90%|████████▉ | 146/163 [02:47<00:23,  1.39s/it, loss=0.1365, batch_acc=0.9062, running_acc=0.9843, grad=7.3874]Training epoch 47:  90%|████████▉ | 146/163 [02:47<00:23,  1.39s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9844, grad=8.6312]Training epoch 47:  90%|█████████ | 147/163 [02:48<00:19,  1.24s/it, loss=0.1028, batch_acc=1.0000, running_acc=0.9844, grad=8.6312]Training epoch 47:  90%|█████████ | 147/163 [02:48<00:19,  1.24s/it, loss=0.0908, batch_acc=1.0000, running_acc=0.9845, grad=8.8535]Training epoch 47:  91%|█████████ | 148/163 [02:49<00:16,  1.13s/it, loss=0.0908, batch_acc=1.0000, running_acc=0.9845, grad=8.8535]Training epoch 47:  91%|█████████ | 148/163 [02:49<00:16,  1.13s/it, loss=0.0938, batch_acc=1.0000, running_acc=0.9846, grad=8.6679]Training epoch 47:  91%|█████████▏| 149/163 [02:50<00:14,  1.06s/it, loss=0.0938, batch_acc=1.0000, running_acc=0.9846, grad=8.6679]Training epoch 47:  91%|█████████▏| 149/163 [02:50<00:14,  1.06s/it, loss=0.0885, batch_acc=1.0000, running_acc=0.9847, grad=5.1270]Training epoch 47:  92%|█████████▏| 150/163 [02:51<00:15,  1.17s/it, loss=0.0885, batch_acc=1.0000, running_acc=0.9847, grad=5.1270]Training epoch 47:  92%|█████████▏| 150/163 [02:51<00:15,  1.17s/it, loss=0.1227, batch_acc=1.0000, running_acc=0.9848, grad=10.8150]Training epoch 47:  93%|█████████▎| 151/163 [02:52<00:12,  1.08s/it, loss=0.1227, batch_acc=1.0000, running_acc=0.9848, grad=10.8150]Training epoch 47:  93%|█████████▎| 151/163 [02:52<00:12,  1.08s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9847, grad=6.6807] Training epoch 47:  93%|█████████▎| 152/163 [02:53<00:11,  1.02s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9847, grad=6.6807]Training epoch 47:  93%|█████████▎| 152/163 [02:53<00:11,  1.02s/it, loss=0.1197, batch_acc=0.9688, running_acc=0.9846, grad=8.3554]Training epoch 47:  94%|█████████▍| 153/163 [02:54<00:09,  1.02it/s, loss=0.1197, batch_acc=0.9688, running_acc=0.9846, grad=8.3554]Training epoch 47:  94%|█████████▍| 153/163 [02:54<00:09,  1.02it/s, loss=0.0721, batch_acc=1.0000, running_acc=0.9847, grad=8.0541]Training epoch 47:  94%|█████████▍| 154/163 [02:56<00:12,  1.39s/it, loss=0.0721, batch_acc=1.0000, running_acc=0.9847, grad=8.0541]Training epoch 47:  94%|█████████▍| 154/163 [02:56<00:12,  1.39s/it, loss=0.1224, batch_acc=0.9688, running_acc=0.9846, grad=9.5445]Training epoch 47:  95%|█████████▌| 155/163 [02:57<00:09,  1.24s/it, loss=0.1224, batch_acc=0.9688, running_acc=0.9846, grad=9.5445]Training epoch 47:  95%|█████████▌| 155/163 [02:57<00:09,  1.24s/it, loss=0.0737, batch_acc=1.0000, running_acc=0.9847, grad=5.3693]Training epoch 47:  96%|█████████▌| 156/163 [02:58<00:08,  1.16s/it, loss=0.0737, batch_acc=1.0000, running_acc=0.9847, grad=5.3693]Training epoch 47:  96%|█████████▌| 156/163 [02:58<00:08,  1.16s/it, loss=0.1458, batch_acc=0.9688, running_acc=0.9846, grad=8.3144]Training epoch 47:  96%|█████████▋| 157/163 [02:59<00:06,  1.07s/it, loss=0.1458, batch_acc=0.9688, running_acc=0.9846, grad=8.3144]Training epoch 47:  96%|█████████▋| 157/163 [02:59<00:06,  1.07s/it, loss=0.0764, batch_acc=1.0000, running_acc=0.9847, grad=6.4919]Training epoch 47:  97%|█████████▋| 158/163 [03:00<00:05,  1.17s/it, loss=0.0764, batch_acc=1.0000, running_acc=0.9847, grad=6.4919]Training epoch 47:  97%|█████████▋| 158/163 [03:00<00:05,  1.17s/it, loss=0.0815, batch_acc=1.0000, running_acc=0.9848, grad=5.5795]Training epoch 47:  98%|█████████▊| 159/163 [03:01<00:04,  1.08s/it, loss=0.0815, batch_acc=1.0000, running_acc=0.9848, grad=5.5795]Training epoch 47:  98%|█████████▊| 159/163 [03:01<00:04,  1.08s/it, loss=0.1120, batch_acc=0.9688, running_acc=0.9847, grad=9.3276]Training epoch 47:  98%|█████████▊| 160/163 [03:02<00:03,  1.02s/it, loss=0.1120, batch_acc=0.9688, running_acc=0.9847, grad=9.3276]Training epoch 47:  98%|█████████▊| 160/163 [03:02<00:03,  1.02s/it, loss=0.1304, batch_acc=0.9688, running_acc=0.9846, grad=12.7918]Training epoch 47:  99%|█████████▉| 161/163 [03:03<00:01,  1.02it/s, loss=0.1304, batch_acc=0.9688, running_acc=0.9846, grad=12.7918]Training epoch 47:  99%|█████████▉| 161/163 [03:03<00:01,  1.02it/s, loss=0.1155, batch_acc=0.9688, running_acc=0.9845, grad=8.4761] Training epoch 47:  99%|█████████▉| 162/163 [03:04<00:00,  1.05it/s, loss=0.1155, batch_acc=0.9688, running_acc=0.9845, grad=8.4761]Training epoch 47:  99%|█████████▉| 162/163 [03:04<00:00,  1.05it/s, loss=0.2043, batch_acc=0.9062, running_acc=0.9840, grad=12.5362]Training epoch 47: 100%|██████████| 163/163 [03:05<00:00,  1.17it/s, loss=0.2043, batch_acc=0.9062, running_acc=0.9840, grad=12.5362]Training epoch 47: 100%|██████████| 163/163 [03:05<00:00,  1.17it/s, loss=0.0697, batch_acc=1.0000, running_acc=0.9841, grad=8.5014] Training epoch 47: 100%|██████████| 163/163 [03:05<00:00,  1.14s/it, loss=0.0697, batch_acc=1.0000, running_acc=0.9841, grad=8.5014]
Evaluation epoch 47:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 47:   4%|▎         | 1/28 [00:04<02:07,  4.73s/it]Evaluation epoch 47:   4%|▎         | 1/28 [00:04<02:07,  4.73s/it, loss=0.3883, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 47:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.3883, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 47:   7%|▋         | 2/28 [00:05<00:56,  2.19s/it, loss=0.2270, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 47:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.2270, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 47:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.2909, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 47:  14%|█▍        | 4/28 [00:09<00:57,  2.41s/it, loss=0.2909, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 47:  14%|█▍        | 4/28 [00:09<00:57,  2.41s/it, loss=0.4046, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 47:  18%|█▊        | 5/28 [00:09<00:37,  1.63s/it, loss=0.4046, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 47:  18%|█▊        | 5/28 [00:09<00:37,  1.63s/it, loss=1.3086, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 47:  21%|██▏       | 6/28 [00:10<00:25,  1.17s/it, loss=1.3086, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 47:  21%|██▏       | 6/28 [00:10<00:25,  1.17s/it, loss=0.5123, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 47:  25%|██▌       | 7/28 [00:10<00:18,  1.15it/s, loss=0.5123, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 47:  25%|██▌       | 7/28 [00:10<00:18,  1.15it/s, loss=0.6235, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 47:  29%|██▊       | 8/28 [00:13<00:32,  1.65s/it, loss=0.6235, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 47:  29%|██▊       | 8/28 [00:13<00:32,  1.65s/it, loss=0.3989, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 47:  32%|███▏      | 9/28 [00:14<00:25,  1.34s/it, loss=0.3989, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 47:  32%|███▏      | 9/28 [00:14<00:25,  1.34s/it, loss=0.4235, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 47:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.4235, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 47:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.4378, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 47:  39%|███▉      | 11/28 [00:14<00:13,  1.29it/s, loss=0.4378, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 47:  39%|███▉      | 11/28 [00:14<00:13,  1.29it/s, loss=0.3002, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 47:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=0.3002, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 47:  43%|████▎     | 12/28 [00:20<00:35,  2.23s/it, loss=0.8723, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 47:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=0.8723, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 47:  46%|████▋     | 13/28 [00:20<00:24,  1.64s/it, loss=0.2672, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 47:  50%|█████     | 14/28 [00:20<00:17,  1.22s/it, loss=0.2672, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 47:  50%|█████     | 14/28 [00:20<00:17,  1.22s/it, loss=0.8537, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 47:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=0.8537, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 47:  54%|█████▎    | 15/28 [00:21<00:12,  1.07it/s, loss=0.9312, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 47:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=0.9312, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 47:  57%|█████▋    | 16/28 [00:24<00:18,  1.54s/it, loss=0.7594, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 47:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.7594, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 47:  61%|██████    | 17/28 [00:24<00:12,  1.15s/it, loss=0.6182, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 47:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.6182, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 47:  64%|██████▍   | 18/28 [00:24<00:08,  1.13it/s, loss=0.5200, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 47:  68%|██████▊   | 19/28 [00:24<00:06,  1.43it/s, loss=0.5200, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 47:  68%|██████▊   | 19/28 [00:24<00:06,  1.43it/s, loss=0.8623, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 47:  71%|███████▏  | 20/28 [00:28<00:12,  1.57s/it, loss=0.8623, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 47:  71%|███████▏  | 20/28 [00:28<00:12,  1.57s/it, loss=0.5675, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 47:  75%|███████▌  | 21/28 [00:28<00:08,  1.18s/it, loss=0.5675, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 47:  75%|███████▌  | 21/28 [00:28<00:08,  1.18s/it, loss=0.5742, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 47:  79%|███████▊  | 22/28 [00:28<00:05,  1.11it/s, loss=0.5742, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 47:  79%|███████▊  | 22/28 [00:28<00:05,  1.11it/s, loss=0.4134, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 47:  82%|████████▏ | 23/28 [00:29<00:03,  1.40it/s, loss=0.4134, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 47:  82%|████████▏ | 23/28 [00:29<00:03,  1.40it/s, loss=0.7754, batch_acc=0.7812, running_acc=0.8492]Evaluation epoch 47:  86%|████████▌ | 24/28 [00:34<00:08,  2.15s/it, loss=0.7754, batch_acc=0.7812, running_acc=0.8492]Evaluation epoch 47:  86%|████████▌ | 24/28 [00:34<00:08,  2.15s/it, loss=0.3066, batch_acc=0.9375, running_acc=0.8529]Evaluation epoch 47:  89%|████████▉ | 25/28 [00:35<00:04,  1.59s/it, loss=0.3066, batch_acc=0.9375, running_acc=0.8529]Evaluation epoch 47:  89%|████████▉ | 25/28 [00:35<00:04,  1.59s/it, loss=0.1276, batch_acc=1.0000, running_acc=0.8588]Evaluation epoch 47:  93%|█████████▎| 26/28 [00:35<00:02,  1.19s/it, loss=0.1276, batch_acc=1.0000, running_acc=0.8588]Evaluation epoch 47:  93%|█████████▎| 26/28 [00:35<00:02,  1.19s/it, loss=0.5393, batch_acc=0.8438, running_acc=0.8582]Evaluation epoch 47:  96%|█████████▋| 27/28 [00:35<00:00,  1.10it/s, loss=0.5393, batch_acc=0.8438, running_acc=0.8582]Evaluation epoch 47:  96%|█████████▋| 27/28 [00:35<00:00,  1.10it/s, loss=0.8345, batch_acc=0.7812, running_acc=0.8553]Evaluation epoch 47: 100%|██████████| 28/28 [00:35<00:00,  1.10it/s, loss=1.1366, batch_acc=0.6667, running_acc=0.8547]Evaluation epoch 47: 100%|██████████| 28/28 [00:35<00:00,  1.27s/it, loss=1.1366, batch_acc=0.6667, running_acc=0.8547]
Training epoch 48:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 48:   1%|          | 1/163 [00:06<16:38,  6.16s/it]Training epoch 48:   1%|          | 1/163 [00:06<16:38,  6.16s/it, loss=0.1174, batch_acc=0.9688, running_acc=0.9688, grad=6.7683]Training epoch 48:   1%|          | 2/163 [00:07<08:11,  3.06s/it, loss=0.1174, batch_acc=0.9688, running_acc=0.9688, grad=6.7683]Training epoch 48:   1%|          | 2/163 [00:07<08:11,  3.06s/it, loss=0.0846, batch_acc=1.0000, running_acc=0.9844, grad=7.4460]Training epoch 48:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=0.0846, batch_acc=1.0000, running_acc=0.9844, grad=7.4460]Training epoch 48:   2%|▏         | 3/163 [00:07<05:29,  2.06s/it, loss=0.0586, batch_acc=1.0000, running_acc=0.9896, grad=4.6371]Training epoch 48:   2%|▏         | 4/163 [00:11<07:06,  2.68s/it, loss=0.0586, batch_acc=1.0000, running_acc=0.9896, grad=4.6371]Training epoch 48:   2%|▏         | 4/163 [00:11<07:06,  2.68s/it, loss=0.1480, batch_acc=0.9688, running_acc=0.9844, grad=12.2045]Training epoch 48:   3%|▎         | 5/163 [00:12<05:21,  2.03s/it, loss=0.1480, batch_acc=0.9688, running_acc=0.9844, grad=12.2045]Training epoch 48:   3%|▎         | 5/163 [00:12<05:21,  2.03s/it, loss=0.1302, batch_acc=1.0000, running_acc=0.9875, grad=7.4623] Training epoch 48:   4%|▎         | 6/163 [00:13<04:17,  1.64s/it, loss=0.1302, batch_acc=1.0000, running_acc=0.9875, grad=7.4623]Training epoch 48:   4%|▎         | 6/163 [00:13<04:17,  1.64s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9896, grad=7.8617]Training epoch 48:   4%|▍         | 7/163 [00:14<03:37,  1.39s/it, loss=0.0890, batch_acc=1.0000, running_acc=0.9896, grad=7.8617]Training epoch 48:   4%|▍         | 7/163 [00:14<03:37,  1.39s/it, loss=0.1337, batch_acc=0.9688, running_acc=0.9866, grad=13.3525]Training epoch 48:   5%|▍         | 8/163 [00:16<04:04,  1.58s/it, loss=0.1337, batch_acc=0.9688, running_acc=0.9866, grad=13.3525]Training epoch 48:   5%|▍         | 8/163 [00:16<04:04,  1.58s/it, loss=0.1734, batch_acc=0.9688, running_acc=0.9844, grad=8.2281] Training epoch 48:   6%|▌         | 9/163 [00:17<03:29,  1.36s/it, loss=0.1734, batch_acc=0.9688, running_acc=0.9844, grad=8.2281]Training epoch 48:   6%|▌         | 9/163 [00:17<03:29,  1.36s/it, loss=0.0930, batch_acc=0.9688, running_acc=0.9826, grad=7.6631]Training epoch 48:   6%|▌         | 10/163 [00:17<03:05,  1.21s/it, loss=0.0930, batch_acc=0.9688, running_acc=0.9826, grad=7.6631]Training epoch 48:   6%|▌         | 10/163 [00:17<03:05,  1.21s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9844, grad=10.6329]Training epoch 48:   7%|▋         | 11/163 [00:18<02:48,  1.11s/it, loss=0.0943, batch_acc=1.0000, running_acc=0.9844, grad=10.6329]Training epoch 48:   7%|▋         | 11/163 [00:18<02:48,  1.11s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9858, grad=9.8931] Training epoch 48:   7%|▋         | 12/163 [00:20<03:09,  1.25s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9858, grad=9.8931]Training epoch 48:   7%|▋         | 12/163 [00:20<03:09,  1.25s/it, loss=0.1039, batch_acc=1.0000, running_acc=0.9870, grad=7.5606]Training epoch 48:   8%|▊         | 13/163 [00:21<02:50,  1.14s/it, loss=0.1039, batch_acc=1.0000, running_acc=0.9870, grad=7.5606]Training epoch 48:   8%|▊         | 13/163 [00:21<02:50,  1.14s/it, loss=0.1183, batch_acc=0.9688, running_acc=0.9856, grad=6.3895]Training epoch 48:   9%|▊         | 14/163 [00:22<02:38,  1.06s/it, loss=0.1183, batch_acc=0.9688, running_acc=0.9856, grad=6.3895]Training epoch 48:   9%|▊         | 14/163 [00:22<02:38,  1.06s/it, loss=0.0697, batch_acc=1.0000, running_acc=0.9866, grad=5.6624]Training epoch 48:   9%|▉         | 15/163 [00:23<02:28,  1.01s/it, loss=0.0697, batch_acc=1.0000, running_acc=0.9866, grad=5.6624]Training epoch 48:   9%|▉         | 15/163 [00:23<02:28,  1.01s/it, loss=0.1435, batch_acc=0.9375, running_acc=0.9833, grad=12.7058]Training epoch 48:  10%|▉         | 16/163 [00:24<03:02,  1.24s/it, loss=0.1435, batch_acc=0.9375, running_acc=0.9833, grad=12.7058]Training epoch 48:  10%|▉         | 16/163 [00:24<03:02,  1.24s/it, loss=0.1118, batch_acc=0.9688, running_acc=0.9824, grad=7.5682] Training epoch 48:  10%|█         | 17/163 [00:25<02:45,  1.14s/it, loss=0.1118, batch_acc=0.9688, running_acc=0.9824, grad=7.5682]Training epoch 48:  10%|█         | 17/163 [00:25<02:45,  1.14s/it, loss=0.1053, batch_acc=1.0000, running_acc=0.9835, grad=10.6909]Training epoch 48:  11%|█         | 18/163 [00:26<02:33,  1.06s/it, loss=0.1053, batch_acc=1.0000, running_acc=0.9835, grad=10.6909]Training epoch 48:  11%|█         | 18/163 [00:26<02:33,  1.06s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9826, grad=9.4774] Training epoch 48:  12%|█▏        | 19/163 [00:27<02:24,  1.00s/it, loss=0.1106, batch_acc=0.9688, running_acc=0.9826, grad=9.4774]Training epoch 48:  12%|█▏        | 19/163 [00:27<02:24,  1.00s/it, loss=0.0615, batch_acc=1.0000, running_acc=0.9836, grad=4.8111]Training epoch 48:  12%|█▏        | 20/163 [00:29<03:01,  1.27s/it, loss=0.0615, batch_acc=1.0000, running_acc=0.9836, grad=4.8111]Training epoch 48:  12%|█▏        | 20/163 [00:29<03:01,  1.27s/it, loss=0.0550, batch_acc=1.0000, running_acc=0.9844, grad=4.0212]Training epoch 48:  13%|█▎        | 21/163 [00:30<02:43,  1.15s/it, loss=0.0550, batch_acc=1.0000, running_acc=0.9844, grad=4.0212]Training epoch 48:  13%|█▎        | 21/163 [00:30<02:43,  1.15s/it, loss=0.1307, batch_acc=0.9688, running_acc=0.9836, grad=8.7117]Training epoch 48:  13%|█▎        | 22/163 [00:31<02:30,  1.07s/it, loss=0.1307, batch_acc=0.9688, running_acc=0.9836, grad=8.7117]Training epoch 48:  13%|█▎        | 22/163 [00:31<02:30,  1.07s/it, loss=0.1115, batch_acc=0.9688, running_acc=0.9830, grad=9.4097]Training epoch 48:  14%|█▍        | 23/163 [00:31<02:21,  1.01s/it, loss=0.1115, batch_acc=0.9688, running_acc=0.9830, grad=9.4097]Training epoch 48:  14%|█▍        | 23/163 [00:31<02:21,  1.01s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9837, grad=7.9324]Training epoch 48:  15%|█▍        | 24/163 [00:33<02:39,  1.14s/it, loss=0.1151, batch_acc=1.0000, running_acc=0.9837, grad=7.9324]Training epoch 48:  15%|█▍        | 24/163 [00:33<02:39,  1.14s/it, loss=0.1167, batch_acc=1.0000, running_acc=0.9844, grad=17.9456]Training epoch 48:  15%|█▌        | 25/163 [00:34<02:27,  1.07s/it, loss=0.1167, batch_acc=1.0000, running_acc=0.9844, grad=17.9456]Training epoch 48:  15%|█▌        | 25/163 [00:34<02:27,  1.07s/it, loss=0.1519, batch_acc=0.9375, running_acc=0.9825, grad=11.9160]Training epoch 48:  16%|█▌        | 26/163 [00:35<02:18,  1.01s/it, loss=0.1519, batch_acc=0.9375, running_acc=0.9825, grad=11.9160]Training epoch 48:  16%|█▌        | 26/163 [00:35<02:18,  1.01s/it, loss=0.0908, batch_acc=1.0000, running_acc=0.9832, grad=6.5921] Training epoch 48:  17%|█▋        | 27/163 [00:36<02:11,  1.03it/s, loss=0.0908, batch_acc=1.0000, running_acc=0.9832, grad=6.5921]Training epoch 48:  17%|█▋        | 27/163 [00:36<02:11,  1.03it/s, loss=0.1015, batch_acc=1.0000, running_acc=0.9838, grad=7.7599]Training epoch 48:  17%|█▋        | 28/163 [00:37<02:32,  1.13s/it, loss=0.1015, batch_acc=1.0000, running_acc=0.9838, grad=7.7599]Training epoch 48:  17%|█▋        | 28/163 [00:37<02:32,  1.13s/it, loss=0.0950, batch_acc=1.0000, running_acc=0.9844, grad=10.5886]Training epoch 48:  18%|█▊        | 29/163 [00:38<02:21,  1.06s/it, loss=0.0950, batch_acc=1.0000, running_acc=0.9844, grad=10.5886]Training epoch 48:  18%|█▊        | 29/163 [00:38<02:21,  1.06s/it, loss=0.1566, batch_acc=0.9688, running_acc=0.9838, grad=10.2327]Training epoch 48:  18%|█▊        | 30/163 [00:39<02:13,  1.00s/it, loss=0.1566, batch_acc=0.9688, running_acc=0.9838, grad=10.2327]Training epoch 48:  18%|█▊        | 30/163 [00:39<02:13,  1.00s/it, loss=0.0951, batch_acc=1.0000, running_acc=0.9844, grad=6.2401] Training epoch 48:  19%|█▉        | 31/163 [00:40<02:07,  1.04it/s, loss=0.0951, batch_acc=1.0000, running_acc=0.9844, grad=6.2401]Training epoch 48:  19%|█▉        | 31/163 [00:40<02:07,  1.04it/s, loss=0.0782, batch_acc=1.0000, running_acc=0.9849, grad=6.0715]Training epoch 48:  20%|█▉        | 32/163 [00:41<02:36,  1.20s/it, loss=0.0782, batch_acc=1.0000, running_acc=0.9849, grad=6.0715]Training epoch 48:  20%|█▉        | 32/163 [00:41<02:36,  1.20s/it, loss=0.1004, batch_acc=1.0000, running_acc=0.9854, grad=12.0106]Training epoch 48:  20%|██        | 33/163 [00:42<02:23,  1.10s/it, loss=0.1004, batch_acc=1.0000, running_acc=0.9854, grad=12.0106]Training epoch 48:  20%|██        | 33/163 [00:42<02:23,  1.10s/it, loss=0.0939, batch_acc=0.9688, running_acc=0.9848, grad=7.7244] Training epoch 48:  21%|██        | 34/163 [00:43<02:13,  1.04s/it, loss=0.0939, batch_acc=0.9688, running_acc=0.9848, grad=7.7244]Training epoch 48:  21%|██        | 34/163 [00:43<02:13,  1.04s/it, loss=0.1023, batch_acc=1.0000, running_acc=0.9853, grad=8.9456]Training epoch 48:  21%|██▏       | 35/163 [00:44<02:06,  1.01it/s, loss=0.1023, batch_acc=1.0000, running_acc=0.9853, grad=8.9456]Training epoch 48:  21%|██▏       | 35/163 [00:44<02:06,  1.01it/s, loss=0.1089, batch_acc=1.0000, running_acc=0.9857, grad=8.9740]Training epoch 48:  22%|██▏       | 36/163 [00:46<02:39,  1.25s/it, loss=0.1089, batch_acc=1.0000, running_acc=0.9857, grad=8.9740]Training epoch 48:  22%|██▏       | 36/163 [00:46<02:39,  1.25s/it, loss=0.0887, batch_acc=1.0000, running_acc=0.9861, grad=9.4723]Training epoch 48:  23%|██▎       | 37/163 [00:47<02:23,  1.14s/it, loss=0.0887, batch_acc=1.0000, running_acc=0.9861, grad=9.4723]Training epoch 48:  23%|██▎       | 37/163 [00:47<02:23,  1.14s/it, loss=0.0997, batch_acc=1.0000, running_acc=0.9865, grad=18.1256]Training epoch 48:  23%|██▎       | 38/163 [00:48<02:12,  1.06s/it, loss=0.0997, batch_acc=1.0000, running_acc=0.9865, grad=18.1256]Training epoch 48:  23%|██▎       | 38/163 [00:48<02:12,  1.06s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9868, grad=7.8024] Training epoch 48:  24%|██▍       | 39/163 [00:49<02:04,  1.01s/it, loss=0.1093, batch_acc=1.0000, running_acc=0.9868, grad=7.8024]Training epoch 48:  24%|██▍       | 39/163 [00:49<02:04,  1.01s/it, loss=0.1149, batch_acc=0.9688, running_acc=0.9864, grad=5.9417]Training epoch 48:  25%|██▍       | 40/163 [00:50<02:24,  1.18s/it, loss=0.1149, batch_acc=0.9688, running_acc=0.9864, grad=5.9417]Training epoch 48:  25%|██▍       | 40/163 [00:50<02:24,  1.18s/it, loss=0.0628, batch_acc=1.0000, running_acc=0.9867, grad=5.0401]Training epoch 48:  25%|██▌       | 41/163 [00:51<02:12,  1.09s/it, loss=0.0628, batch_acc=1.0000, running_acc=0.9867, grad=5.0401]Training epoch 48:  25%|██▌       | 41/163 [00:51<02:12,  1.09s/it, loss=0.1014, batch_acc=1.0000, running_acc=0.9870, grad=8.4528]Training epoch 48:  26%|██▌       | 42/163 [00:52<02:04,  1.03s/it, loss=0.1014, batch_acc=1.0000, running_acc=0.9870, grad=8.4528]Training epoch 48:  26%|██▌       | 42/163 [00:52<02:04,  1.03s/it, loss=0.1236, batch_acc=0.9688, running_acc=0.9866, grad=8.4867]Training epoch 48:  26%|██▋       | 43/163 [00:53<01:57,  1.02it/s, loss=0.1236, batch_acc=0.9688, running_acc=0.9866, grad=8.4867]Training epoch 48:  26%|██▋       | 43/163 [00:53<01:57,  1.02it/s, loss=0.1207, batch_acc=1.0000, running_acc=0.9869, grad=11.6993]Training epoch 48:  27%|██▋       | 44/163 [00:55<02:25,  1.22s/it, loss=0.1207, batch_acc=1.0000, running_acc=0.9869, grad=11.6993]Training epoch 48:  27%|██▋       | 44/163 [00:55<02:25,  1.22s/it, loss=0.0790, batch_acc=1.0000, running_acc=0.9872, grad=5.6930] Training epoch 48:  28%|██▊       | 45/163 [00:55<02:12,  1.12s/it, loss=0.0790, batch_acc=1.0000, running_acc=0.9872, grad=5.6930]Training epoch 48:  28%|██▊       | 45/163 [00:55<02:12,  1.12s/it, loss=0.1009, batch_acc=0.9688, running_acc=0.9868, grad=7.7025]Training epoch 48:  28%|██▊       | 46/163 [00:56<02:02,  1.05s/it, loss=0.1009, batch_acc=0.9688, running_acc=0.9868, grad=7.7025]Training epoch 48:  28%|██▊       | 46/163 [00:56<02:02,  1.05s/it, loss=0.0885, batch_acc=0.9688, running_acc=0.9864, grad=7.4692]Training epoch 48:  29%|██▉       | 47/163 [00:57<01:55,  1.00it/s, loss=0.0885, batch_acc=0.9688, running_acc=0.9864, grad=7.4692]Training epoch 48:  29%|██▉       | 47/163 [00:57<01:55,  1.00it/s, loss=0.1160, batch_acc=0.9688, running_acc=0.9860, grad=9.9411]Training epoch 48:  29%|██▉       | 48/163 [00:59<02:13,  1.16s/it, loss=0.1160, batch_acc=0.9688, running_acc=0.9860, grad=9.9411]Training epoch 48:  29%|██▉       | 48/163 [00:59<02:13,  1.16s/it, loss=0.0973, batch_acc=1.0000, running_acc=0.9863, grad=8.1400]Training epoch 48:  30%|███       | 49/163 [01:00<02:02,  1.07s/it, loss=0.0973, batch_acc=1.0000, running_acc=0.9863, grad=8.1400]Training epoch 48:  30%|███       | 49/163 [01:00<02:02,  1.07s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9866, grad=10.6555]Training epoch 48:  31%|███       | 50/163 [01:01<01:58,  1.04s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9866, grad=10.6555]Training epoch 48:  31%|███       | 50/163 [01:01<01:58,  1.04s/it, loss=0.1383, batch_acc=0.9688, running_acc=0.9862, grad=11.8110]Training epoch 48:  31%|███▏      | 51/163 [01:02<01:51,  1.01it/s, loss=0.1383, batch_acc=0.9688, running_acc=0.9862, grad=11.8110]Training epoch 48:  31%|███▏      | 51/163 [01:02<01:51,  1.01it/s, loss=0.1400, batch_acc=0.9688, running_acc=0.9859, grad=10.3227]Training epoch 48:  32%|███▏      | 52/163 [01:03<02:03,  1.11s/it, loss=0.1400, batch_acc=0.9688, running_acc=0.9859, grad=10.3227]Training epoch 48:  32%|███▏      | 52/163 [01:03<02:03,  1.11s/it, loss=0.1411, batch_acc=0.9375, running_acc=0.9850, grad=7.7448] Training epoch 48:  33%|███▎      | 53/163 [01:04<01:54,  1.04s/it, loss=0.1411, batch_acc=0.9375, running_acc=0.9850, grad=7.7448]Training epoch 48:  33%|███▎      | 53/163 [01:04<01:54,  1.04s/it, loss=0.1994, batch_acc=0.9062, running_acc=0.9835, grad=12.4512]Training epoch 48:  33%|███▎      | 54/163 [01:05<01:49,  1.01s/it, loss=0.1994, batch_acc=0.9062, running_acc=0.9835, grad=12.4512]Training epoch 48:  33%|███▎      | 54/163 [01:05<01:49,  1.01s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9838, grad=6.4570] Training epoch 48:  34%|███▎      | 55/163 [01:06<01:44,  1.03it/s, loss=0.0812, batch_acc=1.0000, running_acc=0.9838, grad=6.4570]Training epoch 48:  34%|███▎      | 55/163 [01:06<01:44,  1.03it/s, loss=0.1046, batch_acc=1.0000, running_acc=0.9841, grad=12.9227]Training epoch 48:  34%|███▍      | 56/163 [01:08<02:14,  1.26s/it, loss=0.1046, batch_acc=1.0000, running_acc=0.9841, grad=12.9227]Training epoch 48:  34%|███▍      | 56/163 [01:08<02:14,  1.26s/it, loss=0.1097, batch_acc=1.0000, running_acc=0.9844, grad=9.6805] Training epoch 48:  35%|███▍      | 57/163 [01:08<02:01,  1.14s/it, loss=0.1097, batch_acc=1.0000, running_acc=0.9844, grad=9.6805]Training epoch 48:  35%|███▍      | 57/163 [01:08<02:01,  1.14s/it, loss=0.0675, batch_acc=1.0000, running_acc=0.9846, grad=6.0060]Training epoch 48:  36%|███▌      | 58/163 [01:09<01:51,  1.07s/it, loss=0.0675, batch_acc=1.0000, running_acc=0.9846, grad=6.0060]Training epoch 48:  36%|███▌      | 58/163 [01:09<01:51,  1.07s/it, loss=0.1139, batch_acc=1.0000, running_acc=0.9849, grad=8.1696]Training epoch 48:  36%|███▌      | 59/163 [01:10<01:44,  1.01s/it, loss=0.1139, batch_acc=1.0000, running_acc=0.9849, grad=8.1696]Training epoch 48:  36%|███▌      | 59/163 [01:10<01:44,  1.01s/it, loss=0.0981, batch_acc=0.9688, running_acc=0.9846, grad=6.6670]Training epoch 48:  37%|███▋      | 60/163 [01:12<02:09,  1.25s/it, loss=0.0981, batch_acc=0.9688, running_acc=0.9846, grad=6.6670]Training epoch 48:  37%|███▋      | 60/163 [01:12<02:09,  1.25s/it, loss=0.1069, batch_acc=0.9688, running_acc=0.9844, grad=9.4846]Training epoch 48:  37%|███▋      | 61/163 [01:13<01:56,  1.14s/it, loss=0.1069, batch_acc=0.9688, running_acc=0.9844, grad=9.4846]Training epoch 48:  37%|███▋      | 61/163 [01:13<01:56,  1.14s/it, loss=0.0720, batch_acc=1.0000, running_acc=0.9846, grad=7.4045]Training epoch 48:  38%|███▊      | 62/163 [01:14<01:47,  1.06s/it, loss=0.0720, batch_acc=1.0000, running_acc=0.9846, grad=7.4045]Training epoch 48:  38%|███▊      | 62/163 [01:14<01:47,  1.06s/it, loss=0.1054, batch_acc=0.9688, running_acc=0.9844, grad=7.1842]Training epoch 48:  39%|███▊      | 63/163 [01:15<01:40,  1.01s/it, loss=0.1054, batch_acc=0.9688, running_acc=0.9844, grad=7.1842]Training epoch 48:  39%|███▊      | 63/163 [01:15<01:40,  1.01s/it, loss=0.0714, batch_acc=1.0000, running_acc=0.9846, grad=5.7607]Training epoch 48:  39%|███▉      | 64/163 [01:16<01:55,  1.17s/it, loss=0.0714, batch_acc=1.0000, running_acc=0.9846, grad=5.7607]Training epoch 48:  39%|███▉      | 64/163 [01:16<01:55,  1.17s/it, loss=0.1391, batch_acc=0.9688, running_acc=0.9844, grad=10.3599]Training epoch 48:  40%|███▉      | 65/163 [01:17<01:46,  1.08s/it, loss=0.1391, batch_acc=0.9688, running_acc=0.9844, grad=10.3599]Training epoch 48:  40%|███▉      | 65/163 [01:17<01:46,  1.08s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9841, grad=7.0992] Training epoch 48:  40%|████      | 66/163 [01:18<01:39,  1.02s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9841, grad=7.0992]Training epoch 48:  40%|████      | 66/163 [01:18<01:39,  1.02s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9844, grad=6.7300]Training epoch 48:  41%|████      | 67/163 [01:19<01:33,  1.02it/s, loss=0.0731, batch_acc=1.0000, running_acc=0.9844, grad=6.7300]Training epoch 48:  41%|████      | 67/163 [01:19<01:33,  1.02it/s, loss=0.1085, batch_acc=1.0000, running_acc=0.9846, grad=8.6147]Training epoch 48:  42%|████▏     | 68/163 [01:21<02:00,  1.27s/it, loss=0.1085, batch_acc=1.0000, running_acc=0.9846, grad=8.6147]Training epoch 48:  42%|████▏     | 68/163 [01:21<02:00,  1.27s/it, loss=0.1284, batch_acc=1.0000, running_acc=0.9848, grad=8.3740]Training epoch 48:  42%|████▏     | 69/163 [01:22<01:48,  1.15s/it, loss=0.1284, batch_acc=1.0000, running_acc=0.9848, grad=8.3740]Training epoch 48:  42%|████▏     | 69/163 [01:22<01:48,  1.15s/it, loss=0.1113, batch_acc=1.0000, running_acc=0.9851, grad=9.2227]Training epoch 48:  43%|████▎     | 70/163 [01:23<01:39,  1.07s/it, loss=0.1113, batch_acc=1.0000, running_acc=0.9851, grad=9.2227]Training epoch 48:  43%|████▎     | 70/163 [01:23<01:39,  1.07s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9853, grad=9.8719]Training epoch 48:  44%|████▎     | 71/163 [01:23<01:33,  1.01s/it, loss=0.0788, batch_acc=1.0000, running_acc=0.9853, grad=9.8719]Training epoch 48:  44%|████▎     | 71/163 [01:23<01:33,  1.01s/it, loss=0.0650, batch_acc=1.0000, running_acc=0.9855, grad=4.7827]Training epoch 48:  44%|████▍     | 72/163 [01:24<01:32,  1.02s/it, loss=0.0650, batch_acc=1.0000, running_acc=0.9855, grad=4.7827]Training epoch 48:  44%|████▍     | 72/163 [01:24<01:32,  1.02s/it, loss=0.0924, batch_acc=0.9688, running_acc=0.9852, grad=6.7349]Training epoch 48:  45%|████▍     | 73/163 [01:25<01:28,  1.02it/s, loss=0.0924, batch_acc=0.9688, running_acc=0.9852, grad=6.7349]Training epoch 48:  45%|████▍     | 73/163 [01:25<01:28,  1.02it/s, loss=0.0864, batch_acc=1.0000, running_acc=0.9854, grad=8.6668]Training epoch 48:  45%|████▌     | 74/163 [01:27<01:34,  1.06s/it, loss=0.0864, batch_acc=1.0000, running_acc=0.9854, grad=8.6668]Training epoch 48:  45%|████▌     | 74/163 [01:27<01:34,  1.06s/it, loss=0.1462, batch_acc=1.0000, running_acc=0.9856, grad=14.0574]Training epoch 48:  46%|████▌     | 75/163 [01:27<01:28,  1.01s/it, loss=0.1462, batch_acc=1.0000, running_acc=0.9856, grad=14.0574]Training epoch 48:  46%|████▌     | 75/163 [01:27<01:28,  1.01s/it, loss=0.1393, batch_acc=1.0000, running_acc=0.9858, grad=9.8456] Training epoch 48:  47%|████▋     | 76/163 [01:29<01:29,  1.03s/it, loss=0.1393, batch_acc=1.0000, running_acc=0.9858, grad=9.8456]Training epoch 48:  47%|████▋     | 76/163 [01:29<01:29,  1.03s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9860, grad=8.5575]Training epoch 48:  47%|████▋     | 77/163 [01:29<01:26,  1.01s/it, loss=0.1016, batch_acc=1.0000, running_acc=0.9860, grad=8.5575]Training epoch 48:  47%|████▋     | 77/163 [01:29<01:26,  1.01s/it, loss=0.1277, batch_acc=0.9688, running_acc=0.9858, grad=10.2131]Training epoch 48:  48%|████▊     | 78/163 [01:31<01:38,  1.15s/it, loss=0.1277, batch_acc=0.9688, running_acc=0.9858, grad=10.2131]Training epoch 48:  48%|████▊     | 78/163 [01:31<01:38,  1.15s/it, loss=0.0821, batch_acc=1.0000, running_acc=0.9860, grad=6.5618] Training epoch 48:  48%|████▊     | 79/163 [01:32<01:29,  1.07s/it, loss=0.0821, batch_acc=1.0000, running_acc=0.9860, grad=6.5618]Training epoch 48:  48%|████▊     | 79/163 [01:32<01:29,  1.07s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9862, grad=11.5511]Training epoch 48:  49%|████▉     | 80/163 [01:33<01:31,  1.10s/it, loss=0.1356, batch_acc=1.0000, running_acc=0.9862, grad=11.5511]Training epoch 48:  49%|████▉     | 80/163 [01:33<01:31,  1.10s/it, loss=0.0757, batch_acc=1.0000, running_acc=0.9863, grad=6.4580] Training epoch 48:  50%|████▉     | 81/163 [01:34<01:24,  1.03s/it, loss=0.0757, batch_acc=1.0000, running_acc=0.9863, grad=6.4580]Training epoch 48:  50%|████▉     | 81/163 [01:34<01:24,  1.03s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9865, grad=10.1670]Training epoch 48:  50%|█████     | 82/163 [01:35<01:37,  1.20s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9865, grad=10.1670]Training epoch 48:  50%|█████     | 82/163 [01:35<01:37,  1.20s/it, loss=0.0922, batch_acc=1.0000, running_acc=0.9867, grad=6.8184] Training epoch 48:  51%|█████     | 83/163 [01:36<01:28,  1.10s/it, loss=0.0922, batch_acc=1.0000, running_acc=0.9867, grad=6.8184]Training epoch 48:  51%|█████     | 83/163 [01:36<01:28,  1.10s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9868, grad=14.2556]Training epoch 48:  52%|█████▏    | 84/163 [01:38<01:30,  1.15s/it, loss=0.1195, batch_acc=1.0000, running_acc=0.9868, grad=14.2556]Training epoch 48:  52%|█████▏    | 84/163 [01:38<01:30,  1.15s/it, loss=0.1043, batch_acc=0.9688, running_acc=0.9866, grad=7.8048] Training epoch 48:  52%|█████▏    | 85/163 [01:39<01:23,  1.07s/it, loss=0.1043, batch_acc=0.9688, running_acc=0.9866, grad=7.8048]Training epoch 48:  52%|█████▏    | 85/163 [01:39<01:23,  1.07s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9868, grad=6.0675]Training epoch 48:  53%|█████▎    | 86/163 [01:40<01:28,  1.15s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9868, grad=6.0675]Training epoch 48:  53%|█████▎    | 86/163 [01:40<01:28,  1.15s/it, loss=0.1007, batch_acc=0.9688, running_acc=0.9866, grad=7.3148]Training epoch 48:  53%|█████▎    | 87/163 [01:41<01:21,  1.07s/it, loss=0.1007, batch_acc=0.9688, running_acc=0.9866, grad=7.3148]Training epoch 48:  53%|█████▎    | 87/163 [01:41<01:21,  1.07s/it, loss=0.0962, batch_acc=0.9688, running_acc=0.9864, grad=7.8545]Training epoch 48:  54%|█████▍    | 88/163 [01:42<01:34,  1.26s/it, loss=0.0962, batch_acc=0.9688, running_acc=0.9864, grad=7.8545]Training epoch 48:  54%|█████▍    | 88/163 [01:42<01:34,  1.26s/it, loss=0.1315, batch_acc=0.9375, running_acc=0.9858, grad=10.9277]Training epoch 48:  55%|█████▍    | 89/163 [01:43<01:24,  1.14s/it, loss=0.1315, batch_acc=0.9375, running_acc=0.9858, grad=10.9277]Training epoch 48:  55%|█████▍    | 89/163 [01:43<01:24,  1.14s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9860, grad=8.6543] Training epoch 48:  55%|█████▌    | 90/163 [01:44<01:22,  1.13s/it, loss=0.0770, batch_acc=1.0000, running_acc=0.9860, grad=8.6543]Training epoch 48:  55%|█████▌    | 90/163 [01:44<01:22,  1.13s/it, loss=0.1164, batch_acc=0.9375, running_acc=0.9854, grad=6.3202]Training epoch 48:  56%|█████▌    | 91/163 [01:45<01:15,  1.05s/it, loss=0.1164, batch_acc=0.9375, running_acc=0.9854, grad=6.3202]Training epoch 48:  56%|█████▌    | 91/163 [01:45<01:15,  1.05s/it, loss=0.0704, batch_acc=1.0000, running_acc=0.9856, grad=6.3654]Training epoch 48:  56%|█████▋    | 92/163 [01:47<01:27,  1.24s/it, loss=0.0704, batch_acc=1.0000, running_acc=0.9856, grad=6.3654]Training epoch 48:  56%|█████▋    | 92/163 [01:47<01:27,  1.24s/it, loss=0.1545, batch_acc=0.9375, running_acc=0.9851, grad=14.1370]Training epoch 48:  57%|█████▋    | 93/163 [01:48<01:19,  1.13s/it, loss=0.1545, batch_acc=0.9375, running_acc=0.9851, grad=14.1370]Training epoch 48:  57%|█████▋    | 93/163 [01:48<01:19,  1.13s/it, loss=0.0714, batch_acc=1.0000, running_acc=0.9852, grad=6.2698] Training epoch 48:  58%|█████▊    | 94/163 [01:49<01:13,  1.06s/it, loss=0.0714, batch_acc=1.0000, running_acc=0.9852, grad=6.2698]Training epoch 48:  58%|█████▊    | 94/163 [01:49<01:13,  1.06s/it, loss=0.0616, batch_acc=1.0000, running_acc=0.9854, grad=7.2048]Training epoch 48:  58%|█████▊    | 95/163 [01:50<01:08,  1.00s/it, loss=0.0616, batch_acc=1.0000, running_acc=0.9854, grad=7.2048]Training epoch 48:  58%|█████▊    | 95/163 [01:50<01:08,  1.00s/it, loss=0.1046, batch_acc=0.9688, running_acc=0.9852, grad=6.6614]Training epoch 48:  59%|█████▉    | 96/163 [01:51<01:17,  1.16s/it, loss=0.1046, batch_acc=0.9688, running_acc=0.9852, grad=6.6614]Training epoch 48:  59%|█████▉    | 96/163 [01:51<01:17,  1.16s/it, loss=0.0855, batch_acc=0.9688, running_acc=0.9850, grad=5.7924]Training epoch 48:  60%|█████▉    | 97/163 [01:52<01:10,  1.07s/it, loss=0.0855, batch_acc=0.9688, running_acc=0.9850, grad=5.7924]Training epoch 48:  60%|█████▉    | 97/163 [01:52<01:10,  1.07s/it, loss=0.0513, batch_acc=1.0000, running_acc=0.9852, grad=4.2309]Training epoch 48:  60%|██████    | 98/163 [01:53<01:06,  1.03s/it, loss=0.0513, batch_acc=1.0000, running_acc=0.9852, grad=4.2309]Training epoch 48:  60%|██████    | 98/163 [01:53<01:06,  1.03s/it, loss=0.1112, batch_acc=0.9688, running_acc=0.9850, grad=6.1074]Training epoch 48:  61%|██████    | 99/163 [01:54<01:02,  1.02it/s, loss=0.1112, batch_acc=0.9688, running_acc=0.9850, grad=6.1074]Training epoch 48:  61%|██████    | 99/163 [01:54<01:02,  1.02it/s, loss=0.0768, batch_acc=1.0000, running_acc=0.9852, grad=5.5499]Training epoch 48:  61%|██████▏   | 100/163 [01:56<01:18,  1.24s/it, loss=0.0768, batch_acc=1.0000, running_acc=0.9852, grad=5.5499]Training epoch 48:  61%|██████▏   | 100/163 [01:56<01:18,  1.24s/it, loss=0.1433, batch_acc=0.9375, running_acc=0.9847, grad=9.3228]Training epoch 48:  62%|██████▏   | 101/163 [01:57<01:10,  1.13s/it, loss=0.1433, batch_acc=0.9375, running_acc=0.9847, grad=9.3228]Training epoch 48:  62%|██████▏   | 101/163 [01:57<01:10,  1.13s/it, loss=0.1124, batch_acc=1.0000, running_acc=0.9848, grad=11.1993]Training epoch 48:  63%|██████▎   | 102/163 [01:57<01:04,  1.06s/it, loss=0.1124, batch_acc=1.0000, running_acc=0.9848, grad=11.1993]Training epoch 48:  63%|██████▎   | 102/163 [01:57<01:04,  1.06s/it, loss=0.1592, batch_acc=0.9375, running_acc=0.9844, grad=9.4267] Training epoch 48:  63%|██████▎   | 103/163 [01:58<01:00,  1.00s/it, loss=0.1592, batch_acc=0.9375, running_acc=0.9844, grad=9.4267]Training epoch 48:  63%|██████▎   | 103/163 [01:58<01:00,  1.00s/it, loss=0.1063, batch_acc=1.0000, running_acc=0.9845, grad=8.1653]Training epoch 48:  64%|██████▍   | 104/163 [02:00<01:10,  1.20s/it, loss=0.1063, batch_acc=1.0000, running_acc=0.9845, grad=8.1653]Training epoch 48:  64%|██████▍   | 104/163 [02:00<01:10,  1.20s/it, loss=0.1449, batch_acc=0.9375, running_acc=0.9841, grad=15.3002]Training epoch 48:  64%|██████▍   | 105/163 [02:01<01:04,  1.11s/it, loss=0.1449, batch_acc=0.9375, running_acc=0.9841, grad=15.3002]Training epoch 48:  64%|██████▍   | 105/163 [02:01<01:04,  1.11s/it, loss=0.0790, batch_acc=1.0000, running_acc=0.9842, grad=7.3789] Training epoch 48:  65%|██████▌   | 106/163 [02:02<00:59,  1.04s/it, loss=0.0790, batch_acc=1.0000, running_acc=0.9842, grad=7.3789]Training epoch 48:  65%|██████▌   | 106/163 [02:02<00:59,  1.04s/it, loss=0.1018, batch_acc=1.0000, running_acc=0.9844, grad=9.9029]Training epoch 48:  66%|██████▌   | 107/163 [02:03<00:55,  1.01it/s, loss=0.1018, batch_acc=1.0000, running_acc=0.9844, grad=9.9029]Training epoch 48:  66%|██████▌   | 107/163 [02:03<00:55,  1.01it/s, loss=0.1336, batch_acc=1.0000, running_acc=0.9845, grad=7.4837]Training epoch 48:  66%|██████▋   | 108/163 [02:05<01:14,  1.35s/it, loss=0.1336, batch_acc=1.0000, running_acc=0.9845, grad=7.4837]Training epoch 48:  66%|██████▋   | 108/163 [02:05<01:14,  1.35s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9847, grad=11.8429]Training epoch 48:  67%|██████▋   | 109/163 [02:06<01:05,  1.21s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9847, grad=11.8429]Training epoch 48:  67%|██████▋   | 109/163 [02:06<01:05,  1.21s/it, loss=0.0880, batch_acc=1.0000, running_acc=0.9848, grad=9.5896] Training epoch 48:  67%|██████▋   | 110/163 [02:07<00:58,  1.11s/it, loss=0.0880, batch_acc=1.0000, running_acc=0.9848, grad=9.5896]Training epoch 48:  67%|██████▋   | 110/163 [02:07<00:58,  1.11s/it, loss=0.1536, batch_acc=0.9688, running_acc=0.9847, grad=16.0055]Training epoch 48:  68%|██████▊   | 111/163 [02:07<00:54,  1.04s/it, loss=0.1536, batch_acc=0.9688, running_acc=0.9847, grad=16.0055]Training epoch 48:  68%|██████▊   | 111/163 [02:07<00:54,  1.04s/it, loss=0.1237, batch_acc=0.9375, running_acc=0.9842, grad=7.6285] Training epoch 48:  69%|██████▊   | 112/163 [02:09<01:04,  1.27s/it, loss=0.1237, batch_acc=0.9375, running_acc=0.9842, grad=7.6285]Training epoch 48:  69%|██████▊   | 112/163 [02:09<01:04,  1.27s/it, loss=0.1496, batch_acc=0.9375, running_acc=0.9838, grad=12.6376]Training epoch 48:  69%|██████▉   | 113/163 [02:10<00:57,  1.15s/it, loss=0.1496, batch_acc=0.9375, running_acc=0.9838, grad=12.6376]Training epoch 48:  69%|██████▉   | 113/163 [02:10<00:57,  1.15s/it, loss=0.0836, batch_acc=0.9688, running_acc=0.9837, grad=7.8909] Training epoch 48:  70%|██████▉   | 114/163 [02:11<00:52,  1.07s/it, loss=0.0836, batch_acc=0.9688, running_acc=0.9837, grad=7.8909]Training epoch 48:  70%|██████▉   | 114/163 [02:11<00:52,  1.07s/it, loss=0.0888, batch_acc=1.0000, running_acc=0.9838, grad=5.4527]Training epoch 48:  71%|███████   | 115/163 [02:12<00:48,  1.01s/it, loss=0.0888, batch_acc=1.0000, running_acc=0.9838, grad=5.4527]Training epoch 48:  71%|███████   | 115/163 [02:12<00:48,  1.01s/it, loss=0.1351, batch_acc=0.9688, running_acc=0.9837, grad=10.3558]Training epoch 48:  71%|███████   | 116/163 [02:13<00:54,  1.16s/it, loss=0.1351, batch_acc=0.9688, running_acc=0.9837, grad=10.3558]Training epoch 48:  71%|███████   | 116/163 [02:13<00:54,  1.16s/it, loss=0.0561, batch_acc=1.0000, running_acc=0.9838, grad=4.5905] Training epoch 48:  72%|███████▏  | 117/163 [02:14<00:49,  1.08s/it, loss=0.0561, batch_acc=1.0000, running_acc=0.9838, grad=4.5905]Training epoch 48:  72%|███████▏  | 117/163 [02:14<00:49,  1.08s/it, loss=0.1268, batch_acc=0.9688, running_acc=0.9837, grad=7.9618]Training epoch 48:  72%|███████▏  | 118/163 [02:15<00:45,  1.02s/it, loss=0.1268, batch_acc=0.9688, running_acc=0.9837, grad=7.9618]Training epoch 48:  72%|███████▏  | 118/163 [02:15<00:45,  1.02s/it, loss=0.0724, batch_acc=1.0000, running_acc=0.9838, grad=6.1742]Training epoch 48:  73%|███████▎  | 119/163 [02:16<00:42,  1.03it/s, loss=0.0724, batch_acc=1.0000, running_acc=0.9838, grad=6.1742]Training epoch 48:  73%|███████▎  | 119/163 [02:16<00:42,  1.03it/s, loss=0.0911, batch_acc=1.0000, running_acc=0.9840, grad=7.2461]Training epoch 48:  74%|███████▎  | 120/163 [02:18<00:53,  1.25s/it, loss=0.0911, batch_acc=1.0000, running_acc=0.9840, grad=7.2461]Training epoch 48:  74%|███████▎  | 120/163 [02:18<00:53,  1.25s/it, loss=0.0873, batch_acc=1.0000, running_acc=0.9841, grad=5.7746]Training epoch 48:  74%|███████▍  | 121/163 [02:19<00:47,  1.14s/it, loss=0.0873, batch_acc=1.0000, running_acc=0.9841, grad=5.7746]Training epoch 48:  74%|███████▍  | 121/163 [02:19<00:47,  1.14s/it, loss=0.1374, batch_acc=0.9688, running_acc=0.9840, grad=16.0932]Training epoch 48:  75%|███████▍  | 122/163 [02:20<00:44,  1.09s/it, loss=0.1374, batch_acc=0.9688, running_acc=0.9840, grad=16.0932]Training epoch 48:  75%|███████▍  | 122/163 [02:20<00:44,  1.09s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9841, grad=6.5413] Training epoch 48:  75%|███████▌  | 123/163 [02:21<00:40,  1.02s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9841, grad=6.5413]Training epoch 48:  75%|███████▌  | 123/163 [02:21<00:40,  1.02s/it, loss=0.0889, batch_acc=1.0000, running_acc=0.9842, grad=7.4577]Training epoch 48:  76%|███████▌  | 124/163 [02:22<00:46,  1.19s/it, loss=0.0889, batch_acc=1.0000, running_acc=0.9842, grad=7.4577]Training epoch 48:  76%|███████▌  | 124/163 [02:22<00:46,  1.19s/it, loss=0.1602, batch_acc=0.9375, running_acc=0.9839, grad=7.7988]Training epoch 48:  77%|███████▋  | 125/163 [02:23<00:41,  1.09s/it, loss=0.1602, batch_acc=0.9375, running_acc=0.9839, grad=7.7988]Training epoch 48:  77%|███████▋  | 125/163 [02:23<00:41,  1.09s/it, loss=0.0993, batch_acc=1.0000, running_acc=0.9840, grad=9.7910]Training epoch 48:  77%|███████▋  | 126/163 [02:24<00:38,  1.03s/it, loss=0.0993, batch_acc=1.0000, running_acc=0.9840, grad=9.7910]Training epoch 48:  77%|███████▋  | 126/163 [02:24<00:38,  1.03s/it, loss=0.1211, batch_acc=1.0000, running_acc=0.9841, grad=15.9153]Training epoch 48:  78%|███████▊  | 127/163 [02:25<00:35,  1.02it/s, loss=0.1211, batch_acc=1.0000, running_acc=0.9841, grad=15.9153]Training epoch 48:  78%|███████▊  | 127/163 [02:25<00:35,  1.02it/s, loss=0.1091, batch_acc=0.9688, running_acc=0.9840, grad=9.2519] Training epoch 48:  79%|███████▊  | 128/163 [02:26<00:37,  1.08s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9840, grad=9.2519]Training epoch 48:  79%|███████▊  | 128/163 [02:26<00:37,  1.08s/it, loss=0.1766, batch_acc=0.9688, running_acc=0.9839, grad=13.6330]Training epoch 48:  79%|███████▉  | 129/163 [02:27<00:34,  1.02s/it, loss=0.1766, batch_acc=0.9688, running_acc=0.9839, grad=13.6330]Training epoch 48:  79%|███████▉  | 129/163 [02:27<00:34,  1.02s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9840, grad=6.7534] Training epoch 48:  80%|███████▉  | 130/163 [02:28<00:32,  1.02it/s, loss=0.0812, batch_acc=1.0000, running_acc=0.9840, grad=6.7534]Training epoch 48:  80%|███████▉  | 130/163 [02:28<00:32,  1.02it/s, loss=0.1056, batch_acc=1.0000, running_acc=0.9841, grad=8.6466]Training epoch 48:  80%|████████  | 131/163 [02:29<00:30,  1.05it/s, loss=0.1056, batch_acc=1.0000, running_acc=0.9841, grad=8.6466]Training epoch 48:  80%|████████  | 131/163 [02:29<00:30,  1.05it/s, loss=0.1178, batch_acc=0.9688, running_acc=0.9840, grad=7.5055]Training epoch 48:  81%|████████  | 132/163 [02:30<00:31,  1.03s/it, loss=0.1178, batch_acc=0.9688, running_acc=0.9840, grad=7.5055]Training epoch 48:  81%|████████  | 132/163 [02:30<00:31,  1.03s/it, loss=0.1110, batch_acc=1.0000, running_acc=0.9841, grad=8.2818]Training epoch 48:  82%|████████▏ | 133/163 [02:31<00:29,  1.02it/s, loss=0.1110, batch_acc=1.0000, running_acc=0.9841, grad=8.2818]Training epoch 48:  82%|████████▏ | 133/163 [02:31<00:29,  1.02it/s, loss=0.0836, batch_acc=1.0000, running_acc=0.9843, grad=9.0567]Training epoch 48:  82%|████████▏ | 134/163 [02:32<00:27,  1.05it/s, loss=0.0836, batch_acc=1.0000, running_acc=0.9843, grad=9.0567]Training epoch 48:  82%|████████▏ | 134/163 [02:32<00:27,  1.05it/s, loss=0.0922, batch_acc=0.9688, running_acc=0.9841, grad=8.4707]Training epoch 48:  83%|████████▎ | 135/163 [02:33<00:26,  1.08it/s, loss=0.0922, batch_acc=0.9688, running_acc=0.9841, grad=8.4707]Training epoch 48:  83%|████████▎ | 135/163 [02:33<00:26,  1.08it/s, loss=0.0706, batch_acc=1.0000, running_acc=0.9843, grad=5.6611]Training epoch 48:  83%|████████▎ | 136/163 [02:34<00:30,  1.14s/it, loss=0.0706, batch_acc=1.0000, running_acc=0.9843, grad=5.6611]Training epoch 48:  83%|████████▎ | 136/163 [02:34<00:30,  1.14s/it, loss=0.0779, batch_acc=0.9688, running_acc=0.9841, grad=6.7971]Training epoch 48:  84%|████████▍ | 137/163 [02:35<00:27,  1.06s/it, loss=0.0779, batch_acc=0.9688, running_acc=0.9841, grad=6.7971]Training epoch 48:  84%|████████▍ | 137/163 [02:35<00:27,  1.06s/it, loss=0.0811, batch_acc=1.0000, running_acc=0.9843, grad=8.1761]Training epoch 48:  85%|████████▍ | 138/163 [02:36<00:26,  1.04s/it, loss=0.0811, batch_acc=1.0000, running_acc=0.9843, grad=8.1761]Training epoch 48:  85%|████████▍ | 138/163 [02:36<00:26,  1.04s/it, loss=0.0812, batch_acc=1.0000, running_acc=0.9844, grad=7.2906]Training epoch 48:  85%|████████▌ | 139/163 [02:37<00:23,  1.01it/s, loss=0.0812, batch_acc=1.0000, running_acc=0.9844, grad=7.2906]Training epoch 48:  85%|████████▌ | 139/163 [02:37<00:23,  1.01it/s, loss=0.0575, batch_acc=1.0000, running_acc=0.9845, grad=5.3174]Training epoch 48:  86%|████████▌ | 140/163 [02:38<00:24,  1.09s/it, loss=0.0575, batch_acc=1.0000, running_acc=0.9845, grad=5.3174]Training epoch 48:  86%|████████▌ | 140/163 [02:38<00:24,  1.09s/it, loss=0.0741, batch_acc=1.0000, running_acc=0.9846, grad=6.5885]Training epoch 48:  87%|████████▋ | 141/163 [02:39<00:22,  1.02s/it, loss=0.0741, batch_acc=1.0000, running_acc=0.9846, grad=6.5885]Training epoch 48:  87%|████████▋ | 141/163 [02:39<00:22,  1.02s/it, loss=0.0794, batch_acc=1.0000, running_acc=0.9847, grad=8.0089]Training epoch 48:  87%|████████▋ | 142/163 [02:40<00:23,  1.11s/it, loss=0.0794, batch_acc=1.0000, running_acc=0.9847, grad=8.0089]Training epoch 48:  87%|████████▋ | 142/163 [02:40<00:23,  1.11s/it, loss=0.1149, batch_acc=1.0000, running_acc=0.9848, grad=8.1542]Training epoch 48:  88%|████████▊ | 143/163 [02:41<00:20,  1.04s/it, loss=0.1149, batch_acc=1.0000, running_acc=0.9848, grad=8.1542]Training epoch 48:  88%|████████▊ | 143/163 [02:41<00:20,  1.04s/it, loss=0.0916, batch_acc=1.0000, running_acc=0.9849, grad=6.9553]Training epoch 48:  88%|████████▊ | 144/163 [02:42<00:18,  1.01it/s, loss=0.0916, batch_acc=1.0000, running_acc=0.9849, grad=6.9553]Training epoch 48:  88%|████████▊ | 144/163 [02:42<00:18,  1.01it/s, loss=0.0717, batch_acc=1.0000, running_acc=0.9850, grad=7.1528]Training epoch 48:  89%|████████▉ | 145/163 [02:43<00:17,  1.04it/s, loss=0.0717, batch_acc=1.0000, running_acc=0.9850, grad=7.1528]Training epoch 48:  89%|████████▉ | 145/163 [02:43<00:17,  1.04it/s, loss=0.0887, batch_acc=1.0000, running_acc=0.9851, grad=6.0232]Training epoch 48:  90%|████████▉ | 146/163 [02:45<00:19,  1.13s/it, loss=0.0887, batch_acc=1.0000, running_acc=0.9851, grad=6.0232]Training epoch 48:  90%|████████▉ | 146/163 [02:45<00:19,  1.13s/it, loss=0.0865, batch_acc=1.0000, running_acc=0.9852, grad=6.9758]Training epoch 48:  90%|█████████ | 147/163 [02:46<00:16,  1.05s/it, loss=0.0865, batch_acc=1.0000, running_acc=0.9852, grad=6.9758]Training epoch 48:  90%|█████████ | 147/163 [02:46<00:16,  1.05s/it, loss=0.0989, batch_acc=0.9688, running_acc=0.9851, grad=6.9059]Training epoch 48:  91%|█████████ | 148/163 [02:46<00:15,  1.00s/it, loss=0.0989, batch_acc=0.9688, running_acc=0.9851, grad=6.9059]Training epoch 48:  91%|█████████ | 148/163 [02:46<00:15,  1.00s/it, loss=0.0905, batch_acc=1.0000, running_acc=0.9852, grad=9.4638]Training epoch 48:  91%|█████████▏| 149/163 [02:47<00:13,  1.04it/s, loss=0.0905, batch_acc=1.0000, running_acc=0.9852, grad=9.4638]Training epoch 48:  91%|█████████▏| 149/163 [02:47<00:13,  1.04it/s, loss=0.1077, batch_acc=0.9688, running_acc=0.9851, grad=7.5757]Training epoch 48:  92%|█████████▏| 150/163 [02:49<00:15,  1.17s/it, loss=0.1077, batch_acc=0.9688, running_acc=0.9851, grad=7.5757]Training epoch 48:  92%|█████████▏| 150/163 [02:49<00:15,  1.17s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9852, grad=8.2385]Training epoch 48:  93%|█████████▎| 151/163 [02:50<00:12,  1.08s/it, loss=0.0952, batch_acc=1.0000, running_acc=0.9852, grad=8.2385]Training epoch 48:  93%|█████████▎| 151/163 [02:50<00:12,  1.08s/it, loss=0.0599, batch_acc=1.0000, running_acc=0.9853, grad=4.9256]Training epoch 48:  93%|█████████▎| 152/163 [02:51<00:11,  1.02s/it, loss=0.0599, batch_acc=1.0000, running_acc=0.9853, grad=4.9256]Training epoch 48:  93%|█████████▎| 152/163 [02:51<00:11,  1.02s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9854, grad=6.0561]Training epoch 48:  94%|█████████▍| 153/163 [02:52<00:09,  1.01it/s, loss=0.0691, batch_acc=1.0000, running_acc=0.9854, grad=6.0561]Training epoch 48:  94%|█████████▍| 153/163 [02:52<00:09,  1.01it/s, loss=0.1397, batch_acc=0.9375, running_acc=0.9851, grad=7.4764]Training epoch 48:  94%|█████████▍| 154/163 [02:53<00:11,  1.23s/it, loss=0.1397, batch_acc=0.9375, running_acc=0.9851, grad=7.4764]Training epoch 48:  94%|█████████▍| 154/163 [02:53<00:11,  1.23s/it, loss=0.1042, batch_acc=0.9375, running_acc=0.9848, grad=9.6826]Training epoch 48:  95%|█████████▌| 155/163 [02:54<00:08,  1.12s/it, loss=0.1042, batch_acc=0.9375, running_acc=0.9848, grad=9.6826]Training epoch 48:  95%|█████████▌| 155/163 [02:54<00:08,  1.12s/it, loss=0.0937, batch_acc=1.0000, running_acc=0.9849, grad=7.9668]Training epoch 48:  96%|█████████▌| 156/163 [02:55<00:07,  1.05s/it, loss=0.0937, batch_acc=1.0000, running_acc=0.9849, grad=7.9668]Training epoch 48:  96%|█████████▌| 156/163 [02:55<00:07,  1.05s/it, loss=0.1228, batch_acc=1.0000, running_acc=0.9850, grad=8.7138]Training epoch 48:  96%|█████████▋| 157/163 [02:56<00:06,  1.11s/it, loss=0.1228, batch_acc=1.0000, running_acc=0.9850, grad=8.7138]Training epoch 48:  96%|█████████▋| 157/163 [02:56<00:06,  1.11s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9849, grad=6.6747]Training epoch 48:  97%|█████████▋| 158/163 [02:58<00:06,  1.36s/it, loss=0.1175, batch_acc=0.9688, running_acc=0.9849, grad=6.6747]Training epoch 48:  97%|█████████▋| 158/163 [02:58<00:06,  1.36s/it, loss=0.1293, batch_acc=0.9688, running_acc=0.9848, grad=15.4940]Training epoch 48:  98%|█████████▊| 159/163 [02:59<00:04,  1.21s/it, loss=0.1293, batch_acc=0.9688, running_acc=0.9848, grad=15.4940]Training epoch 48:  98%|█████████▊| 159/163 [02:59<00:04,  1.21s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9849, grad=17.6443]Training epoch 48:  98%|█████████▊| 160/163 [03:00<00:03,  1.11s/it, loss=0.1043, batch_acc=1.0000, running_acc=0.9849, grad=17.6443]Training epoch 48:  98%|█████████▊| 160/163 [03:00<00:03,  1.11s/it, loss=0.1321, batch_acc=0.9375, running_acc=0.9846, grad=10.1902]Training epoch 48:  99%|█████████▉| 161/163 [03:01<00:02,  1.04s/it, loss=0.1321, batch_acc=0.9375, running_acc=0.9846, grad=10.1902]Training epoch 48:  99%|█████████▉| 161/163 [03:01<00:02,  1.04s/it, loss=0.1085, batch_acc=0.9688, running_acc=0.9845, grad=8.0492] Training epoch 48:  99%|█████████▉| 162/163 [03:02<00:00,  1.01it/s, loss=0.1085, batch_acc=0.9688, running_acc=0.9845, grad=8.0492]Training epoch 48:  99%|█████████▉| 162/163 [03:02<00:00,  1.01it/s, loss=0.0998, batch_acc=1.0000, running_acc=0.9846, grad=7.0706]Training epoch 48: 100%|██████████| 163/163 [03:02<00:00,  1.13it/s, loss=0.0998, batch_acc=1.0000, running_acc=0.9846, grad=7.0706]Training epoch 48: 100%|██████████| 163/163 [03:02<00:00,  1.13it/s, loss=0.1501, batch_acc=0.9524, running_acc=0.9844, grad=15.0271]Training epoch 48: 100%|██████████| 163/163 [03:02<00:00,  1.12s/it, loss=0.1501, batch_acc=0.9524, running_acc=0.9844, grad=15.0271]
Evaluation epoch 48:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 48:   4%|▎         | 1/28 [00:04<02:09,  4.79s/it]Evaluation epoch 48:   4%|▎         | 1/28 [00:04<02:09,  4.79s/it, loss=0.3792, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 48:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=0.3792, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 48:   7%|▋         | 2/28 [00:05<00:57,  2.21s/it, loss=0.2181, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 48:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=0.2181, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 48:  11%|█         | 3/28 [00:05<00:32,  1.32s/it, loss=0.2961, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 48:  14%|█▍        | 4/28 [00:09<00:58,  2.44s/it, loss=0.2961, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 48:  14%|█▍        | 4/28 [00:09<00:58,  2.44s/it, loss=0.4181, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 48:  18%|█▊        | 5/28 [00:09<00:37,  1.65s/it, loss=0.4181, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 48:  18%|█▊        | 5/28 [00:09<00:37,  1.65s/it, loss=1.3060, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 48:  21%|██▏       | 6/28 [00:10<00:25,  1.18s/it, loss=1.3060, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 48:  21%|██▏       | 6/28 [00:10<00:25,  1.18s/it, loss=0.4972, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 48:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=0.4972, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 48:  25%|██▌       | 7/28 [00:10<00:18,  1.14it/s, loss=0.6045, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 48:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=0.6045, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 48:  29%|██▊       | 8/28 [00:13<00:33,  1.66s/it, loss=0.4087, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 48:  32%|███▏      | 9/28 [00:14<00:25,  1.32s/it, loss=0.4087, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 48:  32%|███▏      | 9/28 [00:14<00:25,  1.32s/it, loss=0.4074, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 48:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.4074, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 48:  36%|███▌      | 10/28 [00:14<00:17,  1.01it/s, loss=0.4330, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 48:  39%|███▉      | 11/28 [00:14<00:13,  1.30it/s, loss=0.4330, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 48:  39%|███▉      | 11/28 [00:14<00:13,  1.30it/s, loss=0.2964, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 48:  43%|████▎     | 12/28 [00:20<00:34,  2.14s/it, loss=0.2964, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 48:  43%|████▎     | 12/28 [00:20<00:34,  2.14s/it, loss=0.8918, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 48:  46%|████▋     | 13/28 [00:20<00:23,  1.57s/it, loss=0.8918, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 48:  46%|████▋     | 13/28 [00:20<00:23,  1.57s/it, loss=0.2658, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 48:  50%|█████     | 14/28 [00:20<00:16,  1.17s/it, loss=0.2658, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 48:  50%|█████     | 14/28 [00:20<00:16,  1.17s/it, loss=0.8562, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 48:  54%|█████▎    | 15/28 [00:20<00:11,  1.11it/s, loss=0.8562, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 48:  54%|█████▎    | 15/28 [00:20<00:11,  1.11it/s, loss=0.9432, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 48:  57%|█████▋    | 16/28 [00:23<00:18,  1.51s/it, loss=0.9432, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 48:  57%|█████▋    | 16/28 [00:23<00:18,  1.51s/it, loss=0.7746, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 48:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.7746, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 48:  61%|██████    | 17/28 [00:24<00:12,  1.13s/it, loss=0.6380, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 48:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.6380, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 48:  64%|██████▍   | 18/28 [00:24<00:08,  1.15it/s, loss=0.5248, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 48:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.5248, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 48:  68%|██████▊   | 19/28 [00:24<00:06,  1.45it/s, loss=0.8897, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 48:  71%|███████▏  | 20/28 [00:27<00:11,  1.38s/it, loss=0.8897, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 48:  71%|███████▏  | 20/28 [00:27<00:11,  1.38s/it, loss=0.5608, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 48:  75%|███████▌  | 21/28 [00:27<00:07,  1.04s/it, loss=0.5608, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 48:  75%|███████▌  | 21/28 [00:27<00:07,  1.04s/it, loss=0.5625, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 48:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.5625, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 48:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.3956, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 48:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=0.3956, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 48:  82%|████████▏ | 23/28 [00:28<00:03,  1.55it/s, loss=0.7759, batch_acc=0.7812, running_acc=0.8492]Evaluation epoch 48:  86%|████████▌ | 24/28 [00:33<00:08,  2.07s/it, loss=0.7759, batch_acc=0.7812, running_acc=0.8492]Evaluation epoch 48:  86%|████████▌ | 24/28 [00:33<00:08,  2.07s/it, loss=0.2963, batch_acc=0.9375, running_acc=0.8529]Evaluation epoch 48:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.2963, batch_acc=0.9375, running_acc=0.8529]Evaluation epoch 48:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.1244, batch_acc=1.0000, running_acc=0.8588]Evaluation epoch 48:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.1244, batch_acc=1.0000, running_acc=0.8588]Evaluation epoch 48:  93%|█████████▎| 26/28 [00:34<00:02,  1.15s/it, loss=0.5731, batch_acc=0.8438, running_acc=0.8582]Evaluation epoch 48:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=0.5731, batch_acc=0.8438, running_acc=0.8582]Evaluation epoch 48:  96%|█████████▋| 27/28 [00:34<00:00,  1.13it/s, loss=0.8388, batch_acc=0.7500, running_acc=0.8542]Evaluation epoch 48: 100%|██████████| 28/28 [00:34<00:00,  1.13it/s, loss=1.1299, batch_acc=0.6667, running_acc=0.8535]Evaluation epoch 48: 100%|██████████| 28/28 [00:34<00:00,  1.24s/it, loss=1.1299, batch_acc=0.6667, running_acc=0.8535]
Training epoch 49:   0%|          | 0/163 [00:00<?, ?it/s]Training epoch 49:   1%|          | 1/163 [00:05<15:51,  5.87s/it]Training epoch 49:   1%|          | 1/163 [00:05<15:51,  5.87s/it, loss=0.1448, batch_acc=0.9688, running_acc=0.9688, grad=11.0828]Training epoch 49:   1%|          | 2/163 [00:06<07:52,  2.93s/it, loss=0.1448, batch_acc=0.9688, running_acc=0.9688, grad=11.0828]Training epoch 49:   1%|          | 2/163 [00:06<07:52,  2.93s/it, loss=0.1290, batch_acc=0.9688, running_acc=0.9688, grad=7.7377] Training epoch 49:   2%|▏         | 3/163 [00:07<05:19,  1.99s/it, loss=0.1290, batch_acc=0.9688, running_acc=0.9688, grad=7.7377]Training epoch 49:   2%|▏         | 3/163 [00:07<05:19,  1.99s/it, loss=0.0805, batch_acc=1.0000, running_acc=0.9792, grad=8.8838]Training epoch 49:   2%|▏         | 4/163 [00:10<06:28,  2.44s/it, loss=0.0805, batch_acc=1.0000, running_acc=0.9792, grad=8.8838]Training epoch 49:   2%|▏         | 4/163 [00:10<06:28,  2.44s/it, loss=0.1360, batch_acc=0.9688, running_acc=0.9766, grad=6.5345]Training epoch 49:   3%|▎         | 5/163 [00:11<04:57,  1.88s/it, loss=0.1360, batch_acc=0.9688, running_acc=0.9766, grad=6.5345]Training epoch 49:   3%|▎         | 5/163 [00:11<04:57,  1.88s/it, loss=0.0856, batch_acc=1.0000, running_acc=0.9812, grad=6.5562]Training epoch 49:   4%|▎         | 6/163 [00:12<04:01,  1.54s/it, loss=0.0856, batch_acc=1.0000, running_acc=0.9812, grad=6.5562]Training epoch 49:   4%|▎         | 6/163 [00:12<04:01,  1.54s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9792, grad=6.7476]Training epoch 49:   4%|▍         | 7/163 [00:13<03:26,  1.32s/it, loss=0.1226, batch_acc=0.9688, running_acc=0.9792, grad=6.7476]Training epoch 49:   4%|▍         | 7/163 [00:13<03:26,  1.32s/it, loss=0.0823, batch_acc=1.0000, running_acc=0.9821, grad=16.3037]Training epoch 49:   5%|▍         | 8/163 [00:15<04:13,  1.63s/it, loss=0.0823, batch_acc=1.0000, running_acc=0.9821, grad=16.3037]Training epoch 49:   5%|▍         | 8/163 [00:15<04:13,  1.63s/it, loss=0.0703, batch_acc=1.0000, running_acc=0.9844, grad=4.5952] Training epoch 49:   6%|▌         | 9/163 [00:16<03:35,  1.40s/it, loss=0.0703, batch_acc=1.0000, running_acc=0.9844, grad=4.5952]Training epoch 49:   6%|▌         | 9/163 [00:16<03:35,  1.40s/it, loss=0.0784, batch_acc=1.0000, running_acc=0.9861, grad=6.1095]Training epoch 49:   6%|▌         | 10/163 [00:17<03:09,  1.24s/it, loss=0.0784, batch_acc=1.0000, running_acc=0.9861, grad=6.1095]Training epoch 49:   6%|▌         | 10/163 [00:17<03:09,  1.24s/it, loss=0.1395, batch_acc=0.9688, running_acc=0.9844, grad=18.1852]Training epoch 49:   7%|▋         | 11/163 [00:18<02:51,  1.13s/it, loss=0.1395, batch_acc=0.9688, running_acc=0.9844, grad=18.1852]Training epoch 49:   7%|▋         | 11/163 [00:18<02:51,  1.13s/it, loss=0.1077, batch_acc=0.9688, running_acc=0.9830, grad=9.3065] Training epoch 49:   7%|▋         | 12/163 [00:20<03:36,  1.43s/it, loss=0.1077, batch_acc=0.9688, running_acc=0.9830, grad=9.3065]Training epoch 49:   7%|▋         | 12/163 [00:20<03:36,  1.43s/it, loss=0.0563, batch_acc=1.0000, running_acc=0.9844, grad=5.4571]Training epoch 49:   8%|▊         | 13/163 [00:21<03:10,  1.27s/it, loss=0.0563, batch_acc=1.0000, running_acc=0.9844, grad=5.4571]Training epoch 49:   8%|▊         | 13/163 [00:21<03:10,  1.27s/it, loss=0.0828, batch_acc=1.0000, running_acc=0.9856, grad=9.2488]Training epoch 49:   9%|▊         | 14/163 [00:22<02:51,  1.15s/it, loss=0.0828, batch_acc=1.0000, running_acc=0.9856, grad=9.2488]Training epoch 49:   9%|▊         | 14/163 [00:22<02:51,  1.15s/it, loss=0.0936, batch_acc=1.0000, running_acc=0.9866, grad=9.8525]Training epoch 49:   9%|▉         | 15/163 [00:23<02:37,  1.07s/it, loss=0.0936, batch_acc=1.0000, running_acc=0.9866, grad=9.8525]Training epoch 49:   9%|▉         | 15/163 [00:23<02:37,  1.07s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9875, grad=7.6837]Training epoch 49:  10%|▉         | 16/163 [00:25<03:18,  1.35s/it, loss=0.1108, batch_acc=1.0000, running_acc=0.9875, grad=7.6837]Training epoch 49:  10%|▉         | 16/163 [00:25<03:18,  1.35s/it, loss=0.1119, batch_acc=0.9688, running_acc=0.9863, grad=8.1709]Training epoch 49:  10%|█         | 17/163 [00:25<02:56,  1.21s/it, loss=0.1119, batch_acc=0.9688, running_acc=0.9863, grad=8.1709]Training epoch 49:  10%|█         | 17/163 [00:25<02:56,  1.21s/it, loss=0.1447, batch_acc=1.0000, running_acc=0.9871, grad=13.6292]Training epoch 49:  11%|█         | 18/163 [00:26<02:41,  1.11s/it, loss=0.1447, batch_acc=1.0000, running_acc=0.9871, grad=13.6292]Training epoch 49:  11%|█         | 18/163 [00:26<02:41,  1.11s/it, loss=0.1115, batch_acc=0.9688, running_acc=0.9861, grad=9.3310] Training epoch 49:  12%|█▏        | 19/163 [00:27<02:30,  1.04s/it, loss=0.1115, batch_acc=0.9688, running_acc=0.9861, grad=9.3310]Training epoch 49:  12%|█▏        | 19/163 [00:27<02:30,  1.04s/it, loss=0.1040, batch_acc=1.0000, running_acc=0.9868, grad=9.9677]Training epoch 49:  12%|█▏        | 20/163 [00:30<03:35,  1.51s/it, loss=0.1040, batch_acc=1.0000, running_acc=0.9868, grad=9.9677]Training epoch 49:  12%|█▏        | 20/163 [00:30<03:35,  1.51s/it, loss=0.1831, batch_acc=0.9062, running_acc=0.9828, grad=16.6867]Training epoch 49:  13%|█▎        | 21/163 [00:31<03:07,  1.32s/it, loss=0.1831, batch_acc=0.9062, running_acc=0.9828, grad=16.6867]Training epoch 49:  13%|█▎        | 21/163 [00:31<03:07,  1.32s/it, loss=0.0578, batch_acc=1.0000, running_acc=0.9836, grad=4.0617] Training epoch 49:  13%|█▎        | 22/163 [00:32<02:47,  1.19s/it, loss=0.0578, batch_acc=1.0000, running_acc=0.9836, grad=4.0617]Training epoch 49:  13%|█▎        | 22/163 [00:32<02:47,  1.19s/it, loss=0.1493, batch_acc=1.0000, running_acc=0.9844, grad=13.4503]Training epoch 49:  14%|█▍        | 23/163 [00:32<02:33,  1.10s/it, loss=0.1493, batch_acc=1.0000, running_acc=0.9844, grad=13.4503]Training epoch 49:  14%|█▍        | 23/163 [00:32<02:33,  1.10s/it, loss=0.0661, batch_acc=1.0000, running_acc=0.9851, grad=5.9425] Training epoch 49:  15%|█▍        | 24/163 [00:35<03:10,  1.37s/it, loss=0.0661, batch_acc=1.0000, running_acc=0.9851, grad=5.9425]Training epoch 49:  15%|█▍        | 24/163 [00:35<03:10,  1.37s/it, loss=0.0740, batch_acc=1.0000, running_acc=0.9857, grad=8.2744]Training epoch 49:  15%|█▌        | 25/163 [00:35<02:48,  1.22s/it, loss=0.0740, batch_acc=1.0000, running_acc=0.9857, grad=8.2744]Training epoch 49:  15%|█▌        | 25/163 [00:35<02:48,  1.22s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9850, grad=7.0800]Training epoch 49:  16%|█▌        | 26/163 [00:36<02:33,  1.12s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9850, grad=7.0800]Training epoch 49:  16%|█▌        | 26/163 [00:36<02:33,  1.12s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9856, grad=8.1976]Training epoch 49:  17%|█▋        | 27/163 [00:37<02:22,  1.05s/it, loss=0.0982, batch_acc=1.0000, running_acc=0.9856, grad=8.1976]Training epoch 49:  17%|█▋        | 27/163 [00:37<02:22,  1.05s/it, loss=0.1045, batch_acc=0.9688, running_acc=0.9850, grad=8.3705]Training epoch 49:  17%|█▋        | 28/163 [00:39<02:37,  1.16s/it, loss=0.1045, batch_acc=0.9688, running_acc=0.9850, grad=8.3705]Training epoch 49:  17%|█▋        | 28/163 [00:39<02:37,  1.16s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9844, grad=6.7974]Training epoch 49:  18%|█▊        | 29/163 [00:39<02:24,  1.08s/it, loss=0.1050, batch_acc=0.9688, running_acc=0.9844, grad=6.7974]Training epoch 49:  18%|█▊        | 29/163 [00:39<02:24,  1.08s/it, loss=0.1571, batch_acc=0.9688, running_acc=0.9838, grad=9.2848]Training epoch 49:  18%|█▊        | 30/163 [00:40<02:15,  1.02s/it, loss=0.1571, batch_acc=0.9688, running_acc=0.9838, grad=9.2848]Training epoch 49:  18%|█▊        | 30/163 [00:40<02:15,  1.02s/it, loss=0.1290, batch_acc=0.9688, running_acc=0.9833, grad=5.9553]Training epoch 49:  19%|█▉        | 31/163 [00:41<02:08,  1.02it/s, loss=0.1290, batch_acc=0.9688, running_acc=0.9833, grad=5.9553]Training epoch 49:  19%|█▉        | 31/163 [00:41<02:08,  1.02it/s, loss=0.0971, batch_acc=1.0000, running_acc=0.9839, grad=8.7048]Training epoch 49:  20%|█▉        | 32/163 [00:43<02:34,  1.18s/it, loss=0.0971, batch_acc=1.0000, running_acc=0.9839, grad=8.7048]Training epoch 49:  20%|█▉        | 32/163 [00:43<02:34,  1.18s/it, loss=0.1038, batch_acc=0.9688, running_acc=0.9834, grad=8.2664]Training epoch 49:  20%|██        | 33/163 [00:44<02:21,  1.09s/it, loss=0.1038, batch_acc=0.9688, running_acc=0.9834, grad=8.2664]Training epoch 49:  20%|██        | 33/163 [00:44<02:21,  1.09s/it, loss=0.1047, batch_acc=0.9688, running_acc=0.9830, grad=7.3307]Training epoch 49:  21%|██        | 34/163 [00:45<02:12,  1.03s/it, loss=0.1047, batch_acc=0.9688, running_acc=0.9830, grad=7.3307]Training epoch 49:  21%|██        | 34/163 [00:45<02:12,  1.03s/it, loss=0.0722, batch_acc=1.0000, running_acc=0.9835, grad=8.7375]Training epoch 49:  21%|██▏       | 35/163 [00:46<02:05,  1.02it/s, loss=0.0722, batch_acc=1.0000, running_acc=0.9835, grad=8.7375]Training epoch 49:  21%|██▏       | 35/163 [00:46<02:05,  1.02it/s, loss=0.0918, batch_acc=1.0000, running_acc=0.9839, grad=6.7416]Training epoch 49:  22%|██▏       | 36/163 [00:47<02:28,  1.17s/it, loss=0.0918, batch_acc=1.0000, running_acc=0.9839, grad=6.7416]Training epoch 49:  22%|██▏       | 36/163 [00:47<02:28,  1.17s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9844, grad=5.4779]Training epoch 49:  23%|██▎       | 37/163 [00:48<02:16,  1.09s/it, loss=0.0691, batch_acc=1.0000, running_acc=0.9844, grad=5.4779]Training epoch 49:  23%|██▎       | 37/163 [00:48<02:16,  1.09s/it, loss=0.1252, batch_acc=0.9688, running_acc=0.9840, grad=21.6989]Training epoch 49:  23%|██▎       | 38/163 [00:49<02:07,  1.02s/it, loss=0.1252, batch_acc=0.9688, running_acc=0.9840, grad=21.6989]Training epoch 49:  23%|██▎       | 38/163 [00:49<02:07,  1.02s/it, loss=0.0627, batch_acc=1.0000, running_acc=0.9844, grad=6.5736] Training epoch 49:  24%|██▍       | 39/163 [00:50<02:01,  1.02it/s, loss=0.0627, batch_acc=1.0000, running_acc=0.9844, grad=6.5736]Training epoch 49:  24%|██▍       | 39/163 [00:50<02:01,  1.02it/s, loss=0.0698, batch_acc=1.0000, running_acc=0.9848, grad=5.2102]Training epoch 49:  25%|██▍       | 40/163 [00:52<02:38,  1.28s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9848, grad=5.2102]Training epoch 49:  25%|██▍       | 40/163 [00:52<02:38,  1.28s/it, loss=0.1141, batch_acc=0.9688, running_acc=0.9844, grad=6.2240]Training epoch 49:  25%|██▌       | 41/163 [00:53<02:22,  1.16s/it, loss=0.1141, batch_acc=0.9688, running_acc=0.9844, grad=6.2240]Training epoch 49:  25%|██▌       | 41/163 [00:53<02:22,  1.16s/it, loss=0.1320, batch_acc=0.9688, running_acc=0.9840, grad=10.3760]Training epoch 49:  26%|██▌       | 42/163 [00:54<02:10,  1.08s/it, loss=0.1320, batch_acc=0.9688, running_acc=0.9840, grad=10.3760]Training epoch 49:  26%|██▌       | 42/163 [00:54<02:10,  1.08s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9836, grad=8.2538] Training epoch 49:  26%|██▋       | 43/163 [00:54<02:02,  1.02s/it, loss=0.1091, batch_acc=0.9688, running_acc=0.9836, grad=8.2538]Training epoch 49:  26%|██▋       | 43/163 [00:54<02:02,  1.02s/it, loss=0.1703, batch_acc=0.9062, running_acc=0.9818, grad=6.8366]Training epoch 49:  27%|██▋       | 44/163 [00:56<02:28,  1.25s/it, loss=0.1703, batch_acc=0.9062, running_acc=0.9818, grad=6.8366]Training epoch 49:  27%|██▋       | 44/163 [00:56<02:28,  1.25s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9815, grad=10.1258]Training epoch 49:  28%|██▊       | 45/163 [00:57<02:14,  1.14s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9815, grad=10.1258]Training epoch 49:  28%|██▊       | 45/163 [00:57<02:14,  1.14s/it, loss=0.0725, batch_acc=1.0000, running_acc=0.9819, grad=5.3879] Training epoch 49:  28%|██▊       | 46/163 [00:58<02:03,  1.06s/it, loss=0.0725, batch_acc=1.0000, running_acc=0.9819, grad=5.3879]Training epoch 49:  28%|██▊       | 46/163 [00:58<02:03,  1.06s/it, loss=0.1031, batch_acc=1.0000, running_acc=0.9823, grad=9.4937]Training epoch 49:  29%|██▉       | 47/163 [00:59<01:56,  1.00s/it, loss=0.1031, batch_acc=1.0000, running_acc=0.9823, grad=9.4937]Training epoch 49:  29%|██▉       | 47/163 [00:59<01:56,  1.00s/it, loss=0.1431, batch_acc=1.0000, running_acc=0.9827, grad=8.7824]Training epoch 49:  29%|██▉       | 48/163 [01:00<02:13,  1.16s/it, loss=0.1431, batch_acc=1.0000, running_acc=0.9827, grad=8.7824]Training epoch 49:  29%|██▉       | 48/163 [01:00<02:13,  1.16s/it, loss=0.0864, batch_acc=0.9688, running_acc=0.9824, grad=7.4270]Training epoch 49:  30%|███       | 49/163 [01:01<02:02,  1.08s/it, loss=0.0864, batch_acc=0.9688, running_acc=0.9824, grad=7.4270]Training epoch 49:  30%|███       | 49/163 [01:01<02:02,  1.08s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9828, grad=9.5577]Training epoch 49:  31%|███       | 50/163 [01:02<01:54,  1.02s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9828, grad=9.5577]Training epoch 49:  31%|███       | 50/163 [01:02<01:54,  1.02s/it, loss=0.0976, batch_acc=1.0000, running_acc=0.9831, grad=7.9417]Training epoch 49:  31%|███▏      | 51/163 [01:03<01:49,  1.03it/s, loss=0.0976, batch_acc=1.0000, running_acc=0.9831, grad=7.9417]Training epoch 49:  31%|███▏      | 51/163 [01:03<01:49,  1.03it/s, loss=0.0820, batch_acc=0.9688, running_acc=0.9828, grad=6.7113]Training epoch 49:  32%|███▏      | 52/163 [01:04<02:02,  1.10s/it, loss=0.0820, batch_acc=0.9688, running_acc=0.9828, grad=6.7113]Training epoch 49:  32%|███▏      | 52/163 [01:04<02:02,  1.10s/it, loss=0.0787, batch_acc=1.0000, running_acc=0.9832, grad=6.0019]Training epoch 49:  33%|███▎      | 53/163 [01:05<01:53,  1.04s/it, loss=0.0787, batch_acc=1.0000, running_acc=0.9832, grad=6.0019]Training epoch 49:  33%|███▎      | 53/163 [01:05<01:53,  1.04s/it, loss=0.0970, batch_acc=1.0000, running_acc=0.9835, grad=9.0093]Training epoch 49:  33%|███▎      | 54/163 [01:06<01:47,  1.01it/s, loss=0.0970, batch_acc=1.0000, running_acc=0.9835, grad=9.0093]Training epoch 49:  33%|███▎      | 54/163 [01:06<01:47,  1.01it/s, loss=0.0763, batch_acc=1.0000, running_acc=0.9838, grad=6.3421]Training epoch 49:  34%|███▎      | 55/163 [01:07<01:43,  1.05it/s, loss=0.0763, batch_acc=1.0000, running_acc=0.9838, grad=6.3421]Training epoch 49:  34%|███▎      | 55/163 [01:07<01:43,  1.05it/s, loss=0.0901, batch_acc=1.0000, running_acc=0.9841, grad=7.0156]Training epoch 49:  34%|███▍      | 56/163 [01:08<01:52,  1.05s/it, loss=0.0901, batch_acc=1.0000, running_acc=0.9841, grad=7.0156]Training epoch 49:  34%|███▍      | 56/163 [01:08<01:52,  1.05s/it, loss=0.1077, batch_acc=0.9688, running_acc=0.9838, grad=8.4857]Training epoch 49:  35%|███▍      | 57/163 [01:09<01:46,  1.00s/it, loss=0.1077, batch_acc=0.9688, running_acc=0.9838, grad=8.4857]Training epoch 49:  35%|███▍      | 57/163 [01:09<01:46,  1.00s/it, loss=0.1087, batch_acc=1.0000, running_acc=0.9841, grad=10.5576]Training epoch 49:  36%|███▌      | 58/163 [01:10<01:41,  1.04it/s, loss=0.1087, batch_acc=1.0000, running_acc=0.9841, grad=10.5576]Training epoch 49:  36%|███▌      | 58/163 [01:10<01:41,  1.04it/s, loss=0.0796, batch_acc=1.0000, running_acc=0.9844, grad=6.9062] Training epoch 49:  36%|███▌      | 59/163 [01:11<01:37,  1.06it/s, loss=0.0796, batch_acc=1.0000, running_acc=0.9844, grad=6.9062]Training epoch 49:  36%|███▌      | 59/163 [01:11<01:37,  1.06it/s, loss=0.0733, batch_acc=1.0000, running_acc=0.9846, grad=5.7181]Training epoch 49:  37%|███▋      | 60/163 [01:13<02:22,  1.38s/it, loss=0.0733, batch_acc=1.0000, running_acc=0.9846, grad=5.7181]Training epoch 49:  37%|███▋      | 60/163 [01:13<02:22,  1.38s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9849, grad=5.9541]Training epoch 49:  37%|███▋      | 61/163 [01:14<02:05,  1.23s/it, loss=0.0698, batch_acc=1.0000, running_acc=0.9849, grad=5.9541]Training epoch 49:  37%|███▋      | 61/163 [01:14<02:05,  1.23s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9851, grad=6.2786]Training epoch 49:  38%|███▊      | 62/163 [01:15<01:53,  1.12s/it, loss=0.0731, batch_acc=1.0000, running_acc=0.9851, grad=6.2786]Training epoch 49:  38%|███▊      | 62/163 [01:15<01:53,  1.12s/it, loss=0.1038, batch_acc=0.9688, running_acc=0.9849, grad=7.0238]Training epoch 49:  39%|███▊      | 63/163 [01:16<01:45,  1.05s/it, loss=0.1038, batch_acc=0.9688, running_acc=0.9849, grad=7.0238]Training epoch 49:  39%|███▊      | 63/163 [01:16<01:45,  1.05s/it, loss=0.0993, batch_acc=0.9688, running_acc=0.9846, grad=5.4548]Training epoch 49:  39%|███▉      | 64/163 [01:18<02:08,  1.30s/it, loss=0.0993, batch_acc=0.9688, running_acc=0.9846, grad=5.4548]Training epoch 49:  39%|███▉      | 64/163 [01:18<02:08,  1.30s/it, loss=0.1407, batch_acc=0.9688, running_acc=0.9844, grad=8.7619]Training epoch 49:  40%|███▉      | 65/163 [01:19<01:54,  1.17s/it, loss=0.1407, batch_acc=0.9688, running_acc=0.9844, grad=8.7619]Training epoch 49:  40%|███▉      | 65/163 [01:19<01:54,  1.17s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9846, grad=12.6008]Training epoch 49:  40%|████      | 66/163 [01:20<01:45,  1.08s/it, loss=0.1217, batch_acc=1.0000, running_acc=0.9846, grad=12.6008]Training epoch 49:  40%|████      | 66/163 [01:20<01:45,  1.08s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9848, grad=5.4265] Training epoch 49:  41%|████      | 67/163 [01:20<01:38,  1.02s/it, loss=0.0779, batch_acc=1.0000, running_acc=0.9848, grad=5.4265]Training epoch 49:  41%|████      | 67/163 [01:20<01:38,  1.02s/it, loss=0.0587, batch_acc=1.0000, running_acc=0.9851, grad=5.4425]Training epoch 49:  42%|████▏     | 68/163 [01:22<01:52,  1.18s/it, loss=0.0587, batch_acc=1.0000, running_acc=0.9851, grad=5.4425]Training epoch 49:  42%|████▏     | 68/163 [01:22<01:52,  1.18s/it, loss=0.0980, batch_acc=1.0000, running_acc=0.9853, grad=9.0914]Training epoch 49:  42%|████▏     | 69/163 [01:23<01:42,  1.09s/it, loss=0.0980, batch_acc=1.0000, running_acc=0.9853, grad=9.0914]Training epoch 49:  42%|████▏     | 69/163 [01:23<01:42,  1.09s/it, loss=0.1772, batch_acc=1.0000, running_acc=0.9855, grad=13.3125]Training epoch 49:  43%|████▎     | 70/163 [01:24<01:35,  1.03s/it, loss=0.1772, batch_acc=1.0000, running_acc=0.9855, grad=13.3125]Training epoch 49:  43%|████▎     | 70/163 [01:24<01:35,  1.03s/it, loss=0.1149, batch_acc=0.9688, running_acc=0.9853, grad=7.9515] Training epoch 49:  44%|████▎     | 71/163 [01:25<01:30,  1.02it/s, loss=0.1149, batch_acc=0.9688, running_acc=0.9853, grad=7.9515]Training epoch 49:  44%|████▎     | 71/163 [01:25<01:30,  1.02it/s, loss=0.1273, batch_acc=1.0000, running_acc=0.9855, grad=11.6670]Training epoch 49:  44%|████▍     | 72/163 [01:27<01:54,  1.26s/it, loss=0.1273, batch_acc=1.0000, running_acc=0.9855, grad=11.6670]Training epoch 49:  44%|████▍     | 72/163 [01:27<01:54,  1.26s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9852, grad=7.8198] Training epoch 49:  45%|████▍     | 73/163 [01:27<01:43,  1.15s/it, loss=0.1136, batch_acc=0.9688, running_acc=0.9852, grad=7.8198]Training epoch 49:  45%|████▍     | 73/163 [01:27<01:43,  1.15s/it, loss=0.0766, batch_acc=1.0000, running_acc=0.9854, grad=5.8307]Training epoch 49:  45%|████▌     | 74/163 [01:28<01:35,  1.07s/it, loss=0.0766, batch_acc=1.0000, running_acc=0.9854, grad=5.8307]Training epoch 49:  45%|████▌     | 74/163 [01:28<01:35,  1.07s/it, loss=0.1197, batch_acc=0.9688, running_acc=0.9852, grad=12.7257]Training epoch 49:  46%|████▌     | 75/163 [01:29<01:29,  1.01s/it, loss=0.1197, batch_acc=0.9688, running_acc=0.9852, grad=12.7257]Training epoch 49:  46%|████▌     | 75/163 [01:29<01:29,  1.01s/it, loss=0.0516, batch_acc=1.0000, running_acc=0.9854, grad=3.7591] Training epoch 49:  47%|████▋     | 76/163 [01:31<01:41,  1.17s/it, loss=0.0516, batch_acc=1.0000, running_acc=0.9854, grad=3.7591]Training epoch 49:  47%|████▋     | 76/163 [01:31<01:41,  1.17s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9856, grad=5.9689]Training epoch 49:  47%|████▋     | 77/163 [01:32<01:33,  1.08s/it, loss=0.0862, batch_acc=1.0000, running_acc=0.9856, grad=5.9689]Training epoch 49:  47%|████▋     | 77/163 [01:32<01:33,  1.08s/it, loss=0.1367, batch_acc=0.9375, running_acc=0.9850, grad=8.8148]Training epoch 49:  48%|████▊     | 78/163 [01:33<01:26,  1.02s/it, loss=0.1367, batch_acc=0.9375, running_acc=0.9850, grad=8.8148]Training epoch 49:  48%|████▊     | 78/163 [01:33<01:26,  1.02s/it, loss=0.1522, batch_acc=1.0000, running_acc=0.9852, grad=9.0138]Training epoch 49:  48%|████▊     | 79/163 [01:33<01:22,  1.02it/s, loss=0.1522, batch_acc=1.0000, running_acc=0.9852, grad=9.0138]Training epoch 49:  48%|████▊     | 79/163 [01:33<01:22,  1.02it/s, loss=0.1340, batch_acc=0.9688, running_acc=0.9850, grad=9.8999]Training epoch 49:  49%|████▉     | 80/163 [01:35<01:32,  1.12s/it, loss=0.1340, batch_acc=0.9688, running_acc=0.9850, grad=9.8999]Training epoch 49:  49%|████▉     | 80/163 [01:35<01:32,  1.12s/it, loss=0.0699, batch_acc=1.0000, running_acc=0.9852, grad=5.4647]Training epoch 49:  50%|████▉     | 81/163 [01:36<01:25,  1.05s/it, loss=0.0699, batch_acc=1.0000, running_acc=0.9852, grad=5.4647]Training epoch 49:  50%|████▉     | 81/163 [01:36<01:25,  1.05s/it, loss=0.1306, batch_acc=0.9688, running_acc=0.9850, grad=9.4564]Training epoch 49:  50%|█████     | 82/163 [01:37<01:20,  1.00it/s, loss=0.1306, batch_acc=0.9688, running_acc=0.9850, grad=9.4564]Training epoch 49:  50%|█████     | 82/163 [01:37<01:20,  1.00it/s, loss=0.0811, batch_acc=1.0000, running_acc=0.9851, grad=8.1563]Training epoch 49:  51%|█████     | 83/163 [01:37<01:16,  1.04it/s, loss=0.0811, batch_acc=1.0000, running_acc=0.9851, grad=8.1563]Training epoch 49:  51%|█████     | 83/163 [01:37<01:16,  1.04it/s, loss=0.1328, batch_acc=0.9688, running_acc=0.9849, grad=10.8094]Training epoch 49:  52%|█████▏    | 84/163 [01:39<01:28,  1.12s/it, loss=0.1328, batch_acc=0.9688, running_acc=0.9849, grad=10.8094]Training epoch 49:  52%|█████▏    | 84/163 [01:39<01:28,  1.12s/it, loss=0.1236, batch_acc=0.9688, running_acc=0.9847, grad=9.2146] Training epoch 49:  52%|█████▏    | 85/163 [01:40<01:21,  1.05s/it, loss=0.1236, batch_acc=0.9688, running_acc=0.9847, grad=9.2146]Training epoch 49:  52%|█████▏    | 85/163 [01:40<01:21,  1.05s/it, loss=0.1462, batch_acc=0.9688, running_acc=0.9846, grad=13.5534]Training epoch 49:  53%|█████▎    | 86/163 [01:41<01:16,  1.00it/s, loss=0.1462, batch_acc=0.9688, running_acc=0.9846, grad=13.5534]Training epoch 49:  53%|█████▎    | 86/163 [01:41<01:16,  1.00it/s, loss=0.2198, batch_acc=0.9375, running_acc=0.9840, grad=10.0753]Training epoch 49:  53%|█████▎    | 87/163 [01:42<01:13,  1.04it/s, loss=0.2198, batch_acc=0.9375, running_acc=0.9840, grad=10.0753]Training epoch 49:  53%|█████▎    | 87/163 [01:42<01:13,  1.04it/s, loss=0.1354, batch_acc=0.9375, running_acc=0.9835, grad=11.1675]Training epoch 49:  54%|█████▍    | 88/163 [01:43<01:27,  1.16s/it, loss=0.1354, batch_acc=0.9375, running_acc=0.9835, grad=11.1675]Training epoch 49:  54%|█████▍    | 88/163 [01:43<01:27,  1.16s/it, loss=0.1156, batch_acc=0.9688, running_acc=0.9833, grad=8.2987] Training epoch 49:  55%|█████▍    | 89/163 [01:44<01:19,  1.08s/it, loss=0.1156, batch_acc=0.9688, running_acc=0.9833, grad=8.2987]Training epoch 49:  55%|█████▍    | 89/163 [01:44<01:19,  1.08s/it, loss=0.1165, batch_acc=0.9375, running_acc=0.9828, grad=6.7344]Training epoch 49:  55%|█████▌    | 90/163 [01:45<01:14,  1.02s/it, loss=0.1165, batch_acc=0.9375, running_acc=0.9828, grad=6.7344]Training epoch 49:  55%|█████▌    | 90/163 [01:45<01:14,  1.02s/it, loss=0.1166, batch_acc=0.9688, running_acc=0.9826, grad=9.0117]Training epoch 49:  56%|█████▌    | 91/163 [01:46<01:10,  1.02it/s, loss=0.1166, batch_acc=0.9688, running_acc=0.9826, grad=9.0117]Training epoch 49:  56%|█████▌    | 91/163 [01:46<01:10,  1.02it/s, loss=0.0584, batch_acc=1.0000, running_acc=0.9828, grad=5.2041]Training epoch 49:  56%|█████▋    | 92/163 [01:47<01:20,  1.14s/it, loss=0.0584, batch_acc=1.0000, running_acc=0.9828, grad=5.2041]Training epoch 49:  56%|█████▋    | 92/163 [01:47<01:20,  1.14s/it, loss=0.1027, batch_acc=0.9688, running_acc=0.9827, grad=6.3555]Training epoch 49:  57%|█████▋    | 93/163 [01:48<01:14,  1.06s/it, loss=0.1027, batch_acc=0.9688, running_acc=0.9827, grad=6.3555]Training epoch 49:  57%|█████▋    | 93/163 [01:48<01:14,  1.06s/it, loss=0.1269, batch_acc=1.0000, running_acc=0.9829, grad=10.5588]Training epoch 49:  58%|█████▊    | 94/163 [01:49<01:09,  1.00s/it, loss=0.1269, batch_acc=1.0000, running_acc=0.9829, grad=10.5588]Training epoch 49:  58%|█████▊    | 94/163 [01:49<01:09,  1.00s/it, loss=0.1504, batch_acc=0.9688, running_acc=0.9827, grad=9.0363] Training epoch 49:  58%|█████▊    | 95/163 [01:50<01:05,  1.03it/s, loss=0.1504, batch_acc=0.9688, running_acc=0.9827, grad=9.0363]Training epoch 49:  58%|█████▊    | 95/163 [01:50<01:05,  1.03it/s, loss=0.0806, batch_acc=1.0000, running_acc=0.9829, grad=6.2313]Training epoch 49:  59%|█████▉    | 96/163 [01:52<01:17,  1.15s/it, loss=0.0806, batch_acc=1.0000, running_acc=0.9829, grad=6.2313]Training epoch 49:  59%|█████▉    | 96/163 [01:52<01:17,  1.15s/it, loss=0.1072, batch_acc=0.9688, running_acc=0.9827, grad=11.3290]Training epoch 49:  60%|█████▉    | 97/163 [01:53<01:10,  1.07s/it, loss=0.1072, batch_acc=0.9688, running_acc=0.9827, grad=11.3290]Training epoch 49:  60%|█████▉    | 97/163 [01:53<01:10,  1.07s/it, loss=0.0850, batch_acc=1.0000, running_acc=0.9829, grad=7.3535] Training epoch 49:  60%|██████    | 98/163 [01:53<01:05,  1.01s/it, loss=0.0850, batch_acc=1.0000, running_acc=0.9829, grad=7.3535]Training epoch 49:  60%|██████    | 98/163 [01:53<01:05,  1.01s/it, loss=0.0846, batch_acc=1.0000, running_acc=0.9831, grad=11.8715]Training epoch 49:  61%|██████    | 99/163 [01:54<01:02,  1.03it/s, loss=0.0846, batch_acc=1.0000, running_acc=0.9831, grad=11.8715]Training epoch 49:  61%|██████    | 99/163 [01:54<01:02,  1.03it/s, loss=0.0626, batch_acc=1.0000, running_acc=0.9833, grad=5.9409] Training epoch 49:  61%|██████▏   | 100/163 [01:56<01:11,  1.13s/it, loss=0.0626, batch_acc=1.0000, running_acc=0.9833, grad=5.9409]Training epoch 49:  61%|██████▏   | 100/163 [01:56<01:11,  1.13s/it, loss=0.1131, batch_acc=1.0000, running_acc=0.9834, grad=10.7436]Training epoch 49:  62%|██████▏   | 101/163 [01:57<01:05,  1.05s/it, loss=0.1131, batch_acc=1.0000, running_acc=0.9834, grad=10.7436]Training epoch 49:  62%|██████▏   | 101/163 [01:57<01:05,  1.05s/it, loss=0.0957, batch_acc=0.9688, running_acc=0.9833, grad=6.0480] Training epoch 49:  63%|██████▎   | 102/163 [01:58<01:01,  1.00s/it, loss=0.0957, batch_acc=0.9688, running_acc=0.9833, grad=6.0480]Training epoch 49:  63%|██████▎   | 102/163 [01:58<01:01,  1.00s/it, loss=0.0637, batch_acc=1.0000, running_acc=0.9835, grad=4.7617]Training epoch 49:  63%|██████▎   | 103/163 [01:58<00:57,  1.04it/s, loss=0.0637, batch_acc=1.0000, running_acc=0.9835, grad=4.7617]Training epoch 49:  63%|██████▎   | 103/163 [01:58<00:57,  1.04it/s, loss=0.1161, batch_acc=0.9688, running_acc=0.9833, grad=13.2972]Training epoch 49:  64%|██████▍   | 104/163 [02:00<01:01,  1.04s/it, loss=0.1161, batch_acc=0.9688, running_acc=0.9833, grad=13.2972]Training epoch 49:  64%|██████▍   | 104/163 [02:00<01:01,  1.04s/it, loss=0.1055, batch_acc=0.9688, running_acc=0.9832, grad=9.0219] Training epoch 49:  64%|██████▍   | 105/163 [02:00<00:57,  1.01it/s, loss=0.1055, batch_acc=0.9688, running_acc=0.9832, grad=9.0219]Training epoch 49:  64%|██████▍   | 105/163 [02:00<00:57,  1.01it/s, loss=0.1198, batch_acc=0.9375, running_acc=0.9827, grad=10.3599]Training epoch 49:  65%|██████▌   | 106/163 [02:01<00:54,  1.04it/s, loss=0.1198, batch_acc=0.9375, running_acc=0.9827, grad=10.3599]Training epoch 49:  65%|██████▌   | 106/163 [02:01<00:54,  1.04it/s, loss=0.0771, batch_acc=1.0000, running_acc=0.9829, grad=6.0710] Training epoch 49:  66%|██████▌   | 107/163 [02:02<00:52,  1.07it/s, loss=0.0771, batch_acc=1.0000, running_acc=0.9829, grad=6.0710]Training epoch 49:  66%|██████▌   | 107/163 [02:02<00:52,  1.07it/s, loss=0.0954, batch_acc=0.9688, running_acc=0.9828, grad=7.3620]Training epoch 49:  66%|██████▋   | 108/163 [02:04<00:58,  1.06s/it, loss=0.0954, batch_acc=0.9688, running_acc=0.9828, grad=7.3620]Training epoch 49:  66%|██████▋   | 108/163 [02:04<00:58,  1.06s/it, loss=0.1225, batch_acc=0.9688, running_acc=0.9826, grad=8.8698]Training epoch 49:  67%|██████▋   | 109/163 [02:04<00:54,  1.01s/it, loss=0.1225, batch_acc=0.9688, running_acc=0.9826, grad=8.8698]Training epoch 49:  67%|██████▋   | 109/163 [02:04<00:54,  1.01s/it, loss=0.0814, batch_acc=1.0000, running_acc=0.9828, grad=5.6372]Training epoch 49:  67%|██████▋   | 110/163 [02:05<00:51,  1.03it/s, loss=0.0814, batch_acc=1.0000, running_acc=0.9828, grad=5.6372]Training epoch 49:  67%|██████▋   | 110/163 [02:05<00:51,  1.03it/s, loss=0.1151, batch_acc=0.9688, running_acc=0.9827, grad=10.8159]Training epoch 49:  68%|██████▊   | 111/163 [02:06<00:49,  1.06it/s, loss=0.1151, batch_acc=0.9688, running_acc=0.9827, grad=10.8159]Training epoch 49:  68%|██████▊   | 111/163 [02:06<00:49,  1.06it/s, loss=0.0975, batch_acc=0.9688, running_acc=0.9825, grad=6.0991] Training epoch 49:  69%|██████▊   | 112/163 [02:08<00:56,  1.11s/it, loss=0.0975, batch_acc=0.9688, running_acc=0.9825, grad=6.0991]Training epoch 49:  69%|██████▊   | 112/163 [02:08<00:56,  1.11s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9827, grad=7.2344]Training epoch 49:  69%|██████▉   | 113/163 [02:09<00:52,  1.04s/it, loss=0.0882, batch_acc=1.0000, running_acc=0.9827, grad=7.2344]Training epoch 49:  69%|██████▉   | 113/163 [02:09<00:52,  1.04s/it, loss=0.1288, batch_acc=0.9375, running_acc=0.9823, grad=11.0603]Training epoch 49:  70%|██████▉   | 114/163 [02:10<00:48,  1.01it/s, loss=0.1288, batch_acc=0.9375, running_acc=0.9823, grad=11.0603]Training epoch 49:  70%|██████▉   | 114/163 [02:10<00:48,  1.01it/s, loss=0.1057, batch_acc=1.0000, running_acc=0.9825, grad=11.4013]Training epoch 49:  71%|███████   | 115/163 [02:11<00:59,  1.23s/it, loss=0.1057, batch_acc=1.0000, running_acc=0.9825, grad=11.4013]Training epoch 49:  71%|███████   | 115/163 [02:11<00:59,  1.23s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9823, grad=9.5002] Training epoch 49:  71%|███████   | 116/163 [02:12<00:53,  1.13s/it, loss=0.1129, batch_acc=0.9688, running_acc=0.9823, grad=9.5002]Training epoch 49:  71%|███████   | 116/163 [02:12<00:53,  1.13s/it, loss=0.1466, batch_acc=0.9688, running_acc=0.9822, grad=10.3105]Training epoch 49:  72%|███████▏  | 117/163 [02:13<00:48,  1.05s/it, loss=0.1466, batch_acc=0.9688, running_acc=0.9822, grad=10.3105]Training epoch 49:  72%|███████▏  | 117/163 [02:13<00:48,  1.05s/it, loss=0.0791, batch_acc=1.0000, running_acc=0.9824, grad=12.1918]Training epoch 49:  72%|███████▏  | 118/163 [02:14<00:45,  1.00s/it, loss=0.0791, batch_acc=1.0000, running_acc=0.9824, grad=12.1918]Training epoch 49:  72%|███████▏  | 118/163 [02:14<00:45,  1.00s/it, loss=0.0609, batch_acc=1.0000, running_acc=0.9825, grad=4.7991] Training epoch 49:  73%|███████▎  | 119/163 [02:15<00:43,  1.00it/s, loss=0.0609, batch_acc=1.0000, running_acc=0.9825, grad=4.7991]Training epoch 49:  73%|███████▎  | 119/163 [02:15<00:43,  1.00it/s, loss=0.0774, batch_acc=1.0000, running_acc=0.9827, grad=5.7250]Training epoch 49:  74%|███████▎  | 120/163 [02:16<00:46,  1.09s/it, loss=0.0774, batch_acc=1.0000, running_acc=0.9827, grad=5.7250]Training epoch 49:  74%|███████▎  | 120/163 [02:16<00:46,  1.09s/it, loss=0.1314, batch_acc=0.9688, running_acc=0.9826, grad=13.4987]Training epoch 49:  74%|███████▍  | 121/163 [02:17<00:43,  1.03s/it, loss=0.1314, batch_acc=0.9688, running_acc=0.9826, grad=13.4987]Training epoch 49:  74%|███████▍  | 121/163 [02:17<00:43,  1.03s/it, loss=0.0767, batch_acc=1.0000, running_acc=0.9827, grad=9.0109] Training epoch 49:  75%|███████▍  | 122/163 [02:18<00:40,  1.01it/s, loss=0.0767, batch_acc=1.0000, running_acc=0.9827, grad=9.0109]Training epoch 49:  75%|███████▍  | 122/163 [02:18<00:40,  1.01it/s, loss=0.1473, batch_acc=0.9688, running_acc=0.9826, grad=15.1930]Training epoch 49:  75%|███████▌  | 123/163 [02:20<00:47,  1.18s/it, loss=0.1473, batch_acc=0.9688, running_acc=0.9826, grad=15.1930]Training epoch 49:  75%|███████▌  | 123/163 [02:20<00:47,  1.18s/it, loss=0.0850, batch_acc=0.9688, running_acc=0.9825, grad=6.8349] Training epoch 49:  76%|███████▌  | 124/163 [02:21<00:42,  1.09s/it, loss=0.0850, batch_acc=0.9688, running_acc=0.9825, grad=6.8349]Training epoch 49:  76%|███████▌  | 124/163 [02:21<00:42,  1.09s/it, loss=0.1415, batch_acc=0.9688, running_acc=0.9824, grad=13.2491]Training epoch 49:  77%|███████▋  | 125/163 [02:21<00:39,  1.03s/it, loss=0.1415, batch_acc=0.9688, running_acc=0.9824, grad=13.2491]Training epoch 49:  77%|███████▋  | 125/163 [02:21<00:39,  1.03s/it, loss=0.1300, batch_acc=0.9688, running_acc=0.9822, grad=6.0968] Training epoch 49:  77%|███████▋  | 126/163 [02:22<00:36,  1.02it/s, loss=0.1300, batch_acc=0.9688, running_acc=0.9822, grad=6.0968]Training epoch 49:  77%|███████▋  | 126/163 [02:22<00:36,  1.02it/s, loss=0.1639, batch_acc=0.9375, running_acc=0.9819, grad=15.2432]Training epoch 49:  78%|███████▊  | 127/163 [02:24<00:41,  1.16s/it, loss=0.1639, batch_acc=0.9375, running_acc=0.9819, grad=15.2432]Training epoch 49:  78%|███████▊  | 127/163 [02:24<00:41,  1.16s/it, loss=0.0836, batch_acc=1.0000, running_acc=0.9820, grad=6.0652] Training epoch 49:  79%|███████▊  | 128/163 [02:25<00:39,  1.12s/it, loss=0.0836, batch_acc=1.0000, running_acc=0.9820, grad=6.0652]Training epoch 49:  79%|███████▊  | 128/163 [02:25<00:39,  1.12s/it, loss=0.0787, batch_acc=1.0000, running_acc=0.9822, grad=6.3920]Training epoch 49:  79%|███████▉  | 129/163 [02:26<00:35,  1.05s/it, loss=0.0787, batch_acc=1.0000, running_acc=0.9822, grad=6.3920]Training epoch 49:  79%|███████▉  | 129/163 [02:26<00:35,  1.05s/it, loss=0.1111, batch_acc=1.0000, running_acc=0.9823, grad=9.5020]Training epoch 49:  80%|███████▉  | 130/163 [02:27<00:33,  1.00s/it, loss=0.1111, batch_acc=1.0000, running_acc=0.9823, grad=9.5020]Training epoch 49:  80%|███████▉  | 130/163 [02:27<00:33,  1.00s/it, loss=0.0989, batch_acc=1.0000, running_acc=0.9825, grad=6.3732]Training epoch 49:  80%|████████  | 131/163 [02:28<00:38,  1.20s/it, loss=0.0989, batch_acc=1.0000, running_acc=0.9825, grad=6.3732]Training epoch 49:  80%|████████  | 131/163 [02:28<00:38,  1.20s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9826, grad=5.9334]Training epoch 49:  81%|████████  | 132/163 [02:29<00:34,  1.10s/it, loss=0.0772, batch_acc=1.0000, running_acc=0.9826, grad=5.9334]Training epoch 49:  81%|████████  | 132/163 [02:29<00:34,  1.10s/it, loss=0.0873, batch_acc=1.0000, running_acc=0.9827, grad=7.2941]Training epoch 49:  82%|████████▏ | 133/163 [02:30<00:31,  1.04s/it, loss=0.0873, batch_acc=1.0000, running_acc=0.9827, grad=7.2941]Training epoch 49:  82%|████████▏ | 133/163 [02:30<00:31,  1.04s/it, loss=0.1160, batch_acc=0.9375, running_acc=0.9824, grad=7.7306]Training epoch 49:  82%|████████▏ | 134/163 [02:31<00:28,  1.01it/s, loss=0.1160, batch_acc=0.9375, running_acc=0.9824, grad=7.7306]Training epoch 49:  82%|████████▏ | 134/163 [02:31<00:28,  1.01it/s, loss=0.1134, batch_acc=1.0000, running_acc=0.9825, grad=12.7479]Training epoch 49:  83%|████████▎ | 135/163 [02:33<00:36,  1.32s/it, loss=0.1134, batch_acc=1.0000, running_acc=0.9825, grad=12.7479]Training epoch 49:  83%|████████▎ | 135/163 [02:33<00:36,  1.32s/it, loss=0.1134, batch_acc=0.9688, running_acc=0.9824, grad=9.8852] Training epoch 49:  83%|████████▎ | 136/163 [02:34<00:32,  1.19s/it, loss=0.1134, batch_acc=0.9688, running_acc=0.9824, grad=9.8852]Training epoch 49:  83%|████████▎ | 136/163 [02:34<00:32,  1.19s/it, loss=0.0818, batch_acc=1.0000, running_acc=0.9825, grad=8.5884]Training epoch 49:  84%|████████▍ | 137/163 [02:35<00:28,  1.09s/it, loss=0.0818, batch_acc=1.0000, running_acc=0.9825, grad=8.5884]Training epoch 49:  84%|████████▍ | 137/163 [02:35<00:28,  1.09s/it, loss=0.0701, batch_acc=1.0000, running_acc=0.9827, grad=5.3533]Training epoch 49:  85%|████████▍ | 138/163 [02:36<00:25,  1.03s/it, loss=0.0701, batch_acc=1.0000, running_acc=0.9827, grad=5.3533]Training epoch 49:  85%|████████▍ | 138/163 [02:36<00:25,  1.03s/it, loss=0.0884, batch_acc=1.0000, running_acc=0.9828, grad=7.9836]Training epoch 49:  85%|████████▌ | 139/163 [02:38<00:37,  1.54s/it, loss=0.0884, batch_acc=1.0000, running_acc=0.9828, grad=7.9836]Training epoch 49:  85%|████████▌ | 139/163 [02:38<00:37,  1.54s/it, loss=0.1131, batch_acc=1.0000, running_acc=0.9829, grad=7.2356]Training epoch 49:  86%|████████▌ | 140/163 [02:39<00:30,  1.34s/it, loss=0.1131, batch_acc=1.0000, running_acc=0.9829, grad=7.2356]Training epoch 49:  86%|████████▌ | 140/163 [02:39<00:30,  1.34s/it, loss=0.1287, batch_acc=0.9375, running_acc=0.9826, grad=7.1393]Training epoch 49:  87%|████████▋ | 141/163 [02:40<00:26,  1.20s/it, loss=0.1287, batch_acc=0.9375, running_acc=0.9826, grad=7.1393]Training epoch 49:  87%|████████▋ | 141/163 [02:40<00:26,  1.20s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9827, grad=6.5543]Training epoch 49:  87%|████████▋ | 142/163 [02:41<00:23,  1.11s/it, loss=0.0877, batch_acc=1.0000, running_acc=0.9827, grad=6.5543]Training epoch 49:  87%|████████▋ | 142/163 [02:41<00:23,  1.11s/it, loss=0.0793, batch_acc=1.0000, running_acc=0.9828, grad=6.6583]Training epoch 49:  88%|████████▊ | 143/163 [02:43<00:28,  1.44s/it, loss=0.0793, batch_acc=1.0000, running_acc=0.9828, grad=6.6583]Training epoch 49:  88%|████████▊ | 143/163 [02:43<00:28,  1.44s/it, loss=0.1008, batch_acc=1.0000, running_acc=0.9830, grad=8.9101]Training epoch 49:  88%|████████▊ | 144/163 [02:44<00:24,  1.27s/it, loss=0.1008, batch_acc=1.0000, running_acc=0.9830, grad=8.9101]Training epoch 49:  88%|████████▊ | 144/163 [02:44<00:24,  1.27s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9831, grad=8.6503]Training epoch 49:  89%|████████▉ | 145/163 [02:45<00:20,  1.15s/it, loss=0.1091, batch_acc=1.0000, running_acc=0.9831, grad=8.6503]Training epoch 49:  89%|████████▉ | 145/163 [02:45<00:20,  1.15s/it, loss=0.2000, batch_acc=0.9688, running_acc=0.9830, grad=10.7824]Training epoch 49:  90%|████████▉ | 146/163 [02:46<00:18,  1.07s/it, loss=0.2000, batch_acc=0.9688, running_acc=0.9830, grad=10.7824]Training epoch 49:  90%|████████▉ | 146/163 [02:46<00:18,  1.07s/it, loss=0.0744, batch_acc=1.0000, running_acc=0.9831, grad=8.6411] Training epoch 49:  90%|█████████ | 147/163 [02:48<00:20,  1.30s/it, loss=0.0744, batch_acc=1.0000, running_acc=0.9831, grad=8.6411]Training epoch 49:  90%|█████████ | 147/163 [02:48<00:20,  1.30s/it, loss=0.1484, batch_acc=0.9375, running_acc=0.9828, grad=10.0864]Training epoch 49:  91%|█████████ | 148/163 [02:49<00:17,  1.17s/it, loss=0.1484, batch_acc=0.9375, running_acc=0.9828, grad=10.0864]Training epoch 49:  91%|█████████ | 148/163 [02:49<00:17,  1.17s/it, loss=0.0727, batch_acc=1.0000, running_acc=0.9829, grad=5.5392] Training epoch 49:  91%|█████████▏| 149/163 [02:50<00:15,  1.09s/it, loss=0.0727, batch_acc=1.0000, running_acc=0.9829, grad=5.5392]Training epoch 49:  91%|█████████▏| 149/163 [02:50<00:15,  1.09s/it, loss=0.0460, batch_acc=1.0000, running_acc=0.9830, grad=4.4547]Training epoch 49:  92%|█████████▏| 150/163 [02:50<00:13,  1.02s/it, loss=0.0460, batch_acc=1.0000, running_acc=0.9830, grad=4.4547]Training epoch 49:  92%|█████████▏| 150/163 [02:50<00:13,  1.02s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9831, grad=8.8385]Training epoch 49:  93%|█████████▎| 151/163 [02:53<00:16,  1.40s/it, loss=0.0942, batch_acc=1.0000, running_acc=0.9831, grad=8.8385]Training epoch 49:  93%|█████████▎| 151/163 [02:53<00:16,  1.40s/it, loss=0.0585, batch_acc=1.0000, running_acc=0.9832, grad=5.3534]Training epoch 49:  93%|█████████▎| 152/163 [02:54<00:13,  1.25s/it, loss=0.0585, batch_acc=1.0000, running_acc=0.9832, grad=5.3534]Training epoch 49:  93%|█████████▎| 152/163 [02:54<00:13,  1.25s/it, loss=0.0643, batch_acc=1.0000, running_acc=0.9833, grad=5.4797]Training epoch 49:  94%|█████████▍| 153/163 [02:54<00:11,  1.14s/it, loss=0.0643, batch_acc=1.0000, running_acc=0.9833, grad=5.4797]Training epoch 49:  94%|█████████▍| 153/163 [02:54<00:11,  1.14s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9835, grad=6.1799]Training epoch 49:  94%|█████████▍| 154/163 [02:55<00:09,  1.06s/it, loss=0.0847, batch_acc=1.0000, running_acc=0.9835, grad=6.1799]Training epoch 49:  94%|█████████▍| 154/163 [02:55<00:09,  1.06s/it, loss=0.0749, batch_acc=1.0000, running_acc=0.9836, grad=6.3990]Training epoch 49:  95%|█████████▌| 155/163 [02:58<00:11,  1.42s/it, loss=0.0749, batch_acc=1.0000, running_acc=0.9836, grad=6.3990]Training epoch 49:  95%|█████████▌| 155/163 [02:58<00:11,  1.42s/it, loss=0.1088, batch_acc=1.0000, running_acc=0.9837, grad=7.1503]Training epoch 49:  96%|█████████▌| 156/163 [02:58<00:08,  1.26s/it, loss=0.1088, batch_acc=1.0000, running_acc=0.9837, grad=7.1503]Training epoch 49:  96%|█████████▌| 156/163 [02:58<00:08,  1.26s/it, loss=0.1369, batch_acc=1.0000, running_acc=0.9838, grad=12.3163]Training epoch 49:  96%|█████████▋| 157/163 [02:59<00:06,  1.14s/it, loss=0.1369, batch_acc=1.0000, running_acc=0.9838, grad=12.3163]Training epoch 49:  96%|█████████▋| 157/163 [02:59<00:06,  1.14s/it, loss=0.1137, batch_acc=1.0000, running_acc=0.9839, grad=12.7570]Training epoch 49:  97%|█████████▋| 158/163 [03:00<00:05,  1.06s/it, loss=0.1137, batch_acc=1.0000, running_acc=0.9839, grad=12.7570]Training epoch 49:  97%|█████████▋| 158/163 [03:00<00:05,  1.06s/it, loss=0.0551, batch_acc=1.0000, running_acc=0.9840, grad=5.3315] Training epoch 49:  98%|█████████▊| 159/163 [03:02<00:04,  1.18s/it, loss=0.0551, batch_acc=1.0000, running_acc=0.9840, grad=5.3315]Training epoch 49:  98%|█████████▊| 159/163 [03:02<00:04,  1.18s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9841, grad=10.8429]Training epoch 49:  98%|█████████▊| 160/163 [03:03<00:03,  1.09s/it, loss=0.0912, batch_acc=1.0000, running_acc=0.9841, grad=10.8429]Training epoch 49:  98%|█████████▊| 160/163 [03:03<00:03,  1.09s/it, loss=0.0792, batch_acc=1.0000, running_acc=0.9842, grad=5.0640] Training epoch 49:  99%|█████████▉| 161/163 [03:03<00:02,  1.03s/it, loss=0.0792, batch_acc=1.0000, running_acc=0.9842, grad=5.0640]Training epoch 49:  99%|█████████▉| 161/163 [03:03<00:02,  1.03s/it, loss=0.1349, batch_acc=1.0000, running_acc=0.9843, grad=18.2327]Training epoch 49:  99%|█████████▉| 162/163 [03:04<00:00,  1.02it/s, loss=0.1349, batch_acc=1.0000, running_acc=0.9843, grad=18.2327]Training epoch 49:  99%|█████████▉| 162/163 [03:04<00:00,  1.02it/s, loss=0.1091, batch_acc=1.0000, running_acc=0.9844, grad=12.8382]Training epoch 49: 100%|██████████| 163/163 [03:05<00:00,  1.13it/s, loss=0.1091, batch_acc=1.0000, running_acc=0.9844, grad=12.8382]Training epoch 49: 100%|██████████| 163/163 [03:05<00:00,  1.13it/s, loss=0.0581, batch_acc=1.0000, running_acc=0.9844, grad=7.1192] Training epoch 49: 100%|██████████| 163/163 [03:05<00:00,  1.14s/it, loss=0.0581, batch_acc=1.0000, running_acc=0.9844, grad=7.1192]
Evaluation epoch 49:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 49:   4%|▎         | 1/28 [00:05<02:16,  5.07s/it]Evaluation epoch 49:   4%|▎         | 1/28 [00:05<02:16,  5.07s/it, loss=0.3742, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 49:   7%|▋         | 2/28 [00:05<00:59,  2.27s/it, loss=0.3742, batch_acc=0.9062, running_acc=0.9062]Evaluation epoch 49:   7%|▋         | 2/28 [00:05<00:59,  2.27s/it, loss=0.2191, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 49:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.2191, batch_acc=1.0000, running_acc=0.9531]Evaluation epoch 49:  11%|█         | 3/28 [00:05<00:33,  1.35s/it, loss=0.2954, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 49:  14%|█▍        | 4/28 [00:09<01:00,  2.52s/it, loss=0.2954, batch_acc=0.9688, running_acc=0.9583]Evaluation epoch 49:  14%|█▍        | 4/28 [00:09<01:00,  2.52s/it, loss=0.4139, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 49:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=0.4139, batch_acc=0.9062, running_acc=0.9453]Evaluation epoch 49:  18%|█▊        | 5/28 [00:10<00:39,  1.71s/it, loss=1.3115, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 49:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=1.3115, batch_acc=0.6875, running_acc=0.8938]Evaluation epoch 49:  21%|██▏       | 6/28 [00:10<00:26,  1.22s/it, loss=0.5004, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 49:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.5004, batch_acc=0.9062, running_acc=0.8958]Evaluation epoch 49:  25%|██▌       | 7/28 [00:10<00:18,  1.11it/s, loss=0.6107, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 49:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=0.6107, batch_acc=0.8750, running_acc=0.8929]Evaluation epoch 49:  29%|██▊       | 8/28 [00:14<00:33,  1.70s/it, loss=0.4034, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 49:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.4034, batch_acc=0.8438, running_acc=0.8867]Evaluation epoch 49:  32%|███▏      | 9/28 [00:14<00:23,  1.25s/it, loss=0.4095, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 49:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.4095, batch_acc=0.9062, running_acc=0.8889]Evaluation epoch 49:  36%|███▌      | 10/28 [00:14<00:17,  1.06it/s, loss=0.4349, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 49:  39%|███▉      | 11/28 [00:14<00:12,  1.36it/s, loss=0.4349, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 49:  39%|███▉      | 11/28 [00:14<00:12,  1.36it/s, loss=0.2977, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 49:  43%|████▎     | 12/28 [00:20<00:37,  2.33s/it, loss=0.2977, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 49:  43%|████▎     | 12/28 [00:20<00:37,  2.33s/it, loss=0.8780, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 49:  46%|████▋     | 13/28 [00:21<00:25,  1.70s/it, loss=0.8780, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 49:  46%|████▋     | 13/28 [00:21<00:25,  1.70s/it, loss=0.2656, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 49:  50%|█████     | 14/28 [00:21<00:17,  1.27s/it, loss=0.2656, batch_acc=0.9375, running_acc=0.8942]Evaluation epoch 49:  50%|█████     | 14/28 [00:21<00:17,  1.27s/it, loss=0.8582, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 49:  54%|█████▎    | 15/28 [00:21<00:12,  1.04it/s, loss=0.8582, batch_acc=0.7500, running_acc=0.8839]Evaluation epoch 49:  54%|█████▎    | 15/28 [00:21<00:12,  1.04it/s, loss=0.9331, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 49:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=0.9331, batch_acc=0.8438, running_acc=0.8812]Evaluation epoch 49:  57%|█████▋    | 16/28 [00:24<00:18,  1.56s/it, loss=0.7749, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 49:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=0.7749, batch_acc=0.7812, running_acc=0.8750]Evaluation epoch 49:  61%|██████    | 17/28 [00:24<00:12,  1.17s/it, loss=0.6391, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 49:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=0.6391, batch_acc=0.7500, running_acc=0.8676]Evaluation epoch 49:  64%|██████▍   | 18/28 [00:25<00:08,  1.12it/s, loss=0.5284, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 49:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=0.5284, batch_acc=0.8750, running_acc=0.8681]Evaluation epoch 49:  68%|██████▊   | 19/28 [00:25<00:06,  1.42it/s, loss=0.8788, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 49:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=0.8788, batch_acc=0.6250, running_acc=0.8553]Evaluation epoch 49:  71%|███████▏  | 20/28 [00:28<00:10,  1.37s/it, loss=0.5620, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 49:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.5620, batch_acc=0.7188, running_acc=0.8484]Evaluation epoch 49:  75%|███████▌  | 21/28 [00:28<00:07,  1.04s/it, loss=0.5645, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 49:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.5645, batch_acc=0.8125, running_acc=0.8467]Evaluation epoch 49:  79%|███████▊  | 22/28 [00:28<00:04,  1.24it/s, loss=0.4025, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 49:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.4025, batch_acc=0.9688, running_acc=0.8523]Evaluation epoch 49:  82%|████████▏ | 23/28 [00:29<00:03,  1.56it/s, loss=0.7714, batch_acc=0.7812, running_acc=0.8492]Evaluation epoch 49:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=0.7714, batch_acc=0.7812, running_acc=0.8492]Evaluation epoch 49:  86%|████████▌ | 24/28 [00:34<00:08,  2.07s/it, loss=0.2958, batch_acc=0.9375, running_acc=0.8529]Evaluation epoch 49:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.2958, batch_acc=0.9375, running_acc=0.8529]Evaluation epoch 49:  89%|████████▉ | 25/28 [00:34<00:04,  1.53s/it, loss=0.1263, batch_acc=1.0000, running_acc=0.8588]Evaluation epoch 49:  93%|█████████▎| 26/28 [00:35<00:02,  1.15s/it, loss=0.1263, batch_acc=1.0000, running_acc=0.8588]Evaluation epoch 49:  93%|█████████▎| 26/28 [00:35<00:02,  1.15s/it, loss=0.5662, batch_acc=0.8438, running_acc=0.8582]Evaluation epoch 49:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=0.5662, batch_acc=0.8438, running_acc=0.8582]Evaluation epoch 49:  96%|█████████▋| 27/28 [00:35<00:00,  1.13it/s, loss=0.8310, batch_acc=0.7812, running_acc=0.8553]Evaluation epoch 49: 100%|██████████| 28/28 [00:35<00:00,  1.13it/s, loss=1.1329, batch_acc=0.6667, running_acc=0.8547]Evaluation epoch 49: 100%|██████████| 28/28 [00:35<00:00,  1.26s/it, loss=1.1329, batch_acc=0.6667, running_acc=0.8547]
Evaluation epoch 49:   0%|          | 0/28 [00:00<?, ?it/s]Evaluation epoch 49:   4%|▎         | 1/28 [00:04<02:04,  4.63s/it]Evaluation epoch 49:   4%|▎         | 1/28 [00:04<02:04,  4.63s/it, loss=0.3794, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 49:   7%|▋         | 2/28 [00:05<00:57,  2.19s/it, loss=0.3794, batch_acc=0.9375, running_acc=0.9375]Evaluation epoch 49:   7%|▋         | 2/28 [00:05<00:57,  2.19s/it, loss=0.2518, batch_acc=0.9688, running_acc=0.9531]Evaluation epoch 49:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.2518, batch_acc=0.9688, running_acc=0.9531]Evaluation epoch 49:  11%|█         | 3/28 [00:05<00:32,  1.31s/it, loss=0.3800, batch_acc=0.9375, running_acc=0.9479]Evaluation epoch 49:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.3800, batch_acc=0.9375, running_acc=0.9479]Evaluation epoch 49:  14%|█▍        | 4/28 [00:09<00:58,  2.45s/it, loss=0.5064, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 49:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=0.5064, batch_acc=0.9062, running_acc=0.9375]Evaluation epoch 49:  18%|█▊        | 5/28 [00:09<00:38,  1.66s/it, loss=0.8048, batch_acc=0.8125, running_acc=0.9125]Evaluation epoch 49:  21%|██▏       | 6/28 [00:10<00:26,  1.18s/it, loss=0.8048, batch_acc=0.8125, running_acc=0.9125]Evaluation epoch 49:  21%|██▏       | 6/28 [00:10<00:26,  1.18s/it, loss=0.6271, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 49:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.6271, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 49:  25%|██▌       | 7/28 [00:10<00:18,  1.13it/s, loss=0.4681, batch_acc=0.9375, running_acc=0.8973]Evaluation epoch 49:  29%|██▊       | 8/28 [00:14<00:36,  1.82s/it, loss=0.4681, batch_acc=0.9375, running_acc=0.8973]Evaluation epoch 49:  29%|██▊       | 8/28 [00:14<00:36,  1.82s/it, loss=0.5964, batch_acc=0.8438, running_acc=0.8906]Evaluation epoch 49:  32%|███▏      | 9/28 [00:14<00:25,  1.34s/it, loss=0.5964, batch_acc=0.8438, running_acc=0.8906]Evaluation epoch 49:  32%|███▏      | 9/28 [00:14<00:25,  1.34s/it, loss=0.5832, batch_acc=0.8750, running_acc=0.8889]Evaluation epoch 49:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.5832, batch_acc=0.8750, running_acc=0.8889]Evaluation epoch 49:  36%|███▌      | 10/28 [00:14<00:18,  1.00s/it, loss=0.2713, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 49:  39%|███▉      | 11/28 [00:14<00:13,  1.29it/s, loss=0.2713, batch_acc=0.9375, running_acc=0.8938]Evaluation epoch 49:  39%|███▉      | 11/28 [00:14<00:13,  1.29it/s, loss=0.2392, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 49:  43%|████▎     | 12/28 [00:18<00:27,  1.75s/it, loss=0.2392, batch_acc=0.9688, running_acc=0.9006]Evaluation epoch 49:  43%|████▎     | 12/28 [00:18<00:27,  1.75s/it, loss=0.9008, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 49:  46%|████▋     | 13/28 [00:19<00:22,  1.49s/it, loss=0.9008, batch_acc=0.7812, running_acc=0.8906]Evaluation epoch 49:  46%|████▋     | 13/28 [00:19<00:22,  1.49s/it, loss=0.4407, batch_acc=0.9062, running_acc=0.8918]Evaluation epoch 49:  50%|█████     | 14/28 [00:20<00:15,  1.12s/it, loss=0.4407, batch_acc=0.9062, running_acc=0.8918]Evaluation epoch 49:  50%|█████     | 14/28 [00:20<00:15,  1.12s/it, loss=0.5680, batch_acc=0.8750, running_acc=0.8906]Evaluation epoch 49:  54%|█████▎    | 15/28 [00:20<00:11,  1.16it/s, loss=0.5680, batch_acc=0.8750, running_acc=0.8906]Evaluation epoch 49:  54%|█████▎    | 15/28 [00:20<00:11,  1.16it/s, loss=0.5385, batch_acc=0.8750, running_acc=0.8896]Evaluation epoch 49:  57%|█████▋    | 16/28 [00:22<00:13,  1.14s/it, loss=0.5385, batch_acc=0.8750, running_acc=0.8896]Evaluation epoch 49:  57%|█████▋    | 16/28 [00:22<00:13,  1.14s/it, loss=0.7296, batch_acc=0.7812, running_acc=0.8828]Evaluation epoch 49:  61%|██████    | 17/28 [00:23<00:12,  1.10s/it, loss=0.7296, batch_acc=0.7812, running_acc=0.8828]Evaluation epoch 49:  61%|██████    | 17/28 [00:23<00:12,  1.10s/it, loss=0.8167, batch_acc=0.5938, running_acc=0.8658]Evaluation epoch 49:  64%|██████▍   | 18/28 [00:23<00:08,  1.18it/s, loss=0.8167, batch_acc=0.5938, running_acc=0.8658]Evaluation epoch 49:  64%|██████▍   | 18/28 [00:23<00:08,  1.18it/s, loss=0.5560, batch_acc=0.8438, running_acc=0.8646]Evaluation epoch 49:  68%|██████▊   | 19/28 [00:23<00:06,  1.49it/s, loss=0.5560, batch_acc=0.8438, running_acc=0.8646]Evaluation epoch 49:  68%|██████▊   | 19/28 [00:23<00:06,  1.49it/s, loss=0.6394, batch_acc=0.8438, running_acc=0.8635]Evaluation epoch 49:  71%|███████▏  | 20/28 [00:26<00:09,  1.19s/it, loss=0.6394, batch_acc=0.8438, running_acc=0.8635]Evaluation epoch 49:  71%|███████▏  | 20/28 [00:26<00:09,  1.19s/it, loss=0.9837, batch_acc=0.4375, running_acc=0.8422]Evaluation epoch 49:  75%|███████▌  | 21/28 [00:27<00:08,  1.17s/it, loss=0.9837, batch_acc=0.4375, running_acc=0.8422]Evaluation epoch 49:  75%|███████▌  | 21/28 [00:27<00:08,  1.17s/it, loss=0.7112, batch_acc=0.8438, running_acc=0.8423]Evaluation epoch 49:  79%|███████▊  | 22/28 [00:27<00:05,  1.11it/s, loss=0.7112, batch_acc=0.8438, running_acc=0.8423]Evaluation epoch 49:  79%|███████▊  | 22/28 [00:27<00:05,  1.11it/s, loss=0.5084, batch_acc=0.8438, running_acc=0.8423]Evaluation epoch 49:  82%|████████▏ | 23/28 [00:27<00:03,  1.42it/s, loss=0.5084, batch_acc=0.8438, running_acc=0.8423]Evaluation epoch 49:  82%|████████▏ | 23/28 [00:27<00:03,  1.42it/s, loss=0.8529, batch_acc=0.8438, running_acc=0.8424]Evaluation epoch 49:  86%|████████▌ | 24/28 [00:30<00:05,  1.29s/it, loss=0.8529, batch_acc=0.8438, running_acc=0.8424]Evaluation epoch 49:  86%|████████▌ | 24/28 [00:30<00:05,  1.29s/it, loss=0.6638, batch_acc=0.8125, running_acc=0.8411]Evaluation epoch 49:  89%|████████▉ | 25/28 [00:33<00:05,  1.69s/it, loss=0.6638, batch_acc=0.8125, running_acc=0.8411]Evaluation epoch 49:  89%|████████▉ | 25/28 [00:33<00:05,  1.69s/it, loss=0.0739, batch_acc=1.0000, running_acc=0.8475]Evaluation epoch 49:  93%|█████████▎| 26/28 [00:33<00:02,  1.26s/it, loss=0.0739, batch_acc=1.0000, running_acc=0.8475]Evaluation epoch 49:  93%|█████████▎| 26/28 [00:33<00:02,  1.26s/it, loss=0.4085, batch_acc=0.9062, running_acc=0.8498]Evaluation epoch 49:  96%|█████████▋| 27/28 [00:33<00:00,  1.04it/s, loss=0.4085, batch_acc=0.9062, running_acc=0.8498]Evaluation epoch 49:  96%|█████████▋| 27/28 [00:33<00:00,  1.04it/s, loss=0.3984, batch_acc=0.9375, running_acc=0.8530]Evaluation epoch 49: 100%|██████████| 28/28 [00:33<00:00,  1.31it/s, loss=0.3984, batch_acc=0.9375, running_acc=0.8530]Evaluation epoch 49: 100%|██████████| 28/28 [00:33<00:00,  1.31it/s, loss=0.7726, batch_acc=0.8667, running_acc=0.8535]Evaluation epoch 49: 100%|██████████| 28/28 [00:33<00:00,  1.21s/it, loss=0.7726, batch_acc=0.8667, running_acc=0.8535]
